Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=71, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.9516,                   Accuracy: 254/2000.0 (12.70%)



-= Testing valid =-
Test set: Average loss: 1.3563,                   Accuracy: 1029/2000.0 (51.45%)



-= Testing valid =-
Test set: Average loss: 0.7014,                   Accuracy: 1563/2000.0 (78.15%)



-= Testing valid =-
Test set: Average loss: 0.3355,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.2554,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2037,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.2001,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1702,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1186,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1982,                   Accuracy: 1874/2000.0 (93.70%)



Epoch 10 train accuracy: 97.39%, valid accuracy 93.70%
-= Testing valid =-
Test set: Average loss: 0.1106,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0707,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 20 train accuracy: 98.39%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0698,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0633,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0620,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 30 train accuracy: 98.72%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0568,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0629,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0585,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 40 train accuracy: 99.21%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0575,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0547,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 50 train accuracy: 99.16%, valid accuracy 98.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0726,                   Accuracy: 58705/60000 (97.84%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1099,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2424,                   Accuracy: 55931/60000 (93.22%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5476,                   Accuracy: 51105/60000 (85.18%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8642,                   Accuracy: 45524/60000 (75.87%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9391,                   Accuracy: 43869/60000 (73.11%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6439,                   Accuracy: 48281/60000 (80.47%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2869,                   Accuracy: 54680/60000 (91.13%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1050,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0726,                   Accuracy: 58705/60000 (97.84%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1099,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2424,                   Accuracy: 55931/60000 (93.22%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5476,                   Accuracy: 51105/60000 (85.18%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8642,                   Accuracy: 45524/60000 (75.87%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9391,                   Accuracy: 43869/60000 (73.11%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6439,                   Accuracy: 48281/60000 (80.47%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2869,                   Accuracy: 54680/60000 (91.13%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1050,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0726,                   Accuracy: 58705/60000 (97.84%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1099,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2424,                   Accuracy: 55931/60000 (93.22%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5476,                   Accuracy: 51105/60000 (85.18%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8642,                   Accuracy: 45524/60000 (75.87%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9391,                   Accuracy: 43869/60000 (73.11%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6439,                   Accuracy: 48281/60000 (80.47%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2869,                   Accuracy: 54680/60000 (91.13%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1050,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0726,                   Accuracy: 58705/60000 (97.84%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1099,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2424,                   Accuracy: 55931/60000 (93.22%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5476,                   Accuracy: 51105/60000 (85.18%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8642,                   Accuracy: 45524/60000 (75.87%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9391,                   Accuracy: 43869/60000 (73.11%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6439,                   Accuracy: 48281/60000 (80.47%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2869,                   Accuracy: 54680/60000 (91.13%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1050,                   Accuracy: 58097/60000 (96.83%)
{0: tensor(97.8417), 10: tensor(96.7450), 20: tensor(93.2183), 30: tensor(85.1750), 40: tensor(75.8733), 50: tensor(73.1150), 60: tensor(80.4683), 70: tensor(91.1333), 80: tensor(96.8283), 90: tensor(97.8417), 100: tensor(96.7450), 110: tensor(93.2183), 120: tensor(85.1750), 130: tensor(75.8733), 140: tensor(73.1150), 150: tensor(80.4683), 160: tensor(91.1333), 170: tensor(96.8283), 180: tensor(97.8417), 190: tensor(96.7450), 200: tensor(93.2183), 210: tensor(85.1750), 220: tensor(75.8733), 230: tensor(73.1150), 240: tensor(80.4683), 250: tensor(91.1333), 260: tensor(96.8283), 270: tensor(97.8417), 280: tensor(96.7450), 290: tensor(93.2183), 300: tensor(85.1750), 310: tensor(75.8733), 320: tensor(73.1150), 330: tensor(80.4683), 340: tensor(91.1333), 350: tensor(96.8283)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=72, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2304,                   Accuracy: 520/2000.0 (26.00%)



-= Testing valid =-
Test set: Average loss: 0.9389,                   Accuracy: 1459/2000.0 (72.95%)



-= Testing valid =-
Test set: Average loss: 0.8608,                   Accuracy: 1358/2000.0 (67.90%)



-= Testing valid =-
Test set: Average loss: 0.5294,                   Accuracy: 1643/2000.0 (82.15%)



-= Testing valid =-
Test set: Average loss: 0.2502,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.5920,                   Accuracy: 1597/2000.0 (79.85%)



-= Testing valid =-
Test set: Average loss: 0.2097,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.2162,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.1707,                   Accuracy: 1887/2000.0 (94.35%)



Epoch 10 train accuracy: 96.12%, valid accuracy 94.35%
-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1058,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.1132,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 20 train accuracy: 97.60%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0734,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0738,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0647,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0590,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0626,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0497,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 30 train accuracy: 98.40%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0485,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 40 train accuracy: 98.69%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0477,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 50 train accuracy: 99.00%, valid accuracy 98.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0834,                   Accuracy: 58571/60000 (97.62%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1342,                   Accuracy: 57566/60000 (95.94%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2644,                   Accuracy: 55298/60000 (92.16%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6291,                   Accuracy: 49417/60000 (82.36%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0577,                   Accuracy: 43033/60000 (71.72%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1301,                   Accuracy: 41560/60000 (69.27%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7411,                   Accuracy: 47219/60000 (78.70%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3649,                   Accuracy: 53483/60000 (89.14%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1300,                   Accuracy: 57637/60000 (96.06%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0834,                   Accuracy: 58571/60000 (97.62%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1342,                   Accuracy: 57566/60000 (95.94%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2644,                   Accuracy: 55298/60000 (92.16%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6291,                   Accuracy: 49417/60000 (82.36%)
-= Testing Rotation 130 =-
Test set: Average loss: 1.0577,                   Accuracy: 43033/60000 (71.72%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.1301,                   Accuracy: 41560/60000 (69.27%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7411,                   Accuracy: 47219/60000 (78.70%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3649,                   Accuracy: 53483/60000 (89.14%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1300,                   Accuracy: 57637/60000 (96.06%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0834,                   Accuracy: 58571/60000 (97.62%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1342,                   Accuracy: 57566/60000 (95.94%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2644,                   Accuracy: 55298/60000 (92.16%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6291,                   Accuracy: 49417/60000 (82.36%)
-= Testing Rotation 220 =-
Test set: Average loss: 1.0577,                   Accuracy: 43033/60000 (71.72%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.1301,                   Accuracy: 41560/60000 (69.27%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7411,                   Accuracy: 47219/60000 (78.70%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3649,                   Accuracy: 53483/60000 (89.14%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1300,                   Accuracy: 57637/60000 (96.06%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0834,                   Accuracy: 58571/60000 (97.62%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1342,                   Accuracy: 57566/60000 (95.94%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2644,                   Accuracy: 55298/60000 (92.16%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6291,                   Accuracy: 49417/60000 (82.36%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0577,                   Accuracy: 43033/60000 (71.72%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1301,                   Accuracy: 41560/60000 (69.27%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7411,                   Accuracy: 47219/60000 (78.70%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3649,                   Accuracy: 53483/60000 (89.14%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1300,                   Accuracy: 57637/60000 (96.06%)
{0: tensor(97.6183), 10: tensor(95.9433), 20: tensor(92.1633), 30: tensor(82.3617), 40: tensor(71.7217), 50: tensor(69.2667), 60: tensor(78.6983), 70: tensor(89.1383), 80: tensor(96.0617), 90: tensor(97.6183), 100: tensor(95.9433), 110: tensor(92.1633), 120: tensor(82.3617), 130: tensor(71.7217), 140: tensor(69.2667), 150: tensor(78.6983), 160: tensor(89.1383), 170: tensor(96.0617), 180: tensor(97.6183), 190: tensor(95.9433), 200: tensor(92.1633), 210: tensor(82.3617), 220: tensor(71.7217), 230: tensor(69.2667), 240: tensor(78.6983), 250: tensor(89.1383), 260: tensor(96.0617), 270: tensor(97.6183), 280: tensor(95.9433), 290: tensor(92.1633), 300: tensor(82.3617), 310: tensor(71.7217), 320: tensor(69.2667), 330: tensor(78.6983), 340: tensor(89.1383), 350: tensor(96.0617)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=73, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9195,                   Accuracy: 647/2000.0 (32.35%)



-= Testing valid =-
Test set: Average loss: 1.0637,                   Accuracy: 1174/2000.0 (58.70%)



-= Testing valid =-
Test set: Average loss: 0.7895,                   Accuracy: 1499/2000.0 (74.95%)



-= Testing valid =-
Test set: Average loss: 0.4391,                   Accuracy: 1735/2000.0 (86.75%)



-= Testing valid =-
Test set: Average loss: 0.2622,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.3452,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.1305,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1231,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1230,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1386,                   Accuracy: 1909/2000.0 (95.45%)



Epoch 10 train accuracy: 96.14%, valid accuracy 95.45%
-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1012,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0719,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0734,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1449,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.0619,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 20 train accuracy: 97.78%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0657,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0559,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0641,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 30 train accuracy: 98.19%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0580,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0618,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 40 train accuracy: 98.88%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0497,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 50 train accuracy: 99.05%, valid accuracy 98.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0792,                   Accuracy: 58589/60000 (97.65%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1166,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2508,                   Accuracy: 55568/60000 (92.61%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5466,                   Accuracy: 50574/60000 (84.29%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8782,                   Accuracy: 45110/60000 (75.18%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9321,                   Accuracy: 44009/60000 (73.35%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6121,                   Accuracy: 49116/60000 (81.86%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2800,                   Accuracy: 54909/60000 (91.51%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1189,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0792,                   Accuracy: 58589/60000 (97.65%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1166,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2508,                   Accuracy: 55568/60000 (92.61%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5466,                   Accuracy: 50574/60000 (84.29%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8782,                   Accuracy: 45110/60000 (75.18%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9321,                   Accuracy: 44009/60000 (73.35%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6121,                   Accuracy: 49116/60000 (81.86%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2800,                   Accuracy: 54909/60000 (91.51%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1189,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0792,                   Accuracy: 58589/60000 (97.65%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1166,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2508,                   Accuracy: 55568/60000 (92.61%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5466,                   Accuracy: 50574/60000 (84.29%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8782,                   Accuracy: 45110/60000 (75.18%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9321,                   Accuracy: 44009/60000 (73.35%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6121,                   Accuracy: 49116/60000 (81.86%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2800,                   Accuracy: 54909/60000 (91.51%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1189,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0792,                   Accuracy: 58589/60000 (97.65%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1166,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2508,                   Accuracy: 55568/60000 (92.61%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5466,                   Accuracy: 50574/60000 (84.29%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8782,                   Accuracy: 45110/60000 (75.18%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9321,                   Accuracy: 44009/60000 (73.35%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6121,                   Accuracy: 49116/60000 (81.86%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2800,                   Accuracy: 54909/60000 (91.51%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1189,                   Accuracy: 57887/60000 (96.48%)
{0: tensor(97.6483), 10: tensor(96.5217), 20: tensor(92.6133), 30: tensor(84.2900), 40: tensor(75.1833), 50: tensor(73.3483), 60: tensor(81.8600), 70: tensor(91.5150), 80: tensor(96.4783), 90: tensor(97.6483), 100: tensor(96.5217), 110: tensor(92.6133), 120: tensor(84.2900), 130: tensor(75.1833), 140: tensor(73.3483), 150: tensor(81.8600), 160: tensor(91.5150), 170: tensor(96.4783), 180: tensor(97.6483), 190: tensor(96.5217), 200: tensor(92.6133), 210: tensor(84.2900), 220: tensor(75.1833), 230: tensor(73.3483), 240: tensor(81.8600), 250: tensor(91.5150), 260: tensor(96.4783), 270: tensor(97.6483), 280: tensor(96.5217), 290: tensor(92.6133), 300: tensor(84.2900), 310: tensor(75.1833), 320: tensor(73.3483), 330: tensor(81.8600), 340: tensor(91.5150), 350: tensor(96.4783)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=74, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9177,                   Accuracy: 564/2000.0 (28.20%)



-= Testing valid =-
Test set: Average loss: 1.0691,                   Accuracy: 1284/2000.0 (64.20%)



-= Testing valid =-
Test set: Average loss: 1.1518,                   Accuracy: 1270/2000.0 (63.50%)



-= Testing valid =-
Test set: Average loss: 0.6621,                   Accuracy: 1572/2000.0 (78.60%)



-= Testing valid =-
Test set: Average loss: 0.5015,                   Accuracy: 1655/2000.0 (82.75%)



-= Testing valid =-
Test set: Average loss: 0.2665,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2405,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.1615,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1285,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1663,                   Accuracy: 1893/2000.0 (94.65%)



Epoch 10 train accuracy: 96.04%, valid accuracy 94.65%
-= Testing valid =-
Test set: Average loss: 0.1110,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.2188,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.0677,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.1182,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0677,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 20 train accuracy: 97.81%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0625,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 30 train accuracy: 98.47%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0600,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0485,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0497,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 40 train accuracy: 98.82%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0469,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 50 train accuracy: 98.90%, valid accuracy 98.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0799,                   Accuracy: 58610/60000 (97.68%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1313,                   Accuracy: 57698/60000 (96.16%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2846,                   Accuracy: 55099/60000 (91.83%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6172,                   Accuracy: 49520/60000 (82.53%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9994,                   Accuracy: 43024/60000 (71.71%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0725,                   Accuracy: 41433/60000 (69.06%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7707,                   Accuracy: 46430/60000 (77.38%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3550,                   Accuracy: 53686/60000 (89.48%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1316,                   Accuracy: 57651/60000 (96.08%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0799,                   Accuracy: 58610/60000 (97.68%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1313,                   Accuracy: 57698/60000 (96.16%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2846,                   Accuracy: 55099/60000 (91.83%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6172,                   Accuracy: 49520/60000 (82.53%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9994,                   Accuracy: 43024/60000 (71.71%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0725,                   Accuracy: 41433/60000 (69.06%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7707,                   Accuracy: 46430/60000 (77.38%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3550,                   Accuracy: 53686/60000 (89.48%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1316,                   Accuracy: 57651/60000 (96.08%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0799,                   Accuracy: 58610/60000 (97.68%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1313,                   Accuracy: 57698/60000 (96.16%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2846,                   Accuracy: 55099/60000 (91.83%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6172,                   Accuracy: 49520/60000 (82.53%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9994,                   Accuracy: 43024/60000 (71.71%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0725,                   Accuracy: 41433/60000 (69.06%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7707,                   Accuracy: 46430/60000 (77.38%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3550,                   Accuracy: 53686/60000 (89.48%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1316,                   Accuracy: 57651/60000 (96.08%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0799,                   Accuracy: 58610/60000 (97.68%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1313,                   Accuracy: 57698/60000 (96.16%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2846,                   Accuracy: 55099/60000 (91.83%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6172,                   Accuracy: 49520/60000 (82.53%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9994,                   Accuracy: 43024/60000 (71.71%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0725,                   Accuracy: 41433/60000 (69.06%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7707,                   Accuracy: 46430/60000 (77.38%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3550,                   Accuracy: 53686/60000 (89.48%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1316,                   Accuracy: 57651/60000 (96.08%)
{0: tensor(97.6833), 10: tensor(96.1633), 20: tensor(91.8317), 30: tensor(82.5333), 40: tensor(71.7067), 50: tensor(69.0550), 60: tensor(77.3833), 70: tensor(89.4767), 80: tensor(96.0850), 90: tensor(97.6833), 100: tensor(96.1633), 110: tensor(91.8317), 120: tensor(82.5333), 130: tensor(71.7067), 140: tensor(69.0550), 150: tensor(77.3833), 160: tensor(89.4767), 170: tensor(96.0850), 180: tensor(97.6833), 190: tensor(96.1633), 200: tensor(91.8317), 210: tensor(82.5333), 220: tensor(71.7067), 230: tensor(69.0550), 240: tensor(77.3833), 250: tensor(89.4767), 260: tensor(96.0850), 270: tensor(97.6833), 280: tensor(96.1633), 290: tensor(91.8317), 300: tensor(82.5333), 310: tensor(71.7067), 320: tensor(69.0550), 330: tensor(77.3833), 340: tensor(89.4767), 350: tensor(96.0850)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=75, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0468,                   Accuracy: 661/2000.0 (33.05%)



-= Testing valid =-
Test set: Average loss: 1.4077,                   Accuracy: 925/2000.0 (46.25%)



-= Testing valid =-
Test set: Average loss: 1.2488,                   Accuracy: 1152/2000.0 (57.60%)



-= Testing valid =-
Test set: Average loss: 0.3049,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.3676,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.2208,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.2493,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2004,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.1444,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1959,                   Accuracy: 1882/2000.0 (94.10%)



Epoch 10 train accuracy: 96.56%, valid accuracy 94.10%
-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1207,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.0755,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1254,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1072,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0723,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 20 train accuracy: 97.97%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0602,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0578,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0596,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 30 train accuracy: 98.57%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0520,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 40 train accuracy: 98.90%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 50 train accuracy: 99.21%, valid accuracy 98.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0823,                   Accuracy: 58572/60000 (97.62%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1511,                   Accuracy: 57233/60000 (95.39%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3253,                   Accuracy: 54231/60000 (90.39%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5996,                   Accuracy: 49440/60000 (82.40%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9606,                   Accuracy: 43715/60000 (72.86%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0352,                   Accuracy: 42674/60000 (71.12%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6274,                   Accuracy: 48964/60000 (81.61%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3093,                   Accuracy: 54492/60000 (90.82%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1231,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0823,                   Accuracy: 58572/60000 (97.62%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1511,                   Accuracy: 57233/60000 (95.39%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3253,                   Accuracy: 54231/60000 (90.39%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5996,                   Accuracy: 49440/60000 (82.40%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9606,                   Accuracy: 43715/60000 (72.86%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0352,                   Accuracy: 42674/60000 (71.12%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6274,                   Accuracy: 48964/60000 (81.61%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3093,                   Accuracy: 54492/60000 (90.82%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1231,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0823,                   Accuracy: 58572/60000 (97.62%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1511,                   Accuracy: 57233/60000 (95.39%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3253,                   Accuracy: 54231/60000 (90.39%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5996,                   Accuracy: 49440/60000 (82.40%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9606,                   Accuracy: 43715/60000 (72.86%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0352,                   Accuracy: 42674/60000 (71.12%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6274,                   Accuracy: 48964/60000 (81.61%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3093,                   Accuracy: 54492/60000 (90.82%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1231,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0823,                   Accuracy: 58572/60000 (97.62%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1511,                   Accuracy: 57233/60000 (95.39%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3253,                   Accuracy: 54231/60000 (90.39%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5996,                   Accuracy: 49440/60000 (82.40%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9606,                   Accuracy: 43715/60000 (72.86%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0352,                   Accuracy: 42674/60000 (71.12%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6274,                   Accuracy: 48964/60000 (81.61%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3093,                   Accuracy: 54492/60000 (90.82%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1231,                   Accuracy: 57804/60000 (96.34%)
{0: tensor(97.6200), 10: tensor(95.3883), 20: tensor(90.3850), 30: tensor(82.4000), 40: tensor(72.8583), 50: tensor(71.1233), 60: tensor(81.6067), 70: tensor(90.8200), 80: tensor(96.3400), 90: tensor(97.6200), 100: tensor(95.3883), 110: tensor(90.3850), 120: tensor(82.4000), 130: tensor(72.8583), 140: tensor(71.1233), 150: tensor(81.6067), 160: tensor(90.8200), 170: tensor(96.3400), 180: tensor(97.6200), 190: tensor(95.3883), 200: tensor(90.3850), 210: tensor(82.4000), 220: tensor(72.8583), 230: tensor(71.1233), 240: tensor(81.6067), 250: tensor(90.8200), 260: tensor(96.3400), 270: tensor(97.6200), 280: tensor(95.3883), 290: tensor(90.3850), 300: tensor(82.4000), 310: tensor(72.8583), 320: tensor(71.1233), 330: tensor(81.6067), 340: tensor(90.8200), 350: tensor(96.3400)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=76, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2959,                   Accuracy: 399/2000.0 (19.95%)



-= Testing valid =-
Test set: Average loss: 1.4636,                   Accuracy: 958/2000.0 (47.90%)



-= Testing valid =-
Test set: Average loss: 0.5300,                   Accuracy: 1676/2000.0 (83.80%)



-= Testing valid =-
Test set: Average loss: 0.2832,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.3886,                   Accuracy: 1745/2000.0 (87.25%)



-= Testing valid =-
Test set: Average loss: 0.2686,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.1312,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1349,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1128,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 10 train accuracy: 96.15%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0641,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0657,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 20 train accuracy: 97.96%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0567,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0646,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0554,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0485,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 30 train accuracy: 98.46%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0555,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 40 train accuracy: 98.74%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0477,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0450,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 50 train accuracy: 99.06%, valid accuracy 98.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0757,                   Accuracy: 58641/60000 (97.74%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1274,                   Accuracy: 57622/60000 (96.04%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2413,                   Accuracy: 55600/60000 (92.67%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4654,                   Accuracy: 51537/60000 (85.89%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7254,                   Accuracy: 47271/60000 (78.79%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.7606,                   Accuracy: 46694/60000 (77.82%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.4802,                   Accuracy: 51381/60000 (85.64%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2399,                   Accuracy: 55680/60000 (92.80%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1092,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0757,                   Accuracy: 58641/60000 (97.74%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1274,                   Accuracy: 57622/60000 (96.04%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2413,                   Accuracy: 55600/60000 (92.67%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4654,                   Accuracy: 51537/60000 (85.89%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7254,                   Accuracy: 47271/60000 (78.79%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.7606,                   Accuracy: 46694/60000 (77.82%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4802,                   Accuracy: 51381/60000 (85.64%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2399,                   Accuracy: 55680/60000 (92.80%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1092,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0757,                   Accuracy: 58641/60000 (97.74%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1274,                   Accuracy: 57622/60000 (96.04%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2413,                   Accuracy: 55600/60000 (92.67%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4654,                   Accuracy: 51537/60000 (85.89%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7254,                   Accuracy: 47271/60000 (78.79%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.7606,                   Accuracy: 46694/60000 (77.82%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4802,                   Accuracy: 51381/60000 (85.64%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2399,                   Accuracy: 55680/60000 (92.80%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1092,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0757,                   Accuracy: 58641/60000 (97.74%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1274,                   Accuracy: 57622/60000 (96.04%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2413,                   Accuracy: 55600/60000 (92.67%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.4654,                   Accuracy: 51537/60000 (85.89%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7254,                   Accuracy: 47271/60000 (78.79%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.7606,                   Accuracy: 46694/60000 (77.82%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4802,                   Accuracy: 51381/60000 (85.64%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2399,                   Accuracy: 55680/60000 (92.80%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1092,                   Accuracy: 57987/60000 (96.64%)
{0: tensor(97.7350), 10: tensor(96.0367), 20: tensor(92.6667), 30: tensor(85.8950), 40: tensor(78.7850), 50: tensor(77.8233), 60: tensor(85.6350), 70: tensor(92.8000), 80: tensor(96.6450), 90: tensor(97.7350), 100: tensor(96.0367), 110: tensor(92.6667), 120: tensor(85.8950), 130: tensor(78.7850), 140: tensor(77.8233), 150: tensor(85.6350), 160: tensor(92.8000), 170: tensor(96.6450), 180: tensor(97.7350), 190: tensor(96.0367), 200: tensor(92.6667), 210: tensor(85.8950), 220: tensor(78.7850), 230: tensor(77.8233), 240: tensor(85.6350), 250: tensor(92.8000), 260: tensor(96.6450), 270: tensor(97.7350), 280: tensor(96.0367), 290: tensor(92.6667), 300: tensor(85.8950), 310: tensor(78.7850), 320: tensor(77.8233), 330: tensor(85.6350), 340: tensor(92.8000), 350: tensor(96.6450)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=77, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3856,                   Accuracy: 461/2000.0 (23.05%)



-= Testing valid =-
Test set: Average loss: 2.3173,                   Accuracy: 522/2000.0 (26.10%)



-= Testing valid =-
Test set: Average loss: 0.9250,                   Accuracy: 1371/2000.0 (68.55%)



-= Testing valid =-
Test set: Average loss: 0.5440,                   Accuracy: 1648/2000.0 (82.40%)



-= Testing valid =-
Test set: Average loss: 1.1391,                   Accuracy: 1237/2000.0 (61.85%)



-= Testing valid =-
Test set: Average loss: 0.3821,                   Accuracy: 1740/2000.0 (87.00%)



-= Testing valid =-
Test set: Average loss: 0.2071,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.5610,                   Accuracy: 1632/2000.0 (81.60%)



-= Testing valid =-
Test set: Average loss: 0.2430,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.1419,                   Accuracy: 1914/2000.0 (95.70%)



Epoch 10 train accuracy: 95.09%, valid accuracy 95.70%
-= Testing valid =-
Test set: Average loss: 0.1430,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1149,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1117,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1169,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1235,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 20 train accuracy: 97.95%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0641,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0617,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0650,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0687,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 30 train accuracy: 98.50%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0578,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0590,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 40 train accuracy: 98.57%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0519,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 50 train accuracy: 98.85%, valid accuracy 98.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0819,                   Accuracy: 58596/60000 (97.66%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1309,                   Accuracy: 57620/60000 (96.03%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2557,                   Accuracy: 55302/60000 (92.17%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5502,                   Accuracy: 50302/60000 (83.84%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8540,                   Accuracy: 45809/60000 (76.35%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9068,                   Accuracy: 44973/60000 (74.96%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6079,                   Accuracy: 49421/60000 (82.37%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3153,                   Accuracy: 54338/60000 (90.56%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1352,                   Accuracy: 57543/60000 (95.90%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0819,                   Accuracy: 58596/60000 (97.66%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1309,                   Accuracy: 57620/60000 (96.03%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2557,                   Accuracy: 55302/60000 (92.17%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5502,                   Accuracy: 50302/60000 (83.84%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8540,                   Accuracy: 45809/60000 (76.35%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9068,                   Accuracy: 44973/60000 (74.96%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6079,                   Accuracy: 49421/60000 (82.37%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3153,                   Accuracy: 54338/60000 (90.56%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1352,                   Accuracy: 57543/60000 (95.90%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0819,                   Accuracy: 58596/60000 (97.66%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1309,                   Accuracy: 57620/60000 (96.03%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2557,                   Accuracy: 55302/60000 (92.17%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5502,                   Accuracy: 50302/60000 (83.84%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8540,                   Accuracy: 45809/60000 (76.35%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9068,                   Accuracy: 44973/60000 (74.96%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6079,                   Accuracy: 49421/60000 (82.37%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3153,                   Accuracy: 54338/60000 (90.56%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1352,                   Accuracy: 57543/60000 (95.90%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0819,                   Accuracy: 58596/60000 (97.66%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1309,                   Accuracy: 57620/60000 (96.03%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2557,                   Accuracy: 55302/60000 (92.17%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5502,                   Accuracy: 50302/60000 (83.84%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8540,                   Accuracy: 45809/60000 (76.35%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9068,                   Accuracy: 44973/60000 (74.96%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6079,                   Accuracy: 49421/60000 (82.37%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3153,                   Accuracy: 54338/60000 (90.56%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1352,                   Accuracy: 57543/60000 (95.90%)
{0: tensor(97.6600), 10: tensor(96.0333), 20: tensor(92.1700), 30: tensor(83.8367), 40: tensor(76.3483), 50: tensor(74.9550), 60: tensor(82.3683), 70: tensor(90.5633), 80: tensor(95.9050), 90: tensor(97.6600), 100: tensor(96.0333), 110: tensor(92.1700), 120: tensor(83.8367), 130: tensor(76.3483), 140: tensor(74.9550), 150: tensor(82.3683), 160: tensor(90.5633), 170: tensor(95.9050), 180: tensor(97.6600), 190: tensor(96.0333), 200: tensor(92.1700), 210: tensor(83.8367), 220: tensor(76.3483), 230: tensor(74.9550), 240: tensor(82.3683), 250: tensor(90.5633), 260: tensor(95.9050), 270: tensor(97.6600), 280: tensor(96.0333), 290: tensor(92.1700), 300: tensor(83.8367), 310: tensor(76.3483), 320: tensor(74.9550), 330: tensor(82.3683), 340: tensor(90.5633), 350: tensor(95.9050)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=78, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2025,                   Accuracy: 552/2000.0 (27.60%)



-= Testing valid =-
Test set: Average loss: 1.2130,                   Accuracy: 1186/2000.0 (59.30%)



-= Testing valid =-
Test set: Average loss: 1.4410,                   Accuracy: 1035/2000.0 (51.75%)



-= Testing valid =-
Test set: Average loss: 0.4967,                   Accuracy: 1698/2000.0 (84.90%)



-= Testing valid =-
Test set: Average loss: 0.3898,                   Accuracy: 1752/2000.0 (87.60%)



-= Testing valid =-
Test set: Average loss: 0.2360,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.1799,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1927,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.2525,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.1453,                   Accuracy: 1914/2000.0 (95.70%)



Epoch 10 train accuracy: 96.20%, valid accuracy 95.70%
-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1249,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1017,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1114,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1159,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 20 train accuracy: 97.79%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0704,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0686,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0802,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 30 train accuracy: 98.59%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0650,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0655,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0708,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 40 train accuracy: 98.89%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0620,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0636,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0632,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0630,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0618,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 50 train accuracy: 98.85%, valid accuracy 98.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0784,                   Accuracy: 58610/60000 (97.68%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1314,                   Accuracy: 57595/60000 (95.99%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2260,                   Accuracy: 55935/60000 (93.22%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4778,                   Accuracy: 51423/60000 (85.71%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7926,                   Accuracy: 45964/60000 (76.61%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8689,                   Accuracy: 44794/60000 (74.66%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5862,                   Accuracy: 49447/60000 (82.41%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2807,                   Accuracy: 54981/60000 (91.64%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1196,                   Accuracy: 57808/60000 (96.35%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0784,                   Accuracy: 58610/60000 (97.68%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1314,                   Accuracy: 57595/60000 (95.99%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2260,                   Accuracy: 55935/60000 (93.22%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4778,                   Accuracy: 51423/60000 (85.71%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7926,                   Accuracy: 45964/60000 (76.61%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8689,                   Accuracy: 44794/60000 (74.66%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5862,                   Accuracy: 49447/60000 (82.41%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2807,                   Accuracy: 54981/60000 (91.64%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1196,                   Accuracy: 57808/60000 (96.35%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0784,                   Accuracy: 58610/60000 (97.68%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1314,                   Accuracy: 57595/60000 (95.99%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2260,                   Accuracy: 55935/60000 (93.22%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4778,                   Accuracy: 51423/60000 (85.71%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7926,                   Accuracy: 45964/60000 (76.61%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8689,                   Accuracy: 44794/60000 (74.66%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5862,                   Accuracy: 49447/60000 (82.41%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2807,                   Accuracy: 54981/60000 (91.64%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1196,                   Accuracy: 57808/60000 (96.35%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0784,                   Accuracy: 58610/60000 (97.68%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1314,                   Accuracy: 57595/60000 (95.99%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2260,                   Accuracy: 55935/60000 (93.22%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.4778,                   Accuracy: 51423/60000 (85.71%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7926,                   Accuracy: 45963/60000 (76.61%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8689,                   Accuracy: 44794/60000 (74.66%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5862,                   Accuracy: 49447/60000 (82.41%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2807,                   Accuracy: 54981/60000 (91.64%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1196,                   Accuracy: 57808/60000 (96.35%)
{0: tensor(97.6833), 10: tensor(95.9917), 20: tensor(93.2250), 30: tensor(85.7050), 40: tensor(76.6067), 50: tensor(74.6567), 60: tensor(82.4117), 70: tensor(91.6350), 80: tensor(96.3467), 90: tensor(97.6833), 100: tensor(95.9917), 110: tensor(93.2250), 120: tensor(85.7050), 130: tensor(76.6067), 140: tensor(74.6567), 150: tensor(82.4117), 160: tensor(91.6350), 170: tensor(96.3467), 180: tensor(97.6833), 190: tensor(95.9917), 200: tensor(93.2250), 210: tensor(85.7050), 220: tensor(76.6067), 230: tensor(74.6567), 240: tensor(82.4117), 250: tensor(91.6350), 260: tensor(96.3467), 270: tensor(97.6833), 280: tensor(95.9917), 290: tensor(93.2250), 300: tensor(85.7050), 310: tensor(76.6050), 320: tensor(74.6567), 330: tensor(82.4117), 340: tensor(91.6350), 350: tensor(96.3467)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=79, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.6606,                   Accuracy: 642/2000.0 (32.10%)



-= Testing valid =-
Test set: Average loss: 1.0633,                   Accuracy: 1325/2000.0 (66.25%)



-= Testing valid =-
Test set: Average loss: 1.0846,                   Accuracy: 1234/2000.0 (61.70%)



-= Testing valid =-
Test set: Average loss: 0.5063,                   Accuracy: 1698/2000.0 (84.90%)



-= Testing valid =-
Test set: Average loss: 0.2649,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2141,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1711,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1260,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1140,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 10 train accuracy: 96.18%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.1158,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1146,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1015,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 20 train accuracy: 97.97%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0641,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0638,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0638,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0607,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 30 train accuracy: 98.56%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0555,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0604,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0572,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0520,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 40 train accuracy: 98.97%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0554,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 50 train accuracy: 99.10%, valid accuracy 98.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0834,                   Accuracy: 58537/60000 (97.56%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1312,                   Accuracy: 57665/60000 (96.11%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2672,                   Accuracy: 55368/60000 (92.28%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6046,                   Accuracy: 49798/60000 (83.00%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0546,                   Accuracy: 43123/60000 (71.87%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1752,                   Accuracy: 41292/60000 (68.82%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8149,                   Accuracy: 46452/60000 (77.42%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.4063,                   Accuracy: 53090/60000 (88.48%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1523,                   Accuracy: 57312/60000 (95.52%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0834,                   Accuracy: 58537/60000 (97.56%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1312,                   Accuracy: 57665/60000 (96.11%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2672,                   Accuracy: 55368/60000 (92.28%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6046,                   Accuracy: 49798/60000 (83.00%)
-= Testing Rotation 130 =-
Test set: Average loss: 1.0546,                   Accuracy: 43123/60000 (71.87%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.1752,                   Accuracy: 41292/60000 (68.82%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.8149,                   Accuracy: 46452/60000 (77.42%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4063,                   Accuracy: 53090/60000 (88.48%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1523,                   Accuracy: 57312/60000 (95.52%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0834,                   Accuracy: 58537/60000 (97.56%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1312,                   Accuracy: 57665/60000 (96.11%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2672,                   Accuracy: 55368/60000 (92.28%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6046,                   Accuracy: 49798/60000 (83.00%)
-= Testing Rotation 220 =-
Test set: Average loss: 1.0546,                   Accuracy: 43123/60000 (71.87%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.1752,                   Accuracy: 41292/60000 (68.82%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.8149,                   Accuracy: 46452/60000 (77.42%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.4063,                   Accuracy: 53090/60000 (88.48%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1523,                   Accuracy: 57312/60000 (95.52%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0834,                   Accuracy: 58537/60000 (97.56%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1312,                   Accuracy: 57665/60000 (96.11%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2672,                   Accuracy: 55368/60000 (92.28%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6046,                   Accuracy: 49798/60000 (83.00%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0546,                   Accuracy: 43123/60000 (71.87%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1752,                   Accuracy: 41292/60000 (68.82%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8149,                   Accuracy: 46452/60000 (77.42%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.4063,                   Accuracy: 53090/60000 (88.48%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1523,                   Accuracy: 57312/60000 (95.52%)
{0: tensor(97.5617), 10: tensor(96.1083), 20: tensor(92.2800), 30: tensor(82.9967), 40: tensor(71.8717), 50: tensor(68.8200), 60: tensor(77.4200), 70: tensor(88.4833), 80: tensor(95.5200), 90: tensor(97.5617), 100: tensor(96.1083), 110: tensor(92.2800), 120: tensor(82.9967), 130: tensor(71.8717), 140: tensor(68.8200), 150: tensor(77.4200), 160: tensor(88.4833), 170: tensor(95.5200), 180: tensor(97.5617), 190: tensor(96.1083), 200: tensor(92.2800), 210: tensor(82.9967), 220: tensor(71.8717), 230: tensor(68.8200), 240: tensor(77.4200), 250: tensor(88.4833), 260: tensor(95.5200), 270: tensor(97.5617), 280: tensor(96.1083), 290: tensor(92.2800), 300: tensor(82.9967), 310: tensor(71.8717), 320: tensor(68.8200), 330: tensor(77.4200), 340: tensor(88.4833), 350: tensor(95.5200)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=80, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.6798,                   Accuracy: 692/2000.0 (34.60%)



-= Testing valid =-
Test set: Average loss: 1.4900,                   Accuracy: 965/2000.0 (48.25%)



-= Testing valid =-
Test set: Average loss: 1.9229,                   Accuracy: 751/2000.0 (37.55%)



-= Testing valid =-
Test set: Average loss: 0.6182,                   Accuracy: 1595/2000.0 (79.75%)



-= Testing valid =-
Test set: Average loss: 0.3023,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2233,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.1626,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.2427,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.1484,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.2102,                   Accuracy: 1859/2000.0 (92.95%)



Epoch 10 train accuracy: 96.35%, valid accuracy 92.95%
-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1427,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1497,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 20 train accuracy: 97.95%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 30 train accuracy: 98.65%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0560,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0554,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0578,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0621,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 40 train accuracy: 98.94%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0559,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0568,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0594,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0535,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0580,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 50 train accuracy: 99.24%, valid accuracy 97.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0857,                   Accuracy: 58447/60000 (97.41%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1367,                   Accuracy: 57502/60000 (95.84%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2656,                   Accuracy: 55133/60000 (91.89%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5519,                   Accuracy: 49572/60000 (82.62%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7764,                   Accuracy: 45480/60000 (75.80%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.7880,                   Accuracy: 45222/60000 (75.37%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5057,                   Accuracy: 50410/60000 (84.02%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2527,                   Accuracy: 55259/60000 (92.10%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1163,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0857,                   Accuracy: 58447/60000 (97.41%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1367,                   Accuracy: 57502/60000 (95.84%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2656,                   Accuracy: 55133/60000 (91.89%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5519,                   Accuracy: 49572/60000 (82.62%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7764,                   Accuracy: 45480/60000 (75.80%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.7880,                   Accuracy: 45222/60000 (75.37%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5057,                   Accuracy: 50410/60000 (84.02%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2527,                   Accuracy: 55259/60000 (92.10%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1163,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0857,                   Accuracy: 58447/60000 (97.41%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1367,                   Accuracy: 57502/60000 (95.84%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2656,                   Accuracy: 55133/60000 (91.89%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5519,                   Accuracy: 49572/60000 (82.62%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7764,                   Accuracy: 45480/60000 (75.80%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.7880,                   Accuracy: 45222/60000 (75.37%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5057,                   Accuracy: 50410/60000 (84.02%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2527,                   Accuracy: 55259/60000 (92.10%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1163,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0857,                   Accuracy: 58447/60000 (97.41%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1367,                   Accuracy: 57502/60000 (95.84%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2656,                   Accuracy: 55133/60000 (91.89%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5519,                   Accuracy: 49572/60000 (82.62%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7764,                   Accuracy: 45480/60000 (75.80%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.7880,                   Accuracy: 45222/60000 (75.37%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5057,                   Accuracy: 50410/60000 (84.02%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2527,                   Accuracy: 55259/60000 (92.10%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1163,                   Accuracy: 57894/60000 (96.49%)
{0: tensor(97.4117), 10: tensor(95.8367), 20: tensor(91.8883), 30: tensor(82.6200), 40: tensor(75.8000), 50: tensor(75.3700), 60: tensor(84.0167), 70: tensor(92.0983), 80: tensor(96.4900), 90: tensor(97.4117), 100: tensor(95.8367), 110: tensor(91.8883), 120: tensor(82.6200), 130: tensor(75.8000), 140: tensor(75.3700), 150: tensor(84.0167), 160: tensor(92.0983), 170: tensor(96.4900), 180: tensor(97.4117), 190: tensor(95.8367), 200: tensor(91.8883), 210: tensor(82.6200), 220: tensor(75.8000), 230: tensor(75.3700), 240: tensor(84.0167), 250: tensor(92.0983), 260: tensor(96.4900), 270: tensor(97.4117), 280: tensor(95.8367), 290: tensor(91.8883), 300: tensor(82.6200), 310: tensor(75.8000), 320: tensor(75.3700), 330: tensor(84.0167), 340: tensor(92.0983), 350: tensor(96.4900)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=81, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.7438,                   Accuracy: 226/2000.0 (11.30%)



-= Testing valid =-
Test set: Average loss: 1.8566,                   Accuracy: 737/2000.0 (36.85%)



-= Testing valid =-
Test set: Average loss: 0.6461,                   Accuracy: 1561/2000.0 (78.05%)



-= Testing valid =-
Test set: Average loss: 0.5755,                   Accuracy: 1587/2000.0 (79.35%)



-= Testing valid =-
Test set: Average loss: 0.2539,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.3605,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.1728,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1037,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.2066,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1247,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 10 train accuracy: 96.51%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1093,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0798,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 20 train accuracy: 97.86%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 30 train accuracy: 98.57%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0644,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0585,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0638,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0606,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 40 train accuracy: 99.05%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0590,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0601,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0560,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0579,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 50 train accuracy: 99.05%, valid accuracy 98.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0855,                   Accuracy: 58474/60000 (97.46%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1304,                   Accuracy: 57595/60000 (95.99%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2555,                   Accuracy: 55389/60000 (92.32%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5465,                   Accuracy: 49606/60000 (82.68%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8052,                   Accuracy: 44963/60000 (74.94%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8092,                   Accuracy: 44845/60000 (74.74%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5455,                   Accuracy: 49667/60000 (82.78%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2667,                   Accuracy: 54902/60000 (91.50%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1216,                   Accuracy: 57758/60000 (96.26%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0855,                   Accuracy: 58474/60000 (97.46%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1304,                   Accuracy: 57595/60000 (95.99%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2555,                   Accuracy: 55389/60000 (92.32%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5465,                   Accuracy: 49606/60000 (82.68%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8052,                   Accuracy: 44963/60000 (74.94%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8092,                   Accuracy: 44845/60000 (74.74%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5455,                   Accuracy: 49667/60000 (82.78%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2667,                   Accuracy: 54902/60000 (91.50%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1216,                   Accuracy: 57758/60000 (96.26%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0855,                   Accuracy: 58474/60000 (97.46%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1304,                   Accuracy: 57595/60000 (95.99%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2555,                   Accuracy: 55389/60000 (92.32%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5465,                   Accuracy: 49606/60000 (82.68%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8052,                   Accuracy: 44963/60000 (74.94%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8092,                   Accuracy: 44845/60000 (74.74%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5455,                   Accuracy: 49667/60000 (82.78%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2667,                   Accuracy: 54902/60000 (91.50%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1216,                   Accuracy: 57758/60000 (96.26%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0855,                   Accuracy: 58474/60000 (97.46%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1304,                   Accuracy: 57595/60000 (95.99%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2555,                   Accuracy: 55389/60000 (92.32%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5465,                   Accuracy: 49606/60000 (82.68%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8052,                   Accuracy: 44963/60000 (74.94%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8092,                   Accuracy: 44845/60000 (74.74%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5455,                   Accuracy: 49667/60000 (82.78%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2667,                   Accuracy: 54902/60000 (91.50%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1216,                   Accuracy: 57758/60000 (96.26%)
{0: tensor(97.4567), 10: tensor(95.9917), 20: tensor(92.3150), 30: tensor(82.6767), 40: tensor(74.9383), 50: tensor(74.7417), 60: tensor(82.7783), 70: tensor(91.5033), 80: tensor(96.2633), 90: tensor(97.4567), 100: tensor(95.9917), 110: tensor(92.3150), 120: tensor(82.6767), 130: tensor(74.9383), 140: tensor(74.7417), 150: tensor(82.7783), 160: tensor(91.5033), 170: tensor(96.2633), 180: tensor(97.4567), 190: tensor(95.9917), 200: tensor(92.3150), 210: tensor(82.6767), 220: tensor(74.9383), 230: tensor(74.7417), 240: tensor(82.7783), 250: tensor(91.5033), 260: tensor(96.2633), 270: tensor(97.4567), 280: tensor(95.9917), 290: tensor(92.3150), 300: tensor(82.6767), 310: tensor(74.9383), 320: tensor(74.7417), 330: tensor(82.7783), 340: tensor(91.5033), 350: tensor(96.2633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=82, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9008,                   Accuracy: 548/2000.0 (27.40%)



-= Testing valid =-
Test set: Average loss: 1.2319,                   Accuracy: 1074/2000.0 (53.70%)



-= Testing valid =-
Test set: Average loss: 0.8218,                   Accuracy: 1441/2000.0 (72.05%)



-= Testing valid =-
Test set: Average loss: 1.2073,                   Accuracy: 1196/2000.0 (59.80%)



-= Testing valid =-
Test set: Average loss: 0.2830,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2752,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.3294,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.1234,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1966,                   Accuracy: 1864/2000.0 (93.20%)



Epoch 10 train accuracy: 96.14%, valid accuracy 93.20%
-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1166,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0756,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0738,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1221,                   Accuracy: 1905/2000.0 (95.25%)



Epoch 20 train accuracy: 97.96%, valid accuracy 95.25%
-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0486,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 30 train accuracy: 98.36%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 40 train accuracy: 98.89%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 50 train accuracy: 98.81%, valid accuracy 98.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0696,                   Accuracy: 58732/60000 (97.89%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1180,                   Accuracy: 57892/60000 (96.49%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2370,                   Accuracy: 55856/60000 (93.09%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4729,                   Accuracy: 51474/60000 (85.79%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7279,                   Accuracy: 46720/60000 (77.87%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.7631,                   Accuracy: 45590/60000 (75.98%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5083,                   Accuracy: 50208/60000 (83.68%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2374,                   Accuracy: 55529/60000 (92.55%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1050,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0696,                   Accuracy: 58732/60000 (97.89%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1180,                   Accuracy: 57892/60000 (96.49%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2370,                   Accuracy: 55856/60000 (93.09%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4729,                   Accuracy: 51474/60000 (85.79%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7279,                   Accuracy: 46720/60000 (77.87%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.7631,                   Accuracy: 45590/60000 (75.98%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5083,                   Accuracy: 50208/60000 (83.68%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2374,                   Accuracy: 55529/60000 (92.55%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1050,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0696,                   Accuracy: 58732/60000 (97.89%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1180,                   Accuracy: 57892/60000 (96.49%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2370,                   Accuracy: 55856/60000 (93.09%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4729,                   Accuracy: 51474/60000 (85.79%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7279,                   Accuracy: 46720/60000 (77.87%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.7631,                   Accuracy: 45590/60000 (75.98%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5083,                   Accuracy: 50208/60000 (83.68%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2374,                   Accuracy: 55529/60000 (92.55%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1050,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0696,                   Accuracy: 58732/60000 (97.89%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1180,                   Accuracy: 57892/60000 (96.49%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2370,                   Accuracy: 55856/60000 (93.09%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.4729,                   Accuracy: 51474/60000 (85.79%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7279,                   Accuracy: 46720/60000 (77.87%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.7631,                   Accuracy: 45590/60000 (75.98%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5083,                   Accuracy: 50208/60000 (83.68%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2374,                   Accuracy: 55529/60000 (92.55%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1050,                   Accuracy: 58081/60000 (96.80%)
{0: tensor(97.8867), 10: tensor(96.4867), 20: tensor(93.0933), 30: tensor(85.7900), 40: tensor(77.8667), 50: tensor(75.9833), 60: tensor(83.6800), 70: tensor(92.5483), 80: tensor(96.8017), 90: tensor(97.8867), 100: tensor(96.4867), 110: tensor(93.0933), 120: tensor(85.7900), 130: tensor(77.8667), 140: tensor(75.9833), 150: tensor(83.6800), 160: tensor(92.5483), 170: tensor(96.8017), 180: tensor(97.8867), 190: tensor(96.4867), 200: tensor(93.0933), 210: tensor(85.7900), 220: tensor(77.8667), 230: tensor(75.9833), 240: tensor(83.6800), 250: tensor(92.5483), 260: tensor(96.8017), 270: tensor(97.8867), 280: tensor(96.4867), 290: tensor(93.0933), 300: tensor(85.7900), 310: tensor(77.8667), 320: tensor(75.9833), 330: tensor(83.6800), 340: tensor(92.5483), 350: tensor(96.8017)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=83, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4462,                   Accuracy: 397/2000.0 (19.85%)



-= Testing valid =-
Test set: Average loss: 1.3604,                   Accuracy: 899/2000.0 (44.95%)



-= Testing valid =-
Test set: Average loss: 1.1551,                   Accuracy: 1160/2000.0 (58.00%)



-= Testing valid =-
Test set: Average loss: 1.1223,                   Accuracy: 1282/2000.0 (64.10%)



-= Testing valid =-
Test set: Average loss: 0.2563,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2577,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.1356,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1193,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1668,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1950,                   Accuracy: 1874/2000.0 (93.70%)



Epoch 10 train accuracy: 95.94%, valid accuracy 93.70%
-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1011,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 20 train accuracy: 97.74%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0708,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0734,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0630,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0602,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 30 train accuracy: 98.57%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0618,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0580,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0555,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0647,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0593,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 40 train accuracy: 98.89%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0637,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 50 train accuracy: 98.96%, valid accuracy 98.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0770,                   Accuracy: 58659/60000 (97.76%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1420,                   Accuracy: 57475/60000 (95.79%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2569,                   Accuracy: 55410/60000 (92.35%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5253,                   Accuracy: 50597/60000 (84.33%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8113,                   Accuracy: 45828/60000 (76.38%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8445,                   Accuracy: 45293/60000 (75.49%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5368,                   Accuracy: 50379/60000 (83.96%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2540,                   Accuracy: 55496/60000 (92.49%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1179,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0770,                   Accuracy: 58659/60000 (97.76%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1420,                   Accuracy: 57475/60000 (95.79%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2569,                   Accuracy: 55410/60000 (92.35%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5253,                   Accuracy: 50597/60000 (84.33%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8113,                   Accuracy: 45828/60000 (76.38%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8445,                   Accuracy: 45293/60000 (75.49%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5368,                   Accuracy: 50379/60000 (83.96%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2540,                   Accuracy: 55496/60000 (92.49%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1179,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0770,                   Accuracy: 58659/60000 (97.76%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1420,                   Accuracy: 57475/60000 (95.79%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2569,                   Accuracy: 55410/60000 (92.35%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5253,                   Accuracy: 50597/60000 (84.33%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8113,                   Accuracy: 45828/60000 (76.38%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8445,                   Accuracy: 45293/60000 (75.49%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5368,                   Accuracy: 50379/60000 (83.96%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2540,                   Accuracy: 55496/60000 (92.49%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1179,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0770,                   Accuracy: 58659/60000 (97.76%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1420,                   Accuracy: 57475/60000 (95.79%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2569,                   Accuracy: 55410/60000 (92.35%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5253,                   Accuracy: 50597/60000 (84.33%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8113,                   Accuracy: 45828/60000 (76.38%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8445,                   Accuracy: 45293/60000 (75.49%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5368,                   Accuracy: 50379/60000 (83.96%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2540,                   Accuracy: 55496/60000 (92.49%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1179,                   Accuracy: 57976/60000 (96.63%)
{0: tensor(97.7650), 10: tensor(95.7917), 20: tensor(92.3500), 30: tensor(84.3283), 40: tensor(76.3800), 50: tensor(75.4883), 60: tensor(83.9650), 70: tensor(92.4933), 80: tensor(96.6267), 90: tensor(97.7650), 100: tensor(95.7917), 110: tensor(92.3500), 120: tensor(84.3283), 130: tensor(76.3800), 140: tensor(75.4883), 150: tensor(83.9650), 160: tensor(92.4933), 170: tensor(96.6267), 180: tensor(97.7650), 190: tensor(95.7917), 200: tensor(92.3500), 210: tensor(84.3283), 220: tensor(76.3800), 230: tensor(75.4883), 240: tensor(83.9650), 250: tensor(92.4933), 260: tensor(96.6267), 270: tensor(97.7650), 280: tensor(95.7917), 290: tensor(92.3500), 300: tensor(84.3283), 310: tensor(76.3800), 320: tensor(75.4883), 330: tensor(83.9650), 340: tensor(92.4933), 350: tensor(96.6267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=84, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7770,                   Accuracy: 599/2000.0 (29.95%)



-= Testing valid =-
Test set: Average loss: 0.8559,                   Accuracy: 1393/2000.0 (69.65%)



-= Testing valid =-
Test set: Average loss: 1.2170,                   Accuracy: 1102/2000.0 (55.10%)



-= Testing valid =-
Test set: Average loss: 0.2430,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.3142,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.1782,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.2797,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.1663,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1168,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.2822,                   Accuracy: 1826/2000.0 (91.30%)



Epoch 10 train accuracy: 96.79%, valid accuracy 91.30%
-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0617,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0638,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0626,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0715,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0618,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.1236,                   Accuracy: 1921/2000.0 (96.05%)



Epoch 20 train accuracy: 98.06%, valid accuracy 96.05%
-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0595,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0617,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 30 train accuracy: 99.00%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0535,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 40 train accuracy: 99.12%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 50 train accuracy: 99.05%, valid accuracy 98.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0637,                   Accuracy: 58904/60000 (98.17%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1098,                   Accuracy: 58099/60000 (96.83%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2345,                   Accuracy: 55926/60000 (93.21%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5446,                   Accuracy: 50875/60000 (84.79%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8273,                   Accuracy: 45789/60000 (76.32%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8615,                   Accuracy: 44786/60000 (74.64%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5588,                   Accuracy: 49790/60000 (82.98%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2506,                   Accuracy: 55409/60000 (92.35%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1048,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0637,                   Accuracy: 58904/60000 (98.17%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1098,                   Accuracy: 58099/60000 (96.83%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2345,                   Accuracy: 55926/60000 (93.21%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5446,                   Accuracy: 50875/60000 (84.79%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8273,                   Accuracy: 45789/60000 (76.32%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8615,                   Accuracy: 44786/60000 (74.64%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5588,                   Accuracy: 49790/60000 (82.98%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2506,                   Accuracy: 55409/60000 (92.35%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1048,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0637,                   Accuracy: 58904/60000 (98.17%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1098,                   Accuracy: 58099/60000 (96.83%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2345,                   Accuracy: 55926/60000 (93.21%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5446,                   Accuracy: 50875/60000 (84.79%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8273,                   Accuracy: 45789/60000 (76.32%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8615,                   Accuracy: 44786/60000 (74.64%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5588,                   Accuracy: 49790/60000 (82.98%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2506,                   Accuracy: 55409/60000 (92.35%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1048,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0637,                   Accuracy: 58904/60000 (98.17%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1098,                   Accuracy: 58099/60000 (96.83%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2345,                   Accuracy: 55926/60000 (93.21%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5446,                   Accuracy: 50875/60000 (84.79%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8273,                   Accuracy: 45789/60000 (76.32%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8615,                   Accuracy: 44786/60000 (74.64%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5588,                   Accuracy: 49790/60000 (82.98%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2506,                   Accuracy: 55409/60000 (92.35%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1048,                   Accuracy: 58097/60000 (96.83%)
{0: tensor(98.1733), 10: tensor(96.8317), 20: tensor(93.2100), 30: tensor(84.7917), 40: tensor(76.3150), 50: tensor(74.6433), 60: tensor(82.9833), 70: tensor(92.3483), 80: tensor(96.8283), 90: tensor(98.1733), 100: tensor(96.8317), 110: tensor(93.2100), 120: tensor(84.7917), 130: tensor(76.3150), 140: tensor(74.6433), 150: tensor(82.9833), 160: tensor(92.3483), 170: tensor(96.8283), 180: tensor(98.1733), 190: tensor(96.8317), 200: tensor(93.2100), 210: tensor(84.7917), 220: tensor(76.3150), 230: tensor(74.6433), 240: tensor(82.9833), 250: tensor(92.3483), 260: tensor(96.8283), 270: tensor(98.1733), 280: tensor(96.8317), 290: tensor(93.2100), 300: tensor(84.7917), 310: tensor(76.3150), 320: tensor(74.6433), 330: tensor(82.9833), 340: tensor(92.3483), 350: tensor(96.8283)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=85, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 6.3462,                   Accuracy: 196/2000.0 (9.80%)



-= Testing valid =-
Test set: Average loss: 1.7649,                   Accuracy: 713/2000.0 (35.65%)



-= Testing valid =-
Test set: Average loss: 0.7486,                   Accuracy: 1570/2000.0 (78.50%)



-= Testing valid =-
Test set: Average loss: 1.1228,                   Accuracy: 1261/2000.0 (63.05%)



-= Testing valid =-
Test set: Average loss: 0.4720,                   Accuracy: 1680/2000.0 (84.00%)



-= Testing valid =-
Test set: Average loss: 0.4678,                   Accuracy: 1707/2000.0 (85.35%)



-= Testing valid =-
Test set: Average loss: 0.1478,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1837,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1760,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1733,                   Accuracy: 1907/2000.0 (95.35%)



Epoch 10 train accuracy: 96.46%, valid accuracy 95.35%
-= Testing valid =-
Test set: Average loss: 0.0882,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1191,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1208,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1632,                   Accuracy: 1908/2000.0 (95.40%)



Epoch 20 train accuracy: 98.18%, valid accuracy 95.40%
-= Testing valid =-
Test set: Average loss: 0.0628,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0595,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 30 train accuracy: 98.45%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0578,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0628,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0742,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 40 train accuracy: 99.16%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0567,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0606,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 50 train accuracy: 99.15%, valid accuracy 98.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0778,                   Accuracy: 58670/60000 (97.78%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1152,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2330,                   Accuracy: 55983/60000 (93.31%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5301,                   Accuracy: 50768/60000 (84.61%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8256,                   Accuracy: 45611/60000 (76.02%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9030,                   Accuracy: 44242/60000 (73.74%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6169,                   Accuracy: 49095/60000 (81.82%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2950,                   Accuracy: 54744/60000 (91.24%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1148,                   Accuracy: 57955/60000 (96.59%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0778,                   Accuracy: 58670/60000 (97.78%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1152,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2330,                   Accuracy: 55983/60000 (93.31%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5301,                   Accuracy: 50768/60000 (84.61%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8256,                   Accuracy: 45611/60000 (76.02%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9030,                   Accuracy: 44242/60000 (73.74%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6169,                   Accuracy: 49095/60000 (81.82%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2950,                   Accuracy: 54744/60000 (91.24%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1148,                   Accuracy: 57955/60000 (96.59%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0778,                   Accuracy: 58670/60000 (97.78%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1152,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2330,                   Accuracy: 55983/60000 (93.31%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5301,                   Accuracy: 50768/60000 (84.61%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8256,                   Accuracy: 45611/60000 (76.02%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9030,                   Accuracy: 44242/60000 (73.74%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6169,                   Accuracy: 49095/60000 (81.82%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2950,                   Accuracy: 54744/60000 (91.24%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1148,                   Accuracy: 57955/60000 (96.59%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0778,                   Accuracy: 58670/60000 (97.78%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1152,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2330,                   Accuracy: 55983/60000 (93.31%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5301,                   Accuracy: 50768/60000 (84.61%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8256,                   Accuracy: 45611/60000 (76.02%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9030,                   Accuracy: 44242/60000 (73.74%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6169,                   Accuracy: 49095/60000 (81.82%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2950,                   Accuracy: 54744/60000 (91.24%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1148,                   Accuracy: 57955/60000 (96.59%)
{0: tensor(97.7833), 10: tensor(96.7017), 20: tensor(93.3050), 30: tensor(84.6133), 40: tensor(76.0183), 50: tensor(73.7367), 60: tensor(81.8250), 70: tensor(91.2400), 80: tensor(96.5917), 90: tensor(97.7833), 100: tensor(96.7017), 110: tensor(93.3050), 120: tensor(84.6133), 130: tensor(76.0183), 140: tensor(73.7367), 150: tensor(81.8250), 160: tensor(91.2400), 170: tensor(96.5917), 180: tensor(97.7833), 190: tensor(96.7017), 200: tensor(93.3050), 210: tensor(84.6133), 220: tensor(76.0183), 230: tensor(73.7367), 240: tensor(81.8250), 250: tensor(91.2400), 260: tensor(96.5917), 270: tensor(97.7833), 280: tensor(96.7017), 290: tensor(93.3050), 300: tensor(84.6133), 310: tensor(76.0183), 320: tensor(73.7367), 330: tensor(81.8250), 340: tensor(91.2400), 350: tensor(96.5917)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=86, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.8497,                   Accuracy: 432/2000.0 (21.60%)



-= Testing valid =-
Test set: Average loss: 1.0956,                   Accuracy: 1182/2000.0 (59.10%)



-= Testing valid =-
Test set: Average loss: 0.5707,                   Accuracy: 1675/2000.0 (83.75%)



-= Testing valid =-
Test set: Average loss: 0.6566,                   Accuracy: 1544/2000.0 (77.20%)



-= Testing valid =-
Test set: Average loss: 0.6506,                   Accuracy: 1568/2000.0 (78.40%)



-= Testing valid =-
Test set: Average loss: 0.1846,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1849,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.2661,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.1197,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1891,                   Accuracy: 1894/2000.0 (94.70%)



Epoch 10 train accuracy: 96.26%, valid accuracy 94.70%
-= Testing valid =-
Test set: Average loss: 0.0935,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1112,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1146,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0686,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0622,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0628,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0632,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 20 train accuracy: 97.97%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 30 train accuracy: 98.59%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0485,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0477,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 40 train accuracy: 99.06%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 50 train accuracy: 99.05%, valid accuracy 98.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0827,                   Accuracy: 58573/60000 (97.62%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1424,                   Accuracy: 57514/60000 (95.86%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2891,                   Accuracy: 54905/60000 (91.51%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5914,                   Accuracy: 49761/60000 (82.93%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9046,                   Accuracy: 43598/60000 (72.66%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9559,                   Accuracy: 42066/60000 (70.11%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6259,                   Accuracy: 47843/60000 (79.74%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3068,                   Accuracy: 53960/60000 (89.93%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1314,                   Accuracy: 57583/60000 (95.97%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0827,                   Accuracy: 58573/60000 (97.62%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1424,                   Accuracy: 57514/60000 (95.86%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2891,                   Accuracy: 54905/60000 (91.51%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5914,                   Accuracy: 49761/60000 (82.93%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9046,                   Accuracy: 43598/60000 (72.66%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9559,                   Accuracy: 42066/60000 (70.11%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6259,                   Accuracy: 47843/60000 (79.74%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3068,                   Accuracy: 53960/60000 (89.93%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1314,                   Accuracy: 57583/60000 (95.97%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0827,                   Accuracy: 58573/60000 (97.62%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1424,                   Accuracy: 57514/60000 (95.86%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2891,                   Accuracy: 54904/60000 (91.51%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5914,                   Accuracy: 49761/60000 (82.93%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9046,                   Accuracy: 43598/60000 (72.66%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9559,                   Accuracy: 42066/60000 (70.11%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6259,                   Accuracy: 47843/60000 (79.74%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3068,                   Accuracy: 53960/60000 (89.93%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1314,                   Accuracy: 57583/60000 (95.97%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0827,                   Accuracy: 58573/60000 (97.62%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1424,                   Accuracy: 57514/60000 (95.86%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2891,                   Accuracy: 54904/60000 (91.51%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5914,                   Accuracy: 49761/60000 (82.93%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9046,                   Accuracy: 43598/60000 (72.66%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9559,                   Accuracy: 42066/60000 (70.11%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6259,                   Accuracy: 47843/60000 (79.74%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3068,                   Accuracy: 53960/60000 (89.93%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1314,                   Accuracy: 57583/60000 (95.97%)
{0: tensor(97.6217), 10: tensor(95.8567), 20: tensor(91.5083), 30: tensor(82.9350), 40: tensor(72.6633), 50: tensor(70.1100), 60: tensor(79.7383), 70: tensor(89.9333), 80: tensor(95.9717), 90: tensor(97.6217), 100: tensor(95.8567), 110: tensor(91.5083), 120: tensor(82.9350), 130: tensor(72.6633), 140: tensor(70.1100), 150: tensor(79.7383), 160: tensor(89.9333), 170: tensor(95.9717), 180: tensor(97.6217), 190: tensor(95.8567), 200: tensor(91.5067), 210: tensor(82.9350), 220: tensor(72.6633), 230: tensor(70.1100), 240: tensor(79.7383), 250: tensor(89.9333), 260: tensor(95.9717), 270: tensor(97.6217), 280: tensor(95.8567), 290: tensor(91.5067), 300: tensor(82.9350), 310: tensor(72.6633), 320: tensor(70.1100), 330: tensor(79.7383), 340: tensor(89.9333), 350: tensor(95.9717)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=87, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7103,                   Accuracy: 687/2000.0 (34.35%)



-= Testing valid =-
Test set: Average loss: 1.5420,                   Accuracy: 921/2000.0 (46.05%)



-= Testing valid =-
Test set: Average loss: 1.3109,                   Accuracy: 1103/2000.0 (55.15%)



-= Testing valid =-
Test set: Average loss: 0.5841,                   Accuracy: 1644/2000.0 (82.20%)



-= Testing valid =-
Test set: Average loss: 0.3001,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.1615,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1758,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.2968,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.3024,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.2463,                   Accuracy: 1856/2000.0 (92.80%)



Epoch 10 train accuracy: 95.78%, valid accuracy 92.80%
-= Testing valid =-
Test set: Average loss: 0.1222,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1074,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1012,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1261,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 20 train accuracy: 98.09%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 30 train accuracy: 98.82%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0678,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 40 train accuracy: 98.96%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0646,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0658,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0620,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0641,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0554,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 50 train accuracy: 99.07%, valid accuracy 98.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0777,                   Accuracy: 58643/60000 (97.74%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1318,                   Accuracy: 57682/60000 (96.14%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2955,                   Accuracy: 54868/60000 (91.45%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6511,                   Accuracy: 49047/60000 (81.75%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9852,                   Accuracy: 43551/60000 (72.58%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0397,                   Accuracy: 42703/60000 (71.17%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6522,                   Accuracy: 48389/60000 (80.65%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2920,                   Accuracy: 54746/60000 (91.24%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1150,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0777,                   Accuracy: 58643/60000 (97.74%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1318,                   Accuracy: 57682/60000 (96.14%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2955,                   Accuracy: 54868/60000 (91.45%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6511,                   Accuracy: 49047/60000 (81.75%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9852,                   Accuracy: 43551/60000 (72.58%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0397,                   Accuracy: 42703/60000 (71.17%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6522,                   Accuracy: 48389/60000 (80.65%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2920,                   Accuracy: 54746/60000 (91.24%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1150,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0777,                   Accuracy: 58643/60000 (97.74%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1318,                   Accuracy: 57682/60000 (96.14%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2955,                   Accuracy: 54868/60000 (91.45%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6511,                   Accuracy: 49047/60000 (81.75%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9852,                   Accuracy: 43551/60000 (72.58%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0397,                   Accuracy: 42703/60000 (71.17%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6522,                   Accuracy: 48389/60000 (80.65%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2920,                   Accuracy: 54746/60000 (91.24%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1150,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0777,                   Accuracy: 58643/60000 (97.74%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1318,                   Accuracy: 57682/60000 (96.14%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2955,                   Accuracy: 54868/60000 (91.45%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6511,                   Accuracy: 49047/60000 (81.75%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9852,                   Accuracy: 43551/60000 (72.58%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0397,                   Accuracy: 42703/60000 (71.17%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6522,                   Accuracy: 48389/60000 (80.65%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2920,                   Accuracy: 54746/60000 (91.24%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1150,                   Accuracy: 57953/60000 (96.59%)
{0: tensor(97.7383), 10: tensor(96.1367), 20: tensor(91.4467), 30: tensor(81.7450), 40: tensor(72.5850), 50: tensor(71.1717), 60: tensor(80.6483), 70: tensor(91.2433), 80: tensor(96.5883), 90: tensor(97.7383), 100: tensor(96.1367), 110: tensor(91.4467), 120: tensor(81.7450), 130: tensor(72.5850), 140: tensor(71.1717), 150: tensor(80.6483), 160: tensor(91.2433), 170: tensor(96.5883), 180: tensor(97.7383), 190: tensor(96.1367), 200: tensor(91.4467), 210: tensor(81.7450), 220: tensor(72.5850), 230: tensor(71.1717), 240: tensor(80.6483), 250: tensor(91.2433), 260: tensor(96.5883), 270: tensor(97.7383), 280: tensor(96.1367), 290: tensor(91.4467), 300: tensor(81.7450), 310: tensor(72.5850), 320: tensor(71.1717), 330: tensor(80.6483), 340: tensor(91.2433), 350: tensor(96.5883)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=88, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7384,                   Accuracy: 741/2000.0 (37.05%)



-= Testing valid =-
Test set: Average loss: 1.3943,                   Accuracy: 1063/2000.0 (53.15%)



-= Testing valid =-
Test set: Average loss: 3.8187,                   Accuracy: 366/2000.0 (18.30%)



-= Testing valid =-
Test set: Average loss: 0.6085,                   Accuracy: 1616/2000.0 (80.80%)



-= Testing valid =-
Test set: Average loss: 0.5236,                   Accuracy: 1643/2000.0 (82.15%)



-= Testing valid =-
Test set: Average loss: 0.2615,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2425,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2114,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1192,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1934/2000.0 (96.70%)



Epoch 10 train accuracy: 96.40%, valid accuracy 96.70%
-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0691,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 20 train accuracy: 97.57%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0572,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 30 train accuracy: 98.68%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0450,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0579,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 40 train accuracy: 98.90%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 50 train accuracy: 99.00%, valid accuracy 98.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0710,                   Accuracy: 58747/60000 (97.91%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1450,                   Accuracy: 57406/60000 (95.68%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2684,                   Accuracy: 55148/60000 (91.91%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6065,                   Accuracy: 49313/60000 (82.19%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9509,                   Accuracy: 43797/60000 (73.00%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9827,                   Accuracy: 43291/60000 (72.15%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6408,                   Accuracy: 48485/60000 (80.81%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3058,                   Accuracy: 54533/60000 (90.89%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1275,                   Accuracy: 57723/60000 (96.21%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0710,                   Accuracy: 58747/60000 (97.91%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1450,                   Accuracy: 57406/60000 (95.68%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2684,                   Accuracy: 55148/60000 (91.91%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6065,                   Accuracy: 49313/60000 (82.19%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9509,                   Accuracy: 43797/60000 (73.00%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9827,                   Accuracy: 43291/60000 (72.15%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6408,                   Accuracy: 48485/60000 (80.81%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3058,                   Accuracy: 54533/60000 (90.89%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1275,                   Accuracy: 57723/60000 (96.21%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0710,                   Accuracy: 58747/60000 (97.91%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1450,                   Accuracy: 57406/60000 (95.68%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2684,                   Accuracy: 55148/60000 (91.91%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6065,                   Accuracy: 49313/60000 (82.19%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9509,                   Accuracy: 43797/60000 (73.00%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9827,                   Accuracy: 43291/60000 (72.15%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6408,                   Accuracy: 48485/60000 (80.81%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3058,                   Accuracy: 54533/60000 (90.89%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1275,                   Accuracy: 57723/60000 (96.21%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0710,                   Accuracy: 58747/60000 (97.91%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1450,                   Accuracy: 57406/60000 (95.68%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2684,                   Accuracy: 55148/60000 (91.91%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6065,                   Accuracy: 49313/60000 (82.19%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9509,                   Accuracy: 43797/60000 (73.00%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9827,                   Accuracy: 43291/60000 (72.15%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6408,                   Accuracy: 48485/60000 (80.81%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3058,                   Accuracy: 54533/60000 (90.89%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1275,                   Accuracy: 57723/60000 (96.21%)
{0: tensor(97.9117), 10: tensor(95.6767), 20: tensor(91.9133), 30: tensor(82.1883), 40: tensor(72.9950), 50: tensor(72.1517), 60: tensor(80.8083), 70: tensor(90.8883), 80: tensor(96.2050), 90: tensor(97.9117), 100: tensor(95.6767), 110: tensor(91.9133), 120: tensor(82.1883), 130: tensor(72.9950), 140: tensor(72.1517), 150: tensor(80.8083), 160: tensor(90.8883), 170: tensor(96.2050), 180: tensor(97.9117), 190: tensor(95.6767), 200: tensor(91.9133), 210: tensor(82.1883), 220: tensor(72.9950), 230: tensor(72.1517), 240: tensor(80.8083), 250: tensor(90.8883), 260: tensor(96.2050), 270: tensor(97.9117), 280: tensor(95.6767), 290: tensor(91.9133), 300: tensor(82.1883), 310: tensor(72.9950), 320: tensor(72.1517), 330: tensor(80.8083), 340: tensor(90.8883), 350: tensor(96.2050)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=89, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4076,                   Accuracy: 246/2000.0 (12.30%)



-= Testing valid =-
Test set: Average loss: 1.2045,                   Accuracy: 1145/2000.0 (57.25%)



-= Testing valid =-
Test set: Average loss: 2.5397,                   Accuracy: 571/2000.0 (28.55%)



-= Testing valid =-
Test set: Average loss: 2.8424,                   Accuracy: 684/2000.0 (34.20%)



-= Testing valid =-
Test set: Average loss: 0.2080,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.4534,                   Accuracy: 1708/2000.0 (85.40%)



-= Testing valid =-
Test set: Average loss: 0.3955,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.1576,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1497,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1303,                   Accuracy: 1916/2000.0 (95.80%)



Epoch 10 train accuracy: 95.76%, valid accuracy 95.80%
-= Testing valid =-
Test set: Average loss: 0.1554,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0707,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.1994,                   Accuracy: 1882/2000.0 (94.10%)



Epoch 20 train accuracy: 97.55%, valid accuracy 94.10%
-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0560,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0547,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 30 train accuracy: 98.53%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0472,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 40 train accuracy: 98.75%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0454,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 50 train accuracy: 99.12%, valid accuracy 98.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0757,                   Accuracy: 58642/60000 (97.74%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1422,                   Accuracy: 57558/60000 (95.93%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2824,                   Accuracy: 55090/60000 (91.82%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5984,                   Accuracy: 49917/60000 (83.19%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9513,                   Accuracy: 44125/60000 (73.54%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0821,                   Accuracy: 42149/60000 (70.25%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6738,                   Accuracy: 48095/60000 (80.16%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3098,                   Accuracy: 54315/60000 (90.53%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1274,                   Accuracy: 57670/60000 (96.12%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0757,                   Accuracy: 58642/60000 (97.74%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1422,                   Accuracy: 57558/60000 (95.93%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2824,                   Accuracy: 55090/60000 (91.82%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5984,                   Accuracy: 49917/60000 (83.19%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9513,                   Accuracy: 44125/60000 (73.54%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0821,                   Accuracy: 42149/60000 (70.25%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6738,                   Accuracy: 48095/60000 (80.16%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3098,                   Accuracy: 54315/60000 (90.53%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1274,                   Accuracy: 57670/60000 (96.12%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0757,                   Accuracy: 58642/60000 (97.74%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1422,                   Accuracy: 57558/60000 (95.93%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2824,                   Accuracy: 55090/60000 (91.82%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5984,                   Accuracy: 49917/60000 (83.19%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9513,                   Accuracy: 44125/60000 (73.54%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0821,                   Accuracy: 42149/60000 (70.25%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6738,                   Accuracy: 48095/60000 (80.16%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3098,                   Accuracy: 54315/60000 (90.53%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1274,                   Accuracy: 57670/60000 (96.12%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0757,                   Accuracy: 58642/60000 (97.74%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1422,                   Accuracy: 57558/60000 (95.93%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2824,                   Accuracy: 55090/60000 (91.82%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5984,                   Accuracy: 49917/60000 (83.19%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9513,                   Accuracy: 44125/60000 (73.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0821,                   Accuracy: 42149/60000 (70.25%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6738,                   Accuracy: 48095/60000 (80.16%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3098,                   Accuracy: 54315/60000 (90.53%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1274,                   Accuracy: 57670/60000 (96.12%)
{0: tensor(97.7367), 10: tensor(95.9300), 20: tensor(91.8167), 30: tensor(83.1950), 40: tensor(73.5417), 50: tensor(70.2483), 60: tensor(80.1583), 70: tensor(90.5250), 80: tensor(96.1167), 90: tensor(97.7367), 100: tensor(95.9300), 110: tensor(91.8167), 120: tensor(83.1950), 130: tensor(73.5417), 140: tensor(70.2483), 150: tensor(80.1583), 160: tensor(90.5250), 170: tensor(96.1167), 180: tensor(97.7367), 190: tensor(95.9300), 200: tensor(91.8167), 210: tensor(83.1950), 220: tensor(73.5417), 230: tensor(70.2483), 240: tensor(80.1583), 250: tensor(90.5250), 260: tensor(96.1167), 270: tensor(97.7367), 280: tensor(95.9300), 290: tensor(91.8167), 300: tensor(83.1950), 310: tensor(73.5417), 320: tensor(70.2483), 330: tensor(80.1583), 340: tensor(90.5250), 350: tensor(96.1167)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=90, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.7141,                   Accuracy: 290/2000.0 (14.50%)



-= Testing valid =-
Test set: Average loss: 0.7644,                   Accuracy: 1541/2000.0 (77.05%)



-= Testing valid =-
Test set: Average loss: 0.5048,                   Accuracy: 1698/2000.0 (84.90%)



-= Testing valid =-
Test set: Average loss: 0.2952,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.3551,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.1900,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.2112,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1858,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1506,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.2927,                   Accuracy: 1819/2000.0 (90.95%)



Epoch 10 train accuracy: 96.03%, valid accuracy 90.95%
-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1182,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1167,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1069,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0715,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 20 train accuracy: 97.97%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0687,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0684,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0630,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0684,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 30 train accuracy: 98.71%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0595,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0647,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0593,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 40 train accuracy: 99.11%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0606,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0608,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0646,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 50 train accuracy: 99.26%, valid accuracy 98.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0813,                   Accuracy: 58616/60000 (97.69%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1275,                   Accuracy: 57762/60000 (96.27%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2899,                   Accuracy: 55064/60000 (91.77%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6275,                   Accuracy: 49420/60000 (82.37%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9623,                   Accuracy: 43864/60000 (73.11%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0336,                   Accuracy: 42628/60000 (71.05%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7174,                   Accuracy: 47539/60000 (79.23%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3505,                   Accuracy: 53776/60000 (89.63%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1219,                   Accuracy: 57787/60000 (96.31%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0813,                   Accuracy: 58616/60000 (97.69%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1275,                   Accuracy: 57762/60000 (96.27%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2899,                   Accuracy: 55064/60000 (91.77%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6275,                   Accuracy: 49420/60000 (82.37%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9623,                   Accuracy: 43864/60000 (73.11%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0336,                   Accuracy: 42628/60000 (71.05%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7174,                   Accuracy: 47539/60000 (79.23%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3505,                   Accuracy: 53776/60000 (89.63%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1219,                   Accuracy: 57787/60000 (96.31%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0813,                   Accuracy: 58616/60000 (97.69%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1275,                   Accuracy: 57762/60000 (96.27%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2899,                   Accuracy: 55064/60000 (91.77%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6275,                   Accuracy: 49420/60000 (82.37%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9623,                   Accuracy: 43864/60000 (73.11%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0336,                   Accuracy: 42628/60000 (71.05%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7174,                   Accuracy: 47539/60000 (79.23%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3505,                   Accuracy: 53776/60000 (89.63%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1219,                   Accuracy: 57787/60000 (96.31%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0813,                   Accuracy: 58616/60000 (97.69%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1275,                   Accuracy: 57762/60000 (96.27%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2899,                   Accuracy: 55064/60000 (91.77%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6275,                   Accuracy: 49420/60000 (82.37%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9623,                   Accuracy: 43864/60000 (73.11%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0336,                   Accuracy: 42628/60000 (71.05%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7174,                   Accuracy: 47539/60000 (79.23%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3505,                   Accuracy: 53776/60000 (89.63%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1219,                   Accuracy: 57787/60000 (96.31%)
{0: tensor(97.6933), 10: tensor(96.2700), 20: tensor(91.7733), 30: tensor(82.3667), 40: tensor(73.1067), 50: tensor(71.0467), 60: tensor(79.2317), 70: tensor(89.6267), 80: tensor(96.3117), 90: tensor(97.6933), 100: tensor(96.2700), 110: tensor(91.7733), 120: tensor(82.3667), 130: tensor(73.1067), 140: tensor(71.0467), 150: tensor(79.2317), 160: tensor(89.6267), 170: tensor(96.3117), 180: tensor(97.6933), 190: tensor(96.2700), 200: tensor(91.7733), 210: tensor(82.3667), 220: tensor(73.1067), 230: tensor(71.0467), 240: tensor(79.2317), 250: tensor(89.6267), 260: tensor(96.3117), 270: tensor(97.6933), 280: tensor(96.2700), 290: tensor(91.7733), 300: tensor(82.3667), 310: tensor(73.1067), 320: tensor(71.0467), 330: tensor(79.2317), 340: tensor(89.6267), 350: tensor(96.3117)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=91, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6165,                   Accuracy: 381/2000.0 (19.05%)



-= Testing valid =-
Test set: Average loss: 4.4368,                   Accuracy: 230/2000.0 (11.50%)



-= Testing valid =-
Test set: Average loss: 2.4110,                   Accuracy: 615/2000.0 (30.75%)



-= Testing valid =-
Test set: Average loss: 0.7203,                   Accuracy: 1449/2000.0 (72.45%)



-= Testing valid =-
Test set: Average loss: 0.4997,                   Accuracy: 1667/2000.0 (83.35%)



-= Testing valid =-
Test set: Average loss: 0.2663,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.4681,                   Accuracy: 1711/2000.0 (85.55%)



-= Testing valid =-
Test set: Average loss: 0.2681,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2752,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2319,                   Accuracy: 1862/2000.0 (93.10%)



Epoch 10 train accuracy: 95.62%, valid accuracy 93.10%
-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1070,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0919,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 20 train accuracy: 97.70%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0580,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 30 train accuracy: 98.55%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0594,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0683,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0636,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0678,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 40 train accuracy: 99.00%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0622,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0604,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0715,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0594,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0618,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 50 train accuracy: 99.20%, valid accuracy 98.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0792,                   Accuracy: 58592/60000 (97.65%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1312,                   Accuracy: 57571/60000 (95.95%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2702,                   Accuracy: 54903/60000 (91.50%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5640,                   Accuracy: 49557/60000 (82.60%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9675,                   Accuracy: 42943/60000 (71.57%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0944,                   Accuracy: 41803/60000 (69.67%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7663,                   Accuracy: 46723/60000 (77.87%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3630,                   Accuracy: 53451/60000 (89.08%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1291,                   Accuracy: 57629/60000 (96.05%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0792,                   Accuracy: 58592/60000 (97.65%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1312,                   Accuracy: 57571/60000 (95.95%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2702,                   Accuracy: 54903/60000 (91.50%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5640,                   Accuracy: 49557/60000 (82.60%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9675,                   Accuracy: 42943/60000 (71.57%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0944,                   Accuracy: 41803/60000 (69.67%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7663,                   Accuracy: 46723/60000 (77.87%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3630,                   Accuracy: 53451/60000 (89.08%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1291,                   Accuracy: 57629/60000 (96.05%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0792,                   Accuracy: 58592/60000 (97.65%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1312,                   Accuracy: 57571/60000 (95.95%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2702,                   Accuracy: 54903/60000 (91.50%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5640,                   Accuracy: 49557/60000 (82.60%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9675,                   Accuracy: 42943/60000 (71.57%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0944,                   Accuracy: 41803/60000 (69.67%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7663,                   Accuracy: 46723/60000 (77.87%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3630,                   Accuracy: 53451/60000 (89.08%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1291,                   Accuracy: 57629/60000 (96.05%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0792,                   Accuracy: 58592/60000 (97.65%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1312,                   Accuracy: 57571/60000 (95.95%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2702,                   Accuracy: 54903/60000 (91.50%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5640,                   Accuracy: 49557/60000 (82.60%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9675,                   Accuracy: 42943/60000 (71.57%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0944,                   Accuracy: 41803/60000 (69.67%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7663,                   Accuracy: 46723/60000 (77.87%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3630,                   Accuracy: 53451/60000 (89.08%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1291,                   Accuracy: 57629/60000 (96.05%)
{0: tensor(97.6533), 10: tensor(95.9517), 20: tensor(91.5050), 30: tensor(82.5950), 40: tensor(71.5717), 50: tensor(69.6717), 60: tensor(77.8717), 70: tensor(89.0850), 80: tensor(96.0483), 90: tensor(97.6533), 100: tensor(95.9517), 110: tensor(91.5050), 120: tensor(82.5950), 130: tensor(71.5717), 140: tensor(69.6717), 150: tensor(77.8717), 160: tensor(89.0850), 170: tensor(96.0483), 180: tensor(97.6533), 190: tensor(95.9517), 200: tensor(91.5050), 210: tensor(82.5950), 220: tensor(71.5717), 230: tensor(69.6717), 240: tensor(77.8717), 250: tensor(89.0850), 260: tensor(96.0483), 270: tensor(97.6533), 280: tensor(95.9517), 290: tensor(91.5050), 300: tensor(82.5950), 310: tensor(71.5717), 320: tensor(69.6717), 330: tensor(77.8717), 340: tensor(89.0850), 350: tensor(96.0483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=92, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3282,                   Accuracy: 362/2000.0 (18.10%)



-= Testing valid =-
Test set: Average loss: 1.1289,                   Accuracy: 1161/2000.0 (58.05%)



-= Testing valid =-
Test set: Average loss: 0.4943,                   Accuracy: 1709/2000.0 (85.45%)



-= Testing valid =-
Test set: Average loss: 0.2679,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.5778,                   Accuracy: 1631/2000.0 (81.55%)



-= Testing valid =-
Test set: Average loss: 0.1717,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.2737,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.1588,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1739,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1280,                   Accuracy: 1906/2000.0 (95.30%)



Epoch 10 train accuracy: 96.30%, valid accuracy 95.30%
-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1011,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.1037,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 20 train accuracy: 97.65%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0598,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0790,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0734,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0677,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 30 train accuracy: 98.81%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0658,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0604,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0662,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 40 train accuracy: 99.03%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0632,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0644,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0601,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0668,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0647,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0621,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 50 train accuracy: 99.07%, valid accuracy 98.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0838,                   Accuracy: 58507/60000 (97.51%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1237,                   Accuracy: 57781/60000 (96.30%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2601,                   Accuracy: 55330/60000 (92.22%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5808,                   Accuracy: 49366/60000 (82.28%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9051,                   Accuracy: 43616/60000 (72.69%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9528,                   Accuracy: 42891/60000 (71.49%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6504,                   Accuracy: 48469/60000 (80.78%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2886,                   Accuracy: 54782/60000 (91.30%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1214,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0838,                   Accuracy: 58507/60000 (97.51%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1237,                   Accuracy: 57781/60000 (96.30%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2601,                   Accuracy: 55330/60000 (92.22%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5808,                   Accuracy: 49366/60000 (82.28%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9051,                   Accuracy: 43616/60000 (72.69%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9528,                   Accuracy: 42891/60000 (71.49%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6504,                   Accuracy: 48469/60000 (80.78%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2886,                   Accuracy: 54782/60000 (91.30%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1214,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0838,                   Accuracy: 58507/60000 (97.51%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1237,                   Accuracy: 57781/60000 (96.30%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2601,                   Accuracy: 55330/60000 (92.22%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5808,                   Accuracy: 49366/60000 (82.28%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9051,                   Accuracy: 43616/60000 (72.69%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9528,                   Accuracy: 42891/60000 (71.49%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6504,                   Accuracy: 48469/60000 (80.78%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2886,                   Accuracy: 54782/60000 (91.30%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1214,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0838,                   Accuracy: 58507/60000 (97.51%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1237,                   Accuracy: 57781/60000 (96.30%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2601,                   Accuracy: 55330/60000 (92.22%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5808,                   Accuracy: 49366/60000 (82.28%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9051,                   Accuracy: 43616/60000 (72.69%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9528,                   Accuracy: 42891/60000 (71.49%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6504,                   Accuracy: 48469/60000 (80.78%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2886,                   Accuracy: 54782/60000 (91.30%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1214,                   Accuracy: 57819/60000 (96.36%)
{0: tensor(97.5117), 10: tensor(96.3017), 20: tensor(92.2167), 30: tensor(82.2767), 40: tensor(72.6933), 50: tensor(71.4850), 60: tensor(80.7817), 70: tensor(91.3033), 80: tensor(96.3650), 90: tensor(97.5117), 100: tensor(96.3017), 110: tensor(92.2167), 120: tensor(82.2767), 130: tensor(72.6933), 140: tensor(71.4850), 150: tensor(80.7817), 160: tensor(91.3033), 170: tensor(96.3650), 180: tensor(97.5117), 190: tensor(96.3017), 200: tensor(92.2167), 210: tensor(82.2767), 220: tensor(72.6933), 230: tensor(71.4850), 240: tensor(80.7817), 250: tensor(91.3033), 260: tensor(96.3650), 270: tensor(97.5117), 280: tensor(96.3017), 290: tensor(92.2167), 300: tensor(82.2767), 310: tensor(72.6933), 320: tensor(71.4850), 330: tensor(80.7817), 340: tensor(91.3033), 350: tensor(96.3650)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=93, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 7.6973,                   Accuracy: 184/2000.0 (9.20%)



-= Testing valid =-
Test set: Average loss: 1.1829,                   Accuracy: 1135/2000.0 (56.75%)



-= Testing valid =-
Test set: Average loss: 1.2782,                   Accuracy: 1147/2000.0 (57.35%)



-= Testing valid =-
Test set: Average loss: 0.4467,                   Accuracy: 1663/2000.0 (83.15%)



-= Testing valid =-
Test set: Average loss: 0.3618,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.2579,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.1604,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1533,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1675,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 10 train accuracy: 96.40%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.0919,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1141,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0947,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0636,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 20 train accuracy: 97.93%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0674,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0454,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0607,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 30 train accuracy: 98.65%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0567,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 40 train accuracy: 98.89%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 50 train accuracy: 99.05%, valid accuracy 98.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0763,                   Accuracy: 58644/60000 (97.74%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1268,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2454,                   Accuracy: 55566/60000 (92.61%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5256,                   Accuracy: 50556/60000 (84.26%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7840,                   Accuracy: 45981/60000 (76.64%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8250,                   Accuracy: 45604/60000 (76.01%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5206,                   Accuracy: 50841/60000 (84.74%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2692,                   Accuracy: 55341/60000 (92.24%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1175,                   Accuracy: 57903/60000 (96.50%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0763,                   Accuracy: 58644/60000 (97.74%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1268,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2454,                   Accuracy: 55566/60000 (92.61%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5256,                   Accuracy: 50556/60000 (84.26%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7840,                   Accuracy: 45981/60000 (76.64%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8250,                   Accuracy: 45604/60000 (76.01%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5206,                   Accuracy: 50841/60000 (84.74%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2692,                   Accuracy: 55341/60000 (92.24%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1175,                   Accuracy: 57903/60000 (96.50%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0763,                   Accuracy: 58644/60000 (97.74%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1268,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2454,                   Accuracy: 55566/60000 (92.61%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5256,                   Accuracy: 50556/60000 (84.26%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7840,                   Accuracy: 45981/60000 (76.64%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8250,                   Accuracy: 45604/60000 (76.01%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5206,                   Accuracy: 50841/60000 (84.74%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2692,                   Accuracy: 55341/60000 (92.24%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1175,                   Accuracy: 57903/60000 (96.50%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0763,                   Accuracy: 58644/60000 (97.74%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1268,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2454,                   Accuracy: 55566/60000 (92.61%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5256,                   Accuracy: 50556/60000 (84.26%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7840,                   Accuracy: 45981/60000 (76.64%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8250,                   Accuracy: 45604/60000 (76.01%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5206,                   Accuracy: 50841/60000 (84.74%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2692,                   Accuracy: 55341/60000 (92.24%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1175,                   Accuracy: 57903/60000 (96.50%)
{0: tensor(97.7400), 10: tensor(96.1417), 20: tensor(92.6100), 30: tensor(84.2600), 40: tensor(76.6350), 50: tensor(76.0067), 60: tensor(84.7350), 70: tensor(92.2350), 80: tensor(96.5050), 90: tensor(97.7400), 100: tensor(96.1417), 110: tensor(92.6100), 120: tensor(84.2600), 130: tensor(76.6350), 140: tensor(76.0067), 150: tensor(84.7350), 160: tensor(92.2350), 170: tensor(96.5050), 180: tensor(97.7400), 190: tensor(96.1417), 200: tensor(92.6100), 210: tensor(84.2600), 220: tensor(76.6350), 230: tensor(76.0067), 240: tensor(84.7350), 250: tensor(92.2350), 260: tensor(96.5050), 270: tensor(97.7400), 280: tensor(96.1417), 290: tensor(92.6100), 300: tensor(84.2600), 310: tensor(76.6350), 320: tensor(76.0067), 330: tensor(84.7350), 340: tensor(92.2350), 350: tensor(96.5050)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=94, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 12.1679,                   Accuracy: 193/2000.0 (9.65%)



-= Testing valid =-
Test set: Average loss: 0.8945,                   Accuracy: 1404/2000.0 (70.20%)



-= Testing valid =-
Test set: Average loss: 0.8672,                   Accuracy: 1386/2000.0 (69.30%)



-= Testing valid =-
Test set: Average loss: 0.2823,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 1.0955,                   Accuracy: 1302/2000.0 (65.10%)



-= Testing valid =-
Test set: Average loss: 0.5806,                   Accuracy: 1552/2000.0 (77.60%)



-= Testing valid =-
Test set: Average loss: 0.1450,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1306,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1529,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1261,                   Accuracy: 1918/2000.0 (95.90%)



Epoch 10 train accuracy: 96.32%, valid accuracy 95.90%
-= Testing valid =-
Test set: Average loss: 0.1203,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0798,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1245,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1192,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 20 train accuracy: 98.05%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0645,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0709,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0909,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 30 train accuracy: 98.71%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0646,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0704,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0630,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0598,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0641,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 40 train accuracy: 98.97%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0625,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0629,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0647,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 50 train accuracy: 99.05%, valid accuracy 98.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0943,                   Accuracy: 58400/60000 (97.33%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1580,                   Accuracy: 57247/60000 (95.41%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3352,                   Accuracy: 54321/60000 (90.54%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7816,                   Accuracy: 47400/60000 (79.00%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.1409,                   Accuracy: 41806/60000 (69.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2160,                   Accuracy: 40113/60000 (66.86%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7791,                   Accuracy: 46831/60000 (78.05%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3449,                   Accuracy: 53979/60000 (89.96%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1459,                   Accuracy: 57399/60000 (95.67%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0943,                   Accuracy: 58400/60000 (97.33%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1580,                   Accuracy: 57247/60000 (95.41%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3352,                   Accuracy: 54321/60000 (90.54%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.7816,                   Accuracy: 47400/60000 (79.00%)
-= Testing Rotation 130 =-
Test set: Average loss: 1.1409,                   Accuracy: 41806/60000 (69.68%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.2160,                   Accuracy: 40113/60000 (66.86%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7791,                   Accuracy: 46831/60000 (78.05%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3449,                   Accuracy: 53979/60000 (89.96%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1459,                   Accuracy: 57399/60000 (95.67%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0943,                   Accuracy: 58400/60000 (97.33%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1580,                   Accuracy: 57247/60000 (95.41%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3352,                   Accuracy: 54321/60000 (90.54%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.7816,                   Accuracy: 47400/60000 (79.00%)
-= Testing Rotation 220 =-
Test set: Average loss: 1.1409,                   Accuracy: 41806/60000 (69.68%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.2160,                   Accuracy: 40113/60000 (66.86%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7791,                   Accuracy: 46831/60000 (78.05%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3449,                   Accuracy: 53979/60000 (89.96%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1459,                   Accuracy: 57399/60000 (95.67%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0943,                   Accuracy: 58400/60000 (97.33%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1580,                   Accuracy: 57247/60000 (95.41%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3352,                   Accuracy: 54321/60000 (90.54%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.7816,                   Accuracy: 47400/60000 (79.00%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1409,                   Accuracy: 41806/60000 (69.68%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2160,                   Accuracy: 40113/60000 (66.86%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7791,                   Accuracy: 46831/60000 (78.05%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3449,                   Accuracy: 53979/60000 (89.96%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1459,                   Accuracy: 57399/60000 (95.67%)
{0: tensor(97.3333), 10: tensor(95.4117), 20: tensor(90.5350), 30: tensor(79.), 40: tensor(69.6767), 50: tensor(66.8550), 60: tensor(78.0517), 70: tensor(89.9650), 80: tensor(95.6650), 90: tensor(97.3333), 100: tensor(95.4117), 110: tensor(90.5350), 120: tensor(79.), 130: tensor(69.6767), 140: tensor(66.8550), 150: tensor(78.0517), 160: tensor(89.9650), 170: tensor(95.6650), 180: tensor(97.3333), 190: tensor(95.4117), 200: tensor(90.5350), 210: tensor(79.), 220: tensor(69.6767), 230: tensor(66.8550), 240: tensor(78.0517), 250: tensor(89.9650), 260: tensor(95.6650), 270: tensor(97.3333), 280: tensor(95.4117), 290: tensor(90.5350), 300: tensor(79.), 310: tensor(69.6767), 320: tensor(66.8550), 330: tensor(78.0517), 340: tensor(89.9650), 350: tensor(95.6650)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=95, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.9035,                   Accuracy: 351/2000.0 (17.55%)



-= Testing valid =-
Test set: Average loss: 1.9718,                   Accuracy: 707/2000.0 (35.35%)



-= Testing valid =-
Test set: Average loss: 1.1668,                   Accuracy: 1196/2000.0 (59.80%)



-= Testing valid =-
Test set: Average loss: 0.4155,                   Accuracy: 1709/2000.0 (85.45%)



-= Testing valid =-
Test set: Average loss: 0.4801,                   Accuracy: 1698/2000.0 (84.90%)



-= Testing valid =-
Test set: Average loss: 0.2230,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.2683,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.1704,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1744,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.2277,                   Accuracy: 1849/2000.0 (92.45%)



Epoch 10 train accuracy: 96.53%, valid accuracy 92.45%
-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0656,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0618,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 20 train accuracy: 98.24%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0633,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0594,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 30 train accuracy: 98.59%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0645,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0580,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0637,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 40 train accuracy: 98.90%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0594,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0559,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 50 train accuracy: 99.01%, valid accuracy 98.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0834,                   Accuracy: 58551/60000 (97.58%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1260,                   Accuracy: 57795/60000 (96.32%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2711,                   Accuracy: 55282/60000 (92.14%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5961,                   Accuracy: 49808/60000 (83.01%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9688,                   Accuracy: 44303/60000 (73.84%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0577,                   Accuracy: 42951/60000 (71.58%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7367,                   Accuracy: 47624/60000 (79.37%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3556,                   Accuracy: 53756/60000 (89.59%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1304,                   Accuracy: 57670/60000 (96.12%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0834,                   Accuracy: 58551/60000 (97.58%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1260,                   Accuracy: 57795/60000 (96.32%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2711,                   Accuracy: 55282/60000 (92.14%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5961,                   Accuracy: 49808/60000 (83.01%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9688,                   Accuracy: 44303/60000 (73.84%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0577,                   Accuracy: 42951/60000 (71.58%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7367,                   Accuracy: 47624/60000 (79.37%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3556,                   Accuracy: 53755/60000 (89.59%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1304,                   Accuracy: 57670/60000 (96.12%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0834,                   Accuracy: 58551/60000 (97.58%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1260,                   Accuracy: 57795/60000 (96.32%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2711,                   Accuracy: 55282/60000 (92.14%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5961,                   Accuracy: 49808/60000 (83.01%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9688,                   Accuracy: 44303/60000 (73.84%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0577,                   Accuracy: 42951/60000 (71.58%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7367,                   Accuracy: 47624/60000 (79.37%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3556,                   Accuracy: 53756/60000 (89.59%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1304,                   Accuracy: 57670/60000 (96.12%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0834,                   Accuracy: 58551/60000 (97.58%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1260,                   Accuracy: 57795/60000 (96.32%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2711,                   Accuracy: 55282/60000 (92.14%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5961,                   Accuracy: 49808/60000 (83.01%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9688,                   Accuracy: 44303/60000 (73.84%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0577,                   Accuracy: 42951/60000 (71.58%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7367,                   Accuracy: 47624/60000 (79.37%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3556,                   Accuracy: 53755/60000 (89.59%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1304,                   Accuracy: 57670/60000 (96.12%)
{0: tensor(97.5850), 10: tensor(96.3250), 20: tensor(92.1367), 30: tensor(83.0133), 40: tensor(73.8383), 50: tensor(71.5850), 60: tensor(79.3733), 70: tensor(89.5933), 80: tensor(96.1167), 90: tensor(97.5850), 100: tensor(96.3250), 110: tensor(92.1367), 120: tensor(83.0133), 130: tensor(73.8383), 140: tensor(71.5850), 150: tensor(79.3733), 160: tensor(89.5917), 170: tensor(96.1167), 180: tensor(97.5850), 190: tensor(96.3250), 200: tensor(92.1367), 210: tensor(83.0133), 220: tensor(73.8383), 230: tensor(71.5850), 240: tensor(79.3733), 250: tensor(89.5933), 260: tensor(96.1167), 270: tensor(97.5850), 280: tensor(96.3250), 290: tensor(92.1367), 300: tensor(83.0133), 310: tensor(73.8383), 320: tensor(71.5850), 330: tensor(79.3733), 340: tensor(89.5917), 350: tensor(96.1167)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=96, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.7021,                   Accuracy: 316/2000.0 (15.80%)



-= Testing valid =-
Test set: Average loss: 2.5691,                   Accuracy: 327/2000.0 (16.35%)



-= Testing valid =-
Test set: Average loss: 1.8040,                   Accuracy: 653/2000.0 (32.65%)



-= Testing valid =-
Test set: Average loss: 0.5305,                   Accuracy: 1639/2000.0 (81.95%)



-= Testing valid =-
Test set: Average loss: 0.3253,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2023,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.2664,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2026,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.3437,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.2257,                   Accuracy: 1840/2000.0 (92.00%)



Epoch 10 train accuracy: 96.20%, valid accuracy 92.00%
-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0721,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 20 train accuracy: 97.72%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0638,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0630,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0607,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0620,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0597,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 30 train accuracy: 98.46%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0572,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 40 train accuracy: 98.81%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 50 train accuracy: 99.04%, valid accuracy 98.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0822,                   Accuracy: 58583/60000 (97.64%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1381,                   Accuracy: 57535/60000 (95.89%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3081,                   Accuracy: 54529/60000 (90.88%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5660,                   Accuracy: 50104/60000 (83.51%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7963,                   Accuracy: 46137/60000 (76.89%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8354,                   Accuracy: 45630/60000 (76.05%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5738,                   Accuracy: 49812/60000 (83.02%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3013,                   Accuracy: 54641/60000 (91.07%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1282,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0822,                   Accuracy: 58583/60000 (97.64%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1381,                   Accuracy: 57535/60000 (95.89%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3081,                   Accuracy: 54529/60000 (90.88%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5660,                   Accuracy: 50104/60000 (83.51%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7963,                   Accuracy: 46137/60000 (76.89%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8354,                   Accuracy: 45630/60000 (76.05%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5738,                   Accuracy: 49812/60000 (83.02%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3013,                   Accuracy: 54641/60000 (91.07%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1282,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0822,                   Accuracy: 58583/60000 (97.64%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1381,                   Accuracy: 57535/60000 (95.89%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3081,                   Accuracy: 54529/60000 (90.88%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5660,                   Accuracy: 50104/60000 (83.51%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7963,                   Accuracy: 46137/60000 (76.89%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8354,                   Accuracy: 45630/60000 (76.05%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5738,                   Accuracy: 49812/60000 (83.02%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3013,                   Accuracy: 54641/60000 (91.07%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1282,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0822,                   Accuracy: 58583/60000 (97.64%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1381,                   Accuracy: 57535/60000 (95.89%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3081,                   Accuracy: 54529/60000 (90.88%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5660,                   Accuracy: 50104/60000 (83.51%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7963,                   Accuracy: 46137/60000 (76.89%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8354,                   Accuracy: 45630/60000 (76.05%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5738,                   Accuracy: 49812/60000 (83.02%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3013,                   Accuracy: 54641/60000 (91.07%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1282,                   Accuracy: 57685/60000 (96.14%)
{0: tensor(97.6383), 10: tensor(95.8917), 20: tensor(90.8817), 30: tensor(83.5067), 40: tensor(76.8950), 50: tensor(76.0500), 60: tensor(83.0200), 70: tensor(91.0683), 80: tensor(96.1417), 90: tensor(97.6383), 100: tensor(95.8917), 110: tensor(90.8817), 120: tensor(83.5067), 130: tensor(76.8950), 140: tensor(76.0500), 150: tensor(83.0200), 160: tensor(91.0683), 170: tensor(96.1417), 180: tensor(97.6383), 190: tensor(95.8917), 200: tensor(90.8817), 210: tensor(83.5067), 220: tensor(76.8950), 230: tensor(76.0500), 240: tensor(83.0200), 250: tensor(91.0683), 260: tensor(96.1417), 270: tensor(97.6383), 280: tensor(95.8917), 290: tensor(90.8817), 300: tensor(83.5067), 310: tensor(76.8950), 320: tensor(76.0500), 330: tensor(83.0200), 340: tensor(91.0683), 350: tensor(96.1417)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=97, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 7.5698,                   Accuracy: 204/2000.0 (10.20%)



-= Testing valid =-
Test set: Average loss: 1.7454,                   Accuracy: 579/2000.0 (28.95%)



-= Testing valid =-
Test set: Average loss: 3.1769,                   Accuracy: 413/2000.0 (20.65%)



-= Testing valid =-
Test set: Average loss: 1.4112,                   Accuracy: 1173/2000.0 (58.65%)



-= Testing valid =-
Test set: Average loss: 0.5684,                   Accuracy: 1627/2000.0 (81.35%)



-= Testing valid =-
Test set: Average loss: 0.2214,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1763,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.6759,                   Accuracy: 1578/2000.0 (78.90%)



-= Testing valid =-
Test set: Average loss: 0.1860,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1482,                   Accuracy: 1907/2000.0 (95.35%)



Epoch 10 train accuracy: 95.84%, valid accuracy 95.35%
-= Testing valid =-
Test set: Average loss: 0.1169,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1072,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1531,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1473,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1200,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 20 train accuracy: 97.57%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0641,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 30 train accuracy: 98.51%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0485,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 40 train accuracy: 98.93%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0472,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0450,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 50 train accuracy: 98.94%, valid accuracy 98.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0779,                   Accuracy: 58636/60000 (97.73%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1131,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2229,                   Accuracy: 55861/60000 (93.10%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4629,                   Accuracy: 51388/60000 (85.65%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7261,                   Accuracy: 46549/60000 (77.58%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.7558,                   Accuracy: 46056/60000 (76.76%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5416,                   Accuracy: 49848/60000 (83.08%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2946,                   Accuracy: 54406/60000 (90.68%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1166,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0779,                   Accuracy: 58636/60000 (97.73%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1131,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2229,                   Accuracy: 55861/60000 (93.10%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4629,                   Accuracy: 51388/60000 (85.65%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7261,                   Accuracy: 46549/60000 (77.58%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.7558,                   Accuracy: 46056/60000 (76.76%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5416,                   Accuracy: 49848/60000 (83.08%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2946,                   Accuracy: 54406/60000 (90.68%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1166,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0779,                   Accuracy: 58636/60000 (97.73%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1131,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2229,                   Accuracy: 55861/60000 (93.10%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4629,                   Accuracy: 51388/60000 (85.65%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7261,                   Accuracy: 46549/60000 (77.58%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.7558,                   Accuracy: 46056/60000 (76.76%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5416,                   Accuracy: 49848/60000 (83.08%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2946,                   Accuracy: 54406/60000 (90.68%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1166,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0779,                   Accuracy: 58636/60000 (97.73%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1131,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2229,                   Accuracy: 55861/60000 (93.10%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.4629,                   Accuracy: 51388/60000 (85.65%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7261,                   Accuracy: 46549/60000 (77.58%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.7558,                   Accuracy: 46056/60000 (76.76%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5416,                   Accuracy: 49848/60000 (83.08%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2946,                   Accuracy: 54406/60000 (90.68%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1166,                   Accuracy: 57826/60000 (96.38%)
{0: tensor(97.7267), 10: tensor(96.5883), 20: tensor(93.1017), 30: tensor(85.6467), 40: tensor(77.5817), 50: tensor(76.7600), 60: tensor(83.0800), 70: tensor(90.6767), 80: tensor(96.3767), 90: tensor(97.7267), 100: tensor(96.5883), 110: tensor(93.1017), 120: tensor(85.6467), 130: tensor(77.5817), 140: tensor(76.7600), 150: tensor(83.0800), 160: tensor(90.6767), 170: tensor(96.3767), 180: tensor(97.7267), 190: tensor(96.5883), 200: tensor(93.1017), 210: tensor(85.6467), 220: tensor(77.5817), 230: tensor(76.7600), 240: tensor(83.0800), 250: tensor(90.6767), 260: tensor(96.3767), 270: tensor(97.7267), 280: tensor(96.5883), 290: tensor(93.1017), 300: tensor(85.6467), 310: tensor(77.5817), 320: tensor(76.7600), 330: tensor(83.0800), 340: tensor(90.6767), 350: tensor(96.3767)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=98, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1794,                   Accuracy: 307/2000.0 (15.35%)



-= Testing valid =-
Test set: Average loss: 1.5545,                   Accuracy: 724/2000.0 (36.20%)



-= Testing valid =-
Test set: Average loss: 1.3227,                   Accuracy: 1014/2000.0 (50.70%)



-= Testing valid =-
Test set: Average loss: 0.5035,                   Accuracy: 1675/2000.0 (83.75%)



-= Testing valid =-
Test set: Average loss: 0.4469,                   Accuracy: 1699/2000.0 (84.95%)



-= Testing valid =-
Test set: Average loss: 0.3283,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.2483,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2163,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.2356,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.1312,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 10 train accuracy: 96.10%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.1219,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1524,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1610,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1290,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1199,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1048,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1485,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1010,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1289,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 20 train accuracy: 97.44%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1015,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 30 train accuracy: 98.45%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0746,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0711,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 40 train accuracy: 98.59%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0698,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0734,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0718,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0723,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 50 train accuracy: 98.95%, valid accuracy 97.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0918,                   Accuracy: 58418/60000 (97.36%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1331,                   Accuracy: 57638/60000 (96.06%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2782,                   Accuracy: 55045/60000 (91.74%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5635,                   Accuracy: 49933/60000 (83.22%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8620,                   Accuracy: 44680/60000 (74.47%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9144,                   Accuracy: 43923/60000 (73.21%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6564,                   Accuracy: 48456/60000 (80.76%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3180,                   Accuracy: 54422/60000 (90.70%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1227,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0918,                   Accuracy: 58418/60000 (97.36%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1331,                   Accuracy: 57638/60000 (96.06%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2782,                   Accuracy: 55045/60000 (91.74%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5635,                   Accuracy: 49933/60000 (83.22%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8620,                   Accuracy: 44680/60000 (74.47%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9144,                   Accuracy: 43923/60000 (73.21%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6564,                   Accuracy: 48456/60000 (80.76%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3180,                   Accuracy: 54422/60000 (90.70%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1227,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0918,                   Accuracy: 58418/60000 (97.36%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1331,                   Accuracy: 57638/60000 (96.06%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2782,                   Accuracy: 55045/60000 (91.74%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5635,                   Accuracy: 49933/60000 (83.22%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8620,                   Accuracy: 44680/60000 (74.47%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9144,                   Accuracy: 43923/60000 (73.21%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6564,                   Accuracy: 48456/60000 (80.76%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3180,                   Accuracy: 54422/60000 (90.70%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1227,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0918,                   Accuracy: 58418/60000 (97.36%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1331,                   Accuracy: 57638/60000 (96.06%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2782,                   Accuracy: 55045/60000 (91.74%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5635,                   Accuracy: 49933/60000 (83.22%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8620,                   Accuracy: 44680/60000 (74.47%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9144,                   Accuracy: 43923/60000 (73.21%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6564,                   Accuracy: 48456/60000 (80.76%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3180,                   Accuracy: 54422/60000 (90.70%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1227,                   Accuracy: 57826/60000 (96.38%)
{0: tensor(97.3633), 10: tensor(96.0633), 20: tensor(91.7417), 30: tensor(83.2217), 40: tensor(74.4667), 50: tensor(73.2050), 60: tensor(80.7600), 70: tensor(90.7033), 80: tensor(96.3767), 90: tensor(97.3633), 100: tensor(96.0633), 110: tensor(91.7417), 120: tensor(83.2217), 130: tensor(74.4667), 140: tensor(73.2050), 150: tensor(80.7600), 160: tensor(90.7033), 170: tensor(96.3767), 180: tensor(97.3633), 190: tensor(96.0633), 200: tensor(91.7417), 210: tensor(83.2217), 220: tensor(74.4667), 230: tensor(73.2050), 240: tensor(80.7600), 250: tensor(90.7033), 260: tensor(96.3767), 270: tensor(97.3633), 280: tensor(96.0633), 290: tensor(91.7417), 300: tensor(83.2217), 310: tensor(74.4667), 320: tensor(73.2050), 330: tensor(80.7600), 340: tensor(90.7033), 350: tensor(96.3767)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=99, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 6.1891,                   Accuracy: 196/2000.0 (9.80%)



-= Testing valid =-
Test set: Average loss: 2.3925,                   Accuracy: 705/2000.0 (35.25%)



-= Testing valid =-
Test set: Average loss: 1.4406,                   Accuracy: 1065/2000.0 (53.25%)



-= Testing valid =-
Test set: Average loss: 0.5446,                   Accuracy: 1634/2000.0 (81.70%)



-= Testing valid =-
Test set: Average loss: 0.2178,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.1363,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.4095,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.3169,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.1336,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 10 train accuracy: 96.38%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0572,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0668,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 20 train accuracy: 98.14%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 98.71%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 40 train accuracy: 99.11%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 50 train accuracy: 99.18%, valid accuracy 98.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0712,                   Accuracy: 58697/60000 (97.83%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1159,                   Accuracy: 57893/60000 (96.49%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2265,                   Accuracy: 55981/60000 (93.30%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4644,                   Accuracy: 51407/60000 (85.68%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7272,                   Accuracy: 46268/60000 (77.11%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.7822,                   Accuracy: 44917/60000 (74.86%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5457,                   Accuracy: 49346/60000 (82.24%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2705,                   Accuracy: 54875/60000 (91.46%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1164,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0712,                   Accuracy: 58697/60000 (97.83%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1159,                   Accuracy: 57893/60000 (96.49%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2265,                   Accuracy: 55981/60000 (93.30%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4644,                   Accuracy: 51407/60000 (85.68%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7272,                   Accuracy: 46268/60000 (77.11%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.7822,                   Accuracy: 44917/60000 (74.86%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5457,                   Accuracy: 49346/60000 (82.24%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2705,                   Accuracy: 54875/60000 (91.46%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1164,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0712,                   Accuracy: 58697/60000 (97.83%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1159,                   Accuracy: 57893/60000 (96.49%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2265,                   Accuracy: 55981/60000 (93.30%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4644,                   Accuracy: 51407/60000 (85.68%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7272,                   Accuracy: 46268/60000 (77.11%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.7822,                   Accuracy: 44917/60000 (74.86%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5457,                   Accuracy: 49346/60000 (82.24%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2705,                   Accuracy: 54875/60000 (91.46%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1164,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0712,                   Accuracy: 58697/60000 (97.83%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1159,                   Accuracy: 57893/60000 (96.49%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2265,                   Accuracy: 55981/60000 (93.30%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.4644,                   Accuracy: 51407/60000 (85.68%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7272,                   Accuracy: 46268/60000 (77.11%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.7822,                   Accuracy: 44917/60000 (74.86%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5457,                   Accuracy: 49346/60000 (82.24%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2705,                   Accuracy: 54875/60000 (91.46%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1164,                   Accuracy: 57869/60000 (96.45%)
{0: tensor(97.8283), 10: tensor(96.4883), 20: tensor(93.3017), 30: tensor(85.6783), 40: tensor(77.1133), 50: tensor(74.8617), 60: tensor(82.2433), 70: tensor(91.4583), 80: tensor(96.4483), 90: tensor(97.8283), 100: tensor(96.4883), 110: tensor(93.3017), 120: tensor(85.6783), 130: tensor(77.1133), 140: tensor(74.8617), 150: tensor(82.2433), 160: tensor(91.4583), 170: tensor(96.4483), 180: tensor(97.8283), 190: tensor(96.4883), 200: tensor(93.3017), 210: tensor(85.6783), 220: tensor(77.1133), 230: tensor(74.8617), 240: tensor(82.2433), 250: tensor(91.4583), 260: tensor(96.4483), 270: tensor(97.8283), 280: tensor(96.4883), 290: tensor(93.3017), 300: tensor(85.6783), 310: tensor(77.1133), 320: tensor(74.8617), 330: tensor(82.2433), 340: tensor(91.4583), 350: tensor(96.4483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=100, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4345,                   Accuracy: 332/2000.0 (16.60%)



-= Testing valid =-
Test set: Average loss: 1.0754,                   Accuracy: 1218/2000.0 (60.90%)



-= Testing valid =-
Test set: Average loss: 0.5239,                   Accuracy: 1677/2000.0 (83.85%)



-= Testing valid =-
Test set: Average loss: 0.3343,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.2913,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2387,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2542,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.1586,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1796,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1376,                   Accuracy: 1907/2000.0 (95.35%)



Epoch 10 train accuracy: 96.29%, valid accuracy 95.35%
-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1184,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1303,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0711,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0790,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 20 train accuracy: 97.97%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0677,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0637,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0580,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0645,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 30 train accuracy: 98.75%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0637,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0529,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0595,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 40 train accuracy: 98.78%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0579,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 50 train accuracy: 98.97%, valid accuracy 98.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0774,                   Accuracy: 58600/60000 (97.67%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1185,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2247,                   Accuracy: 55949/60000 (93.25%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5213,                   Accuracy: 50862/60000 (84.77%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8513,                   Accuracy: 45448/60000 (75.75%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9320,                   Accuracy: 44076/60000 (73.46%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6289,                   Accuracy: 48719/60000 (81.20%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3177,                   Accuracy: 54226/60000 (90.38%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1321,                   Accuracy: 57598/60000 (96.00%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0774,                   Accuracy: 58600/60000 (97.67%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1185,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2247,                   Accuracy: 55949/60000 (93.25%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5213,                   Accuracy: 50862/60000 (84.77%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8513,                   Accuracy: 45448/60000 (75.75%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9320,                   Accuracy: 44076/60000 (73.46%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6289,                   Accuracy: 48719/60000 (81.20%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3177,                   Accuracy: 54226/60000 (90.38%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1321,                   Accuracy: 57598/60000 (96.00%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0774,                   Accuracy: 58600/60000 (97.67%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1185,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2247,                   Accuracy: 55949/60000 (93.25%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5213,                   Accuracy: 50862/60000 (84.77%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8513,                   Accuracy: 45448/60000 (75.75%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9320,                   Accuracy: 44076/60000 (73.46%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6289,                   Accuracy: 48719/60000 (81.20%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3177,                   Accuracy: 54226/60000 (90.38%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1321,                   Accuracy: 57598/60000 (96.00%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0774,                   Accuracy: 58600/60000 (97.67%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1185,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2247,                   Accuracy: 55949/60000 (93.25%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5213,                   Accuracy: 50862/60000 (84.77%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8513,                   Accuracy: 45448/60000 (75.75%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9320,                   Accuracy: 44076/60000 (73.46%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6289,                   Accuracy: 48719/60000 (81.20%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3177,                   Accuracy: 54226/60000 (90.38%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1321,                   Accuracy: 57598/60000 (96.00%)
{0: tensor(97.6667), 10: tensor(96.4467), 20: tensor(93.2483), 30: tensor(84.7700), 40: tensor(75.7467), 50: tensor(73.4600), 60: tensor(81.1983), 70: tensor(90.3767), 80: tensor(95.9967), 90: tensor(97.6667), 100: tensor(96.4467), 110: tensor(93.2483), 120: tensor(84.7700), 130: tensor(75.7467), 140: tensor(73.4600), 150: tensor(81.1983), 160: tensor(90.3767), 170: tensor(95.9967), 180: tensor(97.6667), 190: tensor(96.4467), 200: tensor(93.2483), 210: tensor(84.7700), 220: tensor(75.7467), 230: tensor(73.4600), 240: tensor(81.1983), 250: tensor(90.3767), 260: tensor(95.9967), 270: tensor(97.6667), 280: tensor(96.4467), 290: tensor(93.2483), 300: tensor(84.7700), 310: tensor(75.7467), 320: tensor(73.4600), 330: tensor(81.1983), 340: tensor(90.3767), 350: tensor(95.9967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=71, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8375,                   Accuracy: 613/2000.0 (30.65%)



-= Testing valid =-
Test set: Average loss: 1.0130,                   Accuracy: 1311/2000.0 (65.55%)



-= Testing valid =-
Test set: Average loss: 0.5007,                   Accuracy: 1704/2000.0 (85.20%)



-= Testing valid =-
Test set: Average loss: 0.2492,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2164,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1674,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.0626,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 10 train accuracy: 98.32%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0450,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 20 train accuracy: 99.19%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.50%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0251,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.65%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0217,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0226,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 50 train accuracy: 99.72%, valid accuracy 99.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0497,                   Accuracy: 59163/60000 (98.61%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0729,                   Accuracy: 58762/60000 (97.94%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1532,                   Accuracy: 57432/60000 (95.72%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3839,                   Accuracy: 53644/60000 (89.41%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7523,                   Accuracy: 47544/60000 (79.24%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9615,                   Accuracy: 43555/60000 (72.59%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8567,                   Accuracy: 44555/60000 (74.26%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.5568,                   Accuracy: 49529/60000 (82.55%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4195,                   Accuracy: 51857/60000 (86.43%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4264,                   Accuracy: 51678/60000 (86.13%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8339,                   Accuracy: 45865/60000 (76.44%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6684,                   Accuracy: 37698/60000 (62.83%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.8587,                   Accuracy: 29566/60000 (49.28%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.9013,                   Accuracy: 23674/60000 (39.46%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.4981,                   Accuracy: 21597/60000 (35.99%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.5681,                   Accuracy: 22511/60000 (37.52%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.2246,                   Accuracy: 25454/60000 (42.42%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.7809,                   Accuracy: 27895/60000 (46.49%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.4696,                   Accuracy: 29042/60000 (48.40%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4970,                   Accuracy: 28694/60000 (47.82%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.6890,                   Accuracy: 26622/60000 (44.37%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9600,                   Accuracy: 24345/60000 (40.58%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.8905,                   Accuracy: 23497/60000 (39.16%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.4288,                   Accuracy: 25338/60000 (42.23%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.6189,                   Accuracy: 30322/60000 (50.54%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.6227,                   Accuracy: 37473/60000 (62.46%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9208,                   Accuracy: 44037/60000 (73.39%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5421,                   Accuracy: 50009/60000 (83.35%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6171,                   Accuracy: 48014/60000 (80.02%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8067,                   Accuracy: 44927/60000 (74.88%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1977,                   Accuracy: 39537/60000 (65.89%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4075,                   Accuracy: 35937/60000 (59.90%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2672,                   Accuracy: 38810/60000 (64.68%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7761,                   Accuracy: 46649/60000 (77.75%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2469,                   Accuracy: 55467/60000 (92.44%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0829,                   Accuracy: 58483/60000 (97.47%)
{0: tensor(98.6050), 10: tensor(97.9367), 20: tensor(95.7200), 30: tensor(89.4067), 40: tensor(79.2400), 50: tensor(72.5917), 60: tensor(74.2583), 70: tensor(82.5483), 80: tensor(86.4283), 90: tensor(86.1300), 100: tensor(76.4417), 110: tensor(62.8300), 120: tensor(49.2767), 130: tensor(39.4567), 140: tensor(35.9950), 150: tensor(37.5183), 160: tensor(42.4233), 170: tensor(46.4917), 180: tensor(48.4033), 190: tensor(47.8233), 200: tensor(44.3700), 210: tensor(40.5750), 220: tensor(39.1617), 230: tensor(42.2300), 240: tensor(50.5367), 250: tensor(62.4550), 260: tensor(73.3950), 270: tensor(83.3483), 280: tensor(80.0233), 290: tensor(74.8783), 300: tensor(65.8950), 310: tensor(59.8950), 320: tensor(64.6833), 330: tensor(77.7483), 340: tensor(92.4450), 350: tensor(97.4717)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=72, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9908,                   Accuracy: 541/2000.0 (27.05%)



-= Testing valid =-
Test set: Average loss: 1.2409,                   Accuracy: 1096/2000.0 (54.80%)



-= Testing valid =-
Test set: Average loss: 0.3048,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.1815,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1276,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1614,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1122,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0568,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 10 train accuracy: 98.19%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 20 train accuracy: 98.94%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0197,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0208,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0197,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0191,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0206,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0218,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0226,                   Accuracy: 1988/2000.0 (99.40%)



Epoch 30 train accuracy: 99.47%, valid accuracy 99.40%
-= Testing valid =-
Test set: Average loss: 0.0190,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0208,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0195,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0169,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0210,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0202,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0200,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0207,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0198,                   Accuracy: 1990/2000.0 (99.50%)



Epoch 40 train accuracy: 99.69%, valid accuracy 99.50%
-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0175,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0170,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0183,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0173,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0175,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0173,                   Accuracy: 1992/2000.0 (99.60%)



-= Testing valid =-
Test set: Average loss: 0.0173,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0166,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0195,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 50 train accuracy: 99.65%, valid accuracy 99.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0441,                   Accuracy: 59234/60000 (98.72%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0746,                   Accuracy: 58745/60000 (97.91%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1667,                   Accuracy: 57218/60000 (95.36%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4267,                   Accuracy: 53255/60000 (88.76%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9418,                   Accuracy: 45632/60000 (76.05%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2897,                   Accuracy: 40518/60000 (67.53%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1780,                   Accuracy: 41271/60000 (68.79%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7839,                   Accuracy: 46053/60000 (76.75%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5181,                   Accuracy: 49999/60000 (83.33%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4067,                   Accuracy: 51980/60000 (86.63%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.5470,                   Accuracy: 49575/60000 (82.62%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.0375,                   Accuracy: 42179/60000 (70.30%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0408,                   Accuracy: 30994/60000 (51.66%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8556,                   Accuracy: 25223/60000 (42.04%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3990,                   Accuracy: 22896/60000 (38.16%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.3917,                   Accuracy: 25226/60000 (42.04%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.9279,                   Accuracy: 29765/60000 (49.61%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.6696,                   Accuracy: 34468/60000 (57.45%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.5426,                   Accuracy: 35753/60000 (59.59%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.5318,                   Accuracy: 33966/60000 (56.61%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.8689,                   Accuracy: 30623/60000 (51.04%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.2131,                   Accuracy: 25726/60000 (42.88%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.2482,                   Accuracy: 23195/60000 (38.66%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8945,                   Accuracy: 24947/60000 (41.58%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0441,                   Accuracy: 31946/60000 (53.24%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2437,                   Accuracy: 40510/60000 (67.52%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7123,                   Accuracy: 47464/60000 (79.11%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3553,                   Accuracy: 53067/60000 (88.44%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5396,                   Accuracy: 49795/60000 (82.99%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8357,                   Accuracy: 45326/60000 (75.54%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3366,                   Accuracy: 39066/60000 (65.11%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.6722,                   Accuracy: 35619/60000 (59.37%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.6234,                   Accuracy: 37114/60000 (61.86%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9894,                   Accuracy: 45198/60000 (75.33%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3443,                   Accuracy: 54077/60000 (90.13%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0997,                   Accuracy: 58190/60000 (96.98%)
{0: tensor(98.7233), 10: tensor(97.9083), 20: tensor(95.3633), 30: tensor(88.7583), 40: tensor(76.0533), 50: tensor(67.5300), 60: tensor(68.7850), 70: tensor(76.7550), 80: tensor(83.3317), 90: tensor(86.6333), 100: tensor(82.6250), 110: tensor(70.2983), 120: tensor(51.6567), 130: tensor(42.0383), 140: tensor(38.1600), 150: tensor(42.0433), 160: tensor(49.6083), 170: tensor(57.4467), 180: tensor(59.5883), 190: tensor(56.6100), 200: tensor(51.0383), 210: tensor(42.8767), 220: tensor(38.6583), 230: tensor(41.5783), 240: tensor(53.2433), 250: tensor(67.5167), 260: tensor(79.1067), 270: tensor(88.4450), 280: tensor(82.9917), 290: tensor(75.5433), 300: tensor(65.1100), 310: tensor(59.3650), 320: tensor(61.8567), 330: tensor(75.3300), 340: tensor(90.1283), 350: tensor(96.9833)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=73, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7736,                   Accuracy: 746/2000.0 (37.30%)



-= Testing valid =-
Test set: Average loss: 0.7563,                   Accuracy: 1624/2000.0 (81.20%)



-= Testing valid =-
Test set: Average loss: 0.5542,                   Accuracy: 1637/2000.0 (81.85%)



-= Testing valid =-
Test set: Average loss: 0.1548,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.2155,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1164,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0678,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 10 train accuracy: 98.32%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 20 train accuracy: 98.82%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0206,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0183,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0160,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0176,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0217,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0190,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 30 train accuracy: 99.56%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0171,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0181,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0170,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0177,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0169,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0184,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0151,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0167,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0184,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0137,                   Accuracy: 1988/2000.0 (99.40%)



Epoch 40 train accuracy: 99.61%, valid accuracy 99.40%
-= Testing valid =-
Test set: Average loss: 0.0174,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0146,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0136,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0164,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0138,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0144,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0134,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0142,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0154,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0130,                   Accuracy: 1991/2000.0 (99.55%)



Epoch 50 train accuracy: 99.69%, valid accuracy 99.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0436,                   Accuracy: 59284/60000 (98.81%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0779,                   Accuracy: 58682/60000 (97.80%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1768,                   Accuracy: 56992/60000 (94.99%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4566,                   Accuracy: 52200/60000 (87.00%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8161,                   Accuracy: 46173/60000 (76.96%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9786,                   Accuracy: 43423/60000 (72.37%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8607,                   Accuracy: 44653/60000 (74.42%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6148,                   Accuracy: 48182/60000 (80.30%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5442,                   Accuracy: 49299/60000 (82.17%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5058,                   Accuracy: 49184/60000 (81.97%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8519,                   Accuracy: 43895/60000 (73.16%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5542,                   Accuracy: 35147/60000 (58.58%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.3647,                   Accuracy: 27643/60000 (46.07%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.1496,                   Accuracy: 23868/60000 (39.78%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.4359,                   Accuracy: 23622/60000 (39.37%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4588,                   Accuracy: 24915/60000 (41.53%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5322,                   Accuracy: 27230/60000 (45.38%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5922,                   Accuracy: 28912/60000 (48.19%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.6656,                   Accuracy: 29551/60000 (49.25%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.8035,                   Accuracy: 28513/60000 (47.52%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.1687,                   Accuracy: 25904/60000 (43.17%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.3782,                   Accuracy: 23554/60000 (39.26%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.0840,                   Accuracy: 23287/60000 (38.81%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.3182,                   Accuracy: 26187/60000 (43.65%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.1813,                   Accuracy: 32695/60000 (54.49%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1172,                   Accuracy: 41428/60000 (69.05%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5865,                   Accuracy: 48120/60000 (80.20%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3077,                   Accuracy: 53774/60000 (89.62%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4223,                   Accuracy: 51549/60000 (85.92%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6446,                   Accuracy: 48399/60000 (80.67%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9767,                   Accuracy: 44348/60000 (73.91%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2191,                   Accuracy: 41227/60000 (68.71%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0866,                   Accuracy: 43571/60000 (72.62%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6165,                   Accuracy: 49928/60000 (83.21%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2000,                   Accuracy: 56402/60000 (94.00%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0778,                   Accuracy: 58618/60000 (97.70%)
{0: tensor(98.8067), 10: tensor(97.8033), 20: tensor(94.9867), 30: tensor(87.), 40: tensor(76.9550), 50: tensor(72.3717), 60: tensor(74.4217), 70: tensor(80.3033), 80: tensor(82.1650), 90: tensor(81.9733), 100: tensor(73.1583), 110: tensor(58.5783), 120: tensor(46.0717), 130: tensor(39.7800), 140: tensor(39.3700), 150: tensor(41.5250), 160: tensor(45.3833), 170: tensor(48.1867), 180: tensor(49.2517), 190: tensor(47.5217), 200: tensor(43.1733), 210: tensor(39.2567), 220: tensor(38.8117), 230: tensor(43.6450), 240: tensor(54.4917), 250: tensor(69.0467), 260: tensor(80.2000), 270: tensor(89.6233), 280: tensor(85.9150), 290: tensor(80.6650), 300: tensor(73.9133), 310: tensor(68.7117), 320: tensor(72.6183), 330: tensor(83.2133), 340: tensor(94.0033), 350: tensor(97.6967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=74, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8254,                   Accuracy: 734/2000.0 (36.70%)



-= Testing valid =-
Test set: Average loss: 1.8624,                   Accuracy: 760/2000.0 (38.00%)



-= Testing valid =-
Test set: Average loss: 0.6383,                   Accuracy: 1639/2000.0 (81.95%)



-= Testing valid =-
Test set: Average loss: 0.4451,                   Accuracy: 1692/2000.0 (84.60%)



-= Testing valid =-
Test set: Average loss: 0.1582,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.2085,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1263,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 10 train accuracy: 98.47%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0621,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 20 train accuracy: 99.19%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 30 train accuracy: 99.54%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.72%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.85%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0493,                   Accuracy: 59146/60000 (98.58%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0746,                   Accuracy: 58719/60000 (97.86%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1708,                   Accuracy: 57052/60000 (95.09%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4483,                   Accuracy: 52212/60000 (87.02%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9147,                   Accuracy: 44236/60000 (73.73%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2441,                   Accuracy: 38514/60000 (64.19%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1902,                   Accuracy: 38135/60000 (63.56%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9943,                   Accuracy: 40940/60000 (68.23%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.9483,                   Accuracy: 41822/60000 (69.70%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.9651,                   Accuracy: 43319/60000 (72.20%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.1960,                   Accuracy: 39290/60000 (65.48%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.7466,                   Accuracy: 32505/60000 (54.17%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.4984,                   Accuracy: 27419/60000 (45.70%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.1082,                   Accuracy: 24435/60000 (40.72%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.6108,                   Accuracy: 23547/60000 (39.24%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.9821,                   Accuracy: 24876/60000 (41.46%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.2488,                   Accuracy: 27655/60000 (46.09%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.5928,                   Accuracy: 28855/60000 (48.09%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.7407,                   Accuracy: 28568/60000 (47.61%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.8443,                   Accuracy: 28272/60000 (47.12%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.8993,                   Accuracy: 27044/60000 (45.07%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.9862,                   Accuracy: 24443/60000 (40.74%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.7176,                   Accuracy: 23629/60000 (39.38%)
-= Testing Rotation 230 =-
Test set: Average loss: 4.0312,                   Accuracy: 25089/60000 (41.81%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.9220,                   Accuracy: 29447/60000 (49.08%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.7763,                   Accuracy: 36902/60000 (61.50%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.0232,                   Accuracy: 42893/60000 (71.49%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7234,                   Accuracy: 46248/60000 (77.08%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.8439,                   Accuracy: 43707/60000 (72.85%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9693,                   Accuracy: 41213/60000 (68.69%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2004,                   Accuracy: 37316/60000 (62.19%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2486,                   Accuracy: 37576/60000 (62.63%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0395,                   Accuracy: 41643/60000 (69.40%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5641,                   Accuracy: 49628/60000 (82.71%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2055,                   Accuracy: 56106/60000 (93.51%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0816,                   Accuracy: 58524/60000 (97.54%)
{0: tensor(98.5767), 10: tensor(97.8650), 20: tensor(95.0867), 30: tensor(87.0200), 40: tensor(73.7267), 50: tensor(64.1900), 60: tensor(63.5583), 70: tensor(68.2333), 80: tensor(69.7033), 90: tensor(72.1983), 100: tensor(65.4833), 110: tensor(54.1750), 120: tensor(45.6983), 130: tensor(40.7250), 140: tensor(39.2450), 150: tensor(41.4600), 160: tensor(46.0917), 170: tensor(48.0917), 180: tensor(47.6133), 190: tensor(47.1200), 200: tensor(45.0733), 210: tensor(40.7383), 220: tensor(39.3817), 230: tensor(41.8150), 240: tensor(49.0783), 250: tensor(61.5033), 260: tensor(71.4883), 270: tensor(77.0800), 280: tensor(72.8450), 290: tensor(68.6883), 300: tensor(62.1933), 310: tensor(62.6267), 320: tensor(69.4050), 330: tensor(82.7133), 340: tensor(93.5100), 350: tensor(97.5400)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=75, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7755,                   Accuracy: 706/2000.0 (35.30%)



-= Testing valid =-
Test set: Average loss: 1.4400,                   Accuracy: 987/2000.0 (49.35%)



-= Testing valid =-
Test set: Average loss: 0.8410,                   Accuracy: 1447/2000.0 (72.35%)



-= Testing valid =-
Test set: Average loss: 0.8885,                   Accuracy: 1426/2000.0 (71.30%)



-= Testing valid =-
Test set: Average loss: 3.9483,                   Accuracy: 650/2000.0 (32.50%)



-= Testing valid =-
Test set: Average loss: 0.7263,                   Accuracy: 1583/2000.0 (79.15%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1832,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.0937,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 10 train accuracy: 97.90%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0469,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0629,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 20 train accuracy: 99.05%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0520,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.30%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 40 train accuracy: 99.62%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.71%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0472,                   Accuracy: 59169/60000 (98.61%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0770,                   Accuracy: 58661/60000 (97.77%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1824,                   Accuracy: 56770/60000 (94.62%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4779,                   Accuracy: 51858/60000 (86.43%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9428,                   Accuracy: 44273/60000 (73.79%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2270,                   Accuracy: 39970/60000 (66.62%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0650,                   Accuracy: 42310/60000 (70.52%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7247,                   Accuracy: 47533/60000 (79.22%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4778,                   Accuracy: 51186/60000 (85.31%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4154,                   Accuracy: 52048/60000 (86.75%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7737,                   Accuracy: 46048/60000 (76.75%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6072,                   Accuracy: 36261/60000 (60.44%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5334,                   Accuracy: 28195/60000 (46.99%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.3534,                   Accuracy: 23443/60000 (39.07%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.7861,                   Accuracy: 22067/60000 (36.78%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.7106,                   Accuracy: 24064/60000 (40.11%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4474,                   Accuracy: 28131/60000 (46.88%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.3029,                   Accuracy: 31339/60000 (52.23%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.1185,                   Accuracy: 33110/60000 (55.18%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.5054,                   Accuracy: 32454/60000 (54.09%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.6485,                   Accuracy: 30857/60000 (51.43%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.6243,                   Accuracy: 27412/60000 (45.69%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.5867,                   Accuracy: 24633/60000 (41.06%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.0549,                   Accuracy: 25896/60000 (43.16%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0928,                   Accuracy: 32545/60000 (54.24%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1999,                   Accuracy: 41259/60000 (68.76%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6488,                   Accuracy: 48062/60000 (80.10%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4507,                   Accuracy: 50874/60000 (84.79%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6734,                   Accuracy: 46482/60000 (77.47%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0761,                   Accuracy: 41067/60000 (68.44%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.4972,                   Accuracy: 36375/60000 (60.62%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.7880,                   Accuracy: 33977/60000 (56.63%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.6679,                   Accuracy: 37366/60000 (62.28%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9965,                   Accuracy: 45771/60000 (76.29%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3666,                   Accuracy: 54148/60000 (90.25%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0960,                   Accuracy: 58300/60000 (97.17%)
{0: tensor(98.6150), 10: tensor(97.7683), 20: tensor(94.6167), 30: tensor(86.4300), 40: tensor(73.7883), 50: tensor(66.6167), 60: tensor(70.5167), 70: tensor(79.2217), 80: tensor(85.3100), 90: tensor(86.7467), 100: tensor(76.7467), 110: tensor(60.4350), 120: tensor(46.9917), 130: tensor(39.0717), 140: tensor(36.7783), 150: tensor(40.1067), 160: tensor(46.8850), 170: tensor(52.2317), 180: tensor(55.1833), 190: tensor(54.0900), 200: tensor(51.4283), 210: tensor(45.6867), 220: tensor(41.0550), 230: tensor(43.1600), 240: tensor(54.2417), 250: tensor(68.7650), 260: tensor(80.1033), 270: tensor(84.7900), 280: tensor(77.4700), 290: tensor(68.4450), 300: tensor(60.6250), 310: tensor(56.6283), 320: tensor(62.2767), 330: tensor(76.2850), 340: tensor(90.2467), 350: tensor(97.1667)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=76, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.9914,                   Accuracy: 318/2000.0 (15.90%)



-= Testing valid =-
Test set: Average loss: 1.6647,                   Accuracy: 787/2000.0 (39.35%)



-= Testing valid =-
Test set: Average loss: 1.1303,                   Accuracy: 1117/2000.0 (55.85%)



-= Testing valid =-
Test set: Average loss: 0.4075,                   Accuracy: 1721/2000.0 (86.05%)



-= Testing valid =-
Test set: Average loss: 0.1368,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.2011,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0511,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 10 train accuracy: 97.90%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0472,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 20 train accuracy: 98.99%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 30 train accuracy: 99.51%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 40 train accuracy: 99.46%, valid accuracy 99.35%
-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.74%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0518,                   Accuracy: 59112/60000 (98.52%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0701,                   Accuracy: 58760/60000 (97.93%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1486,                   Accuracy: 57392/60000 (95.65%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3857,                   Accuracy: 53455/60000 (89.09%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7506,                   Accuracy: 47360/60000 (78.93%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0147,                   Accuracy: 42440/60000 (70.73%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0243,                   Accuracy: 41897/60000 (69.83%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7749,                   Accuracy: 45528/60000 (75.88%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6834,                   Accuracy: 47547/60000 (79.25%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7447,                   Accuracy: 47846/60000 (79.74%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.2412,                   Accuracy: 42494/60000 (70.82%)
-= Testing Rotation 110 =-
Test set: Average loss: 2.0890,                   Accuracy: 36038/60000 (60.06%)
-= Testing Rotation 120 =-
Test set: Average loss: 3.1053,                   Accuracy: 30518/60000 (50.86%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.7895,                   Accuracy: 25886/60000 (43.14%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.0924,                   Accuracy: 23726/60000 (39.54%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.1070,                   Accuracy: 24084/60000 (40.14%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.9488,                   Accuracy: 27143/60000 (45.24%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.9748,                   Accuracy: 28824/60000 (48.04%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.0768,                   Accuracy: 28592/60000 (47.65%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.0052,                   Accuracy: 28331/60000 (47.22%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.1625,                   Accuracy: 26403/60000 (44.01%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.2114,                   Accuracy: 24017/60000 (40.03%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.0429,                   Accuracy: 22770/60000 (37.95%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.4601,                   Accuracy: 23908/60000 (39.85%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.5346,                   Accuracy: 28679/60000 (47.80%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.5232,                   Accuracy: 37600/60000 (62.67%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8896,                   Accuracy: 44520/60000 (74.20%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5737,                   Accuracy: 49286/60000 (82.14%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6188,                   Accuracy: 48320/60000 (80.53%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8465,                   Accuracy: 43967/60000 (73.28%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1948,                   Accuracy: 38463/60000 (64.11%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3788,                   Accuracy: 35403/60000 (59.01%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1755,                   Accuracy: 38797/60000 (64.66%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6502,                   Accuracy: 47938/60000 (79.90%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2115,                   Accuracy: 56045/60000 (93.41%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0771,                   Accuracy: 58594/60000 (97.66%)
{0: tensor(98.5200), 10: tensor(97.9333), 20: tensor(95.6533), 30: tensor(89.0917), 40: tensor(78.9333), 50: tensor(70.7333), 60: tensor(69.8283), 70: tensor(75.8800), 80: tensor(79.2450), 90: tensor(79.7433), 100: tensor(70.8233), 110: tensor(60.0633), 120: tensor(50.8633), 130: tensor(43.1433), 140: tensor(39.5433), 150: tensor(40.1400), 160: tensor(45.2383), 170: tensor(48.0400), 180: tensor(47.6533), 190: tensor(47.2183), 200: tensor(44.0050), 210: tensor(40.0283), 220: tensor(37.9500), 230: tensor(39.8467), 240: tensor(47.7983), 250: tensor(62.6667), 260: tensor(74.2000), 270: tensor(82.1433), 280: tensor(80.5333), 290: tensor(73.2783), 300: tensor(64.1050), 310: tensor(59.0050), 320: tensor(64.6617), 330: tensor(79.8967), 340: tensor(93.4083), 350: tensor(97.6567)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=77, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0413,                   Accuracy: 275/2000.0 (13.75%)



-= Testing valid =-
Test set: Average loss: 1.1174,                   Accuracy: 1074/2000.0 (53.70%)



-= Testing valid =-
Test set: Average loss: 0.4405,                   Accuracy: 1728/2000.0 (86.40%)



-= Testing valid =-
Test set: Average loss: 0.1410,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.2979,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2164,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.1525,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1367,                   Accuracy: 1915/2000.0 (95.75%)



Epoch 10 train accuracy: 98.19%, valid accuracy 95.75%
-= Testing valid =-
Test set: Average loss: 0.1235,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.2044,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 20 train accuracy: 99.38%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 30 train accuracy: 99.62%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0492,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 40 train accuracy: 99.68%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0409,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 50 train accuracy: 99.78%, valid accuracy 98.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0522,                   Accuracy: 59112/60000 (98.52%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0761,                   Accuracy: 58644/60000 (97.74%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1781,                   Accuracy: 56969/60000 (94.95%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5786,                   Accuracy: 50942/60000 (84.90%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.1559,                   Accuracy: 42500/60000 (70.83%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.5562,                   Accuracy: 36836/60000 (61.39%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.3769,                   Accuracy: 38102/60000 (63.50%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9071,                   Accuracy: 43884/60000 (73.14%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6661,                   Accuracy: 46913/60000 (78.19%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5099,                   Accuracy: 49333/60000 (82.22%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6520,                   Accuracy: 46905/60000 (78.18%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.0739,                   Accuracy: 40599/60000 (67.67%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.8806,                   Accuracy: 32074/60000 (53.46%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8344,                   Accuracy: 25627/60000 (42.71%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.5485,                   Accuracy: 23226/60000 (38.71%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.7573,                   Accuracy: 24606/60000 (41.01%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.6394,                   Accuracy: 28095/60000 (46.83%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5907,                   Accuracy: 29690/60000 (49.48%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.4077,                   Accuracy: 29617/60000 (49.36%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.3636,                   Accuracy: 29845/60000 (49.74%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.3658,                   Accuracy: 28385/60000 (47.31%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4678,                   Accuracy: 25482/60000 (42.47%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.4139,                   Accuracy: 24556/60000 (40.93%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9345,                   Accuracy: 26374/60000 (43.96%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9788,                   Accuracy: 33533/60000 (55.89%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0447,                   Accuracy: 43188/60000 (71.98%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5362,                   Accuracy: 50177/60000 (83.63%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3442,                   Accuracy: 53466/60000 (89.11%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4253,                   Accuracy: 51909/60000 (86.51%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6333,                   Accuracy: 48147/60000 (80.25%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1548,                   Accuracy: 42006/60000 (70.01%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.5154,                   Accuracy: 38101/60000 (63.50%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.4923,                   Accuracy: 39082/60000 (65.14%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8322,                   Accuracy: 47378/60000 (78.96%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2752,                   Accuracy: 55261/60000 (92.10%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0881,                   Accuracy: 58418/60000 (97.36%)
{0: tensor(98.5200), 10: tensor(97.7400), 20: tensor(94.9483), 30: tensor(84.9033), 40: tensor(70.8333), 50: tensor(61.3933), 60: tensor(63.5033), 70: tensor(73.1400), 80: tensor(78.1883), 90: tensor(82.2217), 100: tensor(78.1750), 110: tensor(67.6650), 120: tensor(53.4567), 130: tensor(42.7117), 140: tensor(38.7100), 150: tensor(41.0100), 160: tensor(46.8250), 170: tensor(49.4833), 180: tensor(49.3617), 190: tensor(49.7417), 200: tensor(47.3083), 210: tensor(42.4700), 220: tensor(40.9267), 230: tensor(43.9567), 240: tensor(55.8883), 250: tensor(71.9800), 260: tensor(83.6283), 270: tensor(89.1100), 280: tensor(86.5150), 290: tensor(80.2450), 300: tensor(70.0100), 310: tensor(63.5017), 320: tensor(65.1367), 330: tensor(78.9633), 340: tensor(92.1017), 350: tensor(97.3633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=78, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0469,                   Accuracy: 598/2000.0 (29.90%)



-= Testing valid =-
Test set: Average loss: 0.8736,                   Accuracy: 1562/2000.0 (78.10%)



-= Testing valid =-
Test set: Average loss: 0.6272,                   Accuracy: 1644/2000.0 (82.20%)



-= Testing valid =-
Test set: Average loss: 1.1982,                   Accuracy: 1194/2000.0 (59.70%)



-= Testing valid =-
Test set: Average loss: 0.2399,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.2908,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.6140,                   Accuracy: 1624/2000.0 (81.20%)



-= Testing valid =-
Test set: Average loss: 0.1363,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.2286,                   Accuracy: 1869/2000.0 (93.45%)



Epoch 10 train accuracy: 98.21%, valid accuracy 93.45%
-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.1129,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.2851,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 20 train accuracy: 99.25%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0568,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0595,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 30 train accuracy: 99.49%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0555,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 40 train accuracy: 99.69%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0492,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0477,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 50 train accuracy: 99.74%, valid accuracy 98.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0540,                   Accuracy: 59093/60000 (98.49%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0837,                   Accuracy: 58549/60000 (97.58%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1907,                   Accuracy: 56763/60000 (94.61%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5079,                   Accuracy: 51404/60000 (85.67%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9524,                   Accuracy: 43777/60000 (72.96%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.3350,                   Accuracy: 37166/60000 (61.94%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2527,                   Accuracy: 38130/60000 (63.55%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9396,                   Accuracy: 42803/60000 (71.34%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7455,                   Accuracy: 45646/60000 (76.08%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5944,                   Accuracy: 47731/60000 (79.55%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7070,                   Accuracy: 46159/60000 (76.93%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.0805,                   Accuracy: 40976/60000 (68.29%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.7995,                   Accuracy: 32418/60000 (54.03%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.4676,                   Accuracy: 26033/60000 (43.39%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.0289,                   Accuracy: 23162/60000 (38.60%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.1352,                   Accuracy: 24338/60000 (40.56%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.0120,                   Accuracy: 26782/60000 (44.64%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.0380,                   Accuracy: 28428/60000 (47.38%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.9870,                   Accuracy: 29897/60000 (49.83%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.0359,                   Accuracy: 28981/60000 (48.30%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.3204,                   Accuracy: 27007/60000 (45.01%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4649,                   Accuracy: 24481/60000 (40.80%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.2853,                   Accuracy: 24151/60000 (40.25%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7662,                   Accuracy: 26386/60000 (43.98%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.8297,                   Accuracy: 33654/60000 (56.09%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.9723,                   Accuracy: 44212/60000 (73.69%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5207,                   Accuracy: 50351/60000 (83.92%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3646,                   Accuracy: 53047/60000 (88.41%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5522,                   Accuracy: 49855/60000 (83.09%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7896,                   Accuracy: 45826/60000 (76.38%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2283,                   Accuracy: 40285/60000 (67.14%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3362,                   Accuracy: 38397/60000 (63.99%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2310,                   Accuracy: 40776/60000 (67.96%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6458,                   Accuracy: 49125/60000 (81.88%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2144,                   Accuracy: 56052/60000 (93.42%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0786,                   Accuracy: 58549/60000 (97.58%)
{0: tensor(98.4883), 10: tensor(97.5817), 20: tensor(94.6050), 30: tensor(85.6733), 40: tensor(72.9617), 50: tensor(61.9433), 60: tensor(63.5500), 70: tensor(71.3383), 80: tensor(76.0767), 90: tensor(79.5517), 100: tensor(76.9317), 110: tensor(68.2933), 120: tensor(54.0300), 130: tensor(43.3883), 140: tensor(38.6033), 150: tensor(40.5633), 160: tensor(44.6367), 170: tensor(47.3800), 180: tensor(49.8283), 190: tensor(48.3017), 200: tensor(45.0117), 210: tensor(40.8017), 220: tensor(40.2517), 230: tensor(43.9767), 240: tensor(56.0900), 250: tensor(73.6867), 260: tensor(83.9183), 270: tensor(88.4117), 280: tensor(83.0917), 290: tensor(76.3767), 300: tensor(67.1417), 310: tensor(63.9950), 320: tensor(67.9600), 330: tensor(81.8750), 340: tensor(93.4200), 350: tensor(97.5817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=79, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0053,                   Accuracy: 530/2000.0 (26.50%)



-= Testing valid =-
Test set: Average loss: 0.9794,                   Accuracy: 1385/2000.0 (69.25%)



-= Testing valid =-
Test set: Average loss: 0.7285,                   Accuracy: 1519/2000.0 (75.95%)



-= Testing valid =-
Test set: Average loss: 0.4293,                   Accuracy: 1737/2000.0 (86.85%)



-= Testing valid =-
Test set: Average loss: 0.1593,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1965,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 10 train accuracy: 97.95%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0604,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 20 train accuracy: 99.09%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.34%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 40 train accuracy: 99.59%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.70%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0547,                   Accuracy: 59090/60000 (98.48%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0846,                   Accuracy: 58529/60000 (97.55%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1894,                   Accuracy: 56654/60000 (94.42%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4599,                   Accuracy: 52048/60000 (86.75%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8797,                   Accuracy: 44724/60000 (74.54%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1170,                   Accuracy: 40751/60000 (67.92%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1132,                   Accuracy: 40183/60000 (66.97%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9529,                   Accuracy: 42128/60000 (70.21%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8904,                   Accuracy: 43159/60000 (71.93%)
-= Testing Rotation 90 =-
Test set: Average loss: 1.0158,                   Accuracy: 41991/60000 (69.99%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.3437,                   Accuracy: 37553/60000 (62.59%)
-= Testing Rotation 110 =-
Test set: Average loss: 2.1628,                   Accuracy: 30629/60000 (51.05%)
-= Testing Rotation 120 =-
Test set: Average loss: 3.0680,                   Accuracy: 22861/60000 (38.10%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.7052,                   Accuracy: 21216/60000 (35.36%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.8433,                   Accuracy: 21902/60000 (36.50%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8401,                   Accuracy: 24984/60000 (41.64%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.8332,                   Accuracy: 28481/60000 (47.47%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.9479,                   Accuracy: 30726/60000 (51.21%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.1654,                   Accuracy: 30783/60000 (51.31%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.3434,                   Accuracy: 29066/60000 (48.44%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.5985,                   Accuracy: 26461/60000 (44.10%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.8325,                   Accuracy: 23536/60000 (39.23%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.3761,                   Accuracy: 22867/60000 (38.11%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.4382,                   Accuracy: 26245/60000 (43.74%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.1983,                   Accuracy: 33187/60000 (55.31%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2145,                   Accuracy: 40986/60000 (68.31%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6785,                   Accuracy: 47099/60000 (78.50%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5080,                   Accuracy: 49931/60000 (83.22%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6860,                   Accuracy: 46883/60000 (78.14%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9913,                   Accuracy: 43209/60000 (72.01%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.4301,                   Accuracy: 37458/60000 (62.43%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.6086,                   Accuracy: 36577/60000 (60.96%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3400,                   Accuracy: 40737/60000 (67.89%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7294,                   Accuracy: 48807/60000 (81.35%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2359,                   Accuracy: 55873/60000 (93.12%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0838,                   Accuracy: 58505/60000 (97.51%)
{0: tensor(98.4833), 10: tensor(97.5483), 20: tensor(94.4233), 30: tensor(86.7467), 40: tensor(74.5400), 50: tensor(67.9183), 60: tensor(66.9717), 70: tensor(70.2133), 80: tensor(71.9317), 90: tensor(69.9850), 100: tensor(62.5883), 110: tensor(51.0483), 120: tensor(38.1017), 130: tensor(35.3600), 140: tensor(36.5033), 150: tensor(41.6400), 160: tensor(47.4683), 170: tensor(51.2100), 180: tensor(51.3050), 190: tensor(48.4433), 200: tensor(44.1017), 210: tensor(39.2267), 220: tensor(38.1117), 230: tensor(43.7417), 240: tensor(55.3117), 250: tensor(68.3100), 260: tensor(78.4983), 270: tensor(83.2183), 280: tensor(78.1383), 290: tensor(72.0150), 300: tensor(62.4300), 310: tensor(60.9617), 320: tensor(67.8950), 330: tensor(81.3450), 340: tensor(93.1217), 350: tensor(97.5083)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=80, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0142,                   Accuracy: 317/2000.0 (15.85%)



-= Testing valid =-
Test set: Average loss: 2.0349,                   Accuracy: 638/2000.0 (31.90%)



-= Testing valid =-
Test set: Average loss: 0.5779,                   Accuracy: 1663/2000.0 (83.15%)



-= Testing valid =-
Test set: Average loss: 0.2488,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.2473,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.3582,                   Accuracy: 1780/2000.0 (89.00%)



-= Testing valid =-
Test set: Average loss: 0.1126,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.4961,                   Accuracy: 1720/2000.0 (86.00%)



-= Testing valid =-
Test set: Average loss: 0.1320,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 10 train accuracy: 97.94%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 20 train accuracy: 99.01%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0251,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 30 train accuracy: 99.36%, valid accuracy 99.30%
-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 40 train accuracy: 99.49%, valid accuracy 99.30%
-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0220,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0213,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 50 train accuracy: 99.59%, valid accuracy 99.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0528,                   Accuracy: 59055/60000 (98.43%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0799,                   Accuracy: 58576/60000 (97.63%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1737,                   Accuracy: 56918/60000 (94.86%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4485,                   Accuracy: 51928/60000 (86.55%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8372,                   Accuracy: 44725/60000 (74.54%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0558,                   Accuracy: 40373/60000 (67.29%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9550,                   Accuracy: 41579/60000 (69.30%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7275,                   Accuracy: 45566/60000 (75.94%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6020,                   Accuracy: 47515/60000 (79.19%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5117,                   Accuracy: 49589/60000 (82.65%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7615,                   Accuracy: 45663/60000 (76.11%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2439,                   Accuracy: 39599/60000 (66.00%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0103,                   Accuracy: 32501/60000 (54.17%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8386,                   Accuracy: 27569/60000 (45.95%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.2235,                   Accuracy: 25978/60000 (43.30%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4364,                   Accuracy: 25915/60000 (43.19%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4264,                   Accuracy: 28667/60000 (47.78%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.6189,                   Accuracy: 30362/60000 (50.60%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.5865,                   Accuracy: 30948/60000 (51.58%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4034,                   Accuracy: 31207/60000 (52.01%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.3179,                   Accuracy: 29991/60000 (49.99%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4607,                   Accuracy: 26781/60000 (44.63%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.1973,                   Accuracy: 25080/60000 (41.80%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.6451,                   Accuracy: 26773/60000 (44.62%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9174,                   Accuracy: 31342/60000 (52.24%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1994,                   Accuracy: 37668/60000 (62.78%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7980,                   Accuracy: 42183/60000 (70.31%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6197,                   Accuracy: 45030/60000 (75.05%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7071,                   Accuracy: 43889/60000 (73.15%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8679,                   Accuracy: 41707/60000 (69.51%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2012,                   Accuracy: 38299/60000 (63.83%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3494,                   Accuracy: 37819/60000 (63.03%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1953,                   Accuracy: 41658/60000 (69.43%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6821,                   Accuracy: 48746/60000 (81.24%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2384,                   Accuracy: 55523/60000 (92.54%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0840,                   Accuracy: 58430/60000 (97.38%)
{0: tensor(98.4250), 10: tensor(97.6267), 20: tensor(94.8633), 30: tensor(86.5467), 40: tensor(74.5417), 50: tensor(67.2883), 60: tensor(69.2983), 70: tensor(75.9433), 80: tensor(79.1917), 90: tensor(82.6483), 100: tensor(76.1050), 110: tensor(65.9983), 120: tensor(54.1683), 130: tensor(45.9483), 140: tensor(43.2967), 150: tensor(43.1917), 160: tensor(47.7783), 170: tensor(50.6033), 180: tensor(51.5800), 190: tensor(52.0117), 200: tensor(49.9850), 210: tensor(44.6350), 220: tensor(41.8000), 230: tensor(44.6217), 240: tensor(52.2367), 250: tensor(62.7800), 260: tensor(70.3050), 270: tensor(75.0500), 280: tensor(73.1483), 290: tensor(69.5117), 300: tensor(63.8317), 310: tensor(63.0317), 320: tensor(69.4300), 330: tensor(81.2433), 340: tensor(92.5383), 350: tensor(97.3833)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=81, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9899,                   Accuracy: 558/2000.0 (27.90%)



-= Testing valid =-
Test set: Average loss: 2.8377,                   Accuracy: 343/2000.0 (17.15%)



-= Testing valid =-
Test set: Average loss: 1.2308,                   Accuracy: 1096/2000.0 (54.80%)



-= Testing valid =-
Test set: Average loss: 0.2680,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.1394,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1284,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1739,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1763,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.0721,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 10 train accuracy: 98.25%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0453,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 20 train accuracy: 99.06%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 30 train accuracy: 99.56%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 40 train accuracy: 99.62%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.66%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0475,                   Accuracy: 59128/60000 (98.55%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0751,                   Accuracy: 58636/60000 (97.73%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1570,                   Accuracy: 57221/60000 (95.37%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4199,                   Accuracy: 52638/60000 (87.73%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8672,                   Accuracy: 45045/60000 (75.07%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2775,                   Accuracy: 38560/60000 (64.27%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2620,                   Accuracy: 37966/60000 (63.28%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.1354,                   Accuracy: 38973/60000 (64.96%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.9993,                   Accuracy: 41957/60000 (69.93%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.9170,                   Accuracy: 42945/60000 (71.57%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.2651,                   Accuracy: 38083/60000 (63.47%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.7488,                   Accuracy: 33021/60000 (55.03%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5862,                   Accuracy: 26296/60000 (43.83%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.2277,                   Accuracy: 22848/60000 (38.08%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.6487,                   Accuracy: 21303/60000 (35.51%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.7910,                   Accuracy: 22612/60000 (37.69%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.6890,                   Accuracy: 24497/60000 (40.83%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.8796,                   Accuracy: 26006/60000 (43.34%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.7972,                   Accuracy: 26674/60000 (44.46%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.7584,                   Accuracy: 27416/60000 (45.69%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.9584,                   Accuracy: 26585/60000 (44.31%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.1786,                   Accuracy: 24587/60000 (40.98%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.0724,                   Accuracy: 22478/60000 (37.46%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.5927,                   Accuracy: 22363/60000 (37.27%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.7105,                   Accuracy: 25818/60000 (43.03%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.8160,                   Accuracy: 31816/60000 (53.03%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.2262,                   Accuracy: 37503/60000 (62.51%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.8352,                   Accuracy: 43592/60000 (72.65%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.9920,                   Accuracy: 41384/60000 (68.97%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.2022,                   Accuracy: 38346/60000 (63.91%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.4754,                   Accuracy: 35018/60000 (58.36%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.5056,                   Accuracy: 35013/60000 (58.35%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3687,                   Accuracy: 37823/60000 (63.04%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8008,                   Accuracy: 46120/60000 (76.87%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2980,                   Accuracy: 54276/60000 (90.46%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0857,                   Accuracy: 58410/60000 (97.35%)
{0: tensor(98.5467), 10: tensor(97.7267), 20: tensor(95.3683), 30: tensor(87.7300), 40: tensor(75.0750), 50: tensor(64.2667), 60: tensor(63.2767), 70: tensor(64.9550), 80: tensor(69.9283), 90: tensor(71.5750), 100: tensor(63.4717), 110: tensor(55.0350), 120: tensor(43.8267), 130: tensor(38.0800), 140: tensor(35.5050), 150: tensor(37.6867), 160: tensor(40.8283), 170: tensor(43.3433), 180: tensor(44.4567), 190: tensor(45.6933), 200: tensor(44.3083), 210: tensor(40.9783), 220: tensor(37.4633), 230: tensor(37.2717), 240: tensor(43.0300), 250: tensor(53.0267), 260: tensor(62.5050), 270: tensor(72.6533), 280: tensor(68.9733), 290: tensor(63.9100), 300: tensor(58.3633), 310: tensor(58.3550), 320: tensor(63.0383), 330: tensor(76.8667), 340: tensor(90.4600), 350: tensor(97.3500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=82, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2562,                   Accuracy: 432/2000.0 (21.60%)



-= Testing valid =-
Test set: Average loss: 2.4084,                   Accuracy: 733/2000.0 (36.65%)



-= Testing valid =-
Test set: Average loss: 0.2810,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.1535,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.2958,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2288,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1232,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.2603,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 10 train accuracy: 98.24%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 20 train accuracy: 98.86%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0189,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0193,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0204,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0200,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 30 train accuracy: 99.56%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0164,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0188,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0193,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0213,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0178,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0163,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0161,                   Accuracy: 1991/2000.0 (99.55%)



Epoch 40 train accuracy: 99.50%, valid accuracy 99.55%
-= Testing valid =-
Test set: Average loss: 0.0183,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0221,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0177,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0173,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0157,                   Accuracy: 1993/2000.0 (99.65%)



-= Testing valid =-
Test set: Average loss: 0.0183,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0198,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0180,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0159,                   Accuracy: 1992/2000.0 (99.60%)



Epoch 50 train accuracy: 99.69%, valid accuracy 99.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0436,                   Accuracy: 59244/60000 (98.74%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0729,                   Accuracy: 58754/60000 (97.92%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1514,                   Accuracy: 57438/60000 (95.73%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3985,                   Accuracy: 53339/60000 (88.90%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7479,                   Accuracy: 47833/60000 (79.72%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9651,                   Accuracy: 44428/60000 (74.05%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8624,                   Accuracy: 45470/60000 (75.78%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6526,                   Accuracy: 47546/60000 (79.24%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5818,                   Accuracy: 47796/60000 (79.66%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6035,                   Accuracy: 47366/60000 (78.94%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9671,                   Accuracy: 42285/60000 (70.47%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6885,                   Accuracy: 35115/60000 (58.53%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.7255,                   Accuracy: 27922/60000 (46.54%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.5377,                   Accuracy: 23601/60000 (39.33%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.9684,                   Accuracy: 22561/60000 (37.60%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8965,                   Accuracy: 23765/60000 (39.61%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.7229,                   Accuracy: 26593/60000 (44.32%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.7431,                   Accuracy: 28578/60000 (47.63%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.7523,                   Accuracy: 29557/60000 (49.26%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.8533,                   Accuracy: 28679/60000 (47.80%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.1785,                   Accuracy: 26362/60000 (43.94%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.3885,                   Accuracy: 23680/60000 (39.47%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.0071,                   Accuracy: 23694/60000 (39.49%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2537,                   Accuracy: 26519/60000 (44.20%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.1728,                   Accuracy: 33571/60000 (55.95%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2168,                   Accuracy: 42494/60000 (70.82%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7222,                   Accuracy: 48513/60000 (80.86%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4110,                   Accuracy: 52676/60000 (87.79%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4790,                   Accuracy: 51163/60000 (85.27%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7667,                   Accuracy: 46621/60000 (77.70%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2935,                   Accuracy: 39442/60000 (65.74%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.5503,                   Accuracy: 36209/60000 (60.35%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.4241,                   Accuracy: 39344/60000 (65.57%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8423,                   Accuracy: 47253/60000 (78.75%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2697,                   Accuracy: 55212/60000 (92.02%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0864,                   Accuracy: 58404/60000 (97.34%)
{0: tensor(98.7400), 10: tensor(97.9233), 20: tensor(95.7300), 30: tensor(88.8983), 40: tensor(79.7217), 50: tensor(74.0467), 60: tensor(75.7833), 70: tensor(79.2433), 80: tensor(79.6600), 90: tensor(78.9433), 100: tensor(70.4750), 110: tensor(58.5250), 120: tensor(46.5367), 130: tensor(39.3350), 140: tensor(37.6017), 150: tensor(39.6083), 160: tensor(44.3217), 170: tensor(47.6300), 180: tensor(49.2617), 190: tensor(47.7983), 200: tensor(43.9367), 210: tensor(39.4667), 220: tensor(39.4900), 230: tensor(44.1983), 240: tensor(55.9517), 250: tensor(70.8233), 260: tensor(80.8550), 270: tensor(87.7933), 280: tensor(85.2717), 290: tensor(77.7017), 300: tensor(65.7367), 310: tensor(60.3483), 320: tensor(65.5733), 330: tensor(78.7550), 340: tensor(92.0200), 350: tensor(97.3400)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=83, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 7.4579,                   Accuracy: 232/2000.0 (11.60%)



-= Testing valid =-
Test set: Average loss: 1.3700,                   Accuracy: 997/2000.0 (49.85%)



-= Testing valid =-
Test set: Average loss: 0.5114,                   Accuracy: 1680/2000.0 (84.00%)



-= Testing valid =-
Test set: Average loss: 0.3053,                   Accuracy: 1751/2000.0 (87.55%)



-= Testing valid =-
Test set: Average loss: 0.5850,                   Accuracy: 1650/2000.0 (82.50%)



-= Testing valid =-
Test set: Average loss: 0.1581,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.1928,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.1340,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.0755,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 10 train accuracy: 98.24%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0579,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0428,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 20 train accuracy: 99.09%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 30 train accuracy: 99.53%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 40 train accuracy: 99.55%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.66%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0436,                   Accuracy: 59227/60000 (98.71%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0733,                   Accuracy: 58727/60000 (97.88%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1714,                   Accuracy: 56994/60000 (94.99%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4901,                   Accuracy: 51239/60000 (85.40%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9152,                   Accuracy: 43800/60000 (73.00%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0971,                   Accuracy: 39897/60000 (66.50%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9869,                   Accuracy: 40915/60000 (68.19%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7653,                   Accuracy: 44691/60000 (74.49%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6626,                   Accuracy: 46624/60000 (77.71%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6652,                   Accuracy: 46756/60000 (77.93%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9777,                   Accuracy: 41490/60000 (69.15%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6457,                   Accuracy: 34519/60000 (57.53%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5128,                   Accuracy: 26916/60000 (44.86%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.1928,                   Accuracy: 22776/60000 (37.96%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3608,                   Accuracy: 23150/60000 (38.58%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.2453,                   Accuracy: 26918/60000 (44.86%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.9472,                   Accuracy: 31401/60000 (52.33%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.8309,                   Accuracy: 33468/60000 (55.78%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.8709,                   Accuracy: 33192/60000 (55.32%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.9577,                   Accuracy: 32035/60000 (53.39%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.3206,                   Accuracy: 28589/60000 (47.65%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.6310,                   Accuracy: 25017/60000 (41.69%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.5221,                   Accuracy: 24586/60000 (40.98%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7980,                   Accuracy: 27913/60000 (46.52%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.8449,                   Accuracy: 35015/60000 (58.36%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.9902,                   Accuracy: 43729/60000 (72.88%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5455,                   Accuracy: 50153/60000 (83.59%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3757,                   Accuracy: 52811/60000 (88.02%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4596,                   Accuracy: 51162/60000 (85.27%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6924,                   Accuracy: 46753/60000 (77.92%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0985,                   Accuracy: 40935/60000 (68.22%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2124,                   Accuracy: 39565/60000 (65.94%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0586,                   Accuracy: 43120/60000 (71.87%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6342,                   Accuracy: 49745/60000 (82.91%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2164,                   Accuracy: 56163/60000 (93.61%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0716,                   Accuracy: 58706/60000 (97.84%)
{0: tensor(98.7117), 10: tensor(97.8783), 20: tensor(94.9900), 30: tensor(85.3983), 40: tensor(73.), 50: tensor(66.4950), 60: tensor(68.1917), 70: tensor(74.4850), 80: tensor(77.7067), 90: tensor(77.9267), 100: tensor(69.1500), 110: tensor(57.5317), 120: tensor(44.8600), 130: tensor(37.9600), 140: tensor(38.5833), 150: tensor(44.8633), 160: tensor(52.3350), 170: tensor(55.7800), 180: tensor(55.3200), 190: tensor(53.3917), 200: tensor(47.6483), 210: tensor(41.6950), 220: tensor(40.9767), 230: tensor(46.5217), 240: tensor(58.3583), 250: tensor(72.8817), 260: tensor(83.5883), 270: tensor(88.0183), 280: tensor(85.2700), 290: tensor(77.9217), 300: tensor(68.2250), 310: tensor(65.9417), 320: tensor(71.8667), 330: tensor(82.9083), 340: tensor(93.6050), 350: tensor(97.8433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=84, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7719,                   Accuracy: 684/2000.0 (34.20%)



-= Testing valid =-
Test set: Average loss: 1.0923,                   Accuracy: 1205/2000.0 (60.25%)



-= Testing valid =-
Test set: Average loss: 0.5114,                   Accuracy: 1691/2000.0 (84.55%)



-= Testing valid =-
Test set: Average loss: 0.2796,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.1378,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1220,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 10 train accuracy: 98.24%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0605,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 20 train accuracy: 99.36%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.65%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.62%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0204,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0218,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0210,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0213,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0218,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0200,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0212,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 50 train accuracy: 99.80%, valid accuracy 99.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0460,                   Accuracy: 59240/60000 (98.73%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0734,                   Accuracy: 58788/60000 (97.98%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1756,                   Accuracy: 57176/60000 (95.29%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4512,                   Accuracy: 52555/60000 (87.59%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9251,                   Accuracy: 44867/60000 (74.78%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2379,                   Accuracy: 39597/60000 (66.00%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1892,                   Accuracy: 39737/60000 (66.23%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8568,                   Accuracy: 44090/60000 (73.48%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6690,                   Accuracy: 46973/60000 (78.29%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6692,                   Accuracy: 46363/60000 (77.27%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0949,                   Accuracy: 38589/60000 (64.32%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.8006,                   Accuracy: 31636/60000 (52.73%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.7275,                   Accuracy: 25331/60000 (42.22%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.5731,                   Accuracy: 22294/60000 (37.16%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.9420,                   Accuracy: 22950/60000 (38.25%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.9473,                   Accuracy: 26083/60000 (43.47%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.8436,                   Accuracy: 30063/60000 (50.10%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.7752,                   Accuracy: 32056/60000 (53.43%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.8490,                   Accuracy: 32709/60000 (54.51%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.8663,                   Accuracy: 31883/60000 (53.14%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.1195,                   Accuracy: 29459/60000 (49.10%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.3858,                   Accuracy: 25879/60000 (43.13%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.3207,                   Accuracy: 23956/60000 (39.93%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.6750,                   Accuracy: 25429/60000 (42.38%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.6094,                   Accuracy: 30937/60000 (51.56%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.4528,                   Accuracy: 39242/60000 (65.40%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8055,                   Accuracy: 45749/60000 (76.25%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6114,                   Accuracy: 48140/60000 (80.23%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.9010,                   Accuracy: 44073/60000 (73.46%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.3087,                   Accuracy: 39348/60000 (65.58%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.7233,                   Accuracy: 35271/60000 (58.78%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.8796,                   Accuracy: 33968/60000 (56.61%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.5443,                   Accuracy: 38598/60000 (64.33%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8160,                   Accuracy: 47717/60000 (79.53%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2265,                   Accuracy: 56121/60000 (93.54%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0692,                   Accuracy: 58770/60000 (97.95%)
{0: tensor(98.7333), 10: tensor(97.9800), 20: tensor(95.2933), 30: tensor(87.5917), 40: tensor(74.7783), 50: tensor(65.9950), 60: tensor(66.2283), 70: tensor(73.4833), 80: tensor(78.2883), 90: tensor(77.2717), 100: tensor(64.3150), 110: tensor(52.7267), 120: tensor(42.2183), 130: tensor(37.1567), 140: tensor(38.2500), 150: tensor(43.4717), 160: tensor(50.1050), 170: tensor(53.4267), 180: tensor(54.5150), 190: tensor(53.1383), 200: tensor(49.0983), 210: tensor(43.1317), 220: tensor(39.9267), 230: tensor(42.3817), 240: tensor(51.5617), 250: tensor(65.4033), 260: tensor(76.2483), 270: tensor(80.2333), 280: tensor(73.4550), 290: tensor(65.5800), 300: tensor(58.7850), 310: tensor(56.6133), 320: tensor(64.3300), 330: tensor(79.5283), 340: tensor(93.5350), 350: tensor(97.9500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=85, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4000,                   Accuracy: 334/2000.0 (16.70%)



-= Testing valid =-
Test set: Average loss: 1.0162,                   Accuracy: 1255/2000.0 (62.75%)



-= Testing valid =-
Test set: Average loss: 0.4726,                   Accuracy: 1714/2000.0 (85.70%)



-= Testing valid =-
Test set: Average loss: 0.1551,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.2024,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1837,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.0684,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0597,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 10 train accuracy: 98.18%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0628,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.2585,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.0718,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0622,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 20 train accuracy: 99.22%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0594,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.55%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 40 train accuracy: 99.66%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.72%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0556,                   Accuracy: 59040/60000 (98.40%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0849,                   Accuracy: 58569/60000 (97.61%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1988,                   Accuracy: 56636/60000 (94.39%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5226,                   Accuracy: 51428/60000 (85.71%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9739,                   Accuracy: 44773/60000 (74.62%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2468,                   Accuracy: 40528/60000 (67.55%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2144,                   Accuracy: 40264/60000 (67.11%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9676,                   Accuracy: 43493/60000 (72.49%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7447,                   Accuracy: 46606/60000 (77.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5951,                   Accuracy: 48833/60000 (81.39%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7703,                   Accuracy: 45474/60000 (75.79%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1555,                   Accuracy: 39120/60000 (65.20%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.7710,                   Accuracy: 31652/60000 (52.75%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.4022,                   Accuracy: 25897/60000 (43.16%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.8647,                   Accuracy: 23483/60000 (39.14%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.1522,                   Accuracy: 23539/60000 (39.23%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.3027,                   Accuracy: 25831/60000 (43.05%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.3510,                   Accuracy: 28344/60000 (47.24%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.1956,                   Accuracy: 28883/60000 (48.14%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4998,                   Accuracy: 28158/60000 (46.93%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7100,                   Accuracy: 25981/60000 (43.30%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.8085,                   Accuracy: 23495/60000 (39.16%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.5396,                   Accuracy: 23654/60000 (39.42%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8919,                   Accuracy: 26559/60000 (44.26%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0935,                   Accuracy: 32113/60000 (53.52%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2808,                   Accuracy: 39529/60000 (65.88%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7949,                   Accuracy: 45426/60000 (75.71%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5551,                   Accuracy: 49328/60000 (82.21%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7428,                   Accuracy: 44902/60000 (74.84%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9124,                   Accuracy: 41986/60000 (69.98%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1783,                   Accuracy: 38734/60000 (64.56%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2449,                   Accuracy: 39052/60000 (65.09%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0328,                   Accuracy: 42970/60000 (71.62%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5918,                   Accuracy: 49885/60000 (83.14%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2083,                   Accuracy: 56259/60000 (93.76%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0761,                   Accuracy: 58668/60000 (97.78%)
{0: tensor(98.4000), 10: tensor(97.6150), 20: tensor(94.3933), 30: tensor(85.7133), 40: tensor(74.6217), 50: tensor(67.5467), 60: tensor(67.1067), 70: tensor(72.4883), 80: tensor(77.6767), 90: tensor(81.3883), 100: tensor(75.7900), 110: tensor(65.2000), 120: tensor(52.7533), 130: tensor(43.1617), 140: tensor(39.1383), 150: tensor(39.2317), 160: tensor(43.0517), 170: tensor(47.2400), 180: tensor(48.1383), 190: tensor(46.9300), 200: tensor(43.3017), 210: tensor(39.1583), 220: tensor(39.4233), 230: tensor(44.2650), 240: tensor(53.5217), 250: tensor(65.8817), 260: tensor(75.7100), 270: tensor(82.2133), 280: tensor(74.8367), 290: tensor(69.9767), 300: tensor(64.5567), 310: tensor(65.0867), 320: tensor(71.6167), 330: tensor(83.1417), 340: tensor(93.7650), 350: tensor(97.7800)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=86, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8456,                   Accuracy: 642/2000.0 (32.10%)



-= Testing valid =-
Test set: Average loss: 1.2694,                   Accuracy: 1085/2000.0 (54.25%)



-= Testing valid =-
Test set: Average loss: 2.0396,                   Accuracy: 808/2000.0 (40.40%)



-= Testing valid =-
Test set: Average loss: 0.4568,                   Accuracy: 1660/2000.0 (83.00%)



-= Testing valid =-
Test set: Average loss: 0.1353,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1330,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1185,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.1188,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1489,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 10 train accuracy: 97.69%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0602,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 20 train accuracy: 99.25%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.40%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.62%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.84%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0540,                   Accuracy: 59112/60000 (98.52%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0738,                   Accuracy: 58780/60000 (97.97%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1632,                   Accuracy: 57273/60000 (95.46%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4118,                   Accuracy: 52963/60000 (88.27%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7480,                   Accuracy: 47100/60000 (78.50%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9863,                   Accuracy: 42646/60000 (71.08%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9151,                   Accuracy: 43536/60000 (72.56%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6515,                   Accuracy: 47906/60000 (79.84%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4406,                   Accuracy: 51518/60000 (85.86%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4214,                   Accuracy: 51854/60000 (86.42%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6874,                   Accuracy: 47543/60000 (79.24%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3330,                   Accuracy: 39790/60000 (66.32%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.3831,                   Accuracy: 30849/60000 (51.42%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.2856,                   Accuracy: 25212/60000 (42.02%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.7818,                   Accuracy: 23160/60000 (38.60%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8507,                   Accuracy: 24310/60000 (40.52%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.6818,                   Accuracy: 26864/60000 (44.77%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5594,                   Accuracy: 28587/60000 (47.65%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.5347,                   Accuracy: 29304/60000 (48.84%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.6856,                   Accuracy: 28494/60000 (47.49%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7942,                   Accuracy: 26668/60000 (44.45%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9826,                   Accuracy: 24076/60000 (40.13%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.0126,                   Accuracy: 22921/60000 (38.20%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.3087,                   Accuracy: 25800/60000 (43.00%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2538,                   Accuracy: 32029/60000 (53.38%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2294,                   Accuracy: 41394/60000 (68.99%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6447,                   Accuracy: 48180/60000 (80.30%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4186,                   Accuracy: 51696/60000 (86.16%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5274,                   Accuracy: 49325/60000 (82.21%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7297,                   Accuracy: 46400/60000 (77.33%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1284,                   Accuracy: 39681/60000 (66.14%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3890,                   Accuracy: 35636/60000 (59.39%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3049,                   Accuracy: 37850/60000 (63.08%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7941,                   Accuracy: 46453/60000 (77.42%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2810,                   Accuracy: 54974/60000 (91.62%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0937,                   Accuracy: 58341/60000 (97.24%)
{0: tensor(98.5200), 10: tensor(97.9667), 20: tensor(95.4550), 30: tensor(88.2717), 40: tensor(78.5000), 50: tensor(71.0767), 60: tensor(72.5600), 70: tensor(79.8433), 80: tensor(85.8633), 90: tensor(86.4233), 100: tensor(79.2383), 110: tensor(66.3167), 120: tensor(51.4150), 130: tensor(42.0200), 140: tensor(38.6000), 150: tensor(40.5167), 160: tensor(44.7733), 170: tensor(47.6450), 180: tensor(48.8400), 190: tensor(47.4900), 200: tensor(44.4467), 210: tensor(40.1267), 220: tensor(38.2017), 230: tensor(43.), 240: tensor(53.3817), 250: tensor(68.9900), 260: tensor(80.3000), 270: tensor(86.1600), 280: tensor(82.2083), 290: tensor(77.3333), 300: tensor(66.1350), 310: tensor(59.3933), 320: tensor(63.0833), 330: tensor(77.4217), 340: tensor(91.6233), 350: tensor(97.2350)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=87, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4557,                   Accuracy: 409/2000.0 (20.45%)



-= Testing valid =-
Test set: Average loss: 0.8510,                   Accuracy: 1499/2000.0 (74.95%)



-= Testing valid =-
Test set: Average loss: 0.8118,                   Accuracy: 1501/2000.0 (75.05%)



-= Testing valid =-
Test set: Average loss: 0.2157,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1251,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1713,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.1457,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 10 train accuracy: 98.46%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 20 train accuracy: 99.11%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.45%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 40 train accuracy: 99.62%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 50 train accuracy: 99.79%, valid accuracy 99.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0430,                   Accuracy: 59243/60000 (98.74%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0740,                   Accuracy: 58705/60000 (97.84%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1620,                   Accuracy: 57284/60000 (95.47%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4331,                   Accuracy: 52943/60000 (88.24%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8200,                   Accuracy: 46505/60000 (77.51%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0819,                   Accuracy: 41484/60000 (69.14%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0788,                   Accuracy: 40563/60000 (67.61%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8958,                   Accuracy: 43064/60000 (71.77%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8206,                   Accuracy: 43685/60000 (72.81%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7409,                   Accuracy: 45949/60000 (76.58%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.1251,                   Accuracy: 41442/60000 (69.07%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.8123,                   Accuracy: 35683/60000 (59.47%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.7971,                   Accuracy: 28535/60000 (47.56%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.5110,                   Accuracy: 24287/60000 (40.48%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.7979,                   Accuracy: 22975/60000 (38.29%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.7828,                   Accuracy: 24109/60000 (40.18%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.6290,                   Accuracy: 26421/60000 (44.03%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.6204,                   Accuracy: 28159/60000 (46.93%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.4555,                   Accuracy: 29701/60000 (49.50%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.6319,                   Accuracy: 29313/60000 (48.85%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.8872,                   Accuracy: 27820/60000 (46.37%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.1014,                   Accuracy: 24961/60000 (41.60%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.8920,                   Accuracy: 23792/60000 (39.65%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1951,                   Accuracy: 25972/60000 (43.29%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2003,                   Accuracy: 31802/60000 (53.00%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2435,                   Accuracy: 40530/60000 (67.55%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6767,                   Accuracy: 47767/60000 (79.61%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4537,                   Accuracy: 51203/60000 (85.34%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5445,                   Accuracy: 49845/60000 (83.07%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7672,                   Accuracy: 46830/60000 (78.05%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2234,                   Accuracy: 40743/60000 (67.90%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4609,                   Accuracy: 38186/60000 (63.64%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3320,                   Accuracy: 40545/60000 (67.57%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7521,                   Accuracy: 48226/60000 (80.38%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2322,                   Accuracy: 55813/60000 (93.02%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0778,                   Accuracy: 58586/60000 (97.64%)
{0: tensor(98.7383), 10: tensor(97.8417), 20: tensor(95.4733), 30: tensor(88.2383), 40: tensor(77.5083), 50: tensor(69.1400), 60: tensor(67.6050), 70: tensor(71.7733), 80: tensor(72.8083), 90: tensor(76.5817), 100: tensor(69.0700), 110: tensor(59.4717), 120: tensor(47.5583), 130: tensor(40.4783), 140: tensor(38.2917), 150: tensor(40.1817), 160: tensor(44.0350), 170: tensor(46.9317), 180: tensor(49.5017), 190: tensor(48.8550), 200: tensor(46.3667), 210: tensor(41.6017), 220: tensor(39.6533), 230: tensor(43.2867), 240: tensor(53.0033), 250: tensor(67.5500), 260: tensor(79.6117), 270: tensor(85.3383), 280: tensor(83.0750), 290: tensor(78.0500), 300: tensor(67.9050), 310: tensor(63.6433), 320: tensor(67.5750), 330: tensor(80.3767), 340: tensor(93.0217), 350: tensor(97.6433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=88, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3694,                   Accuracy: 278/2000.0 (13.90%)



-= Testing valid =-
Test set: Average loss: 1.7410,                   Accuracy: 788/2000.0 (39.40%)



-= Testing valid =-
Test set: Average loss: 0.3863,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.5147,                   Accuracy: 1672/2000.0 (83.60%)



-= Testing valid =-
Test set: Average loss: 0.9602,                   Accuracy: 1467/2000.0 (73.35%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1066,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 10 train accuracy: 98.14%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 20 train accuracy: 99.05%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0486,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 30 train accuracy: 99.40%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.56%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.70%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0548,                   Accuracy: 59059/60000 (98.43%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0730,                   Accuracy: 58739/60000 (97.90%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1597,                   Accuracy: 57304/60000 (95.51%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4125,                   Accuracy: 53028/60000 (88.38%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8252,                   Accuracy: 46247/60000 (77.08%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1743,                   Accuracy: 40148/60000 (66.91%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2841,                   Accuracy: 38230/60000 (63.72%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.0524,                   Accuracy: 41175/60000 (68.62%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8228,                   Accuracy: 44260/60000 (73.77%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7287,                   Accuracy: 45849/60000 (76.42%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9121,                   Accuracy: 43050/60000 (71.75%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5304,                   Accuracy: 35210/60000 (58.68%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.4758,                   Accuracy: 27420/60000 (45.70%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.3631,                   Accuracy: 23004/60000 (38.34%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.9191,                   Accuracy: 22183/60000 (36.97%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.1576,                   Accuracy: 23265/60000 (38.78%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.1064,                   Accuracy: 26146/60000 (43.58%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.0308,                   Accuracy: 28137/60000 (46.90%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.9449,                   Accuracy: 28506/60000 (47.51%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.9064,                   Accuracy: 27913/60000 (46.52%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.9754,                   Accuracy: 25827/60000 (43.04%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9941,                   Accuracy: 23520/60000 (39.20%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.8215,                   Accuracy: 22709/60000 (37.85%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.3028,                   Accuracy: 24854/60000 (41.42%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.5310,                   Accuracy: 30902/60000 (51.50%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.7101,                   Accuracy: 38201/60000 (63.67%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.0673,                   Accuracy: 43720/60000 (72.87%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7046,                   Accuracy: 47825/60000 (79.71%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.8064,                   Accuracy: 45332/60000 (75.55%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0016,                   Accuracy: 41548/60000 (69.25%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3620,                   Accuracy: 36739/60000 (61.23%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.5220,                   Accuracy: 35062/60000 (58.44%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2734,                   Accuracy: 39356/60000 (65.59%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7547,                   Accuracy: 47367/60000 (78.94%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2410,                   Accuracy: 55682/60000 (92.80%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0812,                   Accuracy: 58582/60000 (97.64%)
{0: tensor(98.4317), 10: tensor(97.8983), 20: tensor(95.5067), 30: tensor(88.3800), 40: tensor(77.0783), 50: tensor(66.9133), 60: tensor(63.7167), 70: tensor(68.6250), 80: tensor(73.7667), 90: tensor(76.4150), 100: tensor(71.7500), 110: tensor(58.6833), 120: tensor(45.7000), 130: tensor(38.3400), 140: tensor(36.9717), 150: tensor(38.7750), 160: tensor(43.5767), 170: tensor(46.8950), 180: tensor(47.5100), 190: tensor(46.5217), 200: tensor(43.0450), 210: tensor(39.2000), 220: tensor(37.8483), 230: tensor(41.4233), 240: tensor(51.5033), 250: tensor(63.6683), 260: tensor(72.8667), 270: tensor(79.7083), 280: tensor(75.5533), 290: tensor(69.2467), 300: tensor(61.2317), 310: tensor(58.4367), 320: tensor(65.5933), 330: tensor(78.9450), 340: tensor(92.8033), 350: tensor(97.6367)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=89, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6268,                   Accuracy: 223/2000.0 (11.15%)



-= Testing valid =-
Test set: Average loss: 1.4850,                   Accuracy: 1041/2000.0 (52.05%)



-= Testing valid =-
Test set: Average loss: 0.3207,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2824,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.1794,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.6013,                   Accuracy: 1649/2000.0 (82.45%)



-= Testing valid =-
Test set: Average loss: 0.1787,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1106,                   Accuracy: 1934/2000.0 (96.70%)



Epoch 10 train accuracy: 97.80%, valid accuracy 96.70%
-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0450,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0454,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 20 train accuracy: 98.95%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.34%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.65%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.70%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0494,                   Accuracy: 59120/60000 (98.53%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0774,                   Accuracy: 58631/60000 (97.72%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1717,                   Accuracy: 57068/60000 (95.11%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4726,                   Accuracy: 52298/60000 (87.16%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8709,                   Accuracy: 45476/60000 (75.79%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1360,                   Accuracy: 40803/60000 (68.00%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0085,                   Accuracy: 42221/60000 (70.37%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7290,                   Accuracy: 46012/60000 (76.69%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6510,                   Accuracy: 46994/60000 (78.32%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6599,                   Accuracy: 46931/60000 (78.22%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0646,                   Accuracy: 40790/60000 (67.98%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6831,                   Accuracy: 34775/60000 (57.96%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.7267,                   Accuracy: 26372/60000 (43.95%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.4173,                   Accuracy: 22886/60000 (38.14%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.7357,                   Accuracy: 22489/60000 (37.48%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.6801,                   Accuracy: 24518/60000 (40.86%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4416,                   Accuracy: 27973/60000 (46.62%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.4220,                   Accuracy: 29427/60000 (49.04%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.3972,                   Accuracy: 30245/60000 (50.41%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.3870,                   Accuracy: 29119/60000 (48.53%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.4790,                   Accuracy: 26610/60000 (44.35%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9177,                   Accuracy: 22751/60000 (37.92%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7609,                   Accuracy: 21211/60000 (35.35%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1926,                   Accuracy: 23474/60000 (39.12%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.1791,                   Accuracy: 30344/60000 (50.57%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1964,                   Accuracy: 39863/60000 (66.44%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7137,                   Accuracy: 46027/60000 (76.71%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5011,                   Accuracy: 50157/60000 (83.60%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6536,                   Accuracy: 48127/60000 (80.21%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9345,                   Accuracy: 44187/60000 (73.64%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.5372,                   Accuracy: 37146/60000 (61.91%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.6361,                   Accuracy: 35581/60000 (59.30%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3702,                   Accuracy: 39029/60000 (65.05%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7928,                   Accuracy: 47477/60000 (79.13%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2608,                   Accuracy: 55404/60000 (92.34%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0916,                   Accuracy: 58355/60000 (97.26%)
{0: tensor(98.5333), 10: tensor(97.7183), 20: tensor(95.1133), 30: tensor(87.1633), 40: tensor(75.7933), 50: tensor(68.0050), 60: tensor(70.3683), 70: tensor(76.6867), 80: tensor(78.3233), 90: tensor(78.2183), 100: tensor(67.9833), 110: tensor(57.9583), 120: tensor(43.9533), 130: tensor(38.1433), 140: tensor(37.4817), 150: tensor(40.8633), 160: tensor(46.6217), 170: tensor(49.0450), 180: tensor(50.4083), 190: tensor(48.5317), 200: tensor(44.3500), 210: tensor(37.9183), 220: tensor(35.3517), 230: tensor(39.1233), 240: tensor(50.5733), 250: tensor(66.4383), 260: tensor(76.7117), 270: tensor(83.5950), 280: tensor(80.2117), 290: tensor(73.6450), 300: tensor(61.9100), 310: tensor(59.3017), 320: tensor(65.0483), 330: tensor(79.1283), 340: tensor(92.3400), 350: tensor(97.2583)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=90, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9901,                   Accuracy: 557/2000.0 (27.85%)



-= Testing valid =-
Test set: Average loss: 0.9684,                   Accuracy: 1312/2000.0 (65.60%)



-= Testing valid =-
Test set: Average loss: 0.8705,                   Accuracy: 1449/2000.0 (72.45%)



-= Testing valid =-
Test set: Average loss: 0.1339,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1107,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1021,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0711,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 10 train accuracy: 98.20%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0453,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 20 train accuracy: 99.19%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0668,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 30 train accuracy: 99.38%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 40 train accuracy: 99.68%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.86%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0463,                   Accuracy: 59209/60000 (98.68%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0800,                   Accuracy: 58602/60000 (97.67%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1952,                   Accuracy: 56707/60000 (94.51%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4700,                   Accuracy: 52042/60000 (86.74%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8751,                   Accuracy: 45078/60000 (75.13%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1423,                   Accuracy: 40306/60000 (67.18%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1035,                   Accuracy: 40244/60000 (67.07%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8289,                   Accuracy: 44125/60000 (73.54%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6184,                   Accuracy: 47845/60000 (79.74%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5502,                   Accuracy: 49018/60000 (81.70%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6797,                   Accuracy: 47087/60000 (78.48%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1195,                   Accuracy: 41663/60000 (69.44%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.8687,                   Accuracy: 33748/60000 (56.25%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.6119,                   Accuracy: 27542/60000 (45.90%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.0389,                   Accuracy: 25071/60000 (41.78%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.2746,                   Accuracy: 24911/60000 (41.52%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.2589,                   Accuracy: 26908/60000 (44.85%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.2382,                   Accuracy: 28994/60000 (48.32%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.2892,                   Accuracy: 29689/60000 (49.48%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.1570,                   Accuracy: 29964/60000 (49.94%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.1852,                   Accuracy: 28607/60000 (47.68%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4436,                   Accuracy: 25850/60000 (43.08%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.3832,                   Accuracy: 24146/60000 (40.24%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.0004,                   Accuracy: 25044/60000 (41.74%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2517,                   Accuracy: 29187/60000 (48.65%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.4008,                   Accuracy: 36764/60000 (61.27%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7988,                   Accuracy: 43979/60000 (73.30%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5741,                   Accuracy: 47443/60000 (79.07%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5941,                   Accuracy: 47214/60000 (78.69%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7688,                   Accuracy: 44463/60000 (74.11%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0621,                   Accuracy: 39589/60000 (65.98%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1346,                   Accuracy: 37996/60000 (63.33%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9573,                   Accuracy: 41464/60000 (69.11%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5299,                   Accuracy: 49537/60000 (82.56%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1911,                   Accuracy: 56289/60000 (93.82%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0728,                   Accuracy: 58679/60000 (97.80%)
{0: tensor(98.6817), 10: tensor(97.6700), 20: tensor(94.5117), 30: tensor(86.7367), 40: tensor(75.1300), 50: tensor(67.1767), 60: tensor(67.0733), 70: tensor(73.5417), 80: tensor(79.7417), 90: tensor(81.6967), 100: tensor(78.4783), 110: tensor(69.4383), 120: tensor(56.2467), 130: tensor(45.9033), 140: tensor(41.7850), 150: tensor(41.5183), 160: tensor(44.8467), 170: tensor(48.3233), 180: tensor(49.4817), 190: tensor(49.9400), 200: tensor(47.6783), 210: tensor(43.0833), 220: tensor(40.2433), 230: tensor(41.7400), 240: tensor(48.6450), 250: tensor(61.2733), 260: tensor(73.2983), 270: tensor(79.0717), 280: tensor(78.6900), 290: tensor(74.1050), 300: tensor(65.9817), 310: tensor(63.3267), 320: tensor(69.1067), 330: tensor(82.5617), 340: tensor(93.8150), 350: tensor(97.7983)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=91, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.5017,                   Accuracy: 247/2000.0 (12.35%)



-= Testing valid =-
Test set: Average loss: 1.4120,                   Accuracy: 879/2000.0 (43.95%)



-= Testing valid =-
Test set: Average loss: 1.2047,                   Accuracy: 1234/2000.0 (61.70%)



-= Testing valid =-
Test set: Average loss: 0.8054,                   Accuracy: 1480/2000.0 (74.00%)



-= Testing valid =-
Test set: Average loss: 0.1301,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.4185,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.3928,                   Accuracy: 1751/2000.0 (87.55%)



-= Testing valid =-
Test set: Average loss: 0.1114,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1398,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 10 train accuracy: 97.56%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 20 train accuracy: 98.81%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 30 train accuracy: 99.47%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.51%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 50 train accuracy: 99.62%, valid accuracy 99.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0555,                   Accuracy: 59027/60000 (98.38%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0789,                   Accuracy: 58622/60000 (97.70%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1423,                   Accuracy: 57514/60000 (95.86%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3147,                   Accuracy: 54574/60000 (90.96%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.5576,                   Accuracy: 50272/60000 (83.79%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.7319,                   Accuracy: 47098/60000 (78.50%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7391,                   Accuracy: 46767/60000 (77.94%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6114,                   Accuracy: 48700/60000 (81.17%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5023,                   Accuracy: 50320/60000 (83.87%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4660,                   Accuracy: 50835/60000 (84.72%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8038,                   Accuracy: 46037/60000 (76.73%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5152,                   Accuracy: 38790/60000 (64.65%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0990,                   Accuracy: 32683/60000 (54.47%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8815,                   Accuracy: 27113/60000 (45.19%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.2661,                   Accuracy: 25395/60000 (42.33%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.5432,                   Accuracy: 26003/60000 (43.34%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5409,                   Accuracy: 29454/60000 (49.09%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.4195,                   Accuracy: 31864/60000 (53.11%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.3443,                   Accuracy: 32621/60000 (54.37%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.3902,                   Accuracy: 33089/60000 (55.15%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.3501,                   Accuracy: 31824/60000 (53.04%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4586,                   Accuracy: 27474/60000 (45.79%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.3533,                   Accuracy: 25223/60000 (42.04%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7398,                   Accuracy: 26771/60000 (44.62%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.8794,                   Accuracy: 32521/60000 (54.20%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1454,                   Accuracy: 40190/60000 (66.98%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7120,                   Accuracy: 46234/60000 (77.06%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4694,                   Accuracy: 50232/60000 (83.72%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6006,                   Accuracy: 48546/60000 (80.91%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8566,                   Accuracy: 45117/60000 (75.19%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9403,                   Accuracy: 43224/60000 (72.04%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0956,                   Accuracy: 40867/60000 (68.11%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9555,                   Accuracy: 43275/60000 (72.12%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5447,                   Accuracy: 50062/60000 (83.44%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2482,                   Accuracy: 55431/60000 (92.39%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0860,                   Accuracy: 58431/60000 (97.39%)
{0: tensor(98.3783), 10: tensor(97.7033), 20: tensor(95.8567), 30: tensor(90.9567), 40: tensor(83.7867), 50: tensor(78.4967), 60: tensor(77.9450), 70: tensor(81.1667), 80: tensor(83.8667), 90: tensor(84.7250), 100: tensor(76.7283), 110: tensor(64.6500), 120: tensor(54.4717), 130: tensor(45.1883), 140: tensor(42.3250), 150: tensor(43.3383), 160: tensor(49.0900), 170: tensor(53.1067), 180: tensor(54.3683), 190: tensor(55.1483), 200: tensor(53.0400), 210: tensor(45.7900), 220: tensor(42.0383), 230: tensor(44.6183), 240: tensor(54.2017), 250: tensor(66.9833), 260: tensor(77.0567), 270: tensor(83.7200), 280: tensor(80.9100), 290: tensor(75.1950), 300: tensor(72.0400), 310: tensor(68.1117), 320: tensor(72.1250), 330: tensor(83.4367), 340: tensor(92.3850), 350: tensor(97.3850)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=92, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6630,                   Accuracy: 371/2000.0 (18.55%)



-= Testing valid =-
Test set: Average loss: 2.7931,                   Accuracy: 515/2000.0 (25.75%)



-= Testing valid =-
Test set: Average loss: 0.4014,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.2311,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2530,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.1105,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1946,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 10 train accuracy: 97.99%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 20 train accuracy: 99.24%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.40%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0251,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 40 train accuracy: 99.62%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.69%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0479,                   Accuracy: 59157/60000 (98.60%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0783,                   Accuracy: 58667/60000 (97.78%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1836,                   Accuracy: 56822/60000 (94.70%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4871,                   Accuracy: 51628/60000 (86.05%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9516,                   Accuracy: 43667/60000 (72.78%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2395,                   Accuracy: 38232/60000 (63.72%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1401,                   Accuracy: 38901/60000 (64.83%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8502,                   Accuracy: 43475/60000 (72.46%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6439,                   Accuracy: 47151/60000 (78.58%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6463,                   Accuracy: 47326/60000 (78.88%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0146,                   Accuracy: 42095/60000 (70.16%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6890,                   Accuracy: 34995/60000 (58.33%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.6532,                   Accuracy: 27843/60000 (46.40%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.4239,                   Accuracy: 23719/60000 (39.53%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.8666,                   Accuracy: 22644/60000 (37.74%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8724,                   Accuracy: 23529/60000 (39.22%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.6112,                   Accuracy: 25966/60000 (43.28%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.4976,                   Accuracy: 27583/60000 (45.97%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.3038,                   Accuracy: 28553/60000 (47.59%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.3357,                   Accuracy: 27659/60000 (46.10%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.3842,                   Accuracy: 25737/60000 (42.90%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4931,                   Accuracy: 23361/60000 (38.94%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.3868,                   Accuracy: 22371/60000 (37.28%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9072,                   Accuracy: 24968/60000 (41.61%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0261,                   Accuracy: 32302/60000 (53.84%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1826,                   Accuracy: 40734/60000 (67.89%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6408,                   Accuracy: 47507/60000 (79.18%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4117,                   Accuracy: 51689/60000 (86.15%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5582,                   Accuracy: 48760/60000 (81.27%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8123,                   Accuracy: 44833/60000 (74.72%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2063,                   Accuracy: 39855/60000 (66.43%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4287,                   Accuracy: 37554/60000 (62.59%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3045,                   Accuracy: 40125/60000 (66.88%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7791,                   Accuracy: 47844/60000 (79.74%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2768,                   Accuracy: 55243/60000 (92.07%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0820,                   Accuracy: 58473/60000 (97.46%)
{0: tensor(98.5950), 10: tensor(97.7783), 20: tensor(94.7033), 30: tensor(86.0467), 40: tensor(72.7783), 50: tensor(63.7200), 60: tensor(64.8350), 70: tensor(72.4583), 80: tensor(78.5850), 90: tensor(78.8767), 100: tensor(70.1583), 110: tensor(58.3250), 120: tensor(46.4050), 130: tensor(39.5317), 140: tensor(37.7400), 150: tensor(39.2150), 160: tensor(43.2767), 170: tensor(45.9717), 180: tensor(47.5883), 190: tensor(46.0983), 200: tensor(42.8950), 210: tensor(38.9350), 220: tensor(37.2850), 230: tensor(41.6133), 240: tensor(53.8367), 250: tensor(67.8900), 260: tensor(79.1783), 270: tensor(86.1483), 280: tensor(81.2667), 290: tensor(74.7217), 300: tensor(66.4250), 310: tensor(62.5900), 320: tensor(66.8750), 330: tensor(79.7400), 340: tensor(92.0717), 350: tensor(97.4550)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=93, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.3593,                   Accuracy: 184/2000.0 (9.20%)



-= Testing valid =-
Test set: Average loss: 1.7453,                   Accuracy: 698/2000.0 (34.90%)



-= Testing valid =-
Test set: Average loss: 0.7796,                   Accuracy: 1455/2000.0 (72.75%)



-= Testing valid =-
Test set: Average loss: 0.5502,                   Accuracy: 1555/2000.0 (77.75%)



-= Testing valid =-
Test set: Average loss: 0.2954,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 10 train accuracy: 98.07%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0720,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 20 train accuracy: 99.30%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.1289,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 30 train accuracy: 99.51%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.74%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 50 train accuracy: 99.76%, valid accuracy 99.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0492,                   Accuracy: 59171/60000 (98.62%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0773,                   Accuracy: 58707/60000 (97.85%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1775,                   Accuracy: 56940/60000 (94.90%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4310,                   Accuracy: 52783/60000 (87.97%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7886,                   Accuracy: 47152/60000 (78.59%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9560,                   Accuracy: 44194/60000 (73.66%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8306,                   Accuracy: 46134/60000 (76.89%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.5979,                   Accuracy: 49767/60000 (82.94%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4744,                   Accuracy: 51382/60000 (85.64%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4429,                   Accuracy: 51505/60000 (85.84%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7656,                   Accuracy: 45762/60000 (76.27%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3513,                   Accuracy: 37308/60000 (62.18%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2362,                   Accuracy: 29061/60000 (48.44%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.1504,                   Accuracy: 23791/60000 (39.65%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.6603,                   Accuracy: 22538/60000 (37.56%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8372,                   Accuracy: 23826/60000 (39.71%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.7826,                   Accuracy: 25896/60000 (43.16%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.7983,                   Accuracy: 27360/60000 (45.60%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.9367,                   Accuracy: 27481/60000 (45.80%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.2432,                   Accuracy: 27163/60000 (45.27%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.5336,                   Accuracy: 25262/60000 (42.10%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.7719,                   Accuracy: 23348/60000 (38.91%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.5771,                   Accuracy: 22441/60000 (37.40%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.8272,                   Accuracy: 24548/60000 (40.91%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.7107,                   Accuracy: 30722/60000 (51.20%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.5477,                   Accuracy: 39813/60000 (66.36%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7999,                   Accuracy: 47454/60000 (79.09%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3956,                   Accuracy: 53259/60000 (88.76%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4747,                   Accuracy: 51414/60000 (85.69%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.5885,                   Accuracy: 48915/60000 (81.53%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.8499,                   Accuracy: 43975/60000 (73.29%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9634,                   Accuracy: 42030/60000 (70.05%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8163,                   Accuracy: 44798/60000 (74.66%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4354,                   Accuracy: 51688/60000 (86.15%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1644,                   Accuracy: 56980/60000 (94.97%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0704,                   Accuracy: 58713/60000 (97.86%)
{0: tensor(98.6183), 10: tensor(97.8450), 20: tensor(94.9000), 30: tensor(87.9717), 40: tensor(78.5867), 50: tensor(73.6567), 60: tensor(76.8900), 70: tensor(82.9450), 80: tensor(85.6367), 90: tensor(85.8417), 100: tensor(76.2700), 110: tensor(62.1800), 120: tensor(48.4350), 130: tensor(39.6517), 140: tensor(37.5633), 150: tensor(39.7100), 160: tensor(43.1600), 170: tensor(45.6000), 180: tensor(45.8017), 190: tensor(45.2717), 200: tensor(42.1033), 210: tensor(38.9133), 220: tensor(37.4017), 230: tensor(40.9133), 240: tensor(51.2033), 250: tensor(66.3550), 260: tensor(79.0900), 270: tensor(88.7650), 280: tensor(85.6900), 290: tensor(81.5250), 300: tensor(73.2917), 310: tensor(70.0500), 320: tensor(74.6633), 330: tensor(86.1467), 340: tensor(94.9667), 350: tensor(97.8550)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=94, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5235,                   Accuracy: 422/2000.0 (21.10%)



-= Testing valid =-
Test set: Average loss: 1.4573,                   Accuracy: 966/2000.0 (48.30%)



-= Testing valid =-
Test set: Average loss: 1.5439,                   Accuracy: 981/2000.0 (49.05%)



-= Testing valid =-
Test set: Average loss: 0.5781,                   Accuracy: 1614/2000.0 (80.70%)



-= Testing valid =-
Test set: Average loss: 0.4585,                   Accuracy: 1712/2000.0 (85.60%)



-= Testing valid =-
Test set: Average loss: 0.1479,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0629,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 10 train accuracy: 98.16%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1268,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0656,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0485,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.1644,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 20 train accuracy: 98.91%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.49%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0598,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 40 train accuracy: 99.68%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 50 train accuracy: 99.76%, valid accuracy 98.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0595,                   Accuracy: 58980/60000 (98.30%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0966,                   Accuracy: 58378/60000 (97.30%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2020,                   Accuracy: 56614/60000 (94.36%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4399,                   Accuracy: 52545/60000 (87.57%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8051,                   Accuracy: 46501/60000 (77.50%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9898,                   Accuracy: 42914/60000 (71.52%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8588,                   Accuracy: 44623/60000 (74.37%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6248,                   Accuracy: 48604/60000 (81.01%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4439,                   Accuracy: 51635/60000 (86.06%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3519,                   Accuracy: 53209/60000 (88.68%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.5000,                   Accuracy: 50221/60000 (83.70%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.8752,                   Accuracy: 42705/60000 (71.18%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.5495,                   Accuracy: 32962/60000 (54.94%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.2079,                   Accuracy: 27078/60000 (45.13%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.6952,                   Accuracy: 24508/60000 (40.85%)
-= Testing Rotation 150 =-
Test set: Average loss: 2.7861,                   Accuracy: 26586/60000 (44.31%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.6803,                   Accuracy: 29726/60000 (49.54%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.7149,                   Accuracy: 32027/60000 (53.38%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.6405,                   Accuracy: 33269/60000 (55.45%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.7474,                   Accuracy: 32791/60000 (54.65%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.8660,                   Accuracy: 30938/60000 (51.56%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.8590,                   Accuracy: 27725/60000 (46.21%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.7461,                   Accuracy: 26204/60000 (43.67%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.3068,                   Accuracy: 28133/60000 (46.89%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.6203,                   Accuracy: 34732/60000 (57.89%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0190,                   Accuracy: 42720/60000 (71.20%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5793,                   Accuracy: 49052/60000 (81.75%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3306,                   Accuracy: 53741/60000 (89.57%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4398,                   Accuracy: 51658/60000 (86.10%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6137,                   Accuracy: 48558/60000 (80.93%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9239,                   Accuracy: 42424/60000 (70.71%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1594,                   Accuracy: 38741/60000 (64.57%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1974,                   Accuracy: 39694/60000 (66.16%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7246,                   Accuracy: 47467/60000 (79.11%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2761,                   Accuracy: 54849/60000 (91.42%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1049,                   Accuracy: 58064/60000 (96.77%)
{0: tensor(98.3000), 10: tensor(97.2967), 20: tensor(94.3567), 30: tensor(87.5750), 40: tensor(77.5017), 50: tensor(71.5233), 60: tensor(74.3717), 70: tensor(81.0067), 80: tensor(86.0583), 90: tensor(88.6817), 100: tensor(83.7017), 110: tensor(71.1750), 120: tensor(54.9367), 130: tensor(45.1300), 140: tensor(40.8467), 150: tensor(44.3100), 160: tensor(49.5433), 170: tensor(53.3783), 180: tensor(55.4483), 190: tensor(54.6517), 200: tensor(51.5633), 210: tensor(46.2083), 220: tensor(43.6733), 230: tensor(46.8883), 240: tensor(57.8867), 250: tensor(71.2000), 260: tensor(81.7533), 270: tensor(89.5683), 280: tensor(86.0967), 290: tensor(80.9300), 300: tensor(70.7067), 310: tensor(64.5683), 320: tensor(66.1567), 330: tensor(79.1117), 340: tensor(91.4150), 350: tensor(96.7733)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=95, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0162,                   Accuracy: 497/2000.0 (24.85%)



-= Testing valid =-
Test set: Average loss: 1.1746,                   Accuracy: 1257/2000.0 (62.85%)



-= Testing valid =-
Test set: Average loss: 0.5098,                   Accuracy: 1737/2000.0 (86.85%)



-= Testing valid =-
Test set: Average loss: 0.1520,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1867,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1380,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1212,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1263,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1381,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1276,                   Accuracy: 1920/2000.0 (96.00%)



Epoch 10 train accuracy: 97.96%, valid accuracy 96.00%
-= Testing valid =-
Test set: Average loss: 0.0686,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0472,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 20 train accuracy: 99.15%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 30 train accuracy: 99.45%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 40 train accuracy: 99.72%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 50 train accuracy: 99.61%, valid accuracy 99.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0491,                   Accuracy: 59127/60000 (98.54%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0786,                   Accuracy: 58589/60000 (97.65%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1619,                   Accuracy: 57231/60000 (95.39%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3788,                   Accuracy: 53482/60000 (89.14%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7013,                   Accuracy: 47609/60000 (79.35%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9255,                   Accuracy: 43309/60000 (72.18%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9533,                   Accuracy: 41963/60000 (69.94%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7572,                   Accuracy: 44953/60000 (74.92%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5743,                   Accuracy: 48101/60000 (80.17%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5626,                   Accuracy: 48599/60000 (81.00%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8141,                   Accuracy: 45050/60000 (75.08%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2292,                   Accuracy: 40103/60000 (66.84%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0163,                   Accuracy: 31784/60000 (52.97%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8792,                   Accuracy: 26675/60000 (44.46%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.5727,                   Accuracy: 24695/60000 (41.16%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.9883,                   Accuracy: 25175/60000 (41.96%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.0213,                   Accuracy: 27059/60000 (45.10%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.0221,                   Accuracy: 28847/60000 (48.08%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.9327,                   Accuracy: 29852/60000 (49.75%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.9142,                   Accuracy: 29180/60000 (48.63%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.9258,                   Accuracy: 27500/60000 (45.83%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9502,                   Accuracy: 25584/60000 (42.64%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6760,                   Accuracy: 24435/60000 (40.72%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1239,                   Accuracy: 25706/60000 (42.84%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3793,                   Accuracy: 30087/60000 (50.15%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.5764,                   Accuracy: 36413/60000 (60.69%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8987,                   Accuracy: 43763/60000 (72.94%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6573,                   Accuracy: 47296/60000 (78.83%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.8076,                   Accuracy: 45097/60000 (75.16%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9420,                   Accuracy: 42042/60000 (70.07%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1151,                   Accuracy: 38661/60000 (64.43%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1200,                   Accuracy: 38491/60000 (64.15%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9204,                   Accuracy: 42356/60000 (70.59%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5011,                   Accuracy: 50284/60000 (83.81%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1867,                   Accuracy: 56463/60000 (94.11%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0733,                   Accuracy: 58667/60000 (97.78%)
{0: tensor(98.5450), 10: tensor(97.6483), 20: tensor(95.3850), 30: tensor(89.1367), 40: tensor(79.3483), 50: tensor(72.1817), 60: tensor(69.9383), 70: tensor(74.9217), 80: tensor(80.1683), 90: tensor(80.9983), 100: tensor(75.0833), 110: tensor(66.8383), 120: tensor(52.9733), 130: tensor(44.4583), 140: tensor(41.1583), 150: tensor(41.9583), 160: tensor(45.0983), 170: tensor(48.0783), 180: tensor(49.7533), 190: tensor(48.6333), 200: tensor(45.8333), 210: tensor(42.6400), 220: tensor(40.7250), 230: tensor(42.8433), 240: tensor(50.1450), 250: tensor(60.6883), 260: tensor(72.9383), 270: tensor(78.8267), 280: tensor(75.1617), 290: tensor(70.0700), 300: tensor(64.4350), 310: tensor(64.1517), 320: tensor(70.5933), 330: tensor(83.8067), 340: tensor(94.1050), 350: tensor(97.7783)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=96, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.5616,                   Accuracy: 243/2000.0 (12.15%)



-= Testing valid =-
Test set: Average loss: 4.8270,                   Accuracy: 257/2000.0 (12.85%)



-= Testing valid =-
Test set: Average loss: 1.4442,                   Accuracy: 1055/2000.0 (52.75%)



-= Testing valid =-
Test set: Average loss: 0.2553,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.2522,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1671,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1513,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 10 train accuracy: 97.91%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0596,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 20 train accuracy: 99.07%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.47%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 40 train accuracy: 99.61%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 50 train accuracy: 99.61%, valid accuracy 98.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0629,                   Accuracy: 58928/60000 (98.21%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0975,                   Accuracy: 58318/60000 (97.20%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2037,                   Accuracy: 56491/60000 (94.15%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4560,                   Accuracy: 52229/60000 (87.05%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7974,                   Accuracy: 46136/60000 (76.89%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9978,                   Accuracy: 42045/60000 (70.07%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9608,                   Accuracy: 42692/60000 (71.15%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7411,                   Accuracy: 46221/60000 (77.04%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5584,                   Accuracy: 49596/60000 (82.66%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5432,                   Accuracy: 49568/60000 (82.61%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8010,                   Accuracy: 44785/60000 (74.64%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2641,                   Accuracy: 38143/60000 (63.57%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.7737,                   Accuracy: 32746/60000 (54.58%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.2993,                   Accuracy: 27547/60000 (45.91%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.7316,                   Accuracy: 25393/60000 (42.32%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.0385,                   Accuracy: 26373/60000 (43.96%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.1800,                   Accuracy: 29242/60000 (48.74%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.3743,                   Accuracy: 30303/60000 (50.51%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.3759,                   Accuracy: 29687/60000 (49.48%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.7588,                   Accuracy: 28321/60000 (47.20%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7818,                   Accuracy: 26376/60000 (43.96%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7519,                   Accuracy: 24017/60000 (40.03%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.4140,                   Accuracy: 23979/60000 (39.97%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7802,                   Accuracy: 26976/60000 (44.96%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0010,                   Accuracy: 32282/60000 (53.80%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3188,                   Accuracy: 37981/60000 (63.30%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9041,                   Accuracy: 42579/60000 (70.96%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7076,                   Accuracy: 46141/60000 (76.90%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.9108,                   Accuracy: 42792/60000 (71.32%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0665,                   Accuracy: 40423/60000 (67.37%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3036,                   Accuracy: 36974/60000 (61.62%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3040,                   Accuracy: 37018/60000 (61.70%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0417,                   Accuracy: 41840/60000 (69.73%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5975,                   Accuracy: 49465/60000 (82.44%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2177,                   Accuracy: 56030/60000 (93.38%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0897,                   Accuracy: 58431/60000 (97.39%)
{0: tensor(98.2133), 10: tensor(97.1967), 20: tensor(94.1517), 30: tensor(87.0483), 40: tensor(76.8933), 50: tensor(70.0750), 60: tensor(71.1533), 70: tensor(77.0350), 80: tensor(82.6600), 90: tensor(82.6133), 100: tensor(74.6417), 110: tensor(63.5717), 120: tensor(54.5767), 130: tensor(45.9117), 140: tensor(42.3217), 150: tensor(43.9550), 160: tensor(48.7367), 170: tensor(50.5050), 180: tensor(49.4783), 190: tensor(47.2017), 200: tensor(43.9600), 210: tensor(40.0283), 220: tensor(39.9650), 230: tensor(44.9600), 240: tensor(53.8033), 250: tensor(63.3017), 260: tensor(70.9650), 270: tensor(76.9017), 280: tensor(71.3200), 290: tensor(67.3717), 300: tensor(61.6233), 310: tensor(61.6967), 320: tensor(69.7333), 330: tensor(82.4417), 340: tensor(93.3833), 350: tensor(97.3850)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=97, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.4466,                   Accuracy: 239/2000.0 (11.95%)



-= Testing valid =-
Test set: Average loss: 1.7855,                   Accuracy: 577/2000.0 (28.85%)



-= Testing valid =-
Test set: Average loss: 0.7312,                   Accuracy: 1472/2000.0 (73.60%)



-= Testing valid =-
Test set: Average loss: 0.2627,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.1849,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2037,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.2329,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.1030,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.3049,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.2446,                   Accuracy: 1822/2000.0 (91.10%)



Epoch 10 train accuracy: 97.49%, valid accuracy 91.10%
-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0600,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 20 train accuracy: 98.85%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0453,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.47%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 40 train accuracy: 99.56%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.59%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0573,                   Accuracy: 59043/60000 (98.40%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1065,                   Accuracy: 58230/60000 (97.05%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2147,                   Accuracy: 56429/60000 (94.05%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4375,                   Accuracy: 53043/60000 (88.40%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7590,                   Accuracy: 47983/60000 (79.97%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9432,                   Accuracy: 44491/60000 (74.15%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8924,                   Accuracy: 44447/60000 (74.08%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7656,                   Accuracy: 45928/60000 (76.55%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7118,                   Accuracy: 46463/60000 (77.44%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6568,                   Accuracy: 47583/60000 (79.31%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0445,                   Accuracy: 41709/60000 (69.51%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6028,                   Accuracy: 35171/60000 (58.62%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.1741,                   Accuracy: 29487/60000 (49.15%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8203,                   Accuracy: 25426/60000 (42.38%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.2237,                   Accuracy: 24519/60000 (40.87%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.3536,                   Accuracy: 26257/60000 (43.76%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4002,                   Accuracy: 28897/60000 (48.16%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5057,                   Accuracy: 30191/60000 (50.32%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.2887,                   Accuracy: 31321/60000 (52.20%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.5368,                   Accuracy: 30155/60000 (50.26%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.5493,                   Accuracy: 28926/60000 (48.21%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4810,                   Accuracy: 26751/60000 (44.58%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.2958,                   Accuracy: 26106/60000 (43.51%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7122,                   Accuracy: 28705/60000 (47.84%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.8314,                   Accuracy: 35117/60000 (58.53%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0973,                   Accuracy: 42207/60000 (70.35%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6230,                   Accuracy: 48382/60000 (80.64%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3665,                   Accuracy: 53034/60000 (88.39%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5206,                   Accuracy: 50113/60000 (83.52%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7755,                   Accuracy: 45677/60000 (76.13%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0573,                   Accuracy: 42161/60000 (70.27%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2246,                   Accuracy: 40285/60000 (67.14%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0700,                   Accuracy: 43418/60000 (72.36%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6075,                   Accuracy: 50023/60000 (83.37%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2403,                   Accuracy: 55690/60000 (92.82%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1099,                   Accuracy: 58053/60000 (96.75%)
{0: tensor(98.4050), 10: tensor(97.0500), 20: tensor(94.0483), 30: tensor(88.4050), 40: tensor(79.9717), 50: tensor(74.1517), 60: tensor(74.0783), 70: tensor(76.5467), 80: tensor(77.4383), 90: tensor(79.3050), 100: tensor(69.5150), 110: tensor(58.6183), 120: tensor(49.1450), 130: tensor(42.3767), 140: tensor(40.8650), 150: tensor(43.7617), 160: tensor(48.1617), 170: tensor(50.3183), 180: tensor(52.2017), 190: tensor(50.2583), 200: tensor(48.2100), 210: tensor(44.5850), 220: tensor(43.5100), 230: tensor(47.8417), 240: tensor(58.5283), 250: tensor(70.3450), 260: tensor(80.6367), 270: tensor(88.3900), 280: tensor(83.5217), 290: tensor(76.1283), 300: tensor(70.2683), 310: tensor(67.1417), 320: tensor(72.3633), 330: tensor(83.3717), 340: tensor(92.8167), 350: tensor(96.7550)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=98, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.7035,                   Accuracy: 211/2000.0 (10.55%)



-= Testing valid =-
Test set: Average loss: 2.4482,                   Accuracy: 490/2000.0 (24.50%)



-= Testing valid =-
Test set: Average loss: 1.9075,                   Accuracy: 662/2000.0 (33.10%)



-= Testing valid =-
Test set: Average loss: 1.4431,                   Accuracy: 1055/2000.0 (52.75%)



-= Testing valid =-
Test set: Average loss: 0.1661,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1169,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1591,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1565,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 10 train accuracy: 97.99%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.0555,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0756,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0710,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 20 train accuracy: 98.99%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.41%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 40 train accuracy: 99.56%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 50 train accuracy: 99.50%, valid accuracy 98.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0568,                   Accuracy: 59011/60000 (98.35%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0918,                   Accuracy: 58433/60000 (97.39%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1995,                   Accuracy: 56451/60000 (94.08%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4880,                   Accuracy: 51357/60000 (85.60%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9183,                   Accuracy: 43935/60000 (73.22%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2460,                   Accuracy: 37929/60000 (63.22%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2630,                   Accuracy: 36291/60000 (60.49%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.0780,                   Accuracy: 37847/60000 (63.08%)
-= Testing Rotation 80 =-
Test set: Average loss: 1.0902,                   Accuracy: 37122/60000 (61.87%)
-= Testing Rotation 90 =-
Test set: Average loss: 1.1176,                   Accuracy: 37253/60000 (62.09%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.4906,                   Accuracy: 31874/60000 (53.12%)
-= Testing Rotation 110 =-
Test set: Average loss: 2.1149,                   Accuracy: 25732/60000 (42.89%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.8721,                   Accuracy: 21681/60000 (36.13%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.3704,                   Accuracy: 20854/60000 (34.76%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.6231,                   Accuracy: 22106/60000 (36.84%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.6857,                   Accuracy: 24956/60000 (41.59%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.6863,                   Accuracy: 28451/60000 (47.42%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.9090,                   Accuracy: 29605/60000 (49.34%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.9091,                   Accuracy: 29492/60000 (49.15%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.9119,                   Accuracy: 28918/60000 (48.20%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.9674,                   Accuracy: 26827/60000 (44.71%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9922,                   Accuracy: 24414/60000 (40.69%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6174,                   Accuracy: 24722/60000 (41.20%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8743,                   Accuracy: 27993/60000 (46.65%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9021,                   Accuracy: 34704/60000 (57.84%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0381,                   Accuracy: 43695/60000 (72.82%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6360,                   Accuracy: 49117/60000 (81.86%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4814,                   Accuracy: 51117/60000 (85.19%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7050,                   Accuracy: 46807/60000 (78.01%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0525,                   Accuracy: 41358/60000 (68.93%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.5940,                   Accuracy: 35181/60000 (58.63%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.7075,                   Accuracy: 34324/60000 (57.21%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.4428,                   Accuracy: 38730/60000 (64.55%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7607,                   Accuracy: 47685/60000 (79.47%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2374,                   Accuracy: 55675/60000 (92.79%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0883,                   Accuracy: 58418/60000 (97.36%)
{0: tensor(98.3517), 10: tensor(97.3883), 20: tensor(94.0850), 30: tensor(85.5950), 40: tensor(73.2250), 50: tensor(63.2150), 60: tensor(60.4850), 70: tensor(63.0783), 80: tensor(61.8700), 90: tensor(62.0883), 100: tensor(53.1233), 110: tensor(42.8867), 120: tensor(36.1350), 130: tensor(34.7567), 140: tensor(36.8433), 150: tensor(41.5933), 160: tensor(47.4183), 170: tensor(49.3417), 180: tensor(49.1533), 190: tensor(48.1967), 200: tensor(44.7117), 210: tensor(40.6900), 220: tensor(41.2033), 230: tensor(46.6550), 240: tensor(57.8400), 250: tensor(72.8250), 260: tensor(81.8617), 270: tensor(85.1950), 280: tensor(78.0117), 290: tensor(68.9300), 300: tensor(58.6350), 310: tensor(57.2067), 320: tensor(64.5500), 330: tensor(79.4750), 340: tensor(92.7917), 350: tensor(97.3633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=99, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.9090,                   Accuracy: 312/2000.0 (15.60%)



-= Testing valid =-
Test set: Average loss: 2.0137,                   Accuracy: 680/2000.0 (34.00%)



-= Testing valid =-
Test set: Average loss: 0.3511,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.3693,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.4310,                   Accuracy: 1723/2000.0 (86.15%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1773,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1715,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.1384,                   Accuracy: 1912/2000.0 (95.60%)



Epoch 10 train accuracy: 98.22%, valid accuracy 95.60%
-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0738,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 20 train accuracy: 99.12%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 30 train accuracy: 99.53%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 40 train accuracy: 99.59%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.70%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0507,                   Accuracy: 59167/60000 (98.61%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0848,                   Accuracy: 58593/60000 (97.65%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1711,                   Accuracy: 57054/60000 (95.09%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4006,                   Accuracy: 52750/60000 (87.92%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7032,                   Accuracy: 47212/60000 (78.69%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8366,                   Accuracy: 44629/60000 (74.38%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7258,                   Accuracy: 46140/60000 (76.90%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.5607,                   Accuracy: 48896/60000 (81.49%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5094,                   Accuracy: 50093/60000 (83.49%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5420,                   Accuracy: 50230/60000 (83.72%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8476,                   Accuracy: 46358/60000 (77.26%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3410,                   Accuracy: 40265/60000 (67.11%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0593,                   Accuracy: 32196/60000 (53.66%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.6464,                   Accuracy: 27571/60000 (45.95%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.9710,                   Accuracy: 27131/60000 (45.22%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.0059,                   Accuracy: 29713/60000 (49.52%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.8327,                   Accuracy: 33251/60000 (55.42%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.7593,                   Accuracy: 34899/60000 (58.17%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.7410,                   Accuracy: 33878/60000 (56.46%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.9345,                   Accuracy: 32226/60000 (53.71%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.2559,                   Accuracy: 29106/60000 (48.51%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4430,                   Accuracy: 26276/60000 (43.79%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.2731,                   Accuracy: 25720/60000 (42.87%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.6798,                   Accuracy: 28665/60000 (47.78%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.7844,                   Accuracy: 35754/60000 (59.59%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0219,                   Accuracy: 43779/60000 (72.96%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5993,                   Accuracy: 48977/60000 (81.63%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4147,                   Accuracy: 51969/60000 (86.61%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5201,                   Accuracy: 50010/60000 (83.35%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7135,                   Accuracy: 46724/60000 (77.87%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9581,                   Accuracy: 43074/60000 (71.79%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0374,                   Accuracy: 41886/60000 (69.81%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8813,                   Accuracy: 44613/60000 (74.36%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5142,                   Accuracy: 50729/60000 (84.55%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1902,                   Accuracy: 56436/60000 (94.06%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0724,                   Accuracy: 58678/60000 (97.80%)
{0: tensor(98.6117), 10: tensor(97.6550), 20: tensor(95.0900), 30: tensor(87.9167), 40: tensor(78.6867), 50: tensor(74.3817), 60: tensor(76.9000), 70: tensor(81.4933), 80: tensor(83.4883), 90: tensor(83.7167), 100: tensor(77.2633), 110: tensor(67.1083), 120: tensor(53.6600), 130: tensor(45.9517), 140: tensor(45.2183), 150: tensor(49.5217), 160: tensor(55.4183), 170: tensor(58.1650), 180: tensor(56.4633), 190: tensor(53.7100), 200: tensor(48.5100), 210: tensor(43.7933), 220: tensor(42.8667), 230: tensor(47.7750), 240: tensor(59.5900), 250: tensor(72.9650), 260: tensor(81.6283), 270: tensor(86.6150), 280: tensor(83.3500), 290: tensor(77.8733), 300: tensor(71.7900), 310: tensor(69.8100), 320: tensor(74.3550), 330: tensor(84.5483), 340: tensor(94.0600), 350: tensor(97.7967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=100, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4710,                   Accuracy: 333/2000.0 (16.65%)



-= Testing valid =-
Test set: Average loss: 1.8459,                   Accuracy: 672/2000.0 (33.60%)



-= Testing valid =-
Test set: Average loss: 0.3544,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.3607,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.2342,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.1296,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1840,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1152,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 10 train accuracy: 98.20%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 20 train accuracy: 99.18%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0686,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 30 train accuracy: 99.36%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 40 train accuracy: 99.49%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 50 train accuracy: 99.72%, valid accuracy 98.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0553,                   Accuracy: 59041/60000 (98.40%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0761,                   Accuracy: 58717/60000 (97.86%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1580,                   Accuracy: 57328/60000 (95.55%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4170,                   Accuracy: 53324/60000 (88.87%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7783,                   Accuracy: 47008/60000 (78.35%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0670,                   Accuracy: 41729/60000 (69.55%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0440,                   Accuracy: 41369/60000 (68.95%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7789,                   Accuracy: 45364/60000 (75.61%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6620,                   Accuracy: 47217/60000 (78.69%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6601,                   Accuracy: 47078/60000 (78.46%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9197,                   Accuracy: 42959/60000 (71.60%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.4332,                   Accuracy: 36164/60000 (60.27%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2011,                   Accuracy: 28650/60000 (47.75%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8440,                   Accuracy: 24057/60000 (40.10%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.2686,                   Accuracy: 22220/60000 (37.03%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4502,                   Accuracy: 23201/60000 (38.67%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.3319,                   Accuracy: 26645/60000 (44.41%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.1329,                   Accuracy: 29432/60000 (49.05%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.0894,                   Accuracy: 30887/60000 (51.48%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.9823,                   Accuracy: 31036/60000 (51.73%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.0418,                   Accuracy: 29669/60000 (49.45%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.1650,                   Accuracy: 27166/60000 (45.28%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.0004,                   Accuracy: 26456/60000 (44.09%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.5977,                   Accuracy: 27928/60000 (46.55%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9540,                   Accuracy: 32705/60000 (54.51%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2585,                   Accuracy: 40600/60000 (67.67%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7477,                   Accuracy: 46810/60000 (78.02%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4119,                   Accuracy: 52148/60000 (86.91%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4577,                   Accuracy: 51054/60000 (85.09%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.5788,                   Accuracy: 48684/60000 (81.14%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9173,                   Accuracy: 42836/60000 (71.39%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0624,                   Accuracy: 40761/60000 (67.93%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9773,                   Accuracy: 42999/60000 (71.67%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6284,                   Accuracy: 48993/60000 (81.65%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2434,                   Accuracy: 55441/60000 (92.40%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0969,                   Accuracy: 58277/60000 (97.13%)
{0: tensor(98.4017), 10: tensor(97.8617), 20: tensor(95.5467), 30: tensor(88.8733), 40: tensor(78.3467), 50: tensor(69.5483), 60: tensor(68.9483), 70: tensor(75.6067), 80: tensor(78.6950), 90: tensor(78.4633), 100: tensor(71.5983), 110: tensor(60.2733), 120: tensor(47.7500), 130: tensor(40.0950), 140: tensor(37.0333), 150: tensor(38.6683), 160: tensor(44.4083), 170: tensor(49.0533), 180: tensor(51.4783), 190: tensor(51.7267), 200: tensor(49.4483), 210: tensor(45.2767), 220: tensor(44.0933), 230: tensor(46.5467), 240: tensor(54.5083), 250: tensor(67.6667), 260: tensor(78.0167), 270: tensor(86.9133), 280: tensor(85.0900), 290: tensor(81.1400), 300: tensor(71.3933), 310: tensor(67.9350), 320: tensor(71.6650), 330: tensor(81.6550), 340: tensor(92.4017), 350: tensor(97.1283)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=71, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4054,                   Accuracy: 354/2000.0 (17.70%)



-= Testing valid =-
Test set: Average loss: 1.9375,                   Accuracy: 631/2000.0 (31.55%)



-= Testing valid =-
Test set: Average loss: 0.8329,                   Accuracy: 1445/2000.0 (72.25%)



-= Testing valid =-
Test set: Average loss: 0.1436,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1245,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1654,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1526,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1083,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0712,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 10 train accuracy: 98.16%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0428,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0519,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0645,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.1067,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 20 train accuracy: 99.14%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 30 train accuracy: 99.45%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 40 train accuracy: 99.59%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.71%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0496,                   Accuracy: 59183/60000 (98.64%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0677,                   Accuracy: 58843/60000 (98.07%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1409,                   Accuracy: 57545/60000 (95.91%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3774,                   Accuracy: 53557/60000 (89.26%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7832,                   Accuracy: 47321/60000 (78.87%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0825,                   Accuracy: 42057/60000 (70.10%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0786,                   Accuracy: 41118/60000 (68.53%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8258,                   Accuracy: 44696/60000 (74.49%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6115,                   Accuracy: 47732/60000 (79.55%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6737,                   Accuracy: 46556/60000 (77.59%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.1004,                   Accuracy: 41518/60000 (69.20%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.8854,                   Accuracy: 35453/60000 (59.09%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.9373,                   Accuracy: 27452/60000 (45.75%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.9819,                   Accuracy: 23481/60000 (39.13%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.7586,                   Accuracy: 22243/60000 (37.07%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.1524,                   Accuracy: 23993/60000 (39.99%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.2249,                   Accuracy: 26139/60000 (43.56%)
-= Testing Rotation 170 =-
Test set: Average loss: 5.1578,                   Accuracy: 27457/60000 (45.76%)
-= Testing Rotation 180 =-
Test set: Average loss: 5.3947,                   Accuracy: 28163/60000 (46.94%)
-= Testing Rotation 190 =-
Test set: Average loss: 5.4216,                   Accuracy: 28398/60000 (47.33%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.5164,                   Accuracy: 27115/60000 (45.19%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.5353,                   Accuracy: 24783/60000 (41.31%)
-= Testing Rotation 220 =-
Test set: Average loss: 5.2432,                   Accuracy: 22928/60000 (38.21%)
-= Testing Rotation 230 =-
Test set: Average loss: 4.5025,                   Accuracy: 23121/60000 (38.53%)
-= Testing Rotation 240 =-
Test set: Average loss: 3.3347,                   Accuracy: 26354/60000 (43.92%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.1745,                   Accuracy: 31830/60000 (53.05%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.3225,                   Accuracy: 38447/60000 (64.08%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.8815,                   Accuracy: 43600/60000 (72.67%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.8816,                   Accuracy: 42812/60000 (71.35%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0134,                   Accuracy: 40223/60000 (67.04%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3417,                   Accuracy: 35565/60000 (59.28%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4676,                   Accuracy: 34649/60000 (57.75%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2605,                   Accuracy: 38890/60000 (64.82%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7269,                   Accuracy: 47767/60000 (79.61%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2572,                   Accuracy: 55429/60000 (92.38%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0828,                   Accuracy: 58558/60000 (97.60%)
{0: tensor(98.6383), 10: tensor(98.0717), 20: tensor(95.9083), 30: tensor(89.2617), 40: tensor(78.8683), 50: tensor(70.0950), 60: tensor(68.5300), 70: tensor(74.4933), 80: tensor(79.5533), 90: tensor(77.5933), 100: tensor(69.1967), 110: tensor(59.0883), 120: tensor(45.7533), 130: tensor(39.1350), 140: tensor(37.0717), 150: tensor(39.9883), 160: tensor(43.5650), 170: tensor(45.7617), 180: tensor(46.9383), 190: tensor(47.3300), 200: tensor(45.1917), 210: tensor(41.3050), 220: tensor(38.2133), 230: tensor(38.5350), 240: tensor(43.9233), 250: tensor(53.0500), 260: tensor(64.0783), 270: tensor(72.6667), 280: tensor(71.3533), 290: tensor(67.0383), 300: tensor(59.2750), 310: tensor(57.7483), 320: tensor(64.8167), 330: tensor(79.6117), 340: tensor(92.3817), 350: tensor(97.5967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=72, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8105,                   Accuracy: 592/2000.0 (29.60%)



-= Testing valid =-
Test set: Average loss: 0.9870,                   Accuracy: 1294/2000.0 (64.70%)



-= Testing valid =-
Test set: Average loss: 1.2086,                   Accuracy: 1158/2000.0 (57.90%)



-= Testing valid =-
Test set: Average loss: 0.2549,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.1821,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1673,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1330,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1230,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.2588,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.2301,                   Accuracy: 1895/2000.0 (94.75%)



Epoch 10 train accuracy: 98.34%, valid accuracy 94.75%
-= Testing valid =-
Test set: Average loss: 0.1171,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.2104,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 20 train accuracy: 99.12%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0559,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 30 train accuracy: 99.50%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 40 train accuracy: 99.57%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.81%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0589,                   Accuracy: 58969/60000 (98.28%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0908,                   Accuracy: 58428/60000 (97.38%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1887,                   Accuracy: 56787/60000 (94.64%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4700,                   Accuracy: 52045/60000 (86.74%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8337,                   Accuracy: 45962/60000 (76.60%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0045,                   Accuracy: 43101/60000 (71.83%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8784,                   Accuracy: 44746/60000 (74.58%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.5741,                   Accuracy: 49548/60000 (82.58%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3652,                   Accuracy: 53091/60000 (88.49%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3377,                   Accuracy: 53305/60000 (88.84%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.5233,                   Accuracy: 49685/60000 (82.81%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.8731,                   Accuracy: 43742/60000 (72.90%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.5091,                   Accuracy: 35496/60000 (59.16%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.1407,                   Accuracy: 28400/60000 (47.33%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.4135,                   Accuracy: 26622/60000 (44.37%)
-= Testing Rotation 150 =-
Test set: Average loss: 2.4138,                   Accuracy: 27688/60000 (46.15%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.1998,                   Accuracy: 31221/60000 (52.03%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.0206,                   Accuracy: 34135/60000 (56.89%)
-= Testing Rotation 180 =-
Test set: Average loss: 1.9508,                   Accuracy: 35549/60000 (59.25%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.1443,                   Accuracy: 32821/60000 (54.70%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.3204,                   Accuracy: 29672/60000 (49.45%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.6334,                   Accuracy: 26126/60000 (43.54%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.6844,                   Accuracy: 24832/60000 (41.39%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.2919,                   Accuracy: 27541/60000 (45.90%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.6117,                   Accuracy: 34299/60000 (57.17%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.9948,                   Accuracy: 41522/60000 (69.20%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6207,                   Accuracy: 47664/60000 (79.44%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4146,                   Accuracy: 51566/60000 (85.94%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5210,                   Accuracy: 49497/60000 (82.50%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7425,                   Accuracy: 45718/60000 (76.20%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9935,                   Accuracy: 42727/60000 (71.21%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0874,                   Accuracy: 41723/60000 (69.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9126,                   Accuracy: 44697/60000 (74.50%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5474,                   Accuracy: 50396/60000 (83.99%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2118,                   Accuracy: 56075/60000 (93.46%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0794,                   Accuracy: 58554/60000 (97.59%)
{0: tensor(98.2817), 10: tensor(97.3800), 20: tensor(94.6450), 30: tensor(86.7417), 40: tensor(76.6033), 50: tensor(71.8350), 60: tensor(74.5767), 70: tensor(82.5800), 80: tensor(88.4850), 90: tensor(88.8417), 100: tensor(82.8083), 110: tensor(72.9033), 120: tensor(59.1600), 130: tensor(47.3333), 140: tensor(44.3700), 150: tensor(46.1467), 160: tensor(52.0350), 170: tensor(56.8917), 180: tensor(59.2483), 190: tensor(54.7017), 200: tensor(49.4533), 210: tensor(43.5433), 220: tensor(41.3867), 230: tensor(45.9017), 240: tensor(57.1650), 250: tensor(69.2033), 260: tensor(79.4400), 270: tensor(85.9433), 280: tensor(82.4950), 290: tensor(76.1967), 300: tensor(71.2117), 310: tensor(69.5383), 320: tensor(74.4950), 330: tensor(83.9933), 340: tensor(93.4583), 350: tensor(97.5900)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=73, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9010,                   Accuracy: 490/2000.0 (24.50%)



-= Testing valid =-
Test set: Average loss: 1.8919,                   Accuracy: 717/2000.0 (35.85%)



-= Testing valid =-
Test set: Average loss: 0.5277,                   Accuracy: 1712/2000.0 (85.60%)



-= Testing valid =-
Test set: Average loss: 0.3589,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.1687,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.1053,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 10 train accuracy: 98.38%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0625,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.1368,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 20 train accuracy: 99.12%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 30 train accuracy: 99.50%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 40 train accuracy: 99.62%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.69%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0482,                   Accuracy: 59185/60000 (98.64%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0762,                   Accuracy: 58716/60000 (97.86%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1584,                   Accuracy: 57317/60000 (95.53%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4057,                   Accuracy: 52967/60000 (88.28%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7649,                   Accuracy: 46973/60000 (78.29%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0097,                   Accuracy: 42843/60000 (71.40%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8996,                   Accuracy: 44244/60000 (73.74%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6273,                   Accuracy: 48193/60000 (80.32%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4584,                   Accuracy: 50388/60000 (83.98%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4851,                   Accuracy: 48823/60000 (81.37%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7583,                   Accuracy: 44077/60000 (73.46%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2723,                   Accuracy: 38010/60000 (63.35%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.1545,                   Accuracy: 30090/60000 (50.15%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.9471,                   Accuracy: 25979/60000 (43.30%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3687,                   Accuracy: 24872/60000 (41.45%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4718,                   Accuracy: 25940/60000 (43.23%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4017,                   Accuracy: 28369/60000 (47.28%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.4356,                   Accuracy: 29967/60000 (49.94%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.5557,                   Accuracy: 30372/60000 (50.62%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.6192,                   Accuracy: 30247/60000 (50.41%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7775,                   Accuracy: 28444/60000 (47.41%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9748,                   Accuracy: 24972/60000 (41.62%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.8472,                   Accuracy: 23578/60000 (39.30%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2428,                   Accuracy: 26012/60000 (43.35%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2048,                   Accuracy: 33026/60000 (55.04%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2263,                   Accuracy: 41448/60000 (69.08%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5842,                   Accuracy: 49341/60000 (82.24%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3191,                   Accuracy: 53961/60000 (89.93%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4126,                   Accuracy: 52089/60000 (86.82%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6051,                   Accuracy: 48739/60000 (81.23%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9911,                   Accuracy: 42687/60000 (71.14%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2336,                   Accuracy: 39170/60000 (65.28%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1131,                   Accuracy: 40786/60000 (67.98%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6269,                   Accuracy: 48498/60000 (80.83%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2161,                   Accuracy: 55833/60000 (93.06%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0758,                   Accuracy: 58641/60000 (97.74%)
{0: tensor(98.6417), 10: tensor(97.8600), 20: tensor(95.5283), 30: tensor(88.2783), 40: tensor(78.2883), 50: tensor(71.4050), 60: tensor(73.7400), 70: tensor(80.3217), 80: tensor(83.9800), 90: tensor(81.3717), 100: tensor(73.4617), 110: tensor(63.3500), 120: tensor(50.1500), 130: tensor(43.2983), 140: tensor(41.4533), 150: tensor(43.2333), 160: tensor(47.2817), 170: tensor(49.9450), 180: tensor(50.6200), 190: tensor(50.4117), 200: tensor(47.4067), 210: tensor(41.6200), 220: tensor(39.2967), 230: tensor(43.3533), 240: tensor(55.0433), 250: tensor(69.0800), 260: tensor(82.2350), 270: tensor(89.9350), 280: tensor(86.8150), 290: tensor(81.2317), 300: tensor(71.1450), 310: tensor(65.2833), 320: tensor(67.9767), 330: tensor(80.8300), 340: tensor(93.0550), 350: tensor(97.7350)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=74, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.7723,                   Accuracy: 282/2000.0 (14.10%)



-= Testing valid =-
Test set: Average loss: 1.6729,                   Accuracy: 746/2000.0 (37.30%)



-= Testing valid =-
Test set: Average loss: 0.6960,                   Accuracy: 1639/2000.0 (81.95%)



-= Testing valid =-
Test set: Average loss: 1.1164,                   Accuracy: 1293/2000.0 (64.65%)



-= Testing valid =-
Test set: Average loss: 0.9330,                   Accuracy: 1458/2000.0 (72.90%)



-= Testing valid =-
Test set: Average loss: 0.2240,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.2548,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.1614,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1670,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.2823,                   Accuracy: 1781/2000.0 (89.05%)



Epoch 10 train accuracy: 98.19%, valid accuracy 89.05%
-= Testing valid =-
Test set: Average loss: 0.1383,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1384,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1255,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1217,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 20 train accuracy: 99.14%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.1484,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.1286,                   Accuracy: 1899/2000.0 (94.95%)



Epoch 30 train accuracy: 99.30%, valid accuracy 94.95%
-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0617,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 40 train accuracy: 99.66%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0641,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0707,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0646,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0746,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0746,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 50 train accuracy: 99.79%, valid accuracy 97.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0691,                   Accuracy: 58794/60000 (97.99%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0900,                   Accuracy: 58437/60000 (97.39%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1994,                   Accuracy: 56549/60000 (94.25%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4992,                   Accuracy: 50835/60000 (84.72%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9419,                   Accuracy: 42850/60000 (71.42%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2397,                   Accuracy: 37522/60000 (62.54%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.3038,                   Accuracy: 35545/60000 (59.24%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.0510,                   Accuracy: 40013/60000 (66.69%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.9626,                   Accuracy: 42537/60000 (70.89%)
-= Testing Rotation 90 =-
Test set: Average loss: 1.1354,                   Accuracy: 41781/60000 (69.64%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.3459,                   Accuracy: 39752/60000 (66.25%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.9478,                   Accuracy: 31909/60000 (53.18%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.7009,                   Accuracy: 25128/60000 (41.88%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.2468,                   Accuracy: 22386/60000 (37.31%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.5306,                   Accuracy: 22341/60000 (37.24%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.6508,                   Accuracy: 23743/60000 (39.57%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.6587,                   Accuracy: 27605/60000 (46.01%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.7113,                   Accuracy: 28916/60000 (48.19%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.6493,                   Accuracy: 29025/60000 (48.38%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.7539,                   Accuracy: 28966/60000 (48.28%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.8625,                   Accuracy: 27078/60000 (45.13%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.0258,                   Accuracy: 23771/60000 (39.62%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.8709,                   Accuracy: 23236/60000 (38.73%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2008,                   Accuracy: 25291/60000 (42.15%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3610,                   Accuracy: 29347/60000 (48.91%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.4152,                   Accuracy: 38196/60000 (63.66%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7923,                   Accuracy: 45570/60000 (75.95%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5908,                   Accuracy: 48359/60000 (80.60%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5806,                   Accuracy: 48561/60000 (80.93%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7416,                   Accuracy: 45314/60000 (75.52%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0863,                   Accuracy: 38839/60000 (64.73%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1285,                   Accuracy: 37955/60000 (63.26%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9978,                   Accuracy: 41315/60000 (68.86%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6269,                   Accuracy: 48303/60000 (80.50%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2122,                   Accuracy: 55999/60000 (93.33%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0819,                   Accuracy: 58497/60000 (97.50%)
{0: tensor(97.9900), 10: tensor(97.3950), 20: tensor(94.2483), 30: tensor(84.7250), 40: tensor(71.4167), 50: tensor(62.5367), 60: tensor(59.2417), 70: tensor(66.6883), 80: tensor(70.8950), 90: tensor(69.6350), 100: tensor(66.2533), 110: tensor(53.1817), 120: tensor(41.8800), 130: tensor(37.3100), 140: tensor(37.2350), 150: tensor(39.5717), 160: tensor(46.0083), 170: tensor(48.1933), 180: tensor(48.3750), 190: tensor(48.2767), 200: tensor(45.1300), 210: tensor(39.6183), 220: tensor(38.7267), 230: tensor(42.1517), 240: tensor(48.9117), 250: tensor(63.6600), 260: tensor(75.9500), 270: tensor(80.5983), 280: tensor(80.9350), 290: tensor(75.5233), 300: tensor(64.7317), 310: tensor(63.2583), 320: tensor(68.8583), 330: tensor(80.5050), 340: tensor(93.3317), 350: tensor(97.4950)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=75, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 17.2286,                   Accuracy: 215/2000.0 (10.75%)



-= Testing valid =-
Test set: Average loss: 2.4266,                   Accuracy: 530/2000.0 (26.50%)



-= Testing valid =-
Test set: Average loss: 1.1598,                   Accuracy: 1220/2000.0 (61.00%)



-= Testing valid =-
Test set: Average loss: 1.8431,                   Accuracy: 957/2000.0 (47.85%)



-= Testing valid =-
Test set: Average loss: 0.2302,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.2493,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.1363,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1086,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.2115,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 10 train accuracy: 97.30%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.0619,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0593,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0721,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 20 train accuracy: 98.99%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.40%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 40 train accuracy: 99.56%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 50 train accuracy: 99.70%, valid accuracy 98.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0461,                   Accuracy: 59174/60000 (98.62%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0782,                   Accuracy: 58621/60000 (97.70%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1730,                   Accuracy: 57004/60000 (95.01%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4837,                   Accuracy: 51848/60000 (86.41%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9053,                   Accuracy: 45071/60000 (75.12%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1429,                   Accuracy: 40541/60000 (67.57%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9817,                   Accuracy: 42257/60000 (70.43%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6889,                   Accuracy: 46573/60000 (77.62%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5430,                   Accuracy: 48782/60000 (81.30%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5302,                   Accuracy: 49114/60000 (81.86%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8391,                   Accuracy: 44974/60000 (74.96%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.4218,                   Accuracy: 37781/60000 (62.97%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2812,                   Accuracy: 29174/60000 (48.62%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.0913,                   Accuracy: 24707/60000 (41.18%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.4957,                   Accuracy: 23610/60000 (39.35%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.5319,                   Accuracy: 25839/60000 (43.06%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.3944,                   Accuracy: 29068/60000 (48.45%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.2161,                   Accuracy: 31012/60000 (51.69%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.1430,                   Accuracy: 31707/60000 (52.85%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.1468,                   Accuracy: 30556/60000 (50.93%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.2500,                   Accuracy: 28490/60000 (47.48%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4187,                   Accuracy: 25352/60000 (42.25%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.2352,                   Accuracy: 24692/60000 (41.15%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7475,                   Accuracy: 28131/60000 (46.88%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9180,                   Accuracy: 35370/60000 (58.95%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0654,                   Accuracy: 44411/60000 (74.02%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5293,                   Accuracy: 51391/60000 (85.65%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3173,                   Accuracy: 54350/60000 (90.58%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4031,                   Accuracy: 52617/60000 (87.69%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.5676,                   Accuracy: 49199/60000 (82.00%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9099,                   Accuracy: 42799/60000 (71.33%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0498,                   Accuracy: 40290/60000 (67.15%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8867,                   Accuracy: 43347/60000 (72.25%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4826,                   Accuracy: 50821/60000 (84.70%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1858,                   Accuracy: 56515/60000 (94.19%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0734,                   Accuracy: 58664/60000 (97.77%)
{0: tensor(98.6233), 10: tensor(97.7017), 20: tensor(95.0067), 30: tensor(86.4133), 40: tensor(75.1183), 50: tensor(67.5683), 60: tensor(70.4283), 70: tensor(77.6217), 80: tensor(81.3033), 90: tensor(81.8567), 100: tensor(74.9567), 110: tensor(62.9683), 120: tensor(48.6233), 130: tensor(41.1783), 140: tensor(39.3500), 150: tensor(43.0650), 160: tensor(48.4467), 170: tensor(51.6867), 180: tensor(52.8450), 190: tensor(50.9267), 200: tensor(47.4833), 210: tensor(42.2533), 220: tensor(41.1533), 230: tensor(46.8850), 240: tensor(58.9500), 250: tensor(74.0183), 260: tensor(85.6517), 270: tensor(90.5833), 280: tensor(87.6950), 290: tensor(81.9983), 300: tensor(71.3317), 310: tensor(67.1500), 320: tensor(72.2450), 330: tensor(84.7017), 340: tensor(94.1917), 350: tensor(97.7733)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=76, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7129,                   Accuracy: 638/2000.0 (31.90%)



-= Testing valid =-
Test set: Average loss: 0.9222,                   Accuracy: 1415/2000.0 (70.75%)



-= Testing valid =-
Test set: Average loss: 1.1572,                   Accuracy: 1079/2000.0 (53.95%)



-= Testing valid =-
Test set: Average loss: 0.7462,                   Accuracy: 1509/2000.0 (75.45%)



-= Testing valid =-
Test set: Average loss: 0.2599,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.1844,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1865,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1394,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.2062,                   Accuracy: 1857/2000.0 (92.85%)



Epoch 10 train accuracy: 97.93%, valid accuracy 92.85%
-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0598,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0882,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 20 train accuracy: 98.93%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.36%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 40 train accuracy: 99.56%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 50 train accuracy: 99.70%, valid accuracy 98.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0524,                   Accuracy: 59070/60000 (98.45%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0773,                   Accuracy: 58642/60000 (97.74%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1689,                   Accuracy: 57003/60000 (95.00%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4333,                   Accuracy: 52278/60000 (87.13%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7867,                   Accuracy: 45722/60000 (76.20%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0447,                   Accuracy: 40947/60000 (68.25%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0143,                   Accuracy: 40934/60000 (68.22%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7697,                   Accuracy: 45136/60000 (75.23%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6756,                   Accuracy: 46555/60000 (77.59%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.8089,                   Accuracy: 44401/60000 (74.00%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.2506,                   Accuracy: 38659/60000 (64.43%)
-= Testing Rotation 110 =-
Test set: Average loss: 2.0244,                   Accuracy: 33130/60000 (55.22%)
-= Testing Rotation 120 =-
Test set: Average loss: 3.0136,                   Accuracy: 27207/60000 (45.35%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.7875,                   Accuracy: 24463/60000 (40.77%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.0739,                   Accuracy: 23547/60000 (39.24%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8867,                   Accuracy: 24707/60000 (41.18%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5040,                   Accuracy: 27723/60000 (46.21%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.3448,                   Accuracy: 29875/60000 (49.79%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.3696,                   Accuracy: 30600/60000 (51.00%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.3166,                   Accuracy: 30752/60000 (51.25%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.5429,                   Accuracy: 29270/60000 (48.78%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.8542,                   Accuracy: 26397/60000 (43.99%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7897,                   Accuracy: 24731/60000 (41.22%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2877,                   Accuracy: 25810/60000 (43.02%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3489,                   Accuracy: 31383/60000 (52.31%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2675,                   Accuracy: 40865/60000 (68.11%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6663,                   Accuracy: 48224/60000 (80.37%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3575,                   Accuracy: 53511/60000 (89.18%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4127,                   Accuracy: 52338/60000 (87.23%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6513,                   Accuracy: 48555/60000 (80.93%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0583,                   Accuracy: 43388/60000 (72.31%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2764,                   Accuracy: 40328/60000 (67.21%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1679,                   Accuracy: 42233/60000 (70.39%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7010,                   Accuracy: 48676/60000 (81.13%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2286,                   Accuracy: 55877/60000 (93.13%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0863,                   Accuracy: 58416/60000 (97.36%)
{0: tensor(98.4500), 10: tensor(97.7367), 20: tensor(95.0050), 30: tensor(87.1300), 40: tensor(76.2033), 50: tensor(68.2450), 60: tensor(68.2233), 70: tensor(75.2267), 80: tensor(77.5917), 90: tensor(74.0017), 100: tensor(64.4317), 110: tensor(55.2167), 120: tensor(45.3450), 130: tensor(40.7717), 140: tensor(39.2450), 150: tensor(41.1783), 160: tensor(46.2050), 170: tensor(49.7917), 180: tensor(51.), 190: tensor(51.2533), 200: tensor(48.7833), 210: tensor(43.9950), 220: tensor(41.2183), 230: tensor(43.0167), 240: tensor(52.3050), 250: tensor(68.1083), 260: tensor(80.3733), 270: tensor(89.1850), 280: tensor(87.2300), 290: tensor(80.9250), 300: tensor(72.3133), 310: tensor(67.2133), 320: tensor(70.3883), 330: tensor(81.1267), 340: tensor(93.1283), 350: tensor(97.3600)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=77, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2728,                   Accuracy: 296/2000.0 (14.80%)



-= Testing valid =-
Test set: Average loss: 1.9943,                   Accuracy: 701/2000.0 (35.05%)



-= Testing valid =-
Test set: Average loss: 1.0439,                   Accuracy: 1262/2000.0 (63.10%)



-= Testing valid =-
Test set: Average loss: 0.3213,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.4531,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.1790,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.1365,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1705,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 10 train accuracy: 98.38%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1276,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 20 train accuracy: 99.09%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.46%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 40 train accuracy: 99.78%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 50 train accuracy: 99.82%, valid accuracy 98.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0465,                   Accuracy: 59175/60000 (98.62%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0699,                   Accuracy: 58779/60000 (97.96%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1473,                   Accuracy: 57478/60000 (95.80%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3922,                   Accuracy: 53478/60000 (89.13%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8366,                   Accuracy: 46712/60000 (77.85%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1198,                   Accuracy: 42125/60000 (70.21%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9853,                   Accuracy: 43322/60000 (72.20%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7176,                   Accuracy: 46761/60000 (77.93%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5075,                   Accuracy: 49641/60000 (82.74%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4579,                   Accuracy: 50487/60000 (84.14%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7066,                   Accuracy: 46250/60000 (77.08%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1851,                   Accuracy: 40184/60000 (66.97%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0112,                   Accuracy: 31794/60000 (52.99%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8608,                   Accuracy: 25564/60000 (42.61%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3351,                   Accuracy: 23305/60000 (38.84%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.3633,                   Accuracy: 23981/60000 (39.97%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.1681,                   Accuracy: 27404/60000 (45.67%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.0766,                   Accuracy: 30337/60000 (50.56%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.0758,                   Accuracy: 31417/60000 (52.36%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.2138,                   Accuracy: 30731/60000 (51.22%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.2684,                   Accuracy: 28691/60000 (47.82%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4347,                   Accuracy: 25338/60000 (42.23%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.3445,                   Accuracy: 23345/60000 (38.91%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8285,                   Accuracy: 25051/60000 (41.75%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9738,                   Accuracy: 31901/60000 (53.17%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0712,                   Accuracy: 42207/60000 (70.35%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5659,                   Accuracy: 49378/60000 (82.30%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3550,                   Accuracy: 53339/60000 (88.90%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3976,                   Accuracy: 52379/60000 (87.30%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.5801,                   Accuracy: 48896/60000 (81.49%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0219,                   Accuracy: 41838/60000 (69.73%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3278,                   Accuracy: 37756/60000 (62.93%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3068,                   Accuracy: 39440/60000 (65.73%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7659,                   Accuracy: 47487/60000 (79.14%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2741,                   Accuracy: 55230/60000 (92.05%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0819,                   Accuracy: 58509/60000 (97.51%)
{0: tensor(98.6250), 10: tensor(97.9650), 20: tensor(95.7967), 30: tensor(89.1300), 40: tensor(77.8533), 50: tensor(70.2083), 60: tensor(72.2033), 70: tensor(77.9350), 80: tensor(82.7350), 90: tensor(84.1450), 100: tensor(77.0833), 110: tensor(66.9733), 120: tensor(52.9900), 130: tensor(42.6067), 140: tensor(38.8417), 150: tensor(39.9683), 160: tensor(45.6733), 170: tensor(50.5617), 180: tensor(52.3617), 190: tensor(51.2183), 200: tensor(47.8183), 210: tensor(42.2300), 220: tensor(38.9083), 230: tensor(41.7517), 240: tensor(53.1683), 250: tensor(70.3450), 260: tensor(82.2967), 270: tensor(88.8983), 280: tensor(87.2983), 290: tensor(81.4933), 300: tensor(69.7300), 310: tensor(62.9267), 320: tensor(65.7333), 330: tensor(79.1450), 340: tensor(92.0500), 350: tensor(97.5150)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=78, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 13.4782,                   Accuracy: 196/2000.0 (9.80%)



-= Testing valid =-
Test set: Average loss: 0.9168,                   Accuracy: 1425/2000.0 (71.25%)



-= Testing valid =-
Test set: Average loss: 1.8630,                   Accuracy: 956/2000.0 (47.80%)



-= Testing valid =-
Test set: Average loss: 1.1103,                   Accuracy: 1118/2000.0 (55.90%)



-= Testing valid =-
Test set: Average loss: 0.1832,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.2485,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.1558,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.2648,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.1613,                   Accuracy: 1908/2000.0 (95.40%)



Epoch 10 train accuracy: 98.03%, valid accuracy 95.40%
-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0595,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0606,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0593,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 20 train accuracy: 99.26%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0454,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 30 train accuracy: 99.53%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 40 train accuracy: 99.70%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0409,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 50 train accuracy: 99.78%, valid accuracy 98.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0499,                   Accuracy: 59154/60000 (98.59%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0743,                   Accuracy: 58723/60000 (97.87%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1705,                   Accuracy: 57160/60000 (95.27%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4467,                   Accuracy: 52438/60000 (87.40%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8215,                   Accuracy: 46185/60000 (76.97%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0342,                   Accuracy: 42270/60000 (70.45%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9076,                   Accuracy: 43968/60000 (73.28%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6268,                   Accuracy: 48663/60000 (81.11%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4591,                   Accuracy: 51444/60000 (85.74%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4722,                   Accuracy: 51101/60000 (85.17%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6412,                   Accuracy: 48326/60000 (80.54%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1153,                   Accuracy: 41124/60000 (68.54%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.8932,                   Accuracy: 32461/60000 (54.10%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.7113,                   Accuracy: 26246/60000 (43.74%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.1721,                   Accuracy: 24853/60000 (41.42%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.2230,                   Accuracy: 26191/60000 (43.65%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.9969,                   Accuracy: 29812/60000 (49.69%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.8892,                   Accuracy: 32364/60000 (53.94%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.9836,                   Accuracy: 32586/60000 (54.31%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.1502,                   Accuracy: 31301/60000 (52.17%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.4564,                   Accuracy: 29137/60000 (48.56%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.8248,                   Accuracy: 25599/60000 (42.67%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7618,                   Accuracy: 24088/60000 (40.15%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1388,                   Accuracy: 26118/60000 (43.53%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.1230,                   Accuracy: 32236/60000 (53.73%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2229,                   Accuracy: 40663/60000 (67.77%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6475,                   Accuracy: 47730/60000 (79.55%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3888,                   Accuracy: 52037/60000 (86.73%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4615,                   Accuracy: 50763/60000 (84.61%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6137,                   Accuracy: 47826/60000 (79.71%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9884,                   Accuracy: 41529/60000 (69.21%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1574,                   Accuracy: 39222/60000 (65.37%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0441,                   Accuracy: 41709/60000 (69.51%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5976,                   Accuracy: 49277/60000 (82.13%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2109,                   Accuracy: 56057/60000 (93.43%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0817,                   Accuracy: 58466/60000 (97.44%)
{0: tensor(98.5900), 10: tensor(97.8717), 20: tensor(95.2667), 30: tensor(87.3967), 40: tensor(76.9750), 50: tensor(70.4500), 60: tensor(73.2800), 70: tensor(81.1050), 80: tensor(85.7400), 90: tensor(85.1683), 100: tensor(80.5433), 110: tensor(68.5400), 120: tensor(54.1017), 130: tensor(43.7433), 140: tensor(41.4217), 150: tensor(43.6517), 160: tensor(49.6867), 170: tensor(53.9400), 180: tensor(54.3100), 190: tensor(52.1683), 200: tensor(48.5617), 210: tensor(42.6650), 220: tensor(40.1467), 230: tensor(43.5300), 240: tensor(53.7267), 250: tensor(67.7717), 260: tensor(79.5500), 270: tensor(86.7283), 280: tensor(84.6050), 290: tensor(79.7100), 300: tensor(69.2150), 310: tensor(65.3700), 320: tensor(69.5150), 330: tensor(82.1283), 340: tensor(93.4283), 350: tensor(97.4433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=79, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0202,                   Accuracy: 303/2000.0 (15.15%)



-= Testing valid =-
Test set: Average loss: 0.7696,                   Accuracy: 1583/2000.0 (79.15%)



-= Testing valid =-
Test set: Average loss: 0.2984,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2099,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.1937,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.1826,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.1799,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1050,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 10 train accuracy: 98.01%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0596,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0554,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 20 train accuracy: 98.99%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0454,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0496,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.46%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 40 train accuracy: 99.57%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 50 train accuracy: 99.76%, valid accuracy 98.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0537,                   Accuracy: 59088/60000 (98.48%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0800,                   Accuracy: 58656/60000 (97.76%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1875,                   Accuracy: 56929/60000 (94.88%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5022,                   Accuracy: 51817/60000 (86.36%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0078,                   Accuracy: 43963/60000 (73.27%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.3271,                   Accuracy: 38561/60000 (64.27%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2322,                   Accuracy: 39111/60000 (65.18%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9391,                   Accuracy: 42775/60000 (71.29%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7007,                   Accuracy: 45847/60000 (76.41%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6012,                   Accuracy: 47345/60000 (78.91%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8473,                   Accuracy: 42174/60000 (70.29%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3236,                   Accuracy: 35348/60000 (58.91%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.1597,                   Accuracy: 27220/60000 (45.37%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.0562,                   Accuracy: 22922/60000 (38.20%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.7263,                   Accuracy: 21998/60000 (36.66%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.0326,                   Accuracy: 24359/60000 (40.60%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.0675,                   Accuracy: 28448/60000 (47.41%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.1540,                   Accuracy: 31476/60000 (52.46%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.2108,                   Accuracy: 32536/60000 (54.23%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.3603,                   Accuracy: 31686/60000 (52.81%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.3964,                   Accuracy: 29868/60000 (49.78%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.6185,                   Accuracy: 26341/60000 (43.90%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.4794,                   Accuracy: 24090/60000 (40.15%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.8788,                   Accuracy: 24606/60000 (41.01%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.7616,                   Accuracy: 29553/60000 (49.26%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.5827,                   Accuracy: 37867/60000 (63.11%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8378,                   Accuracy: 45600/60000 (76.00%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5216,                   Accuracy: 50031/60000 (83.39%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6230,                   Accuracy: 47176/60000 (78.63%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7670,                   Accuracy: 45010/60000 (75.02%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2229,                   Accuracy: 39242/60000 (65.40%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4571,                   Accuracy: 37310/60000 (62.18%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.4398,                   Accuracy: 39097/60000 (65.16%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9139,                   Accuracy: 46461/60000 (77.43%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2995,                   Accuracy: 54785/60000 (91.31%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0894,                   Accuracy: 58368/60000 (97.28%)
{0: tensor(98.4800), 10: tensor(97.7600), 20: tensor(94.8817), 30: tensor(86.3617), 40: tensor(73.2717), 50: tensor(64.2683), 60: tensor(65.1850), 70: tensor(71.2917), 80: tensor(76.4117), 90: tensor(78.9083), 100: tensor(70.2900), 110: tensor(58.9133), 120: tensor(45.3667), 130: tensor(38.2033), 140: tensor(36.6633), 150: tensor(40.5983), 160: tensor(47.4133), 170: tensor(52.4600), 180: tensor(54.2267), 190: tensor(52.8100), 200: tensor(49.7800), 210: tensor(43.9017), 220: tensor(40.1500), 230: tensor(41.0100), 240: tensor(49.2550), 250: tensor(63.1117), 260: tensor(76.), 270: tensor(83.3850), 280: tensor(78.6267), 290: tensor(75.0167), 300: tensor(65.4033), 310: tensor(62.1833), 320: tensor(65.1617), 330: tensor(77.4350), 340: tensor(91.3083), 350: tensor(97.2800)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=80, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.8989,                   Accuracy: 245/2000.0 (12.25%)



-= Testing valid =-
Test set: Average loss: 2.4373,                   Accuracy: 526/2000.0 (26.30%)



-= Testing valid =-
Test set: Average loss: 2.4871,                   Accuracy: 710/2000.0 (35.50%)



-= Testing valid =-
Test set: Average loss: 2.8861,                   Accuracy: 421/2000.0 (21.05%)



-= Testing valid =-
Test set: Average loss: 0.5047,                   Accuracy: 1710/2000.0 (85.50%)



-= Testing valid =-
Test set: Average loss: 0.1254,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1191,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0721,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 10 train accuracy: 98.31%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0453,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 20 train accuracy: 98.90%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 30 train accuracy: 99.44%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0223,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 40 train accuracy: 99.55%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0206,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0226,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0221,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0196,                   Accuracy: 1989/2000.0 (99.45%)



Epoch 50 train accuracy: 99.72%, valid accuracy 99.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0426,                   Accuracy: 59241/60000 (98.74%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0627,                   Accuracy: 58863/60000 (98.11%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1291,                   Accuracy: 57686/60000 (96.14%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3059,                   Accuracy: 54483/60000 (90.81%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.6432,                   Accuracy: 48445/60000 (80.74%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8908,                   Accuracy: 44065/60000 (73.44%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8690,                   Accuracy: 44099/60000 (73.50%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6392,                   Accuracy: 47852/60000 (79.75%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4863,                   Accuracy: 50708/60000 (84.51%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4774,                   Accuracy: 50504/60000 (84.17%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7499,                   Accuracy: 45518/60000 (75.86%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1662,                   Accuracy: 40688/60000 (67.81%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.9236,                   Accuracy: 33008/60000 (55.01%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.6177,                   Accuracy: 28121/60000 (46.87%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.2801,                   Accuracy: 24935/60000 (41.56%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.6484,                   Accuracy: 25493/60000 (42.49%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.7626,                   Accuracy: 28139/60000 (46.90%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.8581,                   Accuracy: 29933/60000 (49.89%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.0739,                   Accuracy: 31251/60000 (52.08%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.9738,                   Accuracy: 31225/60000 (52.04%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.8133,                   Accuracy: 30159/60000 (50.26%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7907,                   Accuracy: 27418/60000 (45.70%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6539,                   Accuracy: 24846/60000 (41.41%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2082,                   Accuracy: 24725/60000 (41.21%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3906,                   Accuracy: 28218/60000 (47.03%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.5152,                   Accuracy: 34988/60000 (58.31%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9181,                   Accuracy: 41765/60000 (69.61%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5968,                   Accuracy: 47549/60000 (79.25%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7021,                   Accuracy: 45859/60000 (76.43%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8875,                   Accuracy: 42367/60000 (70.61%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2196,                   Accuracy: 38702/60000 (64.50%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3135,                   Accuracy: 38154/60000 (63.59%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1961,                   Accuracy: 40791/60000 (67.99%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6884,                   Accuracy: 48385/60000 (80.64%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2144,                   Accuracy: 55938/60000 (93.23%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0702,                   Accuracy: 58696/60000 (97.83%)
{0: tensor(98.7350), 10: tensor(98.1050), 20: tensor(96.1433), 30: tensor(90.8050), 40: tensor(80.7417), 50: tensor(73.4417), 60: tensor(73.4983), 70: tensor(79.7533), 80: tensor(84.5133), 90: tensor(84.1733), 100: tensor(75.8633), 110: tensor(67.8133), 120: tensor(55.0133), 130: tensor(46.8683), 140: tensor(41.5583), 150: tensor(42.4883), 160: tensor(46.8983), 170: tensor(49.8883), 180: tensor(52.0850), 190: tensor(52.0417), 200: tensor(50.2650), 210: tensor(45.6967), 220: tensor(41.4100), 230: tensor(41.2083), 240: tensor(47.0300), 250: tensor(58.3133), 260: tensor(69.6083), 270: tensor(79.2483), 280: tensor(76.4317), 290: tensor(70.6117), 300: tensor(64.5033), 310: tensor(63.5900), 320: tensor(67.9850), 330: tensor(80.6417), 340: tensor(93.2300), 350: tensor(97.8267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=81, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9176,                   Accuracy: 454/2000.0 (22.70%)



-= Testing valid =-
Test set: Average loss: 1.3485,                   Accuracy: 947/2000.0 (47.35%)



-= Testing valid =-
Test set: Average loss: 1.0631,                   Accuracy: 1383/2000.0 (69.15%)



-= Testing valid =-
Test set: Average loss: 0.8397,                   Accuracy: 1442/2000.0 (72.10%)



-= Testing valid =-
Test set: Average loss: 0.9150,                   Accuracy: 1391/2000.0 (69.55%)



-= Testing valid =-
Test set: Average loss: 0.2457,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.2481,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.3233,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.2258,                   Accuracy: 1842/2000.0 (92.10%)



Epoch 10 train accuracy: 98.05%, valid accuracy 92.10%
-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0454,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0450,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 20 train accuracy: 98.99%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 30 train accuracy: 99.29%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0219,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.49%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.69%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0575,                   Accuracy: 58999/60000 (98.33%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0905,                   Accuracy: 58445/60000 (97.41%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2177,                   Accuracy: 56360/60000 (93.93%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5527,                   Accuracy: 51220/60000 (85.37%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9815,                   Accuracy: 44503/60000 (74.17%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2171,                   Accuracy: 40397/60000 (67.33%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1091,                   Accuracy: 41283/60000 (68.81%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7869,                   Accuracy: 45463/60000 (75.77%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6217,                   Accuracy: 47290/60000 (78.82%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6921,                   Accuracy: 45356/60000 (75.59%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0069,                   Accuracy: 39772/60000 (66.29%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5573,                   Accuracy: 31840/60000 (53.07%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.3407,                   Accuracy: 24337/60000 (40.56%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.9335,                   Accuracy: 20407/60000 (34.01%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.1441,                   Accuracy: 20118/60000 (33.53%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.0199,                   Accuracy: 23262/60000 (38.77%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.8892,                   Accuracy: 28140/60000 (46.90%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.9378,                   Accuracy: 31141/60000 (51.90%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.1145,                   Accuracy: 32543/60000 (54.24%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.2835,                   Accuracy: 32234/60000 (53.72%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.4936,                   Accuracy: 30565/60000 (50.94%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7946,                   Accuracy: 26825/60000 (44.71%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6853,                   Accuracy: 24040/60000 (40.07%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2138,                   Accuracy: 24822/60000 (41.37%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3619,                   Accuracy: 29780/60000 (49.63%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.4011,                   Accuracy: 38122/60000 (63.54%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8274,                   Accuracy: 44456/60000 (74.09%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5555,                   Accuracy: 49065/60000 (81.78%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6556,                   Accuracy: 46905/60000 (78.18%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9907,                   Accuracy: 41108/60000 (68.51%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3880,                   Accuracy: 35607/60000 (59.35%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.6020,                   Accuracy: 33194/60000 (55.32%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.4198,                   Accuracy: 36615/60000 (61.03%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7986,                   Accuracy: 46080/60000 (76.80%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2776,                   Accuracy: 55054/60000 (91.76%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0946,                   Accuracy: 58300/60000 (97.17%)
{0: tensor(98.3317), 10: tensor(97.4083), 20: tensor(93.9333), 30: tensor(85.3667), 40: tensor(74.1717), 50: tensor(67.3283), 60: tensor(68.8050), 70: tensor(75.7717), 80: tensor(78.8167), 90: tensor(75.5933), 100: tensor(66.2867), 110: tensor(53.0667), 120: tensor(40.5617), 130: tensor(34.0117), 140: tensor(33.5300), 150: tensor(38.7700), 160: tensor(46.9000), 170: tensor(51.9017), 180: tensor(54.2383), 190: tensor(53.7233), 200: tensor(50.9417), 210: tensor(44.7083), 220: tensor(40.0667), 230: tensor(41.3700), 240: tensor(49.6333), 250: tensor(63.5367), 260: tensor(74.0933), 270: tensor(81.7750), 280: tensor(78.1750), 290: tensor(68.5133), 300: tensor(59.3450), 310: tensor(55.3233), 320: tensor(61.0250), 330: tensor(76.8000), 340: tensor(91.7567), 350: tensor(97.1667)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=82, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6712,                   Accuracy: 451/2000.0 (22.55%)



-= Testing valid =-
Test set: Average loss: 0.8394,                   Accuracy: 1603/2000.0 (80.15%)



-= Testing valid =-
Test set: Average loss: 0.3750,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.3545,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.1222,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.5787,                   Accuracy: 1660/2000.0 (83.00%)



-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 10 train accuracy: 98.25%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0560,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0552,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0647,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 20 train accuracy: 99.03%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 30 train accuracy: 99.47%, valid accuracy 99.35%
-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1992/2000.0 (99.60%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0226,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1992/2000.0 (99.60%)



Epoch 40 train accuracy: 99.74%, valid accuracy 99.60%
-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0208,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0221,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0204,                   Accuracy: 1992/2000.0 (99.60%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1992/2000.0 (99.60%)



Epoch 50 train accuracy: 99.72%, valid accuracy 99.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0514,                   Accuracy: 59073/60000 (98.46%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0803,                   Accuracy: 58600/60000 (97.67%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1774,                   Accuracy: 56971/60000 (94.95%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4549,                   Accuracy: 52367/60000 (87.28%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7850,                   Accuracy: 46857/60000 (78.10%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9817,                   Accuracy: 43229/60000 (72.05%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8710,                   Accuracy: 44766/60000 (74.61%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.5487,                   Accuracy: 50179/60000 (83.63%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4093,                   Accuracy: 52425/60000 (87.38%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4143,                   Accuracy: 52367/60000 (87.28%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6693,                   Accuracy: 47711/60000 (79.52%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1705,                   Accuracy: 41069/60000 (68.45%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0590,                   Accuracy: 31442/60000 (52.40%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.7542,                   Accuracy: 26390/60000 (43.98%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.2042,                   Accuracy: 24853/60000 (41.42%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4197,                   Accuracy: 26050/60000 (43.42%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.3636,                   Accuracy: 29692/60000 (49.49%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.3614,                   Accuracy: 30819/60000 (51.37%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.3088,                   Accuracy: 31058/60000 (51.76%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4236,                   Accuracy: 30192/60000 (50.32%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.5107,                   Accuracy: 27581/60000 (45.97%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.8430,                   Accuracy: 23557/60000 (39.26%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6930,                   Accuracy: 22193/60000 (36.99%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.0728,                   Accuracy: 23897/60000 (39.83%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.1314,                   Accuracy: 29575/60000 (49.29%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2592,                   Accuracy: 37993/60000 (63.32%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8438,                   Accuracy: 43614/60000 (72.69%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5270,                   Accuracy: 48893/60000 (81.49%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5431,                   Accuracy: 49141/60000 (81.90%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7364,                   Accuracy: 46172/60000 (76.95%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0832,                   Accuracy: 41250/60000 (68.75%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1177,                   Accuracy: 40677/60000 (67.79%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9459,                   Accuracy: 43474/60000 (72.46%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5193,                   Accuracy: 50779/60000 (84.63%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1721,                   Accuracy: 56709/60000 (94.51%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0744,                   Accuracy: 58584/60000 (97.64%)
{0: tensor(98.4550), 10: tensor(97.6667), 20: tensor(94.9517), 30: tensor(87.2783), 40: tensor(78.0950), 50: tensor(72.0483), 60: tensor(74.6100), 70: tensor(83.6317), 80: tensor(87.3750), 90: tensor(87.2783), 100: tensor(79.5183), 110: tensor(68.4483), 120: tensor(52.4033), 130: tensor(43.9833), 140: tensor(41.4217), 150: tensor(43.4167), 160: tensor(49.4867), 170: tensor(51.3650), 180: tensor(51.7633), 190: tensor(50.3200), 200: tensor(45.9683), 210: tensor(39.2617), 220: tensor(36.9883), 230: tensor(39.8283), 240: tensor(49.2917), 250: tensor(63.3217), 260: tensor(72.6900), 270: tensor(81.4883), 280: tensor(81.9017), 290: tensor(76.9533), 300: tensor(68.7500), 310: tensor(67.7950), 320: tensor(72.4567), 330: tensor(84.6317), 340: tensor(94.5150), 350: tensor(97.6400)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=83, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0135,                   Accuracy: 578/2000.0 (28.90%)



-= Testing valid =-
Test set: Average loss: 1.1338,                   Accuracy: 1309/2000.0 (65.45%)



-= Testing valid =-
Test set: Average loss: 0.6708,                   Accuracy: 1556/2000.0 (77.80%)



-= Testing valid =-
Test set: Average loss: 0.3318,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.1714,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1300,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.1010,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0807,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 10 train accuracy: 97.90%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0450,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 20 train accuracy: 99.00%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0619,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.50%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 40 train accuracy: 99.71%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.68%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0518,                   Accuracy: 59110/60000 (98.52%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0655,                   Accuracy: 58862/60000 (98.10%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1327,                   Accuracy: 57641/60000 (96.07%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3474,                   Accuracy: 53824/60000 (89.71%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.6860,                   Accuracy: 47763/60000 (79.61%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9269,                   Accuracy: 43283/60000 (72.14%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8745,                   Accuracy: 43778/60000 (72.96%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6553,                   Accuracy: 47835/60000 (79.72%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5740,                   Accuracy: 49584/60000 (82.64%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6087,                   Accuracy: 48976/60000 (81.63%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9836,                   Accuracy: 43136/60000 (71.89%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.7284,                   Accuracy: 35267/60000 (58.78%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.6474,                   Accuracy: 27513/60000 (45.85%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.3867,                   Accuracy: 22393/60000 (37.32%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.7668,                   Accuracy: 20793/60000 (34.65%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8067,                   Accuracy: 22214/60000 (37.02%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5913,                   Accuracy: 25181/60000 (41.97%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.4638,                   Accuracy: 27638/60000 (46.06%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.5064,                   Accuracy: 28147/60000 (46.91%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4726,                   Accuracy: 28107/60000 (46.85%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.6240,                   Accuracy: 26476/60000 (44.13%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7544,                   Accuracy: 23636/60000 (39.39%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.5834,                   Accuracy: 22306/60000 (37.18%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9907,                   Accuracy: 24715/60000 (41.19%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0520,                   Accuracy: 31561/60000 (52.60%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1873,                   Accuracy: 40763/60000 (67.94%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7324,                   Accuracy: 46362/60000 (77.27%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4962,                   Accuracy: 50768/60000 (84.61%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6296,                   Accuracy: 48219/60000 (80.36%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8850,                   Accuracy: 45241/60000 (75.40%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3403,                   Accuracy: 39391/60000 (65.65%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.5228,                   Accuracy: 36367/60000 (60.61%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3566,                   Accuracy: 39096/60000 (65.16%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8172,                   Accuracy: 46853/60000 (78.09%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3023,                   Accuracy: 54745/60000 (91.24%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1059,                   Accuracy: 58149/60000 (96.92%)
{0: tensor(98.5167), 10: tensor(98.1033), 20: tensor(96.0683), 30: tensor(89.7067), 40: tensor(79.6050), 50: tensor(72.1383), 60: tensor(72.9633), 70: tensor(79.7250), 80: tensor(82.6400), 90: tensor(81.6267), 100: tensor(71.8933), 110: tensor(58.7783), 120: tensor(45.8550), 130: tensor(37.3217), 140: tensor(34.6550), 150: tensor(37.0233), 160: tensor(41.9683), 170: tensor(46.0633), 180: tensor(46.9117), 190: tensor(46.8450), 200: tensor(44.1267), 210: tensor(39.3933), 220: tensor(37.1767), 230: tensor(41.1917), 240: tensor(52.6017), 250: tensor(67.9383), 260: tensor(77.2700), 270: tensor(84.6133), 280: tensor(80.3650), 290: tensor(75.4017), 300: tensor(65.6517), 310: tensor(60.6117), 320: tensor(65.1600), 330: tensor(78.0883), 340: tensor(91.2417), 350: tensor(96.9150)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=84, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.8258,                   Accuracy: 338/2000.0 (16.90%)



-= Testing valid =-
Test set: Average loss: 1.3064,                   Accuracy: 1117/2000.0 (55.85%)



-= Testing valid =-
Test set: Average loss: 0.5377,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.8213,                   Accuracy: 1435/2000.0 (71.75%)



-= Testing valid =-
Test set: Average loss: 0.1527,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1185,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.4223,                   Accuracy: 1755/2000.0 (87.75%)



-= Testing valid =-
Test set: Average loss: 0.1510,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1094,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.6074,                   Accuracy: 1618/2000.0 (80.90%)



Epoch 10 train accuracy: 98.41%, valid accuracy 80.90%
-= Testing valid =-
Test set: Average loss: 0.4337,                   Accuracy: 1722/2000.0 (86.10%)



-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.3078,                   Accuracy: 1777/2000.0 (88.85%)



-= Testing valid =-
Test set: Average loss: 0.5219,                   Accuracy: 1681/2000.0 (84.05%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.2775,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.4067,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.2656,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.2533,                   Accuracy: 1801/2000.0 (90.05%)



Epoch 20 train accuracy: 98.93%, valid accuracy 90.05%
-= Testing valid =-
Test set: Average loss: 0.1893,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2085,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.5460,                   Accuracy: 1713/2000.0 (85.65%)



-= Testing valid =-
Test set: Average loss: 0.2462,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.1459,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.2546,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2734,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.2174,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.2305,                   Accuracy: 1859/2000.0 (92.95%)



Epoch 30 train accuracy: 99.64%, valid accuracy 92.95%
-= Testing valid =-
Test set: Average loss: 0.1106,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1804,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1448,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.3360,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.1942,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1553,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.3737,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.2425,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2503,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.5644,                   Accuracy: 1722/2000.0 (86.10%)



Epoch 40 train accuracy: 99.65%, valid accuracy 86.10%
-= Testing valid =-
Test set: Average loss: 0.4393,                   Accuracy: 1752/2000.0 (87.60%)



-= Testing valid =-
Test set: Average loss: 0.3176,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.1870,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1343,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1549,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.2820,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2420,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.3196,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.1822,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1398,                   Accuracy: 1911/2000.0 (95.55%)



Epoch 50 train accuracy: 99.72%, valid accuracy 95.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0741,                   Accuracy: 58696/60000 (97.83%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1111,                   Accuracy: 58022/60000 (96.70%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2347,                   Accuracy: 55788/60000 (92.98%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5752,                   Accuracy: 50179/60000 (83.63%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0012,                   Accuracy: 42865/60000 (71.44%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2836,                   Accuracy: 38008/60000 (63.35%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1066,                   Accuracy: 39482/60000 (65.80%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6974,                   Accuracy: 45861/60000 (76.43%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5194,                   Accuracy: 48685/60000 (81.14%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4468,                   Accuracy: 49956/60000 (83.26%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6487,                   Accuracy: 46920/60000 (78.20%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.0495,                   Accuracy: 41995/60000 (69.99%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.7653,                   Accuracy: 34277/60000 (57.13%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.3706,                   Accuracy: 28830/60000 (48.05%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.7609,                   Accuracy: 26019/60000 (43.37%)
-= Testing Rotation 150 =-
Test set: Average loss: 2.6667,                   Accuracy: 26791/60000 (44.65%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.2887,                   Accuracy: 31064/60000 (51.77%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.0957,                   Accuracy: 33927/60000 (56.54%)
-= Testing Rotation 180 =-
Test set: Average loss: 1.9509,                   Accuracy: 36464/60000 (60.77%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.1341,                   Accuracy: 33709/60000 (56.18%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.2855,                   Accuracy: 31303/60000 (52.17%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.4966,                   Accuracy: 27736/60000 (46.23%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.5369,                   Accuracy: 25963/60000 (43.27%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.1844,                   Accuracy: 28487/60000 (47.48%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.5122,                   Accuracy: 35101/60000 (58.50%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.7995,                   Accuracy: 45419/60000 (75.70%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.4431,                   Accuracy: 51652/60000 (86.09%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3093,                   Accuracy: 54088/60000 (90.15%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3801,                   Accuracy: 52911/60000 (88.18%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6167,                   Accuracy: 48884/60000 (81.47%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0122,                   Accuracy: 43276/60000 (72.13%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2289,                   Accuracy: 39667/60000 (66.11%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2149,                   Accuracy: 40816/60000 (68.03%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7623,                   Accuracy: 46749/60000 (77.92%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2841,                   Accuracy: 54664/60000 (91.11%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1242,                   Accuracy: 57756/60000 (96.26%)
{0: tensor(97.8267), 10: tensor(96.7033), 20: tensor(92.9800), 30: tensor(83.6317), 40: tensor(71.4417), 50: tensor(63.3467), 60: tensor(65.8033), 70: tensor(76.4350), 80: tensor(81.1417), 90: tensor(83.2600), 100: tensor(78.2000), 110: tensor(69.9917), 120: tensor(57.1283), 130: tensor(48.0500), 140: tensor(43.3650), 150: tensor(44.6517), 160: tensor(51.7733), 170: tensor(56.5450), 180: tensor(60.7733), 190: tensor(56.1817), 200: tensor(52.1717), 210: tensor(46.2267), 220: tensor(43.2717), 230: tensor(47.4783), 240: tensor(58.5017), 250: tensor(75.6983), 260: tensor(86.0867), 270: tensor(90.1467), 280: tensor(88.1850), 290: tensor(81.4733), 300: tensor(72.1267), 310: tensor(66.1117), 320: tensor(68.0267), 330: tensor(77.9150), 340: tensor(91.1067), 350: tensor(96.2600)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=85, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1387,                   Accuracy: 501/2000.0 (25.05%)



-= Testing valid =-
Test set: Average loss: 1.0120,                   Accuracy: 1403/2000.0 (70.15%)



-= Testing valid =-
Test set: Average loss: 0.4453,                   Accuracy: 1698/2000.0 (84.90%)



-= Testing valid =-
Test set: Average loss: 0.2704,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.1903,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1248,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.2020,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.1407,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1171,                   Accuracy: 1930/2000.0 (96.50%)



Epoch 10 train accuracy: 98.19%, valid accuracy 96.50%
-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 20 train accuracy: 98.94%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.51%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 40 train accuracy: 99.75%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 50 train accuracy: 99.62%, valid accuracy 98.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0470,                   Accuracy: 59151/60000 (98.58%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0729,                   Accuracy: 58723/60000 (97.87%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1822,                   Accuracy: 56853/60000 (94.75%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4778,                   Accuracy: 51938/60000 (86.56%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8738,                   Accuracy: 45477/60000 (75.79%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0853,                   Accuracy: 41239/60000 (68.73%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9726,                   Accuracy: 42139/60000 (70.23%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6959,                   Accuracy: 46726/60000 (77.88%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5564,                   Accuracy: 48937/60000 (81.56%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5126,                   Accuracy: 49885/60000 (83.14%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8529,                   Accuracy: 44286/60000 (73.81%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5601,                   Accuracy: 35952/60000 (59.92%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5018,                   Accuracy: 27521/60000 (45.87%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.3050,                   Accuracy: 23052/60000 (38.42%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.7765,                   Accuracy: 22077/60000 (36.79%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.7562,                   Accuracy: 24236/60000 (40.39%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5377,                   Accuracy: 27227/60000 (45.38%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.4362,                   Accuracy: 28450/60000 (47.42%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.2967,                   Accuracy: 28534/60000 (47.56%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4938,                   Accuracy: 27630/60000 (46.05%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.5434,                   Accuracy: 25926/60000 (43.21%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7912,                   Accuracy: 23418/60000 (39.03%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7684,                   Accuracy: 21812/60000 (36.35%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.4354,                   Accuracy: 22625/60000 (37.71%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.6316,                   Accuracy: 27316/60000 (45.53%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.7499,                   Accuracy: 34842/60000 (58.07%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.1456,                   Accuracy: 40738/60000 (67.90%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7562,                   Accuracy: 45783/60000 (76.31%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.9209,                   Accuracy: 42228/60000 (70.38%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.1576,                   Accuracy: 38377/60000 (63.96%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.4263,                   Accuracy: 34418/60000 (57.36%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4782,                   Accuracy: 34175/60000 (56.96%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2245,                   Accuracy: 38894/60000 (64.82%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6878,                   Accuracy: 47962/60000 (79.94%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2307,                   Accuracy: 55912/60000 (93.19%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0808,                   Accuracy: 58543/60000 (97.57%)
{0: tensor(98.5850), 10: tensor(97.8717), 20: tensor(94.7550), 30: tensor(86.5633), 40: tensor(75.7950), 50: tensor(68.7317), 60: tensor(70.2317), 70: tensor(77.8767), 80: tensor(81.5617), 90: tensor(83.1417), 100: tensor(73.8100), 110: tensor(59.9200), 120: tensor(45.8683), 130: tensor(38.4200), 140: tensor(36.7950), 150: tensor(40.3933), 160: tensor(45.3783), 170: tensor(47.4167), 180: tensor(47.5567), 190: tensor(46.0500), 200: tensor(43.2100), 210: tensor(39.0300), 220: tensor(36.3533), 230: tensor(37.7083), 240: tensor(45.5267), 250: tensor(58.0700), 260: tensor(67.8967), 270: tensor(76.3050), 280: tensor(70.3800), 290: tensor(63.9617), 300: tensor(57.3633), 310: tensor(56.9583), 320: tensor(64.8233), 330: tensor(79.9367), 340: tensor(93.1867), 350: tensor(97.5717)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=86, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.1531,                   Accuracy: 331/2000.0 (16.55%)



-= Testing valid =-
Test set: Average loss: 0.7696,                   Accuracy: 1514/2000.0 (75.70%)



-= Testing valid =-
Test set: Average loss: 0.5308,                   Accuracy: 1661/2000.0 (83.05%)



-= Testing valid =-
Test set: Average loss: 0.5083,                   Accuracy: 1622/2000.0 (81.10%)



-= Testing valid =-
Test set: Average loss: 0.2438,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.2841,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.1174,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1431,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.0625,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.1492,                   Accuracy: 1896/2000.0 (94.80%)



Epoch 10 train accuracy: 98.15%, valid accuracy 94.80%
-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 20 train accuracy: 99.03%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 30 train accuracy: 99.26%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 40 train accuracy: 99.71%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 50 train accuracy: 99.64%, valid accuracy 98.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0581,                   Accuracy: 59059/60000 (98.43%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0867,                   Accuracy: 58531/60000 (97.55%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1916,                   Accuracy: 56697/60000 (94.50%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4571,                   Accuracy: 52221/60000 (87.04%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8256,                   Accuracy: 45969/60000 (76.61%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0366,                   Accuracy: 42155/60000 (70.26%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9850,                   Accuracy: 42321/60000 (70.54%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8037,                   Accuracy: 44678/60000 (74.46%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7159,                   Accuracy: 46113/60000 (76.86%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7427,                   Accuracy: 45908/60000 (76.51%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.2402,                   Accuracy: 39863/60000 (66.44%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.9733,                   Accuracy: 33614/60000 (56.02%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.8546,                   Accuracy: 27190/60000 (45.32%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.5636,                   Accuracy: 23906/60000 (39.84%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.7609,                   Accuracy: 23048/60000 (38.41%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.6869,                   Accuracy: 24007/60000 (40.01%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5822,                   Accuracy: 25954/60000 (43.26%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5539,                   Accuracy: 27042/60000 (45.07%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.6459,                   Accuracy: 28437/60000 (47.40%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.7809,                   Accuracy: 27803/60000 (46.34%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.8349,                   Accuracy: 26500/60000 (44.17%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9875,                   Accuracy: 24356/60000 (40.59%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7165,                   Accuracy: 24225/60000 (40.38%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9363,                   Accuracy: 28270/60000 (47.12%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9287,                   Accuracy: 35649/60000 (59.42%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0935,                   Accuracy: 43955/60000 (73.26%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6374,                   Accuracy: 49041/60000 (81.74%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4019,                   Accuracy: 52330/60000 (87.22%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4955,                   Accuracy: 50345/60000 (83.91%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7504,                   Accuracy: 46034/60000 (76.72%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1809,                   Accuracy: 40394/60000 (67.32%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4851,                   Accuracy: 37380/60000 (62.30%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.4063,                   Accuracy: 39731/60000 (66.22%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9130,                   Accuracy: 46723/60000 (77.87%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3269,                   Accuracy: 54656/60000 (91.09%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1096,                   Accuracy: 58109/60000 (96.85%)
{0: tensor(98.4317), 10: tensor(97.5517), 20: tensor(94.4950), 30: tensor(87.0350), 40: tensor(76.6150), 50: tensor(70.2583), 60: tensor(70.5350), 70: tensor(74.4633), 80: tensor(76.8550), 90: tensor(76.5133), 100: tensor(66.4383), 110: tensor(56.0233), 120: tensor(45.3167), 130: tensor(39.8433), 140: tensor(38.4133), 150: tensor(40.0117), 160: tensor(43.2567), 170: tensor(45.0700), 180: tensor(47.3950), 190: tensor(46.3383), 200: tensor(44.1667), 210: tensor(40.5933), 220: tensor(40.3750), 230: tensor(47.1167), 240: tensor(59.4150), 250: tensor(73.2583), 260: tensor(81.7350), 270: tensor(87.2167), 280: tensor(83.9083), 290: tensor(76.7233), 300: tensor(67.3233), 310: tensor(62.3000), 320: tensor(66.2183), 330: tensor(77.8717), 340: tensor(91.0933), 350: tensor(96.8483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=87, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3711,                   Accuracy: 401/2000.0 (20.05%)



-= Testing valid =-
Test set: Average loss: 1.9860,                   Accuracy: 616/2000.0 (30.80%)



-= Testing valid =-
Test set: Average loss: 0.7144,                   Accuracy: 1567/2000.0 (78.35%)



-= Testing valid =-
Test set: Average loss: 0.1342,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.2309,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.1443,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1168,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1153,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1577,                   Accuracy: 1905/2000.0 (95.25%)



Epoch 10 train accuracy: 98.01%, valid accuracy 95.25%
-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0492,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 20 train accuracy: 98.90%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 30 train accuracy: 99.54%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0445,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 40 train accuracy: 99.65%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 50 train accuracy: 99.75%, valid accuracy 98.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0435,                   Accuracy: 59221/60000 (98.70%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0698,                   Accuracy: 58756/60000 (97.93%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1528,                   Accuracy: 57321/60000 (95.54%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3650,                   Accuracy: 53682/60000 (89.47%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7118,                   Accuracy: 47679/60000 (79.46%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9159,                   Accuracy: 43973/60000 (73.29%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8589,                   Accuracy: 44477/60000 (74.13%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6662,                   Accuracy: 47425/60000 (79.04%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5115,                   Accuracy: 50096/60000 (83.49%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5177,                   Accuracy: 49673/60000 (82.79%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8876,                   Accuracy: 43569/60000 (72.61%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5644,                   Accuracy: 36074/60000 (60.12%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.4993,                   Accuracy: 28904/60000 (48.17%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.2815,                   Accuracy: 24120/60000 (40.20%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.4669,                   Accuracy: 22944/60000 (38.24%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.1571,                   Accuracy: 24695/60000 (41.16%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.6925,                   Accuracy: 28943/60000 (48.24%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.6439,                   Accuracy: 31174/60000 (51.96%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.6578,                   Accuracy: 31415/60000 (52.36%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.8033,                   Accuracy: 30411/60000 (50.69%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.0414,                   Accuracy: 28504/60000 (47.51%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.3275,                   Accuracy: 25730/60000 (42.88%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.2780,                   Accuracy: 24469/60000 (40.78%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7269,                   Accuracy: 26908/60000 (44.85%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.7923,                   Accuracy: 34167/60000 (56.94%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0449,                   Accuracy: 42360/60000 (70.60%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5985,                   Accuracy: 48707/60000 (81.18%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3491,                   Accuracy: 53160/60000 (88.60%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4826,                   Accuracy: 50634/60000 (84.39%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7637,                   Accuracy: 45892/60000 (76.49%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1898,                   Accuracy: 39973/60000 (66.62%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3824,                   Accuracy: 37382/60000 (62.30%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2029,                   Accuracy: 39907/60000 (66.51%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6684,                   Accuracy: 47924/60000 (79.87%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2262,                   Accuracy: 55723/60000 (92.87%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0771,                   Accuracy: 58576/60000 (97.63%)
{0: tensor(98.7017), 10: tensor(97.9267), 20: tensor(95.5350), 30: tensor(89.4700), 40: tensor(79.4650), 50: tensor(73.2883), 60: tensor(74.1283), 70: tensor(79.0417), 80: tensor(83.4933), 90: tensor(82.7883), 100: tensor(72.6150), 110: tensor(60.1233), 120: tensor(48.1733), 130: tensor(40.2000), 140: tensor(38.2400), 150: tensor(41.1583), 160: tensor(48.2383), 170: tensor(51.9567), 180: tensor(52.3583), 190: tensor(50.6850), 200: tensor(47.5067), 210: tensor(42.8833), 220: tensor(40.7817), 230: tensor(44.8467), 240: tensor(56.9450), 250: tensor(70.6000), 260: tensor(81.1783), 270: tensor(88.6000), 280: tensor(84.3900), 290: tensor(76.4867), 300: tensor(66.6217), 310: tensor(62.3033), 320: tensor(66.5117), 330: tensor(79.8733), 340: tensor(92.8717), 350: tensor(97.6267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=88, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9129,                   Accuracy: 433/2000.0 (21.65%)



-= Testing valid =-
Test set: Average loss: 1.3795,                   Accuracy: 1092/2000.0 (54.60%)



-= Testing valid =-
Test set: Average loss: 0.8500,                   Accuracy: 1396/2000.0 (69.80%)



-= Testing valid =-
Test set: Average loss: 0.5936,                   Accuracy: 1622/2000.0 (81.10%)



-= Testing valid =-
Test set: Average loss: 0.1962,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1124,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1353,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1130,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1801,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 10 train accuracy: 97.68%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0486,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0486,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 20 train accuracy: 99.05%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.43%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.56%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.64%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0498,                   Accuracy: 59152/60000 (98.59%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0786,                   Accuracy: 58618/60000 (97.70%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1772,                   Accuracy: 56928/60000 (94.88%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4161,                   Accuracy: 52863/60000 (88.11%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7074,                   Accuracy: 48021/60000 (80.04%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8356,                   Accuracy: 45730/60000 (76.22%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7017,                   Accuracy: 47741/60000 (79.57%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.4624,                   Accuracy: 51484/60000 (85.81%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3529,                   Accuracy: 53165/60000 (88.61%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4019,                   Accuracy: 51726/60000 (86.21%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6573,                   Accuracy: 47439/60000 (79.07%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3222,                   Accuracy: 39107/60000 (65.18%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.3320,                   Accuracy: 30473/60000 (50.79%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.2284,                   Accuracy: 25126/60000 (41.88%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.6215,                   Accuracy: 23687/60000 (39.48%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.5311,                   Accuracy: 25502/60000 (42.50%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.2453,                   Accuracy: 29287/60000 (48.81%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.1130,                   Accuracy: 31337/60000 (52.23%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.0950,                   Accuracy: 32554/60000 (54.26%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.1391,                   Accuracy: 31870/60000 (53.12%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.1546,                   Accuracy: 29964/60000 (49.94%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4313,                   Accuracy: 27107/60000 (45.18%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.3372,                   Accuracy: 25968/60000 (43.28%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7863,                   Accuracy: 28142/60000 (46.90%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.8733,                   Accuracy: 34443/60000 (57.40%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0803,                   Accuracy: 42478/60000 (70.80%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5886,                   Accuracy: 48788/60000 (81.31%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3722,                   Accuracy: 52191/60000 (86.99%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4706,                   Accuracy: 50472/60000 (84.12%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7310,                   Accuracy: 45473/60000 (75.79%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1396,                   Accuracy: 39932/60000 (66.55%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3428,                   Accuracy: 37044/60000 (61.74%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1520,                   Accuracy: 40527/60000 (67.54%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6291,                   Accuracy: 48859/60000 (81.43%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2137,                   Accuracy: 56011/60000 (93.35%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0803,                   Accuracy: 58590/60000 (97.65%)
{0: tensor(98.5867), 10: tensor(97.6967), 20: tensor(94.8800), 30: tensor(88.1050), 40: tensor(80.0350), 50: tensor(76.2167), 60: tensor(79.5683), 70: tensor(85.8067), 80: tensor(88.6083), 90: tensor(86.2100), 100: tensor(79.0650), 110: tensor(65.1783), 120: tensor(50.7883), 130: tensor(41.8767), 140: tensor(39.4783), 150: tensor(42.5033), 160: tensor(48.8117), 170: tensor(52.2283), 180: tensor(54.2567), 190: tensor(53.1167), 200: tensor(49.9400), 210: tensor(45.1783), 220: tensor(43.2800), 230: tensor(46.9033), 240: tensor(57.4050), 250: tensor(70.7967), 260: tensor(81.3133), 270: tensor(86.9850), 280: tensor(84.1200), 290: tensor(75.7883), 300: tensor(66.5533), 310: tensor(61.7400), 320: tensor(67.5450), 330: tensor(81.4317), 340: tensor(93.3517), 350: tensor(97.6500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=89, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.4449,                   Accuracy: 221/2000.0 (11.05%)



-= Testing valid =-
Test set: Average loss: 3.0963,                   Accuracy: 349/2000.0 (17.45%)



-= Testing valid =-
Test set: Average loss: 2.2558,                   Accuracy: 608/2000.0 (30.40%)



-= Testing valid =-
Test set: Average loss: 0.2702,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.1876,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1238,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1588,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1455,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1416,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1865,                   Accuracy: 1895/2000.0 (94.75%)



Epoch 10 train accuracy: 97.86%, valid accuracy 94.75%
-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0579,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 20 train accuracy: 99.09%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0469,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.39%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.60%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.60%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0540,                   Accuracy: 59088/60000 (98.48%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0804,                   Accuracy: 58637/60000 (97.73%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1879,                   Accuracy: 56839/60000 (94.73%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4589,                   Accuracy: 52546/60000 (87.58%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7040,                   Accuracy: 48486/60000 (80.81%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8192,                   Accuracy: 46381/60000 (77.30%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6919,                   Accuracy: 48177/60000 (80.29%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.4318,                   Accuracy: 52379/60000 (87.30%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2737,                   Accuracy: 54996/60000 (91.66%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2683,                   Accuracy: 55067/60000 (91.78%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.4555,                   Accuracy: 51234/60000 (85.39%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.9493,                   Accuracy: 43093/60000 (71.82%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.6906,                   Accuracy: 34371/60000 (57.28%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.4514,                   Accuracy: 27663/60000 (46.10%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.7757,                   Accuracy: 25665/60000 (42.78%)
-= Testing Rotation 150 =-
Test set: Average loss: 2.7289,                   Accuracy: 26879/60000 (44.80%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.4383,                   Accuracy: 31959/60000 (53.26%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.2376,                   Accuracy: 36392/60000 (60.65%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.3213,                   Accuracy: 36597/60000 (60.99%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.2860,                   Accuracy: 35321/60000 (58.87%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.5504,                   Accuracy: 31318/60000 (52.20%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.9369,                   Accuracy: 26789/60000 (44.65%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.8485,                   Accuracy: 25914/60000 (43.19%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.3910,                   Accuracy: 28815/60000 (48.03%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.6060,                   Accuracy: 35660/60000 (59.43%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.8447,                   Accuracy: 44525/60000 (74.21%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.4489,                   Accuracy: 50920/60000 (84.87%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3068,                   Accuracy: 53222/60000 (88.70%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3135,                   Accuracy: 53919/60000 (89.86%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.5262,                   Accuracy: 49933/60000 (83.22%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9363,                   Accuracy: 42341/60000 (70.57%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0937,                   Accuracy: 40003/60000 (66.67%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0088,                   Accuracy: 41605/60000 (69.34%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6289,                   Accuracy: 48007/60000 (80.01%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2370,                   Accuracy: 55423/60000 (92.37%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0799,                   Accuracy: 58582/60000 (97.64%)
{0: tensor(98.4800), 10: tensor(97.7283), 20: tensor(94.7317), 30: tensor(87.5767), 40: tensor(80.8100), 50: tensor(77.3017), 60: tensor(80.2950), 70: tensor(87.2983), 80: tensor(91.6600), 90: tensor(91.7783), 100: tensor(85.3900), 110: tensor(71.8217), 120: tensor(57.2850), 130: tensor(46.1050), 140: tensor(42.7750), 150: tensor(44.7983), 160: tensor(53.2650), 170: tensor(60.6533), 180: tensor(60.9950), 190: tensor(58.8683), 200: tensor(52.1967), 210: tensor(44.6483), 220: tensor(43.1900), 230: tensor(48.0250), 240: tensor(59.4333), 250: tensor(74.2083), 260: tensor(84.8667), 270: tensor(88.7033), 280: tensor(89.8650), 290: tensor(83.2217), 300: tensor(70.5683), 310: tensor(66.6717), 320: tensor(69.3417), 330: tensor(80.0117), 340: tensor(92.3717), 350: tensor(97.6367)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=90, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1022,                   Accuracy: 481/2000.0 (24.05%)



-= Testing valid =-
Test set: Average loss: 1.4670,                   Accuracy: 901/2000.0 (45.05%)



-= Testing valid =-
Test set: Average loss: 0.4321,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.1605,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1220,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 10 train accuracy: 98.07%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 20 train accuracy: 99.10%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 30 train accuracy: 99.34%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.55%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 50 train accuracy: 99.71%, valid accuracy 99.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0516,                   Accuracy: 59137/60000 (98.56%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0776,                   Accuracy: 58690/60000 (97.82%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1760,                   Accuracy: 56990/60000 (94.98%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4567,                   Accuracy: 52449/60000 (87.42%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8271,                   Accuracy: 46068/60000 (76.78%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0049,                   Accuracy: 42665/60000 (71.11%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8912,                   Accuracy: 43767/60000 (72.94%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6072,                   Accuracy: 47877/60000 (79.79%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4582,                   Accuracy: 50025/60000 (83.38%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4127,                   Accuracy: 50846/60000 (84.74%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6083,                   Accuracy: 47882/60000 (79.80%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1319,                   Accuracy: 40800/60000 (68.00%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0080,                   Accuracy: 31718/60000 (52.86%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8560,                   Accuracy: 25812/60000 (43.02%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.1967,                   Accuracy: 24298/60000 (40.50%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.0060,                   Accuracy: 26230/60000 (43.72%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.5955,                   Accuracy: 30435/60000 (50.72%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.4126,                   Accuracy: 33162/60000 (55.27%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.3192,                   Accuracy: 33842/60000 (56.40%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.4053,                   Accuracy: 33324/60000 (55.54%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.6967,                   Accuracy: 30013/60000 (50.02%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.1462,                   Accuracy: 25945/60000 (43.24%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.1339,                   Accuracy: 25252/60000 (42.09%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.5801,                   Accuracy: 28769/60000 (47.95%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.6927,                   Accuracy: 36080/60000 (60.13%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.8416,                   Accuracy: 46233/60000 (77.06%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3911,                   Accuracy: 53028/60000 (88.38%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2263,                   Accuracy: 55987/60000 (93.31%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2841,                   Accuracy: 55010/60000 (91.68%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.4961,                   Accuracy: 51479/60000 (85.80%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.8459,                   Accuracy: 45903/60000 (76.50%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1085,                   Accuracy: 41525/60000 (69.21%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0443,                   Accuracy: 42973/60000 (71.62%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6416,                   Accuracy: 49093/60000 (81.82%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2338,                   Accuracy: 55814/60000 (93.02%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0831,                   Accuracy: 58531/60000 (97.55%)
{0: tensor(98.5617), 10: tensor(97.8167), 20: tensor(94.9833), 30: tensor(87.4150), 40: tensor(76.7800), 50: tensor(71.1083), 60: tensor(72.9450), 70: tensor(79.7950), 80: tensor(83.3750), 90: tensor(84.7433), 100: tensor(79.8033), 110: tensor(68.), 120: tensor(52.8633), 130: tensor(43.0200), 140: tensor(40.4967), 150: tensor(43.7167), 160: tensor(50.7250), 170: tensor(55.2700), 180: tensor(56.4033), 190: tensor(55.5400), 200: tensor(50.0217), 210: tensor(43.2417), 220: tensor(42.0867), 230: tensor(47.9483), 240: tensor(60.1333), 250: tensor(77.0550), 260: tensor(88.3800), 270: tensor(93.3117), 280: tensor(91.6833), 290: tensor(85.7983), 300: tensor(76.5050), 310: tensor(69.2083), 320: tensor(71.6217), 330: tensor(81.8217), 340: tensor(93.0233), 350: tensor(97.5517)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=91, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.5149,                   Accuracy: 213/2000.0 (10.65%)



-= Testing valid =-
Test set: Average loss: 1.8576,                   Accuracy: 780/2000.0 (39.00%)



-= Testing valid =-
Test set: Average loss: 2.8406,                   Accuracy: 622/2000.0 (31.10%)



-= Testing valid =-
Test set: Average loss: 0.2936,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.1860,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.7446,                   Accuracy: 1494/2000.0 (74.70%)



-= Testing valid =-
Test set: Average loss: 0.1544,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.2586,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2182,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.3284,                   Accuracy: 1701/2000.0 (85.05%)



Epoch 10 train accuracy: 98.32%, valid accuracy 85.05%
-= Testing valid =-
Test set: Average loss: 0.1713,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.1433,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.2876,                   Accuracy: 1747/2000.0 (87.35%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.1272,                   Accuracy: 1901/2000.0 (95.05%)



Epoch 20 train accuracy: 99.09%, valid accuracy 95.05%
-= Testing valid =-
Test set: Average loss: 0.0585,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0712,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.1079,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1197,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1530,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 30 train accuracy: 99.40%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0552,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0575,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.0629,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 40 train accuracy: 99.47%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0535,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 50 train accuracy: 99.59%, valid accuracy 98.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0727,                   Accuracy: 58663/60000 (97.77%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1062,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2061,                   Accuracy: 56332/60000 (93.89%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5264,                   Accuracy: 50737/60000 (84.56%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9691,                   Accuracy: 43610/60000 (72.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2494,                   Accuracy: 39089/60000 (65.15%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2417,                   Accuracy: 38901/60000 (64.83%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9764,                   Accuracy: 42665/60000 (71.11%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8750,                   Accuracy: 44368/60000 (73.95%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.9238,                   Accuracy: 45029/60000 (75.05%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.4803,                   Accuracy: 39259/60000 (65.43%)
-= Testing Rotation 110 =-
Test set: Average loss: 2.1996,                   Accuracy: 33219/60000 (55.37%)
-= Testing Rotation 120 =-
Test set: Average loss: 3.1298,                   Accuracy: 26246/60000 (43.74%)
-= Testing Rotation 130 =-
Test set: Average loss: 4.0545,                   Accuracy: 22446/60000 (37.41%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.5493,                   Accuracy: 21949/60000 (36.58%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.8382,                   Accuracy: 22514/60000 (37.52%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.9929,                   Accuracy: 24881/60000 (41.47%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.9120,                   Accuracy: 26355/60000 (43.92%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.7641,                   Accuracy: 27167/60000 (45.28%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.9906,                   Accuracy: 27138/60000 (45.23%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.0125,                   Accuracy: 24923/60000 (41.54%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.8236,                   Accuracy: 22556/60000 (37.59%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.5510,                   Accuracy: 21851/60000 (36.42%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.8150,                   Accuracy: 23135/60000 (38.56%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.8399,                   Accuracy: 26777/60000 (44.63%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.9340,                   Accuracy: 33199/60000 (55.33%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.3790,                   Accuracy: 38028/60000 (63.38%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.9680,                   Accuracy: 42370/60000 (70.62%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.0234,                   Accuracy: 41628/60000 (69.38%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.2332,                   Accuracy: 39537/60000 (65.89%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.5325,                   Accuracy: 37899/60000 (63.17%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.7542,                   Accuracy: 36948/60000 (61.58%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.4893,                   Accuracy: 40673/60000 (67.79%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9019,                   Accuracy: 47722/60000 (79.54%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3061,                   Accuracy: 55187/60000 (91.98%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1162,                   Accuracy: 57948/60000 (96.58%)
{0: tensor(97.7717), 10: tensor(96.8917), 20: tensor(93.8867), 30: tensor(84.5617), 40: tensor(72.6833), 50: tensor(65.1483), 60: tensor(64.8350), 70: tensor(71.1083), 80: tensor(73.9467), 90: tensor(75.0483), 100: tensor(65.4317), 110: tensor(55.3650), 120: tensor(43.7433), 130: tensor(37.4100), 140: tensor(36.5817), 150: tensor(37.5233), 160: tensor(41.4683), 170: tensor(43.9250), 180: tensor(45.2783), 190: tensor(45.2300), 200: tensor(41.5383), 210: tensor(37.5933), 220: tensor(36.4183), 230: tensor(38.5583), 240: tensor(44.6283), 250: tensor(55.3317), 260: tensor(63.3800), 270: tensor(70.6167), 280: tensor(69.3800), 290: tensor(65.8950), 300: tensor(63.1650), 310: tensor(61.5800), 320: tensor(67.7883), 330: tensor(79.5367), 340: tensor(91.9783), 350: tensor(96.5800)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=92, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.6568,                   Accuracy: 231/2000.0 (11.55%)



-= Testing valid =-
Test set: Average loss: 1.5456,                   Accuracy: 886/2000.0 (44.30%)



-= Testing valid =-
Test set: Average loss: 0.5381,                   Accuracy: 1729/2000.0 (86.45%)



-= Testing valid =-
Test set: Average loss: 0.5126,                   Accuracy: 1662/2000.0 (83.10%)



-= Testing valid =-
Test set: Average loss: 0.6518,                   Accuracy: 1568/2000.0 (78.40%)



-= Testing valid =-
Test set: Average loss: 0.1812,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.3057,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.8512,                   Accuracy: 1412/2000.0 (70.60%)



-= Testing valid =-
Test set: Average loss: 0.2056,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1254,                   Accuracy: 1918/2000.0 (95.90%)



Epoch 10 train accuracy: 97.71%, valid accuracy 95.90%
-= Testing valid =-
Test set: Average loss: 0.1339,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.3325,                   Accuracy: 1722/2000.0 (86.10%)



-= Testing valid =-
Test set: Average loss: 0.1432,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 20 train accuracy: 98.84%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0633,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.1097,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0617,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0575,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 30 train accuracy: 99.34%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0628,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 40 train accuracy: 99.43%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 50 train accuracy: 99.46%, valid accuracy 98.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0550,                   Accuracy: 59039/60000 (98.40%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0807,                   Accuracy: 58629/60000 (97.71%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2146,                   Accuracy: 56434/60000 (94.06%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6313,                   Accuracy: 50333/60000 (83.89%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.1451,                   Accuracy: 43292/60000 (72.15%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.4451,                   Accuracy: 38363/60000 (63.94%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2891,                   Accuracy: 38168/60000 (63.61%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9201,                   Accuracy: 42287/60000 (70.48%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6020,                   Accuracy: 47373/60000 (78.96%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5675,                   Accuracy: 47763/60000 (79.61%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8478,                   Accuracy: 42875/60000 (71.46%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.4552,                   Accuracy: 34961/60000 (58.27%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.3616,                   Accuracy: 25735/60000 (42.89%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.1500,                   Accuracy: 21888/60000 (36.48%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.5691,                   Accuracy: 20996/60000 (34.99%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4147,                   Accuracy: 24185/60000 (40.31%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.1006,                   Accuracy: 28879/60000 (48.13%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.9994,                   Accuracy: 31327/60000 (52.21%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.9761,                   Accuracy: 32487/60000 (54.15%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.0682,                   Accuracy: 31387/60000 (52.31%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.1125,                   Accuracy: 28613/60000 (47.69%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.3226,                   Accuracy: 24653/60000 (41.09%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.3399,                   Accuracy: 22865/60000 (38.11%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9612,                   Accuracy: 24777/60000 (41.29%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.1772,                   Accuracy: 31094/60000 (51.82%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.4514,                   Accuracy: 38750/60000 (64.58%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7213,                   Accuracy: 47323/60000 (78.87%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4383,                   Accuracy: 51545/60000 (85.91%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5711,                   Accuracy: 48783/60000 (81.31%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9833,                   Accuracy: 41807/60000 (69.68%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.4786,                   Accuracy: 34387/60000 (57.31%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.6321,                   Accuracy: 33260/60000 (55.43%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.5407,                   Accuracy: 36240/60000 (60.40%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9479,                   Accuracy: 44972/60000 (74.95%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3456,                   Accuracy: 54231/60000 (90.39%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0956,                   Accuracy: 58261/60000 (97.10%)
{0: tensor(98.3983), 10: tensor(97.7150), 20: tensor(94.0567), 30: tensor(83.8883), 40: tensor(72.1533), 50: tensor(63.9383), 60: tensor(63.6133), 70: tensor(70.4783), 80: tensor(78.9550), 90: tensor(79.6050), 100: tensor(71.4583), 110: tensor(58.2683), 120: tensor(42.8917), 130: tensor(36.4800), 140: tensor(34.9933), 150: tensor(40.3083), 160: tensor(48.1317), 170: tensor(52.2117), 180: tensor(54.1450), 190: tensor(52.3117), 200: tensor(47.6883), 210: tensor(41.0883), 220: tensor(38.1083), 230: tensor(41.2950), 240: tensor(51.8233), 250: tensor(64.5833), 260: tensor(78.8717), 270: tensor(85.9083), 280: tensor(81.3050), 290: tensor(69.6783), 300: tensor(57.3117), 310: tensor(55.4333), 320: tensor(60.4000), 330: tensor(74.9533), 340: tensor(90.3850), 350: tensor(97.1017)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=93, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.5863,                   Accuracy: 872/2000.0 (43.60%)



-= Testing valid =-
Test set: Average loss: 2.4787,                   Accuracy: 465/2000.0 (23.25%)



-= Testing valid =-
Test set: Average loss: 1.2708,                   Accuracy: 1116/2000.0 (55.80%)



-= Testing valid =-
Test set: Average loss: 0.4842,                   Accuracy: 1685/2000.0 (84.25%)



-= Testing valid =-
Test set: Average loss: 0.5478,                   Accuracy: 1659/2000.0 (82.95%)



-= Testing valid =-
Test set: Average loss: 0.1192,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1384,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.1870,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1727,                   Accuracy: 1903/2000.0 (95.15%)



Epoch 10 train accuracy: 98.00%, valid accuracy 95.15%
-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0644,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0477,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0585,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 20 train accuracy: 99.19%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 30 train accuracy: 99.35%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.57%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.60%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0542,                   Accuracy: 59059/60000 (98.43%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0807,                   Accuracy: 58582/60000 (97.64%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1779,                   Accuracy: 56893/60000 (94.82%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4860,                   Accuracy: 51657/60000 (86.10%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9687,                   Accuracy: 44139/60000 (73.57%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.3220,                   Accuracy: 38235/60000 (63.72%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2076,                   Accuracy: 39194/60000 (65.32%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9087,                   Accuracy: 44067/60000 (73.44%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6839,                   Accuracy: 47315/60000 (78.86%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7051,                   Accuracy: 47626/60000 (79.38%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9550,                   Accuracy: 44329/60000 (73.88%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6526,                   Accuracy: 37736/60000 (62.89%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.7623,                   Accuracy: 30053/60000 (50.09%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.8053,                   Accuracy: 25628/60000 (42.71%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.4892,                   Accuracy: 24918/60000 (41.53%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.6565,                   Accuracy: 26761/60000 (44.60%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.6442,                   Accuracy: 30133/60000 (50.22%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.7427,                   Accuracy: 31767/60000 (52.94%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.7903,                   Accuracy: 32202/60000 (53.67%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.7037,                   Accuracy: 31639/60000 (52.73%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.7584,                   Accuracy: 29624/60000 (49.37%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.7048,                   Accuracy: 26412/60000 (44.02%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.3721,                   Accuracy: 23837/60000 (39.73%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.7517,                   Accuracy: 23570/60000 (39.28%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.7769,                   Accuracy: 27355/60000 (45.59%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.9043,                   Accuracy: 33270/60000 (55.45%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.2787,                   Accuracy: 38067/60000 (63.44%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.9709,                   Accuracy: 41265/60000 (68.78%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.1094,                   Accuracy: 38096/60000 (63.49%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.4245,                   Accuracy: 34313/60000 (57.19%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.8449,                   Accuracy: 30280/60000 (50.47%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.8412,                   Accuracy: 31817/60000 (53.03%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.4835,                   Accuracy: 37544/60000 (62.57%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7892,                   Accuracy: 47055/60000 (78.43%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2446,                   Accuracy: 55663/60000 (92.77%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0826,                   Accuracy: 58514/60000 (97.52%)
{0: tensor(98.4317), 10: tensor(97.6367), 20: tensor(94.8217), 30: tensor(86.0950), 40: tensor(73.5650), 50: tensor(63.7250), 60: tensor(65.3233), 70: tensor(73.4450), 80: tensor(78.8583), 90: tensor(79.3767), 100: tensor(73.8817), 110: tensor(62.8933), 120: tensor(50.0883), 130: tensor(42.7133), 140: tensor(41.5300), 150: tensor(44.6017), 160: tensor(50.2217), 170: tensor(52.9450), 180: tensor(53.6700), 190: tensor(52.7317), 200: tensor(49.3733), 210: tensor(44.0200), 220: tensor(39.7283), 230: tensor(39.2833), 240: tensor(45.5917), 250: tensor(55.4500), 260: tensor(63.4450), 270: tensor(68.7750), 280: tensor(63.4933), 290: tensor(57.1883), 300: tensor(50.4667), 310: tensor(53.0283), 320: tensor(62.5733), 330: tensor(78.4250), 340: tensor(92.7717), 350: tensor(97.5233)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=94, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1168,                   Accuracy: 566/2000.0 (28.30%)



-= Testing valid =-
Test set: Average loss: 0.8845,                   Accuracy: 1454/2000.0 (72.70%)



-= Testing valid =-
Test set: Average loss: 3.4505,                   Accuracy: 458/2000.0 (22.90%)



-= Testing valid =-
Test set: Average loss: 0.3173,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 1.2722,                   Accuracy: 1282/2000.0 (64.10%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0937,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.2855,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.1648,                   Accuracy: 1913/2000.0 (95.65%)



Epoch 10 train accuracy: 98.40%, valid accuracy 95.65%
-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.3286,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.3240,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1935,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 20 train accuracy: 99.24%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.1599,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1784,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.0547,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.2834,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 30 train accuracy: 99.62%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0618,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0454,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 40 train accuracy: 99.69%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0600,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0600,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 50 train accuracy: 99.75%, valid accuracy 98.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0701,                   Accuracy: 58781/60000 (97.97%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0959,                   Accuracy: 58345/60000 (97.24%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1973,                   Accuracy: 56541/60000 (94.24%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5866,                   Accuracy: 50677/60000 (84.46%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0687,                   Accuracy: 44017/60000 (73.36%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.3310,                   Accuracy: 40063/60000 (66.77%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1901,                   Accuracy: 41257/60000 (68.76%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7564,                   Accuracy: 46916/60000 (78.19%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4937,                   Accuracy: 50497/60000 (84.16%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4727,                   Accuracy: 49769/60000 (82.95%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6159,                   Accuracy: 47209/60000 (78.68%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.0257,                   Accuracy: 41503/60000 (69.17%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.8288,                   Accuracy: 33226/60000 (55.38%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.7153,                   Accuracy: 27701/60000 (46.17%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.1355,                   Accuracy: 25532/60000 (42.55%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.1016,                   Accuracy: 26383/60000 (43.97%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.8015,                   Accuracy: 29933/60000 (49.89%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.7004,                   Accuracy: 32510/60000 (54.18%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.6324,                   Accuracy: 32658/60000 (54.43%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.7538,                   Accuracy: 30958/60000 (51.60%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.9384,                   Accuracy: 29251/60000 (48.75%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.2799,                   Accuracy: 26272/60000 (43.79%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.2326,                   Accuracy: 25672/60000 (42.79%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7750,                   Accuracy: 27212/60000 (45.35%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9172,                   Accuracy: 32783/60000 (54.64%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1222,                   Accuracy: 40305/60000 (67.18%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7011,                   Accuracy: 45083/60000 (75.14%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5642,                   Accuracy: 48113/60000 (80.19%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5924,                   Accuracy: 46869/60000 (78.11%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8101,                   Accuracy: 43367/60000 (72.28%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3075,                   Accuracy: 36986/60000 (61.64%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.5623,                   Accuracy: 34309/60000 (57.18%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3398,                   Accuracy: 37059/60000 (61.76%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7492,                   Accuracy: 46227/60000 (77.04%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2521,                   Accuracy: 55188/60000 (91.98%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0953,                   Accuracy: 58309/60000 (97.18%)
{0: tensor(97.9683), 10: tensor(97.2417), 20: tensor(94.2350), 30: tensor(84.4617), 40: tensor(73.3617), 50: tensor(66.7717), 60: tensor(68.7617), 70: tensor(78.1933), 80: tensor(84.1617), 90: tensor(82.9483), 100: tensor(78.6817), 110: tensor(69.1717), 120: tensor(55.3767), 130: tensor(46.1683), 140: tensor(42.5533), 150: tensor(43.9717), 160: tensor(49.8883), 170: tensor(54.1833), 180: tensor(54.4300), 190: tensor(51.5967), 200: tensor(48.7517), 210: tensor(43.7867), 220: tensor(42.7867), 230: tensor(45.3533), 240: tensor(54.6383), 250: tensor(67.1750), 260: tensor(75.1383), 270: tensor(80.1883), 280: tensor(78.1150), 290: tensor(72.2783), 300: tensor(61.6433), 310: tensor(57.1817), 320: tensor(61.7650), 330: tensor(77.0450), 340: tensor(91.9800), 350: tensor(97.1817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=95, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8967,                   Accuracy: 543/2000.0 (27.15%)



-= Testing valid =-
Test set: Average loss: 1.6273,                   Accuracy: 766/2000.0 (38.30%)



-= Testing valid =-
Test set: Average loss: 1.5573,                   Accuracy: 979/2000.0 (48.95%)



-= Testing valid =-
Test set: Average loss: 0.2849,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.1398,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.2117,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.2210,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.1730,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1639,                   Accuracy: 1910/2000.0 (95.50%)



Epoch 10 train accuracy: 98.14%, valid accuracy 95.50%
-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0711,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0608,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 20 train accuracy: 99.19%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 30 train accuracy: 99.45%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.60%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 50 train accuracy: 99.61%, valid accuracy 98.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0584,                   Accuracy: 59016/60000 (98.36%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0825,                   Accuracy: 58591/60000 (97.65%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1767,                   Accuracy: 57021/60000 (95.04%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4308,                   Accuracy: 52546/60000 (87.58%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7951,                   Accuracy: 46191/60000 (76.99%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0415,                   Accuracy: 41620/60000 (69.37%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9736,                   Accuracy: 42499/60000 (70.83%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7284,                   Accuracy: 46820/60000 (78.03%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5600,                   Accuracy: 49456/60000 (82.43%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5333,                   Accuracy: 50150/60000 (83.58%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7672,                   Accuracy: 46086/60000 (76.81%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2340,                   Accuracy: 39897/60000 (66.50%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0422,                   Accuracy: 31114/60000 (51.86%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.9286,                   Accuracy: 24619/60000 (41.03%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.5226,                   Accuracy: 22283/60000 (37.14%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.7944,                   Accuracy: 23059/60000 (38.43%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.8019,                   Accuracy: 25559/60000 (42.60%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.7989,                   Accuracy: 27409/60000 (45.68%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.8451,                   Accuracy: 28583/60000 (47.64%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.8419,                   Accuracy: 28088/60000 (46.81%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.0156,                   Accuracy: 26181/60000 (43.63%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.0569,                   Accuracy: 24024/60000 (40.04%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.9091,                   Accuracy: 22651/60000 (37.75%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.4380,                   Accuracy: 23493/60000 (39.15%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.5977,                   Accuracy: 27971/60000 (46.62%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.7018,                   Accuracy: 35000/60000 (58.33%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.0730,                   Accuracy: 41067/60000 (68.44%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6760,                   Accuracy: 46604/60000 (77.67%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6635,                   Accuracy: 46897/60000 (78.16%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8458,                   Accuracy: 44552/60000 (74.25%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1482,                   Accuracy: 41238/60000 (68.73%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3326,                   Accuracy: 39117/60000 (65.19%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2157,                   Accuracy: 41365/60000 (68.94%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7130,                   Accuracy: 48429/60000 (80.71%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2392,                   Accuracy: 55724/60000 (92.87%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0865,                   Accuracy: 58463/60000 (97.44%)
{0: tensor(98.3600), 10: tensor(97.6517), 20: tensor(95.0350), 30: tensor(87.5767), 40: tensor(76.9850), 50: tensor(69.3667), 60: tensor(70.8317), 70: tensor(78.0333), 80: tensor(82.4267), 90: tensor(83.5833), 100: tensor(76.8100), 110: tensor(66.4950), 120: tensor(51.8567), 130: tensor(41.0317), 140: tensor(37.1383), 150: tensor(38.4317), 160: tensor(42.5983), 170: tensor(45.6817), 180: tensor(47.6383), 190: tensor(46.8133), 200: tensor(43.6350), 210: tensor(40.0400), 220: tensor(37.7517), 230: tensor(39.1550), 240: tensor(46.6183), 250: tensor(58.3333), 260: tensor(68.4450), 270: tensor(77.6733), 280: tensor(78.1617), 290: tensor(74.2533), 300: tensor(68.7300), 310: tensor(65.1950), 320: tensor(68.9417), 330: tensor(80.7150), 340: tensor(92.8733), 350: tensor(97.4383)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=96, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7196,                   Accuracy: 680/2000.0 (34.00%)



-= Testing valid =-
Test set: Average loss: 1.1966,                   Accuracy: 1061/2000.0 (53.05%)



-= Testing valid =-
Test set: Average loss: 0.5774,                   Accuracy: 1615/2000.0 (80.75%)



-= Testing valid =-
Test set: Average loss: 0.1396,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1715,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1208,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1117,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1965,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 10 train accuracy: 97.71%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0567,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0621,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.1074,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 20 train accuracy: 99.07%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.36%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 40 train accuracy: 99.60%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.71%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0501,                   Accuracy: 59105/60000 (98.51%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0792,                   Accuracy: 58607/60000 (97.68%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1722,                   Accuracy: 57030/60000 (95.05%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4063,                   Accuracy: 52741/60000 (87.90%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7665,                   Accuracy: 46600/60000 (77.67%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9993,                   Accuracy: 42722/60000 (71.20%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9314,                   Accuracy: 43478/60000 (72.46%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6888,                   Accuracy: 47063/60000 (78.44%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5569,                   Accuracy: 48765/60000 (81.28%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5924,                   Accuracy: 48171/60000 (80.29%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8818,                   Accuracy: 43370/60000 (72.28%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3280,                   Accuracy: 38146/60000 (63.58%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.8776,                   Accuracy: 31745/60000 (52.91%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.4239,                   Accuracy: 26827/60000 (44.71%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.7194,                   Accuracy: 25347/60000 (42.24%)
-= Testing Rotation 150 =-
Test set: Average loss: 2.8845,                   Accuracy: 25961/60000 (43.27%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.9369,                   Accuracy: 28985/60000 (48.31%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.9675,                   Accuracy: 30540/60000 (50.90%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.0288,                   Accuracy: 30674/60000 (51.12%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.1250,                   Accuracy: 30517/60000 (50.86%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.1736,                   Accuracy: 29071/60000 (48.45%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.3614,                   Accuracy: 26001/60000 (43.33%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.3475,                   Accuracy: 24384/60000 (40.64%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8613,                   Accuracy: 26068/60000 (43.45%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0475,                   Accuracy: 31313/60000 (52.19%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2707,                   Accuracy: 39198/60000 (65.33%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8121,                   Accuracy: 45272/60000 (75.45%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6409,                   Accuracy: 47762/60000 (79.60%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6933,                   Accuracy: 47129/60000 (78.55%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8364,                   Accuracy: 44987/60000 (74.98%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9574,                   Accuracy: 42589/60000 (70.98%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9659,                   Accuracy: 42022/60000 (70.04%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8407,                   Accuracy: 44243/60000 (73.74%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5140,                   Accuracy: 50025/60000 (83.38%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2048,                   Accuracy: 55999/60000 (93.33%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0799,                   Accuracy: 58529/60000 (97.55%)
{0: tensor(98.5083), 10: tensor(97.6783), 20: tensor(95.0500), 30: tensor(87.9017), 40: tensor(77.6667), 50: tensor(71.2033), 60: tensor(72.4633), 70: tensor(78.4383), 80: tensor(81.2750), 90: tensor(80.2850), 100: tensor(72.2833), 110: tensor(63.5767), 120: tensor(52.9083), 130: tensor(44.7117), 140: tensor(42.2450), 150: tensor(43.2683), 160: tensor(48.3083), 170: tensor(50.9000), 180: tensor(51.1233), 190: tensor(50.8617), 200: tensor(48.4517), 210: tensor(43.3350), 220: tensor(40.6400), 230: tensor(43.4467), 240: tensor(52.1883), 250: tensor(65.3300), 260: tensor(75.4533), 270: tensor(79.6033), 280: tensor(78.5483), 290: tensor(74.9783), 300: tensor(70.9817), 310: tensor(70.0367), 320: tensor(73.7383), 330: tensor(83.3750), 340: tensor(93.3317), 350: tensor(97.5483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=97, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0819,                   Accuracy: 409/2000.0 (20.45%)



-= Testing valid =-
Test set: Average loss: 1.3352,                   Accuracy: 1063/2000.0 (53.15%)



-= Testing valid =-
Test set: Average loss: 1.0799,                   Accuracy: 1239/2000.0 (61.95%)



-= Testing valid =-
Test set: Average loss: 0.6547,                   Accuracy: 1564/2000.0 (78.20%)



-= Testing valid =-
Test set: Average loss: 0.6554,                   Accuracy: 1566/2000.0 (78.30%)



-= Testing valid =-
Test set: Average loss: 0.3105,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.1705,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1010,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1148,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 10 train accuracy: 97.97%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 20 train accuracy: 99.20%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0572,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 30 train accuracy: 99.56%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.65%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.70%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0566,                   Accuracy: 59024/60000 (98.37%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0770,                   Accuracy: 58669/60000 (97.78%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1519,                   Accuracy: 57440/60000 (95.73%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3786,                   Accuracy: 53474/60000 (89.12%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.6438,                   Accuracy: 48688/60000 (81.15%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.7772,                   Accuracy: 45871/60000 (76.45%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7902,                   Accuracy: 45272/60000 (75.45%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6129,                   Accuracy: 48226/60000 (80.38%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5019,                   Accuracy: 50131/60000 (83.55%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4983,                   Accuracy: 50141/60000 (83.57%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8094,                   Accuracy: 45520/60000 (75.87%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.4393,                   Accuracy: 38736/60000 (64.56%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.1925,                   Accuracy: 30648/60000 (51.08%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.9745,                   Accuracy: 26339/60000 (43.90%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3141,                   Accuracy: 25579/60000 (42.63%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.3782,                   Accuracy: 26853/60000 (44.76%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4218,                   Accuracy: 29659/60000 (49.43%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.3668,                   Accuracy: 30634/60000 (51.06%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.2856,                   Accuracy: 30121/60000 (50.20%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.5740,                   Accuracy: 29115/60000 (48.53%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7793,                   Accuracy: 27487/60000 (45.81%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.8241,                   Accuracy: 24820/60000 (41.37%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.4800,                   Accuracy: 24390/60000 (40.65%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8040,                   Accuracy: 26362/60000 (43.94%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9959,                   Accuracy: 31308/60000 (52.18%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3179,                   Accuracy: 37842/60000 (63.07%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8835,                   Accuracy: 42706/60000 (71.18%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6610,                   Accuracy: 45686/60000 (76.14%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7527,                   Accuracy: 44818/60000 (74.70%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9351,                   Accuracy: 42570/60000 (70.95%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1749,                   Accuracy: 39152/60000 (65.25%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1441,                   Accuracy: 40194/60000 (66.99%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8782,                   Accuracy: 44894/60000 (74.82%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5126,                   Accuracy: 51149/60000 (85.25%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1925,                   Accuracy: 56525/60000 (94.21%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0753,                   Accuracy: 58672/60000 (97.79%)
{0: tensor(98.3733), 10: tensor(97.7817), 20: tensor(95.7333), 30: tensor(89.1233), 40: tensor(81.1467), 50: tensor(76.4517), 60: tensor(75.4533), 70: tensor(80.3767), 80: tensor(83.5517), 90: tensor(83.5683), 100: tensor(75.8667), 110: tensor(64.5600), 120: tensor(51.0800), 130: tensor(43.8983), 140: tensor(42.6317), 150: tensor(44.7550), 160: tensor(49.4317), 170: tensor(51.0567), 180: tensor(50.2017), 190: tensor(48.5250), 200: tensor(45.8117), 210: tensor(41.3667), 220: tensor(40.6500), 230: tensor(43.9367), 240: tensor(52.1800), 250: tensor(63.0700), 260: tensor(71.1767), 270: tensor(76.1433), 280: tensor(74.6967), 290: tensor(70.9500), 300: tensor(65.2533), 310: tensor(66.9900), 320: tensor(74.8233), 330: tensor(85.2483), 340: tensor(94.2083), 350: tensor(97.7867)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=98, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2029,                   Accuracy: 363/2000.0 (18.15%)



-= Testing valid =-
Test set: Average loss: 6.5277,                   Accuracy: 186/2000.0 (9.30%)



-= Testing valid =-
Test set: Average loss: 1.6174,                   Accuracy: 857/2000.0 (42.85%)



-= Testing valid =-
Test set: Average loss: 1.2407,                   Accuracy: 1127/2000.0 (56.35%)



-= Testing valid =-
Test set: Average loss: 1.8641,                   Accuracy: 828/2000.0 (41.40%)



-= Testing valid =-
Test set: Average loss: 0.4286,                   Accuracy: 1717/2000.0 (85.85%)



-= Testing valid =-
Test set: Average loss: 0.2021,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1550,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.3101,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.5171,                   Accuracy: 1619/2000.0 (80.95%)



Epoch 10 train accuracy: 97.70%, valid accuracy 80.95%
-= Testing valid =-
Test set: Average loss: 0.7316,                   Accuracy: 1471/2000.0 (73.55%)



-= Testing valid =-
Test set: Average loss: 0.1487,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0752,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.2681,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.1759,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2028,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1518,                   Accuracy: 1905/2000.0 (95.25%)



Epoch 20 train accuracy: 99.05%, valid accuracy 95.25%
-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0585,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.1107,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1720,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 30 train accuracy: 99.31%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.1345,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1092,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1338,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 40 train accuracy: 99.62%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1495,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1914,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1235,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1358,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 50 train accuracy: 99.61%, valid accuracy 97.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0727,                   Accuracy: 58705/60000 (97.84%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1067,                   Accuracy: 58130/60000 (96.88%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2193,                   Accuracy: 56225/60000 (93.71%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4969,                   Accuracy: 51600/60000 (86.00%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8572,                   Accuracy: 45428/60000 (75.71%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1434,                   Accuracy: 39826/60000 (66.38%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0511,                   Accuracy: 40503/60000 (67.50%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8321,                   Accuracy: 44973/60000 (74.96%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7372,                   Accuracy: 46704/60000 (77.84%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.8179,                   Accuracy: 44358/60000 (73.93%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0939,                   Accuracy: 41060/60000 (68.43%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5115,                   Accuracy: 35415/60000 (59.03%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2588,                   Accuracy: 27901/60000 (46.50%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.9761,                   Accuracy: 23461/60000 (39.10%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.4661,                   Accuracy: 21972/60000 (36.62%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4979,                   Accuracy: 23767/60000 (39.61%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4510,                   Accuracy: 26562/60000 (44.27%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.3966,                   Accuracy: 28496/60000 (47.49%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.4240,                   Accuracy: 29567/60000 (49.28%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.5233,                   Accuracy: 29569/60000 (49.28%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.6285,                   Accuracy: 28616/60000 (47.69%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7070,                   Accuracy: 26789/60000 (44.65%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.4894,                   Accuracy: 25720/60000 (42.87%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.0407,                   Accuracy: 25682/60000 (42.80%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2939,                   Accuracy: 28966/60000 (48.28%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.5247,                   Accuracy: 36656/60000 (61.09%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9824,                   Accuracy: 42990/60000 (71.65%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7836,                   Accuracy: 44823/60000 (74.71%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7922,                   Accuracy: 45058/60000 (75.10%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9459,                   Accuracy: 41991/60000 (69.99%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3032,                   Accuracy: 36402/60000 (60.67%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3505,                   Accuracy: 35533/60000 (59.22%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1835,                   Accuracy: 38939/60000 (64.90%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6499,                   Accuracy: 48036/60000 (80.06%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2516,                   Accuracy: 55323/60000 (92.21%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1091,                   Accuracy: 58071/60000 (96.79%)
{0: tensor(97.8417), 10: tensor(96.8833), 20: tensor(93.7083), 30: tensor(86.), 40: tensor(75.7133), 50: tensor(66.3767), 60: tensor(67.5050), 70: tensor(74.9550), 80: tensor(77.8400), 90: tensor(73.9300), 100: tensor(68.4333), 110: tensor(59.0250), 120: tensor(46.5017), 130: tensor(39.1017), 140: tensor(36.6200), 150: tensor(39.6117), 160: tensor(44.2700), 170: tensor(47.4933), 180: tensor(49.2783), 190: tensor(49.2817), 200: tensor(47.6933), 210: tensor(44.6483), 220: tensor(42.8667), 230: tensor(42.8033), 240: tensor(48.2767), 250: tensor(61.0933), 260: tensor(71.6500), 270: tensor(74.7050), 280: tensor(75.0967), 290: tensor(69.9850), 300: tensor(60.6700), 310: tensor(59.2217), 320: tensor(64.8983), 330: tensor(80.0600), 340: tensor(92.2050), 350: tensor(96.7850)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=99, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3084,                   Accuracy: 371/2000.0 (18.55%)



-= Testing valid =-
Test set: Average loss: 1.3661,                   Accuracy: 967/2000.0 (48.35%)



-= Testing valid =-
Test set: Average loss: 1.4682,                   Accuracy: 970/2000.0 (48.50%)



-= Testing valid =-
Test set: Average loss: 0.3540,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.1624,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.4189,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.1854,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.1509,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 10 train accuracy: 98.20%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0645,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 20 train accuracy: 99.05%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.38%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.64%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.62%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0500,                   Accuracy: 59132/60000 (98.55%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0846,                   Accuracy: 58588/60000 (97.65%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1737,                   Accuracy: 57070/60000 (95.12%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3888,                   Accuracy: 53156/60000 (88.59%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.6733,                   Accuracy: 48251/60000 (80.42%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8086,                   Accuracy: 45964/60000 (76.61%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7272,                   Accuracy: 46838/60000 (78.06%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.5736,                   Accuracy: 49343/60000 (82.24%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4706,                   Accuracy: 50787/60000 (84.64%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4975,                   Accuracy: 50168/60000 (83.61%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8405,                   Accuracy: 45166/60000 (75.28%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3569,                   Accuracy: 39573/60000 (65.96%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.1196,                   Accuracy: 32147/60000 (53.58%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.9223,                   Accuracy: 26595/60000 (44.33%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3638,                   Accuracy: 24603/60000 (41.01%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4429,                   Accuracy: 25573/60000 (42.62%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.1612,                   Accuracy: 28437/60000 (47.40%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.9420,                   Accuracy: 30920/60000 (51.53%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.9823,                   Accuracy: 31221/60000 (52.03%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.0608,                   Accuracy: 30292/60000 (50.49%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.2898,                   Accuracy: 27793/60000 (46.32%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.5665,                   Accuracy: 24921/60000 (41.53%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6142,                   Accuracy: 23949/60000 (39.92%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2159,                   Accuracy: 25623/60000 (42.71%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3380,                   Accuracy: 30919/60000 (51.53%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.4808,                   Accuracy: 38273/60000 (63.79%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8922,                   Accuracy: 44236/60000 (73.73%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5165,                   Accuracy: 49678/60000 (82.80%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5612,                   Accuracy: 48392/60000 (80.65%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7290,                   Accuracy: 45643/60000 (76.07%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9572,                   Accuracy: 42429/60000 (70.71%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0806,                   Accuracy: 41425/60000 (69.04%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9691,                   Accuracy: 43958/60000 (73.26%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5680,                   Accuracy: 50048/60000 (83.41%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1971,                   Accuracy: 56254/60000 (93.76%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0706,                   Accuracy: 58696/60000 (97.83%)
{0: tensor(98.5533), 10: tensor(97.6467), 20: tensor(95.1167), 30: tensor(88.5933), 40: tensor(80.4183), 50: tensor(76.6067), 60: tensor(78.0633), 70: tensor(82.2383), 80: tensor(84.6450), 90: tensor(83.6133), 100: tensor(75.2767), 110: tensor(65.9550), 120: tensor(53.5783), 130: tensor(44.3250), 140: tensor(41.0050), 150: tensor(42.6217), 160: tensor(47.3950), 170: tensor(51.5333), 180: tensor(52.0350), 190: tensor(50.4867), 200: tensor(46.3217), 210: tensor(41.5350), 220: tensor(39.9150), 230: tensor(42.7050), 240: tensor(51.5317), 250: tensor(63.7883), 260: tensor(73.7267), 270: tensor(82.7967), 280: tensor(80.6533), 290: tensor(76.0717), 300: tensor(70.7150), 310: tensor(69.0417), 320: tensor(73.2633), 330: tensor(83.4133), 340: tensor(93.7567), 350: tensor(97.8267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=100, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6645,                   Accuracy: 218/2000.0 (10.90%)



-= Testing valid =-
Test set: Average loss: 1.4231,                   Accuracy: 918/2000.0 (45.90%)



-= Testing valid =-
Test set: Average loss: 2.0666,                   Accuracy: 867/2000.0 (43.35%)



-= Testing valid =-
Test set: Average loss: 0.6872,                   Accuracy: 1500/2000.0 (75.00%)



-= Testing valid =-
Test set: Average loss: 0.5559,                   Accuracy: 1582/2000.0 (79.10%)



-= Testing valid =-
Test set: Average loss: 0.3883,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.2821,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0935,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.2531,                   Accuracy: 1794/2000.0 (89.70%)



Epoch 10 train accuracy: 98.03%, valid accuracy 89.70%
-= Testing valid =-
Test set: Average loss: 0.1669,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1745,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.2759,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.1522,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.2659,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.2101,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.1069,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 20 train accuracy: 99.03%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.1184,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1512,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.0986,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1591,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.1410,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1176,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1464,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1284,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.2556,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.0454,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 30 train accuracy: 99.45%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1384,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1742,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1259,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1798,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.1399,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1209,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1774,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.2217,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1923/2000.0 (96.15%)



Epoch 40 train accuracy: 99.59%, valid accuracy 96.15%
-= Testing valid =-
Test set: Average loss: 0.1119,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1441,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.2128,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.1751,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1901,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.1788,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.1858,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.1842,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.2005,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.1496,                   Accuracy: 1881/2000.0 (94.05%)



Epoch 50 train accuracy: 99.68%, valid accuracy 94.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0640,                   Accuracy: 58876/60000 (98.13%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0892,                   Accuracy: 58466/60000 (97.44%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1944,                   Accuracy: 56619/60000 (94.36%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4455,                   Accuracy: 52223/60000 (87.04%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8091,                   Accuracy: 46180/60000 (76.97%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0212,                   Accuracy: 41872/60000 (69.79%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9072,                   Accuracy: 42615/60000 (71.03%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7357,                   Accuracy: 44982/60000 (74.97%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6508,                   Accuracy: 46210/60000 (77.02%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6542,                   Accuracy: 46791/60000 (77.99%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9896,                   Accuracy: 41410/60000 (69.02%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.4829,                   Accuracy: 35881/60000 (59.80%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.3968,                   Accuracy: 26160/60000 (43.60%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.0607,                   Accuracy: 22275/60000 (37.12%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3272,                   Accuracy: 22064/60000 (36.77%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.1171,                   Accuracy: 25022/60000 (41.70%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.8171,                   Accuracy: 29385/60000 (48.97%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.7070,                   Accuracy: 31794/60000 (52.99%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.7445,                   Accuracy: 32453/60000 (54.09%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.8622,                   Accuracy: 31535/60000 (52.56%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.9717,                   Accuracy: 29633/60000 (49.39%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.1752,                   Accuracy: 26190/60000 (43.65%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.2866,                   Accuracy: 23839/60000 (39.73%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9687,                   Accuracy: 24514/60000 (40.86%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2600,                   Accuracy: 29119/60000 (48.53%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.4764,                   Accuracy: 36086/60000 (60.14%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9508,                   Accuracy: 41521/60000 (69.20%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6973,                   Accuracy: 44986/60000 (74.98%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.8274,                   Accuracy: 43018/60000 (71.70%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0492,                   Accuracy: 39587/60000 (65.98%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.4193,                   Accuracy: 33999/60000 (56.67%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.5464,                   Accuracy: 32294/60000 (53.82%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3191,                   Accuracy: 36877/60000 (61.46%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7046,                   Accuracy: 47127/60000 (78.54%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2363,                   Accuracy: 55555/60000 (92.59%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1026,                   Accuracy: 58110/60000 (96.85%)
{0: tensor(98.1267), 10: tensor(97.4433), 20: tensor(94.3650), 30: tensor(87.0383), 40: tensor(76.9667), 50: tensor(69.7867), 60: tensor(71.0250), 70: tensor(74.9700), 80: tensor(77.0167), 90: tensor(77.9850), 100: tensor(69.0167), 110: tensor(59.8017), 120: tensor(43.6000), 130: tensor(37.1250), 140: tensor(36.7733), 150: tensor(41.7033), 160: tensor(48.9750), 170: tensor(52.9900), 180: tensor(54.0883), 190: tensor(52.5583), 200: tensor(49.3883), 210: tensor(43.6500), 220: tensor(39.7317), 230: tensor(40.8567), 240: tensor(48.5317), 250: tensor(60.1433), 260: tensor(69.2017), 270: tensor(74.9767), 280: tensor(71.6967), 290: tensor(65.9783), 300: tensor(56.6650), 310: tensor(53.8233), 320: tensor(61.4617), 330: tensor(78.5450), 340: tensor(92.5917), 350: tensor(96.8500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=71, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.3821,                   Accuracy: 995/2000.0 (49.75%)



-= Testing valid =-
Test set: Average loss: 0.4150,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.2232,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.1352,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1698,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1204,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0664,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1072,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 10 train accuracy: 97.76%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0687,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0486,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0529,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0590,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 20 train accuracy: 98.81%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.07%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.51%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.56%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0525,                   Accuracy: 59092/60000 (98.49%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0841,                   Accuracy: 58577/60000 (97.63%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2001,                   Accuracy: 56673/60000 (94.46%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5545,                   Accuracy: 51567/60000 (85.94%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3332,                   Accuracy: 41799/60000 (69.67%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.4413,                   Accuracy: 30796/60000 (51.33%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.7153,                   Accuracy: 20828/60000 (34.71%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.6343,                   Accuracy: 14224/60000 (23.71%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.3131,                   Accuracy: 10694/60000 (17.82%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.8219,                   Accuracy: 9284/60000 (15.47%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.9314,                   Accuracy: 9489/60000 (15.81%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.3012,                   Accuracy: 10554/60000 (17.59%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.5179,                   Accuracy: 11645/60000 (19.41%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.5274,                   Accuracy: 14195/60000 (23.66%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.2615,                   Accuracy: 17805/60000 (29.67%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.9001,                   Accuracy: 21866/60000 (36.44%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.8066,                   Accuracy: 25089/60000 (41.81%)
-= Testing Rotation 170 =-
Test set: Average loss: 5.9140,                   Accuracy: 26955/60000 (44.92%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.2523,                   Accuracy: 27356/60000 (45.59%)
-= Testing Rotation 190 =-
Test set: Average loss: 5.9187,                   Accuracy: 27881/60000 (46.47%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.9261,                   Accuracy: 25911/60000 (43.19%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.9266,                   Accuracy: 22166/60000 (36.94%)
-= Testing Rotation 220 =-
Test set: Average loss: 5.8515,                   Accuracy: 18344/60000 (30.57%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.0091,                   Accuracy: 15697/60000 (26.16%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.2045,                   Accuracy: 13320/60000 (22.20%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.3843,                   Accuracy: 11473/60000 (19.12%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.4511,                   Accuracy: 10388/60000 (17.31%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.6117,                   Accuracy: 9254/60000 (15.42%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.2321,                   Accuracy: 8189/60000 (13.65%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.6943,                   Accuracy: 8443/60000 (14.07%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.8208,                   Accuracy: 11945/60000 (19.91%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.6021,                   Accuracy: 20153/60000 (33.59%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1388,                   Accuracy: 32036/60000 (53.39%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8754,                   Accuracy: 46285/60000 (77.14%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2872,                   Accuracy: 55002/60000 (91.67%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0883,                   Accuracy: 58452/60000 (97.42%)
{0: tensor(98.4867), 10: tensor(97.6283), 20: tensor(94.4550), 30: tensor(85.9450), 40: tensor(69.6650), 50: tensor(51.3267), 60: tensor(34.7133), 70: tensor(23.7067), 80: tensor(17.8233), 90: tensor(15.4733), 100: tensor(15.8150), 110: tensor(17.5900), 120: tensor(19.4083), 130: tensor(23.6583), 140: tensor(29.6750), 150: tensor(36.4433), 160: tensor(41.8150), 170: tensor(44.9250), 180: tensor(45.5933), 190: tensor(46.4683), 200: tensor(43.1850), 210: tensor(36.9433), 220: tensor(30.5733), 230: tensor(26.1617), 240: tensor(22.2000), 250: tensor(19.1217), 260: tensor(17.3133), 270: tensor(15.4233), 280: tensor(13.6483), 290: tensor(14.0717), 300: tensor(19.9083), 310: tensor(33.5883), 320: tensor(53.3933), 330: tensor(77.1417), 340: tensor(91.6700), 350: tensor(97.4200)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=72, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.5249,                   Accuracy: 364/2000.0 (18.20%)



-= Testing valid =-
Test set: Average loss: 0.8297,                   Accuracy: 1462/2000.0 (73.10%)



-= Testing valid =-
Test set: Average loss: 0.1748,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1132,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.2018,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1247,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0742,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0579,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 10 train accuracy: 97.56%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 20 train accuracy: 99.01%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.39%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.62%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.81%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0640,                   Accuracy: 58905/60000 (98.18%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1026,                   Accuracy: 58266/60000 (97.11%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2256,                   Accuracy: 56219/60000 (93.70%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6216,                   Accuracy: 49859/60000 (83.10%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.2905,                   Accuracy: 40983/60000 (68.31%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.2129,                   Accuracy: 31054/60000 (51.76%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.2986,                   Accuracy: 21703/60000 (36.17%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.0911,                   Accuracy: 15493/60000 (25.82%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.6874,                   Accuracy: 11769/60000 (19.61%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.0168,                   Accuracy: 11307/60000 (18.84%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.1866,                   Accuracy: 11246/60000 (18.74%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.3494,                   Accuracy: 11378/60000 (18.96%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.4827,                   Accuracy: 13222/60000 (22.04%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.4894,                   Accuracy: 16566/60000 (27.61%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.3693,                   Accuracy: 20619/60000 (34.37%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.4136,                   Accuracy: 24814/60000 (41.36%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.7718,                   Accuracy: 26919/60000 (44.87%)
-= Testing Rotation 170 =-
Test set: Average loss: 5.9161,                   Accuracy: 27997/60000 (46.66%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.4344,                   Accuracy: 27333/60000 (45.56%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.0184,                   Accuracy: 27534/60000 (45.89%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.1557,                   Accuracy: 25317/60000 (42.19%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.0254,                   Accuracy: 21777/60000 (36.29%)
-= Testing Rotation 220 =-
Test set: Average loss: 5.8151,                   Accuracy: 19790/60000 (32.98%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.6736,                   Accuracy: 18189/60000 (30.32%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.5340,                   Accuracy: 16522/60000 (27.54%)
-= Testing Rotation 250 =-
Test set: Average loss: 5.5219,                   Accuracy: 14832/60000 (24.72%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.5858,                   Accuracy: 12922/60000 (21.54%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.3770,                   Accuracy: 13159/60000 (21.93%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.3071,                   Accuracy: 11658/60000 (19.43%)
-= Testing Rotation 290 =-
Test set: Average loss: 4.7995,                   Accuracy: 12453/60000 (20.75%)
-= Testing Rotation 300 =-
Test set: Average loss: 3.8939,                   Accuracy: 16202/60000 (27.00%)
-= Testing Rotation 310 =-
Test set: Average loss: 2.7969,                   Accuracy: 24748/60000 (41.25%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.5511,                   Accuracy: 37657/60000 (62.76%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6283,                   Accuracy: 49678/60000 (82.80%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2099,                   Accuracy: 56355/60000 (93.93%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0856,                   Accuracy: 58519/60000 (97.53%)
{0: tensor(98.1750), 10: tensor(97.1100), 20: tensor(93.6983), 30: tensor(83.0983), 40: tensor(68.3050), 50: tensor(51.7567), 60: tensor(36.1717), 70: tensor(25.8217), 80: tensor(19.6150), 90: tensor(18.8450), 100: tensor(18.7433), 110: tensor(18.9633), 120: tensor(22.0367), 130: tensor(27.6100), 140: tensor(34.3650), 150: tensor(41.3567), 160: tensor(44.8650), 170: tensor(46.6617), 180: tensor(45.5550), 190: tensor(45.8900), 200: tensor(42.1950), 210: tensor(36.2950), 220: tensor(32.9833), 230: tensor(30.3150), 240: tensor(27.5367), 250: tensor(24.7200), 260: tensor(21.5367), 270: tensor(21.9317), 280: tensor(19.4300), 290: tensor(20.7550), 300: tensor(27.0033), 310: tensor(41.2467), 320: tensor(62.7617), 330: tensor(82.7967), 340: tensor(93.9250), 350: tensor(97.5317)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=73, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.4226,                   Accuracy: 1021/2000.0 (51.05%)



-= Testing valid =-
Test set: Average loss: 0.3976,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.2317,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.2329,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.1387,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1145,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0529,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 10 train accuracy: 98.30%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 20 train accuracy: 98.95%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0205,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 30 train accuracy: 99.31%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0213,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0202,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0189,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0205,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0207,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0202,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 40 train accuracy: 99.57%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0205,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0180,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0185,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0198,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0198,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0196,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0195,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0219,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 50 train accuracy: 99.69%, valid accuracy 99.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0476,                   Accuracy: 59157/60000 (98.60%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0763,                   Accuracy: 58680/60000 (97.80%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1994,                   Accuracy: 56641/60000 (94.40%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6165,                   Accuracy: 49975/60000 (83.29%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4550,                   Accuracy: 38831/60000 (64.72%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.5593,                   Accuracy: 28112/60000 (46.85%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.6711,                   Accuracy: 19369/60000 (32.28%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.5682,                   Accuracy: 13635/60000 (22.73%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.0288,                   Accuracy: 11277/60000 (18.80%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.5170,                   Accuracy: 10952/60000 (18.25%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.6316,                   Accuracy: 10443/60000 (17.41%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.7790,                   Accuracy: 10426/60000 (17.38%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.7338,                   Accuracy: 12075/60000 (20.12%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.5753,                   Accuracy: 14693/60000 (24.49%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.4488,                   Accuracy: 17904/60000 (29.84%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.4095,                   Accuracy: 21507/60000 (35.85%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.8116,                   Accuracy: 24165/60000 (40.28%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.2334,                   Accuracy: 25510/60000 (42.52%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.9753,                   Accuracy: 25925/60000 (43.21%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.6962,                   Accuracy: 26167/60000 (43.61%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.5685,                   Accuracy: 24461/60000 (40.77%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.4006,                   Accuracy: 20920/60000 (34.87%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.2338,                   Accuracy: 18025/60000 (30.04%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.1377,                   Accuracy: 15572/60000 (25.95%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.0593,                   Accuracy: 13699/60000 (22.83%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.0615,                   Accuracy: 12213/60000 (20.35%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.9595,                   Accuracy: 11682/60000 (19.47%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.8104,                   Accuracy: 11044/60000 (18.41%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.4722,                   Accuracy: 10655/60000 (17.76%)
-= Testing Rotation 290 =-
Test set: Average loss: 4.9730,                   Accuracy: 10768/60000 (17.95%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.1392,                   Accuracy: 13164/60000 (21.94%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.0886,                   Accuracy: 20740/60000 (34.57%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.8486,                   Accuracy: 32964/60000 (54.94%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8243,                   Accuracy: 46407/60000 (77.35%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2538,                   Accuracy: 55487/60000 (92.48%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0767,                   Accuracy: 58573/60000 (97.62%)
{0: tensor(98.5950), 10: tensor(97.8000), 20: tensor(94.4017), 30: tensor(83.2917), 40: tensor(64.7183), 50: tensor(46.8533), 60: tensor(32.2817), 70: tensor(22.7250), 80: tensor(18.7950), 90: tensor(18.2533), 100: tensor(17.4050), 110: tensor(17.3767), 120: tensor(20.1250), 130: tensor(24.4883), 140: tensor(29.8400), 150: tensor(35.8450), 160: tensor(40.2750), 170: tensor(42.5167), 180: tensor(43.2083), 190: tensor(43.6117), 200: tensor(40.7683), 210: tensor(34.8667), 220: tensor(30.0417), 230: tensor(25.9533), 240: tensor(22.8317), 250: tensor(20.3550), 260: tensor(19.4700), 270: tensor(18.4067), 280: tensor(17.7583), 290: tensor(17.9467), 300: tensor(21.9400), 310: tensor(34.5667), 320: tensor(54.9400), 330: tensor(77.3450), 340: tensor(92.4783), 350: tensor(97.6217)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=74, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7769,                   Accuracy: 704/2000.0 (35.20%)



-= Testing valid =-
Test set: Average loss: 0.3248,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.3966,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.5780,                   Accuracy: 1621/2000.0 (81.05%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.2314,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.2985,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0601,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 10 train accuracy: 97.90%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0485,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0409,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0585,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0597,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 20 train accuracy: 99.00%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 30 train accuracy: 99.25%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.45%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 50 train accuracy: 99.60%, valid accuracy 98.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0619,                   Accuracy: 58959/60000 (98.26%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0858,                   Accuracy: 58494/60000 (97.49%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2127,                   Accuracy: 56433/60000 (94.06%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6413,                   Accuracy: 49598/60000 (82.66%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4477,                   Accuracy: 39204/60000 (65.34%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.4605,                   Accuracy: 28928/60000 (48.21%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.4648,                   Accuracy: 20200/60000 (33.67%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.1343,                   Accuracy: 14737/60000 (24.56%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.6407,                   Accuracy: 11466/60000 (19.11%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.0287,                   Accuracy: 10157/60000 (16.93%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.0971,                   Accuracy: 10377/60000 (17.30%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.4834,                   Accuracy: 10414/60000 (17.36%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.7124,                   Accuracy: 12010/60000 (20.02%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.5915,                   Accuracy: 15051/60000 (25.08%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.4599,                   Accuracy: 18457/60000 (30.76%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.4147,                   Accuracy: 21878/60000 (36.46%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.5413,                   Accuracy: 24776/60000 (41.29%)
-= Testing Rotation 170 =-
Test set: Average loss: 5.8121,                   Accuracy: 26500/60000 (44.17%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.4358,                   Accuracy: 26818/60000 (44.70%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.0552,                   Accuracy: 26657/60000 (44.43%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.9566,                   Accuracy: 24927/60000 (41.54%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.1014,                   Accuracy: 21613/60000 (36.02%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.2534,                   Accuracy: 18542/60000 (30.90%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.4060,                   Accuracy: 16247/60000 (27.08%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.4735,                   Accuracy: 13737/60000 (22.90%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.4288,                   Accuracy: 11479/60000 (19.13%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.2799,                   Accuracy: 9975/60000 (16.62%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.3505,                   Accuracy: 8734/60000 (14.56%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.9371,                   Accuracy: 8185/60000 (13.64%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.5637,                   Accuracy: 8347/60000 (13.91%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.9299,                   Accuracy: 11306/60000 (18.84%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.7738,                   Accuracy: 19538/60000 (32.56%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.3694,                   Accuracy: 31572/60000 (52.62%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.0966,                   Accuracy: 44723/60000 (74.54%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3267,                   Accuracy: 54633/60000 (91.06%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0974,                   Accuracy: 58290/60000 (97.15%)
{0: tensor(98.2650), 10: tensor(97.4900), 20: tensor(94.0550), 30: tensor(82.6633), 40: tensor(65.3400), 50: tensor(48.2133), 60: tensor(33.6667), 70: tensor(24.5617), 80: tensor(19.1100), 90: tensor(16.9283), 100: tensor(17.2950), 110: tensor(17.3567), 120: tensor(20.0167), 130: tensor(25.0850), 140: tensor(30.7617), 150: tensor(36.4633), 160: tensor(41.2933), 170: tensor(44.1667), 180: tensor(44.6967), 190: tensor(44.4283), 200: tensor(41.5450), 210: tensor(36.0217), 220: tensor(30.9033), 230: tensor(27.0783), 240: tensor(22.8950), 250: tensor(19.1317), 260: tensor(16.6250), 270: tensor(14.5567), 280: tensor(13.6417), 290: tensor(13.9117), 300: tensor(18.8433), 310: tensor(32.5633), 320: tensor(52.6200), 330: tensor(74.5383), 340: tensor(91.0550), 350: tensor(97.1500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=75, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.1693,                   Accuracy: 1125/2000.0 (56.25%)



-= Testing valid =-
Test set: Average loss: 0.4403,                   Accuracy: 1737/2000.0 (86.85%)



-= Testing valid =-
Test set: Average loss: 0.3876,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.2564,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.1438,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1444,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0698,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 10 train accuracy: 97.80%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0496,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 20 train accuracy: 98.86%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0198,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0213,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0200,                   Accuracy: 1990/2000.0 (99.50%)



Epoch 30 train accuracy: 99.15%, valid accuracy 99.50%
-= Testing valid =-
Test set: Average loss: 0.0196,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0178,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0172,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0176,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0184,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0207,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0186,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0166,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0163,                   Accuracy: 1993/2000.0 (99.65%)



Epoch 40 train accuracy: 99.45%, valid accuracy 99.65%
-= Testing valid =-
Test set: Average loss: 0.0182,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0167,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0171,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0183,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0170,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0172,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0182,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0188,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0165,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0168,                   Accuracy: 1988/2000.0 (99.40%)



Epoch 50 train accuracy: 99.62%, valid accuracy 99.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0446,                   Accuracy: 59224/60000 (98.71%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0759,                   Accuracy: 58689/60000 (97.82%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1972,                   Accuracy: 56792/60000 (94.65%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6121,                   Accuracy: 50358/60000 (83.93%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4072,                   Accuracy: 40282/60000 (67.14%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.5382,                   Accuracy: 30031/60000 (50.05%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.7478,                   Accuracy: 21624/60000 (36.04%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.6286,                   Accuracy: 15944/60000 (26.57%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.1763,                   Accuracy: 12368/60000 (20.61%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.6259,                   Accuracy: 11648/60000 (19.41%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.7955,                   Accuracy: 11577/60000 (19.30%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.9520,                   Accuracy: 11793/60000 (19.66%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.1916,                   Accuracy: 12831/60000 (21.39%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.2205,                   Accuracy: 15449/60000 (25.75%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.0017,                   Accuracy: 18943/60000 (31.57%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.6533,                   Accuracy: 22969/60000 (38.28%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.6329,                   Accuracy: 26122/60000 (43.54%)
-= Testing Rotation 170 =-
Test set: Average loss: 5.8298,                   Accuracy: 27588/60000 (45.98%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.3508,                   Accuracy: 27759/60000 (46.26%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.3254,                   Accuracy: 27694/60000 (46.16%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.4617,                   Accuracy: 25953/60000 (43.26%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.5065,                   Accuracy: 22630/60000 (37.72%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.5132,                   Accuracy: 18993/60000 (31.66%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.6264,                   Accuracy: 15670/60000 (26.12%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.6632,                   Accuracy: 13072/60000 (21.79%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.6371,                   Accuracy: 11182/60000 (18.64%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.3934,                   Accuracy: 10660/60000 (17.77%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.1881,                   Accuracy: 10645/60000 (17.74%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.7593,                   Accuracy: 10589/60000 (17.65%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.2096,                   Accuracy: 10918/60000 (18.20%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.4672,                   Accuracy: 13752/60000 (22.92%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.3855,                   Accuracy: 21454/60000 (35.76%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.0551,                   Accuracy: 33330/60000 (55.55%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8799,                   Accuracy: 46678/60000 (77.80%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2316,                   Accuracy: 55938/60000 (93.23%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0645,                   Accuracy: 58814/60000 (98.02%)
{0: tensor(98.7067), 10: tensor(97.8150), 20: tensor(94.6533), 30: tensor(83.9300), 40: tensor(67.1367), 50: tensor(50.0517), 60: tensor(36.0400), 70: tensor(26.5733), 80: tensor(20.6133), 90: tensor(19.4133), 100: tensor(19.2950), 110: tensor(19.6550), 120: tensor(21.3850), 130: tensor(25.7483), 140: tensor(31.5717), 150: tensor(38.2817), 160: tensor(43.5367), 170: tensor(45.9800), 180: tensor(46.2650), 190: tensor(46.1567), 200: tensor(43.2550), 210: tensor(37.7167), 220: tensor(31.6550), 230: tensor(26.1167), 240: tensor(21.7867), 250: tensor(18.6367), 260: tensor(17.7667), 270: tensor(17.7417), 280: tensor(17.6483), 290: tensor(18.1967), 300: tensor(22.9200), 310: tensor(35.7567), 320: tensor(55.5500), 330: tensor(77.7967), 340: tensor(93.2300), 350: tensor(98.0233)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=76, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.3793,                   Accuracy: 1091/2000.0 (54.55%)



-= Testing valid =-
Test set: Average loss: 0.7535,                   Accuracy: 1533/2000.0 (76.65%)



-= Testing valid =-
Test set: Average loss: 0.2803,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.1936,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.2740,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.1347,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1050,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1076,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 10 train accuracy: 97.45%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 20 train accuracy: 98.90%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.38%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 40 train accuracy: 99.39%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1988/2000.0 (99.40%)



Epoch 50 train accuracy: 99.69%, valid accuracy 99.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0533,                   Accuracy: 59097/60000 (98.50%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0871,                   Accuracy: 58569/60000 (97.61%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2197,                   Accuracy: 56514/60000 (94.19%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6808,                   Accuracy: 49870/60000 (83.12%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5663,                   Accuracy: 39572/60000 (65.95%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.7849,                   Accuracy: 28897/60000 (48.16%)
-= Testing Rotation 60 =-
Test set: Average loss: 4.0357,                   Accuracy: 20052/60000 (33.42%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.9104,                   Accuracy: 14478/60000 (24.13%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.4400,                   Accuracy: 11586/60000 (19.31%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.7516,                   Accuracy: 10416/60000 (17.36%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.5413,                   Accuracy: 10817/60000 (18.03%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.5603,                   Accuracy: 11214/60000 (18.69%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.4405,                   Accuracy: 13107/60000 (21.84%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.3549,                   Accuracy: 15984/60000 (26.64%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.3158,                   Accuracy: 19488/60000 (32.48%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.4925,                   Accuracy: 23062/60000 (38.44%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.9317,                   Accuracy: 25425/60000 (42.38%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.3266,                   Accuracy: 26698/60000 (44.50%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.0420,                   Accuracy: 26600/60000 (44.33%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.7284,                   Accuracy: 27521/60000 (45.87%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.7447,                   Accuracy: 25898/60000 (43.16%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.7443,                   Accuracy: 22942/60000 (38.24%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.4219,                   Accuracy: 20820/60000 (34.70%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.3876,                   Accuracy: 18242/60000 (30.40%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.2861,                   Accuracy: 15612/60000 (26.02%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.2600,                   Accuracy: 13526/60000 (22.54%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.2865,                   Accuracy: 11974/60000 (19.96%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.3159,                   Accuracy: 10283/60000 (17.14%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.1481,                   Accuracy: 9986/60000 (16.64%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.7728,                   Accuracy: 9887/60000 (16.48%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.9527,                   Accuracy: 12498/60000 (20.83%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.7410,                   Accuracy: 20075/60000 (33.46%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.2591,                   Accuracy: 32401/60000 (54.00%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9946,                   Accuracy: 45897/60000 (76.50%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2984,                   Accuracy: 54987/60000 (91.64%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0830,                   Accuracy: 58503/60000 (97.50%)
{0: tensor(98.4950), 10: tensor(97.6150), 20: tensor(94.1900), 30: tensor(83.1167), 40: tensor(65.9533), 50: tensor(48.1617), 60: tensor(33.4200), 70: tensor(24.1300), 80: tensor(19.3100), 90: tensor(17.3600), 100: tensor(18.0283), 110: tensor(18.6900), 120: tensor(21.8450), 130: tensor(26.6400), 140: tensor(32.4800), 150: tensor(38.4367), 160: tensor(42.3750), 170: tensor(44.4967), 180: tensor(44.3333), 190: tensor(45.8683), 200: tensor(43.1633), 210: tensor(38.2367), 220: tensor(34.7000), 230: tensor(30.4033), 240: tensor(26.0200), 250: tensor(22.5433), 260: tensor(19.9567), 270: tensor(17.1383), 280: tensor(16.6433), 290: tensor(16.4783), 300: tensor(20.8300), 310: tensor(33.4583), 320: tensor(54.0017), 330: tensor(76.4950), 340: tensor(91.6450), 350: tensor(97.5050)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=77, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4342,                   Accuracy: 356/2000.0 (17.80%)



-= Testing valid =-
Test set: Average loss: 0.3486,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.4364,                   Accuracy: 1740/2000.0 (87.00%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.1430,                   Accuracy: 1911/2000.0 (95.55%)



Epoch 10 train accuracy: 98.14%, valid accuracy 95.55%
-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0497,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 20 train accuracy: 99.01%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.26%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.66%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 50 train accuracy: 99.66%, valid accuracy 98.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0506,                   Accuracy: 59128/60000 (98.55%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0774,                   Accuracy: 58730/60000 (97.88%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1909,                   Accuracy: 56907/60000 (94.85%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5749,                   Accuracy: 51092/60000 (85.15%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3437,                   Accuracy: 41518/60000 (69.20%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.4907,                   Accuracy: 30491/60000 (50.82%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.8398,                   Accuracy: 21344/60000 (35.57%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.8278,                   Accuracy: 15741/60000 (26.24%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.5149,                   Accuracy: 11773/60000 (19.62%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.9754,                   Accuracy: 10181/60000 (16.97%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.1417,                   Accuracy: 9398/60000 (15.66%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.3266,                   Accuracy: 9746/60000 (16.24%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.2119,                   Accuracy: 11372/60000 (18.95%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.9627,                   Accuracy: 14099/60000 (23.50%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.7042,                   Accuracy: 17308/60000 (28.85%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.6124,                   Accuracy: 21264/60000 (35.44%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.9490,                   Accuracy: 25027/60000 (41.71%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.1261,                   Accuracy: 27183/60000 (45.31%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.5163,                   Accuracy: 27732/60000 (46.22%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.4047,                   Accuracy: 27613/60000 (46.02%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.5181,                   Accuracy: 25771/60000 (42.95%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.3545,                   Accuracy: 22351/60000 (37.25%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.4442,                   Accuracy: 19321/60000 (32.20%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.6094,                   Accuracy: 16435/60000 (27.39%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.8207,                   Accuracy: 13584/60000 (22.64%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.8607,                   Accuracy: 12161/60000 (20.27%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.6622,                   Accuracy: 11293/60000 (18.82%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.4831,                   Accuracy: 10234/60000 (17.06%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.9071,                   Accuracy: 10489/60000 (17.48%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.4786,                   Accuracy: 11454/60000 (19.09%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.6484,                   Accuracy: 13572/60000 (22.62%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.5685,                   Accuracy: 19589/60000 (32.65%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.2040,                   Accuracy: 31051/60000 (51.75%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9556,                   Accuracy: 45444/60000 (75.74%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2733,                   Accuracy: 55319/60000 (92.20%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0798,                   Accuracy: 58633/60000 (97.72%)
{0: tensor(98.5467), 10: tensor(97.8833), 20: tensor(94.8450), 30: tensor(85.1533), 40: tensor(69.1967), 50: tensor(50.8183), 60: tensor(35.5733), 70: tensor(26.2350), 80: tensor(19.6217), 90: tensor(16.9683), 100: tensor(15.6633), 110: tensor(16.2433), 120: tensor(18.9533), 130: tensor(23.4983), 140: tensor(28.8467), 150: tensor(35.4400), 160: tensor(41.7117), 170: tensor(45.3050), 180: tensor(46.2200), 190: tensor(46.0217), 200: tensor(42.9517), 210: tensor(37.2517), 220: tensor(32.2017), 230: tensor(27.3917), 240: tensor(22.6400), 250: tensor(20.2683), 260: tensor(18.8217), 270: tensor(17.0567), 280: tensor(17.4817), 290: tensor(19.0900), 300: tensor(22.6200), 310: tensor(32.6483), 320: tensor(51.7517), 330: tensor(75.7400), 340: tensor(92.1983), 350: tensor(97.7217)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=78, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.1039,                   Accuracy: 1360/2000.0 (68.00%)



-= Testing valid =-
Test set: Average loss: 0.4387,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.1351,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1449,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.3793,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.1530,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1339,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 10 train accuracy: 97.91%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 20 train accuracy: 98.95%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 30 train accuracy: 99.29%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0218,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0219,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 40 train accuracy: 99.50%, valid accuracy 99.35%
-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0251,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0207,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0201,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 50 train accuracy: 99.62%, valid accuracy 99.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0496,                   Accuracy: 59159/60000 (98.60%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0765,                   Accuracy: 58690/60000 (97.82%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1813,                   Accuracy: 56976/60000 (94.96%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5143,                   Accuracy: 51542/60000 (85.90%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.2300,                   Accuracy: 41780/60000 (69.63%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.2874,                   Accuracy: 31112/60000 (51.85%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.5500,                   Accuracy: 21959/60000 (36.60%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.5345,                   Accuracy: 15980/60000 (26.63%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.2933,                   Accuracy: 12589/60000 (20.98%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.7091,                   Accuracy: 12094/60000 (20.16%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.9487,                   Accuracy: 12408/60000 (20.68%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.9292,                   Accuracy: 12346/60000 (20.58%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.8745,                   Accuracy: 13560/60000 (22.60%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.7997,                   Accuracy: 15798/60000 (26.33%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.7730,                   Accuracy: 18555/60000 (30.92%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.7942,                   Accuracy: 21880/60000 (36.47%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.9831,                   Accuracy: 25051/60000 (41.75%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.2339,                   Accuracy: 26913/60000 (44.85%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.7174,                   Accuracy: 27068/60000 (45.11%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.5874,                   Accuracy: 27434/60000 (45.72%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.5953,                   Accuracy: 25681/60000 (42.80%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.5089,                   Accuracy: 22847/60000 (38.08%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.4192,                   Accuracy: 19678/60000 (32.80%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.3411,                   Accuracy: 17398/60000 (29.00%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.3012,                   Accuracy: 15355/60000 (25.59%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.3029,                   Accuracy: 13585/60000 (22.64%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.2934,                   Accuracy: 12373/60000 (20.62%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.0990,                   Accuracy: 11757/60000 (19.59%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.8725,                   Accuracy: 11288/60000 (18.81%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.4054,                   Accuracy: 11098/60000 (18.50%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.7267,                   Accuracy: 13030/60000 (21.72%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.5865,                   Accuracy: 19856/60000 (33.09%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1402,                   Accuracy: 31901/60000 (53.17%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9335,                   Accuracy: 45658/60000 (76.10%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2649,                   Accuracy: 55384/60000 (92.31%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0788,                   Accuracy: 58588/60000 (97.65%)
{0: tensor(98.5983), 10: tensor(97.8167), 20: tensor(94.9600), 30: tensor(85.9033), 40: tensor(69.6333), 50: tensor(51.8533), 60: tensor(36.5983), 70: tensor(26.6333), 80: tensor(20.9817), 90: tensor(20.1567), 100: tensor(20.6800), 110: tensor(20.5767), 120: tensor(22.6000), 130: tensor(26.3300), 140: tensor(30.9250), 150: tensor(36.4667), 160: tensor(41.7517), 170: tensor(44.8550), 180: tensor(45.1133), 190: tensor(45.7233), 200: tensor(42.8017), 210: tensor(38.0783), 220: tensor(32.7967), 230: tensor(28.9967), 240: tensor(25.5917), 250: tensor(22.6417), 260: tensor(20.6217), 270: tensor(19.5950), 280: tensor(18.8133), 290: tensor(18.4967), 300: tensor(21.7167), 310: tensor(33.0933), 320: tensor(53.1683), 330: tensor(76.0967), 340: tensor(92.3067), 350: tensor(97.6467)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=79, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.0981,                   Accuracy: 1074/2000.0 (53.70%)



-= Testing valid =-
Test set: Average loss: 0.7184,                   Accuracy: 1562/2000.0 (78.10%)



-= Testing valid =-
Test set: Average loss: 0.2981,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2244,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2473,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.1917,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1135,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1415,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1306,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1350,                   Accuracy: 1919/2000.0 (95.95%)



Epoch 10 train accuracy: 97.85%, valid accuracy 95.95%
-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0718,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0723,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0715,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 20 train accuracy: 98.94%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0496,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0519,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0477,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 30 train accuracy: 99.44%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0486,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 40 train accuracy: 99.59%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 50 train accuracy: 99.59%, valid accuracy 98.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0608,                   Accuracy: 58944/60000 (98.24%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1018,                   Accuracy: 58348/60000 (97.25%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2614,                   Accuracy: 56044/60000 (93.41%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7488,                   Accuracy: 49190/60000 (81.98%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5841,                   Accuracy: 39437/60000 (65.73%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.6901,                   Accuracy: 29241/60000 (48.74%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.8237,                   Accuracy: 20954/60000 (34.92%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.5232,                   Accuracy: 15735/60000 (26.23%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.8635,                   Accuracy: 12564/60000 (20.94%)
-= Testing Rotation 90 =-
Test set: Average loss: 4.9907,                   Accuracy: 11596/60000 (19.33%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.0280,                   Accuracy: 11857/60000 (19.76%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.1464,                   Accuracy: 11199/60000 (18.67%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.2343,                   Accuracy: 12220/60000 (20.37%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.3531,                   Accuracy: 14705/60000 (24.51%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.5019,                   Accuracy: 18222/60000 (30.37%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.7129,                   Accuracy: 22338/60000 (37.23%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.1266,                   Accuracy: 25197/60000 (41.99%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.5796,                   Accuracy: 26281/60000 (43.80%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.1309,                   Accuracy: 26082/60000 (43.47%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.9862,                   Accuracy: 25845/60000 (43.08%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.0212,                   Accuracy: 23546/60000 (39.24%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.9344,                   Accuracy: 20875/60000 (34.79%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.8332,                   Accuracy: 18860/60000 (31.43%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.8476,                   Accuracy: 17279/60000 (28.80%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.9285,                   Accuracy: 15772/60000 (26.29%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.9048,                   Accuracy: 15007/60000 (25.01%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.7252,                   Accuracy: 13828/60000 (23.05%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.5199,                   Accuracy: 12675/60000 (21.12%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.0735,                   Accuracy: 11092/60000 (18.49%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.4999,                   Accuracy: 10619/60000 (17.70%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.7177,                   Accuracy: 12587/60000 (20.98%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.5264,                   Accuracy: 19862/60000 (33.10%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.0876,                   Accuracy: 32430/60000 (54.05%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8410,                   Accuracy: 47071/60000 (78.45%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2539,                   Accuracy: 55670/60000 (92.78%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0845,                   Accuracy: 58548/60000 (97.58%)
{0: tensor(98.2400), 10: tensor(97.2467), 20: tensor(93.4067), 30: tensor(81.9833), 40: tensor(65.7283), 50: tensor(48.7350), 60: tensor(34.9233), 70: tensor(26.2250), 80: tensor(20.9400), 90: tensor(19.3267), 100: tensor(19.7617), 110: tensor(18.6650), 120: tensor(20.3667), 130: tensor(24.5083), 140: tensor(30.3700), 150: tensor(37.2300), 160: tensor(41.9950), 170: tensor(43.8017), 180: tensor(43.4700), 190: tensor(43.0750), 200: tensor(39.2433), 210: tensor(34.7917), 220: tensor(31.4333), 230: tensor(28.7983), 240: tensor(26.2867), 250: tensor(25.0117), 260: tensor(23.0467), 270: tensor(21.1250), 280: tensor(18.4867), 290: tensor(17.6983), 300: tensor(20.9783), 310: tensor(33.1033), 320: tensor(54.0500), 330: tensor(78.4517), 340: tensor(92.7833), 350: tensor(97.5800)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=80, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.5868,                   Accuracy: 840/2000.0 (42.00%)



-= Testing valid =-
Test set: Average loss: 1.0437,                   Accuracy: 1306/2000.0 (65.30%)



-= Testing valid =-
Test set: Average loss: 0.1669,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1416,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1190,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1167,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1279,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.0630,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 10 train accuracy: 97.68%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0620,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 20 train accuracy: 99.15%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.44%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 40 train accuracy: 99.51%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.61%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0521,                   Accuracy: 59096/60000 (98.49%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0781,                   Accuracy: 58694/60000 (97.82%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2001,                   Accuracy: 56839/60000 (94.73%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6151,                   Accuracy: 50540/60000 (84.23%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4626,                   Accuracy: 40045/60000 (66.74%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.6750,                   Accuracy: 29405/60000 (49.01%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.9959,                   Accuracy: 20421/60000 (34.03%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.9271,                   Accuracy: 15062/60000 (25.10%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.5728,                   Accuracy: 11427/60000 (19.05%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.8128,                   Accuracy: 11873/60000 (19.79%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.7921,                   Accuracy: 11404/60000 (19.01%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.8474,                   Accuracy: 11965/60000 (19.94%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.8341,                   Accuracy: 13222/60000 (22.04%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.8230,                   Accuracy: 15339/60000 (25.57%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.8100,                   Accuracy: 17759/60000 (29.60%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.6784,                   Accuracy: 21073/60000 (35.12%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.7654,                   Accuracy: 23999/60000 (40.00%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.2255,                   Accuracy: 25920/60000 (43.20%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.8296,                   Accuracy: 25873/60000 (43.12%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.7483,                   Accuracy: 26045/60000 (43.41%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.7053,                   Accuracy: 24986/60000 (41.64%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.5188,                   Accuracy: 22216/60000 (37.03%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.4735,                   Accuracy: 19482/60000 (32.47%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.4880,                   Accuracy: 16845/60000 (28.08%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.5049,                   Accuracy: 14472/60000 (24.12%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.4967,                   Accuracy: 13020/60000 (21.70%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.4805,                   Accuracy: 11924/60000 (19.87%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.4671,                   Accuracy: 11557/60000 (19.26%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.0406,                   Accuracy: 10617/60000 (17.69%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.5047,                   Accuracy: 10696/60000 (17.83%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.6708,                   Accuracy: 13616/60000 (22.69%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.5608,                   Accuracy: 20786/60000 (34.64%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1864,                   Accuracy: 32363/60000 (53.94%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9887,                   Accuracy: 45190/60000 (75.32%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2897,                   Accuracy: 54942/60000 (91.57%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0822,                   Accuracy: 58532/60000 (97.55%)
{0: tensor(98.4933), 10: tensor(97.8233), 20: tensor(94.7317), 30: tensor(84.2333), 40: tensor(66.7417), 50: tensor(49.0083), 60: tensor(34.0350), 70: tensor(25.1033), 80: tensor(19.0450), 90: tensor(19.7883), 100: tensor(19.0067), 110: tensor(19.9417), 120: tensor(22.0367), 130: tensor(25.5650), 140: tensor(29.5983), 150: tensor(35.1217), 160: tensor(39.9983), 170: tensor(43.2000), 180: tensor(43.1217), 190: tensor(43.4083), 200: tensor(41.6433), 210: tensor(37.0267), 220: tensor(32.4700), 230: tensor(28.0750), 240: tensor(24.1200), 250: tensor(21.7000), 260: tensor(19.8733), 270: tensor(19.2617), 280: tensor(17.6950), 290: tensor(17.8267), 300: tensor(22.6933), 310: tensor(34.6433), 320: tensor(53.9383), 330: tensor(75.3167), 340: tensor(91.5700), 350: tensor(97.5533)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=81, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7867,                   Accuracy: 612/2000.0 (30.60%)



-= Testing valid =-
Test set: Average loss: 0.6266,                   Accuracy: 1567/2000.0 (78.35%)



-= Testing valid =-
Test set: Average loss: 0.3394,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.2815,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.1366,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1326,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 10 train accuracy: 97.70%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0607,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 20 train accuracy: 98.81%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.16%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.57%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 50 train accuracy: 99.70%, valid accuracy 98.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0452,                   Accuracy: 59199/60000 (98.67%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0808,                   Accuracy: 58634/60000 (97.72%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1929,                   Accuracy: 56878/60000 (94.80%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5656,                   Accuracy: 51340/60000 (85.57%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3874,                   Accuracy: 40944/60000 (68.24%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.6245,                   Accuracy: 29164/60000 (48.61%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.8727,                   Accuracy: 20205/60000 (33.67%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.7755,                   Accuracy: 14795/60000 (24.66%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.3282,                   Accuracy: 11691/60000 (19.49%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.6679,                   Accuracy: 10870/60000 (18.12%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.6293,                   Accuracy: 11345/60000 (18.91%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.6559,                   Accuracy: 11864/60000 (19.77%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.7828,                   Accuracy: 13302/60000 (22.17%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.8379,                   Accuracy: 15935/60000 (26.56%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.9011,                   Accuracy: 19068/60000 (31.78%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.0537,                   Accuracy: 22856/60000 (38.09%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.4857,                   Accuracy: 25312/60000 (42.19%)
-= Testing Rotation 170 =-
Test set: Average loss: 7.1057,                   Accuracy: 26771/60000 (44.62%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.6237,                   Accuracy: 26910/60000 (44.85%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.3537,                   Accuracy: 26750/60000 (44.58%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.2228,                   Accuracy: 25398/60000 (42.33%)
-= Testing Rotation 210 =-
Test set: Average loss: 7.0047,                   Accuracy: 22420/60000 (37.37%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.8428,                   Accuracy: 18660/60000 (31.10%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.7541,                   Accuracy: 15753/60000 (26.25%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.6469,                   Accuracy: 12915/60000 (21.52%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.4760,                   Accuracy: 11011/60000 (18.35%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.1273,                   Accuracy: 10634/60000 (17.72%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.9472,                   Accuracy: 10231/60000 (17.05%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.4507,                   Accuracy: 10134/60000 (16.89%)
-= Testing Rotation 290 =-
Test set: Average loss: 4.9351,                   Accuracy: 10850/60000 (18.08%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.2681,                   Accuracy: 14242/60000 (23.74%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.2670,                   Accuracy: 21564/60000 (35.94%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.9560,                   Accuracy: 33517/60000 (55.86%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8641,                   Accuracy: 46457/60000 (77.43%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2695,                   Accuracy: 55270/60000 (92.12%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0772,                   Accuracy: 58608/60000 (97.68%)
{0: tensor(98.6650), 10: tensor(97.7233), 20: tensor(94.7967), 30: tensor(85.5667), 40: tensor(68.2400), 50: tensor(48.6067), 60: tensor(33.6750), 70: tensor(24.6583), 80: tensor(19.4850), 90: tensor(18.1167), 100: tensor(18.9083), 110: tensor(19.7733), 120: tensor(22.1700), 130: tensor(26.5583), 140: tensor(31.7800), 150: tensor(38.0933), 160: tensor(42.1867), 170: tensor(44.6183), 180: tensor(44.8500), 190: tensor(44.5833), 200: tensor(42.3300), 210: tensor(37.3667), 220: tensor(31.1000), 230: tensor(26.2550), 240: tensor(21.5250), 250: tensor(18.3517), 260: tensor(17.7233), 270: tensor(17.0517), 280: tensor(16.8900), 290: tensor(18.0833), 300: tensor(23.7367), 310: tensor(35.9400), 320: tensor(55.8617), 330: tensor(77.4283), 340: tensor(92.1167), 350: tensor(97.6800)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=82, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6212,                   Accuracy: 390/2000.0 (19.50%)



-= Testing valid =-
Test set: Average loss: 0.4821,                   Accuracy: 1698/2000.0 (84.90%)



-= Testing valid =-
Test set: Average loss: 0.2500,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.1554,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1998,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 10 train accuracy: 98.10%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 20 train accuracy: 99.01%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0210,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 30 train accuracy: 99.15%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0187,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0173,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0196,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0184,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0187,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0203,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0203,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0192,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0202,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 40 train accuracy: 99.51%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0182,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0185,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0210,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0186,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0193,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0161,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0170,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0161,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0172,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0145,                   Accuracy: 1993/2000.0 (99.65%)



Epoch 50 train accuracy: 99.57%, valid accuracy 99.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0443,                   Accuracy: 59259/60000 (98.76%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0822,                   Accuracy: 58623/60000 (97.71%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1925,                   Accuracy: 56861/60000 (94.77%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5345,                   Accuracy: 51582/60000 (85.97%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.2766,                   Accuracy: 42161/60000 (70.27%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.3468,                   Accuracy: 31981/60000 (53.30%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.6442,                   Accuracy: 21918/60000 (36.53%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.6782,                   Accuracy: 14908/60000 (24.85%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.2156,                   Accuracy: 11577/60000 (19.30%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.4247,                   Accuracy: 11262/60000 (18.77%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.5076,                   Accuracy: 11054/60000 (18.42%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.6104,                   Accuracy: 10906/60000 (18.18%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.8539,                   Accuracy: 11691/60000 (19.49%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.0659,                   Accuracy: 14179/60000 (23.63%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.1281,                   Accuracy: 17438/60000 (29.06%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.1795,                   Accuracy: 21811/60000 (36.35%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.5056,                   Accuracy: 25430/60000 (42.38%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.6686,                   Accuracy: 27486/60000 (45.81%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.1450,                   Accuracy: 27892/60000 (46.49%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.8637,                   Accuracy: 27787/60000 (46.31%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.7003,                   Accuracy: 26429/60000 (44.05%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.8019,                   Accuracy: 23087/60000 (38.48%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.6668,                   Accuracy: 20268/60000 (33.78%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.6940,                   Accuracy: 17556/60000 (29.26%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.7106,                   Accuracy: 14365/60000 (23.94%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.9301,                   Accuracy: 11894/60000 (19.82%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.8304,                   Accuracy: 10491/60000 (17.49%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.3798,                   Accuracy: 9824/60000 (16.37%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.1191,                   Accuracy: 9507/60000 (15.85%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.6502,                   Accuracy: 9923/60000 (16.54%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.9601,                   Accuracy: 11918/60000 (19.86%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.7834,                   Accuracy: 19198/60000 (32.00%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.2270,                   Accuracy: 31681/60000 (52.80%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9291,                   Accuracy: 45791/60000 (76.32%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2543,                   Accuracy: 55586/60000 (92.64%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0763,                   Accuracy: 58646/60000 (97.74%)
{0: tensor(98.7650), 10: tensor(97.7050), 20: tensor(94.7683), 30: tensor(85.9700), 40: tensor(70.2683), 50: tensor(53.3017), 60: tensor(36.5300), 70: tensor(24.8467), 80: tensor(19.2950), 90: tensor(18.7700), 100: tensor(18.4233), 110: tensor(18.1767), 120: tensor(19.4850), 130: tensor(23.6317), 140: tensor(29.0633), 150: tensor(36.3517), 160: tensor(42.3833), 170: tensor(45.8100), 180: tensor(46.4867), 190: tensor(46.3117), 200: tensor(44.0483), 210: tensor(38.4783), 220: tensor(33.7800), 230: tensor(29.2600), 240: tensor(23.9417), 250: tensor(19.8233), 260: tensor(17.4850), 270: tensor(16.3733), 280: tensor(15.8450), 290: tensor(16.5383), 300: tensor(19.8633), 310: tensor(31.9967), 320: tensor(52.8017), 330: tensor(76.3183), 340: tensor(92.6433), 350: tensor(97.7433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=83, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5176,                   Accuracy: 493/2000.0 (24.65%)



-= Testing valid =-
Test set: Average loss: 0.3139,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.6194,                   Accuracy: 1606/2000.0 (80.30%)



-= Testing valid =-
Test set: Average loss: 0.1440,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.2032,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.2065,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.0919,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1155,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 10 train accuracy: 97.94%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0775,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0604,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0684,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 20 train accuracy: 98.72%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0519,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0529,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 30 train accuracy: 99.46%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 40 train accuracy: 99.54%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0477,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 50 train accuracy: 99.69%, valid accuracy 98.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0550,                   Accuracy: 59047/60000 (98.41%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0819,                   Accuracy: 58607/60000 (97.68%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1892,                   Accuracy: 57000/60000 (95.00%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5443,                   Accuracy: 51399/60000 (85.67%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.2368,                   Accuracy: 41810/60000 (69.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.2919,                   Accuracy: 30504/60000 (50.84%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.4098,                   Accuracy: 21141/60000 (35.24%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.1078,                   Accuracy: 15108/60000 (25.18%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.7157,                   Accuracy: 10543/60000 (17.57%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.1762,                   Accuracy: 9438/60000 (15.73%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.3109,                   Accuracy: 9172/60000 (15.29%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.5558,                   Accuracy: 10164/60000 (16.94%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.6973,                   Accuracy: 11729/60000 (19.55%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.7503,                   Accuracy: 14108/60000 (23.51%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.8394,                   Accuracy: 16976/60000 (28.29%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.9393,                   Accuracy: 20931/60000 (34.88%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.2660,                   Accuracy: 24475/60000 (40.79%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.4991,                   Accuracy: 26437/60000 (44.06%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.0163,                   Accuracy: 26542/60000 (44.24%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.7071,                   Accuracy: 26784/60000 (44.64%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.6900,                   Accuracy: 25059/60000 (41.76%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.4515,                   Accuracy: 22370/60000 (37.28%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.1528,                   Accuracy: 20372/60000 (33.95%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.9758,                   Accuracy: 18253/60000 (30.42%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.9539,                   Accuracy: 15603/60000 (26.00%)
-= Testing Rotation 250 =-
Test set: Average loss: 5.9891,                   Accuracy: 13636/60000 (22.73%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.9978,                   Accuracy: 11628/60000 (19.38%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.1935,                   Accuracy: 9256/60000 (15.43%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.0735,                   Accuracy: 9187/60000 (15.31%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.6930,                   Accuracy: 10511/60000 (17.52%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.1181,                   Accuracy: 12839/60000 (21.40%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.8394,                   Accuracy: 19581/60000 (32.63%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.3141,                   Accuracy: 31162/60000 (51.94%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.0392,                   Accuracy: 45037/60000 (75.06%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3032,                   Accuracy: 55047/60000 (91.75%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0896,                   Accuracy: 58455/60000 (97.43%)
{0: tensor(98.4117), 10: tensor(97.6783), 20: tensor(95.), 30: tensor(85.6650), 40: tensor(69.6833), 50: tensor(50.8400), 60: tensor(35.2350), 70: tensor(25.1800), 80: tensor(17.5717), 90: tensor(15.7300), 100: tensor(15.2867), 110: tensor(16.9400), 120: tensor(19.5483), 130: tensor(23.5133), 140: tensor(28.2933), 150: tensor(34.8850), 160: tensor(40.7917), 170: tensor(44.0617), 180: tensor(44.2367), 190: tensor(44.6400), 200: tensor(41.7650), 210: tensor(37.2833), 220: tensor(33.9533), 230: tensor(30.4217), 240: tensor(26.0050), 250: tensor(22.7267), 260: tensor(19.3800), 270: tensor(15.4267), 280: tensor(15.3117), 290: tensor(17.5183), 300: tensor(21.3983), 310: tensor(32.6350), 320: tensor(51.9367), 330: tensor(75.0617), 340: tensor(91.7450), 350: tensor(97.4250)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=84, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0042,                   Accuracy: 769/2000.0 (38.45%)



-= Testing valid =-
Test set: Average loss: 0.2494,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.1770,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1436,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 10 train accuracy: 97.88%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0554,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 20 train accuracy: 98.97%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 30 train accuracy: 99.35%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 40 train accuracy: 99.46%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.65%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0480,                   Accuracy: 59181/60000 (98.64%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0876,                   Accuracy: 58553/60000 (97.59%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2231,                   Accuracy: 56462/60000 (94.10%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6114,                   Accuracy: 50608/60000 (84.35%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3951,                   Accuracy: 40600/60000 (67.67%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.4983,                   Accuracy: 30036/60000 (50.06%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.7746,                   Accuracy: 21441/60000 (35.74%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.7477,                   Accuracy: 16167/60000 (26.94%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.3606,                   Accuracy: 12157/60000 (20.26%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.9569,                   Accuracy: 11017/60000 (18.36%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.9489,                   Accuracy: 10470/60000 (17.45%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.1982,                   Accuracy: 10306/60000 (17.18%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.1040,                   Accuracy: 12109/60000 (20.18%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.9327,                   Accuracy: 15190/60000 (25.32%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.7959,                   Accuracy: 18909/60000 (31.51%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.7415,                   Accuracy: 22929/60000 (38.22%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.1444,                   Accuracy: 25328/60000 (42.21%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.5860,                   Accuracy: 26381/60000 (43.97%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.9265,                   Accuracy: 26975/60000 (44.96%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.8660,                   Accuracy: 26833/60000 (44.72%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.9018,                   Accuracy: 25787/60000 (42.98%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.6571,                   Accuracy: 23296/60000 (38.83%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.5684,                   Accuracy: 20246/60000 (33.74%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.6462,                   Accuracy: 17565/60000 (29.27%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.6007,                   Accuracy: 15329/60000 (25.55%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.5089,                   Accuracy: 14105/60000 (23.51%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.1387,                   Accuracy: 12625/60000 (21.04%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.9795,                   Accuracy: 11561/60000 (19.27%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.5047,                   Accuracy: 11304/60000 (18.84%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.2179,                   Accuracy: 11484/60000 (19.14%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.4329,                   Accuracy: 14022/60000 (23.37%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.2114,                   Accuracy: 21634/60000 (36.06%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.8143,                   Accuracy: 34633/60000 (57.72%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7239,                   Accuracy: 48322/60000 (80.54%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2060,                   Accuracy: 56414/60000 (94.02%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0742,                   Accuracy: 58679/60000 (97.80%)
{0: tensor(98.6350), 10: tensor(97.5883), 20: tensor(94.1033), 30: tensor(84.3467), 40: tensor(67.6667), 50: tensor(50.0600), 60: tensor(35.7350), 70: tensor(26.9450), 80: tensor(20.2617), 90: tensor(18.3617), 100: tensor(17.4500), 110: tensor(17.1767), 120: tensor(20.1817), 130: tensor(25.3167), 140: tensor(31.5150), 150: tensor(38.2150), 160: tensor(42.2133), 170: tensor(43.9683), 180: tensor(44.9583), 190: tensor(44.7217), 200: tensor(42.9783), 210: tensor(38.8267), 220: tensor(33.7433), 230: tensor(29.2750), 240: tensor(25.5483), 250: tensor(23.5083), 260: tensor(21.0417), 270: tensor(19.2683), 280: tensor(18.8400), 290: tensor(19.1400), 300: tensor(23.3700), 310: tensor(36.0567), 320: tensor(57.7217), 330: tensor(80.5367), 340: tensor(94.0233), 350: tensor(97.7983)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=85, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.2443,                   Accuracy: 1067/2000.0 (53.35%)



-= Testing valid =-
Test set: Average loss: 0.2222,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.2714,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.1412,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.3396,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1414,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0646,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 10 train accuracy: 97.85%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 20 train accuracy: 98.93%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.34%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.47%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 50 train accuracy: 99.76%, valid accuracy 99.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0480,                   Accuracy: 59209/60000 (98.68%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0865,                   Accuracy: 58539/60000 (97.57%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2150,                   Accuracy: 56606/60000 (94.34%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6241,                   Accuracy: 50742/60000 (84.57%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4221,                   Accuracy: 40914/60000 (68.19%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.6090,                   Accuracy: 30166/60000 (50.28%)
-= Testing Rotation 60 =-
Test set: Average loss: 4.1053,                   Accuracy: 20464/60000 (34.11%)
-= Testing Rotation 70 =-
Test set: Average loss: 5.2173,                   Accuracy: 14617/60000 (24.36%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.9681,                   Accuracy: 11386/60000 (18.98%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.5579,                   Accuracy: 9607/60000 (16.01%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.7373,                   Accuracy: 9089/60000 (15.15%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.8647,                   Accuracy: 9033/60000 (15.06%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.6744,                   Accuracy: 10017/60000 (16.69%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.5126,                   Accuracy: 13149/60000 (21.92%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.2997,                   Accuracy: 17085/60000 (28.48%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.1715,                   Accuracy: 21692/60000 (36.15%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.3797,                   Accuracy: 25558/60000 (42.60%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.5078,                   Accuracy: 27661/60000 (46.10%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.9600,                   Accuracy: 27518/60000 (45.86%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.6881,                   Accuracy: 27603/60000 (46.01%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.8030,                   Accuracy: 25623/60000 (42.71%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.5929,                   Accuracy: 21731/60000 (36.22%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.5829,                   Accuracy: 18054/60000 (30.09%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.7614,                   Accuracy: 14945/60000 (24.91%)
-= Testing Rotation 240 =-
Test set: Average loss: 7.0574,                   Accuracy: 12335/60000 (20.56%)
-= Testing Rotation 250 =-
Test set: Average loss: 7.2789,                   Accuracy: 10976/60000 (18.29%)
-= Testing Rotation 260 =-
Test set: Average loss: 7.2145,                   Accuracy: 10488/60000 (17.48%)
-= Testing Rotation 270 =-
Test set: Average loss: 7.0376,                   Accuracy: 10157/60000 (16.93%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.6285,                   Accuracy: 10100/60000 (16.83%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.9964,                   Accuracy: 10566/60000 (17.61%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.9636,                   Accuracy: 13076/60000 (21.79%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.5668,                   Accuracy: 21067/60000 (35.11%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.0684,                   Accuracy: 33854/60000 (56.42%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8745,                   Accuracy: 47310/60000 (78.85%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2520,                   Accuracy: 55915/60000 (93.19%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0693,                   Accuracy: 58793/60000 (97.99%)
{0: tensor(98.6817), 10: tensor(97.5650), 20: tensor(94.3433), 30: tensor(84.5700), 40: tensor(68.1900), 50: tensor(50.2767), 60: tensor(34.1067), 70: tensor(24.3617), 80: tensor(18.9767), 90: tensor(16.0117), 100: tensor(15.1483), 110: tensor(15.0550), 120: tensor(16.6950), 130: tensor(21.9150), 140: tensor(28.4750), 150: tensor(36.1533), 160: tensor(42.5967), 170: tensor(46.1017), 180: tensor(45.8633), 190: tensor(46.0050), 200: tensor(42.7050), 210: tensor(36.2183), 220: tensor(30.0900), 230: tensor(24.9083), 240: tensor(20.5583), 250: tensor(18.2933), 260: tensor(17.4800), 270: tensor(16.9283), 280: tensor(16.8333), 290: tensor(17.6100), 300: tensor(21.7933), 310: tensor(35.1117), 320: tensor(56.4233), 330: tensor(78.8500), 340: tensor(93.1917), 350: tensor(97.9883)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=86, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7449,                   Accuracy: 736/2000.0 (36.80%)



-= Testing valid =-
Test set: Average loss: 2.0916,                   Accuracy: 899/2000.0 (44.95%)



-= Testing valid =-
Test set: Average loss: 0.6171,                   Accuracy: 1629/2000.0 (81.45%)



-= Testing valid =-
Test set: Average loss: 0.2032,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1293,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1877,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 10 train accuracy: 97.45%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 20 train accuracy: 99.07%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.28%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.35%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.61%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0519,                   Accuracy: 59093/60000 (98.49%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0822,                   Accuracy: 58591/60000 (97.65%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2029,                   Accuracy: 56620/60000 (94.37%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5956,                   Accuracy: 50516/60000 (84.19%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3540,                   Accuracy: 40842/60000 (68.07%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.3814,                   Accuracy: 30244/60000 (50.41%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.5559,                   Accuracy: 20112/60000 (33.52%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.4080,                   Accuracy: 13995/60000 (23.33%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.1190,                   Accuracy: 10641/60000 (17.74%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.7531,                   Accuracy: 10066/60000 (16.78%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.1540,                   Accuracy: 10806/60000 (18.01%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.8722,                   Accuracy: 11633/60000 (19.39%)
-= Testing Rotation 120 =-
Test set: Average loss: 7.1341,                   Accuracy: 13423/60000 (22.37%)
-= Testing Rotation 130 =-
Test set: Average loss: 7.0223,                   Accuracy: 16005/60000 (26.67%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.7754,                   Accuracy: 19494/60000 (32.49%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.4864,                   Accuracy: 23161/60000 (38.60%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.5365,                   Accuracy: 25745/60000 (42.91%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.6230,                   Accuracy: 26939/60000 (44.90%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.8561,                   Accuracy: 26894/60000 (44.82%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.5795,                   Accuracy: 26892/60000 (44.82%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.4562,                   Accuracy: 25175/60000 (41.96%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.2697,                   Accuracy: 21732/60000 (36.22%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.0815,                   Accuracy: 18525/60000 (30.88%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.9729,                   Accuracy: 15927/60000 (26.55%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.0372,                   Accuracy: 13128/60000 (21.88%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.1531,                   Accuracy: 11356/60000 (18.93%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.2019,                   Accuracy: 10625/60000 (17.71%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.4101,                   Accuracy: 9425/60000 (15.71%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.2940,                   Accuracy: 8696/60000 (14.49%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.9041,                   Accuracy: 9675/60000 (16.12%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.0814,                   Accuracy: 13373/60000 (22.29%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.7302,                   Accuracy: 21648/60000 (36.08%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1525,                   Accuracy: 34269/60000 (57.12%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8905,                   Accuracy: 47430/60000 (79.05%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2484,                   Accuracy: 55814/60000 (93.02%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0763,                   Accuracy: 58641/60000 (97.74%)
{0: tensor(98.4883), 10: tensor(97.6517), 20: tensor(94.3667), 30: tensor(84.1933), 40: tensor(68.0700), 50: tensor(50.4067), 60: tensor(33.5200), 70: tensor(23.3250), 80: tensor(17.7350), 90: tensor(16.7767), 100: tensor(18.0100), 110: tensor(19.3883), 120: tensor(22.3717), 130: tensor(26.6750), 140: tensor(32.4900), 150: tensor(38.6017), 160: tensor(42.9083), 170: tensor(44.8983), 180: tensor(44.8233), 190: tensor(44.8200), 200: tensor(41.9583), 210: tensor(36.2200), 220: tensor(30.8750), 230: tensor(26.5450), 240: tensor(21.8800), 250: tensor(18.9267), 260: tensor(17.7083), 270: tensor(15.7083), 280: tensor(14.4933), 290: tensor(16.1250), 300: tensor(22.2883), 310: tensor(36.0800), 320: tensor(57.1150), 330: tensor(79.0500), 340: tensor(93.0233), 350: tensor(97.7350)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=87, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.1366,                   Accuracy: 1082/2000.0 (54.10%)



-= Testing valid =-
Test set: Average loss: 0.3876,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.2410,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.1366,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.3190,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.1758,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1282,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1299,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0683,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 10 train accuracy: 98.10%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0647,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 20 train accuracy: 98.88%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 30 train accuracy: 99.28%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.56%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.69%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0480,                   Accuracy: 59168/60000 (98.61%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0853,                   Accuracy: 58602/60000 (97.67%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2177,                   Accuracy: 56570/60000 (94.28%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6230,                   Accuracy: 50435/60000 (84.06%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4048,                   Accuracy: 40561/60000 (67.60%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.4704,                   Accuracy: 29949/60000 (49.92%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.5712,                   Accuracy: 21138/60000 (35.23%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.4728,                   Accuracy: 15382/60000 (25.64%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.9604,                   Accuracy: 11709/60000 (19.51%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.2601,                   Accuracy: 11772/60000 (19.62%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.3544,                   Accuracy: 12555/60000 (20.92%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.5929,                   Accuracy: 13892/60000 (23.15%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.7209,                   Accuracy: 15923/60000 (26.54%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.9910,                   Accuracy: 18222/60000 (30.37%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.1192,                   Accuracy: 21073/60000 (35.12%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.1498,                   Accuracy: 24105/60000 (40.17%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.5351,                   Accuracy: 26210/60000 (43.68%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.7992,                   Accuracy: 27166/60000 (45.28%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.0868,                   Accuracy: 26943/60000 (44.90%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.0924,                   Accuracy: 26281/60000 (43.80%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.0145,                   Accuracy: 24432/60000 (40.72%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.5860,                   Accuracy: 21978/60000 (36.63%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.3164,                   Accuracy: 20101/60000 (33.50%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.0812,                   Accuracy: 17841/60000 (29.74%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.9725,                   Accuracy: 15410/60000 (25.68%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.0973,                   Accuracy: 13766/60000 (22.94%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.0957,                   Accuracy: 12494/60000 (20.82%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.9789,                   Accuracy: 11283/60000 (18.81%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.7528,                   Accuracy: 11720/60000 (19.53%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.2610,                   Accuracy: 13389/60000 (22.32%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.4175,                   Accuracy: 16488/60000 (27.48%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.2601,                   Accuracy: 23455/60000 (39.09%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.9338,                   Accuracy: 34752/60000 (57.92%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8368,                   Accuracy: 47199/60000 (78.67%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2413,                   Accuracy: 55738/60000 (92.90%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0740,                   Accuracy: 58645/60000 (97.74%)
{0: tensor(98.6133), 10: tensor(97.6700), 20: tensor(94.2833), 30: tensor(84.0583), 40: tensor(67.6017), 50: tensor(49.9150), 60: tensor(35.2300), 70: tensor(25.6367), 80: tensor(19.5150), 90: tensor(19.6200), 100: tensor(20.9250), 110: tensor(23.1533), 120: tensor(26.5383), 130: tensor(30.3700), 140: tensor(35.1217), 150: tensor(40.1750), 160: tensor(43.6833), 170: tensor(45.2767), 180: tensor(44.9050), 190: tensor(43.8017), 200: tensor(40.7200), 210: tensor(36.6300), 220: tensor(33.5017), 230: tensor(29.7350), 240: tensor(25.6833), 250: tensor(22.9433), 260: tensor(20.8233), 270: tensor(18.8050), 280: tensor(19.5333), 290: tensor(22.3150), 300: tensor(27.4800), 310: tensor(39.0917), 320: tensor(57.9200), 330: tensor(78.6650), 340: tensor(92.8967), 350: tensor(97.7417)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=88, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4105,                   Accuracy: 487/2000.0 (24.35%)



-= Testing valid =-
Test set: Average loss: 0.3954,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.2216,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.1155,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1357,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.3149,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 10 train accuracy: 97.72%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0619,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0428,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 20 train accuracy: 98.91%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 30 train accuracy: 99.36%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 40 train accuracy: 99.65%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 50 train accuracy: 99.65%, valid accuracy 98.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0517,                   Accuracy: 59063/60000 (98.44%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0775,                   Accuracy: 58602/60000 (97.67%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1863,                   Accuracy: 56796/60000 (94.66%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5512,                   Accuracy: 50856/60000 (84.76%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3386,                   Accuracy: 39843/60000 (66.40%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.4114,                   Accuracy: 28455/60000 (47.42%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.5693,                   Accuracy: 19740/60000 (32.90%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.3366,                   Accuracy: 15518/60000 (25.86%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.9292,                   Accuracy: 12845/60000 (21.41%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.3765,                   Accuracy: 11749/60000 (19.58%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.4361,                   Accuracy: 11734/60000 (19.56%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.6034,                   Accuracy: 11211/60000 (18.68%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.7421,                   Accuracy: 11754/60000 (19.59%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.7589,                   Accuracy: 14483/60000 (24.14%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.7951,                   Accuracy: 17847/60000 (29.75%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.8693,                   Accuracy: 21286/60000 (35.48%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.0876,                   Accuracy: 23816/60000 (39.69%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.3016,                   Accuracy: 25304/60000 (42.17%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.6360,                   Accuracy: 25965/60000 (43.28%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.4843,                   Accuracy: 25742/60000 (42.90%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.4685,                   Accuracy: 24720/60000 (41.20%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.3837,                   Accuracy: 21582/60000 (35.97%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.2159,                   Accuracy: 17863/60000 (29.77%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.0683,                   Accuracy: 15343/60000 (25.57%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.0264,                   Accuracy: 13682/60000 (22.80%)
-= Testing Rotation 250 =-
Test set: Average loss: 5.8319,                   Accuracy: 12814/60000 (21.36%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.7825,                   Accuracy: 12258/60000 (20.43%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.8048,                   Accuracy: 11556/60000 (19.26%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.4604,                   Accuracy: 10437/60000 (17.40%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.1002,                   Accuracy: 10212/60000 (17.02%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.4329,                   Accuracy: 12607/60000 (21.01%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.2800,                   Accuracy: 20933/60000 (34.89%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.8850,                   Accuracy: 34267/60000 (57.11%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7964,                   Accuracy: 47519/60000 (79.20%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2279,                   Accuracy: 55984/60000 (93.31%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0751,                   Accuracy: 58641/60000 (97.74%)
{0: tensor(98.4383), 10: tensor(97.6700), 20: tensor(94.6600), 30: tensor(84.7600), 40: tensor(66.4050), 50: tensor(47.4250), 60: tensor(32.9000), 70: tensor(25.8633), 80: tensor(21.4083), 90: tensor(19.5817), 100: tensor(19.5567), 110: tensor(18.6850), 120: tensor(19.5900), 130: tensor(24.1383), 140: tensor(29.7450), 150: tensor(35.4767), 160: tensor(39.6933), 170: tensor(42.1733), 180: tensor(43.2750), 190: tensor(42.9033), 200: tensor(41.2000), 210: tensor(35.9700), 220: tensor(29.7717), 230: tensor(25.5717), 240: tensor(22.8033), 250: tensor(21.3567), 260: tensor(20.4300), 270: tensor(19.2600), 280: tensor(17.3950), 290: tensor(17.0200), 300: tensor(21.0117), 310: tensor(34.8883), 320: tensor(57.1117), 330: tensor(79.1983), 340: tensor(93.3067), 350: tensor(97.7350)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=89, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.4624,                   Accuracy: 968/2000.0 (48.40%)



-= Testing valid =-
Test set: Average loss: 1.4113,                   Accuracy: 1027/2000.0 (51.35%)



-= Testing valid =-
Test set: Average loss: 0.4121,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.2557,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.3309,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.1162,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0678,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.1284,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 10 train accuracy: 97.69%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0477,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 20 train accuracy: 98.68%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 30 train accuracy: 99.31%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 40 train accuracy: 99.60%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.54%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0472,                   Accuracy: 59153/60000 (98.59%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0802,                   Accuracy: 58672/60000 (97.79%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1975,                   Accuracy: 56884/60000 (94.81%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5490,                   Accuracy: 51976/60000 (86.63%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4072,                   Accuracy: 42067/60000 (70.11%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.5959,                   Accuracy: 30907/60000 (51.51%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.9652,                   Accuracy: 20181/60000 (33.63%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.9680,                   Accuracy: 13252/60000 (22.09%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.6063,                   Accuracy: 10353/60000 (17.25%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.8015,                   Accuracy: 11257/60000 (18.76%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.9686,                   Accuracy: 11201/60000 (18.67%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.2896,                   Accuracy: 11751/60000 (19.58%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.4394,                   Accuracy: 13331/60000 (22.22%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.4968,                   Accuracy: 16260/60000 (27.10%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.5439,                   Accuracy: 19944/60000 (33.24%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.7001,                   Accuracy: 23042/60000 (38.40%)
-= Testing Rotation 160 =-
Test set: Average loss: 7.0217,                   Accuracy: 25586/60000 (42.64%)
-= Testing Rotation 170 =-
Test set: Average loss: 7.3566,                   Accuracy: 27048/60000 (45.08%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.7697,                   Accuracy: 27233/60000 (45.39%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.4004,                   Accuracy: 27383/60000 (45.64%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.2155,                   Accuracy: 25724/60000 (42.87%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.9085,                   Accuracy: 22862/60000 (38.10%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.7019,                   Accuracy: 19072/60000 (31.79%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.7002,                   Accuracy: 16133/60000 (26.89%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.7795,                   Accuracy: 13346/60000 (22.24%)
-= Testing Rotation 250 =-
Test set: Average loss: 7.0079,                   Accuracy: 10880/60000 (18.13%)
-= Testing Rotation 260 =-
Test set: Average loss: 7.0547,                   Accuracy: 10491/60000 (17.49%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.9776,                   Accuracy: 10190/60000 (16.98%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.5435,                   Accuracy: 9522/60000 (15.87%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.8552,                   Accuracy: 10759/60000 (17.93%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.8047,                   Accuracy: 14220/60000 (23.70%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.4200,                   Accuracy: 22552/60000 (37.59%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.0169,                   Accuracy: 34554/60000 (57.59%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8995,                   Accuracy: 46776/60000 (77.96%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2601,                   Accuracy: 55583/60000 (92.64%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0793,                   Accuracy: 58576/60000 (97.63%)
{0: tensor(98.5883), 10: tensor(97.7867), 20: tensor(94.8067), 30: tensor(86.6267), 40: tensor(70.1117), 50: tensor(51.5117), 60: tensor(33.6350), 70: tensor(22.0867), 80: tensor(17.2550), 90: tensor(18.7617), 100: tensor(18.6683), 110: tensor(19.5850), 120: tensor(22.2183), 130: tensor(27.1000), 140: tensor(33.2400), 150: tensor(38.4033), 160: tensor(42.6433), 170: tensor(45.0800), 180: tensor(45.3883), 190: tensor(45.6383), 200: tensor(42.8733), 210: tensor(38.1033), 220: tensor(31.7867), 230: tensor(26.8883), 240: tensor(22.2433), 250: tensor(18.1333), 260: tensor(17.4850), 270: tensor(16.9833), 280: tensor(15.8700), 290: tensor(17.9317), 300: tensor(23.7000), 310: tensor(37.5867), 320: tensor(57.5900), 330: tensor(77.9600), 340: tensor(92.6383), 350: tensor(97.6267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=90, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.3958,                   Accuracy: 886/2000.0 (44.30%)



-= Testing valid =-
Test set: Average loss: 0.4427,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.2325,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.1626,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1594,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1122,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1728,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0684,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 10 train accuracy: 97.25%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 20 train accuracy: 98.71%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0486,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 30 train accuracy: 99.43%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.53%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 50 train accuracy: 99.61%, valid accuracy 99.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0543,                   Accuracy: 59074/60000 (98.46%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0776,                   Accuracy: 58679/60000 (97.80%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1808,                   Accuracy: 56860/60000 (94.77%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5288,                   Accuracy: 51055/60000 (85.09%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.1932,                   Accuracy: 41783/60000 (69.64%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.0754,                   Accuracy: 31969/60000 (53.28%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.0299,                   Accuracy: 22987/60000 (38.31%)
-= Testing Rotation 70 =-
Test set: Average loss: 3.8188,                   Accuracy: 16838/60000 (28.06%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.4321,                   Accuracy: 12613/60000 (21.02%)
-= Testing Rotation 90 =-
Test set: Average loss: 4.8585,                   Accuracy: 10270/60000 (17.12%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.2773,                   Accuracy: 9127/60000 (15.21%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.8382,                   Accuracy: 9382/60000 (15.64%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.1864,                   Accuracy: 11025/60000 (18.38%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.3321,                   Accuracy: 14417/60000 (24.03%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.1761,                   Accuracy: 18455/60000 (30.76%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.9565,                   Accuracy: 22201/60000 (37.00%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.7879,                   Accuracy: 25542/60000 (42.57%)
-= Testing Rotation 170 =-
Test set: Average loss: 5.8023,                   Accuracy: 26646/60000 (44.41%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.1533,                   Accuracy: 26623/60000 (44.37%)
-= Testing Rotation 190 =-
Test set: Average loss: 5.9008,                   Accuracy: 26760/60000 (44.60%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.7486,                   Accuracy: 25527/60000 (42.54%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.8135,                   Accuracy: 22787/60000 (37.98%)
-= Testing Rotation 220 =-
Test set: Average loss: 5.8025,                   Accuracy: 19965/60000 (33.28%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.1188,                   Accuracy: 16822/60000 (28.04%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.1616,                   Accuracy: 13964/60000 (23.27%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.2297,                   Accuracy: 10857/60000 (18.09%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.0674,                   Accuracy: 9486/60000 (15.81%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.9336,                   Accuracy: 8561/60000 (14.27%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.5870,                   Accuracy: 8106/60000 (13.51%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.1464,                   Accuracy: 8996/60000 (14.99%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.5578,                   Accuracy: 12212/60000 (20.35%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.4841,                   Accuracy: 20365/60000 (33.94%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.2068,                   Accuracy: 32086/60000 (53.48%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.0625,                   Accuracy: 44662/60000 (74.44%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3198,                   Accuracy: 54673/60000 (91.12%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0934,                   Accuracy: 58340/60000 (97.23%)
{0: tensor(98.4567), 10: tensor(97.7983), 20: tensor(94.7667), 30: tensor(85.0917), 40: tensor(69.6383), 50: tensor(53.2817), 60: tensor(38.3117), 70: tensor(28.0633), 80: tensor(21.0217), 90: tensor(17.1167), 100: tensor(15.2117), 110: tensor(15.6367), 120: tensor(18.3750), 130: tensor(24.0283), 140: tensor(30.7583), 150: tensor(37.0017), 160: tensor(42.5700), 170: tensor(44.4100), 180: tensor(44.3717), 190: tensor(44.6000), 200: tensor(42.5450), 210: tensor(37.9783), 220: tensor(33.2750), 230: tensor(28.0367), 240: tensor(23.2733), 250: tensor(18.0950), 260: tensor(15.8100), 270: tensor(14.2683), 280: tensor(13.5100), 290: tensor(14.9933), 300: tensor(20.3533), 310: tensor(33.9417), 320: tensor(53.4767), 330: tensor(74.4367), 340: tensor(91.1217), 350: tensor(97.2333)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=91, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8227,                   Accuracy: 630/2000.0 (31.50%)



-= Testing valid =-
Test set: Average loss: 0.8028,                   Accuracy: 1441/2000.0 (72.05%)



-= Testing valid =-
Test set: Average loss: 0.2105,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.1919,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1887,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 10 train accuracy: 97.62%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0756,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0712,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0520,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0691,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 20 train accuracy: 98.76%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 30 train accuracy: 99.12%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.54%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.51%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0503,                   Accuracy: 59124/60000 (98.54%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0873,                   Accuracy: 58510/60000 (97.52%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2267,                   Accuracy: 56249/60000 (93.75%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6195,                   Accuracy: 50098/60000 (83.50%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3486,                   Accuracy: 40755/60000 (67.93%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.4707,                   Accuracy: 29794/60000 (49.66%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.7588,                   Accuracy: 20119/60000 (33.53%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.9534,                   Accuracy: 13495/60000 (22.49%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.6245,                   Accuracy: 9532/60000 (15.89%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.1991,                   Accuracy: 8934/60000 (14.89%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.4228,                   Accuracy: 9114/60000 (15.19%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.8867,                   Accuracy: 9143/60000 (15.24%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.9031,                   Accuracy: 10960/60000 (18.27%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.7167,                   Accuracy: 14036/60000 (23.39%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.4804,                   Accuracy: 17793/60000 (29.66%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.2367,                   Accuracy: 21881/60000 (36.47%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.3235,                   Accuracy: 25251/60000 (42.08%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.5622,                   Accuracy: 26832/60000 (44.72%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.8834,                   Accuracy: 26881/60000 (44.80%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.7084,                   Accuracy: 26380/60000 (43.97%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.7649,                   Accuracy: 24445/60000 (40.74%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.3777,                   Accuracy: 22065/60000 (36.78%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.2599,                   Accuracy: 20498/60000 (34.16%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.2339,                   Accuracy: 18628/60000 (31.05%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.1830,                   Accuracy: 16909/60000 (28.18%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.2072,                   Accuracy: 15115/60000 (25.19%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.0281,                   Accuracy: 13467/60000 (22.44%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.1265,                   Accuracy: 12104/60000 (20.17%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.0456,                   Accuracy: 10366/60000 (17.28%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.7773,                   Accuracy: 10091/60000 (16.82%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.9420,                   Accuracy: 12671/60000 (21.12%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.6948,                   Accuracy: 20363/60000 (33.94%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1224,                   Accuracy: 33219/60000 (55.37%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8586,                   Accuracy: 47286/60000 (78.81%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2292,                   Accuracy: 56099/60000 (93.50%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0715,                   Accuracy: 58746/60000 (97.91%)
{0: tensor(98.5400), 10: tensor(97.5167), 20: tensor(93.7483), 30: tensor(83.4967), 40: tensor(67.9250), 50: tensor(49.6567), 60: tensor(33.5317), 70: tensor(22.4917), 80: tensor(15.8867), 90: tensor(14.8900), 100: tensor(15.1900), 110: tensor(15.2383), 120: tensor(18.2667), 130: tensor(23.3933), 140: tensor(29.6550), 150: tensor(36.4683), 160: tensor(42.0850), 170: tensor(44.7200), 180: tensor(44.8017), 190: tensor(43.9667), 200: tensor(40.7417), 210: tensor(36.7750), 220: tensor(34.1633), 230: tensor(31.0467), 240: tensor(28.1817), 250: tensor(25.1917), 260: tensor(22.4450), 270: tensor(20.1733), 280: tensor(17.2767), 290: tensor(16.8183), 300: tensor(21.1183), 310: tensor(33.9383), 320: tensor(55.3650), 330: tensor(78.8100), 340: tensor(93.4983), 350: tensor(97.9100)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=92, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.4071,                   Accuracy: 904/2000.0 (45.20%)



-= Testing valid =-
Test set: Average loss: 0.2852,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.1620,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1169,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1289,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0674,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0486,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0647,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 10 train accuracy: 97.51%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 20 train accuracy: 98.96%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.39%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.57%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.56%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0501,                   Accuracy: 59134/60000 (98.56%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0828,                   Accuracy: 58649/60000 (97.75%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2227,                   Accuracy: 56543/60000 (94.24%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6196,                   Accuracy: 50807/60000 (84.68%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4789,                   Accuracy: 40324/60000 (67.21%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.6746,                   Accuracy: 29200/60000 (48.67%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.9377,                   Accuracy: 19692/60000 (32.82%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.9666,                   Accuracy: 12914/60000 (21.52%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.5249,                   Accuracy: 9870/60000 (16.45%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.7947,                   Accuracy: 9412/60000 (15.69%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.7760,                   Accuracy: 9958/60000 (16.60%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.9090,                   Accuracy: 10747/60000 (17.91%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.0004,                   Accuracy: 12615/60000 (21.02%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.9889,                   Accuracy: 15024/60000 (25.04%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.9350,                   Accuracy: 18599/60000 (31.00%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.9997,                   Accuracy: 22396/60000 (37.33%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.3602,                   Accuracy: 24811/60000 (41.35%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.7218,                   Accuracy: 26011/60000 (43.35%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.1793,                   Accuracy: 26371/60000 (43.95%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.8566,                   Accuracy: 26908/60000 (44.85%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.8039,                   Accuracy: 25421/60000 (42.37%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.7139,                   Accuracy: 22213/60000 (37.02%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.5090,                   Accuracy: 18661/60000 (31.10%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.3668,                   Accuracy: 16008/60000 (26.68%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.2236,                   Accuracy: 13388/60000 (22.31%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.1639,                   Accuracy: 11712/60000 (19.52%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.0538,                   Accuracy: 10541/60000 (17.57%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.0254,                   Accuracy: 8778/60000 (14.63%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.7417,                   Accuracy: 8152/60000 (13.59%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.2454,                   Accuracy: 8709/60000 (14.52%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.5527,                   Accuracy: 11959/60000 (19.93%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.3921,                   Accuracy: 19816/60000 (33.03%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.0053,                   Accuracy: 32208/60000 (53.68%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8294,                   Accuracy: 46837/60000 (78.06%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2465,                   Accuracy: 55797/60000 (93.00%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0753,                   Accuracy: 58688/60000 (97.81%)
{0: tensor(98.5567), 10: tensor(97.7483), 20: tensor(94.2383), 30: tensor(84.6783), 40: tensor(67.2067), 50: tensor(48.6667), 60: tensor(32.8200), 70: tensor(21.5233), 80: tensor(16.4500), 90: tensor(15.6867), 100: tensor(16.5967), 110: tensor(17.9117), 120: tensor(21.0250), 130: tensor(25.0400), 140: tensor(30.9983), 150: tensor(37.3267), 160: tensor(41.3517), 170: tensor(43.3517), 180: tensor(43.9517), 190: tensor(44.8467), 200: tensor(42.3683), 210: tensor(37.0217), 220: tensor(31.1017), 230: tensor(26.6800), 240: tensor(22.3133), 250: tensor(19.5200), 260: tensor(17.5683), 270: tensor(14.6300), 280: tensor(13.5867), 290: tensor(14.5150), 300: tensor(19.9317), 310: tensor(33.0267), 320: tensor(53.6800), 330: tensor(78.0617), 340: tensor(92.9950), 350: tensor(97.8133)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=93, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.2486,                   Accuracy: 1132/2000.0 (56.60%)



-= Testing valid =-
Test set: Average loss: 0.7470,                   Accuracy: 1513/2000.0 (75.65%)



-= Testing valid =-
Test set: Average loss: 0.1267,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1112,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1457,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1046,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0752,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 10 train accuracy: 98.07%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0626,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0580,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 20 train accuracy: 98.65%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.43%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 40 train accuracy: 99.68%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 50 train accuracy: 99.60%, valid accuracy 98.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0569,                   Accuracy: 59041/60000 (98.40%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0945,                   Accuracy: 58495/60000 (97.49%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2526,                   Accuracy: 56099/60000 (93.50%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7219,                   Accuracy: 49181/60000 (81.97%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5640,                   Accuracy: 39248/60000 (65.41%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.7648,                   Accuracy: 28547/60000 (47.58%)
-= Testing Rotation 60 =-
Test set: Average loss: 4.0582,                   Accuracy: 20246/60000 (33.74%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.9886,                   Accuracy: 15474/60000 (25.79%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.5469,                   Accuracy: 12923/60000 (21.54%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.8788,                   Accuracy: 11895/60000 (19.83%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.0968,                   Accuracy: 12227/60000 (20.38%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.3610,                   Accuracy: 11561/60000 (19.27%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.6468,                   Accuracy: 11414/60000 (19.02%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.7423,                   Accuracy: 13125/60000 (21.88%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.7351,                   Accuracy: 16635/60000 (27.73%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.6336,                   Accuracy: 21733/60000 (36.22%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.8559,                   Accuracy: 25853/60000 (43.09%)
-= Testing Rotation 170 =-
Test set: Average loss: 7.2266,                   Accuracy: 27854/60000 (46.42%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.6722,                   Accuracy: 28063/60000 (46.77%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.7032,                   Accuracy: 27381/60000 (45.63%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.6381,                   Accuracy: 25066/60000 (41.78%)
-= Testing Rotation 210 =-
Test set: Average loss: 7.3579,                   Accuracy: 21826/60000 (36.38%)
-= Testing Rotation 220 =-
Test set: Average loss: 7.2042,                   Accuracy: 18361/60000 (30.60%)
-= Testing Rotation 230 =-
Test set: Average loss: 7.1091,                   Accuracy: 15881/60000 (26.47%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.9823,                   Accuracy: 13459/60000 (22.43%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.8145,                   Accuracy: 11704/60000 (19.51%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.5684,                   Accuracy: 10933/60000 (18.22%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.4774,                   Accuracy: 9195/60000 (15.32%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.2528,                   Accuracy: 9305/60000 (15.51%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.8157,                   Accuracy: 9726/60000 (16.21%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.0753,                   Accuracy: 11838/60000 (19.73%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.7304,                   Accuracy: 19750/60000 (32.92%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1536,                   Accuracy: 32499/60000 (54.17%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9016,                   Accuracy: 46331/60000 (77.22%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2471,                   Accuracy: 55745/60000 (92.91%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0762,                   Accuracy: 58676/60000 (97.79%)
{0: tensor(98.4017), 10: tensor(97.4917), 20: tensor(93.4983), 30: tensor(81.9683), 40: tensor(65.4133), 50: tensor(47.5783), 60: tensor(33.7433), 70: tensor(25.7900), 80: tensor(21.5383), 90: tensor(19.8250), 100: tensor(20.3783), 110: tensor(19.2683), 120: tensor(19.0233), 130: tensor(21.8750), 140: tensor(27.7250), 150: tensor(36.2217), 160: tensor(43.0883), 170: tensor(46.4233), 180: tensor(46.7717), 190: tensor(45.6350), 200: tensor(41.7767), 210: tensor(36.3767), 220: tensor(30.6017), 230: tensor(26.4683), 240: tensor(22.4317), 250: tensor(19.5067), 260: tensor(18.2217), 270: tensor(15.3250), 280: tensor(15.5083), 290: tensor(16.2100), 300: tensor(19.7300), 310: tensor(32.9167), 320: tensor(54.1650), 330: tensor(77.2183), 340: tensor(92.9083), 350: tensor(97.7933)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=94, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.2220,                   Accuracy: 1077/2000.0 (53.85%)



-= Testing valid =-
Test set: Average loss: 0.5521,                   Accuracy: 1675/2000.0 (83.75%)



-= Testing valid =-
Test set: Average loss: 0.1635,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.3082,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.1474,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0677,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0636,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.2163,                   Accuracy: 1865/2000.0 (93.25%)



Epoch 10 train accuracy: 97.86%, valid accuracy 93.25%
-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 20 train accuracy: 98.78%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.40%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.49%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 50 train accuracy: 99.70%, valid accuracy 98.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0532,                   Accuracy: 59115/60000 (98.53%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0833,                   Accuracy: 58604/60000 (97.67%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2154,                   Accuracy: 56459/60000 (94.10%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6966,                   Accuracy: 49005/60000 (81.68%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5914,                   Accuracy: 38158/60000 (63.60%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.7935,                   Accuracy: 27638/60000 (46.06%)
-= Testing Rotation 60 =-
Test set: Average loss: 4.0768,                   Accuracy: 19090/60000 (31.82%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.8641,                   Accuracy: 14311/60000 (23.85%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.5194,                   Accuracy: 11254/60000 (18.76%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.1666,                   Accuracy: 10425/60000 (17.38%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.2286,                   Accuracy: 10766/60000 (17.94%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.3153,                   Accuracy: 11185/60000 (18.64%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.1336,                   Accuracy: 12419/60000 (20.70%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.9834,                   Accuracy: 14575/60000 (24.29%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.7476,                   Accuracy: 17657/60000 (29.43%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.5466,                   Accuracy: 22470/60000 (37.45%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.7284,                   Accuracy: 26375/60000 (43.96%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.0163,                   Accuracy: 28633/60000 (47.72%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.6820,                   Accuracy: 29056/60000 (48.43%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.3464,                   Accuracy: 29023/60000 (48.37%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.4785,                   Accuracy: 27062/60000 (45.10%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.3434,                   Accuracy: 22529/60000 (37.55%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.3118,                   Accuracy: 18838/60000 (31.40%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.3803,                   Accuracy: 16216/60000 (27.03%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.3137,                   Accuracy: 13520/60000 (22.53%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.3116,                   Accuracy: 11735/60000 (19.56%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.1740,                   Accuracy: 10723/60000 (17.87%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.4165,                   Accuracy: 9285/60000 (15.48%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.2383,                   Accuracy: 8553/60000 (14.26%)
-= Testing Rotation 290 =-
Test set: Average loss: 6.0498,                   Accuracy: 8435/60000 (14.06%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.1462,                   Accuracy: 11855/60000 (19.76%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.9207,                   Accuracy: 20126/60000 (33.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.2529,                   Accuracy: 32818/60000 (54.70%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9158,                   Accuracy: 46826/60000 (78.04%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2414,                   Accuracy: 55887/60000 (93.14%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0740,                   Accuracy: 58709/60000 (97.85%)
{0: tensor(98.5250), 10: tensor(97.6733), 20: tensor(94.0983), 30: tensor(81.6750), 40: tensor(63.5967), 50: tensor(46.0633), 60: tensor(31.8167), 70: tensor(23.8517), 80: tensor(18.7567), 90: tensor(17.3750), 100: tensor(17.9433), 110: tensor(18.6417), 120: tensor(20.6983), 130: tensor(24.2917), 140: tensor(29.4283), 150: tensor(37.4500), 160: tensor(43.9583), 170: tensor(47.7217), 180: tensor(48.4267), 190: tensor(48.3717), 200: tensor(45.1033), 210: tensor(37.5483), 220: tensor(31.3967), 230: tensor(27.0267), 240: tensor(22.5333), 250: tensor(19.5583), 260: tensor(17.8717), 270: tensor(15.4750), 280: tensor(14.2550), 290: tensor(14.0583), 300: tensor(19.7583), 310: tensor(33.5433), 320: tensor(54.6967), 330: tensor(78.0433), 340: tensor(93.1450), 350: tensor(97.8483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=95, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 0.9345,                   Accuracy: 1441/2000.0 (72.05%)



-= Testing valid =-
Test set: Average loss: 0.7703,                   Accuracy: 1472/2000.0 (73.60%)



-= Testing valid =-
Test set: Average loss: 0.3210,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.4010,                   Accuracy: 1748/2000.0 (87.40%)



-= Testing valid =-
Test set: Average loss: 0.2516,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.1245,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1211,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1061,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1003,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 10 train accuracy: 97.74%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.0626,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 20 train accuracy: 99.15%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 30 train accuracy: 99.45%, valid accuracy 99.30%
-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.57%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 50 train accuracy: 99.59%, valid accuracy 98.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0590,                   Accuracy: 58954/60000 (98.26%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0939,                   Accuracy: 58356/60000 (97.26%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2289,                   Accuracy: 56114/60000 (93.52%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6004,                   Accuracy: 50285/60000 (83.81%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3099,                   Accuracy: 40371/60000 (67.29%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.3240,                   Accuracy: 29766/60000 (49.61%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.4916,                   Accuracy: 20347/60000 (33.91%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.3576,                   Accuracy: 14297/60000 (23.83%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.1300,                   Accuracy: 10366/60000 (17.28%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.6533,                   Accuracy: 9880/60000 (16.47%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.8342,                   Accuracy: 10389/60000 (17.32%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.8944,                   Accuracy: 11236/60000 (18.73%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.0019,                   Accuracy: 12636/60000 (21.06%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.9743,                   Accuracy: 14875/60000 (24.79%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.9798,                   Accuracy: 17961/60000 (29.93%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.0053,                   Accuracy: 21990/60000 (36.65%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.2349,                   Accuracy: 25086/60000 (41.81%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.5210,                   Accuracy: 26546/60000 (44.24%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.8202,                   Accuracy: 26993/60000 (44.99%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.5786,                   Accuracy: 26505/60000 (44.17%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.5023,                   Accuracy: 24676/60000 (41.13%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.4016,                   Accuracy: 21375/60000 (35.62%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.1896,                   Accuracy: 18296/60000 (30.49%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.0981,                   Accuracy: 15630/60000 (26.05%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.1584,                   Accuracy: 13122/60000 (21.87%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.1816,                   Accuracy: 11286/60000 (18.81%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.1080,                   Accuracy: 10440/60000 (17.40%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.2179,                   Accuracy: 10333/60000 (17.22%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.9465,                   Accuracy: 10152/60000 (16.92%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.5119,                   Accuracy: 10773/60000 (17.95%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.8424,                   Accuracy: 13680/60000 (22.80%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.7224,                   Accuracy: 20462/60000 (34.10%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.3005,                   Accuracy: 31919/60000 (53.20%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9878,                   Accuracy: 45667/60000 (76.11%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3003,                   Accuracy: 54953/60000 (91.59%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0865,                   Accuracy: 58491/60000 (97.49%)
{0: tensor(98.2567), 10: tensor(97.2600), 20: tensor(93.5233), 30: tensor(83.8083), 40: tensor(67.2850), 50: tensor(49.6100), 60: tensor(33.9117), 70: tensor(23.8283), 80: tensor(17.2767), 90: tensor(16.4667), 100: tensor(17.3150), 110: tensor(18.7267), 120: tensor(21.0600), 130: tensor(24.7917), 140: tensor(29.9350), 150: tensor(36.6500), 160: tensor(41.8100), 170: tensor(44.2433), 180: tensor(44.9883), 190: tensor(44.1750), 200: tensor(41.1267), 210: tensor(35.6250), 220: tensor(30.4933), 230: tensor(26.0500), 240: tensor(21.8700), 250: tensor(18.8100), 260: tensor(17.4000), 270: tensor(17.2217), 280: tensor(16.9200), 290: tensor(17.9550), 300: tensor(22.8000), 310: tensor(34.1033), 320: tensor(53.1983), 330: tensor(76.1117), 340: tensor(91.5883), 350: tensor(97.4850)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=96, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3321,                   Accuracy: 604/2000.0 (30.20%)



-= Testing valid =-
Test set: Average loss: 0.3992,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.2467,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1884,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1749,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1516,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 10 train accuracy: 97.66%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0637,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0596,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 20 train accuracy: 98.89%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.32%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 40 train accuracy: 99.54%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.62%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0566,                   Accuracy: 58993/60000 (98.32%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0980,                   Accuracy: 58434/60000 (97.39%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2541,                   Accuracy: 56044/60000 (93.41%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6897,                   Accuracy: 49661/60000 (82.77%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4895,                   Accuracy: 40007/60000 (66.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.5088,                   Accuracy: 30106/60000 (50.18%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.6052,                   Accuracy: 20964/60000 (34.94%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.4790,                   Accuracy: 14621/60000 (24.37%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.0387,                   Accuracy: 10606/60000 (17.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.3863,                   Accuracy: 10279/60000 (17.13%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.3476,                   Accuracy: 10616/60000 (17.69%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.6892,                   Accuracy: 10598/60000 (17.66%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.8862,                   Accuracy: 12348/60000 (20.58%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.9504,                   Accuracy: 15107/60000 (25.18%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.8360,                   Accuracy: 18543/60000 (30.91%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.7351,                   Accuracy: 22290/60000 (37.15%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.9442,                   Accuracy: 25196/60000 (41.99%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.2414,                   Accuracy: 26558/60000 (44.26%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.7746,                   Accuracy: 27209/60000 (45.35%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.6691,                   Accuracy: 26739/60000 (44.56%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.7215,                   Accuracy: 25039/60000 (41.73%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.5841,                   Accuracy: 21619/60000 (36.03%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.3995,                   Accuracy: 18937/60000 (31.56%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.3351,                   Accuracy: 16393/60000 (27.32%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.2942,                   Accuracy: 13989/60000 (23.32%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.2676,                   Accuracy: 12340/60000 (20.57%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.1259,                   Accuracy: 11039/60000 (18.40%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.0237,                   Accuracy: 10294/60000 (17.16%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.6432,                   Accuracy: 10442/60000 (17.40%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.2112,                   Accuracy: 11019/60000 (18.36%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.5408,                   Accuracy: 12861/60000 (21.43%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.5410,                   Accuracy: 19582/60000 (32.64%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1642,                   Accuracy: 31189/60000 (51.98%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9040,                   Accuracy: 45667/60000 (76.11%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2554,                   Accuracy: 55435/60000 (92.39%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0804,                   Accuracy: 58607/60000 (97.68%)
{0: tensor(98.3217), 10: tensor(97.3900), 20: tensor(93.4067), 30: tensor(82.7683), 40: tensor(66.6783), 50: tensor(50.1767), 60: tensor(34.9400), 70: tensor(24.3683), 80: tensor(17.6767), 90: tensor(17.1317), 100: tensor(17.6933), 110: tensor(17.6633), 120: tensor(20.5800), 130: tensor(25.1783), 140: tensor(30.9050), 150: tensor(37.1500), 160: tensor(41.9933), 170: tensor(44.2633), 180: tensor(45.3483), 190: tensor(44.5650), 200: tensor(41.7317), 210: tensor(36.0317), 220: tensor(31.5617), 230: tensor(27.3217), 240: tensor(23.3150), 250: tensor(20.5667), 260: tensor(18.3983), 270: tensor(17.1567), 280: tensor(17.4033), 290: tensor(18.3650), 300: tensor(21.4350), 310: tensor(32.6367), 320: tensor(51.9817), 330: tensor(76.1117), 340: tensor(92.3917), 350: tensor(97.6783)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=97, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8165,                   Accuracy: 652/2000.0 (32.60%)



-= Testing valid =-
Test set: Average loss: 0.6136,                   Accuracy: 1609/2000.0 (80.45%)



-= Testing valid =-
Test set: Average loss: 0.1796,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1429,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1753,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1253,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1424,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.0580,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 10 train accuracy: 97.54%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 20 train accuracy: 98.99%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.19%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 40 train accuracy: 99.50%, valid accuracy 99.30%
-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 50 train accuracy: 99.57%, valid accuracy 99.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0503,                   Accuracy: 59160/60000 (98.60%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0760,                   Accuracy: 58752/60000 (97.92%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1762,                   Accuracy: 56976/60000 (94.96%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5019,                   Accuracy: 52000/60000 (86.67%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.2157,                   Accuracy: 42639/60000 (71.07%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.2405,                   Accuracy: 31441/60000 (52.40%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.3851,                   Accuracy: 21567/60000 (35.94%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.2880,                   Accuracy: 15096/60000 (25.16%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.9112,                   Accuracy: 11650/60000 (19.42%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.2889,                   Accuracy: 10126/60000 (16.88%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.4670,                   Accuracy: 9463/60000 (15.77%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.8988,                   Accuracy: 10374/60000 (17.29%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.1073,                   Accuracy: 13003/60000 (21.67%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.2280,                   Accuracy: 16420/60000 (27.37%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.3680,                   Accuracy: 20429/60000 (34.05%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.6573,                   Accuracy: 23832/60000 (39.72%)
-= Testing Rotation 160 =-
Test set: Average loss: 7.0062,                   Accuracy: 25961/60000 (43.27%)
-= Testing Rotation 170 =-
Test set: Average loss: 7.1967,                   Accuracy: 27458/60000 (45.76%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.6006,                   Accuracy: 27676/60000 (46.13%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.0023,                   Accuracy: 27841/60000 (46.40%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.7865,                   Accuracy: 26008/60000 (43.35%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.6062,                   Accuracy: 23130/60000 (38.55%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.0456,                   Accuracy: 19602/60000 (32.67%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.7166,                   Accuracy: 17044/60000 (28.41%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.4765,                   Accuracy: 14779/60000 (24.63%)
-= Testing Rotation 250 =-
Test set: Average loss: 5.3667,                   Accuracy: 12460/60000 (20.77%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.3630,                   Accuracy: 11101/60000 (18.50%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.4894,                   Accuracy: 10410/60000 (17.35%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.4653,                   Accuracy: 9261/60000 (15.44%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.3024,                   Accuracy: 9707/60000 (16.18%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.4834,                   Accuracy: 13437/60000 (22.40%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.3691,                   Accuracy: 21364/60000 (35.61%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.9155,                   Accuracy: 34322/60000 (57.20%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8117,                   Accuracy: 47217/60000 (78.69%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2483,                   Accuracy: 55683/60000 (92.81%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0801,                   Accuracy: 58657/60000 (97.76%)
{0: tensor(98.6000), 10: tensor(97.9200), 20: tensor(94.9600), 30: tensor(86.6667), 40: tensor(71.0650), 50: tensor(52.4017), 60: tensor(35.9450), 70: tensor(25.1600), 80: tensor(19.4167), 90: tensor(16.8767), 100: tensor(15.7717), 110: tensor(17.2900), 120: tensor(21.6717), 130: tensor(27.3667), 140: tensor(34.0483), 150: tensor(39.7200), 160: tensor(43.2683), 170: tensor(45.7633), 180: tensor(46.1267), 190: tensor(46.4017), 200: tensor(43.3467), 210: tensor(38.5500), 220: tensor(32.6700), 230: tensor(28.4067), 240: tensor(24.6317), 250: tensor(20.7667), 260: tensor(18.5017), 270: tensor(17.3500), 280: tensor(15.4350), 290: tensor(16.1783), 300: tensor(22.3950), 310: tensor(35.6067), 320: tensor(57.2033), 330: tensor(78.6950), 340: tensor(92.8050), 350: tensor(97.7617)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=98, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 0.9177,                   Accuracy: 1622/2000.0 (81.10%)



-= Testing valid =-
Test set: Average loss: 0.4306,                   Accuracy: 1742/2000.0 (87.10%)



-= Testing valid =-
Test set: Average loss: 0.4391,                   Accuracy: 1732/2000.0 (86.60%)



-= Testing valid =-
Test set: Average loss: 0.1654,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1444,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1930/2000.0 (96.50%)



Epoch 10 train accuracy: 97.94%, valid accuracy 96.50%
-= Testing valid =-
Test set: Average loss: 0.0428,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0251,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 20 train accuracy: 98.90%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0200,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0206,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0197,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0187,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 30 train accuracy: 99.12%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0201,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0174,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0185,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0189,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0190,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0160,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0167,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0181,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0186,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 40 train accuracy: 99.38%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0157,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0173,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0161,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0159,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0168,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0152,                   Accuracy: 1992/2000.0 (99.60%)



-= Testing valid =-
Test set: Average loss: 0.0168,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0160,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0171,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0181,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 50 train accuracy: 99.40%, valid accuracy 99.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0498,                   Accuracy: 59129/60000 (98.55%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0828,                   Accuracy: 58613/60000 (97.69%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1850,                   Accuracy: 57000/60000 (95.00%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5083,                   Accuracy: 52102/60000 (86.84%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.2483,                   Accuracy: 42373/60000 (70.62%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.3587,                   Accuracy: 31386/60000 (52.31%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.5936,                   Accuracy: 21929/60000 (36.55%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.4652,                   Accuracy: 15448/60000 (25.75%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.0421,                   Accuracy: 11911/60000 (19.85%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.3791,                   Accuracy: 10858/60000 (18.10%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.2942,                   Accuracy: 11629/60000 (19.38%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.4159,                   Accuracy: 12239/60000 (20.40%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.7448,                   Accuracy: 13731/60000 (22.89%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.7288,                   Accuracy: 16632/60000 (27.72%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.8832,                   Accuracy: 19616/60000 (32.69%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.0452,                   Accuracy: 22989/60000 (38.31%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.4297,                   Accuracy: 25274/60000 (42.12%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.6620,                   Accuracy: 26842/60000 (44.74%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.8118,                   Accuracy: 26911/60000 (44.85%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.8382,                   Accuracy: 27113/60000 (45.19%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.5252,                   Accuracy: 26235/60000 (43.72%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.1499,                   Accuracy: 23812/60000 (39.69%)
-= Testing Rotation 220 =-
Test set: Average loss: 5.9686,                   Accuracy: 20791/60000 (34.65%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.0216,                   Accuracy: 18191/60000 (30.32%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.1637,                   Accuracy: 15392/60000 (25.65%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.2398,                   Accuracy: 13085/60000 (21.81%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.1542,                   Accuracy: 12531/60000 (20.89%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.0537,                   Accuracy: 10429/60000 (17.38%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.7974,                   Accuracy: 9566/60000 (15.94%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.2868,                   Accuracy: 10498/60000 (17.50%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.6262,                   Accuracy: 13185/60000 (21.98%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.2500,                   Accuracy: 22511/60000 (37.52%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.9722,                   Accuracy: 34502/60000 (57.50%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8437,                   Accuracy: 47545/60000 (79.24%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2264,                   Accuracy: 56128/60000 (93.55%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0766,                   Accuracy: 58617/60000 (97.69%)
{0: tensor(98.5483), 10: tensor(97.6883), 20: tensor(95.), 30: tensor(86.8367), 40: tensor(70.6217), 50: tensor(52.3100), 60: tensor(36.5483), 70: tensor(25.7467), 80: tensor(19.8517), 90: tensor(18.0967), 100: tensor(19.3817), 110: tensor(20.3983), 120: tensor(22.8850), 130: tensor(27.7200), 140: tensor(32.6933), 150: tensor(38.3150), 160: tensor(42.1233), 170: tensor(44.7367), 180: tensor(44.8517), 190: tensor(45.1883), 200: tensor(43.7250), 210: tensor(39.6867), 220: tensor(34.6517), 230: tensor(30.3183), 240: tensor(25.6533), 250: tensor(21.8083), 260: tensor(20.8850), 270: tensor(17.3817), 280: tensor(15.9433), 290: tensor(17.4967), 300: tensor(21.9750), 310: tensor(37.5183), 320: tensor(57.5033), 330: tensor(79.2417), 340: tensor(93.5467), 350: tensor(97.6950)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=99, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9655,                   Accuracy: 534/2000.0 (26.70%)



-= Testing valid =-
Test set: Average loss: 0.4067,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.3144,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.4203,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.1245,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1391,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.1850,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 10 train accuracy: 97.86%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 20 train accuracy: 98.91%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 30 train accuracy: 99.24%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 40 train accuracy: 99.46%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 50 train accuracy: 99.64%, valid accuracy 99.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0567,                   Accuracy: 59078/60000 (98.46%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0957,                   Accuracy: 58411/60000 (97.35%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2610,                   Accuracy: 55926/60000 (93.21%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7166,                   Accuracy: 49383/60000 (82.31%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.6091,                   Accuracy: 38643/60000 (64.40%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.8006,                   Accuracy: 27736/60000 (46.23%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.9641,                   Accuracy: 19774/60000 (32.96%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.9223,                   Accuracy: 14281/60000 (23.80%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.6053,                   Accuracy: 10322/60000 (17.20%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.3710,                   Accuracy: 9232/60000 (15.39%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.5888,                   Accuracy: 8995/60000 (14.99%)
-= Testing Rotation 110 =-
Test set: Average loss: 7.1207,                   Accuracy: 9522/60000 (15.87%)
-= Testing Rotation 120 =-
Test set: Average loss: 7.4572,                   Accuracy: 10478/60000 (17.46%)
-= Testing Rotation 130 =-
Test set: Average loss: 7.1813,                   Accuracy: 12728/60000 (21.21%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.8956,                   Accuracy: 15794/60000 (26.32%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.4547,                   Accuracy: 20281/60000 (33.80%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.2818,                   Accuracy: 24390/60000 (40.65%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.4047,                   Accuracy: 26466/60000 (44.11%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.8228,                   Accuracy: 26765/60000 (44.61%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.7911,                   Accuracy: 26944/60000 (44.91%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.0300,                   Accuracy: 25006/60000 (41.68%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.9287,                   Accuracy: 22493/60000 (37.49%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.8164,                   Accuracy: 19756/60000 (32.93%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.7590,                   Accuracy: 17183/60000 (28.64%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.6927,                   Accuracy: 14929/60000 (24.88%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.7621,                   Accuracy: 12323/60000 (20.54%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.5227,                   Accuracy: 10694/60000 (17.82%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.6860,                   Accuracy: 9106/60000 (15.18%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.4837,                   Accuracy: 8165/60000 (13.61%)
-= Testing Rotation 290 =-
Test set: Average loss: 6.1319,                   Accuracy: 8644/60000 (14.41%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.4483,                   Accuracy: 11076/60000 (18.46%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.9836,                   Accuracy: 19109/60000 (31.85%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.4229,                   Accuracy: 31281/60000 (52.13%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9720,                   Accuracy: 46092/60000 (76.82%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2485,                   Accuracy: 55779/60000 (92.96%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0800,                   Accuracy: 58600/60000 (97.67%)
{0: tensor(98.4633), 10: tensor(97.3517), 20: tensor(93.2100), 30: tensor(82.3050), 40: tensor(64.4050), 50: tensor(46.2267), 60: tensor(32.9567), 70: tensor(23.8017), 80: tensor(17.2033), 90: tensor(15.3867), 100: tensor(14.9917), 110: tensor(15.8700), 120: tensor(17.4633), 130: tensor(21.2133), 140: tensor(26.3233), 150: tensor(33.8017), 160: tensor(40.6500), 170: tensor(44.1100), 180: tensor(44.6083), 190: tensor(44.9067), 200: tensor(41.6767), 210: tensor(37.4883), 220: tensor(32.9267), 230: tensor(28.6383), 240: tensor(24.8817), 250: tensor(20.5383), 260: tensor(17.8233), 270: tensor(15.1767), 280: tensor(13.6083), 290: tensor(14.4067), 300: tensor(18.4600), 310: tensor(31.8483), 320: tensor(52.1350), 330: tensor(76.8200), 340: tensor(92.9650), 350: tensor(97.6667)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=100, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.1849,                   Accuracy: 1273/2000.0 (63.65%)



-= Testing valid =-
Test set: Average loss: 0.9395,                   Accuracy: 1481/2000.0 (74.05%)



-= Testing valid =-
Test set: Average loss: 0.2302,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2237,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.2053,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1192,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1255,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 10 train accuracy: 97.69%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0807,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 20 train accuracy: 99.00%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.47%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 40 train accuracy: 99.57%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1988/2000.0 (99.40%)



Epoch 50 train accuracy: 99.74%, valid accuracy 99.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0500,                   Accuracy: 59159/60000 (98.60%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0871,                   Accuracy: 58543/60000 (97.57%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2163,                   Accuracy: 56465/60000 (94.11%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6264,                   Accuracy: 50519/60000 (84.20%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4347,                   Accuracy: 40459/60000 (67.43%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.5298,                   Accuracy: 29949/60000 (49.92%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.7956,                   Accuracy: 20728/60000 (34.55%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.5730,                   Accuracy: 15268/60000 (25.45%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.1439,                   Accuracy: 10908/60000 (18.18%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.6364,                   Accuracy: 9224/60000 (15.37%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.4936,                   Accuracy: 10165/60000 (16.94%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.7570,                   Accuracy: 11279/60000 (18.80%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.0317,                   Accuracy: 13816/60000 (23.03%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.0235,                   Accuracy: 17511/60000 (29.18%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.9675,                   Accuracy: 21058/60000 (35.10%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.0251,                   Accuracy: 24332/60000 (40.55%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.3748,                   Accuracy: 26151/60000 (43.58%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.8007,                   Accuracy: 27067/60000 (45.11%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.2574,                   Accuracy: 27481/60000 (45.80%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.0502,                   Accuracy: 26613/60000 (44.35%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.9647,                   Accuracy: 24533/60000 (40.89%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.6967,                   Accuracy: 21663/60000 (36.10%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.6023,                   Accuracy: 18410/60000 (30.68%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.5918,                   Accuracy: 15954/60000 (26.59%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.7533,                   Accuracy: 13811/60000 (23.02%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.7581,                   Accuracy: 11728/60000 (19.55%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.7697,                   Accuracy: 10506/60000 (17.51%)
-= Testing Rotation 270 =-
Test set: Average loss: 7.0971,                   Accuracy: 8711/60000 (14.52%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.5603,                   Accuracy: 8235/60000 (13.73%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.8310,                   Accuracy: 9277/60000 (15.46%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.7741,                   Accuracy: 13949/60000 (23.25%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.2978,                   Accuracy: 22924/60000 (38.21%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.7898,                   Accuracy: 36099/60000 (60.17%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6638,                   Accuracy: 49667/60000 (82.78%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1849,                   Accuracy: 56812/60000 (94.69%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0662,                   Accuracy: 58852/60000 (98.09%)
{0: tensor(98.5983), 10: tensor(97.5717), 20: tensor(94.1083), 30: tensor(84.1983), 40: tensor(67.4317), 50: tensor(49.9150), 60: tensor(34.5467), 70: tensor(25.4467), 80: tensor(18.1800), 90: tensor(15.3733), 100: tensor(16.9417), 110: tensor(18.7983), 120: tensor(23.0267), 130: tensor(29.1850), 140: tensor(35.0967), 150: tensor(40.5533), 160: tensor(43.5850), 170: tensor(45.1117), 180: tensor(45.8017), 190: tensor(44.3550), 200: tensor(40.8883), 210: tensor(36.1050), 220: tensor(30.6833), 230: tensor(26.5900), 240: tensor(23.0183), 250: tensor(19.5467), 260: tensor(17.5100), 270: tensor(14.5183), 280: tensor(13.7250), 290: tensor(15.4617), 300: tensor(23.2483), 310: tensor(38.2067), 320: tensor(60.1650), 330: tensor(82.7783), 340: tensor(94.6867), 350: tensor(98.0867)}
