Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=41, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2341,                   Accuracy: 467/2000.0 (23.35%)



-= Testing valid =-
Test set: Average loss: 1.0935,                   Accuracy: 1232/2000.0 (61.60%)



-= Testing valid =-
Test set: Average loss: 0.4606,                   Accuracy: 1730/2000.0 (86.50%)



-= Testing valid =-
Test set: Average loss: 0.2794,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.1885,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.7059,                   Accuracy: 1612/2000.0 (80.60%)



-= Testing valid =-
Test set: Average loss: 0.1853,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1655,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1737,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1276,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 10 train accuracy: 96.22%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.1437,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1037,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1412,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 20 train accuracy: 97.88%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0655,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0595,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0662,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 30 train accuracy: 98.74%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0626,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0601,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0658,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 40 train accuracy: 99.12%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0575,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0535,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 50 train accuracy: 99.15%, valid accuracy 98.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0787,                   Accuracy: 58605/60000 (97.68%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1384,                   Accuracy: 57450/60000 (95.75%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2905,                   Accuracy: 54843/60000 (91.40%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6357,                   Accuracy: 48993/60000 (81.65%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0513,                   Accuracy: 42852/60000 (71.42%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1608,                   Accuracy: 41398/60000 (69.00%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7407,                   Accuracy: 47598/60000 (79.33%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3801,                   Accuracy: 53255/60000 (88.76%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1287,                   Accuracy: 57632/60000 (96.05%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0787,                   Accuracy: 58605/60000 (97.68%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1384,                   Accuracy: 57450/60000 (95.75%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2905,                   Accuracy: 54843/60000 (91.40%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6357,                   Accuracy: 48993/60000 (81.65%)
-= Testing Rotation 130 =-
Test set: Average loss: 1.0513,                   Accuracy: 42852/60000 (71.42%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.1608,                   Accuracy: 41398/60000 (69.00%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7407,                   Accuracy: 47598/60000 (79.33%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3801,                   Accuracy: 53255/60000 (88.76%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1287,                   Accuracy: 57632/60000 (96.05%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0787,                   Accuracy: 58605/60000 (97.68%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1384,                   Accuracy: 57450/60000 (95.75%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2905,                   Accuracy: 54843/60000 (91.40%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6357,                   Accuracy: 48993/60000 (81.65%)
-= Testing Rotation 220 =-
Test set: Average loss: 1.0513,                   Accuracy: 42852/60000 (71.42%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.1608,                   Accuracy: 41398/60000 (69.00%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7407,                   Accuracy: 47598/60000 (79.33%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3801,                   Accuracy: 53255/60000 (88.76%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1287,                   Accuracy: 57632/60000 (96.05%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0787,                   Accuracy: 58605/60000 (97.68%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1384,                   Accuracy: 57450/60000 (95.75%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2905,                   Accuracy: 54843/60000 (91.40%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6357,                   Accuracy: 48993/60000 (81.65%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0513,                   Accuracy: 42852/60000 (71.42%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1608,                   Accuracy: 41398/60000 (69.00%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7407,                   Accuracy: 47598/60000 (79.33%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3801,                   Accuracy: 53255/60000 (88.76%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1287,                   Accuracy: 57632/60000 (96.05%)
{0: tensor(97.6750), 10: tensor(95.7500), 20: tensor(91.4050), 30: tensor(81.6550), 40: tensor(71.4200), 50: tensor(68.9967), 60: tensor(79.3300), 70: tensor(88.7583), 80: tensor(96.0533), 90: tensor(97.6750), 100: tensor(95.7500), 110: tensor(91.4050), 120: tensor(81.6550), 130: tensor(71.4200), 140: tensor(68.9967), 150: tensor(79.3300), 160: tensor(88.7583), 170: tensor(96.0533), 180: tensor(97.6750), 190: tensor(95.7500), 200: tensor(91.4050), 210: tensor(81.6550), 220: tensor(71.4200), 230: tensor(68.9967), 240: tensor(79.3300), 250: tensor(88.7583), 260: tensor(96.0533), 270: tensor(97.6750), 280: tensor(95.7500), 290: tensor(91.4050), 300: tensor(81.6550), 310: tensor(71.4200), 320: tensor(68.9967), 330: tensor(79.3300), 340: tensor(88.7583), 350: tensor(96.0533)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=42, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3304,                   Accuracy: 453/2000.0 (22.65%)



-= Testing valid =-
Test set: Average loss: 2.0648,                   Accuracy: 725/2000.0 (36.25%)



-= Testing valid =-
Test set: Average loss: 1.0555,                   Accuracy: 1226/2000.0 (61.30%)



-= Testing valid =-
Test set: Average loss: 0.5057,                   Accuracy: 1707/2000.0 (85.35%)



-= Testing valid =-
Test set: Average loss: 0.3406,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.3059,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.1860,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.3417,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.3370,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.2438,                   Accuracy: 1836/2000.0 (91.80%)



Epoch 10 train accuracy: 95.97%, valid accuracy 91.80%
-= Testing valid =-
Test set: Average loss: 0.1402,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1713,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1150,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1576,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1409,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1202,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.2649,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 20 train accuracy: 97.54%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0664,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1171,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 30 train accuracy: 98.32%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0622,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0646,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 40 train accuracy: 98.68%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0718,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0701,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0755,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 50 train accuracy: 99.11%, valid accuracy 97.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0861,                   Accuracy: 58483/60000 (97.47%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1220,                   Accuracy: 57832/60000 (96.39%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2572,                   Accuracy: 55235/60000 (92.06%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5227,                   Accuracy: 50495/60000 (84.16%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7429,                   Accuracy: 46519/60000 (77.53%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8226,                   Accuracy: 45189/60000 (75.32%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6116,                   Accuracy: 48870/60000 (81.45%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3177,                   Accuracy: 54191/60000 (90.32%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1313,                   Accuracy: 57663/60000 (96.11%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0861,                   Accuracy: 58483/60000 (97.47%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1220,                   Accuracy: 57832/60000 (96.39%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2572,                   Accuracy: 55235/60000 (92.06%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5227,                   Accuracy: 50495/60000 (84.16%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7429,                   Accuracy: 46519/60000 (77.53%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8226,                   Accuracy: 45189/60000 (75.32%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6116,                   Accuracy: 48870/60000 (81.45%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3177,                   Accuracy: 54191/60000 (90.32%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1313,                   Accuracy: 57663/60000 (96.11%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0861,                   Accuracy: 58483/60000 (97.47%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1220,                   Accuracy: 57832/60000 (96.39%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2572,                   Accuracy: 55235/60000 (92.06%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5227,                   Accuracy: 50495/60000 (84.16%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7429,                   Accuracy: 46519/60000 (77.53%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8226,                   Accuracy: 45189/60000 (75.32%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6116,                   Accuracy: 48870/60000 (81.45%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3177,                   Accuracy: 54191/60000 (90.32%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1313,                   Accuracy: 57663/60000 (96.11%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0861,                   Accuracy: 58483/60000 (97.47%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1220,                   Accuracy: 57832/60000 (96.39%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2572,                   Accuracy: 55235/60000 (92.06%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5227,                   Accuracy: 50495/60000 (84.16%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7429,                   Accuracy: 46519/60000 (77.53%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8226,                   Accuracy: 45189/60000 (75.32%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6116,                   Accuracy: 48870/60000 (81.45%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3177,                   Accuracy: 54191/60000 (90.32%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1313,                   Accuracy: 57663/60000 (96.11%)
{0: tensor(97.4717), 10: tensor(96.3867), 20: tensor(92.0583), 30: tensor(84.1583), 40: tensor(77.5317), 50: tensor(75.3150), 60: tensor(81.4500), 70: tensor(90.3183), 80: tensor(96.1050), 90: tensor(97.4717), 100: tensor(96.3867), 110: tensor(92.0583), 120: tensor(84.1583), 130: tensor(77.5317), 140: tensor(75.3150), 150: tensor(81.4500), 160: tensor(90.3183), 170: tensor(96.1050), 180: tensor(97.4717), 190: tensor(96.3867), 200: tensor(92.0583), 210: tensor(84.1583), 220: tensor(77.5317), 230: tensor(75.3150), 240: tensor(81.4500), 250: tensor(90.3183), 260: tensor(96.1050), 270: tensor(97.4717), 280: tensor(96.3867), 290: tensor(92.0583), 300: tensor(84.1583), 310: tensor(77.5317), 320: tensor(75.3150), 330: tensor(81.4500), 340: tensor(90.3183), 350: tensor(96.1050)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=43, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9223,                   Accuracy: 623/2000.0 (31.15%)



-= Testing valid =-
Test set: Average loss: 1.5429,                   Accuracy: 765/2000.0 (38.25%)



-= Testing valid =-
Test set: Average loss: 0.6926,                   Accuracy: 1507/2000.0 (75.35%)



-= Testing valid =-
Test set: Average loss: 1.5001,                   Accuracy: 1224/2000.0 (61.20%)



-= Testing valid =-
Test set: Average loss: 0.4889,                   Accuracy: 1680/2000.0 (84.00%)



-= Testing valid =-
Test set: Average loss: 0.1690,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.2386,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.1561,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.2588,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 10 train accuracy: 96.74%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1212,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0698,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 20 train accuracy: 98.00%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0708,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0575,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0598,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0656,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 30 train accuracy: 98.85%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0472,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0486,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 40 train accuracy: 99.14%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0485,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0492,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 50 train accuracy: 99.11%, valid accuracy 98.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0757,                   Accuracy: 58660/60000 (97.77%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1250,                   Accuracy: 57777/60000 (96.29%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2625,                   Accuracy: 55373/60000 (92.29%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4981,                   Accuracy: 51250/60000 (85.42%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7619,                   Accuracy: 46480/60000 (77.47%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8281,                   Accuracy: 44985/60000 (74.97%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5414,                   Accuracy: 49709/60000 (82.85%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2614,                   Accuracy: 55016/60000 (91.69%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1171,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0757,                   Accuracy: 58660/60000 (97.77%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1250,                   Accuracy: 57777/60000 (96.29%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2625,                   Accuracy: 55373/60000 (92.29%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4981,                   Accuracy: 51250/60000 (85.42%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7619,                   Accuracy: 46480/60000 (77.47%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8281,                   Accuracy: 44985/60000 (74.97%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5414,                   Accuracy: 49709/60000 (82.85%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2614,                   Accuracy: 55016/60000 (91.69%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1171,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0757,                   Accuracy: 58660/60000 (97.77%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1250,                   Accuracy: 57777/60000 (96.29%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2625,                   Accuracy: 55373/60000 (92.29%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4981,                   Accuracy: 51250/60000 (85.42%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7619,                   Accuracy: 46480/60000 (77.47%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8281,                   Accuracy: 44985/60000 (74.97%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5414,                   Accuracy: 49709/60000 (82.85%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2614,                   Accuracy: 55016/60000 (91.69%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1171,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0757,                   Accuracy: 58660/60000 (97.77%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1250,                   Accuracy: 57777/60000 (96.29%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2625,                   Accuracy: 55373/60000 (92.29%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.4981,                   Accuracy: 51250/60000 (85.42%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7619,                   Accuracy: 46480/60000 (77.47%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8281,                   Accuracy: 44985/60000 (74.97%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5414,                   Accuracy: 49709/60000 (82.85%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2614,                   Accuracy: 55016/60000 (91.69%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1171,                   Accuracy: 57846/60000 (96.41%)
{0: tensor(97.7667), 10: tensor(96.2950), 20: tensor(92.2883), 30: tensor(85.4167), 40: tensor(77.4667), 50: tensor(74.9750), 60: tensor(82.8483), 70: tensor(91.6933), 80: tensor(96.4100), 90: tensor(97.7667), 100: tensor(96.2950), 110: tensor(92.2883), 120: tensor(85.4167), 130: tensor(77.4667), 140: tensor(74.9750), 150: tensor(82.8483), 160: tensor(91.6933), 170: tensor(96.4100), 180: tensor(97.7667), 190: tensor(96.2950), 200: tensor(92.2883), 210: tensor(85.4167), 220: tensor(77.4667), 230: tensor(74.9750), 240: tensor(82.8483), 250: tensor(91.6933), 260: tensor(96.4100), 270: tensor(97.7667), 280: tensor(96.2950), 290: tensor(92.2883), 300: tensor(85.4167), 310: tensor(77.4667), 320: tensor(74.9750), 330: tensor(82.8483), 340: tensor(91.6933), 350: tensor(96.4100)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=44, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.1925,                   Accuracy: 300/2000.0 (15.00%)



-= Testing valid =-
Test set: Average loss: 1.4984,                   Accuracy: 850/2000.0 (42.50%)



-= Testing valid =-
Test set: Average loss: 0.8571,                   Accuracy: 1426/2000.0 (71.30%)



-= Testing valid =-
Test set: Average loss: 0.7388,                   Accuracy: 1520/2000.0 (76.00%)



-= Testing valid =-
Test set: Average loss: 0.4667,                   Accuracy: 1647/2000.0 (82.35%)



-= Testing valid =-
Test set: Average loss: 0.2361,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.1353,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.2187,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.1501,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1245,                   Accuracy: 1919/2000.0 (95.95%)



Epoch 10 train accuracy: 96.36%, valid accuracy 95.95%
-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0608,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 20 train accuracy: 98.21%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 30 train accuracy: 98.75%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 40 train accuracy: 98.86%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 50 train accuracy: 99.09%, valid accuracy 98.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0862,                   Accuracy: 58490/60000 (97.48%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1249,                   Accuracy: 57811/60000 (96.35%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2670,                   Accuracy: 55343/60000 (92.24%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6268,                   Accuracy: 49433/60000 (82.39%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9787,                   Accuracy: 43657/60000 (72.76%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0519,                   Accuracy: 42285/60000 (70.47%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7375,                   Accuracy: 47394/60000 (78.99%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3272,                   Accuracy: 54216/60000 (90.36%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1225,                   Accuracy: 57742/60000 (96.24%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0862,                   Accuracy: 58490/60000 (97.48%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1249,                   Accuracy: 57811/60000 (96.35%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2670,                   Accuracy: 55343/60000 (92.24%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6268,                   Accuracy: 49433/60000 (82.39%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9787,                   Accuracy: 43657/60000 (72.76%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0519,                   Accuracy: 42285/60000 (70.47%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7375,                   Accuracy: 47394/60000 (78.99%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3272,                   Accuracy: 54216/60000 (90.36%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1225,                   Accuracy: 57742/60000 (96.24%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0862,                   Accuracy: 58490/60000 (97.48%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1249,                   Accuracy: 57811/60000 (96.35%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2670,                   Accuracy: 55343/60000 (92.24%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6268,                   Accuracy: 49433/60000 (82.39%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9787,                   Accuracy: 43657/60000 (72.76%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0519,                   Accuracy: 42285/60000 (70.47%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7375,                   Accuracy: 47394/60000 (78.99%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3272,                   Accuracy: 54216/60000 (90.36%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1225,                   Accuracy: 57742/60000 (96.24%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0862,                   Accuracy: 58490/60000 (97.48%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1249,                   Accuracy: 57811/60000 (96.35%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2670,                   Accuracy: 55343/60000 (92.24%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6268,                   Accuracy: 49433/60000 (82.39%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9787,                   Accuracy: 43657/60000 (72.76%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0519,                   Accuracy: 42285/60000 (70.47%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7375,                   Accuracy: 47394/60000 (78.99%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3272,                   Accuracy: 54216/60000 (90.36%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1225,                   Accuracy: 57742/60000 (96.24%)
{0: tensor(97.4833), 10: tensor(96.3517), 20: tensor(92.2383), 30: tensor(82.3883), 40: tensor(72.7617), 50: tensor(70.4750), 60: tensor(78.9900), 70: tensor(90.3600), 80: tensor(96.2367), 90: tensor(97.4833), 100: tensor(96.3517), 110: tensor(92.2383), 120: tensor(82.3883), 130: tensor(72.7617), 140: tensor(70.4750), 150: tensor(78.9900), 160: tensor(90.3600), 170: tensor(96.2367), 180: tensor(97.4833), 190: tensor(96.3517), 200: tensor(92.2383), 210: tensor(82.3883), 220: tensor(72.7617), 230: tensor(70.4750), 240: tensor(78.9900), 250: tensor(90.3600), 260: tensor(96.2367), 270: tensor(97.4833), 280: tensor(96.3517), 290: tensor(92.2383), 300: tensor(82.3883), 310: tensor(72.7617), 320: tensor(70.4750), 330: tensor(78.9900), 340: tensor(90.3600), 350: tensor(96.2367)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=45, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9785,                   Accuracy: 564/2000.0 (28.20%)



-= Testing valid =-
Test set: Average loss: 1.4762,                   Accuracy: 902/2000.0 (45.10%)



-= Testing valid =-
Test set: Average loss: 0.7683,                   Accuracy: 1481/2000.0 (74.05%)



-= Testing valid =-
Test set: Average loss: 1.2783,                   Accuracy: 1154/2000.0 (57.70%)



-= Testing valid =-
Test set: Average loss: 0.3228,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.7614,                   Accuracy: 1424/2000.0 (71.20%)



-= Testing valid =-
Test set: Average loss: 0.2802,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.7358,                   Accuracy: 1555/2000.0 (77.75%)



-= Testing valid =-
Test set: Average loss: 0.1393,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1301,                   Accuracy: 1920/2000.0 (96.00%)



Epoch 10 train accuracy: 96.05%, valid accuracy 96.00%
-= Testing valid =-
Test set: Average loss: 0.1066,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1120,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1134,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0937,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 20 train accuracy: 97.99%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0684,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0644,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0632,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0668,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0701,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0683,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 30 train accuracy: 98.50%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0560,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0597,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 40 train accuracy: 99.06%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0575,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0572,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0559,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0547,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0568,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 50 train accuracy: 99.11%, valid accuracy 98.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0737,                   Accuracy: 58690/60000 (97.82%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1190,                   Accuracy: 57871/60000 (96.45%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2623,                   Accuracy: 55536/60000 (92.56%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5657,                   Accuracy: 50456/60000 (84.09%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7547,                   Accuracy: 46896/60000 (78.16%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.7758,                   Accuracy: 46055/60000 (76.76%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5152,                   Accuracy: 50485/60000 (84.14%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2546,                   Accuracy: 55287/60000 (92.14%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1105,                   Accuracy: 57940/60000 (96.57%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0737,                   Accuracy: 58690/60000 (97.82%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1190,                   Accuracy: 57871/60000 (96.45%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2623,                   Accuracy: 55536/60000 (92.56%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5657,                   Accuracy: 50456/60000 (84.09%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7547,                   Accuracy: 46897/60000 (78.16%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.7758,                   Accuracy: 46055/60000 (76.76%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5152,                   Accuracy: 50485/60000 (84.14%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2546,                   Accuracy: 55287/60000 (92.14%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1105,                   Accuracy: 57940/60000 (96.57%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0737,                   Accuracy: 58690/60000 (97.82%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1190,                   Accuracy: 57871/60000 (96.45%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2623,                   Accuracy: 55536/60000 (92.56%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5657,                   Accuracy: 50456/60000 (84.09%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7547,                   Accuracy: 46896/60000 (78.16%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.7758,                   Accuracy: 46055/60000 (76.76%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5152,                   Accuracy: 50485/60000 (84.14%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2546,                   Accuracy: 55287/60000 (92.14%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1105,                   Accuracy: 57940/60000 (96.57%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0737,                   Accuracy: 58690/60000 (97.82%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1190,                   Accuracy: 57871/60000 (96.45%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2623,                   Accuracy: 55536/60000 (92.56%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5657,                   Accuracy: 50456/60000 (84.09%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7547,                   Accuracy: 46896/60000 (78.16%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.7758,                   Accuracy: 46055/60000 (76.76%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5152,                   Accuracy: 50485/60000 (84.14%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2546,                   Accuracy: 55287/60000 (92.14%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1105,                   Accuracy: 57940/60000 (96.57%)
{0: tensor(97.8167), 10: tensor(96.4517), 20: tensor(92.5600), 30: tensor(84.0933), 40: tensor(78.1600), 50: tensor(76.7583), 60: tensor(84.1417), 70: tensor(92.1450), 80: tensor(96.5667), 90: tensor(97.8167), 100: tensor(96.4517), 110: tensor(92.5600), 120: tensor(84.0933), 130: tensor(78.1617), 140: tensor(76.7583), 150: tensor(84.1417), 160: tensor(92.1450), 170: tensor(96.5667), 180: tensor(97.8167), 190: tensor(96.4517), 200: tensor(92.5600), 210: tensor(84.0933), 220: tensor(78.1600), 230: tensor(76.7583), 240: tensor(84.1417), 250: tensor(92.1450), 260: tensor(96.5667), 270: tensor(97.8167), 280: tensor(96.4517), 290: tensor(92.5600), 300: tensor(84.0933), 310: tensor(78.1600), 320: tensor(76.7583), 330: tensor(84.1417), 340: tensor(92.1450), 350: tensor(96.5667)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=46, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7823,                   Accuracy: 536/2000.0 (26.80%)



-= Testing valid =-
Test set: Average loss: 1.4411,                   Accuracy: 877/2000.0 (43.85%)



-= Testing valid =-
Test set: Average loss: 0.5251,                   Accuracy: 1642/2000.0 (82.10%)



-= Testing valid =-
Test set: Average loss: 0.3370,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.1645,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.2246,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.1722,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1581,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1255,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1294,                   Accuracy: 1916/2000.0 (95.80%)



Epoch 10 train accuracy: 96.74%, valid accuracy 95.80%
-= Testing valid =-
Test set: Average loss: 0.0723,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0701,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.1237,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0756,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0677,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0608,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 20 train accuracy: 98.15%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0547,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 98.69%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 40 train accuracy: 98.96%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0428,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0445,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 50 train accuracy: 99.19%, valid accuracy 98.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0777,                   Accuracy: 58621/60000 (97.70%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1269,                   Accuracy: 57650/60000 (96.08%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2557,                   Accuracy: 55387/60000 (92.31%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5107,                   Accuracy: 51060/60000 (85.10%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8489,                   Accuracy: 45329/60000 (75.55%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8944,                   Accuracy: 44471/60000 (74.12%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6016,                   Accuracy: 49382/60000 (82.30%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2682,                   Accuracy: 55233/60000 (92.06%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1088,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0777,                   Accuracy: 58621/60000 (97.70%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1269,                   Accuracy: 57650/60000 (96.08%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2557,                   Accuracy: 55387/60000 (92.31%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5107,                   Accuracy: 51060/60000 (85.10%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8489,                   Accuracy: 45329/60000 (75.55%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8944,                   Accuracy: 44471/60000 (74.12%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6016,                   Accuracy: 49382/60000 (82.30%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2682,                   Accuracy: 55233/60000 (92.06%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1088,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0777,                   Accuracy: 58621/60000 (97.70%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1269,                   Accuracy: 57650/60000 (96.08%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2557,                   Accuracy: 55387/60000 (92.31%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5107,                   Accuracy: 51060/60000 (85.10%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8489,                   Accuracy: 45329/60000 (75.55%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8944,                   Accuracy: 44471/60000 (74.12%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6016,                   Accuracy: 49382/60000 (82.30%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2682,                   Accuracy: 55233/60000 (92.06%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1088,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0777,                   Accuracy: 58621/60000 (97.70%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1269,                   Accuracy: 57650/60000 (96.08%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2557,                   Accuracy: 55387/60000 (92.31%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5107,                   Accuracy: 51060/60000 (85.10%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8489,                   Accuracy: 45329/60000 (75.55%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8944,                   Accuracy: 44471/60000 (74.12%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6016,                   Accuracy: 49382/60000 (82.30%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2682,                   Accuracy: 55233/60000 (92.06%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1088,                   Accuracy: 58009/60000 (96.68%)
{0: tensor(97.7017), 10: tensor(96.0833), 20: tensor(92.3117), 30: tensor(85.1000), 40: tensor(75.5483), 50: tensor(74.1183), 60: tensor(82.3033), 70: tensor(92.0550), 80: tensor(96.6817), 90: tensor(97.7017), 100: tensor(96.0833), 110: tensor(92.3117), 120: tensor(85.1000), 130: tensor(75.5483), 140: tensor(74.1183), 150: tensor(82.3033), 160: tensor(92.0550), 170: tensor(96.6817), 180: tensor(97.7017), 190: tensor(96.0833), 200: tensor(92.3117), 210: tensor(85.1000), 220: tensor(75.5483), 230: tensor(74.1183), 240: tensor(82.3033), 250: tensor(92.0550), 260: tensor(96.6817), 270: tensor(97.7017), 280: tensor(96.0833), 290: tensor(92.3117), 300: tensor(85.1000), 310: tensor(75.5483), 320: tensor(74.1183), 330: tensor(82.3033), 340: tensor(92.0550), 350: tensor(96.6817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=47, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0864,                   Accuracy: 220/2000.0 (11.00%)



-= Testing valid =-
Test set: Average loss: 1.7216,                   Accuracy: 825/2000.0 (41.25%)



-= Testing valid =-
Test set: Average loss: 1.1659,                   Accuracy: 1170/2000.0 (58.50%)



-= Testing valid =-
Test set: Average loss: 0.7706,                   Accuracy: 1534/2000.0 (76.70%)



-= Testing valid =-
Test set: Average loss: 0.3737,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.6510,                   Accuracy: 1616/2000.0 (80.80%)



-= Testing valid =-
Test set: Average loss: 0.2600,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.1949,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1596,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1885,                   Accuracy: 1888/2000.0 (94.40%)



Epoch 10 train accuracy: 96.32%, valid accuracy 94.40%
-= Testing valid =-
Test set: Average loss: 0.1289,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1175,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1663,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1426,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1230,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 20 train accuracy: 97.74%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1092,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 30 train accuracy: 98.39%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0686,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0825,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0746,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 40 train accuracy: 98.82%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 50 train accuracy: 98.89%, valid accuracy 97.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0844,                   Accuracy: 58520/60000 (97.53%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1197,                   Accuracy: 57893/60000 (96.49%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2472,                   Accuracy: 55643/60000 (92.74%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5603,                   Accuracy: 50226/60000 (83.71%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8670,                   Accuracy: 45540/60000 (75.90%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8919,                   Accuracy: 45115/60000 (75.19%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5803,                   Accuracy: 50069/60000 (83.45%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2768,                   Accuracy: 55147/60000 (91.91%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1173,                   Accuracy: 57901/60000 (96.50%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0844,                   Accuracy: 58520/60000 (97.53%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1197,                   Accuracy: 57893/60000 (96.49%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2472,                   Accuracy: 55643/60000 (92.74%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5603,                   Accuracy: 50226/60000 (83.71%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8670,                   Accuracy: 45540/60000 (75.90%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8919,                   Accuracy: 45115/60000 (75.19%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5803,                   Accuracy: 50069/60000 (83.45%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2768,                   Accuracy: 55147/60000 (91.91%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1173,                   Accuracy: 57901/60000 (96.50%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0844,                   Accuracy: 58520/60000 (97.53%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1197,                   Accuracy: 57893/60000 (96.49%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2472,                   Accuracy: 55643/60000 (92.74%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5603,                   Accuracy: 50226/60000 (83.71%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8670,                   Accuracy: 45540/60000 (75.90%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8919,                   Accuracy: 45115/60000 (75.19%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5803,                   Accuracy: 50069/60000 (83.45%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2768,                   Accuracy: 55147/60000 (91.91%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1173,                   Accuracy: 57901/60000 (96.50%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0844,                   Accuracy: 58520/60000 (97.53%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1197,                   Accuracy: 57893/60000 (96.49%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2472,                   Accuracy: 55643/60000 (92.74%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5603,                   Accuracy: 50226/60000 (83.71%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8670,                   Accuracy: 45540/60000 (75.90%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8919,                   Accuracy: 45115/60000 (75.19%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5803,                   Accuracy: 50068/60000 (83.45%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2768,                   Accuracy: 55147/60000 (91.91%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1173,                   Accuracy: 57901/60000 (96.50%)
{0: tensor(97.5333), 10: tensor(96.4883), 20: tensor(92.7383), 30: tensor(83.7100), 40: tensor(75.9000), 50: tensor(75.1917), 60: tensor(83.4483), 70: tensor(91.9117), 80: tensor(96.5017), 90: tensor(97.5333), 100: tensor(96.4883), 110: tensor(92.7383), 120: tensor(83.7100), 130: tensor(75.9000), 140: tensor(75.1917), 150: tensor(83.4483), 160: tensor(91.9117), 170: tensor(96.5017), 180: tensor(97.5333), 190: tensor(96.4883), 200: tensor(92.7383), 210: tensor(83.7100), 220: tensor(75.9000), 230: tensor(75.1917), 240: tensor(83.4483), 250: tensor(91.9117), 260: tensor(96.5017), 270: tensor(97.5333), 280: tensor(96.4883), 290: tensor(92.7383), 300: tensor(83.7100), 310: tensor(75.9000), 320: tensor(75.1917), 330: tensor(83.4467), 340: tensor(91.9117), 350: tensor(96.5017)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=48, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2482,                   Accuracy: 345/2000.0 (17.25%)



-= Testing valid =-
Test set: Average loss: 2.2814,                   Accuracy: 448/2000.0 (22.40%)



-= Testing valid =-
Test set: Average loss: 0.6869,                   Accuracy: 1505/2000.0 (75.25%)



-= Testing valid =-
Test set: Average loss: 0.6541,                   Accuracy: 1590/2000.0 (79.50%)



-= Testing valid =-
Test set: Average loss: 0.3391,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.3381,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.2340,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.1439,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.3003,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 10 train accuracy: 96.09%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1196,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0552,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.1011,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 20 train accuracy: 97.86%, valid accuracy 96.45%
-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 30 train accuracy: 98.36%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0469,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 40 train accuracy: 98.88%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0409,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 50 train accuracy: 98.93%, valid accuracy 98.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0725,                   Accuracy: 58709/60000 (97.85%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1176,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2494,                   Accuracy: 55538/60000 (92.56%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5875,                   Accuracy: 49485/60000 (82.47%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9684,                   Accuracy: 42580/60000 (70.97%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0555,                   Accuracy: 40728/60000 (67.88%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7195,                   Accuracy: 46256/60000 (77.09%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3099,                   Accuracy: 53973/60000 (89.96%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1175,                   Accuracy: 57813/60000 (96.36%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0725,                   Accuracy: 58709/60000 (97.85%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1176,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2494,                   Accuracy: 55538/60000 (92.56%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5875,                   Accuracy: 49485/60000 (82.47%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9684,                   Accuracy: 42580/60000 (70.97%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0555,                   Accuracy: 40728/60000 (67.88%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7195,                   Accuracy: 46256/60000 (77.09%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3099,                   Accuracy: 53973/60000 (89.96%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1175,                   Accuracy: 57813/60000 (96.36%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0725,                   Accuracy: 58709/60000 (97.85%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1176,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2494,                   Accuracy: 55538/60000 (92.56%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5875,                   Accuracy: 49485/60000 (82.47%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9684,                   Accuracy: 42580/60000 (70.97%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0555,                   Accuracy: 40728/60000 (67.88%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7195,                   Accuracy: 46256/60000 (77.09%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3099,                   Accuracy: 53973/60000 (89.96%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1175,                   Accuracy: 57813/60000 (96.36%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0725,                   Accuracy: 58709/60000 (97.85%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1176,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2494,                   Accuracy: 55538/60000 (92.56%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5875,                   Accuracy: 49485/60000 (82.47%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9684,                   Accuracy: 42580/60000 (70.97%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0555,                   Accuracy: 40728/60000 (67.88%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7195,                   Accuracy: 46256/60000 (77.09%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3099,                   Accuracy: 53973/60000 (89.96%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1175,                   Accuracy: 57813/60000 (96.36%)
{0: tensor(97.8483), 10: tensor(96.5350), 20: tensor(92.5633), 30: tensor(82.4750), 40: tensor(70.9667), 50: tensor(67.8800), 60: tensor(77.0933), 70: tensor(89.9550), 80: tensor(96.3550), 90: tensor(97.8483), 100: tensor(96.5350), 110: tensor(92.5633), 120: tensor(82.4750), 130: tensor(70.9667), 140: tensor(67.8800), 150: tensor(77.0933), 160: tensor(89.9550), 170: tensor(96.3550), 180: tensor(97.8483), 190: tensor(96.5350), 200: tensor(92.5633), 210: tensor(82.4750), 220: tensor(70.9667), 230: tensor(67.8800), 240: tensor(77.0933), 250: tensor(89.9550), 260: tensor(96.3550), 270: tensor(97.8483), 280: tensor(96.5350), 290: tensor(92.5633), 300: tensor(82.4750), 310: tensor(70.9667), 320: tensor(67.8800), 330: tensor(77.0933), 340: tensor(89.9550), 350: tensor(96.3550)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=49, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1508,                   Accuracy: 443/2000.0 (22.15%)



-= Testing valid =-
Test set: Average loss: 1.8568,                   Accuracy: 798/2000.0 (39.90%)



-= Testing valid =-
Test set: Average loss: 1.0259,                   Accuracy: 1316/2000.0 (65.80%)



-= Testing valid =-
Test set: Average loss: 0.6981,                   Accuracy: 1529/2000.0 (76.45%)



-= Testing valid =-
Test set: Average loss: 0.3528,                   Accuracy: 1780/2000.0 (89.00%)



-= Testing valid =-
Test set: Average loss: 0.3200,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.1966,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1672,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1335,                   Accuracy: 1907/2000.0 (95.35%)



Epoch 10 train accuracy: 96.50%, valid accuracy 95.35%
-= Testing valid =-
Test set: Average loss: 0.1231,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1570,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0644,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 20 train accuracy: 97.80%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0622,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0645,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 30 train accuracy: 98.60%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0567,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 40 train accuracy: 99.06%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0477,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 50 train accuracy: 98.97%, valid accuracy 98.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0776,                   Accuracy: 58629/60000 (97.71%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1238,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2775,                   Accuracy: 55083/60000 (91.81%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6002,                   Accuracy: 49337/60000 (82.23%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0029,                   Accuracy: 42774/60000 (71.29%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0864,                   Accuracy: 41233/60000 (68.72%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7791,                   Accuracy: 46080/60000 (76.80%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3632,                   Accuracy: 53452/60000 (89.09%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1310,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0776,                   Accuracy: 58629/60000 (97.71%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1238,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2775,                   Accuracy: 55083/60000 (91.81%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6002,                   Accuracy: 49337/60000 (82.23%)
-= Testing Rotation 130 =-
Test set: Average loss: 1.0029,                   Accuracy: 42774/60000 (71.29%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0864,                   Accuracy: 41233/60000 (68.72%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7791,                   Accuracy: 46080/60000 (76.80%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3632,                   Accuracy: 53452/60000 (89.09%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1310,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0776,                   Accuracy: 58629/60000 (97.71%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1238,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2775,                   Accuracy: 55083/60000 (91.81%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6002,                   Accuracy: 49337/60000 (82.23%)
-= Testing Rotation 220 =-
Test set: Average loss: 1.0029,                   Accuracy: 42774/60000 (71.29%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0864,                   Accuracy: 41233/60000 (68.72%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7791,                   Accuracy: 46080/60000 (76.80%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3632,                   Accuracy: 53452/60000 (89.09%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1310,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0776,                   Accuracy: 58629/60000 (97.71%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1238,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2775,                   Accuracy: 55083/60000 (91.81%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6002,                   Accuracy: 49337/60000 (82.23%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0029,                   Accuracy: 42774/60000 (71.29%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0864,                   Accuracy: 41233/60000 (68.72%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7791,                   Accuracy: 46080/60000 (76.80%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3632,                   Accuracy: 53452/60000 (89.09%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1310,                   Accuracy: 57685/60000 (96.14%)
{0: tensor(97.7150), 10: tensor(96.3833), 20: tensor(91.8050), 30: tensor(82.2283), 40: tensor(71.2900), 50: tensor(68.7217), 60: tensor(76.8000), 70: tensor(89.0867), 80: tensor(96.1417), 90: tensor(97.7150), 100: tensor(96.3833), 110: tensor(91.8050), 120: tensor(82.2283), 130: tensor(71.2900), 140: tensor(68.7217), 150: tensor(76.8000), 160: tensor(89.0867), 170: tensor(96.1417), 180: tensor(97.7150), 190: tensor(96.3833), 200: tensor(91.8050), 210: tensor(82.2283), 220: tensor(71.2900), 230: tensor(68.7217), 240: tensor(76.8000), 250: tensor(89.0867), 260: tensor(96.1417), 270: tensor(97.7150), 280: tensor(96.3833), 290: tensor(91.8050), 300: tensor(82.2283), 310: tensor(71.2900), 320: tensor(68.7217), 330: tensor(76.8000), 340: tensor(89.0867), 350: tensor(96.1417)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=50, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.6020,                   Accuracy: 880/2000.0 (44.00%)



-= Testing valid =-
Test set: Average loss: 0.8835,                   Accuracy: 1587/2000.0 (79.35%)



-= Testing valid =-
Test set: Average loss: 0.8230,                   Accuracy: 1417/2000.0 (70.85%)



-= Testing valid =-
Test set: Average loss: 0.6391,                   Accuracy: 1581/2000.0 (79.05%)



-= Testing valid =-
Test set: Average loss: 0.3773,                   Accuracy: 1768/2000.0 (88.40%)



-= Testing valid =-
Test set: Average loss: 0.1692,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.2217,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.1581,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1244,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1737,                   Accuracy: 1896/2000.0 (94.80%)



Epoch 10 train accuracy: 96.55%, valid accuracy 94.80%
-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1296,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1082,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0711,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0790,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 20 train accuracy: 98.36%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0658,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0593,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 30 train accuracy: 98.72%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0453,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 40 train accuracy: 98.97%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0472,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0453,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 50 train accuracy: 99.10%, valid accuracy 98.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0706,                   Accuracy: 58758/60000 (97.93%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1259,                   Accuracy: 57724/60000 (96.21%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2759,                   Accuracy: 54827/60000 (91.38%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5997,                   Accuracy: 49215/60000 (82.03%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9445,                   Accuracy: 43144/60000 (71.91%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9830,                   Accuracy: 42216/60000 (70.36%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6179,                   Accuracy: 48533/60000 (80.89%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2626,                   Accuracy: 55063/60000 (91.77%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1044,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0706,                   Accuracy: 58758/60000 (97.93%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1259,                   Accuracy: 57724/60000 (96.21%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2759,                   Accuracy: 54827/60000 (91.38%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5997,                   Accuracy: 49215/60000 (82.03%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9445,                   Accuracy: 43144/60000 (71.91%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9830,                   Accuracy: 42216/60000 (70.36%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6179,                   Accuracy: 48533/60000 (80.89%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2626,                   Accuracy: 55063/60000 (91.77%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1044,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0706,                   Accuracy: 58758/60000 (97.93%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1259,                   Accuracy: 57724/60000 (96.21%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2759,                   Accuracy: 54827/60000 (91.38%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5997,                   Accuracy: 49215/60000 (82.03%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9445,                   Accuracy: 43144/60000 (71.91%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9830,                   Accuracy: 42216/60000 (70.36%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6179,                   Accuracy: 48533/60000 (80.89%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2626,                   Accuracy: 55063/60000 (91.77%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1044,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0706,                   Accuracy: 58758/60000 (97.93%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1259,                   Accuracy: 57724/60000 (96.21%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2759,                   Accuracy: 54827/60000 (91.38%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5997,                   Accuracy: 49215/60000 (82.03%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9445,                   Accuracy: 43144/60000 (71.91%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9830,                   Accuracy: 42216/60000 (70.36%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6179,                   Accuracy: 48533/60000 (80.89%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2626,                   Accuracy: 55063/60000 (91.77%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1044,                   Accuracy: 58059/60000 (96.76%)
{0: tensor(97.9300), 10: tensor(96.2067), 20: tensor(91.3783), 30: tensor(82.0250), 40: tensor(71.9067), 50: tensor(70.3600), 60: tensor(80.8883), 70: tensor(91.7717), 80: tensor(96.7650), 90: tensor(97.9300), 100: tensor(96.2067), 110: tensor(91.3783), 120: tensor(82.0250), 130: tensor(71.9067), 140: tensor(70.3600), 150: tensor(80.8883), 160: tensor(91.7717), 170: tensor(96.7650), 180: tensor(97.9300), 190: tensor(96.2067), 200: tensor(91.3783), 210: tensor(82.0250), 220: tensor(71.9067), 230: tensor(70.3600), 240: tensor(80.8883), 250: tensor(91.7717), 260: tensor(96.7650), 270: tensor(97.9300), 280: tensor(96.2067), 290: tensor(91.3783), 300: tensor(82.0250), 310: tensor(71.9067), 320: tensor(70.3600), 330: tensor(80.8883), 340: tensor(91.7717), 350: tensor(96.7650)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=51, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8117,                   Accuracy: 650/2000.0 (32.50%)



-= Testing valid =-
Test set: Average loss: 1.1353,                   Accuracy: 1160/2000.0 (58.00%)



-= Testing valid =-
Test set: Average loss: 1.4482,                   Accuracy: 1156/2000.0 (57.80%)



-= Testing valid =-
Test set: Average loss: 0.7968,                   Accuracy: 1442/2000.0 (72.10%)



-= Testing valid =-
Test set: Average loss: 0.3243,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.3728,                   Accuracy: 1756/2000.0 (87.80%)



-= Testing valid =-
Test set: Average loss: 0.1975,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1653,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1437,                   Accuracy: 1904/2000.0 (95.20%)



Epoch 10 train accuracy: 96.46%, valid accuracy 95.20%
-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1021,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0644,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0656,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 20 train accuracy: 98.04%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0578,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 30 train accuracy: 98.61%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0485,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 40 train accuracy: 98.91%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0445,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 50 train accuracy: 99.04%, valid accuracy 98.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0797,                   Accuracy: 58604/60000 (97.67%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1365,                   Accuracy: 57627/60000 (96.04%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2853,                   Accuracy: 55094/60000 (91.82%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6236,                   Accuracy: 49603/60000 (82.67%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9397,                   Accuracy: 44829/60000 (74.71%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9272,                   Accuracy: 44897/60000 (74.83%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5967,                   Accuracy: 49738/60000 (82.90%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2828,                   Accuracy: 54890/60000 (91.48%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1149,                   Accuracy: 57959/60000 (96.60%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0797,                   Accuracy: 58604/60000 (97.67%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1365,                   Accuracy: 57627/60000 (96.04%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2853,                   Accuracy: 55094/60000 (91.82%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6236,                   Accuracy: 49603/60000 (82.67%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9397,                   Accuracy: 44829/60000 (74.71%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9272,                   Accuracy: 44897/60000 (74.83%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5967,                   Accuracy: 49738/60000 (82.90%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2828,                   Accuracy: 54890/60000 (91.48%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1149,                   Accuracy: 57959/60000 (96.60%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0797,                   Accuracy: 58604/60000 (97.67%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1365,                   Accuracy: 57627/60000 (96.04%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2853,                   Accuracy: 55094/60000 (91.82%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6236,                   Accuracy: 49603/60000 (82.67%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9397,                   Accuracy: 44829/60000 (74.71%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9272,                   Accuracy: 44897/60000 (74.83%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5967,                   Accuracy: 49738/60000 (82.90%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2828,                   Accuracy: 54890/60000 (91.48%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1149,                   Accuracy: 57959/60000 (96.60%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0797,                   Accuracy: 58604/60000 (97.67%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1365,                   Accuracy: 57627/60000 (96.04%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2853,                   Accuracy: 55094/60000 (91.82%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6236,                   Accuracy: 49603/60000 (82.67%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9397,                   Accuracy: 44829/60000 (74.71%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9272,                   Accuracy: 44897/60000 (74.83%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5967,                   Accuracy: 49738/60000 (82.90%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2828,                   Accuracy: 54890/60000 (91.48%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1149,                   Accuracy: 57959/60000 (96.60%)
{0: tensor(97.6733), 10: tensor(96.0450), 20: tensor(91.8233), 30: tensor(82.6717), 40: tensor(74.7150), 50: tensor(74.8283), 60: tensor(82.8967), 70: tensor(91.4833), 80: tensor(96.5983), 90: tensor(97.6733), 100: tensor(96.0450), 110: tensor(91.8233), 120: tensor(82.6717), 130: tensor(74.7150), 140: tensor(74.8283), 150: tensor(82.8967), 160: tensor(91.4833), 170: tensor(96.5983), 180: tensor(97.6733), 190: tensor(96.0450), 200: tensor(91.8233), 210: tensor(82.6717), 220: tensor(74.7150), 230: tensor(74.8283), 240: tensor(82.8967), 250: tensor(91.4833), 260: tensor(96.5983), 270: tensor(97.6733), 280: tensor(96.0450), 290: tensor(91.8233), 300: tensor(82.6717), 310: tensor(74.7150), 320: tensor(74.8283), 330: tensor(82.8967), 340: tensor(91.4833), 350: tensor(96.5983)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=52, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8544,                   Accuracy: 581/2000.0 (29.05%)



-= Testing valid =-
Test set: Average loss: 1.5229,                   Accuracy: 853/2000.0 (42.65%)



-= Testing valid =-
Test set: Average loss: 0.5947,                   Accuracy: 1700/2000.0 (85.00%)



-= Testing valid =-
Test set: Average loss: 0.4632,                   Accuracy: 1696/2000.0 (84.80%)



-= Testing valid =-
Test set: Average loss: 0.2092,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.2340,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2113,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.3403,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.1811,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.2280,                   Accuracy: 1858/2000.0 (92.90%)



Epoch 10 train accuracy: 95.39%, valid accuracy 92.90%
-= Testing valid =-
Test set: Average loss: 0.1160,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1264,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1483,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1036,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1206,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1011,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1030,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1150,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 20 train accuracy: 97.81%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1286,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 30 train accuracy: 98.53%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0802,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 40 train accuracy: 98.70%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 50 train accuracy: 98.89%, valid accuracy 97.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0844,                   Accuracy: 58519/60000 (97.53%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1547,                   Accuracy: 57194/60000 (95.32%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2987,                   Accuracy: 54564/60000 (90.94%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6194,                   Accuracy: 48715/60000 (81.19%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0290,                   Accuracy: 41868/60000 (69.78%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0968,                   Accuracy: 40597/60000 (67.66%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7362,                   Accuracy: 46526/60000 (77.54%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3262,                   Accuracy: 53918/60000 (89.86%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1353,                   Accuracy: 57498/60000 (95.83%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0844,                   Accuracy: 58519/60000 (97.53%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1547,                   Accuracy: 57194/60000 (95.32%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2987,                   Accuracy: 54564/60000 (90.94%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6194,                   Accuracy: 48715/60000 (81.19%)
-= Testing Rotation 130 =-
Test set: Average loss: 1.0290,                   Accuracy: 41868/60000 (69.78%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0968,                   Accuracy: 40597/60000 (67.66%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7362,                   Accuracy: 46526/60000 (77.54%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3262,                   Accuracy: 53918/60000 (89.86%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1353,                   Accuracy: 57498/60000 (95.83%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0844,                   Accuracy: 58519/60000 (97.53%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1547,                   Accuracy: 57194/60000 (95.32%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2987,                   Accuracy: 54564/60000 (90.94%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6194,                   Accuracy: 48715/60000 (81.19%)
-= Testing Rotation 220 =-
Test set: Average loss: 1.0290,                   Accuracy: 41868/60000 (69.78%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0968,                   Accuracy: 40597/60000 (67.66%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7362,                   Accuracy: 46526/60000 (77.54%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3262,                   Accuracy: 53918/60000 (89.86%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1353,                   Accuracy: 57498/60000 (95.83%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0844,                   Accuracy: 58519/60000 (97.53%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1547,                   Accuracy: 57194/60000 (95.32%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2987,                   Accuracy: 54564/60000 (90.94%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6194,                   Accuracy: 48715/60000 (81.19%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0290,                   Accuracy: 41868/60000 (69.78%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0968,                   Accuracy: 40597/60000 (67.66%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7362,                   Accuracy: 46526/60000 (77.54%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3262,                   Accuracy: 53918/60000 (89.86%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1353,                   Accuracy: 57498/60000 (95.83%)
{0: tensor(97.5317), 10: tensor(95.3233), 20: tensor(90.9400), 30: tensor(81.1917), 40: tensor(69.7800), 50: tensor(67.6617), 60: tensor(77.5433), 70: tensor(89.8633), 80: tensor(95.8300), 90: tensor(97.5317), 100: tensor(95.3233), 110: tensor(90.9400), 120: tensor(81.1917), 130: tensor(69.7800), 140: tensor(67.6617), 150: tensor(77.5433), 160: tensor(89.8633), 170: tensor(95.8300), 180: tensor(97.5317), 190: tensor(95.3233), 200: tensor(90.9400), 210: tensor(81.1917), 220: tensor(69.7800), 230: tensor(67.6617), 240: tensor(77.5433), 250: tensor(89.8633), 260: tensor(95.8300), 270: tensor(97.5317), 280: tensor(95.3233), 290: tensor(90.9400), 300: tensor(81.1917), 310: tensor(69.7800), 320: tensor(67.6617), 330: tensor(77.5433), 340: tensor(89.8633), 350: tensor(95.8300)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=53, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0029,                   Accuracy: 431/2000.0 (21.55%)



-= Testing valid =-
Test set: Average loss: 1.5771,                   Accuracy: 740/2000.0 (37.00%)



-= Testing valid =-
Test set: Average loss: 1.0994,                   Accuracy: 1081/2000.0 (54.05%)



-= Testing valid =-
Test set: Average loss: 0.7457,                   Accuracy: 1543/2000.0 (77.15%)



-= Testing valid =-
Test set: Average loss: 0.4228,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.2649,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.3822,                   Accuracy: 1724/2000.0 (86.20%)



-= Testing valid =-
Test set: Average loss: 0.1831,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.2027,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1362,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 10 train accuracy: 95.90%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1136,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0976,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1126,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 20 train accuracy: 97.97%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0734,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0708,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0687,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 30 train accuracy: 98.41%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0568,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 40 train accuracy: 98.76%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0547,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 50 train accuracy: 99.04%, valid accuracy 98.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0752,                   Accuracy: 58629/60000 (97.71%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1188,                   Accuracy: 57777/60000 (96.29%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2013,                   Accuracy: 56277/60000 (93.79%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4046,                   Accuracy: 52739/60000 (87.90%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.6108,                   Accuracy: 48830/60000 (81.38%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.6856,                   Accuracy: 47004/60000 (78.34%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.4870,                   Accuracy: 50509/60000 (84.18%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2419,                   Accuracy: 55434/60000 (92.39%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1125,                   Accuracy: 57966/60000 (96.61%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0752,                   Accuracy: 58629/60000 (97.71%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1188,                   Accuracy: 57777/60000 (96.29%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2013,                   Accuracy: 56277/60000 (93.79%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4046,                   Accuracy: 52739/60000 (87.90%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.6108,                   Accuracy: 48830/60000 (81.38%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.6856,                   Accuracy: 47004/60000 (78.34%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4870,                   Accuracy: 50509/60000 (84.18%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2419,                   Accuracy: 55434/60000 (92.39%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1125,                   Accuracy: 57966/60000 (96.61%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0752,                   Accuracy: 58629/60000 (97.71%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1188,                   Accuracy: 57777/60000 (96.29%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2013,                   Accuracy: 56277/60000 (93.79%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4046,                   Accuracy: 52739/60000 (87.90%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.6108,                   Accuracy: 48830/60000 (81.38%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.6856,                   Accuracy: 47004/60000 (78.34%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4870,                   Accuracy: 50509/60000 (84.18%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2419,                   Accuracy: 55434/60000 (92.39%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1125,                   Accuracy: 57966/60000 (96.61%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0752,                   Accuracy: 58629/60000 (97.71%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1188,                   Accuracy: 57777/60000 (96.29%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2013,                   Accuracy: 56277/60000 (93.79%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.4046,                   Accuracy: 52739/60000 (87.90%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.6108,                   Accuracy: 48830/60000 (81.38%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.6856,                   Accuracy: 47004/60000 (78.34%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4870,                   Accuracy: 50509/60000 (84.18%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2419,                   Accuracy: 55434/60000 (92.39%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1125,                   Accuracy: 57966/60000 (96.61%)
{0: tensor(97.7150), 10: tensor(96.2950), 20: tensor(93.7950), 30: tensor(87.8983), 40: tensor(81.3833), 50: tensor(78.3400), 60: tensor(84.1817), 70: tensor(92.3900), 80: tensor(96.6100), 90: tensor(97.7150), 100: tensor(96.2950), 110: tensor(93.7950), 120: tensor(87.8983), 130: tensor(81.3833), 140: tensor(78.3400), 150: tensor(84.1817), 160: tensor(92.3900), 170: tensor(96.6100), 180: tensor(97.7150), 190: tensor(96.2950), 200: tensor(93.7950), 210: tensor(87.8983), 220: tensor(81.3833), 230: tensor(78.3400), 240: tensor(84.1817), 250: tensor(92.3900), 260: tensor(96.6100), 270: tensor(97.7150), 280: tensor(96.2950), 290: tensor(93.7950), 300: tensor(87.8983), 310: tensor(81.3833), 320: tensor(78.3400), 330: tensor(84.1817), 340: tensor(92.3900), 350: tensor(96.6100)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=54, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7792,                   Accuracy: 646/2000.0 (32.30%)



-= Testing valid =-
Test set: Average loss: 2.5118,                   Accuracy: 340/2000.0 (17.00%)



-= Testing valid =-
Test set: Average loss: 0.6331,                   Accuracy: 1634/2000.0 (81.70%)



-= Testing valid =-
Test set: Average loss: 0.5886,                   Accuracy: 1608/2000.0 (80.40%)



-= Testing valid =-
Test set: Average loss: 1.4866,                   Accuracy: 1178/2000.0 (58.90%)



-= Testing valid =-
Test set: Average loss: 0.2966,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2981,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2078,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1591,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1440,                   Accuracy: 1916/2000.0 (95.80%)



Epoch 10 train accuracy: 96.11%, valid accuracy 95.80%
-= Testing valid =-
Test set: Average loss: 0.1198,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1167,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1085,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1305,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1139,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0935,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 20 train accuracy: 97.76%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0710,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0644,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0633,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0734,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 30 train accuracy: 98.54%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0655,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0646,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0647,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0645,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 40 train accuracy: 98.90%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0626,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0637,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0605,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0638,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0641,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 50 train accuracy: 98.89%, valid accuracy 98.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0849,                   Accuracy: 58543/60000 (97.57%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1369,                   Accuracy: 57574/60000 (95.96%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3099,                   Accuracy: 54554/60000 (90.92%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7337,                   Accuracy: 47899/60000 (79.83%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.1221,                   Accuracy: 41622/60000 (69.37%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1243,                   Accuracy: 41245/60000 (68.74%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7164,                   Accuracy: 47443/60000 (79.07%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3221,                   Accuracy: 54352/60000 (90.59%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1287,                   Accuracy: 57727/60000 (96.21%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0849,                   Accuracy: 58543/60000 (97.57%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1369,                   Accuracy: 57574/60000 (95.96%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3099,                   Accuracy: 54554/60000 (90.92%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.7337,                   Accuracy: 47899/60000 (79.83%)
-= Testing Rotation 130 =-
Test set: Average loss: 1.1221,                   Accuracy: 41622/60000 (69.37%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.1243,                   Accuracy: 41245/60000 (68.74%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7164,                   Accuracy: 47443/60000 (79.07%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3221,                   Accuracy: 54352/60000 (90.59%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1287,                   Accuracy: 57727/60000 (96.21%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0849,                   Accuracy: 58543/60000 (97.57%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1369,                   Accuracy: 57574/60000 (95.96%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3099,                   Accuracy: 54554/60000 (90.92%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.7337,                   Accuracy: 47899/60000 (79.83%)
-= Testing Rotation 220 =-
Test set: Average loss: 1.1221,                   Accuracy: 41622/60000 (69.37%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.1243,                   Accuracy: 41245/60000 (68.74%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7164,                   Accuracy: 47443/60000 (79.07%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3221,                   Accuracy: 54352/60000 (90.59%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1287,                   Accuracy: 57727/60000 (96.21%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0849,                   Accuracy: 58543/60000 (97.57%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1369,                   Accuracy: 57574/60000 (95.96%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3099,                   Accuracy: 54554/60000 (90.92%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.7337,                   Accuracy: 47899/60000 (79.83%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1221,                   Accuracy: 41622/60000 (69.37%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1243,                   Accuracy: 41245/60000 (68.74%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7164,                   Accuracy: 47443/60000 (79.07%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3221,                   Accuracy: 54352/60000 (90.59%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1287,                   Accuracy: 57727/60000 (96.21%)
{0: tensor(97.5717), 10: tensor(95.9567), 20: tensor(90.9233), 30: tensor(79.8317), 40: tensor(69.3700), 50: tensor(68.7417), 60: tensor(79.0717), 70: tensor(90.5867), 80: tensor(96.2117), 90: tensor(97.5717), 100: tensor(95.9567), 110: tensor(90.9233), 120: tensor(79.8317), 130: tensor(69.3700), 140: tensor(68.7417), 150: tensor(79.0717), 160: tensor(90.5867), 170: tensor(96.2117), 180: tensor(97.5717), 190: tensor(95.9567), 200: tensor(90.9233), 210: tensor(79.8317), 220: tensor(69.3700), 230: tensor(68.7417), 240: tensor(79.0717), 250: tensor(90.5867), 260: tensor(96.2117), 270: tensor(97.5717), 280: tensor(95.9567), 290: tensor(90.9233), 300: tensor(79.8317), 310: tensor(69.3700), 320: tensor(68.7417), 330: tensor(79.0717), 340: tensor(90.5867), 350: tensor(96.2117)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=55, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.5836,                   Accuracy: 294/2000.0 (14.70%)



-= Testing valid =-
Test set: Average loss: 2.6561,                   Accuracy: 490/2000.0 (24.50%)



-= Testing valid =-
Test set: Average loss: 0.3427,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.5013,                   Accuracy: 1696/2000.0 (84.80%)



-= Testing valid =-
Test set: Average loss: 0.1813,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1773,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.2041,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1943,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.1401,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.3061,                   Accuracy: 1811/2000.0 (90.55%)



Epoch 10 train accuracy: 96.09%, valid accuracy 90.55%
-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1118,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 20 train accuracy: 97.47%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 30 train accuracy: 98.62%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0529,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0552,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0597,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0575,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0572,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0595,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 40 train accuracy: 98.71%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0601,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0580,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0555,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0568,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0547,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 50 train accuracy: 99.14%, valid accuracy 98.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0842,                   Accuracy: 58501/60000 (97.50%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1485,                   Accuracy: 57431/60000 (95.72%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2749,                   Accuracy: 55356/60000 (92.26%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6356,                   Accuracy: 49376/60000 (82.29%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0799,                   Accuracy: 42155/60000 (70.26%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1549,                   Accuracy: 40631/60000 (67.72%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7579,                   Accuracy: 46597/60000 (77.66%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3449,                   Accuracy: 53810/60000 (89.68%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1423,                   Accuracy: 57451/60000 (95.75%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0842,                   Accuracy: 58501/60000 (97.50%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1485,                   Accuracy: 57431/60000 (95.72%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2749,                   Accuracy: 55356/60000 (92.26%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6356,                   Accuracy: 49376/60000 (82.29%)
-= Testing Rotation 130 =-
Test set: Average loss: 1.0799,                   Accuracy: 42155/60000 (70.26%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.1549,                   Accuracy: 40631/60000 (67.72%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7579,                   Accuracy: 46597/60000 (77.66%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3449,                   Accuracy: 53810/60000 (89.68%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1423,                   Accuracy: 57451/60000 (95.75%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0842,                   Accuracy: 58501/60000 (97.50%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1485,                   Accuracy: 57431/60000 (95.72%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2749,                   Accuracy: 55356/60000 (92.26%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6356,                   Accuracy: 49376/60000 (82.29%)
-= Testing Rotation 220 =-
Test set: Average loss: 1.0799,                   Accuracy: 42155/60000 (70.26%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.1549,                   Accuracy: 40631/60000 (67.72%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7579,                   Accuracy: 46597/60000 (77.66%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3449,                   Accuracy: 53810/60000 (89.68%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1423,                   Accuracy: 57451/60000 (95.75%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0842,                   Accuracy: 58501/60000 (97.50%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1485,                   Accuracy: 57431/60000 (95.72%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2749,                   Accuracy: 55356/60000 (92.26%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6356,                   Accuracy: 49376/60000 (82.29%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0799,                   Accuracy: 42155/60000 (70.26%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1549,                   Accuracy: 40631/60000 (67.72%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7579,                   Accuracy: 46597/60000 (77.66%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3449,                   Accuracy: 53810/60000 (89.68%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1423,                   Accuracy: 57451/60000 (95.75%)
{0: tensor(97.5017), 10: tensor(95.7183), 20: tensor(92.2600), 30: tensor(82.2933), 40: tensor(70.2583), 50: tensor(67.7183), 60: tensor(77.6617), 70: tensor(89.6833), 80: tensor(95.7517), 90: tensor(97.5017), 100: tensor(95.7183), 110: tensor(92.2600), 120: tensor(82.2933), 130: tensor(70.2583), 140: tensor(67.7183), 150: tensor(77.6617), 160: tensor(89.6833), 170: tensor(95.7517), 180: tensor(97.5017), 190: tensor(95.7183), 200: tensor(92.2600), 210: tensor(82.2933), 220: tensor(70.2583), 230: tensor(67.7183), 240: tensor(77.6617), 250: tensor(89.6833), 260: tensor(95.7517), 270: tensor(97.5017), 280: tensor(95.7183), 290: tensor(92.2600), 300: tensor(82.2933), 310: tensor(70.2583), 320: tensor(67.7183), 330: tensor(77.6617), 340: tensor(89.6833), 350: tensor(95.7517)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=56, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1610,                   Accuracy: 468/2000.0 (23.40%)



-= Testing valid =-
Test set: Average loss: 1.0998,                   Accuracy: 1221/2000.0 (61.05%)



-= Testing valid =-
Test set: Average loss: 0.6667,                   Accuracy: 1478/2000.0 (73.90%)



-= Testing valid =-
Test set: Average loss: 0.2312,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.3821,                   Accuracy: 1780/2000.0 (89.00%)



-= Testing valid =-
Test set: Average loss: 0.2196,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.1567,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1151,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1929,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 10 train accuracy: 96.45%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1100,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0567,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0947,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 20 train accuracy: 98.20%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0619,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0618,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 30 train accuracy: 98.55%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 40 train accuracy: 99.06%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 50 train accuracy: 99.24%, valid accuracy 98.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0712,                   Accuracy: 58733/60000 (97.89%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1143,                   Accuracy: 57916/60000 (96.53%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2238,                   Accuracy: 55863/60000 (93.11%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5316,                   Accuracy: 50380/60000 (83.97%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8781,                   Accuracy: 44527/60000 (74.21%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9920,                   Accuracy: 42359/60000 (70.60%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6848,                   Accuracy: 47596/60000 (79.33%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3153,                   Accuracy: 54143/60000 (90.24%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1114,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0712,                   Accuracy: 58733/60000 (97.89%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1143,                   Accuracy: 57916/60000 (96.53%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2238,                   Accuracy: 55863/60000 (93.11%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5316,                   Accuracy: 50380/60000 (83.97%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8781,                   Accuracy: 44527/60000 (74.21%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9920,                   Accuracy: 42359/60000 (70.60%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6848,                   Accuracy: 47596/60000 (79.33%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3153,                   Accuracy: 54143/60000 (90.24%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1114,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0712,                   Accuracy: 58733/60000 (97.89%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1143,                   Accuracy: 57916/60000 (96.53%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2238,                   Accuracy: 55863/60000 (93.11%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5316,                   Accuracy: 50380/60000 (83.97%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8781,                   Accuracy: 44527/60000 (74.21%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9920,                   Accuracy: 42359/60000 (70.60%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6848,                   Accuracy: 47596/60000 (79.33%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3153,                   Accuracy: 54143/60000 (90.24%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1114,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0712,                   Accuracy: 58733/60000 (97.89%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1143,                   Accuracy: 57916/60000 (96.53%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2238,                   Accuracy: 55863/60000 (93.11%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5316,                   Accuracy: 50380/60000 (83.97%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8781,                   Accuracy: 44527/60000 (74.21%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9920,                   Accuracy: 42359/60000 (70.60%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6848,                   Accuracy: 47596/60000 (79.33%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3153,                   Accuracy: 54143/60000 (90.24%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1114,                   Accuracy: 57961/60000 (96.60%)
{0: tensor(97.8883), 10: tensor(96.5267), 20: tensor(93.1050), 30: tensor(83.9667), 40: tensor(74.2117), 50: tensor(70.5983), 60: tensor(79.3267), 70: tensor(90.2383), 80: tensor(96.6017), 90: tensor(97.8883), 100: tensor(96.5267), 110: tensor(93.1050), 120: tensor(83.9667), 130: tensor(74.2117), 140: tensor(70.5983), 150: tensor(79.3267), 160: tensor(90.2383), 170: tensor(96.6017), 180: tensor(97.8883), 190: tensor(96.5267), 200: tensor(93.1050), 210: tensor(83.9667), 220: tensor(74.2117), 230: tensor(70.5983), 240: tensor(79.3267), 250: tensor(90.2383), 260: tensor(96.6017), 270: tensor(97.8883), 280: tensor(96.5267), 290: tensor(93.1050), 300: tensor(83.9667), 310: tensor(74.2117), 320: tensor(70.5983), 330: tensor(79.3267), 340: tensor(90.2383), 350: tensor(96.6017)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=57, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4306,                   Accuracy: 499/2000.0 (24.95%)



-= Testing valid =-
Test set: Average loss: 1.0686,                   Accuracy: 1100/2000.0 (55.00%)



-= Testing valid =-
Test set: Average loss: 0.4751,                   Accuracy: 1687/2000.0 (84.35%)



-= Testing valid =-
Test set: Average loss: 0.2736,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.1862,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1915,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.2844,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.1307,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1846,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1264,                   Accuracy: 1922/2000.0 (96.10%)



Epoch 10 train accuracy: 96.35%, valid accuracy 96.10%
-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0947,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 20 train accuracy: 98.00%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0519,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0492,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 30 train accuracy: 98.61%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 40 train accuracy: 98.86%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 50 train accuracy: 98.90%, valid accuracy 98.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0740,                   Accuracy: 58722/60000 (97.87%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1193,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2454,                   Accuracy: 55581/60000 (92.64%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5594,                   Accuracy: 50219/60000 (83.70%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9315,                   Accuracy: 43934/60000 (73.22%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9855,                   Accuracy: 42870/60000 (71.45%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6483,                   Accuracy: 48606/60000 (81.01%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2847,                   Accuracy: 54828/60000 (91.38%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1128,                   Accuracy: 57997/60000 (96.66%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0740,                   Accuracy: 58722/60000 (97.87%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1193,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2454,                   Accuracy: 55581/60000 (92.64%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5594,                   Accuracy: 50219/60000 (83.70%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9315,                   Accuracy: 43934/60000 (73.22%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9855,                   Accuracy: 42870/60000 (71.45%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6483,                   Accuracy: 48606/60000 (81.01%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2847,                   Accuracy: 54828/60000 (91.38%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1128,                   Accuracy: 57997/60000 (96.66%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0740,                   Accuracy: 58722/60000 (97.87%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1193,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2454,                   Accuracy: 55581/60000 (92.64%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5594,                   Accuracy: 50219/60000 (83.70%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9315,                   Accuracy: 43934/60000 (73.22%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9855,                   Accuracy: 42870/60000 (71.45%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6483,                   Accuracy: 48606/60000 (81.01%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2847,                   Accuracy: 54828/60000 (91.38%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1128,                   Accuracy: 57997/60000 (96.66%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0740,                   Accuracy: 58722/60000 (97.87%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1193,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2454,                   Accuracy: 55581/60000 (92.64%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5594,                   Accuracy: 50219/60000 (83.70%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9315,                   Accuracy: 43934/60000 (73.22%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9855,                   Accuracy: 42870/60000 (71.45%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6483,                   Accuracy: 48606/60000 (81.01%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2847,                   Accuracy: 54828/60000 (91.38%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1128,                   Accuracy: 57997/60000 (96.66%)
{0: tensor(97.8700), 10: tensor(96.4483), 20: tensor(92.6350), 30: tensor(83.6983), 40: tensor(73.2233), 50: tensor(71.4500), 60: tensor(81.0100), 70: tensor(91.3800), 80: tensor(96.6617), 90: tensor(97.8700), 100: tensor(96.4483), 110: tensor(92.6350), 120: tensor(83.6983), 130: tensor(73.2233), 140: tensor(71.4500), 150: tensor(81.0100), 160: tensor(91.3800), 170: tensor(96.6617), 180: tensor(97.8700), 190: tensor(96.4483), 200: tensor(92.6350), 210: tensor(83.6983), 220: tensor(73.2233), 230: tensor(71.4500), 240: tensor(81.0100), 250: tensor(91.3800), 260: tensor(96.6617), 270: tensor(97.8700), 280: tensor(96.4483), 290: tensor(92.6350), 300: tensor(83.6983), 310: tensor(73.2233), 320: tensor(71.4500), 330: tensor(81.0100), 340: tensor(91.3800), 350: tensor(96.6617)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=58, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8006,                   Accuracy: 618/2000.0 (30.90%)



-= Testing valid =-
Test set: Average loss: 1.9138,                   Accuracy: 790/2000.0 (39.50%)



-= Testing valid =-
Test set: Average loss: 0.5559,                   Accuracy: 1683/2000.0 (84.15%)



-= Testing valid =-
Test set: Average loss: 0.2686,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2296,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.3077,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.1856,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1419,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1723,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1142,                   Accuracy: 1928/2000.0 (96.40%)



Epoch 10 train accuracy: 96.80%, valid accuracy 96.40%
-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1147,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 20 train accuracy: 97.84%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0657,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0594,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0559,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0718,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 30 train accuracy: 98.61%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0600,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0535,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 40 train accuracy: 98.90%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0519,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 50 train accuracy: 99.16%, valid accuracy 98.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0691,                   Accuracy: 58793/60000 (97.99%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1172,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2210,                   Accuracy: 56079/60000 (93.46%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4719,                   Accuracy: 51568/60000 (85.95%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8064,                   Accuracy: 45596/60000 (75.99%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9188,                   Accuracy: 43581/60000 (72.64%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6512,                   Accuracy: 48266/60000 (80.44%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3539,                   Accuracy: 53706/60000 (89.51%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1308,                   Accuracy: 57677/60000 (96.13%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0691,                   Accuracy: 58793/60000 (97.99%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1172,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2210,                   Accuracy: 56079/60000 (93.46%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4719,                   Accuracy: 51568/60000 (85.95%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8064,                   Accuracy: 45596/60000 (75.99%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9188,                   Accuracy: 43581/60000 (72.64%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6512,                   Accuracy: 48266/60000 (80.44%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3539,                   Accuracy: 53706/60000 (89.51%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1308,                   Accuracy: 57677/60000 (96.13%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0691,                   Accuracy: 58793/60000 (97.99%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1172,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2210,                   Accuracy: 56079/60000 (93.46%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4719,                   Accuracy: 51568/60000 (85.95%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8064,                   Accuracy: 45596/60000 (75.99%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9188,                   Accuracy: 43581/60000 (72.64%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6512,                   Accuracy: 48266/60000 (80.44%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3539,                   Accuracy: 53706/60000 (89.51%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1308,                   Accuracy: 57677/60000 (96.13%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0691,                   Accuracy: 58793/60000 (97.99%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1172,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2210,                   Accuracy: 56079/60000 (93.46%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.4719,                   Accuracy: 51568/60000 (85.95%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8064,                   Accuracy: 45596/60000 (75.99%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9188,                   Accuracy: 43581/60000 (72.64%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6512,                   Accuracy: 48266/60000 (80.44%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3539,                   Accuracy: 53706/60000 (89.51%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1308,                   Accuracy: 57677/60000 (96.13%)
{0: tensor(97.9883), 10: tensor(96.5217), 20: tensor(93.4650), 30: tensor(85.9467), 40: tensor(75.9933), 50: tensor(72.6350), 60: tensor(80.4433), 70: tensor(89.5100), 80: tensor(96.1283), 90: tensor(97.9883), 100: tensor(96.5217), 110: tensor(93.4650), 120: tensor(85.9467), 130: tensor(75.9933), 140: tensor(72.6350), 150: tensor(80.4433), 160: tensor(89.5100), 170: tensor(96.1283), 180: tensor(97.9883), 190: tensor(96.5217), 200: tensor(93.4650), 210: tensor(85.9467), 220: tensor(75.9933), 230: tensor(72.6350), 240: tensor(80.4433), 250: tensor(89.5100), 260: tensor(96.1283), 270: tensor(97.9883), 280: tensor(96.5217), 290: tensor(93.4650), 300: tensor(85.9467), 310: tensor(75.9933), 320: tensor(72.6350), 330: tensor(80.4433), 340: tensor(89.5100), 350: tensor(96.1283)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=59, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.2833,                   Accuracy: 261/2000.0 (13.05%)



-= Testing valid =-
Test set: Average loss: 1.4740,                   Accuracy: 754/2000.0 (37.70%)



-= Testing valid =-
Test set: Average loss: 2.5384,                   Accuracy: 669/2000.0 (33.45%)



-= Testing valid =-
Test set: Average loss: 1.5657,                   Accuracy: 1119/2000.0 (55.95%)



-= Testing valid =-
Test set: Average loss: 0.5758,                   Accuracy: 1640/2000.0 (82.00%)



-= Testing valid =-
Test set: Average loss: 0.6847,                   Accuracy: 1558/2000.0 (77.90%)



-= Testing valid =-
Test set: Average loss: 0.5864,                   Accuracy: 1636/2000.0 (81.80%)



-= Testing valid =-
Test set: Average loss: 0.1766,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.2025,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.2107,                   Accuracy: 1867/2000.0 (93.35%)



Epoch 10 train accuracy: 95.60%, valid accuracy 93.35%
-= Testing valid =-
Test set: Average loss: 0.1556,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1179,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1261,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1668,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1927,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1036,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1177,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1266,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1626,                   Accuracy: 1919/2000.0 (95.95%)



Epoch 20 train accuracy: 97.64%, valid accuracy 95.95%
-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1075,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1165,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 30 train accuracy: 98.64%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1048,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 40 train accuracy: 98.88%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 50 train accuracy: 98.99%, valid accuracy 97.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0845,                   Accuracy: 58527/60000 (97.54%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1230,                   Accuracy: 57810/60000 (96.35%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2498,                   Accuracy: 55568/60000 (92.61%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5763,                   Accuracy: 50274/60000 (83.79%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9467,                   Accuracy: 44818/60000 (74.70%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0343,                   Accuracy: 43952/60000 (73.25%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6780,                   Accuracy: 48848/60000 (81.41%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3050,                   Accuracy: 54738/60000 (91.23%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1217,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0845,                   Accuracy: 58527/60000 (97.54%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1230,                   Accuracy: 57810/60000 (96.35%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2498,                   Accuracy: 55568/60000 (92.61%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5763,                   Accuracy: 50274/60000 (83.79%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9467,                   Accuracy: 44818/60000 (74.70%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0343,                   Accuracy: 43952/60000 (73.25%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6780,                   Accuracy: 48848/60000 (81.41%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3050,                   Accuracy: 54738/60000 (91.23%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1217,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0845,                   Accuracy: 58527/60000 (97.54%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1230,                   Accuracy: 57810/60000 (96.35%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2498,                   Accuracy: 55568/60000 (92.61%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5763,                   Accuracy: 50274/60000 (83.79%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9467,                   Accuracy: 44818/60000 (74.70%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0343,                   Accuracy: 43952/60000 (73.25%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6780,                   Accuracy: 48848/60000 (81.41%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3050,                   Accuracy: 54738/60000 (91.23%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1217,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0845,                   Accuracy: 58527/60000 (97.54%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1230,                   Accuracy: 57810/60000 (96.35%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2498,                   Accuracy: 55568/60000 (92.61%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5763,                   Accuracy: 50274/60000 (83.79%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9467,                   Accuracy: 44818/60000 (74.70%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0343,                   Accuracy: 43952/60000 (73.25%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6780,                   Accuracy: 48848/60000 (81.41%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3050,                   Accuracy: 54738/60000 (91.23%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1217,                   Accuracy: 57830/60000 (96.38%)
{0: tensor(97.5450), 10: tensor(96.3500), 20: tensor(92.6133), 30: tensor(83.7900), 40: tensor(74.6967), 50: tensor(73.2533), 60: tensor(81.4133), 70: tensor(91.2300), 80: tensor(96.3833), 90: tensor(97.5450), 100: tensor(96.3500), 110: tensor(92.6133), 120: tensor(83.7900), 130: tensor(74.6967), 140: tensor(73.2533), 150: tensor(81.4133), 160: tensor(91.2300), 170: tensor(96.3833), 180: tensor(97.5450), 190: tensor(96.3500), 200: tensor(92.6133), 210: tensor(83.7900), 220: tensor(74.6967), 230: tensor(73.2533), 240: tensor(81.4133), 250: tensor(91.2300), 260: tensor(96.3833), 270: tensor(97.5450), 280: tensor(96.3500), 290: tensor(92.6133), 300: tensor(83.7900), 310: tensor(74.6967), 320: tensor(73.2533), 330: tensor(81.4133), 340: tensor(91.2300), 350: tensor(96.3833)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=60, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4908,                   Accuracy: 398/2000.0 (19.90%)



-= Testing valid =-
Test set: Average loss: 1.4418,                   Accuracy: 860/2000.0 (43.00%)



-= Testing valid =-
Test set: Average loss: 0.8387,                   Accuracy: 1342/2000.0 (67.10%)



-= Testing valid =-
Test set: Average loss: 0.2557,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2304,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2843,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.1575,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1381,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1982,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1067,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 10 train accuracy: 96.47%, valid accuracy 96.45%
-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1242,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 20 train accuracy: 98.26%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0578,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0572,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0608,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0626,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 30 train accuracy: 98.71%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0519,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 40 train accuracy: 98.85%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0485,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 50 train accuracy: 99.21%, valid accuracy 98.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0767,                   Accuracy: 58640/60000 (97.73%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1551,                   Accuracy: 57237/60000 (95.39%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3307,                   Accuracy: 54326/60000 (90.54%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7061,                   Accuracy: 48783/60000 (81.31%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.1417,                   Accuracy: 42577/60000 (70.96%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1988,                   Accuracy: 41877/60000 (69.79%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7358,                   Accuracy: 47924/60000 (79.87%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2904,                   Accuracy: 54770/60000 (91.28%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1274,                   Accuracy: 57698/60000 (96.16%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0767,                   Accuracy: 58640/60000 (97.73%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1551,                   Accuracy: 57237/60000 (95.39%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3307,                   Accuracy: 54326/60000 (90.54%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.7061,                   Accuracy: 48783/60000 (81.31%)
-= Testing Rotation 130 =-
Test set: Average loss: 1.1417,                   Accuracy: 42577/60000 (70.96%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.1988,                   Accuracy: 41877/60000 (69.79%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7358,                   Accuracy: 47924/60000 (79.87%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2904,                   Accuracy: 54770/60000 (91.28%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1274,                   Accuracy: 57698/60000 (96.16%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0767,                   Accuracy: 58640/60000 (97.73%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1551,                   Accuracy: 57237/60000 (95.39%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3307,                   Accuracy: 54326/60000 (90.54%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.7061,                   Accuracy: 48783/60000 (81.31%)
-= Testing Rotation 220 =-
Test set: Average loss: 1.1417,                   Accuracy: 42577/60000 (70.96%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.1988,                   Accuracy: 41877/60000 (69.79%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7358,                   Accuracy: 47924/60000 (79.87%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2904,                   Accuracy: 54770/60000 (91.28%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1274,                   Accuracy: 57698/60000 (96.16%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0767,                   Accuracy: 58640/60000 (97.73%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1551,                   Accuracy: 57237/60000 (95.39%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3307,                   Accuracy: 54326/60000 (90.54%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.7061,                   Accuracy: 48783/60000 (81.31%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1417,                   Accuracy: 42577/60000 (70.96%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1988,                   Accuracy: 41877/60000 (69.79%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7358,                   Accuracy: 47924/60000 (79.87%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2904,                   Accuracy: 54770/60000 (91.28%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1274,                   Accuracy: 57698/60000 (96.16%)
{0: tensor(97.7333), 10: tensor(95.3950), 20: tensor(90.5433), 30: tensor(81.3050), 40: tensor(70.9617), 50: tensor(69.7950), 60: tensor(79.8733), 70: tensor(91.2833), 80: tensor(96.1633), 90: tensor(97.7333), 100: tensor(95.3950), 110: tensor(90.5433), 120: tensor(81.3050), 130: tensor(70.9617), 140: tensor(69.7950), 150: tensor(79.8733), 160: tensor(91.2833), 170: tensor(96.1633), 180: tensor(97.7333), 190: tensor(95.3950), 200: tensor(90.5433), 210: tensor(81.3050), 220: tensor(70.9617), 230: tensor(69.7950), 240: tensor(79.8733), 250: tensor(91.2833), 260: tensor(96.1633), 270: tensor(97.7333), 280: tensor(95.3950), 290: tensor(90.5433), 300: tensor(81.3050), 310: tensor(70.9617), 320: tensor(69.7950), 330: tensor(79.8733), 340: tensor(91.2833), 350: tensor(96.1633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=61, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8292,                   Accuracy: 534/2000.0 (26.70%)



-= Testing valid =-
Test set: Average loss: 1.2078,                   Accuracy: 1180/2000.0 (59.00%)



-= Testing valid =-
Test set: Average loss: 0.9140,                   Accuracy: 1402/2000.0 (70.10%)



-= Testing valid =-
Test set: Average loss: 0.6092,                   Accuracy: 1548/2000.0 (77.40%)



-= Testing valid =-
Test set: Average loss: 0.5868,                   Accuracy: 1590/2000.0 (79.50%)



-= Testing valid =-
Test set: Average loss: 0.3010,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.1661,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1394,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1247,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1373,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 10 train accuracy: 95.90%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 20 train accuracy: 97.97%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0674,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0601,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 30 train accuracy: 98.46%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0657,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0492,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0647,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0496,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 40 train accuracy: 98.76%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 50 train accuracy: 98.93%, valid accuracy 98.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0786,                   Accuracy: 58619/60000 (97.70%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1222,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2542,                   Accuracy: 55389/60000 (92.32%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5059,                   Accuracy: 50753/60000 (84.59%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8104,                   Accuracy: 45548/60000 (75.91%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8595,                   Accuracy: 44465/60000 (74.11%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5750,                   Accuracy: 49250/60000 (82.08%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2761,                   Accuracy: 54823/60000 (91.37%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1161,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0786,                   Accuracy: 58619/60000 (97.70%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1222,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2542,                   Accuracy: 55389/60000 (92.32%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5059,                   Accuracy: 50753/60000 (84.59%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8104,                   Accuracy: 45548/60000 (75.91%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8595,                   Accuracy: 44465/60000 (74.11%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5750,                   Accuracy: 49250/60000 (82.08%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2761,                   Accuracy: 54823/60000 (91.37%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1161,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0786,                   Accuracy: 58619/60000 (97.70%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1222,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2542,                   Accuracy: 55389/60000 (92.32%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5059,                   Accuracy: 50753/60000 (84.59%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8104,                   Accuracy: 45548/60000 (75.91%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8595,                   Accuracy: 44465/60000 (74.11%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5750,                   Accuracy: 49250/60000 (82.08%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2761,                   Accuracy: 54823/60000 (91.37%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1161,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0786,                   Accuracy: 58619/60000 (97.70%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1222,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2542,                   Accuracy: 55389/60000 (92.32%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5059,                   Accuracy: 50753/60000 (84.59%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8104,                   Accuracy: 45548/60000 (75.91%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8595,                   Accuracy: 44465/60000 (74.11%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5750,                   Accuracy: 49250/60000 (82.08%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2761,                   Accuracy: 54823/60000 (91.37%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1161,                   Accuracy: 57923/60000 (96.54%)
{0: tensor(97.6983), 10: tensor(96.3817), 20: tensor(92.3150), 30: tensor(84.5883), 40: tensor(75.9133), 50: tensor(74.1083), 60: tensor(82.0833), 70: tensor(91.3717), 80: tensor(96.5383), 90: tensor(97.6983), 100: tensor(96.3817), 110: tensor(92.3150), 120: tensor(84.5883), 130: tensor(75.9133), 140: tensor(74.1083), 150: tensor(82.0833), 160: tensor(91.3717), 170: tensor(96.5383), 180: tensor(97.6983), 190: tensor(96.3817), 200: tensor(92.3150), 210: tensor(84.5883), 220: tensor(75.9133), 230: tensor(74.1083), 240: tensor(82.0833), 250: tensor(91.3717), 260: tensor(96.5383), 270: tensor(97.6983), 280: tensor(96.3817), 290: tensor(92.3150), 300: tensor(84.5883), 310: tensor(75.9133), 320: tensor(74.1083), 330: tensor(82.0833), 340: tensor(91.3717), 350: tensor(96.5383)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=62, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.8048,                   Accuracy: 212/2000.0 (10.60%)



-= Testing valid =-
Test set: Average loss: 1.4035,                   Accuracy: 1083/2000.0 (54.15%)



-= Testing valid =-
Test set: Average loss: 1.1870,                   Accuracy: 1125/2000.0 (56.25%)



-= Testing valid =-
Test set: Average loss: 1.0714,                   Accuracy: 1227/2000.0 (61.35%)



-= Testing valid =-
Test set: Average loss: 0.4302,                   Accuracy: 1768/2000.0 (88.40%)



-= Testing valid =-
Test set: Average loss: 0.2946,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2114,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.1879,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2863,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2861,                   Accuracy: 1844/2000.0 (92.20%)



Epoch 10 train accuracy: 95.57%, valid accuracy 92.20%
-= Testing valid =-
Test set: Average loss: 0.1323,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1098,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1122,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1070,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1114,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1236,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1180,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 20 train accuracy: 97.95%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 30 train accuracy: 98.47%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 40 train accuracy: 98.68%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 50 train accuracy: 99.05%, valid accuracy 97.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0822,                   Accuracy: 58549/60000 (97.58%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1266,                   Accuracy: 57694/60000 (96.16%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2683,                   Accuracy: 55181/60000 (91.97%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6445,                   Accuracy: 49397/60000 (82.33%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0352,                   Accuracy: 43485/60000 (72.47%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0790,                   Accuracy: 42436/60000 (70.73%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6469,                   Accuracy: 48622/60000 (81.04%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3060,                   Accuracy: 54513/60000 (90.86%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1212,                   Accuracy: 57786/60000 (96.31%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0822,                   Accuracy: 58549/60000 (97.58%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1266,                   Accuracy: 57694/60000 (96.16%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2683,                   Accuracy: 55181/60000 (91.97%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6445,                   Accuracy: 49397/60000 (82.33%)
-= Testing Rotation 130 =-
Test set: Average loss: 1.0352,                   Accuracy: 43485/60000 (72.47%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0790,                   Accuracy: 42436/60000 (70.73%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6469,                   Accuracy: 48622/60000 (81.04%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3060,                   Accuracy: 54513/60000 (90.86%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1212,                   Accuracy: 57786/60000 (96.31%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0822,                   Accuracy: 58549/60000 (97.58%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1266,                   Accuracy: 57694/60000 (96.16%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2683,                   Accuracy: 55181/60000 (91.97%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6445,                   Accuracy: 49397/60000 (82.33%)
-= Testing Rotation 220 =-
Test set: Average loss: 1.0352,                   Accuracy: 43485/60000 (72.47%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0790,                   Accuracy: 42436/60000 (70.73%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6469,                   Accuracy: 48622/60000 (81.04%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3060,                   Accuracy: 54513/60000 (90.86%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1212,                   Accuracy: 57786/60000 (96.31%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0822,                   Accuracy: 58549/60000 (97.58%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1266,                   Accuracy: 57694/60000 (96.16%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2683,                   Accuracy: 55181/60000 (91.97%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6445,                   Accuracy: 49397/60000 (82.33%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0352,                   Accuracy: 43485/60000 (72.47%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0790,                   Accuracy: 42436/60000 (70.73%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6469,                   Accuracy: 48622/60000 (81.04%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3060,                   Accuracy: 54513/60000 (90.86%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1212,                   Accuracy: 57786/60000 (96.31%)
{0: tensor(97.5817), 10: tensor(96.1567), 20: tensor(91.9683), 30: tensor(82.3283), 40: tensor(72.4750), 50: tensor(70.7267), 60: tensor(81.0367), 70: tensor(90.8550), 80: tensor(96.3100), 90: tensor(97.5817), 100: tensor(96.1567), 110: tensor(91.9683), 120: tensor(82.3283), 130: tensor(72.4750), 140: tensor(70.7267), 150: tensor(81.0367), 160: tensor(90.8550), 170: tensor(96.3100), 180: tensor(97.5817), 190: tensor(96.1567), 200: tensor(91.9683), 210: tensor(82.3283), 220: tensor(72.4750), 230: tensor(70.7267), 240: tensor(81.0367), 250: tensor(90.8550), 260: tensor(96.3100), 270: tensor(97.5817), 280: tensor(96.1567), 290: tensor(91.9683), 300: tensor(82.3283), 310: tensor(72.4750), 320: tensor(70.7267), 330: tensor(81.0367), 340: tensor(90.8550), 350: tensor(96.3100)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=63, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.5194,                   Accuracy: 409/2000.0 (20.45%)



-= Testing valid =-
Test set: Average loss: 0.8887,                   Accuracy: 1483/2000.0 (74.15%)



-= Testing valid =-
Test set: Average loss: 0.5647,                   Accuracy: 1629/2000.0 (81.45%)



-= Testing valid =-
Test set: Average loss: 0.4581,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.2112,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2106,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.3246,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.1397,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1796,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1586,                   Accuracy: 1899/2000.0 (94.95%)



Epoch 10 train accuracy: 96.81%, valid accuracy 94.95%
-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1365,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1034,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 20 train accuracy: 98.20%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0691,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0683,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0691,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1064,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0619,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 30 train accuracy: 98.97%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0629,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0593,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0645,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0601,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0578,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 40 train accuracy: 99.04%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0593,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0568,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 50 train accuracy: 99.11%, valid accuracy 98.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0732,                   Accuracy: 58741/60000 (97.90%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1275,                   Accuracy: 57677/60000 (96.13%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2554,                   Accuracy: 55440/60000 (92.40%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6164,                   Accuracy: 49387/60000 (82.31%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9867,                   Accuracy: 43872/60000 (73.12%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0843,                   Accuracy: 41984/60000 (69.97%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7199,                   Accuracy: 47243/60000 (78.74%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3615,                   Accuracy: 53426/60000 (89.04%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1270,                   Accuracy: 57688/60000 (96.15%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0732,                   Accuracy: 58741/60000 (97.90%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1275,                   Accuracy: 57677/60000 (96.13%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2554,                   Accuracy: 55440/60000 (92.40%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6164,                   Accuracy: 49387/60000 (82.31%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9867,                   Accuracy: 43872/60000 (73.12%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0843,                   Accuracy: 41984/60000 (69.97%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7199,                   Accuracy: 47243/60000 (78.74%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3615,                   Accuracy: 53426/60000 (89.04%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1270,                   Accuracy: 57688/60000 (96.15%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0732,                   Accuracy: 58741/60000 (97.90%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1275,                   Accuracy: 57677/60000 (96.13%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2554,                   Accuracy: 55440/60000 (92.40%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6164,                   Accuracy: 49387/60000 (82.31%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9867,                   Accuracy: 43872/60000 (73.12%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0843,                   Accuracy: 41984/60000 (69.97%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7199,                   Accuracy: 47243/60000 (78.74%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3615,                   Accuracy: 53426/60000 (89.04%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1270,                   Accuracy: 57688/60000 (96.15%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0732,                   Accuracy: 58741/60000 (97.90%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1275,                   Accuracy: 57677/60000 (96.13%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2554,                   Accuracy: 55440/60000 (92.40%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6164,                   Accuracy: 49387/60000 (82.31%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9867,                   Accuracy: 43872/60000 (73.12%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0843,                   Accuracy: 41984/60000 (69.97%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7199,                   Accuracy: 47243/60000 (78.74%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3615,                   Accuracy: 53426/60000 (89.04%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1270,                   Accuracy: 57688/60000 (96.15%)
{0: tensor(97.9017), 10: tensor(96.1283), 20: tensor(92.4000), 30: tensor(82.3117), 40: tensor(73.1200), 50: tensor(69.9733), 60: tensor(78.7383), 70: tensor(89.0433), 80: tensor(96.1467), 90: tensor(97.9017), 100: tensor(96.1283), 110: tensor(92.4000), 120: tensor(82.3117), 130: tensor(73.1200), 140: tensor(69.9733), 150: tensor(78.7383), 160: tensor(89.0433), 170: tensor(96.1467), 180: tensor(97.9017), 190: tensor(96.1283), 200: tensor(92.4000), 210: tensor(82.3117), 220: tensor(73.1200), 230: tensor(69.9733), 240: tensor(78.7383), 250: tensor(89.0433), 260: tensor(96.1467), 270: tensor(97.9017), 280: tensor(96.1283), 290: tensor(92.4000), 300: tensor(82.3117), 310: tensor(73.1200), 320: tensor(69.9733), 330: tensor(78.7383), 340: tensor(89.0433), 350: tensor(96.1467)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=64, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6587,                   Accuracy: 325/2000.0 (16.25%)



-= Testing valid =-
Test set: Average loss: 1.7955,                   Accuracy: 754/2000.0 (37.70%)



-= Testing valid =-
Test set: Average loss: 0.7689,                   Accuracy: 1463/2000.0 (73.15%)



-= Testing valid =-
Test set: Average loss: 0.3180,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2803,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2583,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2116,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.1670,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1750,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.2054,                   Accuracy: 1872/2000.0 (93.60%)



Epoch 10 train accuracy: 95.44%, valid accuracy 93.60%
-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1171,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1189,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 20 train accuracy: 97.56%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0711,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0636,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0637,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 30 train accuracy: 98.43%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0636,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0656,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0597,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0626,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 40 train accuracy: 98.95%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0601,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0579,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 50 train accuracy: 98.91%, valid accuracy 98.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0751,                   Accuracy: 58690/60000 (97.82%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1391,                   Accuracy: 57434/60000 (95.72%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3285,                   Accuracy: 54015/60000 (90.03%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6526,                   Accuracy: 48137/60000 (80.23%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9661,                   Accuracy: 43074/60000 (71.79%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9634,                   Accuracy: 43261/60000 (72.10%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6356,                   Accuracy: 48655/60000 (81.09%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2774,                   Accuracy: 54952/60000 (91.59%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1151,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0751,                   Accuracy: 58690/60000 (97.82%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1391,                   Accuracy: 57434/60000 (95.72%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3285,                   Accuracy: 54015/60000 (90.03%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6526,                   Accuracy: 48137/60000 (80.23%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9661,                   Accuracy: 43074/60000 (71.79%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9634,                   Accuracy: 43261/60000 (72.10%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6356,                   Accuracy: 48655/60000 (81.09%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2774,                   Accuracy: 54952/60000 (91.59%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1151,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0751,                   Accuracy: 58690/60000 (97.82%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1391,                   Accuracy: 57434/60000 (95.72%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3285,                   Accuracy: 54015/60000 (90.03%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6526,                   Accuracy: 48137/60000 (80.23%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9661,                   Accuracy: 43074/60000 (71.79%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9634,                   Accuracy: 43261/60000 (72.10%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6356,                   Accuracy: 48655/60000 (81.09%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2774,                   Accuracy: 54952/60000 (91.59%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1151,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0751,                   Accuracy: 58690/60000 (97.82%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1391,                   Accuracy: 57434/60000 (95.72%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3285,                   Accuracy: 54015/60000 (90.03%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6526,                   Accuracy: 48137/60000 (80.23%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9661,                   Accuracy: 43074/60000 (71.79%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9634,                   Accuracy: 43261/60000 (72.10%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6356,                   Accuracy: 48655/60000 (81.09%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2774,                   Accuracy: 54952/60000 (91.59%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1151,                   Accuracy: 57886/60000 (96.48%)
{0: tensor(97.8167), 10: tensor(95.7233), 20: tensor(90.0250), 30: tensor(80.2283), 40: tensor(71.7900), 50: tensor(72.1017), 60: tensor(81.0917), 70: tensor(91.5867), 80: tensor(96.4767), 90: tensor(97.8167), 100: tensor(95.7233), 110: tensor(90.0250), 120: tensor(80.2283), 130: tensor(71.7900), 140: tensor(72.1017), 150: tensor(81.0917), 160: tensor(91.5867), 170: tensor(96.4767), 180: tensor(97.8167), 190: tensor(95.7233), 200: tensor(90.0250), 210: tensor(80.2283), 220: tensor(71.7900), 230: tensor(72.1017), 240: tensor(81.0917), 250: tensor(91.5867), 260: tensor(96.4767), 270: tensor(97.8167), 280: tensor(95.7233), 290: tensor(90.0250), 300: tensor(80.2283), 310: tensor(71.7900), 320: tensor(72.1017), 330: tensor(81.0917), 340: tensor(91.5867), 350: tensor(96.4767)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=65, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.4105,                   Accuracy: 218/2000.0 (10.90%)



-= Testing valid =-
Test set: Average loss: 1.5979,                   Accuracy: 736/2000.0 (36.80%)



-= Testing valid =-
Test set: Average loss: 0.5367,                   Accuracy: 1756/2000.0 (87.80%)



-= Testing valid =-
Test set: Average loss: 0.3751,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.2343,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2019,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1735,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1927,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1980,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 10 train accuracy: 95.97%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0659,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0790,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0585,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 20 train accuracy: 97.82%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.0579,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0608,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0593,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0719,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 30 train accuracy: 98.34%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0529,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0520,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 40 train accuracy: 98.74%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0453,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0485,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 50 train accuracy: 99.19%, valid accuracy 98.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0783,                   Accuracy: 58645/60000 (97.74%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1226,                   Accuracy: 57902/60000 (96.50%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2409,                   Accuracy: 55885/60000 (93.14%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5136,                   Accuracy: 50946/60000 (84.91%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7949,                   Accuracy: 46257/60000 (77.10%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8919,                   Accuracy: 44745/60000 (74.57%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5501,                   Accuracy: 50104/60000 (83.51%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2647,                   Accuracy: 55293/60000 (92.15%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1163,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0783,                   Accuracy: 58645/60000 (97.74%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1226,                   Accuracy: 57902/60000 (96.50%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2409,                   Accuracy: 55885/60000 (93.14%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5136,                   Accuracy: 50946/60000 (84.91%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7949,                   Accuracy: 46257/60000 (77.10%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8919,                   Accuracy: 44745/60000 (74.57%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5501,                   Accuracy: 50104/60000 (83.51%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2647,                   Accuracy: 55293/60000 (92.15%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1163,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0783,                   Accuracy: 58645/60000 (97.74%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1226,                   Accuracy: 57902/60000 (96.50%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2409,                   Accuracy: 55885/60000 (93.14%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5136,                   Accuracy: 50946/60000 (84.91%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7949,                   Accuracy: 46257/60000 (77.10%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8919,                   Accuracy: 44745/60000 (74.57%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5501,                   Accuracy: 50104/60000 (83.51%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2647,                   Accuracy: 55293/60000 (92.15%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1163,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0783,                   Accuracy: 58645/60000 (97.74%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1226,                   Accuracy: 57902/60000 (96.50%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2409,                   Accuracy: 55885/60000 (93.14%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5136,                   Accuracy: 50946/60000 (84.91%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7949,                   Accuracy: 46257/60000 (77.10%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8919,                   Accuracy: 44745/60000 (74.57%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5501,                   Accuracy: 50104/60000 (83.51%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2647,                   Accuracy: 55293/60000 (92.15%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1163,                   Accuracy: 57929/60000 (96.55%)
{0: tensor(97.7417), 10: tensor(96.5033), 20: tensor(93.1417), 30: tensor(84.9100), 40: tensor(77.0950), 50: tensor(74.5750), 60: tensor(83.5067), 70: tensor(92.1550), 80: tensor(96.5483), 90: tensor(97.7417), 100: tensor(96.5033), 110: tensor(93.1417), 120: tensor(84.9100), 130: tensor(77.0950), 140: tensor(74.5750), 150: tensor(83.5067), 160: tensor(92.1550), 170: tensor(96.5483), 180: tensor(97.7417), 190: tensor(96.5033), 200: tensor(93.1417), 210: tensor(84.9100), 220: tensor(77.0950), 230: tensor(74.5750), 240: tensor(83.5067), 250: tensor(92.1550), 260: tensor(96.5483), 270: tensor(97.7417), 280: tensor(96.5033), 290: tensor(93.1417), 300: tensor(84.9100), 310: tensor(77.0950), 320: tensor(74.5750), 330: tensor(83.5067), 340: tensor(92.1550), 350: tensor(96.5483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=66, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7505,                   Accuracy: 601/2000.0 (30.05%)



-= Testing valid =-
Test set: Average loss: 1.4469,                   Accuracy: 897/2000.0 (44.85%)



-= Testing valid =-
Test set: Average loss: 0.7203,                   Accuracy: 1504/2000.0 (75.20%)



-= Testing valid =-
Test set: Average loss: 0.3059,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.4832,                   Accuracy: 1682/2000.0 (84.10%)



-= Testing valid =-
Test set: Average loss: 0.1899,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1780,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.2032,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.1694,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1682,                   Accuracy: 1891/2000.0 (94.55%)



Epoch 10 train accuracy: 96.05%, valid accuracy 94.55%
-= Testing valid =-
Test set: Average loss: 0.1312,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1011,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1460,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1197,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1518,                   Accuracy: 1908/2000.0 (95.40%)



Epoch 20 train accuracy: 97.93%, valid accuracy 95.40%
-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 30 train accuracy: 98.72%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0674,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0618,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0742,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 40 train accuracy: 99.03%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0650,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0704,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 50 train accuracy: 99.01%, valid accuracy 97.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0807,                   Accuracy: 58575/60000 (97.62%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1396,                   Accuracy: 57546/60000 (95.91%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3163,                   Accuracy: 54361/60000 (90.60%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6224,                   Accuracy: 49379/60000 (82.30%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0241,                   Accuracy: 43631/60000 (72.72%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0890,                   Accuracy: 42928/60000 (71.55%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7039,                   Accuracy: 48496/60000 (80.83%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3159,                   Accuracy: 54499/60000 (90.83%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1284,                   Accuracy: 57713/60000 (96.19%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0807,                   Accuracy: 58575/60000 (97.62%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1396,                   Accuracy: 57546/60000 (95.91%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3163,                   Accuracy: 54361/60000 (90.60%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6224,                   Accuracy: 49379/60000 (82.30%)
-= Testing Rotation 130 =-
Test set: Average loss: 1.0241,                   Accuracy: 43631/60000 (72.72%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0890,                   Accuracy: 42928/60000 (71.55%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7039,                   Accuracy: 48496/60000 (80.83%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3159,                   Accuracy: 54499/60000 (90.83%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1284,                   Accuracy: 57713/60000 (96.19%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0807,                   Accuracy: 58575/60000 (97.62%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1396,                   Accuracy: 57546/60000 (95.91%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3163,                   Accuracy: 54361/60000 (90.60%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6224,                   Accuracy: 49379/60000 (82.30%)
-= Testing Rotation 220 =-
Test set: Average loss: 1.0241,                   Accuracy: 43631/60000 (72.72%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0890,                   Accuracy: 42928/60000 (71.55%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7039,                   Accuracy: 48496/60000 (80.83%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3159,                   Accuracy: 54499/60000 (90.83%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1284,                   Accuracy: 57713/60000 (96.19%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0807,                   Accuracy: 58575/60000 (97.62%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1396,                   Accuracy: 57546/60000 (95.91%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3163,                   Accuracy: 54361/60000 (90.60%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6224,                   Accuracy: 49379/60000 (82.30%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0241,                   Accuracy: 43631/60000 (72.72%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0890,                   Accuracy: 42928/60000 (71.55%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7039,                   Accuracy: 48496/60000 (80.83%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3159,                   Accuracy: 54499/60000 (90.83%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1284,                   Accuracy: 57713/60000 (96.19%)
{0: tensor(97.6250), 10: tensor(95.9100), 20: tensor(90.6017), 30: tensor(82.2983), 40: tensor(72.7183), 50: tensor(71.5467), 60: tensor(80.8267), 70: tensor(90.8317), 80: tensor(96.1883), 90: tensor(97.6250), 100: tensor(95.9100), 110: tensor(90.6017), 120: tensor(82.2983), 130: tensor(72.7183), 140: tensor(71.5467), 150: tensor(80.8267), 160: tensor(90.8317), 170: tensor(96.1883), 180: tensor(97.6250), 190: tensor(95.9100), 200: tensor(90.6017), 210: tensor(82.2983), 220: tensor(72.7183), 230: tensor(71.5467), 240: tensor(80.8267), 250: tensor(90.8317), 260: tensor(96.1883), 270: tensor(97.6250), 280: tensor(95.9100), 290: tensor(90.6017), 300: tensor(82.2983), 310: tensor(72.7183), 320: tensor(71.5467), 330: tensor(80.8267), 340: tensor(90.8317), 350: tensor(96.1883)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=67, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.5300,                   Accuracy: 272/2000.0 (13.60%)



-= Testing valid =-
Test set: Average loss: 1.6307,                   Accuracy: 782/2000.0 (39.10%)



-= Testing valid =-
Test set: Average loss: 0.7490,                   Accuracy: 1501/2000.0 (75.05%)



-= Testing valid =-
Test set: Average loss: 0.5624,                   Accuracy: 1632/2000.0 (81.60%)



-= Testing valid =-
Test set: Average loss: 0.2751,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2353,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.5647,                   Accuracy: 1630/2000.0 (81.50%)



-= Testing valid =-
Test set: Average loss: 0.2708,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1666,                   Accuracy: 1884/2000.0 (94.20%)



Epoch 10 train accuracy: 96.05%, valid accuracy 94.20%
-= Testing valid =-
Test set: Average loss: 0.1074,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0882,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1280,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 20 train accuracy: 97.65%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0559,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0606,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 30 train accuracy: 98.53%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0519,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0497,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 40 train accuracy: 98.81%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 50 train accuracy: 98.91%, valid accuracy 98.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0816,                   Accuracy: 58530/60000 (97.55%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1464,                   Accuracy: 57331/60000 (95.55%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3003,                   Accuracy: 54686/60000 (91.14%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6521,                   Accuracy: 49215/60000 (82.03%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0548,                   Accuracy: 42991/60000 (71.65%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1048,                   Accuracy: 41687/60000 (69.48%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7344,                   Accuracy: 46948/60000 (78.25%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3408,                   Accuracy: 53633/60000 (89.39%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1442,                   Accuracy: 57344/60000 (95.57%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0816,                   Accuracy: 58530/60000 (97.55%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1464,                   Accuracy: 57331/60000 (95.55%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3003,                   Accuracy: 54686/60000 (91.14%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6521,                   Accuracy: 49215/60000 (82.03%)
-= Testing Rotation 130 =-
Test set: Average loss: 1.0548,                   Accuracy: 42991/60000 (71.65%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.1048,                   Accuracy: 41687/60000 (69.48%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7344,                   Accuracy: 46948/60000 (78.25%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3408,                   Accuracy: 53633/60000 (89.39%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1442,                   Accuracy: 57344/60000 (95.57%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0816,                   Accuracy: 58530/60000 (97.55%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1464,                   Accuracy: 57331/60000 (95.55%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3003,                   Accuracy: 54686/60000 (91.14%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6521,                   Accuracy: 49215/60000 (82.03%)
-= Testing Rotation 220 =-
Test set: Average loss: 1.0548,                   Accuracy: 42991/60000 (71.65%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.1048,                   Accuracy: 41687/60000 (69.48%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7344,                   Accuracy: 46948/60000 (78.25%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3408,                   Accuracy: 53633/60000 (89.39%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1442,                   Accuracy: 57344/60000 (95.57%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0816,                   Accuracy: 58530/60000 (97.55%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1464,                   Accuracy: 57331/60000 (95.55%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3003,                   Accuracy: 54686/60000 (91.14%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6521,                   Accuracy: 49215/60000 (82.03%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0548,                   Accuracy: 42991/60000 (71.65%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1048,                   Accuracy: 41687/60000 (69.48%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7344,                   Accuracy: 46948/60000 (78.25%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3408,                   Accuracy: 53633/60000 (89.39%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1442,                   Accuracy: 57344/60000 (95.57%)
{0: tensor(97.5500), 10: tensor(95.5517), 20: tensor(91.1433), 30: tensor(82.0250), 40: tensor(71.6517), 50: tensor(69.4783), 60: tensor(78.2467), 70: tensor(89.3883), 80: tensor(95.5733), 90: tensor(97.5500), 100: tensor(95.5517), 110: tensor(91.1433), 120: tensor(82.0250), 130: tensor(71.6517), 140: tensor(69.4783), 150: tensor(78.2467), 160: tensor(89.3883), 170: tensor(95.5733), 180: tensor(97.5500), 190: tensor(95.5517), 200: tensor(91.1433), 210: tensor(82.0250), 220: tensor(71.6517), 230: tensor(69.4783), 240: tensor(78.2467), 250: tensor(89.3883), 260: tensor(95.5733), 270: tensor(97.5500), 280: tensor(95.5517), 290: tensor(91.1433), 300: tensor(82.0250), 310: tensor(71.6517), 320: tensor(69.4783), 330: tensor(78.2467), 340: tensor(89.3883), 350: tensor(95.5733)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=68, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.4013,                   Accuracy: 387/2000.0 (19.35%)



-= Testing valid =-
Test set: Average loss: 1.2416,                   Accuracy: 1071/2000.0 (53.55%)



-= Testing valid =-
Test set: Average loss: 0.6017,                   Accuracy: 1641/2000.0 (82.05%)



-= Testing valid =-
Test set: Average loss: 0.7972,                   Accuracy: 1468/2000.0 (73.40%)



-= Testing valid =-
Test set: Average loss: 0.2806,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2291,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.2875,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.1386,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1262,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1733,                   Accuracy: 1889/2000.0 (94.45%)



Epoch 10 train accuracy: 95.99%, valid accuracy 94.45%
-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1121,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0910,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1235,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0981,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 20 train accuracy: 97.85%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0650,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0691,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0668,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 30 train accuracy: 98.76%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0674,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0656,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0644,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0678,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0650,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 40 train accuracy: 99.06%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0659,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0664,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0662,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 50 train accuracy: 98.95%, valid accuracy 98.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0794,                   Accuracy: 58593/60000 (97.65%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1225,                   Accuracy: 57770/60000 (96.28%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2673,                   Accuracy: 55289/60000 (92.15%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5920,                   Accuracy: 49918/60000 (83.20%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0024,                   Accuracy: 43796/60000 (72.99%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0735,                   Accuracy: 42391/60000 (70.65%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6911,                   Accuracy: 47952/60000 (79.92%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3283,                   Accuracy: 54004/60000 (90.01%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1194,                   Accuracy: 57778/60000 (96.30%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0794,                   Accuracy: 58593/60000 (97.65%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1225,                   Accuracy: 57770/60000 (96.28%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2673,                   Accuracy: 55289/60000 (92.15%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5920,                   Accuracy: 49918/60000 (83.20%)
-= Testing Rotation 130 =-
Test set: Average loss: 1.0024,                   Accuracy: 43796/60000 (72.99%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0735,                   Accuracy: 42391/60000 (70.65%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6911,                   Accuracy: 47952/60000 (79.92%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3283,                   Accuracy: 54004/60000 (90.01%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1194,                   Accuracy: 57778/60000 (96.30%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0794,                   Accuracy: 58593/60000 (97.65%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1225,                   Accuracy: 57770/60000 (96.28%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2673,                   Accuracy: 55289/60000 (92.15%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5920,                   Accuracy: 49918/60000 (83.20%)
-= Testing Rotation 220 =-
Test set: Average loss: 1.0024,                   Accuracy: 43796/60000 (72.99%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0735,                   Accuracy: 42391/60000 (70.65%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6911,                   Accuracy: 47952/60000 (79.92%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3283,                   Accuracy: 54004/60000 (90.01%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1194,                   Accuracy: 57778/60000 (96.30%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0794,                   Accuracy: 58593/60000 (97.65%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1225,                   Accuracy: 57770/60000 (96.28%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2673,                   Accuracy: 55289/60000 (92.15%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5920,                   Accuracy: 49918/60000 (83.20%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0024,                   Accuracy: 43796/60000 (72.99%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0735,                   Accuracy: 42391/60000 (70.65%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6911,                   Accuracy: 47952/60000 (79.92%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3283,                   Accuracy: 54004/60000 (90.01%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1194,                   Accuracy: 57778/60000 (96.30%)
{0: tensor(97.6550), 10: tensor(96.2833), 20: tensor(92.1483), 30: tensor(83.1967), 40: tensor(72.9933), 50: tensor(70.6517), 60: tensor(79.9200), 70: tensor(90.0067), 80: tensor(96.2967), 90: tensor(97.6550), 100: tensor(96.2833), 110: tensor(92.1483), 120: tensor(83.1967), 130: tensor(72.9933), 140: tensor(70.6517), 150: tensor(79.9200), 160: tensor(90.0067), 170: tensor(96.2967), 180: tensor(97.6550), 190: tensor(96.2833), 200: tensor(92.1483), 210: tensor(83.1967), 220: tensor(72.9933), 230: tensor(70.6517), 240: tensor(79.9200), 250: tensor(90.0067), 260: tensor(96.2967), 270: tensor(97.6550), 280: tensor(96.2833), 290: tensor(92.1483), 300: tensor(83.1967), 310: tensor(72.9933), 320: tensor(70.6517), 330: tensor(79.9200), 340: tensor(90.0067), 350: tensor(96.2967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=69, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4831,                   Accuracy: 241/2000.0 (12.05%)



-= Testing valid =-
Test set: Average loss: 2.3476,                   Accuracy: 414/2000.0 (20.70%)



-= Testing valid =-
Test set: Average loss: 0.7715,                   Accuracy: 1574/2000.0 (78.70%)



-= Testing valid =-
Test set: Average loss: 0.5004,                   Accuracy: 1688/2000.0 (84.40%)



-= Testing valid =-
Test set: Average loss: 0.2853,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.3065,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.2005,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.2690,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.3055,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.1477,                   Accuracy: 1902/2000.0 (95.10%)



Epoch 10 train accuracy: 95.68%, valid accuracy 95.10%
-= Testing valid =-
Test set: Average loss: 0.1204,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1148,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1221,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1134,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1408,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1037,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1051,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1923/2000.0 (96.15%)



Epoch 20 train accuracy: 97.96%, valid accuracy 96.15%
-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0775,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 30 train accuracy: 98.60%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0712,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0683,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0738,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0704,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 40 train accuracy: 98.80%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0683,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0656,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0691,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 50 train accuracy: 98.94%, valid accuracy 97.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0766,                   Accuracy: 58633/60000 (97.72%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1305,                   Accuracy: 57706/60000 (96.18%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2551,                   Accuracy: 55526/60000 (92.54%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5208,                   Accuracy: 50831/60000 (84.72%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8197,                   Accuracy: 45491/60000 (75.82%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8967,                   Accuracy: 43878/60000 (73.13%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6224,                   Accuracy: 48070/60000 (80.12%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3070,                   Accuracy: 54300/60000 (90.50%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1325,                   Accuracy: 57661/60000 (96.10%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0766,                   Accuracy: 58633/60000 (97.72%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1305,                   Accuracy: 57706/60000 (96.18%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2551,                   Accuracy: 55526/60000 (92.54%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5208,                   Accuracy: 50831/60000 (84.72%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8197,                   Accuracy: 45491/60000 (75.82%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8967,                   Accuracy: 43878/60000 (73.13%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6224,                   Accuracy: 48070/60000 (80.12%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3070,                   Accuracy: 54300/60000 (90.50%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1325,                   Accuracy: 57661/60000 (96.10%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0766,                   Accuracy: 58633/60000 (97.72%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1305,                   Accuracy: 57706/60000 (96.18%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2551,                   Accuracy: 55526/60000 (92.54%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5208,                   Accuracy: 50831/60000 (84.72%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8197,                   Accuracy: 45491/60000 (75.82%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8967,                   Accuracy: 43878/60000 (73.13%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6224,                   Accuracy: 48070/60000 (80.12%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3070,                   Accuracy: 54300/60000 (90.50%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1325,                   Accuracy: 57661/60000 (96.10%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0766,                   Accuracy: 58633/60000 (97.72%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1305,                   Accuracy: 57706/60000 (96.18%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2551,                   Accuracy: 55526/60000 (92.54%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5208,                   Accuracy: 50831/60000 (84.72%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8197,                   Accuracy: 45491/60000 (75.82%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8967,                   Accuracy: 43878/60000 (73.13%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6224,                   Accuracy: 48070/60000 (80.12%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3070,                   Accuracy: 54300/60000 (90.50%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1325,                   Accuracy: 57661/60000 (96.10%)
{0: tensor(97.7217), 10: tensor(96.1767), 20: tensor(92.5433), 30: tensor(84.7183), 40: tensor(75.8183), 50: tensor(73.1300), 60: tensor(80.1167), 70: tensor(90.5000), 80: tensor(96.1017), 90: tensor(97.7217), 100: tensor(96.1767), 110: tensor(92.5433), 120: tensor(84.7183), 130: tensor(75.8183), 140: tensor(73.1300), 150: tensor(80.1167), 160: tensor(90.5000), 170: tensor(96.1017), 180: tensor(97.7217), 190: tensor(96.1767), 200: tensor(92.5433), 210: tensor(84.7183), 220: tensor(75.8183), 230: tensor(73.1300), 240: tensor(80.1167), 250: tensor(90.5000), 260: tensor(96.1017), 270: tensor(97.7217), 280: tensor(96.1767), 290: tensor(92.5433), 300: tensor(84.7183), 310: tensor(75.8183), 320: tensor(73.1300), 330: tensor(80.1167), 340: tensor(90.5000), 350: tensor(96.1017)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=70, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.1130,                   Accuracy: 376/2000.0 (18.80%)



-= Testing valid =-
Test set: Average loss: 1.2205,                   Accuracy: 1094/2000.0 (54.70%)



-= Testing valid =-
Test set: Average loss: 0.3905,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.2920,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.4098,                   Accuracy: 1731/2000.0 (86.55%)



-= Testing valid =-
Test set: Average loss: 0.3004,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.1388,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1509,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.2340,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.1324,                   Accuracy: 1922/2000.0 (96.10%)



Epoch 10 train accuracy: 95.71%, valid accuracy 96.10%
-= Testing valid =-
Test set: Average loss: 0.1190,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1166,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 20 train accuracy: 97.94%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0628,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0560,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0597,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 30 train accuracy: 98.41%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0602,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0602,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0621,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0636,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 40 train accuracy: 99.00%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0594,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 50 train accuracy: 98.84%, valid accuracy 98.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0769,                   Accuracy: 58654/60000 (97.76%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1329,                   Accuracy: 57608/60000 (96.01%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2503,                   Accuracy: 55612/60000 (92.69%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5703,                   Accuracy: 50342/60000 (83.90%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8957,                   Accuracy: 45106/60000 (75.18%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9497,                   Accuracy: 43936/60000 (73.23%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5974,                   Accuracy: 49476/60000 (82.46%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2768,                   Accuracy: 55047/60000 (91.75%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1098,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0769,                   Accuracy: 58654/60000 (97.76%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1329,                   Accuracy: 57608/60000 (96.01%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2503,                   Accuracy: 55612/60000 (92.69%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5703,                   Accuracy: 50342/60000 (83.90%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8957,                   Accuracy: 45106/60000 (75.18%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9497,                   Accuracy: 43936/60000 (73.23%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5974,                   Accuracy: 49476/60000 (82.46%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2768,                   Accuracy: 55047/60000 (91.75%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1098,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0769,                   Accuracy: 58654/60000 (97.76%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1329,                   Accuracy: 57608/60000 (96.01%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2503,                   Accuracy: 55612/60000 (92.69%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5703,                   Accuracy: 50342/60000 (83.90%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8957,                   Accuracy: 45106/60000 (75.18%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9497,                   Accuracy: 43936/60000 (73.23%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5974,                   Accuracy: 49476/60000 (82.46%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2768,                   Accuracy: 55047/60000 (91.75%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1098,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0769,                   Accuracy: 58654/60000 (97.76%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1329,                   Accuracy: 57608/60000 (96.01%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2503,                   Accuracy: 55612/60000 (92.69%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5703,                   Accuracy: 50342/60000 (83.90%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8957,                   Accuracy: 45106/60000 (75.18%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9497,                   Accuracy: 43936/60000 (73.23%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5974,                   Accuracy: 49476/60000 (82.46%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2768,                   Accuracy: 55047/60000 (91.75%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1098,                   Accuracy: 57998/60000 (96.66%)
{0: tensor(97.7567), 10: tensor(96.0133), 20: tensor(92.6867), 30: tensor(83.9033), 40: tensor(75.1767), 50: tensor(73.2267), 60: tensor(82.4600), 70: tensor(91.7450), 80: tensor(96.6633), 90: tensor(97.7567), 100: tensor(96.0133), 110: tensor(92.6867), 120: tensor(83.9033), 130: tensor(75.1767), 140: tensor(73.2267), 150: tensor(82.4600), 160: tensor(91.7450), 170: tensor(96.6633), 180: tensor(97.7567), 190: tensor(96.0133), 200: tensor(92.6867), 210: tensor(83.9033), 220: tensor(75.1767), 230: tensor(73.2267), 240: tensor(82.4600), 250: tensor(91.7450), 260: tensor(96.6633), 270: tensor(97.7567), 280: tensor(96.0133), 290: tensor(92.6867), 300: tensor(83.9033), 310: tensor(75.1767), 320: tensor(73.2267), 330: tensor(82.4600), 340: tensor(91.7450), 350: tensor(96.6633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=41, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4750,                   Accuracy: 497/2000.0 (24.85%)



-= Testing valid =-
Test set: Average loss: 0.9958,                   Accuracy: 1269/2000.0 (63.45%)



-= Testing valid =-
Test set: Average loss: 0.4251,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.1805,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1321,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1391,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1179,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0597,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 10 train accuracy: 98.35%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0617,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0445,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 20 train accuracy: 99.24%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 30 train accuracy: 99.46%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 40 train accuracy: 99.72%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0251,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 50 train accuracy: 99.71%, valid accuracy 99.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0420,                   Accuracy: 59224/60000 (98.71%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0756,                   Accuracy: 58664/60000 (97.77%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1741,                   Accuracy: 56948/60000 (94.91%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4570,                   Accuracy: 52379/60000 (87.30%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9080,                   Accuracy: 45053/60000 (75.09%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2089,                   Accuracy: 40032/60000 (66.72%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1260,                   Accuracy: 40913/60000 (68.19%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8679,                   Accuracy: 44287/60000 (73.81%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6531,                   Accuracy: 47543/60000 (79.24%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5950,                   Accuracy: 48278/60000 (80.46%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9268,                   Accuracy: 42450/60000 (70.75%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5241,                   Accuracy: 34807/60000 (58.01%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.4457,                   Accuracy: 25392/60000 (42.32%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.2813,                   Accuracy: 21471/60000 (35.78%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.7778,                   Accuracy: 20688/60000 (34.48%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.9782,                   Accuracy: 23585/60000 (39.31%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.0245,                   Accuracy: 26972/60000 (44.95%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.3012,                   Accuracy: 28661/60000 (47.77%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.3400,                   Accuracy: 29829/60000 (49.72%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.1772,                   Accuracy: 29602/60000 (49.34%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.1232,                   Accuracy: 27811/60000 (46.35%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.0897,                   Accuracy: 24777/60000 (41.29%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7832,                   Accuracy: 23388/60000 (38.98%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1641,                   Accuracy: 24922/60000 (41.54%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2513,                   Accuracy: 30423/60000 (50.71%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3370,                   Accuracy: 38705/60000 (64.51%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7803,                   Accuracy: 45036/60000 (75.06%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5685,                   Accuracy: 48468/60000 (80.78%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6778,                   Accuracy: 46523/60000 (77.54%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8589,                   Accuracy: 42601/60000 (71.00%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1688,                   Accuracy: 37435/60000 (62.39%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2786,                   Accuracy: 36277/60000 (60.46%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1611,                   Accuracy: 39652/60000 (66.09%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6403,                   Accuracy: 48554/60000 (80.92%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2188,                   Accuracy: 55942/60000 (93.24%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0722,                   Accuracy: 58660/60000 (97.77%)
{0: tensor(98.7067), 10: tensor(97.7733), 20: tensor(94.9133), 30: tensor(87.2983), 40: tensor(75.0883), 50: tensor(66.7200), 60: tensor(68.1883), 70: tensor(73.8117), 80: tensor(79.2383), 90: tensor(80.4633), 100: tensor(70.7500), 110: tensor(58.0117), 120: tensor(42.3200), 130: tensor(35.7850), 140: tensor(34.4800), 150: tensor(39.3083), 160: tensor(44.9533), 170: tensor(47.7683), 180: tensor(49.7150), 190: tensor(49.3367), 200: tensor(46.3517), 210: tensor(41.2950), 220: tensor(38.9800), 230: tensor(41.5367), 240: tensor(50.7050), 250: tensor(64.5083), 260: tensor(75.0600), 270: tensor(80.7800), 280: tensor(77.5383), 290: tensor(71.0017), 300: tensor(62.3917), 310: tensor(60.4617), 320: tensor(66.0867), 330: tensor(80.9233), 340: tensor(93.2367), 350: tensor(97.7667)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=42, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9761,                   Accuracy: 571/2000.0 (28.55%)



-= Testing valid =-
Test set: Average loss: 1.5586,                   Accuracy: 930/2000.0 (46.50%)



-= Testing valid =-
Test set: Average loss: 0.6446,                   Accuracy: 1611/2000.0 (80.55%)



-= Testing valid =-
Test set: Average loss: 0.2354,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1401,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1354,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1196,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 10 train accuracy: 98.12%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 20 train accuracy: 99.21%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0220,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0214,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0218,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0217,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0187,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.38%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0179,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0208,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0190,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0221,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0191,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0201,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0186,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0182,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0167,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0177,                   Accuracy: 1989/2000.0 (99.45%)



Epoch 40 train accuracy: 99.69%, valid accuracy 99.45%
-= Testing valid =-
Test set: Average loss: 0.0175,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0177,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0190,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0171,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0167,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0173,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0179,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0201,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0169,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0186,                   Accuracy: 1989/2000.0 (99.45%)



Epoch 50 train accuracy: 99.68%, valid accuracy 99.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0489,                   Accuracy: 59151/60000 (98.58%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0689,                   Accuracy: 58792/60000 (97.99%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1532,                   Accuracy: 57299/60000 (95.50%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3493,                   Accuracy: 53692/60000 (89.49%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7346,                   Accuracy: 47137/60000 (78.56%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9778,                   Accuracy: 42874/60000 (71.46%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9533,                   Accuracy: 42679/60000 (71.13%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7731,                   Accuracy: 44956/60000 (74.93%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5803,                   Accuracy: 48330/60000 (80.55%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4744,                   Accuracy: 50159/60000 (83.60%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7893,                   Accuracy: 45380/60000 (75.63%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.4569,                   Accuracy: 37493/60000 (62.49%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.1094,                   Accuracy: 32050/60000 (53.42%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8819,                   Accuracy: 27513/60000 (45.85%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3105,                   Accuracy: 25345/60000 (42.24%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.5927,                   Accuracy: 24979/60000 (41.63%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5587,                   Accuracy: 27153/60000 (45.26%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.6197,                   Accuracy: 28757/60000 (47.93%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.5358,                   Accuracy: 29363/60000 (48.94%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4756,                   Accuracy: 29180/60000 (48.63%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.4689,                   Accuracy: 26900/60000 (44.83%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.5740,                   Accuracy: 24396/60000 (40.66%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.3900,                   Accuracy: 23736/60000 (39.56%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8207,                   Accuracy: 26508/60000 (44.18%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0224,                   Accuracy: 31927/60000 (53.21%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1697,                   Accuracy: 40773/60000 (67.96%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6247,                   Accuracy: 48137/60000 (80.23%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3215,                   Accuracy: 53544/60000 (89.24%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4216,                   Accuracy: 51737/60000 (86.23%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6682,                   Accuracy: 48082/60000 (80.14%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.8925,                   Accuracy: 44787/60000 (74.64%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0522,                   Accuracy: 42075/60000 (70.12%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0367,                   Accuracy: 42505/60000 (70.84%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6723,                   Accuracy: 47894/60000 (79.82%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2866,                   Accuracy: 54553/60000 (90.92%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0953,                   Accuracy: 58182/60000 (96.97%)
{0: tensor(98.5850), 10: tensor(97.9867), 20: tensor(95.4983), 30: tensor(89.4867), 40: tensor(78.5617), 50: tensor(71.4567), 60: tensor(71.1317), 70: tensor(74.9267), 80: tensor(80.5500), 90: tensor(83.5983), 100: tensor(75.6333), 110: tensor(62.4883), 120: tensor(53.4167), 130: tensor(45.8550), 140: tensor(42.2417), 150: tensor(41.6317), 160: tensor(45.2550), 170: tensor(47.9283), 180: tensor(48.9383), 190: tensor(48.6333), 200: tensor(44.8333), 210: tensor(40.6600), 220: tensor(39.5600), 230: tensor(44.1800), 240: tensor(53.2117), 250: tensor(67.9550), 260: tensor(80.2283), 270: tensor(89.2400), 280: tensor(86.2283), 290: tensor(80.1367), 300: tensor(74.6450), 310: tensor(70.1250), 320: tensor(70.8417), 330: tensor(79.8233), 340: tensor(90.9217), 350: tensor(96.9700)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=43, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 6.3687,                   Accuracy: 246/2000.0 (12.30%)



-= Testing valid =-
Test set: Average loss: 1.8183,                   Accuracy: 580/2000.0 (29.00%)



-= Testing valid =-
Test set: Average loss: 1.1997,                   Accuracy: 1237/2000.0 (61.85%)



-= Testing valid =-
Test set: Average loss: 0.4969,                   Accuracy: 1685/2000.0 (84.25%)



-= Testing valid =-
Test set: Average loss: 0.1845,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1152,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1409,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 10 train accuracy: 98.18%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0409,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0454,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 20 train accuracy: 99.09%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 30 train accuracy: 99.46%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.60%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.69%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0500,                   Accuracy: 59121/60000 (98.54%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0793,                   Accuracy: 58648/60000 (97.75%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1814,                   Accuracy: 56929/60000 (94.88%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4894,                   Accuracy: 51432/60000 (85.72%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9276,                   Accuracy: 44056/60000 (73.43%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1754,                   Accuracy: 39679/60000 (66.13%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0038,                   Accuracy: 42101/60000 (70.17%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7076,                   Accuracy: 46584/60000 (77.64%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4973,                   Accuracy: 50097/60000 (83.50%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4207,                   Accuracy: 51933/60000 (86.56%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6787,                   Accuracy: 47285/60000 (78.81%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3005,                   Accuracy: 38663/60000 (64.44%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.1680,                   Accuracy: 30099/60000 (50.17%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.9339,                   Accuracy: 25594/60000 (42.66%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3207,                   Accuracy: 24944/60000 (41.57%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.3789,                   Accuracy: 26767/60000 (44.61%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.2189,                   Accuracy: 29876/60000 (49.79%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.0832,                   Accuracy: 31321/60000 (52.20%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.9617,                   Accuracy: 32278/60000 (53.80%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.9559,                   Accuracy: 32286/60000 (53.81%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.0518,                   Accuracy: 30506/60000 (50.84%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.2244,                   Accuracy: 27401/60000 (45.67%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.2051,                   Accuracy: 26451/60000 (44.08%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7651,                   Accuracy: 28608/60000 (47.68%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9862,                   Accuracy: 34074/60000 (56.79%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2819,                   Accuracy: 40855/60000 (68.09%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7900,                   Accuracy: 46463/60000 (77.44%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5273,                   Accuracy: 50031/60000 (83.39%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6615,                   Accuracy: 47630/60000 (79.38%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8818,                   Accuracy: 43959/60000 (73.26%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1097,                   Accuracy: 39280/60000 (65.47%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2583,                   Accuracy: 37751/60000 (62.92%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1089,                   Accuracy: 41389/60000 (68.98%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5956,                   Accuracy: 49478/60000 (82.46%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2444,                   Accuracy: 55714/60000 (92.86%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0854,                   Accuracy: 58470/60000 (97.45%)
{0: tensor(98.5350), 10: tensor(97.7467), 20: tensor(94.8817), 30: tensor(85.7200), 40: tensor(73.4267), 50: tensor(66.1317), 60: tensor(70.1683), 70: tensor(77.6400), 80: tensor(83.4950), 90: tensor(86.5550), 100: tensor(78.8083), 110: tensor(64.4383), 120: tensor(50.1650), 130: tensor(42.6567), 140: tensor(41.5733), 150: tensor(44.6117), 160: tensor(49.7933), 170: tensor(52.2017), 180: tensor(53.7967), 190: tensor(53.8100), 200: tensor(50.8433), 210: tensor(45.6683), 220: tensor(44.0850), 230: tensor(47.6800), 240: tensor(56.7900), 250: tensor(68.0917), 260: tensor(77.4383), 270: tensor(83.3850), 280: tensor(79.3833), 290: tensor(73.2650), 300: tensor(65.4667), 310: tensor(62.9183), 320: tensor(68.9817), 330: tensor(82.4633), 340: tensor(92.8567), 350: tensor(97.4500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=44, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9208,                   Accuracy: 468/2000.0 (23.40%)



-= Testing valid =-
Test set: Average loss: 0.9284,                   Accuracy: 1345/2000.0 (67.25%)



-= Testing valid =-
Test set: Average loss: 0.6748,                   Accuracy: 1617/2000.0 (80.85%)



-= Testing valid =-
Test set: Average loss: 0.3602,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.1636,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1698,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1011,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1335,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.1906,                   Accuracy: 1892/2000.0 (94.60%)



Epoch 10 train accuracy: 97.96%, valid accuracy 94.60%
-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0594,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 20 train accuracy: 99.03%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 30 train accuracy: 99.40%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0201,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 40 train accuracy: 99.61%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 50 train accuracy: 99.62%, valid accuracy 99.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0521,                   Accuracy: 59068/60000 (98.45%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0803,                   Accuracy: 58588/60000 (97.65%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1886,                   Accuracy: 56743/60000 (94.57%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4948,                   Accuracy: 51441/60000 (85.74%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9102,                   Accuracy: 44226/60000 (73.71%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1082,                   Accuracy: 40595/60000 (67.66%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9773,                   Accuracy: 42518/60000 (70.86%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6946,                   Accuracy: 47055/60000 (78.43%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5385,                   Accuracy: 49314/60000 (82.19%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5218,                   Accuracy: 49229/60000 (82.05%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7362,                   Accuracy: 45510/60000 (75.85%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3016,                   Accuracy: 38214/60000 (63.69%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.1293,                   Accuracy: 30895/60000 (51.49%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8065,                   Accuracy: 26770/60000 (44.62%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.2141,                   Accuracy: 25289/60000 (42.15%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.3548,                   Accuracy: 26871/60000 (44.78%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.2660,                   Accuracy: 30769/60000 (51.28%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.2866,                   Accuracy: 33171/60000 (55.28%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.2071,                   Accuracy: 33859/60000 (56.43%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.1580,                   Accuracy: 32530/60000 (54.22%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.2633,                   Accuracy: 29557/60000 (49.26%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.3707,                   Accuracy: 25576/60000 (42.63%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.2052,                   Accuracy: 24112/60000 (40.19%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.6250,                   Accuracy: 27305/60000 (45.51%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.7496,                   Accuracy: 34769/60000 (57.95%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.9354,                   Accuracy: 44009/60000 (73.35%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.4503,                   Accuracy: 51208/60000 (85.35%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2577,                   Accuracy: 55135/60000 (91.89%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3674,                   Accuracy: 53191/60000 (88.65%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.5937,                   Accuracy: 49129/60000 (81.88%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0684,                   Accuracy: 42002/60000 (70.00%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3126,                   Accuracy: 38652/60000 (64.42%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1755,                   Accuracy: 40819/60000 (68.03%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6842,                   Accuracy: 48519/60000 (80.86%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2257,                   Accuracy: 55976/60000 (93.29%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0817,                   Accuracy: 58517/60000 (97.53%)
{0: tensor(98.4467), 10: tensor(97.6467), 20: tensor(94.5717), 30: tensor(85.7350), 40: tensor(73.7100), 50: tensor(67.6583), 60: tensor(70.8633), 70: tensor(78.4250), 80: tensor(82.1900), 90: tensor(82.0483), 100: tensor(75.8500), 110: tensor(63.6900), 120: tensor(51.4917), 130: tensor(44.6167), 140: tensor(42.1483), 150: tensor(44.7850), 160: tensor(51.2817), 170: tensor(55.2850), 180: tensor(56.4317), 190: tensor(54.2167), 200: tensor(49.2617), 210: tensor(42.6267), 220: tensor(40.1867), 230: tensor(45.5083), 240: tensor(57.9483), 250: tensor(73.3483), 260: tensor(85.3467), 270: tensor(91.8917), 280: tensor(88.6517), 290: tensor(81.8817), 300: tensor(70.0033), 310: tensor(64.4200), 320: tensor(68.0317), 330: tensor(80.8650), 340: tensor(93.2933), 350: tensor(97.5283)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=45, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.1342,                   Accuracy: 277/2000.0 (13.85%)



-= Testing valid =-
Test set: Average loss: 2.4137,                   Accuracy: 460/2000.0 (23.00%)



-= Testing valid =-
Test set: Average loss: 1.9715,                   Accuracy: 811/2000.0 (40.55%)



-= Testing valid =-
Test set: Average loss: 0.5751,                   Accuracy: 1665/2000.0 (83.25%)



-= Testing valid =-
Test set: Average loss: 0.3082,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.1264,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1153,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1370,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1033,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 10 train accuracy: 98.14%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0720,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 20 train accuracy: 99.00%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.47%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 40 train accuracy: 99.56%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.69%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0470,                   Accuracy: 59182/60000 (98.64%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0754,                   Accuracy: 58685/60000 (97.81%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1573,                   Accuracy: 57285/60000 (95.47%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3491,                   Accuracy: 54094/60000 (90.16%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.6583,                   Accuracy: 48872/60000 (81.45%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8797,                   Accuracy: 45277/60000 (75.46%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8533,                   Accuracy: 45580/60000 (75.97%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6665,                   Accuracy: 48202/60000 (80.34%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5041,                   Accuracy: 50346/60000 (83.91%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5384,                   Accuracy: 49022/60000 (81.70%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8095,                   Accuracy: 44234/60000 (73.72%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3595,                   Accuracy: 37346/60000 (62.24%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2445,                   Accuracy: 28012/60000 (46.69%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.9570,                   Accuracy: 24353/60000 (40.59%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3339,                   Accuracy: 24295/60000 (40.49%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4575,                   Accuracy: 26759/60000 (44.60%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.3373,                   Accuracy: 29706/60000 (49.51%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.4539,                   Accuracy: 31010/60000 (51.68%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.6753,                   Accuracy: 31374/60000 (52.29%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.7062,                   Accuracy: 30438/60000 (50.73%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.9412,                   Accuracy: 28326/60000 (47.21%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.0578,                   Accuracy: 26528/60000 (44.21%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7996,                   Accuracy: 26219/60000 (43.70%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1527,                   Accuracy: 28567/60000 (47.61%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2256,                   Accuracy: 33025/60000 (55.04%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3209,                   Accuracy: 39535/60000 (65.89%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7717,                   Accuracy: 45495/60000 (75.82%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4693,                   Accuracy: 50161/60000 (83.60%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5649,                   Accuracy: 48787/60000 (81.31%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7138,                   Accuracy: 46260/60000 (77.10%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9938,                   Accuracy: 40738/60000 (67.90%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1526,                   Accuracy: 38656/60000 (64.43%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0512,                   Accuracy: 40807/60000 (68.01%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5878,                   Accuracy: 48686/60000 (81.14%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2138,                   Accuracy: 55924/60000 (93.21%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0748,                   Accuracy: 58642/60000 (97.74%)
{0: tensor(98.6367), 10: tensor(97.8083), 20: tensor(95.4750), 30: tensor(90.1567), 40: tensor(81.4533), 50: tensor(75.4617), 60: tensor(75.9667), 70: tensor(80.3367), 80: tensor(83.9100), 90: tensor(81.7033), 100: tensor(73.7233), 110: tensor(62.2433), 120: tensor(46.6867), 130: tensor(40.5883), 140: tensor(40.4917), 150: tensor(44.5983), 160: tensor(49.5100), 170: tensor(51.6833), 180: tensor(52.2900), 190: tensor(50.7300), 200: tensor(47.2100), 210: tensor(44.2133), 220: tensor(43.6983), 230: tensor(47.6117), 240: tensor(55.0417), 250: tensor(65.8917), 260: tensor(75.8250), 270: tensor(83.6017), 280: tensor(81.3117), 290: tensor(77.1000), 300: tensor(67.8967), 310: tensor(64.4267), 320: tensor(68.0117), 330: tensor(81.1433), 340: tensor(93.2067), 350: tensor(97.7367)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=46, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1330,                   Accuracy: 387/2000.0 (19.35%)



-= Testing valid =-
Test set: Average loss: 8.3720,                   Accuracy: 176/2000.0 (8.80%)



-= Testing valid =-
Test set: Average loss: 0.9424,                   Accuracy: 1277/2000.0 (63.85%)



-= Testing valid =-
Test set: Average loss: 0.2232,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.3604,                   Accuracy: 1742/2000.0 (87.10%)



-= Testing valid =-
Test set: Average loss: 0.2778,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.1101,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0644,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 10 train accuracy: 98.46%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0520,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 20 train accuracy: 99.28%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0409,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 30 train accuracy: 99.59%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.74%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.71%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0432,                   Accuracy: 59261/60000 (98.77%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0766,                   Accuracy: 58708/60000 (97.85%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1927,                   Accuracy: 56910/60000 (94.85%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4407,                   Accuracy: 52983/60000 (88.31%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8756,                   Accuracy: 46064/60000 (76.77%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0974,                   Accuracy: 42153/60000 (70.25%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8895,                   Accuracy: 44378/60000 (73.96%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6408,                   Accuracy: 48166/60000 (80.28%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4925,                   Accuracy: 50345/60000 (83.91%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5276,                   Accuracy: 49889/60000 (83.15%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8857,                   Accuracy: 45413/60000 (75.69%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5849,                   Accuracy: 37245/60000 (62.08%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.6576,                   Accuracy: 28730/60000 (47.88%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.5434,                   Accuracy: 23191/60000 (38.65%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.9125,                   Accuracy: 21734/60000 (36.22%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8649,                   Accuracy: 23462/60000 (39.10%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.6034,                   Accuracy: 27232/60000 (45.39%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.6896,                   Accuracy: 29747/60000 (49.58%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.9635,                   Accuracy: 30079/60000 (50.13%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.7858,                   Accuracy: 29663/60000 (49.44%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.0371,                   Accuracy: 27847/60000 (46.41%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.3906,                   Accuracy: 25053/60000 (41.76%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.2461,                   Accuracy: 23953/60000 (39.92%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.6198,                   Accuracy: 25967/60000 (43.28%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.5446,                   Accuracy: 31869/60000 (53.12%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.4950,                   Accuracy: 39327/60000 (65.54%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7157,                   Accuracy: 47341/60000 (78.90%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3909,                   Accuracy: 52615/60000 (87.69%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5116,                   Accuracy: 50179/60000 (83.63%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7720,                   Accuracy: 45843/60000 (76.40%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1316,                   Accuracy: 40950/60000 (68.25%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3617,                   Accuracy: 38192/60000 (63.65%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2566,                   Accuracy: 40861/60000 (68.10%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6619,                   Accuracy: 49015/60000 (81.69%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2326,                   Accuracy: 55911/60000 (93.18%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0784,                   Accuracy: 58619/60000 (97.70%)
{0: tensor(98.7683), 10: tensor(97.8467), 20: tensor(94.8500), 30: tensor(88.3050), 40: tensor(76.7733), 50: tensor(70.2550), 60: tensor(73.9633), 70: tensor(80.2767), 80: tensor(83.9083), 90: tensor(83.1483), 100: tensor(75.6883), 110: tensor(62.0750), 120: tensor(47.8833), 130: tensor(38.6517), 140: tensor(36.2233), 150: tensor(39.1033), 160: tensor(45.3867), 170: tensor(49.5783), 180: tensor(50.1317), 190: tensor(49.4383), 200: tensor(46.4117), 210: tensor(41.7550), 220: tensor(39.9217), 230: tensor(43.2783), 240: tensor(53.1150), 250: tensor(65.5450), 260: tensor(78.9017), 270: tensor(87.6917), 280: tensor(83.6317), 290: tensor(76.4050), 300: tensor(68.2500), 310: tensor(63.6533), 320: tensor(68.1017), 330: tensor(81.6917), 340: tensor(93.1850), 350: tensor(97.6983)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=47, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7650,                   Accuracy: 569/2000.0 (28.45%)



-= Testing valid =-
Test set: Average loss: 1.0093,                   Accuracy: 1331/2000.0 (66.55%)



-= Testing valid =-
Test set: Average loss: 0.5160,                   Accuracy: 1749/2000.0 (87.45%)



-= Testing valid =-
Test set: Average loss: 0.5496,                   Accuracy: 1650/2000.0 (82.50%)



-= Testing valid =-
Test set: Average loss: 0.1831,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1173,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.2028,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1213,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1094,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1030,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 10 train accuracy: 98.12%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0798,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0529,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0593,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 20 train accuracy: 99.00%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 30 train accuracy: 99.34%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0450,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 40 train accuracy: 99.64%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0409,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.88%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0448,                   Accuracy: 59214/60000 (98.69%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0748,                   Accuracy: 58631/60000 (97.72%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1809,                   Accuracy: 56900/60000 (94.83%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4969,                   Accuracy: 51837/60000 (86.39%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8974,                   Accuracy: 45091/60000 (75.15%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1300,                   Accuracy: 41088/60000 (68.48%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9891,                   Accuracy: 42221/60000 (70.37%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6960,                   Accuracy: 46071/60000 (76.79%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5611,                   Accuracy: 48417/60000 (80.69%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5060,                   Accuracy: 49572/60000 (82.62%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7458,                   Accuracy: 45372/60000 (75.62%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2887,                   Accuracy: 38455/60000 (64.09%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.1840,                   Accuracy: 31034/60000 (51.72%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.1306,                   Accuracy: 25171/60000 (41.95%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.7340,                   Accuracy: 23241/60000 (38.74%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8693,                   Accuracy: 24355/60000 (40.59%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.7314,                   Accuracy: 27339/60000 (45.56%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.8651,                   Accuracy: 29007/60000 (48.35%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.9994,                   Accuracy: 29963/60000 (49.94%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.9713,                   Accuracy: 29416/60000 (49.03%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.1643,                   Accuracy: 27206/60000 (45.34%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.4677,                   Accuracy: 24035/60000 (40.06%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.2699,                   Accuracy: 23258/60000 (38.76%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.6025,                   Accuracy: 25639/60000 (42.73%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3544,                   Accuracy: 32298/60000 (53.83%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2343,                   Accuracy: 40902/60000 (68.17%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6285,                   Accuracy: 47892/60000 (79.82%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4047,                   Accuracy: 51577/60000 (85.96%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4378,                   Accuracy: 50568/60000 (84.28%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6069,                   Accuracy: 47157/60000 (78.60%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9052,                   Accuracy: 43627/60000 (72.71%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0430,                   Accuracy: 41370/60000 (68.95%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9778,                   Accuracy: 43100/60000 (71.83%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5524,                   Accuracy: 50047/60000 (83.41%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1825,                   Accuracy: 56471/60000 (94.12%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0699,                   Accuracy: 58704/60000 (97.84%)
{0: tensor(98.6900), 10: tensor(97.7183), 20: tensor(94.8333), 30: tensor(86.3950), 40: tensor(75.1517), 50: tensor(68.4800), 60: tensor(70.3683), 70: tensor(76.7850), 80: tensor(80.6950), 90: tensor(82.6200), 100: tensor(75.6200), 110: tensor(64.0917), 120: tensor(51.7233), 130: tensor(41.9517), 140: tensor(38.7350), 150: tensor(40.5917), 160: tensor(45.5650), 170: tensor(48.3450), 180: tensor(49.9383), 190: tensor(49.0267), 200: tensor(45.3433), 210: tensor(40.0583), 220: tensor(38.7633), 230: tensor(42.7317), 240: tensor(53.8300), 250: tensor(68.1700), 260: tensor(79.8200), 270: tensor(85.9617), 280: tensor(84.2800), 290: tensor(78.5950), 300: tensor(72.7117), 310: tensor(68.9500), 320: tensor(71.8333), 330: tensor(83.4117), 340: tensor(94.1183), 350: tensor(97.8400)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=48, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0466,                   Accuracy: 470/2000.0 (23.50%)



-= Testing valid =-
Test set: Average loss: 2.1048,                   Accuracy: 444/2000.0 (22.20%)



-= Testing valid =-
Test set: Average loss: 3.1862,                   Accuracy: 420/2000.0 (21.00%)



-= Testing valid =-
Test set: Average loss: 0.6101,                   Accuracy: 1603/2000.0 (80.15%)



-= Testing valid =-
Test set: Average loss: 0.2642,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.4065,                   Accuracy: 1732/2000.0 (86.60%)



-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1627,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1235,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 10 train accuracy: 97.70%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 20 train accuracy: 98.56%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 30 train accuracy: 98.99%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 40 train accuracy: 99.35%, valid accuracy 99.30%
-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0223,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 50 train accuracy: 99.56%, valid accuracy 99.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0514,                   Accuracy: 59102/60000 (98.50%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0898,                   Accuracy: 58460/60000 (97.43%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1751,                   Accuracy: 56967/60000 (94.94%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3933,                   Accuracy: 53164/60000 (88.61%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7800,                   Accuracy: 46415/60000 (77.36%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1882,                   Accuracy: 39326/60000 (65.54%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.3750,                   Accuracy: 35810/60000 (59.68%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.3655,                   Accuracy: 35368/60000 (58.95%)
-= Testing Rotation 80 =-
Test set: Average loss: 1.3645,                   Accuracy: 35427/60000 (59.04%)
-= Testing Rotation 90 =-
Test set: Average loss: 1.4202,                   Accuracy: 36556/60000 (60.93%)
-= Testing Rotation 100 =-
Test set: Average loss: 2.0815,                   Accuracy: 31196/60000 (51.99%)
-= Testing Rotation 110 =-
Test set: Average loss: 2.8145,                   Accuracy: 27867/60000 (46.44%)
-= Testing Rotation 120 =-
Test set: Average loss: 3.8382,                   Accuracy: 24509/60000 (40.85%)
-= Testing Rotation 130 =-
Test set: Average loss: 4.5717,                   Accuracy: 22814/60000 (38.02%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.0417,                   Accuracy: 22433/60000 (37.39%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.3187,                   Accuracy: 23368/60000 (38.95%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.4648,                   Accuracy: 24641/60000 (41.07%)
-= Testing Rotation 170 =-
Test set: Average loss: 5.6661,                   Accuracy: 25022/60000 (41.70%)
-= Testing Rotation 180 =-
Test set: Average loss: 5.6149,                   Accuracy: 26399/60000 (44.00%)
-= Testing Rotation 190 =-
Test set: Average loss: 5.7051,                   Accuracy: 25815/60000 (43.03%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.5679,                   Accuracy: 25296/60000 (42.16%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.4148,                   Accuracy: 23554/60000 (39.26%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.9760,                   Accuracy: 22154/60000 (36.92%)
-= Testing Rotation 230 =-
Test set: Average loss: 4.1354,                   Accuracy: 23569/60000 (39.28%)
-= Testing Rotation 240 =-
Test set: Average loss: 3.0535,                   Accuracy: 28061/60000 (46.77%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.0312,                   Accuracy: 34502/60000 (57.50%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.2350,                   Accuracy: 40357/60000 (67.26%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7122,                   Accuracy: 47637/60000 (79.39%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.8660,                   Accuracy: 44503/60000 (74.17%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0206,                   Accuracy: 41843/60000 (69.74%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2970,                   Accuracy: 37980/60000 (63.30%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3862,                   Accuracy: 36876/60000 (61.46%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2085,                   Accuracy: 40534/60000 (67.56%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6624,                   Accuracy: 48851/60000 (81.42%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2422,                   Accuracy: 55619/60000 (92.70%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1002,                   Accuracy: 58214/60000 (97.02%)
{0: tensor(98.5033), 10: tensor(97.4333), 20: tensor(94.9450), 30: tensor(88.6067), 40: tensor(77.3583), 50: tensor(65.5433), 60: tensor(59.6833), 70: tensor(58.9467), 80: tensor(59.0450), 90: tensor(60.9267), 100: tensor(51.9933), 110: tensor(46.4450), 120: tensor(40.8483), 130: tensor(38.0233), 140: tensor(37.3883), 150: tensor(38.9467), 160: tensor(41.0683), 170: tensor(41.7033), 180: tensor(43.9983), 190: tensor(43.0250), 200: tensor(42.1600), 210: tensor(39.2567), 220: tensor(36.9233), 230: tensor(39.2817), 240: tensor(46.7683), 250: tensor(57.5033), 260: tensor(67.2617), 270: tensor(79.3950), 280: tensor(74.1717), 290: tensor(69.7383), 300: tensor(63.3000), 310: tensor(61.4600), 320: tensor(67.5567), 330: tensor(81.4183), 340: tensor(92.6983), 350: tensor(97.0233)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=49, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.5760,                   Accuracy: 787/2000.0 (39.35%)



-= Testing valid =-
Test set: Average loss: 0.8998,                   Accuracy: 1471/2000.0 (73.55%)



-= Testing valid =-
Test set: Average loss: 0.8099,                   Accuracy: 1435/2000.0 (71.75%)



-= Testing valid =-
Test set: Average loss: 0.1299,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1871,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1066,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.1089,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 10 train accuracy: 98.29%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 20 train accuracy: 98.95%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 30 train accuracy: 99.61%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0212,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0188,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0203,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 40 train accuracy: 99.50%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0206,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0210,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0221,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0226,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0208,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 50 train accuracy: 99.78%, valid accuracy 99.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0490,                   Accuracy: 59115/60000 (98.53%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0804,                   Accuracy: 58562/60000 (97.60%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1969,                   Accuracy: 56397/60000 (94.00%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5088,                   Accuracy: 51004/60000 (85.01%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8588,                   Accuracy: 44728/60000 (74.55%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0227,                   Accuracy: 41066/60000 (68.44%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9095,                   Accuracy: 42559/60000 (70.93%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6431,                   Accuracy: 47282/60000 (78.80%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5632,                   Accuracy: 48993/60000 (81.65%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5822,                   Accuracy: 49237/60000 (82.06%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0513,                   Accuracy: 42259/60000 (70.43%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6819,                   Accuracy: 35161/60000 (58.60%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5292,                   Accuracy: 26989/60000 (44.98%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.0535,                   Accuracy: 23180/60000 (38.63%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.2634,                   Accuracy: 22778/60000 (37.96%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.2523,                   Accuracy: 25010/60000 (41.68%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.2325,                   Accuracy: 28297/60000 (47.16%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.3938,                   Accuracy: 29477/60000 (49.13%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.5196,                   Accuracy: 29316/60000 (48.86%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.5534,                   Accuracy: 28900/60000 (48.17%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7618,                   Accuracy: 26941/60000 (44.90%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.8816,                   Accuracy: 23902/60000 (39.84%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6332,                   Accuracy: 22745/60000 (37.91%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.0882,                   Accuracy: 24350/60000 (40.58%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2941,                   Accuracy: 28257/60000 (47.10%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.4791,                   Accuracy: 35684/60000 (59.47%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9952,                   Accuracy: 40835/60000 (68.06%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6859,                   Accuracy: 45849/60000 (76.42%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7653,                   Accuracy: 45382/60000 (75.64%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0535,                   Accuracy: 41662/60000 (69.44%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3946,                   Accuracy: 37167/60000 (61.94%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4164,                   Accuracy: 37073/60000 (61.79%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1554,                   Accuracy: 41169/60000 (68.61%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6223,                   Accuracy: 49149/60000 (81.92%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1972,                   Accuracy: 56294/60000 (93.82%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0768,                   Accuracy: 58563/60000 (97.61%)
{0: tensor(98.5250), 10: tensor(97.6033), 20: tensor(93.9950), 30: tensor(85.0067), 40: tensor(74.5467), 50: tensor(68.4433), 60: tensor(70.9317), 70: tensor(78.8033), 80: tensor(81.6550), 90: tensor(82.0617), 100: tensor(70.4317), 110: tensor(58.6017), 120: tensor(44.9817), 130: tensor(38.6333), 140: tensor(37.9633), 150: tensor(41.6833), 160: tensor(47.1617), 170: tensor(49.1283), 180: tensor(48.8600), 190: tensor(48.1667), 200: tensor(44.9017), 210: tensor(39.8367), 220: tensor(37.9083), 230: tensor(40.5833), 240: tensor(47.0950), 250: tensor(59.4733), 260: tensor(68.0583), 270: tensor(76.4150), 280: tensor(75.6367), 290: tensor(69.4367), 300: tensor(61.9450), 310: tensor(61.7883), 320: tensor(68.6150), 330: tensor(81.9150), 340: tensor(93.8233), 350: tensor(97.6050)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=50, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1480,                   Accuracy: 483/2000.0 (24.15%)



-= Testing valid =-
Test set: Average loss: 2.3922,                   Accuracy: 593/2000.0 (29.65%)



-= Testing valid =-
Test set: Average loss: 0.4249,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.1600,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.3699,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.8661,                   Accuracy: 1394/2000.0 (69.70%)



-= Testing valid =-
Test set: Average loss: 0.6293,                   Accuracy: 1625/2000.0 (81.25%)



-= Testing valid =-
Test set: Average loss: 0.1875,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1036,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1484,                   Accuracy: 1911/2000.0 (95.55%)



Epoch 10 train accuracy: 97.62%, valid accuracy 95.55%
-= Testing valid =-
Test set: Average loss: 0.1500,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.3427,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.3159,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.1722,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.8920,                   Accuracy: 1485/2000.0 (74.25%)



-= Testing valid =-
Test set: Average loss: 0.2920,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.7859,                   Accuracy: 1592/2000.0 (79.60%)



-= Testing valid =-
Test set: Average loss: 0.2729,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.3563,                   Accuracy: 1747/2000.0 (87.35%)



-= Testing valid =-
Test set: Average loss: 0.2238,                   Accuracy: 1857/2000.0 (92.85%)



Epoch 20 train accuracy: 99.15%, valid accuracy 92.85%
-= Testing valid =-
Test set: Average loss: 0.2162,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.4227,                   Accuracy: 1752/2000.0 (87.60%)



-= Testing valid =-
Test set: Average loss: 0.3142,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.2150,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.4887,                   Accuracy: 1729/2000.0 (86.45%)



-= Testing valid =-
Test set: Average loss: 0.2569,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2310,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2465,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.4428,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.2487,                   Accuracy: 1843/2000.0 (92.15%)



Epoch 30 train accuracy: 99.45%, valid accuracy 92.15%
-= Testing valid =-
Test set: Average loss: 0.2265,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2276,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.3955,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.3128,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.4038,                   Accuracy: 1756/2000.0 (87.80%)



-= Testing valid =-
Test set: Average loss: 0.3953,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.4161,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.6269,                   Accuracy: 1681/2000.0 (84.05%)



-= Testing valid =-
Test set: Average loss: 0.2403,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.3973,                   Accuracy: 1765/2000.0 (88.25%)



Epoch 40 train accuracy: 99.68%, valid accuracy 88.25%
-= Testing valid =-
Test set: Average loss: 0.3452,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.1967,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.2362,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.3458,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.2779,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.3358,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.2490,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.3025,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.3798,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.2907,                   Accuracy: 1820/2000.0 (91.00%)



Epoch 50 train accuracy: 99.60%, valid accuracy 91.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1230,                   Accuracy: 57852/60000 (96.42%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2202,                   Accuracy: 56149/60000 (93.58%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.4988,                   Accuracy: 51580/60000 (85.97%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.8890,                   Accuracy: 45797/60000 (76.33%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3689,                   Accuracy: 38822/60000 (64.70%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.6674,                   Accuracy: 34509/60000 (57.51%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.5072,                   Accuracy: 36612/60000 (61.02%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.1997,                   Accuracy: 40442/60000 (67.40%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8514,                   Accuracy: 45002/60000 (75.00%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6496,                   Accuracy: 47830/60000 (79.72%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9398,                   Accuracy: 41432/60000 (69.05%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3742,                   Accuracy: 34250/60000 (57.08%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.8174,                   Accuracy: 28384/60000 (47.31%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.2334,                   Accuracy: 25111/60000 (41.85%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.5075,                   Accuracy: 24701/60000 (41.17%)
-= Testing Rotation 150 =-
Test set: Average loss: 2.6006,                   Accuracy: 26854/60000 (44.76%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.6027,                   Accuracy: 29809/60000 (49.68%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.6379,                   Accuracy: 31958/60000 (53.26%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.6821,                   Accuracy: 32590/60000 (54.32%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.7749,                   Accuracy: 30757/60000 (51.26%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.8952,                   Accuracy: 27678/60000 (46.13%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.9720,                   Accuracy: 25133/60000 (41.89%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.9085,                   Accuracy: 24660/60000 (41.10%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.5587,                   Accuracy: 27074/60000 (45.12%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9230,                   Accuracy: 32905/60000 (54.84%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3283,                   Accuracy: 39207/60000 (65.35%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8224,                   Accuracy: 45697/60000 (76.16%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5545,                   Accuracy: 50019/60000 (83.36%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7211,                   Accuracy: 45797/60000 (76.33%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8621,                   Accuracy: 43226/60000 (72.04%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0213,                   Accuracy: 39939/60000 (66.57%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1172,                   Accuracy: 38802/60000 (64.67%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0405,                   Accuracy: 40823/60000 (68.04%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6438,                   Accuracy: 48224/60000 (80.37%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3202,                   Accuracy: 54254/60000 (90.42%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1616,                   Accuracy: 57196/60000 (95.33%)
{0: tensor(96.4200), 10: tensor(93.5817), 20: tensor(85.9667), 30: tensor(76.3283), 40: tensor(64.7033), 50: tensor(57.5150), 60: tensor(61.0200), 70: tensor(67.4033), 80: tensor(75.0033), 90: tensor(79.7167), 100: tensor(69.0533), 110: tensor(57.0833), 120: tensor(47.3067), 130: tensor(41.8517), 140: tensor(41.1683), 150: tensor(44.7567), 160: tensor(49.6817), 170: tensor(53.2633), 180: tensor(54.3167), 190: tensor(51.2617), 200: tensor(46.1300), 210: tensor(41.8883), 220: tensor(41.1000), 230: tensor(45.1233), 240: tensor(54.8417), 250: tensor(65.3450), 260: tensor(76.1617), 270: tensor(83.3650), 280: tensor(76.3283), 290: tensor(72.0433), 300: tensor(66.5650), 310: tensor(64.6700), 320: tensor(68.0383), 330: tensor(80.3733), 340: tensor(90.4233), 350: tensor(95.3267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=51, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1536,                   Accuracy: 457/2000.0 (22.85%)



-= Testing valid =-
Test set: Average loss: 1.2861,                   Accuracy: 1141/2000.0 (57.05%)



-= Testing valid =-
Test set: Average loss: 0.3532,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2113,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.3015,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.1601,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.1140,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1479,                   Accuracy: 1916/2000.0 (95.80%)



Epoch 10 train accuracy: 98.11%, valid accuracy 95.80%
-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0469,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0602,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 20 train accuracy: 99.30%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.62%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 40 train accuracy: 99.60%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 50 train accuracy: 99.70%, valid accuracy 98.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0572,                   Accuracy: 59028/60000 (98.38%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0830,                   Accuracy: 58597/60000 (97.66%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1738,                   Accuracy: 57122/60000 (95.20%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4305,                   Accuracy: 52773/60000 (87.96%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7954,                   Accuracy: 46071/60000 (76.79%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0460,                   Accuracy: 41249/60000 (68.75%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0508,                   Accuracy: 40429/60000 (67.38%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9463,                   Accuracy: 41716/60000 (69.53%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.9272,                   Accuracy: 42041/60000 (70.07%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.9517,                   Accuracy: 42035/60000 (70.06%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.5180,                   Accuracy: 35739/60000 (59.56%)
-= Testing Rotation 110 =-
Test set: Average loss: 2.4391,                   Accuracy: 29602/60000 (49.34%)
-= Testing Rotation 120 =-
Test set: Average loss: 3.5840,                   Accuracy: 23032/60000 (38.39%)
-= Testing Rotation 130 =-
Test set: Average loss: 4.3885,                   Accuracy: 20229/60000 (33.72%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.7165,                   Accuracy: 20361/60000 (33.94%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.7466,                   Accuracy: 22375/60000 (37.29%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.5303,                   Accuracy: 26167/60000 (43.61%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.5182,                   Accuracy: 28244/60000 (47.07%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.4501,                   Accuracy: 29333/60000 (48.89%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.5798,                   Accuracy: 28822/60000 (48.04%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.6237,                   Accuracy: 27128/60000 (45.21%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.5590,                   Accuracy: 25156/60000 (41.93%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.0739,                   Accuracy: 24533/60000 (40.89%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1220,                   Accuracy: 27159/60000 (45.26%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0146,                   Accuracy: 33836/60000 (56.39%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1100,                   Accuracy: 42325/60000 (70.54%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6983,                   Accuracy: 47501/60000 (79.17%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5463,                   Accuracy: 50007/60000 (83.35%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7615,                   Accuracy: 46087/60000 (76.81%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0502,                   Accuracy: 41960/60000 (69.93%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.5188,                   Accuracy: 37193/60000 (61.99%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.6549,                   Accuracy: 35973/60000 (59.96%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3599,                   Accuracy: 40081/60000 (66.80%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7759,                   Accuracy: 47436/60000 (79.06%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2471,                   Accuracy: 55553/60000 (92.59%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0888,                   Accuracy: 58446/60000 (97.41%)
{0: tensor(98.3800), 10: tensor(97.6617), 20: tensor(95.2033), 30: tensor(87.9550), 40: tensor(76.7850), 50: tensor(68.7483), 60: tensor(67.3817), 70: tensor(69.5267), 80: tensor(70.0683), 90: tensor(70.0583), 100: tensor(59.5650), 110: tensor(49.3367), 120: tensor(38.3867), 130: tensor(33.7150), 140: tensor(33.9350), 150: tensor(37.2917), 160: tensor(43.6117), 170: tensor(47.0733), 180: tensor(48.8883), 190: tensor(48.0367), 200: tensor(45.2133), 210: tensor(41.9267), 220: tensor(40.8883), 230: tensor(45.2650), 240: tensor(56.3933), 250: tensor(70.5417), 260: tensor(79.1683), 270: tensor(83.3450), 280: tensor(76.8117), 290: tensor(69.9333), 300: tensor(61.9883), 310: tensor(59.9550), 320: tensor(66.8017), 330: tensor(79.0600), 340: tensor(92.5883), 350: tensor(97.4100)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=52, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3285,                   Accuracy: 577/2000.0 (28.85%)



-= Testing valid =-
Test set: Average loss: 1.0724,                   Accuracy: 1188/2000.0 (59.40%)



-= Testing valid =-
Test set: Average loss: 0.4330,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.2479,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.4674,                   Accuracy: 1696/2000.0 (84.80%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1492,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 10 train accuracy: 97.80%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0600,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0712,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 20 train accuracy: 99.03%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0492,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0469,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 30 train accuracy: 99.45%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0469,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 40 train accuracy: 99.56%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0445,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0428,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 50 train accuracy: 99.62%, valid accuracy 98.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0491,                   Accuracy: 59155/60000 (98.59%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0671,                   Accuracy: 58835/60000 (98.06%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1375,                   Accuracy: 57546/60000 (95.91%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3887,                   Accuracy: 53174/60000 (88.62%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7361,                   Accuracy: 46967/60000 (78.28%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0407,                   Accuracy: 41560/60000 (69.27%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9286,                   Accuracy: 42993/60000 (71.65%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6368,                   Accuracy: 47683/60000 (79.47%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5054,                   Accuracy: 50014/60000 (83.36%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5081,                   Accuracy: 49827/60000 (83.04%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6337,                   Accuracy: 47198/60000 (78.66%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1879,                   Accuracy: 39894/60000 (66.49%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.9938,                   Accuracy: 32581/60000 (54.30%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.7614,                   Accuracy: 27058/60000 (45.10%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.0727,                   Accuracy: 24771/60000 (41.28%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.0648,                   Accuracy: 26389/60000 (43.98%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.6434,                   Accuracy: 29587/60000 (49.31%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.6936,                   Accuracy: 32184/60000 (53.64%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.9057,                   Accuracy: 33379/60000 (55.63%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.7772,                   Accuracy: 33185/60000 (55.31%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.9733,                   Accuracy: 30802/60000 (51.34%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.3966,                   Accuracy: 27270/60000 (45.45%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.3922,                   Accuracy: 25077/60000 (41.79%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8867,                   Accuracy: 25968/60000 (43.28%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0520,                   Accuracy: 31388/60000 (52.31%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0978,                   Accuracy: 40572/60000 (67.62%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5615,                   Accuracy: 48287/60000 (80.48%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3539,                   Accuracy: 52495/60000 (87.49%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4062,                   Accuracy: 51884/60000 (86.47%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.5764,                   Accuracy: 48991/60000 (81.65%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9571,                   Accuracy: 43067/60000 (71.78%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2008,                   Accuracy: 39717/60000 (66.19%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1778,                   Accuracy: 40800/60000 (68.00%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6953,                   Accuracy: 47842/60000 (79.74%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2640,                   Accuracy: 54987/60000 (91.64%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0973,                   Accuracy: 58220/60000 (97.03%)
{0: tensor(98.5917), 10: tensor(98.0583), 20: tensor(95.9100), 30: tensor(88.6233), 40: tensor(78.2783), 50: tensor(69.2667), 60: tensor(71.6550), 70: tensor(79.4717), 80: tensor(83.3567), 90: tensor(83.0450), 100: tensor(78.6633), 110: tensor(66.4900), 120: tensor(54.3017), 130: tensor(45.0967), 140: tensor(41.2850), 150: tensor(43.9817), 160: tensor(49.3117), 170: tensor(53.6400), 180: tensor(55.6317), 190: tensor(55.3083), 200: tensor(51.3367), 210: tensor(45.4500), 220: tensor(41.7950), 230: tensor(43.2800), 240: tensor(52.3133), 250: tensor(67.6200), 260: tensor(80.4783), 270: tensor(87.4917), 280: tensor(86.4733), 290: tensor(81.6517), 300: tensor(71.7783), 310: tensor(66.1950), 320: tensor(68.), 330: tensor(79.7367), 340: tensor(91.6450), 350: tensor(97.0333)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=53, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.9471,                   Accuracy: 402/2000.0 (20.10%)



-= Testing valid =-
Test set: Average loss: 1.2416,                   Accuracy: 1097/2000.0 (54.85%)



-= Testing valid =-
Test set: Average loss: 0.3679,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2053,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.5468,                   Accuracy: 1707/2000.0 (85.35%)



-= Testing valid =-
Test set: Average loss: 0.1569,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.2556,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2018,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1106,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1072,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 10 train accuracy: 97.94%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0709,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0497,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0477,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 20 train accuracy: 99.18%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0454,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.35%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 40 train accuracy: 99.56%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 50 train accuracy: 99.76%, valid accuracy 98.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0487,                   Accuracy: 59151/60000 (98.58%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0863,                   Accuracy: 58500/60000 (97.50%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1824,                   Accuracy: 56923/60000 (94.87%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4744,                   Accuracy: 52305/60000 (87.18%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9168,                   Accuracy: 45086/60000 (75.14%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2381,                   Accuracy: 40029/60000 (66.71%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1486,                   Accuracy: 40598/60000 (67.66%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7942,                   Accuracy: 45319/60000 (75.53%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6479,                   Accuracy: 46833/60000 (78.06%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5759,                   Accuracy: 47878/60000 (79.80%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7721,                   Accuracy: 44881/60000 (74.80%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1738,                   Accuracy: 39814/60000 (66.36%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0162,                   Accuracy: 30696/60000 (51.16%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.6448,                   Accuracy: 24775/60000 (41.29%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.0684,                   Accuracy: 22561/60000 (37.60%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.1162,                   Accuracy: 23879/60000 (39.80%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.8928,                   Accuracy: 27680/60000 (46.13%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.1044,                   Accuracy: 29220/60000 (48.70%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.1448,                   Accuracy: 30946/60000 (51.58%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.1934,                   Accuracy: 30353/60000 (50.59%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.2543,                   Accuracy: 29131/60000 (48.55%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.5288,                   Accuracy: 26254/60000 (43.76%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.3159,                   Accuracy: 24360/60000 (40.60%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8157,                   Accuracy: 26246/60000 (43.74%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9287,                   Accuracy: 33491/60000 (55.82%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1099,                   Accuracy: 42230/60000 (70.38%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6577,                   Accuracy: 48453/60000 (80.75%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3531,                   Accuracy: 53626/60000 (89.38%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4431,                   Accuracy: 51813/60000 (86.36%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.5769,                   Accuracy: 49293/60000 (82.15%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.8749,                   Accuracy: 44370/60000 (73.95%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0459,                   Accuracy: 41725/60000 (69.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9787,                   Accuracy: 43624/60000 (72.71%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5434,                   Accuracy: 50405/60000 (84.01%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1739,                   Accuracy: 56730/60000 (94.55%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0770,                   Accuracy: 58553/60000 (97.59%)
{0: tensor(98.5850), 10: tensor(97.5000), 20: tensor(94.8717), 30: tensor(87.1750), 40: tensor(75.1433), 50: tensor(66.7150), 60: tensor(67.6633), 70: tensor(75.5317), 80: tensor(78.0550), 90: tensor(79.7967), 100: tensor(74.8017), 110: tensor(66.3567), 120: tensor(51.1600), 130: tensor(41.2917), 140: tensor(37.6017), 150: tensor(39.7983), 160: tensor(46.1333), 170: tensor(48.7000), 180: tensor(51.5767), 190: tensor(50.5883), 200: tensor(48.5517), 210: tensor(43.7567), 220: tensor(40.6000), 230: tensor(43.7433), 240: tensor(55.8183), 250: tensor(70.3833), 260: tensor(80.7550), 270: tensor(89.3767), 280: tensor(86.3550), 290: tensor(82.1550), 300: tensor(73.9500), 310: tensor(69.5417), 320: tensor(72.7067), 330: tensor(84.0083), 340: tensor(94.5500), 350: tensor(97.5883)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=54, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.6225,                   Accuracy: 691/2000.0 (34.55%)



-= Testing valid =-
Test set: Average loss: 1.1810,                   Accuracy: 1263/2000.0 (63.15%)



-= Testing valid =-
Test set: Average loss: 0.3556,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.2570,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2399,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 10 train accuracy: 98.36%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0628,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.1223,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0529,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0798,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 20 train accuracy: 99.19%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.68%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 40 train accuracy: 99.69%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 50 train accuracy: 99.78%, valid accuracy 98.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0462,                   Accuracy: 59224/60000 (98.71%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0891,                   Accuracy: 58503/60000 (97.50%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2075,                   Accuracy: 56525/60000 (94.21%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5735,                   Accuracy: 50839/60000 (84.73%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0853,                   Accuracy: 42880/60000 (71.47%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.3819,                   Accuracy: 37817/60000 (63.03%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.3181,                   Accuracy: 37524/60000 (62.54%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9076,                   Accuracy: 43327/60000 (72.21%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6884,                   Accuracy: 47317/60000 (78.86%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5433,                   Accuracy: 50167/60000 (83.61%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9848,                   Accuracy: 43169/60000 (71.95%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.7789,                   Accuracy: 35589/60000 (59.31%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.9205,                   Accuracy: 28127/60000 (46.88%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.9495,                   Accuracy: 23480/60000 (39.13%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.4301,                   Accuracy: 22514/60000 (37.52%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.4647,                   Accuracy: 22887/60000 (38.15%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.1765,                   Accuracy: 25304/60000 (42.17%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.0303,                   Accuracy: 27332/60000 (45.55%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.7495,                   Accuracy: 28873/60000 (48.12%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.8308,                   Accuracy: 29240/60000 (48.73%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.0703,                   Accuracy: 27222/60000 (45.37%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.2592,                   Accuracy: 24284/60000 (40.47%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.0488,                   Accuracy: 23085/60000 (38.47%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.3153,                   Accuracy: 25415/60000 (42.36%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3178,                   Accuracy: 31180/60000 (51.97%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3381,                   Accuracy: 39727/60000 (66.21%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7855,                   Accuracy: 45804/60000 (76.34%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4842,                   Accuracy: 51196/60000 (85.33%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7063,                   Accuracy: 47079/60000 (78.46%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.1218,                   Accuracy: 40567/60000 (67.61%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.6395,                   Accuracy: 34898/60000 (58.16%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.9569,                   Accuracy: 32478/60000 (54.13%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.7786,                   Accuracy: 36544/60000 (60.91%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.0577,                   Accuracy: 45216/60000 (75.36%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3497,                   Accuracy: 54208/60000 (90.35%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1094,                   Accuracy: 58049/60000 (96.75%)
{0: tensor(98.7067), 10: tensor(97.5050), 20: tensor(94.2083), 30: tensor(84.7317), 40: tensor(71.4667), 50: tensor(63.0283), 60: tensor(62.5400), 70: tensor(72.2117), 80: tensor(78.8617), 90: tensor(83.6117), 100: tensor(71.9483), 110: tensor(59.3150), 120: tensor(46.8783), 130: tensor(39.1333), 140: tensor(37.5233), 150: tensor(38.1450), 160: tensor(42.1733), 170: tensor(45.5533), 180: tensor(48.1217), 190: tensor(48.7333), 200: tensor(45.3700), 210: tensor(40.4733), 220: tensor(38.4750), 230: tensor(42.3583), 240: tensor(51.9667), 250: tensor(66.2117), 260: tensor(76.3400), 270: tensor(85.3267), 280: tensor(78.4650), 290: tensor(67.6117), 300: tensor(58.1633), 310: tensor(54.1300), 320: tensor(60.9067), 330: tensor(75.3600), 340: tensor(90.3467), 350: tensor(96.7483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=55, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7711,                   Accuracy: 715/2000.0 (35.75%)



-= Testing valid =-
Test set: Average loss: 1.3683,                   Accuracy: 950/2000.0 (47.50%)



-= Testing valid =-
Test set: Average loss: 0.6820,                   Accuracy: 1588/2000.0 (79.40%)



-= Testing valid =-
Test set: Average loss: 0.1384,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.4866,                   Accuracy: 1674/2000.0 (83.70%)



-= Testing valid =-
Test set: Average loss: 0.1583,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.1268,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 10 train accuracy: 98.44%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0590,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0477,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 20 train accuracy: 98.93%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.66%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.68%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 50 train accuracy: 99.84%, valid accuracy 99.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0572,                   Accuracy: 59023/60000 (98.37%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0906,                   Accuracy: 58491/60000 (97.49%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1963,                   Accuracy: 56755/60000 (94.59%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4348,                   Accuracy: 52471/60000 (87.45%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7344,                   Accuracy: 47342/60000 (78.90%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8804,                   Accuracy: 44592/60000 (74.32%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8992,                   Accuracy: 44142/60000 (73.57%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7683,                   Accuracy: 46207/60000 (77.01%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6709,                   Accuracy: 47443/60000 (79.07%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7311,                   Accuracy: 46730/60000 (77.88%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0139,                   Accuracy: 42256/60000 (70.43%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6546,                   Accuracy: 34881/60000 (58.13%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5516,                   Accuracy: 27511/60000 (45.85%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.0978,                   Accuracy: 25253/60000 (42.09%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.5511,                   Accuracy: 24809/60000 (41.35%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.9295,                   Accuracy: 25760/60000 (42.93%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.1168,                   Accuracy: 28203/60000 (47.01%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.1707,                   Accuracy: 29885/60000 (49.81%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.3120,                   Accuracy: 30362/60000 (50.60%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.2771,                   Accuracy: 29276/60000 (48.79%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.4335,                   Accuracy: 27308/60000 (45.51%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.4564,                   Accuracy: 25347/60000 (42.24%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.1481,                   Accuracy: 24588/60000 (40.98%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.5441,                   Accuracy: 25761/60000 (42.94%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.8195,                   Accuracy: 28387/60000 (47.31%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.0524,                   Accuracy: 32919/60000 (54.87%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.4313,                   Accuracy: 37396/60000 (62.33%)
-= Testing Rotation 270 =-
Test set: Average loss: 1.0842,                   Accuracy: 40582/60000 (67.64%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.1688,                   Accuracy: 38851/60000 (64.75%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.2325,                   Accuracy: 37226/60000 (62.04%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3958,                   Accuracy: 35333/60000 (58.89%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3104,                   Accuracy: 37025/60000 (61.71%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0275,                   Accuracy: 41722/60000 (69.54%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5726,                   Accuracy: 49304/60000 (82.17%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2120,                   Accuracy: 55986/60000 (93.31%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0839,                   Accuracy: 58483/60000 (97.47%)
{0: tensor(98.3717), 10: tensor(97.4850), 20: tensor(94.5917), 30: tensor(87.4517), 40: tensor(78.9033), 50: tensor(74.3200), 60: tensor(73.5700), 70: tensor(77.0117), 80: tensor(79.0717), 90: tensor(77.8833), 100: tensor(70.4267), 110: tensor(58.1350), 120: tensor(45.8517), 130: tensor(42.0883), 140: tensor(41.3483), 150: tensor(42.9333), 160: tensor(47.0050), 170: tensor(49.8083), 180: tensor(50.6033), 190: tensor(48.7933), 200: tensor(45.5133), 210: tensor(42.2450), 220: tensor(40.9800), 230: tensor(42.9350), 240: tensor(47.3117), 250: tensor(54.8650), 260: tensor(62.3267), 270: tensor(67.6367), 280: tensor(64.7517), 290: tensor(62.0433), 300: tensor(58.8883), 310: tensor(61.7083), 320: tensor(69.5367), 330: tensor(82.1733), 340: tensor(93.3100), 350: tensor(97.4717)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=56, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.6753,                   Accuracy: 671/2000.0 (33.55%)



-= Testing valid =-
Test set: Average loss: 0.7713,                   Accuracy: 1508/2000.0 (75.40%)



-= Testing valid =-
Test set: Average loss: 0.6952,                   Accuracy: 1542/2000.0 (77.10%)



-= Testing valid =-
Test set: Average loss: 0.2724,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1742,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0618,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 10 train accuracy: 98.32%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 20 train accuracy: 99.15%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 30 train accuracy: 99.56%, valid accuracy 99.30%
-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0223,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 40 train accuracy: 99.72%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 50 train accuracy: 99.78%, valid accuracy 99.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0422,                   Accuracy: 59236/60000 (98.73%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0707,                   Accuracy: 58738/60000 (97.90%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1539,                   Accuracy: 57316/60000 (95.53%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3940,                   Accuracy: 53198/60000 (88.66%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7894,                   Accuracy: 46779/60000 (77.96%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0352,                   Accuracy: 42424/60000 (70.71%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0427,                   Accuracy: 41358/60000 (68.93%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9180,                   Accuracy: 42434/60000 (70.72%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8225,                   Accuracy: 42948/60000 (71.58%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7905,                   Accuracy: 42989/60000 (71.65%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0832,                   Accuracy: 38693/60000 (64.49%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5972,                   Accuracy: 33666/60000 (56.11%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5099,                   Accuracy: 25656/60000 (42.76%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.3167,                   Accuracy: 22068/60000 (36.78%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.6025,                   Accuracy: 20992/60000 (34.99%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.5894,                   Accuracy: 22786/60000 (37.98%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4558,                   Accuracy: 25523/60000 (42.54%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5780,                   Accuracy: 26632/60000 (44.39%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.5615,                   Accuracy: 27526/60000 (45.88%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.5726,                   Accuracy: 27395/60000 (45.66%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.8157,                   Accuracy: 25915/60000 (43.19%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.0495,                   Accuracy: 23863/60000 (39.77%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.9354,                   Accuracy: 23136/60000 (38.56%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2592,                   Accuracy: 25643/60000 (42.74%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2279,                   Accuracy: 31804/60000 (53.01%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3454,                   Accuracy: 39334/60000 (65.56%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7535,                   Accuracy: 46803/60000 (78.00%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4085,                   Accuracy: 52653/60000 (87.75%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4942,                   Accuracy: 50907/60000 (84.85%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6325,                   Accuracy: 48024/60000 (80.04%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9131,                   Accuracy: 43578/60000 (72.63%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0877,                   Accuracy: 41214/60000 (68.69%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0007,                   Accuracy: 42845/60000 (71.41%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5585,                   Accuracy: 49790/60000 (82.98%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1980,                   Accuracy: 56151/60000 (93.58%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0749,                   Accuracy: 58575/60000 (97.62%)
{0: tensor(98.7267), 10: tensor(97.8967), 20: tensor(95.5267), 30: tensor(88.6633), 40: tensor(77.9650), 50: tensor(70.7067), 60: tensor(68.9300), 70: tensor(70.7233), 80: tensor(71.5800), 90: tensor(71.6483), 100: tensor(64.4883), 110: tensor(56.1100), 120: tensor(42.7600), 130: tensor(36.7800), 140: tensor(34.9867), 150: tensor(37.9767), 160: tensor(42.5383), 170: tensor(44.3867), 180: tensor(45.8767), 190: tensor(45.6583), 200: tensor(43.1917), 210: tensor(39.7717), 220: tensor(38.5600), 230: tensor(42.7383), 240: tensor(53.0067), 250: tensor(65.5567), 260: tensor(78.0050), 270: tensor(87.7550), 280: tensor(84.8450), 290: tensor(80.0400), 300: tensor(72.6300), 310: tensor(68.6900), 320: tensor(71.4083), 330: tensor(82.9833), 340: tensor(93.5850), 350: tensor(97.6250)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=57, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.7062,                   Accuracy: 405/2000.0 (20.25%)



-= Testing valid =-
Test set: Average loss: 1.8908,                   Accuracy: 559/2000.0 (27.95%)



-= Testing valid =-
Test set: Average loss: 1.3306,                   Accuracy: 1201/2000.0 (60.05%)



-= Testing valid =-
Test set: Average loss: 0.8921,                   Accuracy: 1403/2000.0 (70.15%)



-= Testing valid =-
Test set: Average loss: 0.5288,                   Accuracy: 1650/2000.0 (82.50%)



-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 10 train accuracy: 98.11%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0454,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0492,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 20 train accuracy: 98.96%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 30 train accuracy: 99.55%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0219,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0218,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0208,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 40 train accuracy: 99.57%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0217,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0220,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0226,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0221,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.78%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0437,                   Accuracy: 59218/60000 (98.70%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0747,                   Accuracy: 58665/60000 (97.78%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1920,                   Accuracy: 56753/60000 (94.59%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4934,                   Accuracy: 51810/60000 (86.35%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9412,                   Accuracy: 44654/60000 (74.42%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2017,                   Accuracy: 39987/60000 (66.64%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1457,                   Accuracy: 40355/60000 (67.26%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9882,                   Accuracy: 42292/60000 (70.49%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.9993,                   Accuracy: 42910/60000 (71.52%)
-= Testing Rotation 90 =-
Test set: Average loss: 1.1648,                   Accuracy: 42276/60000 (70.46%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.6290,                   Accuracy: 38315/60000 (63.86%)
-= Testing Rotation 110 =-
Test set: Average loss: 2.3825,                   Accuracy: 33259/60000 (55.43%)
-= Testing Rotation 120 =-
Test set: Average loss: 3.4668,                   Accuracy: 27446/60000 (45.74%)
-= Testing Rotation 130 =-
Test set: Average loss: 4.2136,                   Accuracy: 24206/60000 (40.34%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.5275,                   Accuracy: 24332/60000 (40.55%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.5080,                   Accuracy: 26375/60000 (43.96%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.3818,                   Accuracy: 29144/60000 (48.57%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.5293,                   Accuracy: 30713/60000 (51.19%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.7842,                   Accuracy: 30474/60000 (50.79%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.8016,                   Accuracy: 29199/60000 (48.67%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.9574,                   Accuracy: 26647/60000 (44.41%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.9984,                   Accuracy: 24300/60000 (40.50%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.6156,                   Accuracy: 22938/60000 (38.23%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.8283,                   Accuracy: 25135/60000 (41.89%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.6949,                   Accuracy: 30870/60000 (51.45%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.5329,                   Accuracy: 38771/60000 (64.62%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8744,                   Accuracy: 44385/60000 (73.97%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6360,                   Accuracy: 47057/60000 (78.43%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.8311,                   Accuracy: 43931/60000 (73.22%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.1819,                   Accuracy: 40394/60000 (67.32%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.5312,                   Accuracy: 37743/60000 (62.90%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.7396,                   Accuracy: 36677/60000 (61.13%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.5129,                   Accuracy: 40252/60000 (67.09%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8726,                   Accuracy: 48115/60000 (80.19%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2792,                   Accuracy: 55422/60000 (92.37%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0793,                   Accuracy: 58544/60000 (97.57%)
{0: tensor(98.6967), 10: tensor(97.7750), 20: tensor(94.5883), 30: tensor(86.3500), 40: tensor(74.4233), 50: tensor(66.6450), 60: tensor(67.2583), 70: tensor(70.4867), 80: tensor(71.5167), 90: tensor(70.4600), 100: tensor(63.8583), 110: tensor(55.4317), 120: tensor(45.7433), 130: tensor(40.3433), 140: tensor(40.5533), 150: tensor(43.9583), 160: tensor(48.5733), 170: tensor(51.1883), 180: tensor(50.7900), 190: tensor(48.6650), 200: tensor(44.4117), 210: tensor(40.5000), 220: tensor(38.2300), 230: tensor(41.8917), 240: tensor(51.4500), 250: tensor(64.6183), 260: tensor(73.9750), 270: tensor(78.4283), 280: tensor(73.2183), 290: tensor(67.3233), 300: tensor(62.9050), 310: tensor(61.1283), 320: tensor(67.0867), 330: tensor(80.1917), 340: tensor(92.3700), 350: tensor(97.5733)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=58, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0937,                   Accuracy: 335/2000.0 (16.75%)



-= Testing valid =-
Test set: Average loss: 3.7343,                   Accuracy: 285/2000.0 (14.25%)



-= Testing valid =-
Test set: Average loss: 0.7785,                   Accuracy: 1500/2000.0 (75.00%)



-= Testing valid =-
Test set: Average loss: 0.3638,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.3755,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.1155,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1539,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1223,                   Accuracy: 1928/2000.0 (96.40%)



Epoch 10 train accuracy: 98.18%, valid accuracy 96.40%
-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0600,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.1428,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.1534,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 20 train accuracy: 98.85%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 30 train accuracy: 99.45%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 40 train accuracy: 99.69%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.57%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0553,                   Accuracy: 59057/60000 (98.43%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0909,                   Accuracy: 58457/60000 (97.43%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2199,                   Accuracy: 56340/60000 (93.90%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5498,                   Accuracy: 50956/60000 (84.93%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9968,                   Accuracy: 43495/60000 (72.49%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2861,                   Accuracy: 38485/60000 (64.14%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2486,                   Accuracy: 37774/60000 (62.96%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.0223,                   Accuracy: 40704/60000 (67.84%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8576,                   Accuracy: 42912/60000 (71.52%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7475,                   Accuracy: 45067/60000 (75.11%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0795,                   Accuracy: 39460/60000 (65.77%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6751,                   Accuracy: 33185/60000 (55.31%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5319,                   Accuracy: 27310/60000 (45.52%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.1489,                   Accuracy: 24502/60000 (40.84%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3647,                   Accuracy: 24146/60000 (40.24%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.3616,                   Accuracy: 26025/60000 (43.38%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.2397,                   Accuracy: 29279/60000 (48.80%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.3588,                   Accuracy: 30884/60000 (51.47%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.4444,                   Accuracy: 31299/60000 (52.17%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.6602,                   Accuracy: 30370/60000 (50.62%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.9543,                   Accuracy: 28376/60000 (47.29%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.1611,                   Accuracy: 25130/60000 (41.88%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.8564,                   Accuracy: 24227/60000 (40.38%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.0789,                   Accuracy: 27080/60000 (45.13%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0435,                   Accuracy: 33317/60000 (55.53%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2013,                   Accuracy: 41139/60000 (68.57%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6718,                   Accuracy: 47767/60000 (79.61%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4658,                   Accuracy: 50783/60000 (84.64%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6044,                   Accuracy: 48424/60000 (80.71%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8371,                   Accuracy: 44548/60000 (74.25%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1955,                   Accuracy: 39531/60000 (65.89%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2998,                   Accuracy: 37496/60000 (62.49%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0949,                   Accuracy: 41429/60000 (69.05%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6129,                   Accuracy: 49048/60000 (81.75%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2395,                   Accuracy: 55613/60000 (92.69%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0980,                   Accuracy: 58275/60000 (97.12%)
{0: tensor(98.4283), 10: tensor(97.4283), 20: tensor(93.9000), 30: tensor(84.9267), 40: tensor(72.4917), 50: tensor(64.1417), 60: tensor(62.9567), 70: tensor(67.8400), 80: tensor(71.5200), 90: tensor(75.1117), 100: tensor(65.7667), 110: tensor(55.3083), 120: tensor(45.5167), 130: tensor(40.8367), 140: tensor(40.2433), 150: tensor(43.3750), 160: tensor(48.7983), 170: tensor(51.4733), 180: tensor(52.1650), 190: tensor(50.6167), 200: tensor(47.2933), 210: tensor(41.8833), 220: tensor(40.3783), 230: tensor(45.1333), 240: tensor(55.5283), 250: tensor(68.5650), 260: tensor(79.6117), 270: tensor(84.6383), 280: tensor(80.7067), 290: tensor(74.2467), 300: tensor(65.8850), 310: tensor(62.4933), 320: tensor(69.0483), 330: tensor(81.7467), 340: tensor(92.6883), 350: tensor(97.1250)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=59, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7494,                   Accuracy: 810/2000.0 (40.50%)



-= Testing valid =-
Test set: Average loss: 1.5694,                   Accuracy: 837/2000.0 (41.85%)



-= Testing valid =-
Test set: Average loss: 0.5009,                   Accuracy: 1700/2000.0 (85.00%)



-= Testing valid =-
Test set: Average loss: 0.1878,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1246,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1260,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1302,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 10 train accuracy: 98.12%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0596,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0659,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0597,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 20 train accuracy: 99.21%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0511,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0552,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.56%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 40 train accuracy: 99.69%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0486,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0519,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0497,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.74%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0522,                   Accuracy: 59063/60000 (98.44%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0864,                   Accuracy: 58459/60000 (97.43%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1987,                   Accuracy: 56490/60000 (94.15%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4838,                   Accuracy: 51361/60000 (85.60%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9268,                   Accuracy: 43487/60000 (72.48%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2017,                   Accuracy: 38455/60000 (64.09%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1053,                   Accuracy: 39572/60000 (65.95%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7621,                   Accuracy: 45141/60000 (75.24%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5747,                   Accuracy: 47777/60000 (79.63%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5649,                   Accuracy: 47332/60000 (78.89%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7769,                   Accuracy: 43551/60000 (72.58%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3578,                   Accuracy: 35947/60000 (59.91%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2021,                   Accuracy: 28431/60000 (47.38%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8910,                   Accuracy: 23994/60000 (39.99%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.2327,                   Accuracy: 23454/60000 (39.09%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.2267,                   Accuracy: 25361/60000 (42.27%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.0981,                   Accuracy: 28402/60000 (47.34%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.9988,                   Accuracy: 30747/60000 (51.24%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.0502,                   Accuracy: 31430/60000 (52.38%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.1685,                   Accuracy: 29543/60000 (49.24%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.5014,                   Accuracy: 26039/60000 (43.40%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7771,                   Accuracy: 23085/60000 (38.47%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6602,                   Accuracy: 22271/60000 (37.12%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.0802,                   Accuracy: 24826/60000 (41.38%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.1101,                   Accuracy: 31803/60000 (53.01%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1870,                   Accuracy: 40528/60000 (67.55%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6784,                   Accuracy: 47339/60000 (78.90%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4654,                   Accuracy: 50793/60000 (84.65%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5930,                   Accuracy: 48191/60000 (80.32%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8358,                   Accuracy: 43989/60000 (73.32%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1796,                   Accuracy: 38908/60000 (64.85%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2870,                   Accuracy: 38642/60000 (64.40%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1050,                   Accuracy: 42582/60000 (70.97%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6231,                   Accuracy: 50023/60000 (83.37%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2132,                   Accuracy: 56374/60000 (93.96%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0808,                   Accuracy: 58547/60000 (97.58%)
{0: tensor(98.4383), 10: tensor(97.4317), 20: tensor(94.1500), 30: tensor(85.6017), 40: tensor(72.4783), 50: tensor(64.0917), 60: tensor(65.9533), 70: tensor(75.2350), 80: tensor(79.6283), 90: tensor(78.8867), 100: tensor(72.5850), 110: tensor(59.9117), 120: tensor(47.3850), 130: tensor(39.9900), 140: tensor(39.0900), 150: tensor(42.2683), 160: tensor(47.3367), 170: tensor(51.2450), 180: tensor(52.3833), 190: tensor(49.2383), 200: tensor(43.3983), 210: tensor(38.4750), 220: tensor(37.1183), 230: tensor(41.3767), 240: tensor(53.0050), 250: tensor(67.5467), 260: tensor(78.8983), 270: tensor(84.6550), 280: tensor(80.3183), 290: tensor(73.3150), 300: tensor(64.8467), 310: tensor(64.4033), 320: tensor(70.9700), 330: tensor(83.3717), 340: tensor(93.9567), 350: tensor(97.5783)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=60, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.7210,                   Accuracy: 358/2000.0 (17.90%)



-= Testing valid =-
Test set: Average loss: 3.3513,                   Accuracy: 418/2000.0 (20.90%)



-= Testing valid =-
Test set: Average loss: 1.2538,                   Accuracy: 1014/2000.0 (50.70%)



-= Testing valid =-
Test set: Average loss: 0.4821,                   Accuracy: 1684/2000.0 (84.20%)



-= Testing valid =-
Test set: Average loss: 0.4450,                   Accuracy: 1632/2000.0 (81.60%)



-= Testing valid =-
Test set: Average loss: 0.1845,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.4800,                   Accuracy: 1660/2000.0 (83.00%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.2174,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 10 train accuracy: 97.99%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0575,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1120,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0630,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 20 train accuracy: 99.15%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0547,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0535,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 30 train accuracy: 99.34%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 40 train accuracy: 99.45%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 50 train accuracy: 99.66%, valid accuracy 98.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0536,                   Accuracy: 59075/60000 (98.46%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0804,                   Accuracy: 58585/60000 (97.64%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1691,                   Accuracy: 57032/60000 (95.05%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4948,                   Accuracy: 51219/60000 (85.36%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9109,                   Accuracy: 43673/60000 (72.79%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1651,                   Accuracy: 38806/60000 (64.68%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0761,                   Accuracy: 40151/60000 (66.92%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7364,                   Accuracy: 45792/60000 (76.32%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5915,                   Accuracy: 48262/60000 (80.44%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5783,                   Accuracy: 48935/60000 (81.56%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8466,                   Accuracy: 44309/60000 (73.85%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.4715,                   Accuracy: 37044/60000 (61.74%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.4600,                   Accuracy: 29121/60000 (48.53%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.3824,                   Accuracy: 23710/60000 (39.52%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.9621,                   Accuracy: 22379/60000 (37.30%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.2224,                   Accuracy: 23852/60000 (39.75%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.0051,                   Accuracy: 27255/60000 (45.42%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.8949,                   Accuracy: 28777/60000 (47.96%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.6881,                   Accuracy: 28942/60000 (48.24%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.5435,                   Accuracy: 29434/60000 (49.06%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.5776,                   Accuracy: 27551/60000 (45.92%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7255,                   Accuracy: 24576/60000 (40.96%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6089,                   Accuracy: 23739/60000 (39.56%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1170,                   Accuracy: 25707/60000 (42.85%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2845,                   Accuracy: 31235/60000 (52.06%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3751,                   Accuracy: 39360/60000 (65.60%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8376,                   Accuracy: 44118/60000 (73.53%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5281,                   Accuracy: 48860/60000 (81.43%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7102,                   Accuracy: 45674/60000 (76.12%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8311,                   Accuracy: 43418/60000 (72.36%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0691,                   Accuracy: 41618/60000 (69.36%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2344,                   Accuracy: 40253/60000 (67.09%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1336,                   Accuracy: 43267/60000 (72.11%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6894,                   Accuracy: 49629/60000 (82.71%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2253,                   Accuracy: 55953/60000 (93.25%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0812,                   Accuracy: 58484/60000 (97.47%)
{0: tensor(98.4583), 10: tensor(97.6417), 20: tensor(95.0533), 30: tensor(85.3650), 40: tensor(72.7883), 50: tensor(64.6767), 60: tensor(66.9183), 70: tensor(76.3200), 80: tensor(80.4367), 90: tensor(81.5583), 100: tensor(73.8483), 110: tensor(61.7400), 120: tensor(48.5350), 130: tensor(39.5167), 140: tensor(37.2983), 150: tensor(39.7533), 160: tensor(45.4250), 170: tensor(47.9617), 180: tensor(48.2367), 190: tensor(49.0567), 200: tensor(45.9183), 210: tensor(40.9600), 220: tensor(39.5650), 230: tensor(42.8450), 240: tensor(52.0583), 250: tensor(65.6000), 260: tensor(73.5300), 270: tensor(81.4333), 280: tensor(76.1233), 290: tensor(72.3633), 300: tensor(69.3633), 310: tensor(67.0883), 320: tensor(72.1117), 330: tensor(82.7150), 340: tensor(93.2550), 350: tensor(97.4733)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=61, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.8550,                   Accuracy: 215/2000.0 (10.75%)



-= Testing valid =-
Test set: Average loss: 1.6472,                   Accuracy: 928/2000.0 (46.40%)



-= Testing valid =-
Test set: Average loss: 0.9271,                   Accuracy: 1481/2000.0 (74.05%)



-= Testing valid =-
Test set: Average loss: 0.1359,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1383,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1277,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.1098,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1942,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.1117,                   Accuracy: 1934/2000.0 (96.70%)



Epoch 10 train accuracy: 97.90%, valid accuracy 96.70%
-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0445,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.1037,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 20 train accuracy: 99.31%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0519,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0450,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 30 train accuracy: 99.53%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 40 train accuracy: 99.57%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.78%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0469,                   Accuracy: 59200/60000 (98.67%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0831,                   Accuracy: 58597/60000 (97.66%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1978,                   Accuracy: 56618/60000 (94.36%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4922,                   Accuracy: 51532/60000 (85.89%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9005,                   Accuracy: 44807/60000 (74.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1724,                   Accuracy: 39430/60000 (65.72%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1600,                   Accuracy: 37960/60000 (63.27%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8779,                   Accuracy: 42524/60000 (70.87%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6528,                   Accuracy: 46548/60000 (77.58%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5401,                   Accuracy: 48938/60000 (81.56%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7193,                   Accuracy: 45633/60000 (76.06%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1716,                   Accuracy: 38896/60000 (64.83%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.9503,                   Accuracy: 30083/60000 (50.14%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.6231,                   Accuracy: 25890/60000 (43.15%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.0676,                   Accuracy: 24570/60000 (40.95%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.3314,                   Accuracy: 25659/60000 (42.76%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5019,                   Accuracy: 28494/60000 (47.49%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.6167,                   Accuracy: 30907/60000 (51.51%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.7312,                   Accuracy: 30896/60000 (51.49%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.7564,                   Accuracy: 30271/60000 (50.45%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.8502,                   Accuracy: 27829/60000 (46.38%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7618,                   Accuracy: 25144/60000 (41.91%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.4182,                   Accuracy: 24686/60000 (41.14%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9049,                   Accuracy: 26547/60000 (44.24%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.1592,                   Accuracy: 31560/60000 (52.60%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3195,                   Accuracy: 39567/60000 (65.94%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7796,                   Accuracy: 45877/60000 (76.46%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5958,                   Accuracy: 48401/60000 (80.67%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6941,                   Accuracy: 46481/60000 (77.47%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8879,                   Accuracy: 43442/60000 (72.40%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1292,                   Accuracy: 40160/60000 (66.93%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1992,                   Accuracy: 39967/60000 (66.61%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0186,                   Accuracy: 42727/60000 (71.21%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5674,                   Accuracy: 49558/60000 (82.60%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1873,                   Accuracy: 56388/60000 (93.98%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0644,                   Accuracy: 58796/60000 (97.99%)
{0: tensor(98.6667), 10: tensor(97.6617), 20: tensor(94.3633), 30: tensor(85.8867), 40: tensor(74.6783), 50: tensor(65.7167), 60: tensor(63.2667), 70: tensor(70.8733), 80: tensor(77.5800), 90: tensor(81.5633), 100: tensor(76.0550), 110: tensor(64.8267), 120: tensor(50.1383), 130: tensor(43.1500), 140: tensor(40.9500), 150: tensor(42.7650), 160: tensor(47.4900), 170: tensor(51.5117), 180: tensor(51.4933), 190: tensor(50.4517), 200: tensor(46.3817), 210: tensor(41.9067), 220: tensor(41.1433), 230: tensor(44.2450), 240: tensor(52.6000), 250: tensor(65.9450), 260: tensor(76.4617), 270: tensor(80.6683), 280: tensor(77.4683), 290: tensor(72.4033), 300: tensor(66.9333), 310: tensor(66.6117), 320: tensor(71.2117), 330: tensor(82.5967), 340: tensor(93.9800), 350: tensor(97.9933)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=62, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4945,                   Accuracy: 212/2000.0 (10.60%)



-= Testing valid =-
Test set: Average loss: 1.5012,                   Accuracy: 817/2000.0 (40.85%)



-= Testing valid =-
Test set: Average loss: 0.7909,                   Accuracy: 1501/2000.0 (75.05%)



-= Testing valid =-
Test set: Average loss: 0.2063,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.2441,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.1639,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1067,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1142,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 10 train accuracy: 98.55%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0486,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 20 train accuracy: 99.18%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0559,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0520,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0453,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 30 train accuracy: 99.56%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 40 train accuracy: 99.70%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 50 train accuracy: 99.69%, valid accuracy 98.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0528,                   Accuracy: 59058/60000 (98.43%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0813,                   Accuracy: 58568/60000 (97.61%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1829,                   Accuracy: 56891/60000 (94.82%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4282,                   Accuracy: 52907/60000 (88.18%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7391,                   Accuracy: 48093/60000 (80.15%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9058,                   Accuracy: 44945/60000 (74.91%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8256,                   Accuracy: 45809/60000 (76.35%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6284,                   Accuracy: 48730/60000 (81.22%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4934,                   Accuracy: 50638/60000 (84.40%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4717,                   Accuracy: 50782/60000 (84.64%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7225,                   Accuracy: 46784/60000 (77.97%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2635,                   Accuracy: 39895/60000 (66.49%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0042,                   Accuracy: 31320/60000 (52.20%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.7299,                   Accuracy: 25275/60000 (42.12%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.2042,                   Accuracy: 23542/60000 (39.24%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4402,                   Accuracy: 24692/60000 (41.15%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4968,                   Accuracy: 27722/60000 (46.20%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.6758,                   Accuracy: 28646/60000 (47.74%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.7731,                   Accuracy: 28338/60000 (47.23%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.6858,                   Accuracy: 27979/60000 (46.63%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7230,                   Accuracy: 25445/60000 (42.41%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9792,                   Accuracy: 22692/60000 (37.82%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7510,                   Accuracy: 21855/60000 (36.42%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2252,                   Accuracy: 23913/60000 (39.85%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3524,                   Accuracy: 29544/60000 (49.24%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.5123,                   Accuracy: 37295/60000 (62.16%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8715,                   Accuracy: 44520/60000 (74.20%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4890,                   Accuracy: 50833/60000 (84.72%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4928,                   Accuracy: 50594/60000 (84.32%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6518,                   Accuracy: 47515/60000 (79.19%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.8287,                   Accuracy: 45293/60000 (75.49%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9716,                   Accuracy: 42999/60000 (71.67%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8759,                   Accuracy: 44650/60000 (74.42%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5032,                   Accuracy: 50909/60000 (84.85%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2037,                   Accuracy: 56377/60000 (93.96%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0836,                   Accuracy: 58544/60000 (97.57%)
{0: tensor(98.4300), 10: tensor(97.6133), 20: tensor(94.8183), 30: tensor(88.1783), 40: tensor(80.1550), 50: tensor(74.9083), 60: tensor(76.3483), 70: tensor(81.2167), 80: tensor(84.3967), 90: tensor(84.6367), 100: tensor(77.9733), 110: tensor(66.4917), 120: tensor(52.2000), 130: tensor(42.1250), 140: tensor(39.2367), 150: tensor(41.1533), 160: tensor(46.2033), 170: tensor(47.7433), 180: tensor(47.2300), 190: tensor(46.6317), 200: tensor(42.4083), 210: tensor(37.8200), 220: tensor(36.4250), 230: tensor(39.8550), 240: tensor(49.2400), 250: tensor(62.1583), 260: tensor(74.2000), 270: tensor(84.7217), 280: tensor(84.3233), 290: tensor(79.1917), 300: tensor(75.4883), 310: tensor(71.6650), 320: tensor(74.4167), 330: tensor(84.8483), 340: tensor(93.9617), 350: tensor(97.5733)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=63, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.3435,                   Accuracy: 229/2000.0 (11.45%)



-= Testing valid =-
Test set: Average loss: 1.5994,                   Accuracy: 764/2000.0 (38.20%)



-= Testing valid =-
Test set: Average loss: 0.6988,                   Accuracy: 1558/2000.0 (77.90%)



-= Testing valid =-
Test set: Average loss: 0.4872,                   Accuracy: 1692/2000.0 (84.60%)



-= Testing valid =-
Test set: Average loss: 0.2109,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.3028,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.1242,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 10 train accuracy: 98.55%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0497,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0511,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0497,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0579,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.1437,                   Accuracy: 1880/2000.0 (94.00%)



Epoch 20 train accuracy: 99.10%, valid accuracy 94.00%
-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0575,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 30 train accuracy: 99.59%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 40 train accuracy: 99.57%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.71%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0528,                   Accuracy: 59115/60000 (98.53%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0911,                   Accuracy: 58442/60000 (97.40%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2012,                   Accuracy: 56652/60000 (94.42%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4688,                   Accuracy: 52200/60000 (87.00%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8107,                   Accuracy: 46115/60000 (76.86%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0064,                   Accuracy: 42094/60000 (70.16%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9876,                   Accuracy: 41783/60000 (69.64%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9014,                   Accuracy: 43419/60000 (72.36%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.9078,                   Accuracy: 43737/60000 (72.89%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.9012,                   Accuracy: 45230/60000 (75.38%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.2813,                   Accuracy: 39344/60000 (65.57%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.9134,                   Accuracy: 32517/60000 (54.19%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.7535,                   Accuracy: 26704/60000 (44.51%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.3785,                   Accuracy: 24128/60000 (40.21%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.7570,                   Accuracy: 24173/60000 (40.29%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.9946,                   Accuracy: 25365/60000 (42.28%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.1335,                   Accuracy: 26444/60000 (44.07%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.3198,                   Accuracy: 27782/60000 (46.30%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.2836,                   Accuracy: 28046/60000 (46.74%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.3163,                   Accuracy: 27876/60000 (46.46%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.6403,                   Accuracy: 25574/60000 (42.62%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.5605,                   Accuracy: 25053/60000 (41.76%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.0239,                   Accuracy: 26683/60000 (44.47%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1136,                   Accuracy: 30463/60000 (50.77%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0397,                   Accuracy: 36417/60000 (60.69%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1874,                   Accuracy: 43315/60000 (72.19%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6637,                   Accuracy: 49404/60000 (82.34%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3965,                   Accuracy: 52545/60000 (87.57%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4655,                   Accuracy: 51145/60000 (85.24%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6400,                   Accuracy: 47861/60000 (79.77%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9052,                   Accuracy: 43739/60000 (72.90%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9800,                   Accuracy: 42754/60000 (71.26%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8431,                   Accuracy: 45271/60000 (75.45%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4511,                   Accuracy: 51617/60000 (86.03%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1831,                   Accuracy: 56624/60000 (94.37%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0841,                   Accuracy: 58545/60000 (97.57%)
{0: tensor(98.5250), 10: tensor(97.4033), 20: tensor(94.4200), 30: tensor(87.), 40: tensor(76.8583), 50: tensor(70.1567), 60: tensor(69.6383), 70: tensor(72.3650), 80: tensor(72.8950), 90: tensor(75.3833), 100: tensor(65.5733), 110: tensor(54.1950), 120: tensor(44.5067), 130: tensor(40.2133), 140: tensor(40.2883), 150: tensor(42.2750), 160: tensor(44.0733), 170: tensor(46.3033), 180: tensor(46.7433), 190: tensor(46.4600), 200: tensor(42.6233), 210: tensor(41.7550), 220: tensor(44.4717), 230: tensor(50.7717), 240: tensor(60.6950), 250: tensor(72.1917), 260: tensor(82.3400), 270: tensor(87.5750), 280: tensor(85.2417), 290: tensor(79.7683), 300: tensor(72.8983), 310: tensor(71.2567), 320: tensor(75.4517), 330: tensor(86.0283), 340: tensor(94.3733), 350: tensor(97.5750)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=64, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3842,                   Accuracy: 322/2000.0 (16.10%)



-= Testing valid =-
Test set: Average loss: 1.0400,                   Accuracy: 1220/2000.0 (61.00%)



-= Testing valid =-
Test set: Average loss: 0.5125,                   Accuracy: 1748/2000.0 (87.40%)



-= Testing valid =-
Test set: Average loss: 0.2175,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2580,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.1995,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1229,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0686,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1930/2000.0 (96.50%)



Epoch 10 train accuracy: 97.95%, valid accuracy 96.50%
-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0593,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 20 train accuracy: 98.99%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 30 train accuracy: 99.32%, valid accuracy 99.30%
-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 40 train accuracy: 99.54%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 50 train accuracy: 99.61%, valid accuracy 99.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0481,                   Accuracy: 59189/60000 (98.65%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0766,                   Accuracy: 58708/60000 (97.85%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1904,                   Accuracy: 57013/60000 (95.02%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5574,                   Accuracy: 51904/60000 (86.51%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0806,                   Accuracy: 44831/60000 (74.72%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.3935,                   Accuracy: 39811/60000 (66.35%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.3441,                   Accuracy: 38721/60000 (64.54%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.0056,                   Accuracy: 42563/60000 (70.94%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.9213,                   Accuracy: 43657/60000 (72.76%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.9377,                   Accuracy: 43958/60000 (73.26%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.3254,                   Accuracy: 39642/60000 (66.07%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.8561,                   Accuracy: 34058/60000 (56.76%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.7372,                   Accuracy: 26315/60000 (43.86%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.6378,                   Accuracy: 22484/60000 (37.47%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.2353,                   Accuracy: 21508/60000 (35.85%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.4947,                   Accuracy: 23189/60000 (38.65%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.3265,                   Accuracy: 26712/60000 (44.52%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.4662,                   Accuracy: 28484/60000 (47.47%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.4300,                   Accuracy: 29489/60000 (49.15%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.2246,                   Accuracy: 30348/60000 (50.58%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.2981,                   Accuracy: 29755/60000 (49.59%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.2468,                   Accuracy: 26958/60000 (44.93%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.8641,                   Accuracy: 25688/60000 (42.81%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1394,                   Accuracy: 27182/60000 (45.30%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2026,                   Accuracy: 32339/60000 (53.90%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3014,                   Accuracy: 40679/60000 (67.80%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7940,                   Accuracy: 46174/60000 (76.96%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5427,                   Accuracy: 49897/60000 (83.16%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6955,                   Accuracy: 46467/60000 (77.44%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9388,                   Accuracy: 43199/60000 (72.00%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.4739,                   Accuracy: 37046/60000 (61.74%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.7006,                   Accuracy: 35371/60000 (58.95%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.5392,                   Accuracy: 38607/60000 (64.35%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8433,                   Accuracy: 47240/60000 (78.73%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2637,                   Accuracy: 55571/60000 (92.62%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0819,                   Accuracy: 58546/60000 (97.58%)
{0: tensor(98.6483), 10: tensor(97.8467), 20: tensor(95.0217), 30: tensor(86.5067), 40: tensor(74.7183), 50: tensor(66.3517), 60: tensor(64.5350), 70: tensor(70.9383), 80: tensor(72.7617), 90: tensor(73.2633), 100: tensor(66.0700), 110: tensor(56.7633), 120: tensor(43.8583), 130: tensor(37.4733), 140: tensor(35.8467), 150: tensor(38.6483), 160: tensor(44.5200), 170: tensor(47.4733), 180: tensor(49.1483), 190: tensor(50.5800), 200: tensor(49.5917), 210: tensor(44.9300), 220: tensor(42.8133), 230: tensor(45.3033), 240: tensor(53.8983), 250: tensor(67.7983), 260: tensor(76.9567), 270: tensor(83.1617), 280: tensor(77.4450), 290: tensor(71.9983), 300: tensor(61.7433), 310: tensor(58.9517), 320: tensor(64.3450), 330: tensor(78.7333), 340: tensor(92.6183), 350: tensor(97.5767)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=65, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4112,                   Accuracy: 545/2000.0 (27.25%)



-= Testing valid =-
Test set: Average loss: 1.8646,                   Accuracy: 548/2000.0 (27.40%)



-= Testing valid =-
Test set: Average loss: 0.4805,                   Accuracy: 1714/2000.0 (85.70%)



-= Testing valid =-
Test set: Average loss: 0.3027,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.3654,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.1629,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.2503,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0746,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.1618,                   Accuracy: 1910/2000.0 (95.50%)



Epoch 10 train accuracy: 98.44%, valid accuracy 95.50%
-= Testing valid =-
Test set: Average loss: 0.0605,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0445,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 20 train accuracy: 99.11%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.31%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 40 train accuracy: 99.56%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.74%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0522,                   Accuracy: 59093/60000 (98.49%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0834,                   Accuracy: 58571/60000 (97.62%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1761,                   Accuracy: 57047/60000 (95.08%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4621,                   Accuracy: 52112/60000 (86.85%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7968,                   Accuracy: 46389/60000 (77.32%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0265,                   Accuracy: 42123/60000 (70.21%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9945,                   Accuracy: 41812/60000 (69.69%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7916,                   Accuracy: 44565/60000 (74.28%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7138,                   Accuracy: 44841/60000 (74.74%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7047,                   Accuracy: 44699/60000 (74.50%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0262,                   Accuracy: 40044/60000 (66.74%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6757,                   Accuracy: 31961/60000 (53.27%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5663,                   Accuracy: 26034/60000 (43.39%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.2200,                   Accuracy: 23776/60000 (39.63%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.6224,                   Accuracy: 23198/60000 (38.66%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.7750,                   Accuracy: 24876/60000 (41.46%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.7061,                   Accuracy: 27594/60000 (45.99%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.9066,                   Accuracy: 29453/60000 (49.09%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.0283,                   Accuracy: 30182/60000 (50.30%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.2516,                   Accuracy: 29691/60000 (49.49%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.4897,                   Accuracy: 27838/60000 (46.40%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.5150,                   Accuracy: 25346/60000 (42.24%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.0013,                   Accuracy: 25350/60000 (42.25%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1853,                   Accuracy: 28055/60000 (46.76%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0846,                   Accuracy: 34682/60000 (57.80%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1965,                   Accuracy: 42696/60000 (71.16%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6540,                   Accuracy: 49076/60000 (81.79%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3480,                   Accuracy: 54016/60000 (90.03%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5310,                   Accuracy: 50445/60000 (84.07%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7028,                   Accuracy: 47454/60000 (79.09%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0368,                   Accuracy: 42387/60000 (70.64%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0924,                   Accuracy: 41163/60000 (68.61%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9526,                   Accuracy: 43948/60000 (73.25%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5502,                   Accuracy: 50478/60000 (84.13%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1955,                   Accuracy: 56417/60000 (94.03%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0885,                   Accuracy: 58393/60000 (97.32%)
{0: tensor(98.4883), 10: tensor(97.6183), 20: tensor(95.0783), 30: tensor(86.8533), 40: tensor(77.3150), 50: tensor(70.2050), 60: tensor(69.6867), 70: tensor(74.2750), 80: tensor(74.7350), 90: tensor(74.4983), 100: tensor(66.7400), 110: tensor(53.2683), 120: tensor(43.3900), 130: tensor(39.6267), 140: tensor(38.6633), 150: tensor(41.4600), 160: tensor(45.9900), 170: tensor(49.0883), 180: tensor(50.3033), 190: tensor(49.4850), 200: tensor(46.3967), 210: tensor(42.2433), 220: tensor(42.2500), 230: tensor(46.7583), 240: tensor(57.8033), 250: tensor(71.1600), 260: tensor(81.7933), 270: tensor(90.0267), 280: tensor(84.0750), 290: tensor(79.0900), 300: tensor(70.6450), 310: tensor(68.6050), 320: tensor(73.2467), 330: tensor(84.1300), 340: tensor(94.0283), 350: tensor(97.3217)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=66, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.5454,                   Accuracy: 783/2000.0 (39.15%)



-= Testing valid =-
Test set: Average loss: 3.2276,                   Accuracy: 302/2000.0 (15.10%)



-= Testing valid =-
Test set: Average loss: 1.6002,                   Accuracy: 949/2000.0 (47.45%)



-= Testing valid =-
Test set: Average loss: 0.2733,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.4160,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.1260,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0935,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1176,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.2345,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 10 train accuracy: 98.25%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 20 train accuracy: 99.11%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 30 train accuracy: 99.55%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0220,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.57%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 50 train accuracy: 99.79%, valid accuracy 99.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0442,                   Accuracy: 59186/60000 (98.64%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0727,                   Accuracy: 58756/60000 (97.93%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1669,                   Accuracy: 57065/60000 (95.11%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3985,                   Accuracy: 52987/60000 (88.31%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7428,                   Accuracy: 46976/60000 (78.29%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0156,                   Accuracy: 41786/60000 (69.64%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0901,                   Accuracy: 39984/60000 (66.64%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9257,                   Accuracy: 41885/60000 (69.81%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8247,                   Accuracy: 43609/60000 (72.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.8130,                   Accuracy: 43714/60000 (72.86%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.2587,                   Accuracy: 38215/60000 (63.69%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.9541,                   Accuracy: 32087/60000 (53.48%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.6889,                   Accuracy: 26440/60000 (44.07%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.4597,                   Accuracy: 23522/60000 (39.20%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.9519,                   Accuracy: 22909/60000 (38.18%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.1206,                   Accuracy: 23833/60000 (39.72%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.0058,                   Accuracy: 26389/60000 (43.98%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.9367,                   Accuracy: 28733/60000 (47.89%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.8924,                   Accuracy: 29426/60000 (49.04%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.7691,                   Accuracy: 30437/60000 (50.73%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.9375,                   Accuracy: 28949/60000 (48.25%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.0375,                   Accuracy: 26587/60000 (44.31%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7775,                   Accuracy: 25223/60000 (42.04%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1661,                   Accuracy: 26805/60000 (44.67%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2663,                   Accuracy: 32028/60000 (53.38%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.4493,                   Accuracy: 38916/60000 (64.86%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8899,                   Accuracy: 45198/60000 (75.33%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5642,                   Accuracy: 49635/60000 (82.72%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6971,                   Accuracy: 47620/60000 (79.37%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8718,                   Accuracy: 45219/60000 (75.36%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0164,                   Accuracy: 42207/60000 (70.35%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1271,                   Accuracy: 40526/60000 (67.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9752,                   Accuracy: 43351/60000 (72.25%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5684,                   Accuracy: 49796/60000 (82.99%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2152,                   Accuracy: 56023/60000 (93.37%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0753,                   Accuracy: 58552/60000 (97.59%)
{0: tensor(98.6433), 10: tensor(97.9267), 20: tensor(95.1083), 30: tensor(88.3117), 40: tensor(78.2933), 50: tensor(69.6433), 60: tensor(66.6400), 70: tensor(69.8083), 80: tensor(72.6817), 90: tensor(72.8567), 100: tensor(63.6917), 110: tensor(53.4783), 120: tensor(44.0667), 130: tensor(39.2033), 140: tensor(38.1817), 150: tensor(39.7217), 160: tensor(43.9817), 170: tensor(47.8883), 180: tensor(49.0433), 190: tensor(50.7283), 200: tensor(48.2483), 210: tensor(44.3117), 220: tensor(42.0383), 230: tensor(44.6750), 240: tensor(53.3800), 250: tensor(64.8600), 260: tensor(75.3300), 270: tensor(82.7250), 280: tensor(79.3667), 290: tensor(75.3650), 300: tensor(70.3450), 310: tensor(67.5433), 320: tensor(72.2517), 330: tensor(82.9933), 340: tensor(93.3717), 350: tensor(97.5867)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=67, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7547,                   Accuracy: 711/2000.0 (35.55%)



-= Testing valid =-
Test set: Average loss: 1.9281,                   Accuracy: 663/2000.0 (33.15%)



-= Testing valid =-
Test set: Average loss: 1.3080,                   Accuracy: 1066/2000.0 (53.30%)



-= Testing valid =-
Test set: Average loss: 0.6861,                   Accuracy: 1514/2000.0 (75.70%)



-= Testing valid =-
Test set: Average loss: 0.2183,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1152,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0790,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.3885,                   Accuracy: 1768/2000.0 (88.40%)



-= Testing valid =-
Test set: Average loss: 0.1036,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 10 train accuracy: 97.94%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.1204,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 20 train accuracy: 98.82%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 30 train accuracy: 99.30%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0205,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0226,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0219,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 40 train accuracy: 99.57%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0205,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0198,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0210,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0194,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0185,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0195,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0196,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 50 train accuracy: 99.60%, valid accuracy 99.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0467,                   Accuracy: 59208/60000 (98.68%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0737,                   Accuracy: 58711/60000 (97.85%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1820,                   Accuracy: 56988/60000 (94.98%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4826,                   Accuracy: 52149/60000 (86.92%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9394,                   Accuracy: 44659/60000 (74.43%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2638,                   Accuracy: 38676/60000 (64.46%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2383,                   Accuracy: 37977/60000 (63.29%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9742,                   Accuracy: 41444/60000 (69.07%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7820,                   Accuracy: 43968/60000 (73.28%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7226,                   Accuracy: 44843/60000 (74.74%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9988,                   Accuracy: 40241/60000 (67.07%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6536,                   Accuracy: 32102/60000 (53.50%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.4888,                   Accuracy: 25762/60000 (42.94%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.2429,                   Accuracy: 22056/60000 (36.76%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.6874,                   Accuracy: 21444/60000 (35.74%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.7810,                   Accuracy: 22692/60000 (37.82%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.6075,                   Accuracy: 25552/60000 (42.59%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.4585,                   Accuracy: 27995/60000 (46.66%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.3808,                   Accuracy: 29408/60000 (49.01%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.2949,                   Accuracy: 29744/60000 (49.57%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.4478,                   Accuracy: 26798/60000 (44.66%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4506,                   Accuracy: 23807/60000 (39.68%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.2422,                   Accuracy: 23001/60000 (38.33%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7333,                   Accuracy: 25545/60000 (42.58%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9685,                   Accuracy: 31849/60000 (53.08%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2252,                   Accuracy: 40737/60000 (67.89%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7775,                   Accuracy: 46571/60000 (77.62%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5289,                   Accuracy: 50287/60000 (83.81%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6507,                   Accuracy: 47414/60000 (79.02%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9343,                   Accuracy: 42459/60000 (70.76%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2874,                   Accuracy: 37897/60000 (63.16%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4155,                   Accuracy: 36741/60000 (61.24%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1981,                   Accuracy: 40239/60000 (67.07%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6971,                   Accuracy: 47913/60000 (79.86%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2663,                   Accuracy: 55032/60000 (91.72%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0879,                   Accuracy: 58345/60000 (97.24%)
{0: tensor(98.6800), 10: tensor(97.8517), 20: tensor(94.9800), 30: tensor(86.9150), 40: tensor(74.4317), 50: tensor(64.4600), 60: tensor(63.2950), 70: tensor(69.0733), 80: tensor(73.2800), 90: tensor(74.7383), 100: tensor(67.0683), 110: tensor(53.5033), 120: tensor(42.9367), 130: tensor(36.7600), 140: tensor(35.7400), 150: tensor(37.8200), 160: tensor(42.5867), 170: tensor(46.6583), 180: tensor(49.0133), 190: tensor(49.5733), 200: tensor(44.6633), 210: tensor(39.6783), 220: tensor(38.3350), 230: tensor(42.5750), 240: tensor(53.0817), 250: tensor(67.8950), 260: tensor(77.6183), 270: tensor(83.8117), 280: tensor(79.0233), 290: tensor(70.7650), 300: tensor(63.1617), 310: tensor(61.2350), 320: tensor(67.0650), 330: tensor(79.8550), 340: tensor(91.7200), 350: tensor(97.2417)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=68, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.6230,                   Accuracy: 819/2000.0 (40.95%)



-= Testing valid =-
Test set: Average loss: 1.3995,                   Accuracy: 1041/2000.0 (52.05%)



-= Testing valid =-
Test set: Average loss: 0.7244,                   Accuracy: 1518/2000.0 (75.90%)



-= Testing valid =-
Test set: Average loss: 0.3281,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.3634,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.1222,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1079,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1619,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.2498,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.1470,                   Accuracy: 1911/2000.0 (95.55%)



Epoch 10 train accuracy: 98.26%, valid accuracy 95.55%
-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 20 train accuracy: 99.38%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.54%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.72%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.68%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0445,                   Accuracy: 59202/60000 (98.67%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0728,                   Accuracy: 58727/60000 (97.88%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1507,                   Accuracy: 57419/60000 (95.70%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4292,                   Accuracy: 52658/60000 (87.76%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8929,                   Accuracy: 45094/60000 (75.16%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1493,                   Accuracy: 40669/60000 (67.78%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9871,                   Accuracy: 42056/60000 (70.09%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6646,                   Accuracy: 47371/60000 (78.95%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5074,                   Accuracy: 49986/60000 (83.31%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4922,                   Accuracy: 50744/60000 (84.57%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7305,                   Accuracy: 46700/60000 (77.83%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1530,                   Accuracy: 41771/60000 (69.62%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.9468,                   Accuracy: 32833/60000 (54.72%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8339,                   Accuracy: 26704/60000 (44.51%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3488,                   Accuracy: 24493/60000 (40.82%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.5186,                   Accuracy: 25146/60000 (41.91%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4756,                   Accuracy: 27791/60000 (46.32%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.3187,                   Accuracy: 30109/60000 (50.18%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.1966,                   Accuracy: 30890/60000 (51.48%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4756,                   Accuracy: 30087/60000 (50.15%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.3857,                   Accuracy: 29070/60000 (48.45%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4517,                   Accuracy: 27141/60000 (45.24%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.4751,                   Accuracy: 26197/60000 (43.66%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.0786,                   Accuracy: 28210/60000 (47.02%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2797,                   Accuracy: 33747/60000 (56.24%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.4068,                   Accuracy: 41121/60000 (68.54%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6977,                   Accuracy: 48226/60000 (80.38%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3814,                   Accuracy: 52488/60000 (87.48%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4464,                   Accuracy: 51215/60000 (85.36%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6878,                   Accuracy: 47152/60000 (78.59%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0452,                   Accuracy: 42413/60000 (70.69%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2638,                   Accuracy: 39919/60000 (66.53%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0974,                   Accuracy: 42504/60000 (70.84%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6071,                   Accuracy: 49329/60000 (82.21%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2378,                   Accuracy: 55638/60000 (92.73%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0728,                   Accuracy: 58671/60000 (97.79%)
{0: tensor(98.6700), 10: tensor(97.8783), 20: tensor(95.6983), 30: tensor(87.7633), 40: tensor(75.1567), 50: tensor(67.7817), 60: tensor(70.0933), 70: tensor(78.9517), 80: tensor(83.3100), 90: tensor(84.5733), 100: tensor(77.8333), 110: tensor(69.6183), 120: tensor(54.7217), 130: tensor(44.5067), 140: tensor(40.8217), 150: tensor(41.9100), 160: tensor(46.3183), 170: tensor(50.1817), 180: tensor(51.4833), 190: tensor(50.1450), 200: tensor(48.4500), 210: tensor(45.2350), 220: tensor(43.6617), 230: tensor(47.0167), 240: tensor(56.2450), 250: tensor(68.5350), 260: tensor(80.3767), 270: tensor(87.4800), 280: tensor(85.3583), 290: tensor(78.5867), 300: tensor(70.6883), 310: tensor(66.5317), 320: tensor(70.8400), 330: tensor(82.2150), 340: tensor(92.7300), 350: tensor(97.7850)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=69, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4028,                   Accuracy: 400/2000.0 (20.00%)



-= Testing valid =-
Test set: Average loss: 2.0187,                   Accuracy: 701/2000.0 (35.05%)



-= Testing valid =-
Test set: Average loss: 0.6223,                   Accuracy: 1638/2000.0 (81.90%)



-= Testing valid =-
Test set: Average loss: 0.4257,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.1567,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1680,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 10 train accuracy: 98.22%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0708,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 20 train accuracy: 99.20%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 30 train accuracy: 99.54%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 40 train accuracy: 99.75%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 50 train accuracy: 99.74%, valid accuracy 98.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0496,                   Accuracy: 59166/60000 (98.61%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0760,                   Accuracy: 58715/60000 (97.86%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1892,                   Accuracy: 56729/60000 (94.55%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4312,                   Accuracy: 52386/60000 (87.31%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8429,                   Accuracy: 45141/60000 (75.24%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1287,                   Accuracy: 39654/60000 (66.09%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1433,                   Accuracy: 38903/60000 (64.84%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9730,                   Accuracy: 41681/60000 (69.47%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8239,                   Accuracy: 44175/60000 (73.62%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.8393,                   Accuracy: 43780/60000 (72.97%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.3504,                   Accuracy: 36191/60000 (60.32%)
-= Testing Rotation 110 =-
Test set: Average loss: 2.1469,                   Accuracy: 29748/60000 (49.58%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.9814,                   Accuracy: 24772/60000 (41.29%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.5941,                   Accuracy: 22729/60000 (37.88%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.8182,                   Accuracy: 23168/60000 (38.61%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8198,                   Accuracy: 25530/60000 (42.55%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5532,                   Accuracy: 28804/60000 (48.01%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.4290,                   Accuracy: 30578/60000 (50.96%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.5125,                   Accuracy: 30805/60000 (51.34%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.5916,                   Accuracy: 30632/60000 (51.05%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7701,                   Accuracy: 29347/60000 (48.91%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9593,                   Accuracy: 25919/60000 (43.20%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.8888,                   Accuracy: 22892/60000 (38.15%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.4267,                   Accuracy: 22733/60000 (37.89%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.6374,                   Accuracy: 26292/60000 (43.82%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.7269,                   Accuracy: 33362/60000 (55.60%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.0612,                   Accuracy: 41559/60000 (69.26%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6372,                   Accuracy: 47921/60000 (79.87%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.9144,                   Accuracy: 43842/60000 (73.07%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.1824,                   Accuracy: 41438/60000 (69.06%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.4981,                   Accuracy: 37782/60000 (62.97%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.5606,                   Accuracy: 35795/60000 (59.66%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2784,                   Accuracy: 39006/60000 (65.01%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7360,                   Accuracy: 47109/60000 (78.51%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2602,                   Accuracy: 55212/60000 (92.02%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0903,                   Accuracy: 58367/60000 (97.28%)
{0: tensor(98.6100), 10: tensor(97.8583), 20: tensor(94.5483), 30: tensor(87.3100), 40: tensor(75.2350), 50: tensor(66.0900), 60: tensor(64.8383), 70: tensor(69.4683), 80: tensor(73.6250), 90: tensor(72.9667), 100: tensor(60.3183), 110: tensor(49.5800), 120: tensor(41.2867), 130: tensor(37.8817), 140: tensor(38.6133), 150: tensor(42.5500), 160: tensor(48.0067), 170: tensor(50.9633), 180: tensor(51.3417), 190: tensor(51.0533), 200: tensor(48.9117), 210: tensor(43.1983), 220: tensor(38.1533), 230: tensor(37.8883), 240: tensor(43.8200), 250: tensor(55.6033), 260: tensor(69.2650), 270: tensor(79.8683), 280: tensor(73.0700), 290: tensor(69.0633), 300: tensor(62.9700), 310: tensor(59.6583), 320: tensor(65.0100), 330: tensor(78.5150), 340: tensor(92.0200), 350: tensor(97.2783)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=70, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2082,                   Accuracy: 335/2000.0 (16.75%)



-= Testing valid =-
Test set: Average loss: 1.6844,                   Accuracy: 711/2000.0 (35.55%)



-= Testing valid =-
Test set: Average loss: 0.5464,                   Accuracy: 1664/2000.0 (83.20%)



-= Testing valid =-
Test set: Average loss: 0.2636,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1121,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1381,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1371,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0710,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 10 train accuracy: 98.44%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 20 train accuracy: 99.24%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.44%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.66%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.74%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0488,                   Accuracy: 59184/60000 (98.64%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0740,                   Accuracy: 58726/60000 (97.88%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1755,                   Accuracy: 57035/60000 (95.06%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4548,                   Accuracy: 52491/60000 (87.49%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8404,                   Accuracy: 46202/60000 (77.00%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0416,                   Accuracy: 41992/60000 (69.99%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8792,                   Accuracy: 44304/60000 (73.84%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.5631,                   Accuracy: 49209/60000 (82.01%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4461,                   Accuracy: 51174/60000 (85.29%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4754,                   Accuracy: 50921/60000 (84.87%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7333,                   Accuracy: 47024/60000 (78.37%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3698,                   Accuracy: 38541/60000 (64.24%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.4711,                   Accuracy: 27954/60000 (46.59%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.2663,                   Accuracy: 24414/60000 (40.69%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.6635,                   Accuracy: 24631/60000 (41.05%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.6148,                   Accuracy: 26927/60000 (44.88%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.2705,                   Accuracy: 30619/60000 (51.03%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.2434,                   Accuracy: 31715/60000 (52.86%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.2316,                   Accuracy: 32366/60000 (53.94%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.2724,                   Accuracy: 30554/60000 (50.92%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.3876,                   Accuracy: 28401/60000 (47.33%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.5320,                   Accuracy: 25837/60000 (43.06%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.2353,                   Accuracy: 25209/60000 (42.01%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.5890,                   Accuracy: 28384/60000 (47.31%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.6983,                   Accuracy: 35329/60000 (58.88%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0335,                   Accuracy: 43037/60000 (71.73%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6667,                   Accuracy: 47738/60000 (79.56%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4679,                   Accuracy: 50507/60000 (84.18%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5914,                   Accuracy: 48454/60000 (80.76%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8118,                   Accuracy: 44775/60000 (74.62%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2410,                   Accuracy: 38985/60000 (64.97%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3595,                   Accuracy: 38114/60000 (63.52%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2406,                   Accuracy: 41514/60000 (69.19%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7057,                   Accuracy: 49429/60000 (82.38%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2044,                   Accuracy: 56292/60000 (93.82%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0700,                   Accuracy: 58718/60000 (97.86%)
{0: tensor(98.6400), 10: tensor(97.8767), 20: tensor(95.0583), 30: tensor(87.4850), 40: tensor(77.0033), 50: tensor(69.9867), 60: tensor(73.8400), 70: tensor(82.0150), 80: tensor(85.2900), 90: tensor(84.8683), 100: tensor(78.3733), 110: tensor(64.2350), 120: tensor(46.5900), 130: tensor(40.6900), 140: tensor(41.0517), 150: tensor(44.8783), 160: tensor(51.0317), 170: tensor(52.8583), 180: tensor(53.9433), 190: tensor(50.9233), 200: tensor(47.3350), 210: tensor(43.0617), 220: tensor(42.0150), 230: tensor(47.3067), 240: tensor(58.8817), 250: tensor(71.7283), 260: tensor(79.5633), 270: tensor(84.1783), 280: tensor(80.7567), 290: tensor(74.6250), 300: tensor(64.9750), 310: tensor(63.5233), 320: tensor(69.1900), 330: tensor(82.3817), 340: tensor(93.8200), 350: tensor(97.8633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=41, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 7.8809,                   Accuracy: 214/2000.0 (10.70%)



-= Testing valid =-
Test set: Average loss: 1.8957,                   Accuracy: 612/2000.0 (30.60%)



-= Testing valid =-
Test set: Average loss: 1.5019,                   Accuracy: 956/2000.0 (47.80%)



-= Testing valid =-
Test set: Average loss: 0.3353,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.5957,                   Accuracy: 1608/2000.0 (80.40%)



-= Testing valid =-
Test set: Average loss: 0.1789,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1259,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1293,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1733,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1391,                   Accuracy: 1914/2000.0 (95.70%)



Epoch 10 train accuracy: 98.09%, valid accuracy 95.70%
-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 20 train accuracy: 99.32%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 30 train accuracy: 99.54%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 40 train accuracy: 99.76%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 50 train accuracy: 99.72%, valid accuracy 98.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0417,                   Accuracy: 59266/60000 (98.78%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0687,                   Accuracy: 58809/60000 (98.01%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1516,                   Accuracy: 57319/60000 (95.53%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3656,                   Accuracy: 53594/60000 (89.32%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7397,                   Accuracy: 47289/60000 (78.82%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9717,                   Accuracy: 43084/60000 (71.81%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9253,                   Accuracy: 43555/60000 (72.59%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6979,                   Accuracy: 46959/60000 (78.26%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4670,                   Accuracy: 50895/60000 (84.82%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4102,                   Accuracy: 51883/60000 (86.47%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6933,                   Accuracy: 46887/60000 (78.14%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2261,                   Accuracy: 39391/60000 (65.65%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0349,                   Accuracy: 31817/60000 (53.03%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.9538,                   Accuracy: 26133/60000 (43.56%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.5211,                   Accuracy: 24469/60000 (40.78%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.7565,                   Accuracy: 25754/60000 (42.92%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.7528,                   Accuracy: 27870/60000 (46.45%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.7978,                   Accuracy: 29727/60000 (49.54%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.8671,                   Accuracy: 30562/60000 (50.94%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.7178,                   Accuracy: 30041/60000 (50.07%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7193,                   Accuracy: 28677/60000 (47.79%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7324,                   Accuracy: 26796/60000 (44.66%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6037,                   Accuracy: 26142/60000 (43.57%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1647,                   Accuracy: 27447/60000 (45.74%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3847,                   Accuracy: 31650/60000 (52.75%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.5453,                   Accuracy: 37871/60000 (63.12%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9193,                   Accuracy: 43805/60000 (73.01%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6468,                   Accuracy: 47523/60000 (79.21%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5828,                   Accuracy: 48259/60000 (80.43%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7134,                   Accuracy: 46246/60000 (77.08%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.8812,                   Accuracy: 43190/60000 (71.98%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9880,                   Accuracy: 41115/60000 (68.53%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8661,                   Accuracy: 43509/60000 (72.51%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4938,                   Accuracy: 50300/60000 (83.83%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1885,                   Accuracy: 56370/60000 (93.95%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0659,                   Accuracy: 58770/60000 (97.95%)
{0: tensor(98.7767), 10: tensor(98.0150), 20: tensor(95.5317), 30: tensor(89.3233), 40: tensor(78.8150), 50: tensor(71.8067), 60: tensor(72.5917), 70: tensor(78.2650), 80: tensor(84.8250), 90: tensor(86.4717), 100: tensor(78.1450), 110: tensor(65.6517), 120: tensor(53.0283), 130: tensor(43.5550), 140: tensor(40.7817), 150: tensor(42.9233), 160: tensor(46.4500), 170: tensor(49.5450), 180: tensor(50.9367), 190: tensor(50.0683), 200: tensor(47.7950), 210: tensor(44.6600), 220: tensor(43.5700), 230: tensor(45.7450), 240: tensor(52.7500), 250: tensor(63.1183), 260: tensor(73.0083), 270: tensor(79.2050), 280: tensor(80.4317), 290: tensor(77.0767), 300: tensor(71.9833), 310: tensor(68.5250), 320: tensor(72.5150), 330: tensor(83.8333), 340: tensor(93.9500), 350: tensor(97.9500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=42, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.0113,                   Accuracy: 205/2000.0 (10.25%)



-= Testing valid =-
Test set: Average loss: 1.9682,                   Accuracy: 678/2000.0 (33.90%)



-= Testing valid =-
Test set: Average loss: 0.8099,                   Accuracy: 1559/2000.0 (77.95%)



-= Testing valid =-
Test set: Average loss: 0.3595,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.2385,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.1892,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1388,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1610,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.0736,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 10 train accuracy: 98.07%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0472,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0520,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 20 train accuracy: 99.09%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.29%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.47%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 50 train accuracy: 99.69%, valid accuracy 98.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0546,                   Accuracy: 59045/60000 (98.41%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0831,                   Accuracy: 58599/60000 (97.67%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1924,                   Accuracy: 56808/60000 (94.68%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4616,                   Accuracy: 52263/60000 (87.11%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8478,                   Accuracy: 45789/60000 (76.32%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0013,                   Accuracy: 42786/60000 (71.31%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8486,                   Accuracy: 44744/60000 (74.57%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6620,                   Accuracy: 47578/60000 (79.30%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5199,                   Accuracy: 49671/60000 (82.79%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4914,                   Accuracy: 50147/60000 (83.58%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6404,                   Accuracy: 47358/60000 (78.93%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.0244,                   Accuracy: 41531/60000 (69.22%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.6088,                   Accuracy: 34192/60000 (56.99%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.2113,                   Accuracy: 28460/60000 (47.43%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.5749,                   Accuracy: 26104/60000 (43.51%)
-= Testing Rotation 150 =-
Test set: Average loss: 2.6026,                   Accuracy: 26480/60000 (44.13%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.5048,                   Accuracy: 29367/60000 (48.94%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.3118,                   Accuracy: 32062/60000 (53.44%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.1874,                   Accuracy: 33800/60000 (56.33%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.3200,                   Accuracy: 32938/60000 (54.90%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.5174,                   Accuracy: 30189/60000 (50.31%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.7959,                   Accuracy: 26715/60000 (44.53%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.9543,                   Accuracy: 26161/60000 (43.60%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.6120,                   Accuracy: 29160/60000 (48.60%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.8496,                   Accuracy: 36099/60000 (60.17%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0660,                   Accuracy: 44776/60000 (74.63%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5289,                   Accuracy: 51475/60000 (85.79%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3229,                   Accuracy: 54181/60000 (90.30%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3468,                   Accuracy: 53428/60000 (89.05%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.5069,                   Accuracy: 50760/60000 (84.60%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.7678,                   Accuracy: 46961/60000 (78.27%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9686,                   Accuracy: 43618/60000 (72.70%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8924,                   Accuracy: 44708/60000 (74.51%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5688,                   Accuracy: 49582/60000 (82.64%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2363,                   Accuracy: 55590/60000 (92.65%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0862,                   Accuracy: 58400/60000 (97.33%)
{0: tensor(98.4083), 10: tensor(97.6650), 20: tensor(94.6800), 30: tensor(87.1050), 40: tensor(76.3150), 50: tensor(71.3100), 60: tensor(74.5733), 70: tensor(79.2967), 80: tensor(82.7850), 90: tensor(83.5783), 100: tensor(78.9300), 110: tensor(69.2183), 120: tensor(56.9867), 130: tensor(47.4333), 140: tensor(43.5067), 150: tensor(44.1333), 160: tensor(48.9450), 170: tensor(53.4367), 180: tensor(56.3333), 190: tensor(54.8967), 200: tensor(50.3150), 210: tensor(44.5250), 220: tensor(43.6017), 230: tensor(48.6000), 240: tensor(60.1650), 250: tensor(74.6267), 260: tensor(85.7917), 270: tensor(90.3017), 280: tensor(89.0467), 290: tensor(84.6000), 300: tensor(78.2683), 310: tensor(72.6967), 320: tensor(74.5133), 330: tensor(82.6367), 340: tensor(92.6500), 350: tensor(97.3333)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=43, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.3894,                   Accuracy: 202/2000.0 (10.10%)



-= Testing valid =-
Test set: Average loss: 1.0039,                   Accuracy: 1285/2000.0 (64.25%)



-= Testing valid =-
Test set: Average loss: 1.3779,                   Accuracy: 949/2000.0 (47.45%)



-= Testing valid =-
Test set: Average loss: 0.9549,                   Accuracy: 1399/2000.0 (69.95%)



-= Testing valid =-
Test set: Average loss: 0.2542,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.1728,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.2011,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1586,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 10 train accuracy: 98.00%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1037,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.1817,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0790,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 20 train accuracy: 99.14%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.1295,                   Accuracy: 1881/2000.0 (94.05%)



Epoch 30 train accuracy: 99.51%, valid accuracy 94.05%
-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0497,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0618,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 40 train accuracy: 99.61%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0579,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0617,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 50 train accuracy: 99.69%, valid accuracy 98.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0768,                   Accuracy: 58750/60000 (97.92%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1072,                   Accuracy: 58229/60000 (97.05%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2625,                   Accuracy: 55656/60000 (92.76%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7232,                   Accuracy: 48696/60000 (81.16%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0946,                   Accuracy: 42895/60000 (71.49%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2150,                   Accuracy: 40490/60000 (67.48%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0378,                   Accuracy: 42272/60000 (70.45%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6343,                   Accuracy: 48417/60000 (80.69%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4517,                   Accuracy: 51215/60000 (85.36%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5358,                   Accuracy: 49489/60000 (82.48%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7627,                   Accuracy: 45527/60000 (75.88%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3170,                   Accuracy: 38514/60000 (64.19%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.1582,                   Accuracy: 30515/60000 (50.86%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.7844,                   Accuracy: 26220/60000 (43.70%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.0392,                   Accuracy: 25107/60000 (41.85%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.0384,                   Accuracy: 26478/60000 (44.13%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.9597,                   Accuracy: 29299/60000 (48.83%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.9532,                   Accuracy: 30706/60000 (51.18%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.9013,                   Accuracy: 30283/60000 (50.47%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.2742,                   Accuracy: 29295/60000 (48.83%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7213,                   Accuracy: 27086/60000 (45.14%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9431,                   Accuracy: 24808/60000 (41.35%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6731,                   Accuracy: 25042/60000 (41.74%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9891,                   Accuracy: 27643/60000 (46.07%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9987,                   Accuracy: 33793/60000 (56.32%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1943,                   Accuracy: 41810/60000 (69.68%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6747,                   Accuracy: 47744/60000 (79.57%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4652,                   Accuracy: 50996/60000 (84.99%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5128,                   Accuracy: 49919/60000 (83.20%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7178,                   Accuracy: 46320/60000 (77.20%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0397,                   Accuracy: 41598/60000 (69.33%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0488,                   Accuracy: 41887/60000 (69.81%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9013,                   Accuracy: 44707/60000 (74.51%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5143,                   Accuracy: 50703/60000 (84.50%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1880,                   Accuracy: 56511/60000 (94.18%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0914,                   Accuracy: 58399/60000 (97.33%)
{0: tensor(97.9167), 10: tensor(97.0483), 20: tensor(92.7600), 30: tensor(81.1600), 40: tensor(71.4917), 50: tensor(67.4833), 60: tensor(70.4533), 70: tensor(80.6950), 80: tensor(85.3583), 90: tensor(82.4817), 100: tensor(75.8783), 110: tensor(64.1900), 120: tensor(50.8583), 130: tensor(43.7000), 140: tensor(41.8450), 150: tensor(44.1300), 160: tensor(48.8317), 170: tensor(51.1767), 180: tensor(50.4717), 190: tensor(48.8250), 200: tensor(45.1433), 210: tensor(41.3467), 220: tensor(41.7367), 230: tensor(46.0717), 240: tensor(56.3217), 250: tensor(69.6833), 260: tensor(79.5733), 270: tensor(84.9933), 280: tensor(83.1983), 290: tensor(77.2000), 300: tensor(69.3300), 310: tensor(69.8117), 320: tensor(74.5117), 330: tensor(84.5050), 340: tensor(94.1850), 350: tensor(97.3317)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=44, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.5536,                   Accuracy: 243/2000.0 (12.15%)



-= Testing valid =-
Test set: Average loss: 1.1073,                   Accuracy: 1125/2000.0 (56.25%)



-= Testing valid =-
Test set: Average loss: 0.5079,                   Accuracy: 1707/2000.0 (85.35%)



-= Testing valid =-
Test set: Average loss: 0.5922,                   Accuracy: 1579/2000.0 (78.95%)



-= Testing valid =-
Test set: Average loss: 0.1781,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1048,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1729,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.0775,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1216,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 10 train accuracy: 98.34%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0428,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 20 train accuracy: 98.90%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0519,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 30 train accuracy: 99.40%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0204,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0200,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0207,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0206,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0202,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 40 train accuracy: 99.60%, valid accuracy 99.35%
-= Testing valid =-
Test set: Average loss: 0.0203,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0194,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0223,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0182,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0195,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0195,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0207,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0195,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0169,                   Accuracy: 1989/2000.0 (99.45%)



Epoch 50 train accuracy: 99.64%, valid accuracy 99.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0538,                   Accuracy: 59070/60000 (98.45%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0817,                   Accuracy: 58565/60000 (97.61%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1883,                   Accuracy: 56690/60000 (94.48%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4820,                   Accuracy: 51561/60000 (85.93%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9356,                   Accuracy: 43943/60000 (73.24%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2053,                   Accuracy: 39015/60000 (65.03%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1724,                   Accuracy: 38947/60000 (64.91%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9036,                   Accuracy: 42627/60000 (71.04%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6448,                   Accuracy: 46846/60000 (78.08%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5904,                   Accuracy: 47819/60000 (79.70%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8360,                   Accuracy: 42868/60000 (71.45%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.4219,                   Accuracy: 35095/60000 (58.49%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2312,                   Accuracy: 28300/60000 (47.17%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.9315,                   Accuracy: 23614/60000 (39.36%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3105,                   Accuracy: 23130/60000 (38.55%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.3683,                   Accuracy: 25179/60000 (41.97%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.2781,                   Accuracy: 28696/60000 (47.83%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.2256,                   Accuracy: 30459/60000 (50.76%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.3095,                   Accuracy: 30159/60000 (50.26%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.3320,                   Accuracy: 29517/60000 (49.19%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.4737,                   Accuracy: 26765/60000 (44.61%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.6405,                   Accuracy: 23539/60000 (39.23%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.5554,                   Accuracy: 22233/60000 (37.06%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.0426,                   Accuracy: 24918/60000 (41.53%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2136,                   Accuracy: 31426/60000 (52.38%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3119,                   Accuracy: 40095/60000 (66.82%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7066,                   Accuracy: 47827/60000 (79.71%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4360,                   Accuracy: 51775/60000 (86.29%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4976,                   Accuracy: 50481/60000 (84.14%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7005,                   Accuracy: 46329/60000 (77.21%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9791,                   Accuracy: 41589/60000 (69.32%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1226,                   Accuracy: 38808/60000 (64.68%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0338,                   Accuracy: 40858/60000 (68.10%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6657,                   Accuracy: 47857/60000 (79.76%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2637,                   Accuracy: 55230/60000 (92.05%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0901,                   Accuracy: 58394/60000 (97.32%)
{0: tensor(98.4500), 10: tensor(97.6083), 20: tensor(94.4833), 30: tensor(85.9350), 40: tensor(73.2383), 50: tensor(65.0250), 60: tensor(64.9117), 70: tensor(71.0450), 80: tensor(78.0767), 90: tensor(79.6983), 100: tensor(71.4467), 110: tensor(58.4917), 120: tensor(47.1667), 130: tensor(39.3567), 140: tensor(38.5500), 150: tensor(41.9650), 160: tensor(47.8267), 170: tensor(50.7650), 180: tensor(50.2650), 190: tensor(49.1950), 200: tensor(44.6083), 210: tensor(39.2317), 220: tensor(37.0550), 230: tensor(41.5300), 240: tensor(52.3767), 250: tensor(66.8250), 260: tensor(79.7117), 270: tensor(86.2917), 280: tensor(84.1350), 290: tensor(77.2150), 300: tensor(69.3150), 310: tensor(64.6800), 320: tensor(68.0967), 330: tensor(79.7617), 340: tensor(92.0500), 350: tensor(97.3233)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=45, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.9591,                   Accuracy: 212/2000.0 (10.60%)



-= Testing valid =-
Test set: Average loss: 1.4544,                   Accuracy: 849/2000.0 (42.45%)



-= Testing valid =-
Test set: Average loss: 1.1657,                   Accuracy: 1089/2000.0 (54.45%)



-= Testing valid =-
Test set: Average loss: 1.0989,                   Accuracy: 1340/2000.0 (67.00%)



-= Testing valid =-
Test set: Average loss: 0.4847,                   Accuracy: 1661/2000.0 (83.05%)



-= Testing valid =-
Test set: Average loss: 0.9471,                   Accuracy: 1486/2000.0 (74.30%)



-= Testing valid =-
Test set: Average loss: 0.2179,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.1957,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1303,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1122,                   Accuracy: 1918/2000.0 (95.90%)



Epoch 10 train accuracy: 97.25%, valid accuracy 95.90%
-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.1059,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0578,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0560,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0535,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 20 train accuracy: 98.79%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.15%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 40 train accuracy: 99.49%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 50 train accuracy: 99.51%, valid accuracy 98.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0563,                   Accuracy: 59001/60000 (98.33%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0798,                   Accuracy: 58621/60000 (97.70%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1941,                   Accuracy: 56652/60000 (94.42%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5907,                   Accuracy: 50197/60000 (83.66%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.1442,                   Accuracy: 41903/60000 (69.84%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.5472,                   Accuracy: 35960/60000 (59.93%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.4990,                   Accuracy: 35779/60000 (59.63%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.1348,                   Accuracy: 40107/60000 (66.85%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8505,                   Accuracy: 44232/60000 (73.72%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7919,                   Accuracy: 44626/60000 (74.38%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9662,                   Accuracy: 42594/60000 (70.99%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5154,                   Accuracy: 36467/60000 (60.78%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.3603,                   Accuracy: 30328/60000 (50.55%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.0487,                   Accuracy: 26216/60000 (43.69%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.5750,                   Accuracy: 24379/60000 (40.63%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.7699,                   Accuracy: 25357/60000 (42.26%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.6135,                   Accuracy: 28832/60000 (48.05%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5552,                   Accuracy: 31294/60000 (52.16%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.7046,                   Accuracy: 32325/60000 (53.88%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.7518,                   Accuracy: 31394/60000 (52.32%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7810,                   Accuracy: 28732/60000 (47.89%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9718,                   Accuracy: 25024/60000 (41.71%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.9708,                   Accuracy: 22513/60000 (37.52%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.6162,                   Accuracy: 22882/60000 (38.14%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.9230,                   Accuracy: 25416/60000 (42.36%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.9768,                   Accuracy: 31564/60000 (52.61%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.2899,                   Accuracy: 37356/60000 (62.26%)
-= Testing Rotation 270 =-
Test set: Average loss: 1.0932,                   Accuracy: 38950/60000 (64.92%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.0251,                   Accuracy: 39212/60000 (65.35%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.2583,                   Accuracy: 36364/60000 (60.61%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.7921,                   Accuracy: 30280/60000 (50.47%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.7302,                   Accuracy: 32089/60000 (53.48%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.4376,                   Accuracy: 37331/60000 (62.22%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8050,                   Accuracy: 46811/60000 (78.02%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2593,                   Accuracy: 55489/60000 (92.48%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0903,                   Accuracy: 58385/60000 (97.31%)
{0: tensor(98.3350), 10: tensor(97.7017), 20: tensor(94.4200), 30: tensor(83.6617), 40: tensor(69.8383), 50: tensor(59.9333), 60: tensor(59.6317), 70: tensor(66.8450), 80: tensor(73.7200), 90: tensor(74.3767), 100: tensor(70.9900), 110: tensor(60.7783), 120: tensor(50.5467), 130: tensor(43.6933), 140: tensor(40.6317), 150: tensor(42.2617), 160: tensor(48.0533), 170: tensor(52.1567), 180: tensor(53.8750), 190: tensor(52.3233), 200: tensor(47.8867), 210: tensor(41.7067), 220: tensor(37.5217), 230: tensor(38.1367), 240: tensor(42.3600), 250: tensor(52.6067), 260: tensor(62.2600), 270: tensor(64.9167), 280: tensor(65.3533), 290: tensor(60.6067), 300: tensor(50.4667), 310: tensor(53.4817), 320: tensor(62.2183), 330: tensor(78.0183), 340: tensor(92.4817), 350: tensor(97.3083)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=46, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9811,                   Accuracy: 394/2000.0 (19.70%)



-= Testing valid =-
Test set: Average loss: 1.5664,                   Accuracy: 743/2000.0 (37.15%)



-= Testing valid =-
Test set: Average loss: 0.5773,                   Accuracy: 1678/2000.0 (83.90%)



-= Testing valid =-
Test set: Average loss: 0.2627,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2117,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2480,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.3046,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.1225,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1021,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0742,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 10 train accuracy: 98.21%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.1168,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 20 train accuracy: 99.01%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0668,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0596,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0568,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0686,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 30 train accuracy: 99.35%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0575,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0486,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0552,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0590,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 40 train accuracy: 99.62%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 50 train accuracy: 99.70%, valid accuracy 98.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0504,                   Accuracy: 59056/60000 (98.43%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0829,                   Accuracy: 58569/60000 (97.61%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2121,                   Accuracy: 56466/60000 (94.11%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5697,                   Accuracy: 50831/60000 (84.72%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0421,                   Accuracy: 43419/60000 (72.36%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.3620,                   Accuracy: 37962/60000 (63.27%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2142,                   Accuracy: 38771/60000 (64.62%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8158,                   Accuracy: 44852/60000 (74.75%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6505,                   Accuracy: 47901/60000 (79.83%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7159,                   Accuracy: 47605/60000 (79.34%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.1596,                   Accuracy: 42244/60000 (70.41%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.8713,                   Accuracy: 35044/60000 (58.41%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.8968,                   Accuracy: 27021/60000 (45.03%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.6335,                   Accuracy: 21545/60000 (35.91%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.9856,                   Accuracy: 19951/60000 (33.25%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8408,                   Accuracy: 21864/60000 (36.44%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5716,                   Accuracy: 26272/60000 (43.79%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5905,                   Accuracy: 28754/60000 (47.92%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.5476,                   Accuracy: 29541/60000 (49.24%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.5635,                   Accuracy: 29852/60000 (49.75%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7199,                   Accuracy: 27434/60000 (45.72%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9116,                   Accuracy: 23966/60000 (39.94%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.8816,                   Accuracy: 22304/60000 (37.17%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.4432,                   Accuracy: 22965/60000 (38.28%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.5535,                   Accuracy: 27548/60000 (45.91%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.6733,                   Accuracy: 34911/60000 (58.19%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.0670,                   Accuracy: 40319/60000 (67.20%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7762,                   Accuracy: 44617/60000 (74.36%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.9032,                   Accuracy: 42563/60000 (70.94%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.2023,                   Accuracy: 37061/60000 (61.77%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.5571,                   Accuracy: 32885/60000 (54.81%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.5833,                   Accuracy: 33849/60000 (56.42%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3350,                   Accuracy: 38932/60000 (64.89%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7343,                   Accuracy: 47808/60000 (79.68%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2415,                   Accuracy: 55610/60000 (92.68%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0818,                   Accuracy: 58491/60000 (97.49%)
{0: tensor(98.4267), 10: tensor(97.6150), 20: tensor(94.1100), 30: tensor(84.7183), 40: tensor(72.3650), 50: tensor(63.2700), 60: tensor(64.6183), 70: tensor(74.7533), 80: tensor(79.8350), 90: tensor(79.3417), 100: tensor(70.4067), 110: tensor(58.4067), 120: tensor(45.0350), 130: tensor(35.9083), 140: tensor(33.2517), 150: tensor(36.4400), 160: tensor(43.7867), 170: tensor(47.9233), 180: tensor(49.2350), 190: tensor(49.7533), 200: tensor(45.7233), 210: tensor(39.9433), 220: tensor(37.1733), 230: tensor(38.2750), 240: tensor(45.9133), 250: tensor(58.1850), 260: tensor(67.1983), 270: tensor(74.3617), 280: tensor(70.9383), 290: tensor(61.7683), 300: tensor(54.8083), 310: tensor(56.4150), 320: tensor(64.8867), 330: tensor(79.6800), 340: tensor(92.6833), 350: tensor(97.4850)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=47, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4799,                   Accuracy: 308/2000.0 (15.40%)



-= Testing valid =-
Test set: Average loss: 1.7556,                   Accuracy: 689/2000.0 (34.45%)



-= Testing valid =-
Test set: Average loss: 1.5907,                   Accuracy: 981/2000.0 (49.05%)



-= Testing valid =-
Test set: Average loss: 0.8523,                   Accuracy: 1462/2000.0 (73.10%)



-= Testing valid =-
Test set: Average loss: 0.3994,                   Accuracy: 1755/2000.0 (87.75%)



-= Testing valid =-
Test set: Average loss: 0.6334,                   Accuracy: 1603/2000.0 (80.15%)



-= Testing valid =-
Test set: Average loss: 0.2460,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.1217,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1059,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.2173,                   Accuracy: 1871/2000.0 (93.55%)



Epoch 10 train accuracy: 98.30%, valid accuracy 93.55%
-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.1737,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0650,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0596,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.1388,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 20 train accuracy: 98.95%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 30 train accuracy: 99.43%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0655,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0657,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0585,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0606,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0626,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 40 train accuracy: 99.55%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0593,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0684,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0637,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 50 train accuracy: 99.70%, valid accuracy 98.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0672,                   Accuracy: 58899/60000 (98.17%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0953,                   Accuracy: 58410/60000 (97.35%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2276,                   Accuracy: 56291/60000 (93.82%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6073,                   Accuracy: 50172/60000 (83.62%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0282,                   Accuracy: 43561/60000 (72.60%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2092,                   Accuracy: 40501/60000 (67.50%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0235,                   Accuracy: 42787/60000 (71.31%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6937,                   Accuracy: 48275/60000 (80.46%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4759,                   Accuracy: 51519/60000 (85.86%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4872,                   Accuracy: 50638/60000 (84.40%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8211,                   Accuracy: 44783/60000 (74.64%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3677,                   Accuracy: 37787/60000 (62.98%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.1105,                   Accuracy: 30342/60000 (50.57%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.9045,                   Accuracy: 24635/60000 (41.06%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3306,                   Accuracy: 23487/60000 (39.15%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4191,                   Accuracy: 25214/60000 (42.02%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4115,                   Accuracy: 28002/60000 (46.67%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.3503,                   Accuracy: 29683/60000 (49.47%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.3018,                   Accuracy: 29869/60000 (49.78%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.7390,                   Accuracy: 28596/60000 (47.66%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.0521,                   Accuracy: 25914/60000 (43.19%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.2242,                   Accuracy: 23243/60000 (38.74%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.9877,                   Accuracy: 22413/60000 (37.35%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.3617,                   Accuracy: 24927/60000 (41.54%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3857,                   Accuracy: 30532/60000 (50.89%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.5578,                   Accuracy: 36747/60000 (61.24%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9505,                   Accuracy: 42825/60000 (71.38%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5669,                   Accuracy: 47883/60000 (79.81%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6333,                   Accuracy: 46367/60000 (77.28%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8171,                   Accuracy: 42818/60000 (71.36%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0561,                   Accuracy: 40066/60000 (66.78%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1591,                   Accuracy: 39153/60000 (65.25%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9550,                   Accuracy: 42893/60000 (71.49%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5559,                   Accuracy: 49664/60000 (82.77%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2042,                   Accuracy: 56188/60000 (93.65%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0887,                   Accuracy: 58371/60000 (97.29%)
{0: tensor(98.1650), 10: tensor(97.3500), 20: tensor(93.8183), 30: tensor(83.6200), 40: tensor(72.6017), 50: tensor(67.5017), 60: tensor(71.3117), 70: tensor(80.4583), 80: tensor(85.8650), 90: tensor(84.3967), 100: tensor(74.6383), 110: tensor(62.9783), 120: tensor(50.5700), 130: tensor(41.0583), 140: tensor(39.1450), 150: tensor(42.0233), 160: tensor(46.6700), 170: tensor(49.4717), 180: tensor(49.7817), 190: tensor(47.6600), 200: tensor(43.1900), 210: tensor(38.7383), 220: tensor(37.3550), 230: tensor(41.5450), 240: tensor(50.8867), 250: tensor(61.2450), 260: tensor(71.3750), 270: tensor(79.8050), 280: tensor(77.2783), 290: tensor(71.3633), 300: tensor(66.7767), 310: tensor(65.2550), 320: tensor(71.4883), 330: tensor(82.7733), 340: tensor(93.6467), 350: tensor(97.2850)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=48, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.9590,                   Accuracy: 218/2000.0 (10.90%)



-= Testing valid =-
Test set: Average loss: 1.3830,                   Accuracy: 1030/2000.0 (51.50%)



-= Testing valid =-
Test set: Average loss: 1.4611,                   Accuracy: 830/2000.0 (41.50%)



-= Testing valid =-
Test set: Average loss: 1.0445,                   Accuracy: 1469/2000.0 (73.45%)



-= Testing valid =-
Test set: Average loss: 0.9188,                   Accuracy: 1458/2000.0 (72.90%)



-= Testing valid =-
Test set: Average loss: 0.1567,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1598,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.1566,                   Accuracy: 1909/2000.0 (95.45%)



Epoch 10 train accuracy: 97.76%, valid accuracy 95.45%
-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 20 train accuracy: 98.96%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0251,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 30 train accuracy: 99.39%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 40 train accuracy: 99.47%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 50 train accuracy: 99.57%, valid accuracy 99.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0487,                   Accuracy: 59145/60000 (98.57%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0804,                   Accuracy: 58634/60000 (97.72%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1739,                   Accuracy: 56981/60000 (94.97%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4092,                   Accuracy: 53004/60000 (88.34%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7699,                   Accuracy: 46869/60000 (78.11%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9830,                   Accuracy: 42999/60000 (71.67%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9575,                   Accuracy: 43176/60000 (71.96%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6962,                   Accuracy: 47296/60000 (78.83%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5974,                   Accuracy: 48660/60000 (81.10%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7366,                   Accuracy: 46516/60000 (77.53%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0358,                   Accuracy: 42512/60000 (70.85%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.7408,                   Accuracy: 35135/60000 (58.56%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.7442,                   Accuracy: 28106/60000 (46.84%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.5550,                   Accuracy: 24618/60000 (41.03%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.9839,                   Accuracy: 23919/60000 (39.87%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.1942,                   Accuracy: 24448/60000 (40.75%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.1342,                   Accuracy: 26349/60000 (43.92%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.1098,                   Accuracy: 27365/60000 (45.61%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.3274,                   Accuracy: 27421/60000 (45.70%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.1901,                   Accuracy: 27556/60000 (45.93%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.2293,                   Accuracy: 26671/60000 (44.45%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.4201,                   Accuracy: 25191/60000 (41.99%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.0904,                   Accuracy: 24616/60000 (41.03%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.5315,                   Accuracy: 25730/60000 (42.88%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.7485,                   Accuracy: 28793/60000 (47.99%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.8259,                   Accuracy: 34921/60000 (58.20%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.2155,                   Accuracy: 40148/60000 (66.91%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.8753,                   Accuracy: 43825/60000 (73.04%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.8140,                   Accuracy: 43463/60000 (72.44%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9990,                   Accuracy: 40092/60000 (66.82%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2860,                   Accuracy: 36035/60000 (60.06%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3772,                   Accuracy: 34914/60000 (58.19%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1910,                   Accuracy: 38824/60000 (64.71%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7217,                   Accuracy: 47110/60000 (78.52%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2497,                   Accuracy: 55388/60000 (92.31%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0825,                   Accuracy: 58510/60000 (97.52%)
{0: tensor(98.5750), 10: tensor(97.7233), 20: tensor(94.9683), 30: tensor(88.3400), 40: tensor(78.1150), 50: tensor(71.6650), 60: tensor(71.9600), 70: tensor(78.8267), 80: tensor(81.1000), 90: tensor(77.5267), 100: tensor(70.8533), 110: tensor(58.5583), 120: tensor(46.8433), 130: tensor(41.0300), 140: tensor(39.8650), 150: tensor(40.7467), 160: tensor(43.9150), 170: tensor(45.6083), 180: tensor(45.7017), 190: tensor(45.9267), 200: tensor(44.4517), 210: tensor(41.9850), 220: tensor(41.0267), 230: tensor(42.8833), 240: tensor(47.9883), 250: tensor(58.2017), 260: tensor(66.9133), 270: tensor(73.0417), 280: tensor(72.4383), 290: tensor(66.8200), 300: tensor(60.0583), 310: tensor(58.1900), 320: tensor(64.7067), 330: tensor(78.5167), 340: tensor(92.3133), 350: tensor(97.5167)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=49, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0287,                   Accuracy: 313/2000.0 (15.65%)



-= Testing valid =-
Test set: Average loss: 1.3193,                   Accuracy: 936/2000.0 (46.80%)



-= Testing valid =-
Test set: Average loss: 0.3755,                   Accuracy: 1752/2000.0 (87.60%)



-= Testing valid =-
Test set: Average loss: 0.5267,                   Accuracy: 1632/2000.0 (81.60%)



-= Testing valid =-
Test set: Average loss: 0.1652,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.2847,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.1827,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.2886,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2553,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.2354,                   Accuracy: 1844/2000.0 (92.20%)



Epoch 10 train accuracy: 98.36%, valid accuracy 92.20%
-= Testing valid =-
Test set: Average loss: 0.0575,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.1160,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.1017,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 20 train accuracy: 99.22%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0704,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0578,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 30 train accuracy: 99.54%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0477,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 40 train accuracy: 99.65%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0496,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 50 train accuracy: 99.69%, valid accuracy 98.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0608,                   Accuracy: 58897/60000 (98.16%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0920,                   Accuracy: 58384/60000 (97.31%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1834,                   Accuracy: 56818/60000 (94.70%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4321,                   Accuracy: 52273/60000 (87.12%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8315,                   Accuracy: 44954/60000 (74.92%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0816,                   Accuracy: 40410/60000 (67.35%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0011,                   Accuracy: 41489/60000 (69.15%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7704,                   Accuracy: 45115/60000 (75.19%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5510,                   Accuracy: 48943/60000 (81.57%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4063,                   Accuracy: 51799/60000 (86.33%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6274,                   Accuracy: 47342/60000 (78.90%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.0229,                   Accuracy: 40997/60000 (68.33%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.6675,                   Accuracy: 32779/60000 (54.63%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.3454,                   Accuracy: 26303/60000 (43.84%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.8027,                   Accuracy: 24339/60000 (40.56%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.0354,                   Accuracy: 25296/60000 (42.16%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.0920,                   Accuracy: 27673/60000 (46.12%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.2448,                   Accuracy: 30054/60000 (50.09%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.3838,                   Accuracy: 31117/60000 (51.86%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4486,                   Accuracy: 30602/60000 (51.00%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.4272,                   Accuracy: 29184/60000 (48.64%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4180,                   Accuracy: 26751/60000 (44.58%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.2952,                   Accuracy: 24445/60000 (40.74%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9433,                   Accuracy: 24796/60000 (41.33%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3011,                   Accuracy: 28063/60000 (46.77%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.6106,                   Accuracy: 33414/60000 (55.69%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.0900,                   Accuracy: 38962/60000 (64.94%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7362,                   Accuracy: 44046/60000 (73.41%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7254,                   Accuracy: 44698/60000 (74.50%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8869,                   Accuracy: 42245/60000 (70.41%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1821,                   Accuracy: 38347/60000 (63.91%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3230,                   Accuracy: 36599/60000 (61.00%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2535,                   Accuracy: 38158/60000 (63.60%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8264,                   Accuracy: 45159/60000 (75.26%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3343,                   Accuracy: 53492/60000 (89.15%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1185,                   Accuracy: 57757/60000 (96.26%)
{0: tensor(98.1617), 10: tensor(97.3067), 20: tensor(94.6967), 30: tensor(87.1217), 40: tensor(74.9233), 50: tensor(67.3500), 60: tensor(69.1483), 70: tensor(75.1917), 80: tensor(81.5717), 90: tensor(86.3317), 100: tensor(78.9033), 110: tensor(68.3283), 120: tensor(54.6317), 130: tensor(43.8383), 140: tensor(40.5650), 150: tensor(42.1600), 160: tensor(46.1217), 170: tensor(50.0900), 180: tensor(51.8617), 190: tensor(51.0033), 200: tensor(48.6400), 210: tensor(44.5850), 220: tensor(40.7417), 230: tensor(41.3267), 240: tensor(46.7717), 250: tensor(55.6900), 260: tensor(64.9367), 270: tensor(73.4100), 280: tensor(74.4967), 290: tensor(70.4083), 300: tensor(63.9117), 310: tensor(60.9983), 320: tensor(63.5967), 330: tensor(75.2650), 340: tensor(89.1533), 350: tensor(96.2617)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=50, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9584,                   Accuracy: 631/2000.0 (31.55%)



-= Testing valid =-
Test set: Average loss: 1.3376,                   Accuracy: 1099/2000.0 (54.95%)



-= Testing valid =-
Test set: Average loss: 1.0168,                   Accuracy: 1352/2000.0 (67.60%)



-= Testing valid =-
Test set: Average loss: 0.2256,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1647,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1850,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.4929,                   Accuracy: 1661/2000.0 (83.05%)



-= Testing valid =-
Test set: Average loss: 0.1938,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1237,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1457,                   Accuracy: 1915/2000.0 (95.75%)



Epoch 10 train accuracy: 98.29%, valid accuracy 95.75%
-= Testing valid =-
Test set: Average loss: 0.4237,                   Accuracy: 1714/2000.0 (85.70%)



-= Testing valid =-
Test set: Average loss: 0.1094,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.2283,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.1725,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.1502,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 20 train accuracy: 99.07%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0590,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.1548,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0477,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.1192,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1578,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.1584,                   Accuracy: 1867/2000.0 (93.35%)



Epoch 30 train accuracy: 99.44%, valid accuracy 93.35%
-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0409,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 40 train accuracy: 99.60%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0523,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0554,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0445,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0555,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 50 train accuracy: 99.66%, valid accuracy 98.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0608,                   Accuracy: 58945/60000 (98.24%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1173,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2851,                   Accuracy: 54964/60000 (91.61%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5739,                   Accuracy: 50197/60000 (83.66%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0873,                   Accuracy: 42003/60000 (70.00%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.4192,                   Accuracy: 36867/60000 (61.44%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.3363,                   Accuracy: 37697/60000 (62.83%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.0259,                   Accuracy: 42042/60000 (70.07%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6813,                   Accuracy: 47549/60000 (79.25%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5677,                   Accuracy: 49429/60000 (82.38%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8529,                   Accuracy: 44545/60000 (74.24%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.4645,                   Accuracy: 37189/60000 (61.98%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5302,                   Accuracy: 29259/60000 (48.76%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.1704,                   Accuracy: 24813/60000 (41.35%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.6283,                   Accuracy: 23506/60000 (39.18%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8499,                   Accuracy: 25486/60000 (42.48%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.7672,                   Accuracy: 28661/60000 (47.77%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.9943,                   Accuracy: 30234/60000 (50.39%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.2380,                   Accuracy: 31596/60000 (52.66%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.3738,                   Accuracy: 30653/60000 (51.09%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.3130,                   Accuracy: 28980/60000 (48.30%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.6007,                   Accuracy: 25531/60000 (42.55%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.3278,                   Accuracy: 22989/60000 (38.31%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.8464,                   Accuracy: 22368/60000 (37.28%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.9901,                   Accuracy: 25088/60000 (41.81%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.0978,                   Accuracy: 29387/60000 (48.98%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.3870,                   Accuracy: 34948/60000 (58.25%)
-= Testing Rotation 270 =-
Test set: Average loss: 1.0320,                   Accuracy: 40530/60000 (67.55%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.2100,                   Accuracy: 37967/60000 (63.28%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.4622,                   Accuracy: 34663/60000 (57.77%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.8126,                   Accuracy: 33304/60000 (55.51%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.8447,                   Accuracy: 32702/60000 (54.50%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.5177,                   Accuracy: 37263/60000 (62.10%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8306,                   Accuracy: 47059/60000 (78.43%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2740,                   Accuracy: 55191/60000 (91.99%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1056,                   Accuracy: 58078/60000 (96.80%)
{0: tensor(98.2417), 10: tensor(96.6150), 20: tensor(91.6067), 30: tensor(83.6617), 40: tensor(70.0050), 50: tensor(61.4450), 60: tensor(62.8283), 70: tensor(70.0700), 80: tensor(79.2483), 90: tensor(82.3817), 100: tensor(74.2417), 110: tensor(61.9817), 120: tensor(48.7650), 130: tensor(41.3550), 140: tensor(39.1767), 150: tensor(42.4767), 160: tensor(47.7683), 170: tensor(50.3900), 180: tensor(52.6600), 190: tensor(51.0883), 200: tensor(48.3000), 210: tensor(42.5517), 220: tensor(38.3150), 230: tensor(37.2800), 240: tensor(41.8133), 250: tensor(48.9783), 260: tensor(58.2467), 270: tensor(67.5500), 280: tensor(63.2783), 290: tensor(57.7717), 300: tensor(55.5067), 310: tensor(54.5033), 320: tensor(62.1050), 330: tensor(78.4317), 340: tensor(91.9850), 350: tensor(96.7967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=51, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0816,                   Accuracy: 426/2000.0 (21.30%)



-= Testing valid =-
Test set: Average loss: 1.2388,                   Accuracy: 1011/2000.0 (50.55%)



-= Testing valid =-
Test set: Average loss: 0.4434,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.3898,                   Accuracy: 1745/2000.0 (87.25%)



-= Testing valid =-
Test set: Average loss: 0.3193,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0472,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 10 train accuracy: 98.39%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 20 train accuracy: 99.05%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0226,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.39%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0213,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0219,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0251,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 40 train accuracy: 99.57%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0221,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0219,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.82%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0455,                   Accuracy: 59230/60000 (98.72%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0705,                   Accuracy: 58756/60000 (97.93%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1500,                   Accuracy: 57340/60000 (95.57%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4314,                   Accuracy: 52582/60000 (87.64%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8696,                   Accuracy: 45597/60000 (76.00%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1279,                   Accuracy: 40907/60000 (68.18%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0658,                   Accuracy: 41246/60000 (68.74%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7865,                   Accuracy: 45161/60000 (75.27%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7298,                   Accuracy: 45850/60000 (76.42%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.8445,                   Accuracy: 44178/60000 (73.63%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.2295,                   Accuracy: 38665/60000 (64.44%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.9250,                   Accuracy: 32138/60000 (53.56%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.8360,                   Accuracy: 25535/60000 (42.56%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.3164,                   Accuracy: 22784/60000 (37.97%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.4502,                   Accuracy: 22900/60000 (38.17%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.2875,                   Accuracy: 25093/60000 (41.82%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.1167,                   Accuracy: 28421/60000 (47.37%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.2165,                   Accuracy: 29931/60000 (49.88%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.3881,                   Accuracy: 29795/60000 (49.66%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.5075,                   Accuracy: 28849/60000 (48.08%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.6746,                   Accuracy: 26886/60000 (44.81%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.8766,                   Accuracy: 24425/60000 (40.71%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.5118,                   Accuracy: 24951/60000 (41.58%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8383,                   Accuracy: 27980/60000 (46.63%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.8987,                   Accuracy: 34399/60000 (57.33%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0845,                   Accuracy: 42770/60000 (71.28%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6583,                   Accuracy: 48068/60000 (80.11%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4489,                   Accuracy: 51197/60000 (85.33%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5546,                   Accuracy: 49285/60000 (82.14%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7486,                   Accuracy: 45984/60000 (76.64%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0515,                   Accuracy: 41085/60000 (68.47%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1723,                   Accuracy: 38947/60000 (64.91%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9940,                   Accuracy: 43016/60000 (71.69%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5426,                   Accuracy: 50574/60000 (84.29%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1891,                   Accuracy: 56682/60000 (94.47%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0709,                   Accuracy: 58754/60000 (97.92%)
{0: tensor(98.7167), 10: tensor(97.9267), 20: tensor(95.5667), 30: tensor(87.6367), 40: tensor(75.9950), 50: tensor(68.1783), 60: tensor(68.7433), 70: tensor(75.2683), 80: tensor(76.4167), 90: tensor(73.6300), 100: tensor(64.4417), 110: tensor(53.5633), 120: tensor(42.5583), 130: tensor(37.9733), 140: tensor(38.1667), 150: tensor(41.8217), 160: tensor(47.3683), 170: tensor(49.8850), 180: tensor(49.6583), 190: tensor(48.0817), 200: tensor(44.8100), 210: tensor(40.7083), 220: tensor(41.5850), 230: tensor(46.6333), 240: tensor(57.3317), 250: tensor(71.2833), 260: tensor(80.1133), 270: tensor(85.3283), 280: tensor(82.1417), 290: tensor(76.6400), 300: tensor(68.4750), 310: tensor(64.9117), 320: tensor(71.6933), 330: tensor(84.2900), 340: tensor(94.4700), 350: tensor(97.9233)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=52, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.5105,                   Accuracy: 182/2000.0 (9.10%)



-= Testing valid =-
Test set: Average loss: 1.2861,                   Accuracy: 1167/2000.0 (58.35%)



-= Testing valid =-
Test set: Average loss: 0.9303,                   Accuracy: 1283/2000.0 (64.15%)



-= Testing valid =-
Test set: Average loss: 0.1897,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 1.0102,                   Accuracy: 1334/2000.0 (66.70%)



-= Testing valid =-
Test set: Average loss: 0.1272,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1160,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.1353,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 10 train accuracy: 98.06%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.2309,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.3870,                   Accuracy: 1731/2000.0 (86.55%)



-= Testing valid =-
Test set: Average loss: 0.0568,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.3210,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.2691,                   Accuracy: 1780/2000.0 (89.00%)



-= Testing valid =-
Test set: Average loss: 0.1299,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.3667,                   Accuracy: 1765/2000.0 (88.25%)



-= Testing valid =-
Test set: Average loss: 0.6355,                   Accuracy: 1684/2000.0 (84.20%)



Epoch 20 train accuracy: 99.16%, valid accuracy 84.20%
-= Testing valid =-
Test set: Average loss: 0.2634,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3459,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.2364,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.3445,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.2062,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.1307,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1367,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1964,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.61%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.1321,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0720,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.1341,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1275,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1068,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 40 train accuracy: 99.62%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1129,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1072,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1467,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1097,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 50 train accuracy: 99.78%, valid accuracy 96.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0492,                   Accuracy: 59150/60000 (98.58%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0893,                   Accuracy: 58452/60000 (97.42%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2563,                   Accuracy: 55282/60000 (92.14%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6445,                   Accuracy: 48423/60000 (80.71%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.1031,                   Accuracy: 40194/60000 (66.99%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.3489,                   Accuracy: 35355/60000 (58.92%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1240,                   Accuracy: 37982/60000 (63.30%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7830,                   Accuracy: 43335/60000 (72.22%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6433,                   Accuracy: 45668/60000 (76.11%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6606,                   Accuracy: 45924/60000 (76.54%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0530,                   Accuracy: 38973/60000 (64.96%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.9534,                   Accuracy: 29389/60000 (48.98%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.9414,                   Accuracy: 22677/60000 (37.79%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.6296,                   Accuracy: 20079/60000 (33.47%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.8720,                   Accuracy: 19540/60000 (32.57%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.6131,                   Accuracy: 22678/60000 (37.80%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.2580,                   Accuracy: 27409/60000 (45.68%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.1441,                   Accuracy: 31066/60000 (51.78%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.1717,                   Accuracy: 32077/60000 (53.46%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.2513,                   Accuracy: 31156/60000 (51.93%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.5700,                   Accuracy: 28107/60000 (46.85%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7755,                   Accuracy: 24050/60000 (40.08%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.5492,                   Accuracy: 22278/60000 (37.13%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9121,                   Accuracy: 24735/60000 (41.22%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9614,                   Accuracy: 31915/60000 (53.19%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1332,                   Accuracy: 41346/60000 (68.91%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6467,                   Accuracy: 47674/60000 (79.46%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4181,                   Accuracy: 51288/60000 (85.48%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5908,                   Accuracy: 47553/60000 (79.25%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0292,                   Accuracy: 40711/60000 (67.85%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.5678,                   Accuracy: 34926/60000 (58.21%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.7893,                   Accuracy: 33622/60000 (56.04%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.6478,                   Accuracy: 37340/60000 (62.23%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9055,                   Accuracy: 46678/60000 (77.80%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2691,                   Accuracy: 55430/60000 (92.38%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0811,                   Accuracy: 58554/60000 (97.59%)
{0: tensor(98.5833), 10: tensor(97.4200), 20: tensor(92.1367), 30: tensor(80.7050), 40: tensor(66.9900), 50: tensor(58.9250), 60: tensor(63.3033), 70: tensor(72.2250), 80: tensor(76.1133), 90: tensor(76.5400), 100: tensor(64.9550), 110: tensor(48.9817), 120: tensor(37.7950), 130: tensor(33.4650), 140: tensor(32.5667), 150: tensor(37.7967), 160: tensor(45.6817), 170: tensor(51.7767), 180: tensor(53.4617), 190: tensor(51.9267), 200: tensor(46.8450), 210: tensor(40.0833), 220: tensor(37.1300), 230: tensor(41.2250), 240: tensor(53.1917), 250: tensor(68.9100), 260: tensor(79.4567), 270: tensor(85.4800), 280: tensor(79.2550), 290: tensor(67.8517), 300: tensor(58.2100), 310: tensor(56.0367), 320: tensor(62.2333), 330: tensor(77.7967), 340: tensor(92.3833), 350: tensor(97.5900)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=53, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.6716,                   Accuracy: 641/2000.0 (32.05%)



-= Testing valid =-
Test set: Average loss: 1.1149,                   Accuracy: 1102/2000.0 (55.10%)



-= Testing valid =-
Test set: Average loss: 1.5642,                   Accuracy: 1013/2000.0 (50.65%)



-= Testing valid =-
Test set: Average loss: 0.5457,                   Accuracy: 1672/2000.0 (83.60%)



-= Testing valid =-
Test set: Average loss: 0.1831,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.2433,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.1650,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1298,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1363,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.2249,                   Accuracy: 1871/2000.0 (93.55%)



Epoch 10 train accuracy: 98.35%, valid accuracy 93.55%
-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1129,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0655,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 20 train accuracy: 98.78%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0619,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 30 train accuracy: 99.45%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0496,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 40 train accuracy: 99.49%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.71%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0517,                   Accuracy: 59129/60000 (98.55%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0785,                   Accuracy: 58669/60000 (97.78%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1960,                   Accuracy: 56661/60000 (94.43%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4861,                   Accuracy: 51826/60000 (86.38%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8895,                   Accuracy: 44890/60000 (74.82%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0411,                   Accuracy: 42279/60000 (70.46%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8949,                   Accuracy: 44576/60000 (74.29%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.5994,                   Accuracy: 49490/60000 (82.48%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4144,                   Accuracy: 52587/60000 (87.64%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3838,                   Accuracy: 53150/60000 (88.58%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6023,                   Accuracy: 48825/60000 (81.38%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1153,                   Accuracy: 41240/60000 (68.73%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.9323,                   Accuracy: 31572/60000 (52.62%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.5761,                   Accuracy: 25728/60000 (42.88%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.9139,                   Accuracy: 24454/60000 (40.76%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.0158,                   Accuracy: 25559/60000 (42.60%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.9570,                   Accuracy: 28969/60000 (48.28%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.9953,                   Accuracy: 31281/60000 (52.13%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.0043,                   Accuracy: 32926/60000 (54.88%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.0188,                   Accuracy: 32441/60000 (54.07%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.2803,                   Accuracy: 30095/60000 (50.16%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.5677,                   Accuracy: 26090/60000 (43.48%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.4000,                   Accuracy: 24469/60000 (40.78%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8271,                   Accuracy: 26255/60000 (43.76%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9509,                   Accuracy: 31813/60000 (53.02%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1757,                   Accuracy: 40352/60000 (67.25%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7095,                   Accuracy: 46646/60000 (77.74%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4481,                   Accuracy: 51032/60000 (85.05%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4929,                   Accuracy: 50441/60000 (84.07%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6698,                   Accuracy: 47185/60000 (78.64%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9239,                   Accuracy: 42937/60000 (71.56%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9998,                   Accuracy: 41303/60000 (68.84%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8482,                   Accuracy: 44366/60000 (73.94%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4756,                   Accuracy: 51074/60000 (85.12%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1758,                   Accuracy: 56778/60000 (94.63%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0729,                   Accuracy: 58703/60000 (97.84%)
{0: tensor(98.5483), 10: tensor(97.7817), 20: tensor(94.4350), 30: tensor(86.3767), 40: tensor(74.8167), 50: tensor(70.4650), 60: tensor(74.2933), 70: tensor(82.4833), 80: tensor(87.6450), 90: tensor(88.5833), 100: tensor(81.3750), 110: tensor(68.7333), 120: tensor(52.6200), 130: tensor(42.8800), 140: tensor(40.7567), 150: tensor(42.5983), 160: tensor(48.2817), 170: tensor(52.1350), 180: tensor(54.8767), 190: tensor(54.0683), 200: tensor(50.1583), 210: tensor(43.4833), 220: tensor(40.7817), 230: tensor(43.7583), 240: tensor(53.0217), 250: tensor(67.2533), 260: tensor(77.7433), 270: tensor(85.0533), 280: tensor(84.0683), 290: tensor(78.6417), 300: tensor(71.5617), 310: tensor(68.8383), 320: tensor(73.9433), 330: tensor(85.1233), 340: tensor(94.6300), 350: tensor(97.8383)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=54, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.1217,                   Accuracy: 219/2000.0 (10.95%)



-= Testing valid =-
Test set: Average loss: 1.3871,                   Accuracy: 1010/2000.0 (50.50%)



-= Testing valid =-
Test set: Average loss: 0.6800,                   Accuracy: 1626/2000.0 (81.30%)



-= Testing valid =-
Test set: Average loss: 0.3445,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.2860,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2510,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2248,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.2157,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1244,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1380,                   Accuracy: 1928/2000.0 (96.40%)



Epoch 10 train accuracy: 97.61%, valid accuracy 96.40%
-= Testing valid =-
Test set: Average loss: 0.1042,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1080,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1246,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0593,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 20 train accuracy: 98.99%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 30 train accuracy: 99.35%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0575,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0647,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 40 train accuracy: 99.55%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0590,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0555,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 50 train accuracy: 99.66%, valid accuracy 98.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0708,                   Accuracy: 58779/60000 (97.96%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1340,                   Accuracy: 57765/60000 (96.28%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3111,                   Accuracy: 54769/60000 (91.28%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6992,                   Accuracy: 48536/60000 (80.89%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3014,                   Accuracy: 40262/60000 (67.10%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.6836,                   Accuracy: 34583/60000 (57.64%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.6605,                   Accuracy: 33781/60000 (56.30%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.4372,                   Accuracy: 36199/60000 (60.33%)
-= Testing Rotation 80 =-
Test set: Average loss: 1.1464,                   Accuracy: 40212/60000 (67.02%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.9459,                   Accuracy: 42792/60000 (71.32%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.3604,                   Accuracy: 36521/60000 (60.87%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.8672,                   Accuracy: 31766/60000 (52.94%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5028,                   Accuracy: 25849/60000 (43.08%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.2880,                   Accuracy: 21602/60000 (36.00%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.7314,                   Accuracy: 21061/60000 (35.10%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.0169,                   Accuracy: 23072/60000 (38.45%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.1958,                   Accuracy: 25703/60000 (42.84%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.2465,                   Accuracy: 27677/60000 (46.13%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.1888,                   Accuracy: 28665/60000 (47.78%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.3240,                   Accuracy: 27396/60000 (45.66%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.3362,                   Accuracy: 25149/60000 (41.92%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.5986,                   Accuracy: 21904/60000 (36.51%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.7082,                   Accuracy: 19933/60000 (33.22%)
-= Testing Rotation 230 =-
Test set: Average loss: 4.2917,                   Accuracy: 20816/60000 (34.69%)
-= Testing Rotation 240 =-
Test set: Average loss: 3.4091,                   Accuracy: 24442/60000 (40.74%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.3254,                   Accuracy: 29522/60000 (49.20%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.5392,                   Accuracy: 35459/60000 (59.10%)
-= Testing Rotation 270 =-
Test set: Average loss: 1.0607,                   Accuracy: 41479/60000 (69.13%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.2618,                   Accuracy: 37423/60000 (62.37%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.4995,                   Accuracy: 34557/60000 (57.60%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.7011,                   Accuracy: 31394/60000 (52.32%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.7411,                   Accuracy: 31485/60000 (52.47%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3619,                   Accuracy: 36509/60000 (60.85%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7503,                   Accuracy: 46438/60000 (77.40%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3089,                   Accuracy: 54395/60000 (90.66%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1176,                   Accuracy: 57942/60000 (96.57%)
{0: tensor(97.9650), 10: tensor(96.2750), 20: tensor(91.2817), 30: tensor(80.8933), 40: tensor(67.1033), 50: tensor(57.6383), 60: tensor(56.3017), 70: tensor(60.3317), 80: tensor(67.0200), 90: tensor(71.3200), 100: tensor(60.8683), 110: tensor(52.9433), 120: tensor(43.0817), 130: tensor(36.0033), 140: tensor(35.1017), 150: tensor(38.4533), 160: tensor(42.8383), 170: tensor(46.1283), 180: tensor(47.7750), 190: tensor(45.6600), 200: tensor(41.9150), 210: tensor(36.5067), 220: tensor(33.2217), 230: tensor(34.6933), 240: tensor(40.7367), 250: tensor(49.2033), 260: tensor(59.0983), 270: tensor(69.1317), 280: tensor(62.3717), 290: tensor(57.5950), 300: tensor(52.3233), 310: tensor(52.4750), 320: tensor(60.8483), 330: tensor(77.3967), 340: tensor(90.6583), 350: tensor(96.5700)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=55, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9339,                   Accuracy: 538/2000.0 (26.90%)



-= Testing valid =-
Test set: Average loss: 0.7345,                   Accuracy: 1535/2000.0 (76.75%)



-= Testing valid =-
Test set: Average loss: 0.2655,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1745,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1957,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1088,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1103,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1459,                   Accuracy: 1908/2000.0 (95.40%)



Epoch 10 train accuracy: 98.31%, valid accuracy 95.40%
-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0620,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0798,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 20 train accuracy: 99.03%, valid accuracy 99.30%
-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 30 train accuracy: 99.40%, valid accuracy 99.30%
-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 40 train accuracy: 99.65%, valid accuracy 99.35%
-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0223,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1988/2000.0 (99.40%)



Epoch 50 train accuracy: 99.72%, valid accuracy 99.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0467,                   Accuracy: 59178/60000 (98.63%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0739,                   Accuracy: 58699/60000 (97.83%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1623,                   Accuracy: 57241/60000 (95.40%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3720,                   Accuracy: 53684/60000 (89.47%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7296,                   Accuracy: 47451/60000 (79.08%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9437,                   Accuracy: 43377/60000 (72.29%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9074,                   Accuracy: 43384/60000 (72.31%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7546,                   Accuracy: 45286/60000 (75.48%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5298,                   Accuracy: 49402/60000 (82.34%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4528,                   Accuracy: 50899/60000 (84.83%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7040,                   Accuracy: 46681/60000 (77.80%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2173,                   Accuracy: 39693/60000 (66.15%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.8881,                   Accuracy: 32107/60000 (53.51%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.7048,                   Accuracy: 26104/60000 (43.51%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.1776,                   Accuracy: 24836/60000 (41.39%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.3696,                   Accuracy: 25704/60000 (42.84%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4139,                   Accuracy: 28193/60000 (46.99%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5097,                   Accuracy: 28643/60000 (47.74%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.4539,                   Accuracy: 28890/60000 (48.15%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4667,                   Accuracy: 28485/60000 (47.47%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.5489,                   Accuracy: 26542/60000 (44.24%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7080,                   Accuracy: 24203/60000 (40.34%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.5089,                   Accuracy: 23717/60000 (39.53%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8841,                   Accuracy: 26313/60000 (43.85%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.9702,                   Accuracy: 32439/60000 (54.06%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1531,                   Accuracy: 40219/60000 (67.03%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6236,                   Accuracy: 48013/60000 (80.02%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3473,                   Accuracy: 53123/60000 (88.54%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4236,                   Accuracy: 51622/60000 (86.04%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6050,                   Accuracy: 48172/60000 (80.29%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.8421,                   Accuracy: 43641/60000 (72.74%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0489,                   Accuracy: 40460/60000 (67.43%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9819,                   Accuracy: 42230/60000 (70.38%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6150,                   Accuracy: 48670/60000 (81.12%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2578,                   Accuracy: 55226/60000 (92.04%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0787,                   Accuracy: 58537/60000 (97.56%)
{0: tensor(98.6300), 10: tensor(97.8317), 20: tensor(95.4017), 30: tensor(89.4733), 40: tensor(79.0850), 50: tensor(72.2950), 60: tensor(72.3067), 70: tensor(75.4767), 80: tensor(82.3367), 90: tensor(84.8317), 100: tensor(77.8017), 110: tensor(66.1550), 120: tensor(53.5117), 130: tensor(43.5067), 140: tensor(41.3933), 150: tensor(42.8400), 160: tensor(46.9883), 170: tensor(47.7383), 180: tensor(48.1500), 190: tensor(47.4750), 200: tensor(44.2367), 210: tensor(40.3383), 220: tensor(39.5283), 230: tensor(43.8550), 240: tensor(54.0650), 250: tensor(67.0317), 260: tensor(80.0217), 270: tensor(88.5383), 280: tensor(86.0367), 290: tensor(80.2867), 300: tensor(72.7350), 310: tensor(67.4333), 320: tensor(70.3833), 330: tensor(81.1167), 340: tensor(92.0433), 350: tensor(97.5617)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=56, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0036,                   Accuracy: 470/2000.0 (23.50%)



-= Testing valid =-
Test set: Average loss: 1.5355,                   Accuracy: 1065/2000.0 (53.25%)



-= Testing valid =-
Test set: Average loss: 1.7945,                   Accuracy: 951/2000.0 (47.55%)



-= Testing valid =-
Test set: Average loss: 0.8147,                   Accuracy: 1446/2000.0 (72.30%)



-= Testing valid =-
Test set: Average loss: 0.2952,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.1934,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.7428,                   Accuracy: 1453/2000.0 (72.65%)



-= Testing valid =-
Test set: Average loss: 0.1256,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.4449,                   Accuracy: 1718/2000.0 (85.90%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 10 train accuracy: 97.46%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0450,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0572,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 20 train accuracy: 98.90%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.44%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.44%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0219,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0221,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.60%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0465,                   Accuracy: 59161/60000 (98.60%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0754,                   Accuracy: 58681/60000 (97.80%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1813,                   Accuracy: 56938/60000 (94.90%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3973,                   Accuracy: 53184/60000 (88.64%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7083,                   Accuracy: 47751/60000 (79.58%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9338,                   Accuracy: 43602/60000 (72.67%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8570,                   Accuracy: 44589/60000 (74.32%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6407,                   Accuracy: 48534/60000 (80.89%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5134,                   Accuracy: 50507/60000 (84.18%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5031,                   Accuracy: 50201/60000 (83.67%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8312,                   Accuracy: 44903/60000 (74.84%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.4192,                   Accuracy: 37261/60000 (62.10%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.3325,                   Accuracy: 28860/60000 (48.10%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.2637,                   Accuracy: 23984/60000 (39.97%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.7374,                   Accuracy: 22609/60000 (37.68%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8602,                   Accuracy: 23042/60000 (38.40%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5529,                   Accuracy: 25665/60000 (42.78%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.4552,                   Accuracy: 28142/60000 (46.90%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.5317,                   Accuracy: 29508/60000 (49.18%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4887,                   Accuracy: 29332/60000 (48.89%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.4819,                   Accuracy: 27138/60000 (45.23%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.8246,                   Accuracy: 23660/60000 (39.43%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7548,                   Accuracy: 21936/60000 (36.56%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2345,                   Accuracy: 22754/60000 (37.92%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2980,                   Accuracy: 27669/60000 (46.12%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2840,                   Accuracy: 38051/60000 (63.42%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7525,                   Accuracy: 45373/60000 (75.62%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4940,                   Accuracy: 50204/60000 (83.67%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5100,                   Accuracy: 50345/60000 (83.91%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7085,                   Accuracy: 46529/60000 (77.55%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1110,                   Accuracy: 41815/60000 (69.69%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1768,                   Accuracy: 41054/60000 (68.42%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0760,                   Accuracy: 43728/60000 (72.88%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6029,                   Accuracy: 50511/60000 (84.18%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2089,                   Accuracy: 56279/60000 (93.80%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0777,                   Accuracy: 58561/60000 (97.60%)
{0: tensor(98.6017), 10: tensor(97.8017), 20: tensor(94.8967), 30: tensor(88.6400), 40: tensor(79.5850), 50: tensor(72.6700), 60: tensor(74.3150), 70: tensor(80.8900), 80: tensor(84.1783), 90: tensor(83.6683), 100: tensor(74.8383), 110: tensor(62.1017), 120: tensor(48.1000), 130: tensor(39.9733), 140: tensor(37.6817), 150: tensor(38.4033), 160: tensor(42.7750), 170: tensor(46.9033), 180: tensor(49.1800), 190: tensor(48.8867), 200: tensor(45.2300), 210: tensor(39.4333), 220: tensor(36.5600), 230: tensor(37.9233), 240: tensor(46.1150), 250: tensor(63.4183), 260: tensor(75.6217), 270: tensor(83.6733), 280: tensor(83.9083), 290: tensor(77.5483), 300: tensor(69.6917), 310: tensor(68.4233), 320: tensor(72.8800), 330: tensor(84.1850), 340: tensor(93.7983), 350: tensor(97.6017)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=57, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7464,                   Accuracy: 623/2000.0 (31.15%)



-= Testing valid =-
Test set: Average loss: 0.6964,                   Accuracy: 1658/2000.0 (82.90%)



-= Testing valid =-
Test set: Average loss: 0.2746,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.1532,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.2533,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.2496,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1276,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0981,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 10 train accuracy: 98.29%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0598,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0567,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 20 train accuracy: 99.24%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.53%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.66%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 50 train accuracy: 99.68%, valid accuracy 99.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0500,                   Accuracy: 59148/60000 (98.58%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0763,                   Accuracy: 58652/60000 (97.75%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1658,                   Accuracy: 57136/60000 (95.23%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4012,                   Accuracy: 53192/60000 (88.65%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8172,                   Accuracy: 46445/60000 (77.41%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0707,                   Accuracy: 42239/60000 (70.40%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9978,                   Accuracy: 42146/60000 (70.24%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7678,                   Accuracy: 45016/60000 (75.03%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6729,                   Accuracy: 45913/60000 (76.52%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7548,                   Accuracy: 44707/60000 (74.51%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.1860,                   Accuracy: 39090/60000 (65.15%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.7986,                   Accuracy: 33614/60000 (56.02%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.6577,                   Accuracy: 27801/60000 (46.33%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.4730,                   Accuracy: 24209/60000 (40.35%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.8611,                   Accuracy: 23428/60000 (39.05%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8435,                   Accuracy: 25323/60000 (42.21%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5497,                   Accuracy: 28795/60000 (47.99%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5262,                   Accuracy: 30547/60000 (50.91%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.6190,                   Accuracy: 30424/60000 (50.71%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.5939,                   Accuracy: 30231/60000 (50.38%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7484,                   Accuracy: 28045/60000 (46.74%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.0213,                   Accuracy: 24889/60000 (41.48%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.8150,                   Accuracy: 23527/60000 (39.21%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1744,                   Accuracy: 26018/60000 (43.36%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.1761,                   Accuracy: 32201/60000 (53.67%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1940,                   Accuracy: 40489/60000 (67.48%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6616,                   Accuracy: 47193/60000 (78.65%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4837,                   Accuracy: 50835/60000 (84.72%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6525,                   Accuracy: 48594/60000 (80.99%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9615,                   Accuracy: 44555/60000 (74.26%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3993,                   Accuracy: 39867/60000 (66.44%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.5477,                   Accuracy: 39130/60000 (65.22%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3789,                   Accuracy: 42150/60000 (70.25%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7726,                   Accuracy: 49009/60000 (81.68%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2346,                   Accuracy: 55951/60000 (93.25%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0782,                   Accuracy: 58606/60000 (97.68%)
{0: tensor(98.5800), 10: tensor(97.7533), 20: tensor(95.2267), 30: tensor(88.6533), 40: tensor(77.4083), 50: tensor(70.3983), 60: tensor(70.2433), 70: tensor(75.0267), 80: tensor(76.5217), 90: tensor(74.5117), 100: tensor(65.1500), 110: tensor(56.0233), 120: tensor(46.3350), 130: tensor(40.3483), 140: tensor(39.0467), 150: tensor(42.2050), 160: tensor(47.9917), 170: tensor(50.9117), 180: tensor(50.7067), 190: tensor(50.3850), 200: tensor(46.7417), 210: tensor(41.4817), 220: tensor(39.2117), 230: tensor(43.3633), 240: tensor(53.6683), 250: tensor(67.4817), 260: tensor(78.6550), 270: tensor(84.7250), 280: tensor(80.9900), 290: tensor(74.2583), 300: tensor(66.4450), 310: tensor(65.2167), 320: tensor(70.2500), 330: tensor(81.6817), 340: tensor(93.2517), 350: tensor(97.6767)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=58, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1265,                   Accuracy: 558/2000.0 (27.90%)



-= Testing valid =-
Test set: Average loss: 1.5941,                   Accuracy: 760/2000.0 (38.00%)



-= Testing valid =-
Test set: Average loss: 0.3821,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.5108,                   Accuracy: 1693/2000.0 (84.65%)



-= Testing valid =-
Test set: Average loss: 0.2457,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.1591,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1651,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1433,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1084,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1888,                   Accuracy: 1877/2000.0 (93.85%)



Epoch 10 train accuracy: 98.46%, valid accuracy 93.85%
-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0622,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0621,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0825,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 20 train accuracy: 99.21%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0428,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0632,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0477,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.54%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.72%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.74%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0484,                   Accuracy: 59133/60000 (98.56%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0694,                   Accuracy: 58796/60000 (97.99%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1484,                   Accuracy: 57417/60000 (95.69%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4399,                   Accuracy: 52536/60000 (87.56%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9611,                   Accuracy: 44325/60000 (73.88%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.3263,                   Accuracy: 38542/60000 (64.24%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.3182,                   Accuracy: 37729/60000 (62.88%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.0995,                   Accuracy: 39998/60000 (66.66%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8337,                   Accuracy: 42603/60000 (71.00%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7121,                   Accuracy: 44477/60000 (74.13%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9043,                   Accuracy: 41472/60000 (69.12%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3016,                   Accuracy: 36225/60000 (60.38%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0699,                   Accuracy: 29155/60000 (48.59%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8863,                   Accuracy: 25167/60000 (41.94%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3014,                   Accuracy: 24682/60000 (41.14%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.3623,                   Accuracy: 26249/60000 (43.75%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.3831,                   Accuracy: 28267/60000 (47.11%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.3570,                   Accuracy: 30239/60000 (50.40%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.2735,                   Accuracy: 31506/60000 (52.51%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4706,                   Accuracy: 30622/60000 (51.04%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.6902,                   Accuracy: 29121/60000 (48.53%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.8304,                   Accuracy: 25660/60000 (42.77%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7995,                   Accuracy: 23612/60000 (39.35%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2261,                   Accuracy: 25535/60000 (42.56%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2466,                   Accuracy: 31181/60000 (51.97%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.4005,                   Accuracy: 38240/60000 (63.73%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7218,                   Accuracy: 46037/60000 (76.73%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5100,                   Accuracy: 49417/60000 (82.36%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5743,                   Accuracy: 48031/60000 (80.05%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7836,                   Accuracy: 44830/60000 (74.72%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1035,                   Accuracy: 40791/60000 (67.99%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2762,                   Accuracy: 38700/60000 (64.50%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1033,                   Accuracy: 41721/60000 (69.54%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6554,                   Accuracy: 48497/60000 (80.83%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2616,                   Accuracy: 55022/60000 (91.70%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0822,                   Accuracy: 58444/60000 (97.41%)
{0: tensor(98.5550), 10: tensor(97.9933), 20: tensor(95.6950), 30: tensor(87.5600), 40: tensor(73.8750), 50: tensor(64.2367), 60: tensor(62.8817), 70: tensor(66.6633), 80: tensor(71.0050), 90: tensor(74.1283), 100: tensor(69.1200), 110: tensor(60.3750), 120: tensor(48.5917), 130: tensor(41.9450), 140: tensor(41.1367), 150: tensor(43.7483), 160: tensor(47.1117), 170: tensor(50.3983), 180: tensor(52.5100), 190: tensor(51.0367), 200: tensor(48.5350), 210: tensor(42.7667), 220: tensor(39.3533), 230: tensor(42.5583), 240: tensor(51.9683), 250: tensor(63.7333), 260: tensor(76.7283), 270: tensor(82.3617), 280: tensor(80.0517), 290: tensor(74.7167), 300: tensor(67.9850), 310: tensor(64.5000), 320: tensor(69.5350), 330: tensor(80.8283), 340: tensor(91.7033), 350: tensor(97.4067)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=59, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1159,                   Accuracy: 421/2000.0 (21.05%)



-= Testing valid =-
Test set: Average loss: 2.6637,                   Accuracy: 353/2000.0 (17.65%)



-= Testing valid =-
Test set: Average loss: 1.1190,                   Accuracy: 1200/2000.0 (60.00%)



-= Testing valid =-
Test set: Average loss: 1.9623,                   Accuracy: 867/2000.0 (43.35%)



-= Testing valid =-
Test set: Average loss: 1.2146,                   Accuracy: 1224/2000.0 (61.20%)



-= Testing valid =-
Test set: Average loss: 0.3356,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.4769,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.1602,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1746,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 10 train accuracy: 97.31%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.1094,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1017,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1281,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0712,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1356,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0687,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0637,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 20 train accuracy: 99.00%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0622,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0621,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0619,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0604,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 30 train accuracy: 99.45%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0559,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0608,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0606,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0579,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 40 train accuracy: 99.51%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0581,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0557,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0578,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 50 train accuracy: 99.64%, valid accuracy 98.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0562,                   Accuracy: 59009/60000 (98.35%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0911,                   Accuracy: 58397/60000 (97.33%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2146,                   Accuracy: 56232/60000 (93.72%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5684,                   Accuracy: 50366/60000 (83.94%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0934,                   Accuracy: 42011/60000 (70.02%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.4950,                   Accuracy: 35679/60000 (59.47%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.4129,                   Accuracy: 35174/60000 (58.62%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.1247,                   Accuracy: 38435/60000 (64.06%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8627,                   Accuracy: 42828/60000 (71.38%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7796,                   Accuracy: 43717/60000 (72.86%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.1493,                   Accuracy: 37212/60000 (62.02%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6430,                   Accuracy: 31811/60000 (53.02%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.3697,                   Accuracy: 26655/60000 (44.42%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.0526,                   Accuracy: 23657/60000 (39.43%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.5300,                   Accuracy: 22871/60000 (38.12%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.6725,                   Accuracy: 24510/60000 (40.85%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.7384,                   Accuracy: 26783/60000 (44.64%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.7939,                   Accuracy: 27933/60000 (46.56%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.8261,                   Accuracy: 28559/60000 (47.60%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.8836,                   Accuracy: 27740/60000 (46.23%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.8256,                   Accuracy: 25645/60000 (42.74%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9218,                   Accuracy: 22607/60000 (37.68%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7813,                   Accuracy: 21550/60000 (35.92%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2708,                   Accuracy: 22887/60000 (38.15%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.4391,                   Accuracy: 27730/60000 (46.22%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.5825,                   Accuracy: 34941/60000 (58.24%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.0626,                   Accuracy: 40109/60000 (66.85%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7383,                   Accuracy: 44643/60000 (74.40%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.8645,                   Accuracy: 42448/60000 (70.75%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.1330,                   Accuracy: 38403/60000 (64.00%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.4339,                   Accuracy: 37085/60000 (61.81%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4897,                   Accuracy: 38385/60000 (63.97%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2772,                   Accuracy: 42549/60000 (70.92%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7135,                   Accuracy: 49691/60000 (82.82%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2332,                   Accuracy: 55934/60000 (93.22%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0901,                   Accuracy: 58354/60000 (97.26%)
{0: tensor(98.3483), 10: tensor(97.3283), 20: tensor(93.7200), 30: tensor(83.9433), 40: tensor(70.0183), 50: tensor(59.4650), 60: tensor(58.6233), 70: tensor(64.0583), 80: tensor(71.3800), 90: tensor(72.8617), 100: tensor(62.0200), 110: tensor(53.0183), 120: tensor(44.4250), 130: tensor(39.4283), 140: tensor(38.1183), 150: tensor(40.8500), 160: tensor(44.6383), 170: tensor(46.5550), 180: tensor(47.5983), 190: tensor(46.2333), 200: tensor(42.7417), 210: tensor(37.6783), 220: tensor(35.9167), 230: tensor(38.1450), 240: tensor(46.2167), 250: tensor(58.2350), 260: tensor(66.8483), 270: tensor(74.4050), 280: tensor(70.7467), 290: tensor(64.0050), 300: tensor(61.8083), 310: tensor(63.9750), 320: tensor(70.9150), 330: tensor(82.8183), 340: tensor(93.2233), 350: tensor(97.2567)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=60, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2267,                   Accuracy: 495/2000.0 (24.75%)



-= Testing valid =-
Test set: Average loss: 0.9405,                   Accuracy: 1556/2000.0 (77.80%)



-= Testing valid =-
Test set: Average loss: 0.6103,                   Accuracy: 1623/2000.0 (81.15%)



-= Testing valid =-
Test set: Average loss: 0.2606,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.3997,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.1475,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1815,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0775,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 10 train accuracy: 98.18%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0552,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0659,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 20 train accuracy: 98.95%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0453,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.49%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 40 train accuracy: 99.50%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 50 train accuracy: 99.75%, valid accuracy 98.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0509,                   Accuracy: 59076/60000 (98.46%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0842,                   Accuracy: 58535/60000 (97.56%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2095,                   Accuracy: 56406/60000 (94.01%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5499,                   Accuracy: 50530/60000 (84.22%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0015,                   Accuracy: 42778/60000 (71.30%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1718,                   Accuracy: 39544/60000 (65.91%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9978,                   Accuracy: 41564/60000 (69.27%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6546,                   Accuracy: 47060/60000 (78.43%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4591,                   Accuracy: 50562/60000 (84.27%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4272,                   Accuracy: 51017/60000 (85.03%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7125,                   Accuracy: 45653/60000 (76.09%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3498,                   Accuracy: 36842/60000 (61.40%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2276,                   Accuracy: 27728/60000 (46.21%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.9023,                   Accuracy: 23194/60000 (38.66%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.1737,                   Accuracy: 23046/60000 (38.41%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.1577,                   Accuracy: 24893/60000 (41.49%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.0998,                   Accuracy: 29047/60000 (48.41%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.0635,                   Accuracy: 32432/60000 (54.05%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.1482,                   Accuracy: 33100/60000 (55.17%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.2503,                   Accuracy: 32041/60000 (53.40%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.3029,                   Accuracy: 29888/60000 (49.81%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4279,                   Accuracy: 26095/60000 (43.49%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.1671,                   Accuracy: 24167/60000 (40.28%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.5020,                   Accuracy: 27398/60000 (45.66%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.6658,                   Accuracy: 34104/60000 (56.84%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.9590,                   Accuracy: 42092/60000 (70.15%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5364,                   Accuracy: 48848/60000 (81.41%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3989,                   Accuracy: 51635/60000 (86.06%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4894,                   Accuracy: 49716/60000 (82.86%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8428,                   Accuracy: 43522/60000 (72.54%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3578,                   Accuracy: 36241/60000 (60.40%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.6397,                   Accuracy: 32812/60000 (54.69%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.4423,                   Accuracy: 36718/60000 (61.20%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8542,                   Accuracy: 45471/60000 (75.79%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3300,                   Accuracy: 53805/60000 (89.68%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0974,                   Accuracy: 58171/60000 (96.95%)
{0: tensor(98.4600), 10: tensor(97.5583), 20: tensor(94.0100), 30: tensor(84.2167), 40: tensor(71.2967), 50: tensor(65.9067), 60: tensor(69.2733), 70: tensor(78.4333), 80: tensor(84.2700), 90: tensor(85.0283), 100: tensor(76.0883), 110: tensor(61.4033), 120: tensor(46.2133), 130: tensor(38.6567), 140: tensor(38.4100), 150: tensor(41.4883), 160: tensor(48.4117), 170: tensor(54.0533), 180: tensor(55.1667), 190: tensor(53.4017), 200: tensor(49.8133), 210: tensor(43.4917), 220: tensor(40.2783), 230: tensor(45.6633), 240: tensor(56.8400), 250: tensor(70.1533), 260: tensor(81.4133), 270: tensor(86.0583), 280: tensor(82.8600), 290: tensor(72.5367), 300: tensor(60.4017), 310: tensor(54.6867), 320: tensor(61.1967), 330: tensor(75.7850), 340: tensor(89.6750), 350: tensor(96.9517)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=61, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2948,                   Accuracy: 402/2000.0 (20.10%)



-= Testing valid =-
Test set: Average loss: 3.6482,                   Accuracy: 338/2000.0 (16.90%)



-= Testing valid =-
Test set: Average loss: 0.6149,                   Accuracy: 1592/2000.0 (79.60%)



-= Testing valid =-
Test set: Average loss: 0.3815,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.2912,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.3713,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.1501,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.2770,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2501,                   Accuracy: 1849/2000.0 (92.45%)



Epoch 10 train accuracy: 98.06%, valid accuracy 92.45%
-= Testing valid =-
Test set: Average loss: 0.0662,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0650,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.1161,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 20 train accuracy: 99.07%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0626,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0469,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0594,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0736,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 30 train accuracy: 99.35%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0658,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0637,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 40 train accuracy: 99.75%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0472,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 50 train accuracy: 99.72%, valid accuracy 98.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0626,                   Accuracy: 58969/60000 (98.28%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0899,                   Accuracy: 58514/60000 (97.52%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2089,                   Accuracy: 56402/60000 (94.00%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5495,                   Accuracy: 50311/60000 (83.85%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9307,                   Accuracy: 44526/60000 (74.21%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1107,                   Accuracy: 41604/60000 (69.34%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0299,                   Accuracy: 41851/60000 (69.75%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8668,                   Accuracy: 43881/60000 (73.14%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7402,                   Accuracy: 45362/60000 (75.60%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7424,                   Accuracy: 45102/60000 (75.17%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0793,                   Accuracy: 39729/60000 (66.21%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5432,                   Accuracy: 34974/60000 (58.29%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.1547,                   Accuracy: 30376/60000 (50.63%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8199,                   Accuracy: 26552/60000 (44.25%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.4107,                   Accuracy: 24463/60000 (40.77%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.9322,                   Accuracy: 23706/60000 (39.51%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.3805,                   Accuracy: 24759/60000 (41.26%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.4579,                   Accuracy: 25818/60000 (43.03%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.4303,                   Accuracy: 25820/60000 (43.03%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.5515,                   Accuracy: 25566/60000 (42.61%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.6004,                   Accuracy: 23934/60000 (39.89%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.3805,                   Accuracy: 22247/60000 (37.08%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.8964,                   Accuracy: 22737/60000 (37.90%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1742,                   Accuracy: 25201/60000 (42.00%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2639,                   Accuracy: 30577/60000 (50.96%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.5681,                   Accuracy: 37138/60000 (61.90%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.0655,                   Accuracy: 42185/60000 (70.31%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7359,                   Accuracy: 45941/60000 (76.57%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6659,                   Accuracy: 46931/60000 (78.22%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8638,                   Accuracy: 43503/60000 (72.50%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0576,                   Accuracy: 41760/60000 (69.60%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1161,                   Accuracy: 41598/60000 (69.33%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9728,                   Accuracy: 44439/60000 (74.07%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5835,                   Accuracy: 50250/60000 (83.75%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2086,                   Accuracy: 56199/60000 (93.67%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0813,                   Accuracy: 58546/60000 (97.58%)
{0: tensor(98.2817), 10: tensor(97.5233), 20: tensor(94.0033), 30: tensor(83.8517), 40: tensor(74.2100), 50: tensor(69.3400), 60: tensor(69.7517), 70: tensor(73.1350), 80: tensor(75.6033), 90: tensor(75.1700), 100: tensor(66.2150), 110: tensor(58.2900), 120: tensor(50.6267), 130: tensor(44.2533), 140: tensor(40.7717), 150: tensor(39.5100), 160: tensor(41.2650), 170: tensor(43.0300), 180: tensor(43.0333), 190: tensor(42.6100), 200: tensor(39.8900), 210: tensor(37.0783), 220: tensor(37.8950), 230: tensor(42.0017), 240: tensor(50.9617), 250: tensor(61.8967), 260: tensor(70.3083), 270: tensor(76.5683), 280: tensor(78.2183), 290: tensor(72.5050), 300: tensor(69.6000), 310: tensor(69.3300), 320: tensor(74.0650), 330: tensor(83.7500), 340: tensor(93.6650), 350: tensor(97.5767)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=62, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.7452,                   Accuracy: 181/2000.0 (9.05%)



-= Testing valid =-
Test set: Average loss: 1.7659,                   Accuracy: 689/2000.0 (34.45%)



-= Testing valid =-
Test set: Average loss: 1.2257,                   Accuracy: 1136/2000.0 (56.80%)



-= Testing valid =-
Test set: Average loss: 0.6016,                   Accuracy: 1658/2000.0 (82.90%)



-= Testing valid =-
Test set: Average loss: 0.3130,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2234,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1384,                   Accuracy: 1918/2000.0 (95.90%)



Epoch 10 train accuracy: 98.43%, valid accuracy 95.90%
-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 20 train accuracy: 99.00%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0453,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.64%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.60%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.79%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0436,                   Accuracy: 59278/60000 (98.80%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0686,                   Accuracy: 58825/60000 (98.04%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1567,                   Accuracy: 57305/60000 (95.51%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4046,                   Accuracy: 53204/60000 (88.67%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7170,                   Accuracy: 47717/60000 (79.53%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8699,                   Accuracy: 44407/60000 (74.01%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7822,                   Accuracy: 44959/60000 (74.93%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.5918,                   Accuracy: 47922/60000 (79.87%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4632,                   Accuracy: 50237/60000 (83.73%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4539,                   Accuracy: 50499/60000 (84.17%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7177,                   Accuracy: 46909/60000 (78.18%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2712,                   Accuracy: 39857/60000 (66.43%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2077,                   Accuracy: 31296/60000 (52.16%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.9447,                   Accuracy: 26703/60000 (44.51%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3538,                   Accuracy: 25055/60000 (41.76%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.3384,                   Accuracy: 25716/60000 (42.86%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.0922,                   Accuracy: 28560/60000 (47.60%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.9843,                   Accuracy: 31132/60000 (51.89%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.1162,                   Accuracy: 31558/60000 (52.60%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.2798,                   Accuracy: 29984/60000 (49.97%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.4444,                   Accuracy: 27530/60000 (45.88%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7492,                   Accuracy: 24233/60000 (40.39%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.4248,                   Accuracy: 23665/60000 (39.44%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.6716,                   Accuracy: 26901/60000 (44.83%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.6796,                   Accuracy: 34917/60000 (58.19%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.8819,                   Accuracy: 44962/60000 (74.94%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.4281,                   Accuracy: 52225/60000 (87.04%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2321,                   Accuracy: 55880/60000 (93.13%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3369,                   Accuracy: 53663/60000 (89.44%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.5808,                   Accuracy: 49127/60000 (81.88%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0105,                   Accuracy: 43035/60000 (71.72%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2859,                   Accuracy: 39922/60000 (66.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2717,                   Accuracy: 41706/60000 (69.51%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8560,                   Accuracy: 47566/60000 (79.28%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3526,                   Accuracy: 54199/60000 (90.33%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0913,                   Accuracy: 58391/60000 (97.32%)
{0: tensor(98.7967), 10: tensor(98.0417), 20: tensor(95.5083), 30: tensor(88.6733), 40: tensor(79.5283), 50: tensor(74.0117), 60: tensor(74.9317), 70: tensor(79.8700), 80: tensor(83.7283), 90: tensor(84.1650), 100: tensor(78.1817), 110: tensor(66.4283), 120: tensor(52.1600), 130: tensor(44.5050), 140: tensor(41.7583), 150: tensor(42.8600), 160: tensor(47.6000), 170: tensor(51.8867), 180: tensor(52.5967), 190: tensor(49.9733), 200: tensor(45.8833), 210: tensor(40.3883), 220: tensor(39.4417), 230: tensor(44.8350), 240: tensor(58.1950), 250: tensor(74.9367), 260: tensor(87.0417), 270: tensor(93.1333), 280: tensor(89.4383), 290: tensor(81.8783), 300: tensor(71.7250), 310: tensor(66.5367), 320: tensor(69.5100), 330: tensor(79.2767), 340: tensor(90.3317), 350: tensor(97.3183)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=63, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.3114,                   Accuracy: 278/2000.0 (13.90%)



-= Testing valid =-
Test set: Average loss: 1.9684,                   Accuracy: 653/2000.0 (32.65%)



-= Testing valid =-
Test set: Average loss: 0.6062,                   Accuracy: 1648/2000.0 (82.40%)



-= Testing valid =-
Test set: Average loss: 1.4886,                   Accuracy: 1057/2000.0 (52.85%)



-= Testing valid =-
Test set: Average loss: 0.2683,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.1807,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1666,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.4593,                   Accuracy: 1656/2000.0 (82.80%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 10 train accuracy: 98.60%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.3913,                   Accuracy: 1684/2000.0 (84.20%)



-= Testing valid =-
Test set: Average loss: 0.4876,                   Accuracy: 1648/2000.0 (82.40%)



-= Testing valid =-
Test set: Average loss: 0.5630,                   Accuracy: 1663/2000.0 (83.15%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0742,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0559,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 20 train accuracy: 99.32%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0683,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.1230,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 30 train accuracy: 99.55%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0678,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0519,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 40 train accuracy: 99.66%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0555,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0600,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.69%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0624,                   Accuracy: 58945/60000 (98.24%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0956,                   Accuracy: 58319/60000 (97.20%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2229,                   Accuracy: 56138/60000 (93.56%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5219,                   Accuracy: 50916/60000 (84.86%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9972,                   Accuracy: 43009/60000 (71.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2637,                   Accuracy: 38444/60000 (64.07%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1844,                   Accuracy: 39255/60000 (65.43%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9022,                   Accuracy: 43848/60000 (73.08%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6639,                   Accuracy: 47087/60000 (78.48%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6025,                   Accuracy: 48705/60000 (81.18%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9341,                   Accuracy: 42883/60000 (71.47%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.4770,                   Accuracy: 35746/60000 (59.58%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.3930,                   Accuracy: 26424/60000 (44.04%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.2024,                   Accuracy: 22438/60000 (37.40%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.6573,                   Accuracy: 21950/60000 (36.58%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.7698,                   Accuracy: 23241/60000 (38.74%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.7217,                   Accuracy: 26017/60000 (43.36%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.6689,                   Accuracy: 27932/60000 (46.55%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.6753,                   Accuracy: 28419/60000 (47.37%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.8601,                   Accuracy: 28329/60000 (47.22%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.8645,                   Accuracy: 27468/60000 (45.78%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7999,                   Accuracy: 25174/60000 (41.96%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6679,                   Accuracy: 23057/60000 (38.43%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1664,                   Accuracy: 23697/60000 (39.49%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3496,                   Accuracy: 28495/60000 (47.49%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.6163,                   Accuracy: 35709/60000 (59.51%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.0006,                   Accuracy: 42174/60000 (70.29%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5828,                   Accuracy: 48914/60000 (81.52%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6768,                   Accuracy: 46927/60000 (78.21%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8743,                   Accuracy: 42937/60000 (71.56%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1381,                   Accuracy: 37642/60000 (62.74%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2723,                   Accuracy: 35031/60000 (58.38%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1013,                   Accuracy: 38309/60000 (63.85%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6825,                   Accuracy: 46477/60000 (77.46%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2781,                   Accuracy: 54657/60000 (91.10%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1045,                   Accuracy: 58129/60000 (96.88%)
{0: tensor(98.2417), 10: tensor(97.1983), 20: tensor(93.5633), 30: tensor(84.8600), 40: tensor(71.6817), 50: tensor(64.0733), 60: tensor(65.4250), 70: tensor(73.0800), 80: tensor(78.4783), 90: tensor(81.1750), 100: tensor(71.4717), 110: tensor(59.5767), 120: tensor(44.0400), 130: tensor(37.3967), 140: tensor(36.5833), 150: tensor(38.7350), 160: tensor(43.3617), 170: tensor(46.5533), 180: tensor(47.3650), 190: tensor(47.2150), 200: tensor(45.7800), 210: tensor(41.9567), 220: tensor(38.4283), 230: tensor(39.4950), 240: tensor(47.4917), 250: tensor(59.5150), 260: tensor(70.2900), 270: tensor(81.5233), 280: tensor(78.2117), 290: tensor(71.5617), 300: tensor(62.7367), 310: tensor(58.3850), 320: tensor(63.8483), 330: tensor(77.4617), 340: tensor(91.0950), 350: tensor(96.8817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=64, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2853,                   Accuracy: 297/2000.0 (14.85%)



-= Testing valid =-
Test set: Average loss: 1.4779,                   Accuracy: 824/2000.0 (41.20%)



-= Testing valid =-
Test set: Average loss: 0.5011,                   Accuracy: 1752/2000.0 (87.60%)



-= Testing valid =-
Test set: Average loss: 0.4348,                   Accuracy: 1760/2000.0 (88.00%)



-= Testing valid =-
Test set: Average loss: 0.4238,                   Accuracy: 1697/2000.0 (84.85%)



-= Testing valid =-
Test set: Average loss: 0.1869,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 10 train accuracy: 97.68%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0580,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0629,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 20 train accuracy: 98.94%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 30 train accuracy: 99.34%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1988/2000.0 (99.40%)



Epoch 40 train accuracy: 99.40%, valid accuracy 99.40%
-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0226,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0226,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 50 train accuracy: 99.55%, valid accuracy 99.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0484,                   Accuracy: 59154/60000 (98.59%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0773,                   Accuracy: 58661/60000 (97.77%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1819,                   Accuracy: 56907/60000 (94.85%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5300,                   Accuracy: 51252/60000 (85.42%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0042,                   Accuracy: 43614/60000 (72.69%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2741,                   Accuracy: 39096/60000 (65.16%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1761,                   Accuracy: 39359/60000 (65.60%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8770,                   Accuracy: 42652/60000 (71.09%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7008,                   Accuracy: 45241/60000 (75.40%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6487,                   Accuracy: 46646/60000 (77.74%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9819,                   Accuracy: 41756/60000 (69.59%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6296,                   Accuracy: 34019/60000 (56.70%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.4524,                   Accuracy: 26408/60000 (44.01%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.3216,                   Accuracy: 22577/60000 (37.63%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.8171,                   Accuracy: 22054/60000 (36.76%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.0491,                   Accuracy: 23660/60000 (39.43%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.0055,                   Accuracy: 27044/60000 (45.07%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.8971,                   Accuracy: 29518/60000 (49.20%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.8220,                   Accuracy: 30492/60000 (50.82%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.8049,                   Accuracy: 30362/60000 (50.60%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.9636,                   Accuracy: 28821/60000 (48.03%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.0230,                   Accuracy: 25486/60000 (42.48%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7299,                   Accuracy: 24234/60000 (40.39%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.0299,                   Accuracy: 26008/60000 (43.35%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.1447,                   Accuracy: 31499/60000 (52.50%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2402,                   Accuracy: 39393/60000 (65.65%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7495,                   Accuracy: 45041/60000 (75.07%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5702,                   Accuracy: 48474/60000 (80.79%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6483,                   Accuracy: 46983/60000 (78.31%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8463,                   Accuracy: 43664/60000 (72.77%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2002,                   Accuracy: 39254/60000 (65.42%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4049,                   Accuracy: 37766/60000 (62.94%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2870,                   Accuracy: 41046/60000 (68.41%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7284,                   Accuracy: 48177/60000 (80.29%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2569,                   Accuracy: 55494/60000 (92.49%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0821,                   Accuracy: 58509/60000 (97.51%)
{0: tensor(98.5900), 10: tensor(97.7683), 20: tensor(94.8450), 30: tensor(85.4200), 40: tensor(72.6900), 50: tensor(65.1600), 60: tensor(65.5983), 70: tensor(71.0867), 80: tensor(75.4017), 90: tensor(77.7433), 100: tensor(69.5933), 110: tensor(56.6983), 120: tensor(44.0133), 130: tensor(37.6283), 140: tensor(36.7567), 150: tensor(39.4333), 160: tensor(45.0733), 170: tensor(49.1967), 180: tensor(50.8200), 190: tensor(50.6033), 200: tensor(48.0350), 210: tensor(42.4767), 220: tensor(40.3900), 230: tensor(43.3467), 240: tensor(52.4983), 250: tensor(65.6550), 260: tensor(75.0683), 270: tensor(80.7900), 280: tensor(78.3050), 290: tensor(72.7733), 300: tensor(65.4233), 310: tensor(62.9433), 320: tensor(68.4100), 330: tensor(80.2950), 340: tensor(92.4900), 350: tensor(97.5150)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=65, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3444,                   Accuracy: 540/2000.0 (27.00%)



-= Testing valid =-
Test set: Average loss: 1.1570,                   Accuracy: 1212/2000.0 (60.60%)



-= Testing valid =-
Test set: Average loss: 0.8886,                   Accuracy: 1372/2000.0 (68.60%)



-= Testing valid =-
Test set: Average loss: 0.6101,                   Accuracy: 1586/2000.0 (79.30%)



-= Testing valid =-
Test set: Average loss: 0.1910,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.1365,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.0677,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.1839,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.2043,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 10 train accuracy: 98.15%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.1148,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.1173,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0530,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0469,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 20 train accuracy: 99.21%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0662,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 30 train accuracy: 99.55%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.59%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.66%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0538,                   Accuracy: 59070/60000 (98.45%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1046,                   Accuracy: 58195/60000 (96.99%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2191,                   Accuracy: 56299/60000 (93.83%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5191,                   Accuracy: 51277/60000 (85.46%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9056,                   Accuracy: 45124/60000 (75.21%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0953,                   Accuracy: 42111/60000 (70.18%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9719,                   Accuracy: 43731/60000 (72.89%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7037,                   Accuracy: 47325/60000 (78.88%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5724,                   Accuracy: 49092/60000 (81.82%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4619,                   Accuracy: 50931/60000 (84.89%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7202,                   Accuracy: 46497/60000 (77.50%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1364,                   Accuracy: 39436/60000 (65.73%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.7580,                   Accuracy: 30645/60000 (51.08%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.3732,                   Accuracy: 24901/60000 (41.50%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.7673,                   Accuracy: 23125/60000 (38.54%)
-= Testing Rotation 150 =-
Test set: Average loss: 2.9023,                   Accuracy: 24851/60000 (41.42%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.0227,                   Accuracy: 27513/60000 (45.85%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.1254,                   Accuracy: 29228/60000 (48.71%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.2910,                   Accuracy: 30119/60000 (50.20%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4885,                   Accuracy: 28806/60000 (48.01%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7947,                   Accuracy: 27219/60000 (45.37%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.0082,                   Accuracy: 24765/60000 (41.28%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7073,                   Accuracy: 24188/60000 (40.31%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.0922,                   Accuracy: 26251/60000 (43.75%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.1430,                   Accuracy: 31565/60000 (52.61%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3290,                   Accuracy: 38716/60000 (64.53%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7875,                   Accuracy: 45394/60000 (75.66%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4447,                   Accuracy: 51140/60000 (85.23%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5506,                   Accuracy: 49281/60000 (82.14%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6885,                   Accuracy: 46179/60000 (76.96%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.8911,                   Accuracy: 42511/60000 (70.85%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9549,                   Accuracy: 41879/60000 (69.80%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8225,                   Accuracy: 44816/60000 (74.69%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4920,                   Accuracy: 51032/60000 (85.05%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1974,                   Accuracy: 56367/60000 (93.94%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0881,                   Accuracy: 58369/60000 (97.28%)
{0: tensor(98.4500), 10: tensor(96.9917), 20: tensor(93.8317), 30: tensor(85.4617), 40: tensor(75.2067), 50: tensor(70.1850), 60: tensor(72.8850), 70: tensor(78.8750), 80: tensor(81.8200), 90: tensor(84.8850), 100: tensor(77.4950), 110: tensor(65.7267), 120: tensor(51.0750), 130: tensor(41.5017), 140: tensor(38.5417), 150: tensor(41.4183), 160: tensor(45.8550), 170: tensor(48.7133), 180: tensor(50.1983), 190: tensor(48.0100), 200: tensor(45.3650), 210: tensor(41.2750), 220: tensor(40.3133), 230: tensor(43.7517), 240: tensor(52.6083), 250: tensor(64.5267), 260: tensor(75.6567), 270: tensor(85.2333), 280: tensor(82.1350), 290: tensor(76.9650), 300: tensor(70.8517), 310: tensor(69.7983), 320: tensor(74.6933), 330: tensor(85.0533), 340: tensor(93.9450), 350: tensor(97.2817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=66, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.9232,                   Accuracy: 242/2000.0 (12.10%)



-= Testing valid =-
Test set: Average loss: 1.4803,                   Accuracy: 1076/2000.0 (53.80%)



-= Testing valid =-
Test set: Average loss: 1.9505,                   Accuracy: 835/2000.0 (41.75%)



-= Testing valid =-
Test set: Average loss: 0.3193,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.4287,                   Accuracy: 1747/2000.0 (87.35%)



-= Testing valid =-
Test set: Average loss: 1.4678,                   Accuracy: 1223/2000.0 (61.15%)



-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.8061,                   Accuracy: 1623/2000.0 (81.15%)



-= Testing valid =-
Test set: Average loss: 0.1732,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1042,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 10 train accuracy: 98.36%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.3205,                   Accuracy: 1753/2000.0 (87.65%)



-= Testing valid =-
Test set: Average loss: 0.1378,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1929,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.3128,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.2474,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.3598,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.6470,                   Accuracy: 1759/2000.0 (87.95%)



Epoch 20 train accuracy: 99.18%, valid accuracy 87.95%
-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.4490,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.0718,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.4161,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 30 train accuracy: 99.57%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.3062,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0598,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0597,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.1715,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 40 train accuracy: 99.57%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.1304,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 50 train accuracy: 99.74%, valid accuracy 98.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0643,                   Accuracy: 58907/60000 (98.18%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0974,                   Accuracy: 58332/60000 (97.22%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2151,                   Accuracy: 56379/60000 (93.96%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6237,                   Accuracy: 49896/60000 (83.16%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.1767,                   Accuracy: 41525/60000 (69.21%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.5818,                   Accuracy: 34886/60000 (58.14%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.5500,                   Accuracy: 34290/60000 (57.15%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.1792,                   Accuracy: 38627/60000 (64.38%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.9730,                   Accuracy: 40744/60000 (67.91%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.9369,                   Accuracy: 42531/60000 (70.89%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.2629,                   Accuracy: 37820/60000 (63.03%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.9389,                   Accuracy: 31297/60000 (52.16%)
-= Testing Rotation 120 =-
Test set: Average loss: 3.0189,                   Accuracy: 22769/60000 (37.95%)
-= Testing Rotation 130 =-
Test set: Average loss: 4.0981,                   Accuracy: 19630/60000 (32.72%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.7195,                   Accuracy: 19145/60000 (31.91%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.8389,                   Accuracy: 21068/60000 (35.11%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.7489,                   Accuracy: 23656/60000 (39.43%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.7902,                   Accuracy: 25702/60000 (42.84%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.6490,                   Accuracy: 27905/60000 (46.51%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.7264,                   Accuracy: 27550/60000 (45.92%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.8039,                   Accuracy: 25947/60000 (43.24%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.9000,                   Accuracy: 22215/60000 (37.03%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.7576,                   Accuracy: 20611/60000 (34.35%)
-= Testing Rotation 230 =-
Test set: Average loss: 4.2786,                   Accuracy: 21351/60000 (35.58%)
-= Testing Rotation 240 =-
Test set: Average loss: 3.3901,                   Accuracy: 26189/60000 (43.65%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.3268,                   Accuracy: 33194/60000 (55.32%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.5273,                   Accuracy: 38084/60000 (63.47%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.9309,                   Accuracy: 44365/60000 (73.94%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.9230,                   Accuracy: 42850/60000 (71.42%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.2118,                   Accuracy: 36785/60000 (61.31%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.5257,                   Accuracy: 32600/60000 (54.33%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.7030,                   Accuracy: 31053/60000 (51.76%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.4709,                   Accuracy: 35592/60000 (59.32%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7996,                   Accuracy: 46079/60000 (76.80%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2581,                   Accuracy: 55247/60000 (92.08%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1023,                   Accuracy: 58136/60000 (96.89%)
{0: tensor(98.1783), 10: tensor(97.2200), 20: tensor(93.9650), 30: tensor(83.1600), 40: tensor(69.2083), 50: tensor(58.1433), 60: tensor(57.1500), 70: tensor(64.3783), 80: tensor(67.9067), 90: tensor(70.8850), 100: tensor(63.0333), 110: tensor(52.1617), 120: tensor(37.9483), 130: tensor(32.7167), 140: tensor(31.9083), 150: tensor(35.1133), 160: tensor(39.4267), 170: tensor(42.8367), 180: tensor(46.5083), 190: tensor(45.9167), 200: tensor(43.2450), 210: tensor(37.0250), 220: tensor(34.3517), 230: tensor(35.5850), 240: tensor(43.6483), 250: tensor(55.3233), 260: tensor(63.4733), 270: tensor(73.9417), 280: tensor(71.4167), 290: tensor(61.3083), 300: tensor(54.3333), 310: tensor(51.7550), 320: tensor(59.3200), 330: tensor(76.7983), 340: tensor(92.0783), 350: tensor(96.8933)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=67, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7551,                   Accuracy: 675/2000.0 (33.75%)



-= Testing valid =-
Test set: Average loss: 1.1675,                   Accuracy: 1087/2000.0 (54.35%)



-= Testing valid =-
Test set: Average loss: 0.4370,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2861,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2907,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.1390,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1105,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0552,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 10 train accuracy: 97.84%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 20 train accuracy: 99.04%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.34%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0218,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 40 train accuracy: 99.39%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 50 train accuracy: 99.70%, valid accuracy 99.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0485,                   Accuracy: 59166/60000 (98.61%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0830,                   Accuracy: 58548/60000 (97.58%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1925,                   Accuracy: 56746/60000 (94.58%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5258,                   Accuracy: 51453/60000 (85.75%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9480,                   Accuracy: 44710/60000 (74.52%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1280,                   Accuracy: 41263/60000 (68.77%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9731,                   Accuracy: 43096/60000 (71.83%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6526,                   Accuracy: 47830/60000 (79.72%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4793,                   Accuracy: 50030/60000 (83.38%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5256,                   Accuracy: 48369/60000 (80.61%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7820,                   Accuracy: 43746/60000 (72.91%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2154,                   Accuracy: 39011/60000 (65.02%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0369,                   Accuracy: 29519/60000 (49.20%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.7245,                   Accuracy: 23806/60000 (39.68%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.0022,                   Accuracy: 22519/60000 (37.53%)
-= Testing Rotation 150 =-
Test set: Average loss: 2.9850,                   Accuracy: 23889/60000 (39.81%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.8485,                   Accuracy: 26778/60000 (44.63%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.8451,                   Accuracy: 28674/60000 (47.79%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.0942,                   Accuracy: 28905/60000 (48.17%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.1526,                   Accuracy: 28722/60000 (47.87%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.1283,                   Accuracy: 27514/60000 (45.86%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4510,                   Accuracy: 24437/60000 (40.73%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.3661,                   Accuracy: 22969/60000 (38.28%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8879,                   Accuracy: 25094/60000 (41.82%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0634,                   Accuracy: 31338/60000 (52.23%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2066,                   Accuracy: 39889/60000 (66.48%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6882,                   Accuracy: 46826/60000 (78.04%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4545,                   Accuracy: 50538/60000 (84.23%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5237,                   Accuracy: 49209/60000 (82.01%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7364,                   Accuracy: 45640/60000 (76.07%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0278,                   Accuracy: 41343/60000 (68.90%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1888,                   Accuracy: 38863/60000 (64.77%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0070,                   Accuracy: 41898/60000 (69.83%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5771,                   Accuracy: 49350/60000 (82.25%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2197,                   Accuracy: 56076/60000 (93.46%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0765,                   Accuracy: 58622/60000 (97.70%)
{0: tensor(98.6100), 10: tensor(97.5800), 20: tensor(94.5767), 30: tensor(85.7550), 40: tensor(74.5167), 50: tensor(68.7717), 60: tensor(71.8267), 70: tensor(79.7167), 80: tensor(83.3833), 90: tensor(80.6150), 100: tensor(72.9100), 110: tensor(65.0183), 120: tensor(49.1983), 130: tensor(39.6767), 140: tensor(37.5317), 150: tensor(39.8150), 160: tensor(44.6300), 170: tensor(47.7900), 180: tensor(48.1750), 190: tensor(47.8700), 200: tensor(45.8567), 210: tensor(40.7283), 220: tensor(38.2817), 230: tensor(41.8233), 240: tensor(52.2300), 250: tensor(66.4817), 260: tensor(78.0433), 270: tensor(84.2300), 280: tensor(82.0150), 290: tensor(76.0667), 300: tensor(68.9050), 310: tensor(64.7717), 320: tensor(69.8300), 330: tensor(82.2500), 340: tensor(93.4600), 350: tensor(97.7033)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=68, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2709,                   Accuracy: 414/2000.0 (20.70%)



-= Testing valid =-
Test set: Average loss: 1.0941,                   Accuracy: 1267/2000.0 (63.35%)



-= Testing valid =-
Test set: Average loss: 4.0079,                   Accuracy: 261/2000.0 (13.05%)



-= Testing valid =-
Test set: Average loss: 0.6301,                   Accuracy: 1612/2000.0 (80.60%)



-= Testing valid =-
Test set: Average loss: 0.4563,                   Accuracy: 1718/2000.0 (85.90%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1232,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1411,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 10 train accuracy: 98.18%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.1386,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.0567,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 20 train accuracy: 99.12%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.31%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 40 train accuracy: 99.59%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 50 train accuracy: 99.78%, valid accuracy 98.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0527,                   Accuracy: 59071/60000 (98.45%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0725,                   Accuracy: 58725/60000 (97.88%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1445,                   Accuracy: 57501/60000 (95.83%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3321,                   Accuracy: 54053/60000 (90.09%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7005,                   Accuracy: 47404/60000 (79.01%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9664,                   Accuracy: 42469/60000 (70.78%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9160,                   Accuracy: 43124/60000 (71.87%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6692,                   Accuracy: 47512/60000 (79.19%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4703,                   Accuracy: 51050/60000 (85.08%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4149,                   Accuracy: 51955/60000 (86.59%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.5801,                   Accuracy: 48689/60000 (81.15%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.9562,                   Accuracy: 43346/60000 (72.24%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.5958,                   Accuracy: 35501/60000 (59.17%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.4348,                   Accuracy: 28339/60000 (47.23%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.9459,                   Accuracy: 25588/60000 (42.65%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.0156,                   Accuracy: 26151/60000 (43.58%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.9550,                   Accuracy: 28293/60000 (47.15%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.9509,                   Accuracy: 30060/60000 (50.10%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.0016,                   Accuracy: 30591/60000 (50.99%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.0193,                   Accuracy: 30267/60000 (50.44%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.9987,                   Accuracy: 28924/60000 (48.21%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.0739,                   Accuracy: 26556/60000 (44.26%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.9905,                   Accuracy: 25082/60000 (41.80%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.5744,                   Accuracy: 26831/60000 (44.72%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.8710,                   Accuracy: 32137/60000 (53.56%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1319,                   Accuracy: 39972/60000 (66.62%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6371,                   Accuracy: 47002/60000 (78.34%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4017,                   Accuracy: 50804/60000 (84.67%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4326,                   Accuracy: 50645/60000 (84.41%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.6032,                   Accuracy: 47534/60000 (79.22%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9177,                   Accuracy: 42548/60000 (70.91%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1949,                   Accuracy: 39232/60000 (65.39%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1659,                   Accuracy: 40980/60000 (68.30%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7260,                   Accuracy: 47496/60000 (79.16%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2689,                   Accuracy: 54763/60000 (91.27%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0989,                   Accuracy: 58101/60000 (96.83%)
{0: tensor(98.4517), 10: tensor(97.8750), 20: tensor(95.8350), 30: tensor(90.0883), 40: tensor(79.0067), 50: tensor(70.7817), 60: tensor(71.8733), 70: tensor(79.1867), 80: tensor(85.0833), 90: tensor(86.5917), 100: tensor(81.1483), 110: tensor(72.2433), 120: tensor(59.1683), 130: tensor(47.2317), 140: tensor(42.6467), 150: tensor(43.5850), 160: tensor(47.1550), 170: tensor(50.1000), 180: tensor(50.9850), 190: tensor(50.4450), 200: tensor(48.2067), 210: tensor(44.2600), 220: tensor(41.8033), 230: tensor(44.7183), 240: tensor(53.5617), 250: tensor(66.6200), 260: tensor(78.3367), 270: tensor(84.6733), 280: tensor(84.4083), 290: tensor(79.2233), 300: tensor(70.9133), 310: tensor(65.3867), 320: tensor(68.3000), 330: tensor(79.1600), 340: tensor(91.2717), 350: tensor(96.8350)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=69, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1743,                   Accuracy: 394/2000.0 (19.70%)



-= Testing valid =-
Test set: Average loss: 5.2373,                   Accuracy: 321/2000.0 (16.05%)



-= Testing valid =-
Test set: Average loss: 1.1646,                   Accuracy: 1354/2000.0 (67.70%)



-= Testing valid =-
Test set: Average loss: 0.5169,                   Accuracy: 1632/2000.0 (81.60%)



-= Testing valid =-
Test set: Average loss: 0.1938,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.3200,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.1562,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1389,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.1379,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 10 train accuracy: 97.80%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0617,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0645,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0575,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0601,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 20 train accuracy: 99.07%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 30 train accuracy: 99.38%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.56%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.70%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0456,                   Accuracy: 59204/60000 (98.67%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0787,                   Accuracy: 58626/60000 (97.71%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2202,                   Accuracy: 56344/60000 (93.91%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5659,                   Accuracy: 51125/60000 (85.21%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0697,                   Accuracy: 43338/60000 (72.23%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.4193,                   Accuracy: 38041/60000 (63.40%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.2451,                   Accuracy: 39118/60000 (65.20%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9169,                   Accuracy: 43539/60000 (72.57%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6865,                   Accuracy: 46450/60000 (77.42%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6581,                   Accuracy: 47844/60000 (79.74%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.1426,                   Accuracy: 40056/60000 (66.76%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.8929,                   Accuracy: 31493/60000 (52.49%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.9300,                   Accuracy: 25857/60000 (43.10%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.6839,                   Accuracy: 22751/60000 (37.92%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.0938,                   Accuracy: 22454/60000 (37.42%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.1540,                   Accuracy: 24373/60000 (40.62%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.1197,                   Accuracy: 26662/60000 (44.44%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.1630,                   Accuracy: 27919/60000 (46.53%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.1596,                   Accuracy: 28925/60000 (48.21%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.1045,                   Accuracy: 28193/60000 (46.99%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.4684,                   Accuracy: 25486/60000 (42.48%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.5971,                   Accuracy: 22893/60000 (38.15%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.5116,                   Accuracy: 21334/60000 (35.56%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.9186,                   Accuracy: 22060/60000 (36.77%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.8524,                   Accuracy: 25893/60000 (43.15%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.9047,                   Accuracy: 32196/60000 (53.66%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.2643,                   Accuracy: 39355/60000 (65.59%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.8885,                   Accuracy: 44255/60000 (73.76%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.0177,                   Accuracy: 42337/60000 (70.56%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.3258,                   Accuracy: 37093/60000 (61.82%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.7302,                   Accuracy: 33201/60000 (55.33%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.7782,                   Accuracy: 32904/60000 (54.84%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.4757,                   Accuracy: 37775/60000 (62.96%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7294,                   Accuracy: 48155/60000 (80.26%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2135,                   Accuracy: 56207/60000 (93.68%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0756,                   Accuracy: 58643/60000 (97.74%)
{0: tensor(98.6733), 10: tensor(97.7100), 20: tensor(93.9067), 30: tensor(85.2083), 40: tensor(72.2300), 50: tensor(63.4017), 60: tensor(65.1967), 70: tensor(72.5650), 80: tensor(77.4167), 90: tensor(79.7400), 100: tensor(66.7600), 110: tensor(52.4883), 120: tensor(43.0950), 130: tensor(37.9183), 140: tensor(37.4233), 150: tensor(40.6217), 160: tensor(44.4367), 170: tensor(46.5317), 180: tensor(48.2083), 190: tensor(46.9883), 200: tensor(42.4767), 210: tensor(38.1550), 220: tensor(35.5567), 230: tensor(36.7667), 240: tensor(43.1550), 250: tensor(53.6600), 260: tensor(65.5917), 270: tensor(73.7583), 280: tensor(70.5617), 290: tensor(61.8217), 300: tensor(55.3350), 310: tensor(54.8400), 320: tensor(62.9583), 330: tensor(80.2583), 340: tensor(93.6783), 350: tensor(97.7383)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=70, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.2543,                   Accuracy: 295/2000.0 (14.75%)



-= Testing valid =-
Test set: Average loss: 1.4714,                   Accuracy: 923/2000.0 (46.15%)



-= Testing valid =-
Test set: Average loss: 0.4956,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.3758,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.2342,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.1433,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 10 train accuracy: 98.36%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0519,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 20 train accuracy: 98.97%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 30 train accuracy: 99.41%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0220,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0223,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0213,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0251,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 40 train accuracy: 99.69%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0223,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0205,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0212,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 50 train accuracy: 99.70%, valid accuracy 99.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0496,                   Accuracy: 59104/60000 (98.51%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0826,                   Accuracy: 58533/60000 (97.56%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1735,                   Accuracy: 57005/60000 (95.01%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3644,                   Accuracy: 53711/60000 (89.52%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.6280,                   Accuracy: 49022/60000 (81.70%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.7849,                   Accuracy: 45659/60000 (76.10%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7065,                   Accuracy: 47011/60000 (78.35%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.4906,                   Accuracy: 50836/60000 (84.73%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3739,                   Accuracy: 52673/60000 (87.79%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3711,                   Accuracy: 52759/60000 (87.93%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7020,                   Accuracy: 46891/60000 (78.15%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2588,                   Accuracy: 39437/60000 (65.73%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0406,                   Accuracy: 30332/60000 (50.55%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8131,                   Accuracy: 24465/60000 (40.78%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.2043,                   Accuracy: 22509/60000 (37.51%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.1664,                   Accuracy: 24395/60000 (40.66%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.9332,                   Accuracy: 28792/60000 (47.99%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.7927,                   Accuracy: 31979/60000 (53.30%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.7890,                   Accuracy: 33306/60000 (55.51%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.8980,                   Accuracy: 32478/60000 (54.13%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.9031,                   Accuracy: 30776/60000 (51.29%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.9719,                   Accuracy: 27624/60000 (46.04%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.7572,                   Accuracy: 25825/60000 (43.04%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.3493,                   Accuracy: 27042/60000 (45.07%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.7061,                   Accuracy: 32388/60000 (53.98%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0703,                   Accuracy: 40732/60000 (67.89%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6871,                   Accuracy: 46923/60000 (78.21%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4185,                   Accuracy: 51072/60000 (85.12%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5529,                   Accuracy: 48488/60000 (80.81%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7471,                   Accuracy: 44824/60000 (74.71%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0615,                   Accuracy: 39643/60000 (66.07%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1933,                   Accuracy: 37668/60000 (62.78%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0170,                   Accuracy: 40935/60000 (68.22%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5645,                   Accuracy: 48945/60000 (81.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2001,                   Accuracy: 56098/60000 (93.50%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0827,                   Accuracy: 58508/60000 (97.51%)
{0: tensor(98.5067), 10: tensor(97.5550), 20: tensor(95.0083), 30: tensor(89.5183), 40: tensor(81.7033), 50: tensor(76.0983), 60: tensor(78.3517), 70: tensor(84.7267), 80: tensor(87.7883), 90: tensor(87.9317), 100: tensor(78.1517), 110: tensor(65.7283), 120: tensor(50.5533), 130: tensor(40.7750), 140: tensor(37.5150), 150: tensor(40.6583), 160: tensor(47.9867), 170: tensor(53.2983), 180: tensor(55.5100), 190: tensor(54.1300), 200: tensor(51.2933), 210: tensor(46.0400), 220: tensor(43.0417), 230: tensor(45.0700), 240: tensor(53.9800), 250: tensor(67.8867), 260: tensor(78.2050), 270: tensor(85.1200), 280: tensor(80.8133), 290: tensor(74.7067), 300: tensor(66.0717), 310: tensor(62.7800), 320: tensor(68.2250), 330: tensor(81.5750), 340: tensor(93.4967), 350: tensor(97.5133)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=41, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7121,                   Accuracy: 631/2000.0 (31.55%)



-= Testing valid =-
Test set: Average loss: 0.4079,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.1134,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1818,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1997,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.2269,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1177,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 10 train accuracy: 98.01%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0520,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 20 train accuracy: 98.88%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0207,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0187,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0198,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0203,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 30 train accuracy: 99.25%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0191,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0164,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0180,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0226,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0196,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0219,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 40 train accuracy: 99.47%, valid accuracy 99.35%
-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0193,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0185,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0194,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0186,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0208,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0178,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0220,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.57%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0543,                   Accuracy: 59058/60000 (98.43%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0885,                   Accuracy: 58516/60000 (97.53%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2170,                   Accuracy: 56527/60000 (94.21%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6957,                   Accuracy: 49457/60000 (82.43%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4972,                   Accuracy: 40162/60000 (66.94%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.4843,                   Accuracy: 30500/60000 (50.83%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.6225,                   Accuracy: 21474/60000 (35.79%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.3617,                   Accuracy: 16194/60000 (26.99%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.9262,                   Accuracy: 13094/60000 (21.82%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.4385,                   Accuracy: 12118/60000 (20.20%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.5830,                   Accuracy: 12017/60000 (20.03%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.8020,                   Accuracy: 11874/60000 (19.79%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.0946,                   Accuracy: 11956/60000 (19.93%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.2088,                   Accuracy: 13790/60000 (22.98%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.2014,                   Accuracy: 16946/60000 (28.24%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.1447,                   Accuracy: 21538/60000 (35.90%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.3000,                   Accuracy: 25227/60000 (42.04%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.4984,                   Accuracy: 26998/60000 (45.00%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.9959,                   Accuracy: 26770/60000 (44.62%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.7120,                   Accuracy: 26704/60000 (44.51%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.6315,                   Accuracy: 25246/60000 (42.08%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.4144,                   Accuracy: 22739/60000 (37.90%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.2884,                   Accuracy: 20296/60000 (33.83%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.1703,                   Accuracy: 17828/60000 (29.71%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.1252,                   Accuracy: 15024/60000 (25.04%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.1489,                   Accuracy: 13483/60000 (22.47%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.0508,                   Accuracy: 12347/60000 (20.58%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.0569,                   Accuracy: 10722/60000 (17.87%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.9500,                   Accuracy: 10609/60000 (17.68%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.7011,                   Accuracy: 10702/60000 (17.84%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.1509,                   Accuracy: 12244/60000 (20.41%)
-= Testing Rotation 310 =-
Test set: Average loss: 4.0605,                   Accuracy: 18507/60000 (30.84%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.4515,                   Accuracy: 30277/60000 (50.46%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9993,                   Accuracy: 45297/60000 (75.50%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2880,                   Accuracy: 55206/60000 (92.01%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0857,                   Accuracy: 58523/60000 (97.54%)
{0: tensor(98.4300), 10: tensor(97.5267), 20: tensor(94.2117), 30: tensor(82.4283), 40: tensor(66.9367), 50: tensor(50.8333), 60: tensor(35.7900), 70: tensor(26.9900), 80: tensor(21.8233), 90: tensor(20.1967), 100: tensor(20.0283), 110: tensor(19.7900), 120: tensor(19.9267), 130: tensor(22.9833), 140: tensor(28.2433), 150: tensor(35.8967), 160: tensor(42.0450), 170: tensor(44.9967), 180: tensor(44.6167), 190: tensor(44.5067), 200: tensor(42.0767), 210: tensor(37.8983), 220: tensor(33.8267), 230: tensor(29.7133), 240: tensor(25.0400), 250: tensor(22.4717), 260: tensor(20.5783), 270: tensor(17.8700), 280: tensor(17.6817), 290: tensor(17.8367), 300: tensor(20.4067), 310: tensor(30.8450), 320: tensor(50.4617), 330: tensor(75.4950), 340: tensor(92.0100), 350: tensor(97.5383)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=42, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.1622,                   Accuracy: 1167/2000.0 (58.35%)



-= Testing valid =-
Test set: Average loss: 0.5445,                   Accuracy: 1634/2000.0 (81.70%)



-= Testing valid =-
Test set: Average loss: 0.3138,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.1379,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1112,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.1404,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1107,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 10 train accuracy: 97.36%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 20 train accuracy: 98.89%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 30 train accuracy: 99.36%, valid accuracy 99.30%
-= Testing valid =-
Test set: Average loss: 0.0189,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0208,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0198,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0180,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0198,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0206,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0220,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0195,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0180,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 40 train accuracy: 99.56%, valid accuracy 99.35%
-= Testing valid =-
Test set: Average loss: 0.0194,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0212,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0195,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0185,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0184,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0184,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0187,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0204,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1988/2000.0 (99.40%)



Epoch 50 train accuracy: 99.60%, valid accuracy 99.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0472,                   Accuracy: 59152/60000 (98.59%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0971,                   Accuracy: 58334/60000 (97.22%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2503,                   Accuracy: 55645/60000 (92.74%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5949,                   Accuracy: 50400/60000 (84.00%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4445,                   Accuracy: 39571/60000 (65.95%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.5955,                   Accuracy: 28737/60000 (47.90%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.8412,                   Accuracy: 19213/60000 (32.02%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.7832,                   Accuracy: 12096/60000 (20.16%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.4502,                   Accuracy: 8436/60000 (14.06%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.6452,                   Accuracy: 8596/60000 (14.33%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.7881,                   Accuracy: 8379/60000 (13.97%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.9497,                   Accuracy: 9858/60000 (16.43%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.9918,                   Accuracy: 12680/60000 (21.13%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.9290,                   Accuracy: 16406/60000 (27.34%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.8475,                   Accuracy: 20159/60000 (33.60%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.8899,                   Accuracy: 23599/60000 (39.33%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.1691,                   Accuracy: 25186/60000 (41.98%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.4550,                   Accuracy: 25808/60000 (43.01%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.6990,                   Accuracy: 26660/60000 (44.43%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.4294,                   Accuracy: 25957/60000 (43.26%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.4651,                   Accuracy: 24260/60000 (40.43%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.2507,                   Accuracy: 21661/60000 (36.10%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.2560,                   Accuracy: 17993/60000 (29.99%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.3562,                   Accuracy: 15864/60000 (26.44%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.4708,                   Accuracy: 13676/60000 (22.79%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.4563,                   Accuracy: 11441/60000 (19.07%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.3186,                   Accuracy: 10803/60000 (18.00%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.1500,                   Accuracy: 10724/60000 (17.87%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.8565,                   Accuracy: 8513/60000 (14.19%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.3273,                   Accuracy: 9825/60000 (16.38%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.4168,                   Accuracy: 13625/60000 (22.71%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.2985,                   Accuracy: 22189/60000 (36.98%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.9175,                   Accuracy: 34836/60000 (58.06%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8922,                   Accuracy: 46340/60000 (77.23%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3345,                   Accuracy: 54195/60000 (90.32%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1007,                   Accuracy: 58198/60000 (97.00%)
{0: tensor(98.5867), 10: tensor(97.2233), 20: tensor(92.7417), 30: tensor(84.), 40: tensor(65.9517), 50: tensor(47.8950), 60: tensor(32.0217), 70: tensor(20.1600), 80: tensor(14.0600), 90: tensor(14.3267), 100: tensor(13.9650), 110: tensor(16.4300), 120: tensor(21.1333), 130: tensor(27.3433), 140: tensor(33.5983), 150: tensor(39.3317), 160: tensor(41.9767), 170: tensor(43.0133), 180: tensor(44.4333), 190: tensor(43.2617), 200: tensor(40.4333), 210: tensor(36.1017), 220: tensor(29.9883), 230: tensor(26.4400), 240: tensor(22.7933), 250: tensor(19.0683), 260: tensor(18.0050), 270: tensor(17.8733), 280: tensor(14.1883), 290: tensor(16.3750), 300: tensor(22.7083), 310: tensor(36.9817), 320: tensor(58.0600), 330: tensor(77.2333), 340: tensor(90.3250), 350: tensor(96.9967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=43, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.3530,                   Accuracy: 991/2000.0 (49.55%)



-= Testing valid =-
Test set: Average loss: 0.3067,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.1454,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.2092,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.1374,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.0608,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1160,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 10 train accuracy: 97.94%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 20 train accuracy: 99.21%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0212,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.38%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 40 train accuracy: 99.57%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0220,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 50 train accuracy: 99.72%, valid accuracy 98.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0541,                   Accuracy: 59114/60000 (98.52%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0821,                   Accuracy: 58661/60000 (97.77%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1987,                   Accuracy: 56847/60000 (94.75%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5509,                   Accuracy: 51311/60000 (85.52%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.2950,                   Accuracy: 42101/60000 (70.17%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.4540,                   Accuracy: 31745/60000 (52.91%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.8340,                   Accuracy: 22520/60000 (37.53%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.8380,                   Accuracy: 15956/60000 (26.59%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.5174,                   Accuracy: 11708/60000 (19.51%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.1145,                   Accuracy: 10342/60000 (17.24%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.2087,                   Accuracy: 10848/60000 (18.08%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.3566,                   Accuracy: 11146/60000 (18.58%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.5339,                   Accuracy: 12162/60000 (20.27%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.5107,                   Accuracy: 14993/60000 (24.99%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.5465,                   Accuracy: 17942/60000 (29.90%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.5655,                   Accuracy: 20950/60000 (34.92%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.7441,                   Accuracy: 23931/60000 (39.88%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.9100,                   Accuracy: 25128/60000 (41.88%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.3523,                   Accuracy: 25298/60000 (42.16%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.0843,                   Accuracy: 25739/60000 (42.90%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.1186,                   Accuracy: 24245/60000 (40.41%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.8920,                   Accuracy: 21916/60000 (36.53%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.6681,                   Accuracy: 19454/60000 (32.42%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.6861,                   Accuracy: 17036/60000 (28.39%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.8420,                   Accuracy: 14846/60000 (24.74%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.8626,                   Accuracy: 12818/60000 (21.36%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.6647,                   Accuracy: 12102/60000 (20.17%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.6663,                   Accuracy: 11337/60000 (18.90%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.2424,                   Accuracy: 11040/60000 (18.40%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.7714,                   Accuracy: 11005/60000 (18.34%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.8713,                   Accuracy: 12943/60000 (21.57%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.5512,                   Accuracy: 20411/60000 (34.02%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.0586,                   Accuracy: 32592/60000 (54.32%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8599,                   Accuracy: 46405/60000 (77.34%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2401,                   Accuracy: 55867/60000 (93.11%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0795,                   Accuracy: 58646/60000 (97.74%)
{0: tensor(98.5233), 10: tensor(97.7683), 20: tensor(94.7450), 30: tensor(85.5183), 40: tensor(70.1683), 50: tensor(52.9083), 60: tensor(37.5333), 70: tensor(26.5933), 80: tensor(19.5133), 90: tensor(17.2367), 100: tensor(18.0800), 110: tensor(18.5767), 120: tensor(20.2700), 130: tensor(24.9883), 140: tensor(29.9033), 150: tensor(34.9167), 160: tensor(39.8850), 170: tensor(41.8800), 180: tensor(42.1633), 190: tensor(42.8983), 200: tensor(40.4083), 210: tensor(36.5267), 220: tensor(32.4233), 230: tensor(28.3933), 240: tensor(24.7433), 250: tensor(21.3633), 260: tensor(20.1700), 270: tensor(18.8950), 280: tensor(18.4000), 290: tensor(18.3417), 300: tensor(21.5717), 310: tensor(34.0183), 320: tensor(54.3200), 330: tensor(77.3417), 340: tensor(93.1117), 350: tensor(97.7433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=44, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.3421,                   Accuracy: 1011/2000.0 (50.55%)



-= Testing valid =-
Test set: Average loss: 0.2279,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.2625,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.3144,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.1356,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.0633,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1118,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1759,                   Accuracy: 1895/2000.0 (94.75%)



Epoch 10 train accuracy: 97.93%, valid accuracy 94.75%
-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 20 train accuracy: 98.96%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.16%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.60%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.72%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0465,                   Accuracy: 59198/60000 (98.66%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0788,                   Accuracy: 58686/60000 (97.81%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1962,                   Accuracy: 56809/60000 (94.68%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6149,                   Accuracy: 50436/60000 (84.06%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4696,                   Accuracy: 40015/60000 (66.69%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.6697,                   Accuracy: 29110/60000 (48.52%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.9367,                   Accuracy: 20441/60000 (34.07%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.7388,                   Accuracy: 15179/60000 (25.30%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.3148,                   Accuracy: 11832/60000 (19.72%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.7719,                   Accuracy: 11098/60000 (18.50%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.9149,                   Accuracy: 11359/60000 (18.93%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.1381,                   Accuracy: 11398/60000 (19.00%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.2873,                   Accuracy: 12113/60000 (20.19%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.3021,                   Accuracy: 14797/60000 (24.66%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.2194,                   Accuracy: 17695/60000 (29.49%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.9854,                   Accuracy: 21357/60000 (35.60%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.0411,                   Accuracy: 24550/60000 (40.92%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.2731,                   Accuracy: 25841/60000 (43.07%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.6348,                   Accuracy: 25857/60000 (43.10%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.5815,                   Accuracy: 25552/60000 (42.59%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.5178,                   Accuracy: 24223/60000 (40.37%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.3224,                   Accuracy: 21469/60000 (35.78%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.2089,                   Accuracy: 19604/60000 (32.67%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.3031,                   Accuracy: 17680/60000 (29.47%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.5210,                   Accuracy: 15246/60000 (25.41%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.6939,                   Accuracy: 13171/60000 (21.95%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.6793,                   Accuracy: 10970/60000 (18.28%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.7421,                   Accuracy: 8890/60000 (14.82%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.4192,                   Accuracy: 8442/60000 (14.07%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.9216,                   Accuracy: 8956/60000 (14.93%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.0503,                   Accuracy: 11884/60000 (19.81%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.8311,                   Accuracy: 19191/60000 (31.99%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.2701,                   Accuracy: 31765/60000 (52.94%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9582,                   Accuracy: 45979/60000 (76.63%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2609,                   Accuracy: 55528/60000 (92.55%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0742,                   Accuracy: 58709/60000 (97.85%)
{0: tensor(98.6633), 10: tensor(97.8100), 20: tensor(94.6817), 30: tensor(84.0600), 40: tensor(66.6917), 50: tensor(48.5167), 60: tensor(34.0683), 70: tensor(25.2983), 80: tensor(19.7200), 90: tensor(18.4967), 100: tensor(18.9317), 110: tensor(18.9967), 120: tensor(20.1883), 130: tensor(24.6617), 140: tensor(29.4917), 150: tensor(35.5950), 160: tensor(40.9167), 170: tensor(43.0683), 180: tensor(43.0950), 190: tensor(42.5867), 200: tensor(40.3717), 210: tensor(35.7817), 220: tensor(32.6733), 230: tensor(29.4667), 240: tensor(25.4100), 250: tensor(21.9517), 260: tensor(18.2833), 270: tensor(14.8167), 280: tensor(14.0700), 290: tensor(14.9267), 300: tensor(19.8067), 310: tensor(31.9850), 320: tensor(52.9417), 330: tensor(76.6317), 340: tensor(92.5467), 350: tensor(97.8483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=45, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.2511,                   Accuracy: 1195/2000.0 (59.75%)



-= Testing valid =-
Test set: Average loss: 0.5974,                   Accuracy: 1558/2000.0 (77.90%)



-= Testing valid =-
Test set: Average loss: 0.2218,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.1124,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.1331,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0684,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 10 train accuracy: 97.32%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 20 train accuracy: 98.93%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0188,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0197,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0212,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 30 train accuracy: 99.20%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0173,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0173,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0194,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0192,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 40 train accuracy: 99.45%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0183,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0202,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0207,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0197,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0204,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0189,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0185,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0207,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0174,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0181,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 50 train accuracy: 99.57%, valid accuracy 99.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0458,                   Accuracy: 59170/60000 (98.62%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0733,                   Accuracy: 58700/60000 (97.83%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1673,                   Accuracy: 57044/60000 (95.07%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4865,                   Accuracy: 51584/60000 (85.97%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.1774,                   Accuracy: 41682/60000 (69.47%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.1495,                   Accuracy: 31233/60000 (52.06%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.2112,                   Accuracy: 22270/60000 (37.12%)
-= Testing Rotation 70 =-
Test set: Average loss: 3.9607,                   Accuracy: 16676/60000 (27.79%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.4662,                   Accuracy: 13455/60000 (22.42%)
-= Testing Rotation 90 =-
Test set: Average loss: 4.9484,                   Accuracy: 11967/60000 (19.94%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.0109,                   Accuracy: 11935/60000 (19.89%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.2382,                   Accuracy: 11405/60000 (19.01%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.2871,                   Accuracy: 13162/60000 (21.94%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.1441,                   Accuracy: 16454/60000 (27.42%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.0963,                   Accuracy: 20054/60000 (33.42%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.1933,                   Accuracy: 23760/60000 (39.60%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.4983,                   Accuracy: 26487/60000 (44.15%)
-= Testing Rotation 170 =-
Test set: Average loss: 5.8610,                   Accuracy: 27582/60000 (45.97%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.3959,                   Accuracy: 27699/60000 (46.17%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.0935,                   Accuracy: 27766/60000 (46.28%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.3631,                   Accuracy: 25832/60000 (43.05%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.2952,                   Accuracy: 22731/60000 (37.88%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.1889,                   Accuracy: 19943/60000 (33.24%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.1818,                   Accuracy: 17582/60000 (29.30%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.1556,                   Accuracy: 15478/60000 (25.80%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.0274,                   Accuracy: 13976/60000 (23.29%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.7717,                   Accuracy: 12659/60000 (21.10%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.7868,                   Accuracy: 10892/60000 (18.15%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.4727,                   Accuracy: 10083/60000 (16.81%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.1176,                   Accuracy: 9434/60000 (15.72%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.5455,                   Accuracy: 11342/60000 (18.90%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.4232,                   Accuracy: 18847/60000 (31.41%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1592,                   Accuracy: 30742/60000 (51.24%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.0314,                   Accuracy: 44119/60000 (73.53%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3044,                   Accuracy: 54550/60000 (90.92%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0892,                   Accuracy: 58369/60000 (97.28%)
{0: tensor(98.6167), 10: tensor(97.8333), 20: tensor(95.0733), 30: tensor(85.9733), 40: tensor(69.4700), 50: tensor(52.0550), 60: tensor(37.1167), 70: tensor(27.7933), 80: tensor(22.4250), 90: tensor(19.9450), 100: tensor(19.8917), 110: tensor(19.0083), 120: tensor(21.9367), 130: tensor(27.4233), 140: tensor(33.4233), 150: tensor(39.6000), 160: tensor(44.1450), 170: tensor(45.9700), 180: tensor(46.1650), 190: tensor(46.2767), 200: tensor(43.0533), 210: tensor(37.8850), 220: tensor(33.2383), 230: tensor(29.3033), 240: tensor(25.7967), 250: tensor(23.2933), 260: tensor(21.0983), 270: tensor(18.1533), 280: tensor(16.8050), 290: tensor(15.7233), 300: tensor(18.9033), 310: tensor(31.4117), 320: tensor(51.2367), 330: tensor(73.5317), 340: tensor(90.9167), 350: tensor(97.2817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=46, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.2457,                   Accuracy: 1117/2000.0 (55.85%)



-= Testing valid =-
Test set: Average loss: 0.3310,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2153,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1103,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1416,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.0572,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 10 train accuracy: 97.70%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0638,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 20 train accuracy: 98.72%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 30 train accuracy: 99.28%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.40%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.72%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0520,                   Accuracy: 59067/60000 (98.44%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0891,                   Accuracy: 58469/60000 (97.45%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2276,                   Accuracy: 56226/60000 (93.71%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6461,                   Accuracy: 49668/60000 (82.78%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5437,                   Accuracy: 38492/60000 (64.15%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.7117,                   Accuracy: 27520/60000 (45.87%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.9184,                   Accuracy: 19724/60000 (32.87%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.7044,                   Accuracy: 14622/60000 (24.37%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.1289,                   Accuracy: 12201/60000 (20.33%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.4260,                   Accuracy: 12191/60000 (20.32%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.3387,                   Accuracy: 12371/60000 (20.62%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.4759,                   Accuracy: 12275/60000 (20.46%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.5163,                   Accuracy: 12360/60000 (20.60%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.5079,                   Accuracy: 13915/60000 (23.19%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.4440,                   Accuracy: 16678/60000 (27.80%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.4281,                   Accuracy: 20747/60000 (34.58%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.7094,                   Accuracy: 24579/60000 (40.97%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.0176,                   Accuracy: 26538/60000 (44.23%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.5161,                   Accuracy: 27311/60000 (45.52%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.3287,                   Accuracy: 27067/60000 (45.11%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.3111,                   Accuracy: 25939/60000 (43.23%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.2124,                   Accuracy: 22766/60000 (37.94%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.2081,                   Accuracy: 19427/60000 (32.38%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.2762,                   Accuracy: 16365/60000 (27.27%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.4165,                   Accuracy: 14596/60000 (24.33%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.5433,                   Accuracy: 12952/60000 (21.59%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.3329,                   Accuracy: 12281/60000 (20.47%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.2489,                   Accuracy: 11708/60000 (19.51%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.8151,                   Accuracy: 10825/60000 (18.04%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.4453,                   Accuracy: 10886/60000 (18.14%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.7220,                   Accuracy: 12399/60000 (20.67%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.6366,                   Accuracy: 18743/60000 (31.24%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.2216,                   Accuracy: 30359/60000 (50.60%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9667,                   Accuracy: 44689/60000 (74.48%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2765,                   Accuracy: 55196/60000 (91.99%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0883,                   Accuracy: 58394/60000 (97.32%)
{0: tensor(98.4450), 10: tensor(97.4483), 20: tensor(93.7100), 30: tensor(82.7800), 40: tensor(64.1533), 50: tensor(45.8667), 60: tensor(32.8733), 70: tensor(24.3700), 80: tensor(20.3350), 90: tensor(20.3183), 100: tensor(20.6183), 110: tensor(20.4583), 120: tensor(20.6000), 130: tensor(23.1917), 140: tensor(27.7967), 150: tensor(34.5783), 160: tensor(40.9650), 170: tensor(44.2300), 180: tensor(45.5183), 190: tensor(45.1117), 200: tensor(43.2317), 210: tensor(37.9433), 220: tensor(32.3783), 230: tensor(27.2750), 240: tensor(24.3267), 250: tensor(21.5867), 260: tensor(20.4683), 270: tensor(19.5133), 280: tensor(18.0417), 290: tensor(18.1433), 300: tensor(20.6650), 310: tensor(31.2383), 320: tensor(50.5983), 330: tensor(74.4817), 340: tensor(91.9933), 350: tensor(97.3233)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=47, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7076,                   Accuracy: 746/2000.0 (37.30%)



-= Testing valid =-
Test set: Average loss: 0.2855,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.1919,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1266,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.2292,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1187,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1228,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 10 train accuracy: 97.68%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0618,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0559,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 20 train accuracy: 98.96%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0454,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.40%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0346,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 40 train accuracy: 99.34%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.64%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0541,                   Accuracy: 59112/60000 (98.52%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0927,                   Accuracy: 58476/60000 (97.46%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2380,                   Accuracy: 56250/60000 (93.75%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6726,                   Accuracy: 50143/60000 (83.57%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5010,                   Accuracy: 40325/60000 (67.21%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.6091,                   Accuracy: 29798/60000 (49.66%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.8167,                   Accuracy: 20494/60000 (34.16%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.6471,                   Accuracy: 14836/60000 (24.73%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.0802,                   Accuracy: 11777/60000 (19.63%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.3434,                   Accuracy: 11543/60000 (19.24%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.4278,                   Accuracy: 11337/60000 (18.90%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.7566,                   Accuracy: 11101/60000 (18.50%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.0306,                   Accuracy: 12221/60000 (20.37%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.1683,                   Accuracy: 14636/60000 (24.39%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.2372,                   Accuracy: 18001/60000 (30.00%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.4351,                   Accuracy: 21741/60000 (36.24%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.8735,                   Accuracy: 24545/60000 (40.91%)
-= Testing Rotation 170 =-
Test set: Average loss: 7.2364,                   Accuracy: 25513/60000 (42.52%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.5725,                   Accuracy: 25883/60000 (43.14%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.4397,                   Accuracy: 25881/60000 (43.13%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.3894,                   Accuracy: 24590/60000 (40.98%)
-= Testing Rotation 210 =-
Test set: Average loss: 7.1509,                   Accuracy: 22049/60000 (36.75%)
-= Testing Rotation 220 =-
Test set: Average loss: 7.0337,                   Accuracy: 19448/60000 (32.41%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.9327,                   Accuracy: 16816/60000 (28.03%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.8127,                   Accuracy: 14359/60000 (23.93%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.6658,                   Accuracy: 12663/60000 (21.10%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.2441,                   Accuracy: 11587/60000 (19.31%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.9472,                   Accuracy: 11362/60000 (18.94%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.5732,                   Accuracy: 10671/60000 (17.78%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.0461,                   Accuracy: 11282/60000 (18.80%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.4693,                   Accuracy: 13106/60000 (21.84%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.3999,                   Accuracy: 20295/60000 (33.83%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.0292,                   Accuracy: 32826/60000 (54.71%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8158,                   Accuracy: 47343/60000 (78.90%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2333,                   Accuracy: 55989/60000 (93.32%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0744,                   Accuracy: 58725/60000 (97.88%)
{0: tensor(98.5200), 10: tensor(97.4600), 20: tensor(93.7500), 30: tensor(83.5717), 40: tensor(67.2083), 50: tensor(49.6633), 60: tensor(34.1567), 70: tensor(24.7267), 80: tensor(19.6283), 90: tensor(19.2383), 100: tensor(18.8950), 110: tensor(18.5017), 120: tensor(20.3683), 130: tensor(24.3933), 140: tensor(30.0017), 150: tensor(36.2350), 160: tensor(40.9083), 170: tensor(42.5217), 180: tensor(43.1383), 190: tensor(43.1350), 200: tensor(40.9833), 210: tensor(36.7483), 220: tensor(32.4133), 230: tensor(28.0267), 240: tensor(23.9317), 250: tensor(21.1050), 260: tensor(19.3117), 270: tensor(18.9367), 280: tensor(17.7850), 290: tensor(18.8033), 300: tensor(21.8433), 310: tensor(33.8250), 320: tensor(54.7100), 330: tensor(78.9050), 340: tensor(93.3150), 350: tensor(97.8750)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=48, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.4679,                   Accuracy: 793/2000.0 (39.65%)



-= Testing valid =-
Test set: Average loss: 0.3568,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.1503,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1986,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1976,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1936,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 10 train accuracy: 98.00%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0454,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 20 train accuracy: 98.76%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0183,                   Accuracy: 1993/2000.0 (99.65%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0204,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 30 train accuracy: 99.41%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0214,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0206,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0221,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0207,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0206,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0192,                   Accuracy: 1989/2000.0 (99.45%)



Epoch 40 train accuracy: 99.55%, valid accuracy 99.45%
-= Testing valid =-
Test set: Average loss: 0.0193,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0196,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0217,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0202,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0177,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0193,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0198,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0202,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0207,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 50 train accuracy: 99.59%, valid accuracy 99.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0489,                   Accuracy: 59165/60000 (98.61%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0774,                   Accuracy: 58674/60000 (97.79%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1946,                   Accuracy: 56850/60000 (94.75%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5650,                   Accuracy: 51424/60000 (85.71%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3770,                   Accuracy: 41445/60000 (69.07%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.6386,                   Accuracy: 29595/60000 (49.33%)
-= Testing Rotation 60 =-
Test set: Average loss: 4.1779,                   Accuracy: 18909/60000 (31.51%)
-= Testing Rotation 70 =-
Test set: Average loss: 5.2028,                   Accuracy: 12895/60000 (21.49%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.8059,                   Accuracy: 9758/60000 (16.26%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.3056,                   Accuracy: 9220/60000 (15.37%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.0229,                   Accuracy: 10666/60000 (17.78%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.0524,                   Accuracy: 10608/60000 (17.68%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.1563,                   Accuracy: 11586/60000 (19.31%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.0118,                   Accuracy: 14133/60000 (23.56%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.8606,                   Accuracy: 17347/60000 (28.91%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.9278,                   Accuracy: 21366/60000 (35.61%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.0463,                   Accuracy: 24586/60000 (40.98%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.3489,                   Accuracy: 26744/60000 (44.57%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.0215,                   Accuracy: 27232/60000 (45.39%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.6190,                   Accuracy: 27383/60000 (45.64%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.7364,                   Accuracy: 25616/60000 (42.69%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.6815,                   Accuracy: 22426/60000 (37.38%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.6047,                   Accuracy: 18881/60000 (31.47%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.7229,                   Accuracy: 15547/60000 (25.91%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.9239,                   Accuracy: 12794/60000 (21.32%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.8885,                   Accuracy: 10858/60000 (18.10%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.6446,                   Accuracy: 9907/60000 (16.51%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.8079,                   Accuracy: 8872/60000 (14.79%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.5044,                   Accuracy: 8281/60000 (13.80%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.9259,                   Accuracy: 8920/60000 (14.87%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.0143,                   Accuracy: 12100/60000 (20.17%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.7928,                   Accuracy: 19600/60000 (32.67%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.2576,                   Accuracy: 32017/60000 (53.36%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9333,                   Accuracy: 46329/60000 (77.21%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2691,                   Accuracy: 55582/60000 (92.64%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0719,                   Accuracy: 58732/60000 (97.89%)
{0: tensor(98.6083), 10: tensor(97.7900), 20: tensor(94.7500), 30: tensor(85.7067), 40: tensor(69.0750), 50: tensor(49.3250), 60: tensor(31.5150), 70: tensor(21.4917), 80: tensor(16.2633), 90: tensor(15.3667), 100: tensor(17.7767), 110: tensor(17.6800), 120: tensor(19.3100), 130: tensor(23.5550), 140: tensor(28.9117), 150: tensor(35.6100), 160: tensor(40.9767), 170: tensor(44.5733), 180: tensor(45.3867), 190: tensor(45.6383), 200: tensor(42.6933), 210: tensor(37.3767), 220: tensor(31.4683), 230: tensor(25.9117), 240: tensor(21.3233), 250: tensor(18.0967), 260: tensor(16.5117), 270: tensor(14.7867), 280: tensor(13.8017), 290: tensor(14.8667), 300: tensor(20.1667), 310: tensor(32.6667), 320: tensor(53.3617), 330: tensor(77.2150), 340: tensor(92.6367), 350: tensor(97.8867)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=49, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 0.9541,                   Accuracy: 1600/2000.0 (80.00%)



-= Testing valid =-
Test set: Average loss: 0.3826,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.3151,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2016,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1570,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1379,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1328,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1197,                   Accuracy: 1930/2000.0 (96.50%)



Epoch 10 train accuracy: 97.34%, valid accuracy 96.50%
-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0552,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0527,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 20 train accuracy: 98.81%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 30 train accuracy: 99.22%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0428,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 40 train accuracy: 99.56%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.66%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0536,                   Accuracy: 59108/60000 (98.51%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0903,                   Accuracy: 58514/60000 (97.52%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2303,                   Accuracy: 56389/60000 (93.98%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5932,                   Accuracy: 50912/60000 (84.85%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3356,                   Accuracy: 40941/60000 (68.24%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.4435,                   Accuracy: 30602/60000 (51.00%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.7554,                   Accuracy: 21070/60000 (35.12%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.6823,                   Accuracy: 15072/60000 (25.12%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.3917,                   Accuracy: 11590/60000 (19.32%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.7084,                   Accuracy: 11470/60000 (19.12%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.8903,                   Accuracy: 10783/60000 (17.97%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.2540,                   Accuracy: 9702/60000 (16.17%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.1513,                   Accuracy: 10594/60000 (17.66%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.1347,                   Accuracy: 13440/60000 (22.40%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.9449,                   Accuracy: 17722/60000 (29.54%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.7922,                   Accuracy: 21984/60000 (36.64%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.9669,                   Accuracy: 25742/60000 (42.90%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.2353,                   Accuracy: 27571/60000 (45.95%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.9142,                   Accuracy: 26948/60000 (44.91%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.5621,                   Accuracy: 27261/60000 (45.44%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.7444,                   Accuracy: 25544/60000 (42.57%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.4221,                   Accuracy: 22709/60000 (37.85%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.3607,                   Accuracy: 20123/60000 (33.54%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.4743,                   Accuracy: 17564/60000 (29.27%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.5803,                   Accuracy: 14998/60000 (25.00%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.7690,                   Accuracy: 12988/60000 (21.65%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.6021,                   Accuracy: 11908/60000 (19.85%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.3175,                   Accuracy: 10631/60000 (17.72%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.9586,                   Accuracy: 10156/60000 (16.93%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.5144,                   Accuracy: 10025/60000 (16.71%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.6999,                   Accuracy: 11517/60000 (19.19%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.5454,                   Accuracy: 18902/60000 (31.50%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1372,                   Accuracy: 31104/60000 (51.84%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9348,                   Accuracy: 45404/60000 (75.67%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2832,                   Accuracy: 55273/60000 (92.12%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0880,                   Accuracy: 58479/60000 (97.46%)
{0: tensor(98.5133), 10: tensor(97.5233), 20: tensor(93.9817), 30: tensor(84.8533), 40: tensor(68.2350), 50: tensor(51.0033), 60: tensor(35.1167), 70: tensor(25.1200), 80: tensor(19.3167), 90: tensor(19.1167), 100: tensor(17.9717), 110: tensor(16.1700), 120: tensor(17.6567), 130: tensor(22.4000), 140: tensor(29.5367), 150: tensor(36.6400), 160: tensor(42.9033), 170: tensor(45.9517), 180: tensor(44.9133), 190: tensor(45.4350), 200: tensor(42.5733), 210: tensor(37.8483), 220: tensor(33.5383), 230: tensor(29.2733), 240: tensor(24.9967), 250: tensor(21.6467), 260: tensor(19.8467), 270: tensor(17.7183), 280: tensor(16.9267), 290: tensor(16.7083), 300: tensor(19.1950), 310: tensor(31.5033), 320: tensor(51.8400), 330: tensor(75.6733), 340: tensor(92.1217), 350: tensor(97.4650)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=50, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7270,                   Accuracy: 671/2000.0 (33.55%)



-= Testing valid =-
Test set: Average loss: 0.7304,                   Accuracy: 1497/2000.0 (74.85%)



-= Testing valid =-
Test set: Average loss: 0.2921,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.1574,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1572,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.3865,                   Accuracy: 1780/2000.0 (89.00%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1158,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1496,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 10 train accuracy: 97.95%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0632,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0736,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0601,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 20 train accuracy: 98.95%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0496,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0626,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 30 train accuracy: 99.38%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0496,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 40 train accuracy: 99.54%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.53%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0573,                   Accuracy: 59038/60000 (98.40%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0910,                   Accuracy: 58467/60000 (97.44%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2395,                   Accuracy: 56084/60000 (93.47%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7003,                   Accuracy: 48923/60000 (81.54%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5020,                   Accuracy: 38583/60000 (64.31%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.5377,                   Accuracy: 28295/60000 (47.16%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.6740,                   Accuracy: 19111/60000 (31.85%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.5389,                   Accuracy: 13195/60000 (21.99%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.1459,                   Accuracy: 9973/60000 (16.62%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.4217,                   Accuracy: 9905/60000 (16.51%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.4792,                   Accuracy: 9886/60000 (16.48%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.6062,                   Accuracy: 9927/60000 (16.55%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.6960,                   Accuracy: 11559/60000 (19.26%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.7239,                   Accuracy: 14733/60000 (24.56%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.6536,                   Accuracy: 18923/60000 (31.54%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.7613,                   Accuracy: 23421/60000 (39.03%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.1020,                   Accuracy: 26038/60000 (43.40%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.3715,                   Accuracy: 27750/60000 (46.25%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.9172,                   Accuracy: 27779/60000 (46.30%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.8311,                   Accuracy: 28189/60000 (46.98%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.7682,                   Accuracy: 26534/60000 (44.22%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.6912,                   Accuracy: 22858/60000 (38.10%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.8403,                   Accuracy: 19030/60000 (31.72%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.9101,                   Accuracy: 16300/60000 (27.17%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.9622,                   Accuracy: 13435/60000 (22.39%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.8935,                   Accuracy: 11737/60000 (19.56%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.6790,                   Accuracy: 10885/60000 (18.14%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.3914,                   Accuracy: 10995/60000 (18.33%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.0211,                   Accuracy: 10923/60000 (18.20%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.3311,                   Accuracy: 11528/60000 (19.21%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.3230,                   Accuracy: 14669/60000 (24.45%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.0685,                   Accuracy: 22538/60000 (37.56%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.7407,                   Accuracy: 35361/60000 (58.94%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7161,                   Accuracy: 48569/60000 (80.95%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2229,                   Accuracy: 56312/60000 (93.85%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0812,                   Accuracy: 58632/60000 (97.72%)
{0: tensor(98.3967), 10: tensor(97.4450), 20: tensor(93.4733), 30: tensor(81.5383), 40: tensor(64.3050), 50: tensor(47.1583), 60: tensor(31.8517), 70: tensor(21.9917), 80: tensor(16.6217), 90: tensor(16.5083), 100: tensor(16.4767), 110: tensor(16.5450), 120: tensor(19.2650), 130: tensor(24.5550), 140: tensor(31.5383), 150: tensor(39.0350), 160: tensor(43.3967), 170: tensor(46.2500), 180: tensor(46.2983), 190: tensor(46.9817), 200: tensor(44.2233), 210: tensor(38.0967), 220: tensor(31.7167), 230: tensor(27.1667), 240: tensor(22.3917), 250: tensor(19.5617), 260: tensor(18.1417), 270: tensor(18.3250), 280: tensor(18.2050), 290: tensor(19.2133), 300: tensor(24.4483), 310: tensor(37.5633), 320: tensor(58.9350), 330: tensor(80.9483), 340: tensor(93.8533), 350: tensor(97.7200)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=51, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1341,                   Accuracy: 586/2000.0 (29.30%)



-= Testing valid =-
Test set: Average loss: 1.3786,                   Accuracy: 1207/2000.0 (60.35%)



-= Testing valid =-
Test set: Average loss: 0.2034,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1525,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.2070,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 10 train accuracy: 97.76%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0445,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0520,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 20 train accuracy: 98.94%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 30 train accuracy: 99.46%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.66%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.74%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0499,                   Accuracy: 59176/60000 (98.63%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0864,                   Accuracy: 58609/60000 (97.68%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2317,                   Accuracy: 56415/60000 (94.03%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7110,                   Accuracy: 49549/60000 (82.58%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5981,                   Accuracy: 38791/60000 (64.65%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.7829,                   Accuracy: 27645/60000 (46.08%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.9261,                   Accuracy: 18426/60000 (30.71%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.7393,                   Accuracy: 13540/60000 (22.57%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.1344,                   Accuracy: 10966/60000 (18.28%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.3917,                   Accuracy: 10368/60000 (17.28%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.5060,                   Accuracy: 10840/60000 (18.07%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.8831,                   Accuracy: 10962/60000 (18.27%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.9392,                   Accuracy: 12584/60000 (20.97%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.9274,                   Accuracy: 15073/60000 (25.12%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.8926,                   Accuracy: 18212/60000 (30.35%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.0561,                   Accuracy: 21975/60000 (36.62%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.5430,                   Accuracy: 24639/60000 (41.06%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.9654,                   Accuracy: 26233/60000 (43.72%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.4442,                   Accuracy: 26459/60000 (44.10%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.3366,                   Accuracy: 26212/60000 (43.69%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.3568,                   Accuracy: 24533/60000 (40.89%)
-= Testing Rotation 210 =-
Test set: Average loss: 7.1046,                   Accuracy: 21837/60000 (36.40%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.8943,                   Accuracy: 19047/60000 (31.75%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.6796,                   Accuracy: 17010/60000 (28.35%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.4109,                   Accuracy: 14912/60000 (24.85%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.0988,                   Accuracy: 14085/60000 (23.48%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.8366,                   Accuracy: 12922/60000 (21.54%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.7202,                   Accuracy: 10958/60000 (18.26%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.3595,                   Accuracy: 10221/60000 (17.03%)
-= Testing Rotation 290 =-
Test set: Average loss: 4.9102,                   Accuracy: 10100/60000 (16.83%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.1934,                   Accuracy: 13085/60000 (21.81%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.1048,                   Accuracy: 21099/60000 (35.17%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.8342,                   Accuracy: 33826/60000 (56.38%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7952,                   Accuracy: 46997/60000 (78.33%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2469,                   Accuracy: 55738/60000 (92.90%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0806,                   Accuracy: 58629/60000 (97.71%)
{0: tensor(98.6267), 10: tensor(97.6817), 20: tensor(94.0250), 30: tensor(82.5817), 40: tensor(64.6517), 50: tensor(46.0750), 60: tensor(30.7100), 70: tensor(22.5667), 80: tensor(18.2767), 90: tensor(17.2800), 100: tensor(18.0667), 110: tensor(18.2700), 120: tensor(20.9733), 130: tensor(25.1217), 140: tensor(30.3533), 150: tensor(36.6250), 160: tensor(41.0650), 170: tensor(43.7217), 180: tensor(44.0983), 190: tensor(43.6867), 200: tensor(40.8883), 210: tensor(36.3950), 220: tensor(31.7450), 230: tensor(28.3500), 240: tensor(24.8533), 250: tensor(23.4750), 260: tensor(21.5367), 270: tensor(18.2633), 280: tensor(17.0350), 290: tensor(16.8333), 300: tensor(21.8083), 310: tensor(35.1650), 320: tensor(56.3767), 330: tensor(78.3283), 340: tensor(92.8967), 350: tensor(97.7150)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=52, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.0709,                   Accuracy: 1306/2000.0 (65.30%)



-= Testing valid =-
Test set: Average loss: 0.3041,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2311,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1966,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.1491,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1290,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.1521,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1388,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 10 train accuracy: 97.95%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0454,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0606,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 20 train accuracy: 99.07%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.39%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.46%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 50 train accuracy: 99.74%, valid accuracy 98.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0476,                   Accuracy: 59208/60000 (98.68%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0768,                   Accuracy: 58750/60000 (97.92%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1916,                   Accuracy: 56959/60000 (94.93%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6090,                   Accuracy: 50199/60000 (83.67%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3949,                   Accuracy: 40713/60000 (67.86%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.6139,                   Accuracy: 29575/60000 (49.29%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.9702,                   Accuracy: 20300/60000 (33.83%)
-= Testing Rotation 70 =-
Test set: Average loss: 5.0796,                   Accuracy: 14319/60000 (23.86%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.8515,                   Accuracy: 10882/60000 (18.14%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.2644,                   Accuracy: 10805/60000 (18.01%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.3413,                   Accuracy: 10481/60000 (17.47%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.4572,                   Accuracy: 11350/60000 (18.92%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.4658,                   Accuracy: 12569/60000 (20.95%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.2612,                   Accuracy: 15043/60000 (25.07%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.9877,                   Accuracy: 18564/60000 (30.94%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.9113,                   Accuracy: 22087/60000 (36.81%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.1839,                   Accuracy: 24755/60000 (41.26%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.5248,                   Accuracy: 26453/60000 (44.09%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.9238,                   Accuracy: 26522/60000 (44.20%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.5483,                   Accuracy: 26739/60000 (44.56%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.3527,                   Accuracy: 25557/60000 (42.60%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.1817,                   Accuracy: 22792/60000 (37.99%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.0646,                   Accuracy: 19622/60000 (32.70%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.3473,                   Accuracy: 16439/60000 (27.40%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.8111,                   Accuracy: 13511/60000 (22.52%)
-= Testing Rotation 250 =-
Test set: Average loss: 7.1937,                   Accuracy: 11141/60000 (18.57%)
-= Testing Rotation 260 =-
Test set: Average loss: 7.5529,                   Accuracy: 9939/60000 (16.57%)
-= Testing Rotation 270 =-
Test set: Average loss: 7.7779,                   Accuracy: 8511/60000 (14.19%)
-= Testing Rotation 280 =-
Test set: Average loss: 7.5959,                   Accuracy: 7682/60000 (12.80%)
-= Testing Rotation 290 =-
Test set: Average loss: 7.0406,                   Accuracy: 7691/60000 (12.82%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.9404,                   Accuracy: 10685/60000 (17.81%)
-= Testing Rotation 310 =-
Test set: Average loss: 4.3256,                   Accuracy: 18425/60000 (30.71%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.4626,                   Accuracy: 31430/60000 (52.38%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.0104,                   Accuracy: 45790/60000 (76.32%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2747,                   Accuracy: 55503/60000 (92.50%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0759,                   Accuracy: 58708/60000 (97.85%)
{0: tensor(98.6800), 10: tensor(97.9167), 20: tensor(94.9317), 30: tensor(83.6650), 40: tensor(67.8550), 50: tensor(49.2917), 60: tensor(33.8333), 70: tensor(23.8650), 80: tensor(18.1367), 90: tensor(18.0083), 100: tensor(17.4683), 110: tensor(18.9167), 120: tensor(20.9483), 130: tensor(25.0717), 140: tensor(30.9400), 150: tensor(36.8117), 160: tensor(41.2583), 170: tensor(44.0883), 180: tensor(44.2033), 190: tensor(44.5650), 200: tensor(42.5950), 210: tensor(37.9867), 220: tensor(32.7033), 230: tensor(27.3983), 240: tensor(22.5183), 250: tensor(18.5683), 260: tensor(16.5650), 270: tensor(14.1850), 280: tensor(12.8033), 290: tensor(12.8183), 300: tensor(17.8083), 310: tensor(30.7083), 320: tensor(52.3833), 330: tensor(76.3167), 340: tensor(92.5050), 350: tensor(97.8467)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=53, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.5148,                   Accuracy: 867/2000.0 (43.35%)



-= Testing valid =-
Test set: Average loss: 0.7926,                   Accuracy: 1571/2000.0 (78.55%)



-= Testing valid =-
Test set: Average loss: 0.1705,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1591,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1880,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.2136,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1175,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 10 train accuracy: 97.76%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0742,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0636,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0453,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0501,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 20 train accuracy: 99.10%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.36%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.60%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 50 train accuracy: 99.66%, valid accuracy 98.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0500,                   Accuracy: 59127/60000 (98.54%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0802,                   Accuracy: 58645/60000 (97.74%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1791,                   Accuracy: 57019/60000 (95.03%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5143,                   Accuracy: 51554/60000 (85.92%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.2067,                   Accuracy: 41815/60000 (69.69%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.1531,                   Accuracy: 31763/60000 (52.94%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.2544,                   Accuracy: 22669/60000 (37.78%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.2222,                   Accuracy: 16089/60000 (26.82%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.9408,                   Accuracy: 12339/60000 (20.57%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.4149,                   Accuracy: 11365/60000 (18.94%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.8379,                   Accuracy: 10605/60000 (17.67%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.1776,                   Accuracy: 9573/60000 (15.95%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.4315,                   Accuracy: 10206/60000 (17.01%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.3942,                   Accuracy: 12901/60000 (21.50%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.2887,                   Accuracy: 17032/60000 (28.39%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.1918,                   Accuracy: 21300/60000 (35.50%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.3983,                   Accuracy: 24793/60000 (41.32%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.5289,                   Accuracy: 26437/60000 (44.06%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.7073,                   Accuracy: 26699/60000 (44.50%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.4750,                   Accuracy: 26740/60000 (44.57%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.6164,                   Accuracy: 25296/60000 (42.16%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.5527,                   Accuracy: 22783/60000 (37.97%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.5759,                   Accuracy: 20000/60000 (33.33%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.6380,                   Accuracy: 17375/60000 (28.96%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.6592,                   Accuracy: 14654/60000 (24.42%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.7504,                   Accuracy: 12033/60000 (20.06%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.5116,                   Accuracy: 10808/60000 (18.01%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.3676,                   Accuracy: 9557/60000 (15.93%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.0844,                   Accuracy: 8484/60000 (14.14%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.7200,                   Accuracy: 8823/60000 (14.70%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.8717,                   Accuracy: 11854/60000 (19.76%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.6737,                   Accuracy: 19609/60000 (32.68%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.3015,                   Accuracy: 31556/60000 (52.59%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.0356,                   Accuracy: 45147/60000 (75.25%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2965,                   Accuracy: 55078/60000 (91.80%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0822,                   Accuracy: 58594/60000 (97.66%)
{0: tensor(98.5450), 10: tensor(97.7417), 20: tensor(95.0317), 30: tensor(85.9233), 40: tensor(69.6917), 50: tensor(52.9383), 60: tensor(37.7817), 70: tensor(26.8150), 80: tensor(20.5650), 90: tensor(18.9417), 100: tensor(17.6750), 110: tensor(15.9550), 120: tensor(17.0100), 130: tensor(21.5017), 140: tensor(28.3867), 150: tensor(35.5000), 160: tensor(41.3217), 170: tensor(44.0617), 180: tensor(44.4983), 190: tensor(44.5667), 200: tensor(42.1600), 210: tensor(37.9717), 220: tensor(33.3333), 230: tensor(28.9583), 240: tensor(24.4233), 250: tensor(20.0550), 260: tensor(18.0133), 270: tensor(15.9283), 280: tensor(14.1400), 290: tensor(14.7050), 300: tensor(19.7567), 310: tensor(32.6817), 320: tensor(52.5933), 330: tensor(75.2450), 340: tensor(91.7967), 350: tensor(97.6567)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=54, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 0.9891,                   Accuracy: 1418/2000.0 (70.90%)



-= Testing valid =-
Test set: Average loss: 0.4890,                   Accuracy: 1680/2000.0 (84.00%)



-= Testing valid =-
Test set: Average loss: 0.2279,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.1999,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1133,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1637,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1952,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 10 train accuracy: 97.90%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0554,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0636,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0522,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 20 train accuracy: 98.81%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.31%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.35%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.56%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0577,                   Accuracy: 59068/60000 (98.45%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0932,                   Accuracy: 58466/60000 (97.44%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2279,                   Accuracy: 56462/60000 (94.10%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6550,                   Accuracy: 50216/60000 (83.69%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5012,                   Accuracy: 39964/60000 (66.61%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.6981,                   Accuracy: 29599/60000 (49.33%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.9990,                   Accuracy: 20532/60000 (34.22%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.8663,                   Accuracy: 14950/60000 (24.92%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.4561,                   Accuracy: 11709/60000 (19.51%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.8809,                   Accuracy: 10955/60000 (18.26%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.8413,                   Accuracy: 11577/60000 (19.30%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.8792,                   Accuracy: 12100/60000 (20.17%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.9565,                   Accuracy: 13565/60000 (22.61%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.8774,                   Accuracy: 16225/60000 (27.04%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.7891,                   Accuracy: 19665/60000 (32.78%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.9225,                   Accuracy: 23415/60000 (39.03%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.4433,                   Accuracy: 25398/60000 (42.33%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.8225,                   Accuracy: 26407/60000 (44.01%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.5663,                   Accuracy: 26314/60000 (43.86%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.2602,                   Accuracy: 26358/60000 (43.93%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.3088,                   Accuracy: 24527/60000 (40.88%)
-= Testing Rotation 210 =-
Test set: Average loss: 7.1705,                   Accuracy: 21613/60000 (36.02%)
-= Testing Rotation 220 =-
Test set: Average loss: 7.0091,                   Accuracy: 18584/60000 (30.97%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.9419,                   Accuracy: 16022/60000 (26.70%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.9654,                   Accuracy: 13347/60000 (22.25%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.8671,                   Accuracy: 11551/60000 (19.25%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.7500,                   Accuracy: 10500/60000 (17.50%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.6186,                   Accuracy: 10172/60000 (16.95%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.2865,                   Accuracy: 9774/60000 (16.29%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.5210,                   Accuracy: 10685/60000 (17.81%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.7552,                   Accuracy: 13663/60000 (22.77%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.4058,                   Accuracy: 21833/60000 (36.39%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.9518,                   Accuracy: 34125/60000 (56.88%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7806,                   Accuracy: 47861/60000 (79.77%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2136,                   Accuracy: 56293/60000 (93.82%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0761,                   Accuracy: 58666/60000 (97.78%)
{0: tensor(98.4467), 10: tensor(97.4433), 20: tensor(94.1033), 30: tensor(83.6933), 40: tensor(66.6067), 50: tensor(49.3317), 60: tensor(34.2200), 70: tensor(24.9167), 80: tensor(19.5150), 90: tensor(18.2583), 100: tensor(19.2950), 110: tensor(20.1667), 120: tensor(22.6083), 130: tensor(27.0417), 140: tensor(32.7750), 150: tensor(39.0250), 160: tensor(42.3300), 170: tensor(44.0117), 180: tensor(43.8567), 190: tensor(43.9300), 200: tensor(40.8783), 210: tensor(36.0217), 220: tensor(30.9733), 230: tensor(26.7033), 240: tensor(22.2450), 250: tensor(19.2517), 260: tensor(17.5000), 270: tensor(16.9533), 280: tensor(16.2900), 290: tensor(17.8083), 300: tensor(22.7717), 310: tensor(36.3883), 320: tensor(56.8750), 330: tensor(79.7683), 340: tensor(93.8217), 350: tensor(97.7767)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=55, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.2450,                   Accuracy: 1037/2000.0 (51.85%)



-= Testing valid =-
Test set: Average loss: 0.2696,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1848,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1302,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1399,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1643,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1462,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1210,                   Accuracy: 1921/2000.0 (96.05%)



Epoch 10 train accuracy: 97.76%, valid accuracy 96.05%
-= Testing valid =-
Test set: Average loss: 0.0601,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0511,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 20 train accuracy: 98.79%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 30 train accuracy: 99.28%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.44%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 50 train accuracy: 99.61%, valid accuracy 99.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0547,                   Accuracy: 59129/60000 (98.55%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0850,                   Accuracy: 58610/60000 (97.68%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1979,                   Accuracy: 56817/60000 (94.69%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5895,                   Accuracy: 51128/60000 (85.21%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3770,                   Accuracy: 41336/60000 (68.89%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.5059,                   Accuracy: 30561/60000 (50.94%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.7565,                   Accuracy: 21443/60000 (35.74%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.5849,                   Accuracy: 16254/60000 (27.09%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.1804,                   Accuracy: 12197/60000 (20.33%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.3992,                   Accuracy: 11844/60000 (19.74%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.5396,                   Accuracy: 12169/60000 (20.28%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.7204,                   Accuracy: 11889/60000 (19.82%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.7913,                   Accuracy: 13394/60000 (22.32%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.9005,                   Accuracy: 16229/60000 (27.05%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.0536,                   Accuracy: 19455/60000 (32.42%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.2583,                   Accuracy: 23057/60000 (38.43%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.5781,                   Accuracy: 25995/60000 (43.33%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.9891,                   Accuracy: 27404/60000 (45.67%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.5424,                   Accuracy: 26752/60000 (44.59%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.3824,                   Accuracy: 26437/60000 (44.06%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.3511,                   Accuracy: 24646/60000 (41.08%)
-= Testing Rotation 210 =-
Test set: Average loss: 7.2459,                   Accuracy: 22002/60000 (36.67%)
-= Testing Rotation 220 =-
Test set: Average loss: 7.1287,                   Accuracy: 20087/60000 (33.48%)
-= Testing Rotation 230 =-
Test set: Average loss: 7.0836,                   Accuracy: 17930/60000 (29.88%)
-= Testing Rotation 240 =-
Test set: Average loss: 7.0905,                   Accuracy: 15597/60000 (26.00%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.9506,                   Accuracy: 14214/60000 (23.69%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.8174,                   Accuracy: 12441/60000 (20.74%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.4897,                   Accuracy: 11231/60000 (18.72%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.0962,                   Accuracy: 10368/60000 (17.28%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.6796,                   Accuracy: 10371/60000 (17.28%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.9150,                   Accuracy: 13259/60000 (22.10%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.8427,                   Accuracy: 20449/60000 (34.08%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.3718,                   Accuracy: 32707/60000 (54.51%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.0095,                   Accuracy: 46425/60000 (77.38%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3105,                   Accuracy: 55035/60000 (91.72%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0826,                   Accuracy: 58610/60000 (97.68%)
{0: tensor(98.5483), 10: tensor(97.6833), 20: tensor(94.6950), 30: tensor(85.2133), 40: tensor(68.8933), 50: tensor(50.9350), 60: tensor(35.7383), 70: tensor(27.0900), 80: tensor(20.3283), 90: tensor(19.7400), 100: tensor(20.2817), 110: tensor(19.8150), 120: tensor(22.3233), 130: tensor(27.0483), 140: tensor(32.4250), 150: tensor(38.4283), 160: tensor(43.3250), 170: tensor(45.6733), 180: tensor(44.5867), 190: tensor(44.0617), 200: tensor(41.0767), 210: tensor(36.6700), 220: tensor(33.4783), 230: tensor(29.8833), 240: tensor(25.9950), 250: tensor(23.6900), 260: tensor(20.7350), 270: tensor(18.7183), 280: tensor(17.2800), 290: tensor(17.2850), 300: tensor(22.0983), 310: tensor(34.0817), 320: tensor(54.5117), 330: tensor(77.3750), 340: tensor(91.7250), 350: tensor(97.6833)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=56, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8314,                   Accuracy: 813/2000.0 (40.65%)



-= Testing valid =-
Test set: Average loss: 0.2021,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1913,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.2625,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2557,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.1462,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.1744,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 10 train accuracy: 98.11%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 20 train accuracy: 99.22%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0363,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 30 train accuracy: 99.38%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 40 train accuracy: 99.66%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.79%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0492,                   Accuracy: 59132/60000 (98.55%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0756,                   Accuracy: 58722/60000 (97.87%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1830,                   Accuracy: 56947/60000 (94.91%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5267,                   Accuracy: 51551/60000 (85.92%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.2364,                   Accuracy: 42035/60000 (70.06%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.1794,                   Accuracy: 32227/60000 (53.71%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.1816,                   Accuracy: 23136/60000 (38.56%)
-= Testing Rotation 70 =-
Test set: Average loss: 3.9310,                   Accuracy: 16599/60000 (27.67%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.4416,                   Accuracy: 12018/60000 (20.03%)
-= Testing Rotation 90 =-
Test set: Average loss: 4.7756,                   Accuracy: 11023/60000 (18.37%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.2199,                   Accuracy: 10037/60000 (16.73%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.8322,                   Accuracy: 9646/60000 (16.08%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.3187,                   Accuracy: 11212/60000 (18.69%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.5750,                   Accuracy: 14978/60000 (24.96%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.5188,                   Accuracy: 18967/60000 (31.61%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.3327,                   Accuracy: 22585/60000 (37.64%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.2488,                   Accuracy: 25237/60000 (42.06%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.2861,                   Accuracy: 26941/60000 (44.90%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.5642,                   Accuracy: 26780/60000 (44.63%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.4005,                   Accuracy: 27063/60000 (45.10%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.4330,                   Accuracy: 25376/60000 (42.29%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.1998,                   Accuracy: 22461/60000 (37.44%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.0167,                   Accuracy: 18993/60000 (31.66%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.8539,                   Accuracy: 16158/60000 (26.93%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.7314,                   Accuracy: 13392/60000 (22.32%)
-= Testing Rotation 250 =-
Test set: Average loss: 5.6307,                   Accuracy: 11401/60000 (19.00%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.4570,                   Accuracy: 10581/60000 (17.64%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.3500,                   Accuracy: 10115/60000 (16.86%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.1374,                   Accuracy: 9213/60000 (15.35%)
-= Testing Rotation 290 =-
Test set: Average loss: 4.8156,                   Accuracy: 9492/60000 (15.82%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.1347,                   Accuracy: 12524/60000 (20.87%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.1501,                   Accuracy: 20498/60000 (34.16%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.8915,                   Accuracy: 33534/60000 (55.89%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8643,                   Accuracy: 46467/60000 (77.44%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2906,                   Accuracy: 54781/60000 (91.30%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0854,                   Accuracy: 58432/60000 (97.39%)
{0: tensor(98.5533), 10: tensor(97.8700), 20: tensor(94.9117), 30: tensor(85.9183), 40: tensor(70.0583), 50: tensor(53.7117), 60: tensor(38.5600), 70: tensor(27.6650), 80: tensor(20.0300), 90: tensor(18.3717), 100: tensor(16.7283), 110: tensor(16.0767), 120: tensor(18.6867), 130: tensor(24.9633), 140: tensor(31.6117), 150: tensor(37.6417), 160: tensor(42.0617), 170: tensor(44.9017), 180: tensor(44.6333), 190: tensor(45.1050), 200: tensor(42.2933), 210: tensor(37.4350), 220: tensor(31.6550), 230: tensor(26.9300), 240: tensor(22.3200), 250: tensor(19.0017), 260: tensor(17.6350), 270: tensor(16.8583), 280: tensor(15.3550), 290: tensor(15.8200), 300: tensor(20.8733), 310: tensor(34.1633), 320: tensor(55.8900), 330: tensor(77.4450), 340: tensor(91.3017), 350: tensor(97.3867)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=57, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.0984,                   Accuracy: 1161/2000.0 (58.05%)



-= Testing valid =-
Test set: Average loss: 0.2717,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.1798,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1215,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.2657,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1532,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 10 train accuracy: 97.80%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0454,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 20 train accuracy: 98.89%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0472,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 30 train accuracy: 99.31%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 40 train accuracy: 99.53%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.65%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0528,                   Accuracy: 59112/60000 (98.52%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0873,                   Accuracy: 58571/60000 (97.62%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2106,                   Accuracy: 56770/60000 (94.62%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5824,                   Accuracy: 51187/60000 (85.31%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3776,                   Accuracy: 41356/60000 (68.93%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.5140,                   Accuracy: 30736/60000 (51.23%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.8322,                   Accuracy: 21775/60000 (36.29%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.7932,                   Accuracy: 16059/60000 (26.76%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.5819,                   Accuracy: 12082/60000 (20.14%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.9735,                   Accuracy: 11835/60000 (19.73%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.8789,                   Accuracy: 12728/60000 (21.21%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.9556,                   Accuracy: 13471/60000 (22.45%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.2006,                   Accuracy: 14113/60000 (23.52%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.3842,                   Accuracy: 16084/60000 (26.81%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.5871,                   Accuracy: 18803/60000 (31.34%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.6970,                   Accuracy: 22369/60000 (37.28%)
-= Testing Rotation 160 =-
Test set: Average loss: 7.0695,                   Accuracy: 25258/60000 (42.10%)
-= Testing Rotation 170 =-
Test set: Average loss: 7.4682,                   Accuracy: 26410/60000 (44.02%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.7977,                   Accuracy: 26254/60000 (43.76%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.6045,                   Accuracy: 26839/60000 (44.73%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.6139,                   Accuracy: 25448/60000 (42.41%)
-= Testing Rotation 210 =-
Test set: Average loss: 7.5676,                   Accuracy: 22455/60000 (37.42%)
-= Testing Rotation 220 =-
Test set: Average loss: 7.3937,                   Accuracy: 19783/60000 (32.97%)
-= Testing Rotation 230 =-
Test set: Average loss: 7.3467,                   Accuracy: 17147/60000 (28.58%)
-= Testing Rotation 240 =-
Test set: Average loss: 7.3183,                   Accuracy: 15158/60000 (25.26%)
-= Testing Rotation 250 =-
Test set: Average loss: 7.3229,                   Accuracy: 13371/60000 (22.28%)
-= Testing Rotation 260 =-
Test set: Average loss: 7.0494,                   Accuracy: 12275/60000 (20.46%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.9027,                   Accuracy: 11097/60000 (18.50%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.3291,                   Accuracy: 10632/60000 (17.72%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.7413,                   Accuracy: 10947/60000 (18.25%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.0284,                   Accuracy: 13611/60000 (22.68%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.7619,                   Accuracy: 21096/60000 (35.16%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1969,                   Accuracy: 33645/60000 (56.08%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9095,                   Accuracy: 47040/60000 (78.40%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2543,                   Accuracy: 55715/60000 (92.86%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0799,                   Accuracy: 58628/60000 (97.71%)
{0: tensor(98.5200), 10: tensor(97.6183), 20: tensor(94.6167), 30: tensor(85.3117), 40: tensor(68.9267), 50: tensor(51.2267), 60: tensor(36.2917), 70: tensor(26.7650), 80: tensor(20.1367), 90: tensor(19.7250), 100: tensor(21.2133), 110: tensor(22.4517), 120: tensor(23.5217), 130: tensor(26.8067), 140: tensor(31.3383), 150: tensor(37.2817), 160: tensor(42.0967), 170: tensor(44.0167), 180: tensor(43.7567), 190: tensor(44.7317), 200: tensor(42.4133), 210: tensor(37.4250), 220: tensor(32.9717), 230: tensor(28.5783), 240: tensor(25.2633), 250: tensor(22.2850), 260: tensor(20.4583), 270: tensor(18.4950), 280: tensor(17.7200), 290: tensor(18.2450), 300: tensor(22.6850), 310: tensor(35.1600), 320: tensor(56.0750), 330: tensor(78.4000), 340: tensor(92.8583), 350: tensor(97.7133)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=58, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.0361,                   Accuracy: 1456/2000.0 (72.80%)



-= Testing valid =-
Test set: Average loss: 0.3545,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.1888,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.2358,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.1141,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1459,                   Accuracy: 1914/2000.0 (95.70%)



Epoch 10 train accuracy: 97.64%, valid accuracy 95.70%
-= Testing valid =-
Test set: Average loss: 0.0533,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0605,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0535,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0575,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 20 train accuracy: 98.80%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.26%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 40 train accuracy: 99.65%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 50 train accuracy: 99.60%, valid accuracy 98.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0499,                   Accuracy: 59148/60000 (98.58%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0786,                   Accuracy: 58721/60000 (97.87%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2031,                   Accuracy: 56735/60000 (94.56%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6320,                   Accuracy: 49906/60000 (83.18%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3143,                   Accuracy: 40774/60000 (67.96%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.2605,                   Accuracy: 30961/60000 (51.60%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.4408,                   Accuracy: 21524/60000 (35.87%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.2852,                   Accuracy: 15501/60000 (25.83%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.9295,                   Accuracy: 12322/60000 (20.54%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.4235,                   Accuracy: 10473/60000 (17.45%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.5328,                   Accuracy: 10123/60000 (16.87%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.7767,                   Accuracy: 10163/60000 (16.94%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.9556,                   Accuracy: 10998/60000 (18.33%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.9286,                   Accuracy: 13765/60000 (22.94%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.9506,                   Accuracy: 17367/60000 (28.94%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.0044,                   Accuracy: 21629/60000 (36.05%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.4072,                   Accuracy: 24710/60000 (41.18%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.6756,                   Accuracy: 25931/60000 (43.22%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.1543,                   Accuracy: 26375/60000 (43.96%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.0986,                   Accuracy: 26611/60000 (44.35%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.2566,                   Accuracy: 25251/60000 (42.08%)
-= Testing Rotation 210 =-
Test set: Average loss: 7.2006,                   Accuracy: 21971/60000 (36.62%)
-= Testing Rotation 220 =-
Test set: Average loss: 7.0558,                   Accuracy: 19333/60000 (32.22%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.8979,                   Accuracy: 16932/60000 (28.22%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.6762,                   Accuracy: 14278/60000 (23.80%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.6610,                   Accuracy: 12118/60000 (20.20%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.2285,                   Accuracy: 10748/60000 (17.91%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.0613,                   Accuracy: 9057/60000 (15.10%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.6558,                   Accuracy: 8831/60000 (14.72%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.2868,                   Accuracy: 8872/60000 (14.79%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.4987,                   Accuracy: 11541/60000 (19.24%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.3848,                   Accuracy: 18936/60000 (31.56%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.9575,                   Accuracy: 31790/60000 (52.98%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7964,                   Accuracy: 46827/60000 (78.04%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2408,                   Accuracy: 55891/60000 (93.15%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0772,                   Accuracy: 58660/60000 (97.77%)
{0: tensor(98.5800), 10: tensor(97.8683), 20: tensor(94.5583), 30: tensor(83.1767), 40: tensor(67.9567), 50: tensor(51.6017), 60: tensor(35.8733), 70: tensor(25.8350), 80: tensor(20.5367), 90: tensor(17.4550), 100: tensor(16.8717), 110: tensor(16.9383), 120: tensor(18.3300), 130: tensor(22.9417), 140: tensor(28.9450), 150: tensor(36.0483), 160: tensor(41.1833), 170: tensor(43.2183), 180: tensor(43.9583), 190: tensor(44.3517), 200: tensor(42.0850), 210: tensor(36.6183), 220: tensor(32.2217), 230: tensor(28.2200), 240: tensor(23.7967), 250: tensor(20.1967), 260: tensor(17.9133), 270: tensor(15.0950), 280: tensor(14.7183), 290: tensor(14.7867), 300: tensor(19.2350), 310: tensor(31.5600), 320: tensor(52.9833), 330: tensor(78.0450), 340: tensor(93.1517), 350: tensor(97.7667)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=59, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.3614,                   Accuracy: 1114/2000.0 (55.70%)



-= Testing valid =-
Test set: Average loss: 0.3221,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.2349,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2411,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.1618,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0606,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 10 train accuracy: 97.99%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0644,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 20 train accuracy: 98.95%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 30 train accuracy: 99.15%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0219,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0203,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0230,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 40 train accuracy: 99.61%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0214,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0198,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0196,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0204,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0197,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0194,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0189,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0201,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 50 train accuracy: 99.56%, valid accuracy 99.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0535,                   Accuracy: 59088/60000 (98.48%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0906,                   Accuracy: 58485/60000 (97.47%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2325,                   Accuracy: 56307/60000 (93.85%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6974,                   Accuracy: 49610/60000 (82.68%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5793,                   Accuracy: 39165/60000 (65.28%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.7366,                   Accuracy: 28831/60000 (48.05%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.9548,                   Accuracy: 20199/60000 (33.67%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.8445,                   Accuracy: 14739/60000 (24.57%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.4211,                   Accuracy: 11593/60000 (19.32%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.9142,                   Accuracy: 11100/60000 (18.50%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.8626,                   Accuracy: 11174/60000 (18.62%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.8689,                   Accuracy: 11481/60000 (19.14%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.8420,                   Accuracy: 12810/60000 (21.35%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.7325,                   Accuracy: 15419/60000 (25.70%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.5918,                   Accuracy: 18531/60000 (30.89%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.6311,                   Accuracy: 22220/60000 (37.03%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.8947,                   Accuracy: 25093/60000 (41.82%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.0943,                   Accuracy: 26531/60000 (44.22%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.5385,                   Accuracy: 26718/60000 (44.53%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.2144,                   Accuracy: 26474/60000 (44.12%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.2217,                   Accuracy: 24166/60000 (40.28%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.3499,                   Accuracy: 20766/60000 (34.61%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.3801,                   Accuracy: 18004/60000 (30.01%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.4556,                   Accuracy: 15512/60000 (25.85%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.5312,                   Accuracy: 12998/60000 (21.66%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.4687,                   Accuracy: 11131/60000 (18.55%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.3490,                   Accuracy: 10283/60000 (17.14%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.3262,                   Accuracy: 9647/60000 (16.08%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.9769,                   Accuracy: 9421/60000 (15.70%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.3875,                   Accuracy: 10029/60000 (16.72%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.5721,                   Accuracy: 13751/60000 (22.92%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.3839,                   Accuracy: 22148/60000 (36.91%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.9880,                   Accuracy: 34996/60000 (58.33%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8183,                   Accuracy: 48088/60000 (80.15%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2367,                   Accuracy: 56031/60000 (93.39%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0740,                   Accuracy: 58722/60000 (97.87%)
{0: tensor(98.4800), 10: tensor(97.4750), 20: tensor(93.8450), 30: tensor(82.6833), 40: tensor(65.2750), 50: tensor(48.0517), 60: tensor(33.6650), 70: tensor(24.5650), 80: tensor(19.3217), 90: tensor(18.5000), 100: tensor(18.6233), 110: tensor(19.1350), 120: tensor(21.3500), 130: tensor(25.6983), 140: tensor(30.8850), 150: tensor(37.0333), 160: tensor(41.8217), 170: tensor(44.2183), 180: tensor(44.5300), 190: tensor(44.1233), 200: tensor(40.2767), 210: tensor(34.6100), 220: tensor(30.0067), 230: tensor(25.8533), 240: tensor(21.6633), 250: tensor(18.5517), 260: tensor(17.1383), 270: tensor(16.0783), 280: tensor(15.7017), 290: tensor(16.7150), 300: tensor(22.9183), 310: tensor(36.9133), 320: tensor(58.3267), 330: tensor(80.1467), 340: tensor(93.3850), 350: tensor(97.8700)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=60, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.5988,                   Accuracy: 708/2000.0 (35.40%)



-= Testing valid =-
Test set: Average loss: 0.2870,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.1723,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1149,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1757,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0495,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 10 train accuracy: 97.88%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 20 train accuracy: 98.78%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0217,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 30 train accuracy: 99.34%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0207,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0206,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0220,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 40 train accuracy: 99.69%, valid accuracy 99.35%
-= Testing valid =-
Test set: Average loss: 0.0210,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0202,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0212,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0196,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0201,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0200,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0183,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0196,                   Accuracy: 1989/2000.0 (99.45%)



Epoch 50 train accuracy: 99.59%, valid accuracy 99.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0470,                   Accuracy: 59197/60000 (98.66%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0849,                   Accuracy: 58549/60000 (97.58%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2309,                   Accuracy: 56185/60000 (93.64%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6838,                   Accuracy: 49561/60000 (82.60%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5408,                   Accuracy: 39355/60000 (65.59%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.7157,                   Accuracy: 28431/60000 (47.38%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.9588,                   Accuracy: 19455/60000 (32.42%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.8492,                   Accuracy: 13772/60000 (22.95%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.2739,                   Accuracy: 11211/60000 (18.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.5794,                   Accuracy: 10454/60000 (17.42%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.7635,                   Accuracy: 10121/60000 (16.87%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.0427,                   Accuracy: 10255/60000 (17.09%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.1671,                   Accuracy: 11765/60000 (19.61%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.1487,                   Accuracy: 14991/60000 (24.99%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.9961,                   Accuracy: 18481/60000 (30.80%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.9051,                   Accuracy: 22118/60000 (36.86%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.2078,                   Accuracy: 25077/60000 (41.79%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.4818,                   Accuracy: 26184/60000 (43.64%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.9072,                   Accuracy: 26569/60000 (44.28%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.6867,                   Accuracy: 26602/60000 (44.34%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.6343,                   Accuracy: 25125/60000 (41.88%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.4412,                   Accuracy: 22262/60000 (37.10%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.3351,                   Accuracy: 19222/60000 (32.04%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.3832,                   Accuracy: 16509/60000 (27.51%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.5719,                   Accuracy: 13792/60000 (22.99%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.6735,                   Accuracy: 11519/60000 (19.20%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.4716,                   Accuracy: 9707/60000 (16.18%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.4675,                   Accuracy: 8323/60000 (13.87%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.2239,                   Accuracy: 7736/60000 (12.89%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.8063,                   Accuracy: 8036/60000 (13.39%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.9244,                   Accuracy: 11530/60000 (19.22%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.6547,                   Accuracy: 19887/60000 (33.15%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1223,                   Accuracy: 32858/60000 (54.76%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8556,                   Accuracy: 47028/60000 (78.38%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2262,                   Accuracy: 56121/60000 (93.54%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0733,                   Accuracy: 58737/60000 (97.89%)
{0: tensor(98.6617), 10: tensor(97.5817), 20: tensor(93.6417), 30: tensor(82.6017), 40: tensor(65.5917), 50: tensor(47.3850), 60: tensor(32.4250), 70: tensor(22.9533), 80: tensor(18.6850), 90: tensor(17.4233), 100: tensor(16.8683), 110: tensor(17.0917), 120: tensor(19.6083), 130: tensor(24.9850), 140: tensor(30.8017), 150: tensor(36.8633), 160: tensor(41.7950), 170: tensor(43.6400), 180: tensor(44.2817), 190: tensor(44.3367), 200: tensor(41.8750), 210: tensor(37.1033), 220: tensor(32.0367), 230: tensor(27.5150), 240: tensor(22.9867), 250: tensor(19.1983), 260: tensor(16.1783), 270: tensor(13.8717), 280: tensor(12.8933), 290: tensor(13.3933), 300: tensor(19.2167), 310: tensor(33.1450), 320: tensor(54.7633), 330: tensor(78.3800), 340: tensor(93.5350), 350: tensor(97.8950)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=61, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7562,                   Accuracy: 649/2000.0 (32.45%)



-= Testing valid =-
Test set: Average loss: 0.4300,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.1795,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1773,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0686,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1133,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1361,                   Accuracy: 1913/2000.0 (95.65%)



Epoch 10 train accuracy: 97.91%, valid accuracy 95.65%
-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0621,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0668,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0630,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0646,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 20 train accuracy: 98.93%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0469,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0567,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 30 train accuracy: 99.26%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 40 train accuracy: 99.46%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 50 train accuracy: 99.66%, valid accuracy 98.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0594,                   Accuracy: 58992/60000 (98.32%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0915,                   Accuracy: 58478/60000 (97.46%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2237,                   Accuracy: 56381/60000 (93.97%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6339,                   Accuracy: 50113/60000 (83.52%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4209,                   Accuracy: 40044/60000 (66.74%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.6128,                   Accuracy: 29228/60000 (48.71%)
-= Testing Rotation 60 =-
Test set: Average loss: 4.0088,                   Accuracy: 20283/60000 (33.81%)
-= Testing Rotation 70 =-
Test set: Average loss: 5.0999,                   Accuracy: 14587/60000 (24.31%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.9966,                   Accuracy: 10807/60000 (18.01%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.3222,                   Accuracy: 10342/60000 (17.24%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.3274,                   Accuracy: 10232/60000 (17.05%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.1908,                   Accuracy: 10497/60000 (17.50%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.9065,                   Accuracy: 11703/60000 (19.50%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.6467,                   Accuracy: 14718/60000 (24.53%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.5759,                   Accuracy: 18322/60000 (30.54%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.6537,                   Accuracy: 22231/60000 (37.05%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.1369,                   Accuracy: 24605/60000 (41.01%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.6967,                   Accuracy: 25779/60000 (42.97%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.1574,                   Accuracy: 25332/60000 (42.22%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.4483,                   Accuracy: 25456/60000 (42.43%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.4951,                   Accuracy: 24116/60000 (40.19%)
-= Testing Rotation 210 =-
Test set: Average loss: 7.0640,                   Accuracy: 22007/60000 (36.68%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.9223,                   Accuracy: 19392/60000 (32.32%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.8747,                   Accuracy: 16989/60000 (28.32%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.8719,                   Accuracy: 15372/60000 (25.62%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.9226,                   Accuracy: 14037/60000 (23.40%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.8645,                   Accuracy: 12927/60000 (21.55%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.8093,                   Accuracy: 12277/60000 (20.46%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.4480,                   Accuracy: 11669/60000 (19.45%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.6918,                   Accuracy: 12263/60000 (20.44%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.6179,                   Accuracy: 14363/60000 (23.94%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.3328,                   Accuracy: 21122/60000 (35.20%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.9557,                   Accuracy: 32641/60000 (54.40%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8320,                   Accuracy: 46283/60000 (77.14%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2599,                   Accuracy: 55366/60000 (92.28%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0823,                   Accuracy: 58608/60000 (97.68%)
{0: tensor(98.3200), 10: tensor(97.4633), 20: tensor(93.9683), 30: tensor(83.5217), 40: tensor(66.7400), 50: tensor(48.7133), 60: tensor(33.8050), 70: tensor(24.3117), 80: tensor(18.0117), 90: tensor(17.2367), 100: tensor(17.0533), 110: tensor(17.4950), 120: tensor(19.5050), 130: tensor(24.5300), 140: tensor(30.5367), 150: tensor(37.0517), 160: tensor(41.0083), 170: tensor(42.9650), 180: tensor(42.2200), 190: tensor(42.4267), 200: tensor(40.1933), 210: tensor(36.6783), 220: tensor(32.3200), 230: tensor(28.3150), 240: tensor(25.6200), 250: tensor(23.3950), 260: tensor(21.5450), 270: tensor(20.4617), 280: tensor(19.4483), 290: tensor(20.4383), 300: tensor(23.9383), 310: tensor(35.2033), 320: tensor(54.4017), 330: tensor(77.1383), 340: tensor(92.2767), 350: tensor(97.6800)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=62, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3218,                   Accuracy: 775/2000.0 (38.75%)



-= Testing valid =-
Test set: Average loss: 0.3923,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.2629,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.2177,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2844,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.1438,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1941,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.1904,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1130,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 10 train accuracy: 97.72%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.0605,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0687,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0659,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 20 train accuracy: 98.59%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0498,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0486,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 30 train accuracy: 99.26%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0445,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.53%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.57%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0516,                   Accuracy: 59097/60000 (98.50%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0849,                   Accuracy: 58625/60000 (97.71%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2274,                   Accuracy: 56450/60000 (94.08%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6969,                   Accuracy: 49860/60000 (83.10%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.6588,                   Accuracy: 39215/60000 (65.36%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.9763,                   Accuracy: 28794/60000 (47.99%)
-= Testing Rotation 60 =-
Test set: Average loss: 4.4105,                   Accuracy: 20584/60000 (34.31%)
-= Testing Rotation 70 =-
Test set: Average loss: 5.3381,                   Accuracy: 15564/60000 (25.94%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.9687,                   Accuracy: 12392/60000 (20.65%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.2898,                   Accuracy: 12063/60000 (20.10%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.0992,                   Accuracy: 11982/60000 (19.97%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.0375,                   Accuracy: 12020/60000 (20.03%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.0617,                   Accuracy: 12511/60000 (20.85%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.0371,                   Accuracy: 14600/60000 (24.33%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.1048,                   Accuracy: 17381/60000 (28.97%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.2704,                   Accuracy: 20916/60000 (34.86%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.6765,                   Accuracy: 23828/60000 (39.71%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.8860,                   Accuracy: 25833/60000 (43.06%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.1928,                   Accuracy: 26740/60000 (44.57%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.7727,                   Accuracy: 27054/60000 (45.09%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.8610,                   Accuracy: 25419/60000 (42.37%)
-= Testing Rotation 210 =-
Test set: Average loss: 7.0694,                   Accuracy: 22013/60000 (36.69%)
-= Testing Rotation 220 =-
Test set: Average loss: 7.2096,                   Accuracy: 18719/60000 (31.20%)
-= Testing Rotation 230 =-
Test set: Average loss: 7.3795,                   Accuracy: 16210/60000 (27.02%)
-= Testing Rotation 240 =-
Test set: Average loss: 7.3744,                   Accuracy: 14382/60000 (23.97%)
-= Testing Rotation 250 =-
Test set: Average loss: 7.1306,                   Accuracy: 13128/60000 (21.88%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.8279,                   Accuracy: 12244/60000 (20.41%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.6304,                   Accuracy: 12364/60000 (20.61%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.2970,                   Accuracy: 11239/60000 (18.73%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.7814,                   Accuracy: 10885/60000 (18.14%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.0411,                   Accuracy: 12436/60000 (20.73%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.8642,                   Accuracy: 19078/60000 (31.80%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.4087,                   Accuracy: 30710/60000 (51.18%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.0767,                   Accuracy: 44406/60000 (74.01%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3171,                   Accuracy: 54637/60000 (91.06%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0935,                   Accuracy: 58369/60000 (97.28%)
{0: tensor(98.4950), 10: tensor(97.7083), 20: tensor(94.0833), 30: tensor(83.1000), 40: tensor(65.3583), 50: tensor(47.9900), 60: tensor(34.3067), 70: tensor(25.9400), 80: tensor(20.6533), 90: tensor(20.1050), 100: tensor(19.9700), 110: tensor(20.0333), 120: tensor(20.8517), 130: tensor(24.3333), 140: tensor(28.9683), 150: tensor(34.8600), 160: tensor(39.7133), 170: tensor(43.0550), 180: tensor(44.5667), 190: tensor(45.0900), 200: tensor(42.3650), 210: tensor(36.6883), 220: tensor(31.1983), 230: tensor(27.0167), 240: tensor(23.9700), 250: tensor(21.8800), 260: tensor(20.4067), 270: tensor(20.6067), 280: tensor(18.7317), 290: tensor(18.1417), 300: tensor(20.7267), 310: tensor(31.7967), 320: tensor(51.1833), 330: tensor(74.0100), 340: tensor(91.0617), 350: tensor(97.2817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=63, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.3724,                   Accuracy: 953/2000.0 (47.65%)



-= Testing valid =-
Test set: Average loss: 0.3045,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2012,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1346,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1405,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1438,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1743,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1405,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 10 train accuracy: 98.01%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.0529,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 20 train accuracy: 99.06%, valid accuracy 99.30%
-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 30 train accuracy: 99.50%, valid accuracy 99.35%
-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0205,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.69%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0212,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0223,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0213,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0205,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0200,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0204,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0198,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 50 train accuracy: 99.65%, valid accuracy 99.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0563,                   Accuracy: 59024/60000 (98.37%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0940,                   Accuracy: 58452/60000 (97.42%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2386,                   Accuracy: 56215/60000 (93.69%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7162,                   Accuracy: 48945/60000 (81.57%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5341,                   Accuracy: 38954/60000 (64.92%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.5797,                   Accuracy: 28947/60000 (48.24%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.6870,                   Accuracy: 20988/60000 (34.98%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.5090,                   Accuracy: 15975/60000 (26.62%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.0841,                   Accuracy: 12835/60000 (21.39%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.5376,                   Accuracy: 11969/60000 (19.95%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.8703,                   Accuracy: 11096/60000 (18.49%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.1529,                   Accuracy: 10338/60000 (17.23%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.2191,                   Accuracy: 11326/60000 (18.88%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.1333,                   Accuracy: 13841/60000 (23.07%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.8392,                   Accuracy: 17112/60000 (28.52%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.4868,                   Accuracy: 20731/60000 (34.55%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.5402,                   Accuracy: 23869/60000 (39.78%)
-= Testing Rotation 170 =-
Test set: Average loss: 5.7359,                   Accuracy: 25739/60000 (42.90%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.2168,                   Accuracy: 26033/60000 (43.39%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.0251,                   Accuracy: 26379/60000 (43.97%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.0072,                   Accuracy: 25213/60000 (42.02%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.8220,                   Accuracy: 22601/60000 (37.67%)
-= Testing Rotation 220 =-
Test set: Average loss: 5.7949,                   Accuracy: 19404/60000 (32.34%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.9271,                   Accuracy: 16884/60000 (28.14%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.1412,                   Accuracy: 14894/60000 (24.82%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.3617,                   Accuracy: 13348/60000 (22.25%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.4587,                   Accuracy: 11934/60000 (19.89%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.4813,                   Accuracy: 10705/60000 (17.84%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.3635,                   Accuracy: 9458/60000 (15.76%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.8669,                   Accuracy: 9109/60000 (15.18%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.9979,                   Accuracy: 11383/60000 (18.97%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.7345,                   Accuracy: 18774/60000 (31.29%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.2596,                   Accuracy: 30840/60000 (51.40%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9691,                   Accuracy: 45043/60000 (75.07%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2827,                   Accuracy: 54967/60000 (91.61%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0884,                   Accuracy: 58451/60000 (97.42%)
{0: tensor(98.3733), 10: tensor(97.4200), 20: tensor(93.6917), 30: tensor(81.5750), 40: tensor(64.9233), 50: tensor(48.2450), 60: tensor(34.9800), 70: tensor(26.6250), 80: tensor(21.3917), 90: tensor(19.9483), 100: tensor(18.4933), 110: tensor(17.2300), 120: tensor(18.8767), 130: tensor(23.0683), 140: tensor(28.5200), 150: tensor(34.5517), 160: tensor(39.7817), 170: tensor(42.8983), 180: tensor(43.3883), 190: tensor(43.9650), 200: tensor(42.0217), 210: tensor(37.6683), 220: tensor(32.3400), 230: tensor(28.1400), 240: tensor(24.8233), 250: tensor(22.2467), 260: tensor(19.8900), 270: tensor(17.8417), 280: tensor(15.7633), 290: tensor(15.1817), 300: tensor(18.9717), 310: tensor(31.2900), 320: tensor(51.4000), 330: tensor(75.0717), 340: tensor(91.6117), 350: tensor(97.4183)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=64, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.0456,                   Accuracy: 227/2000.0 (11.35%)



-= Testing valid =-
Test set: Average loss: 0.9259,                   Accuracy: 1407/2000.0 (70.35%)



-= Testing valid =-
Test set: Average loss: 0.9376,                   Accuracy: 1410/2000.0 (70.50%)



-= Testing valid =-
Test set: Average loss: 0.5353,                   Accuracy: 1676/2000.0 (83.80%)



-= Testing valid =-
Test set: Average loss: 0.1119,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1311,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1798,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1172,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.1131,                   Accuracy: 1928/2000.0 (96.40%)



Epoch 10 train accuracy: 97.71%, valid accuracy 96.40%
-= Testing valid =-
Test set: Average loss: 0.1197,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0596,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 20 train accuracy: 98.82%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 30 train accuracy: 99.32%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0205,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0253,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.36%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0217,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0221,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0197,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 50 train accuracy: 99.49%, valid accuracy 99.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0613,                   Accuracy: 58979/60000 (98.30%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0848,                   Accuracy: 58522/60000 (97.54%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2053,                   Accuracy: 56633/60000 (94.39%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5678,                   Accuracy: 50903/60000 (84.84%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.2882,                   Accuracy: 41822/60000 (69.70%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.1716,                   Accuracy: 32231/60000 (53.72%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.1878,                   Accuracy: 23223/60000 (38.71%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.0013,                   Accuracy: 17957/60000 (29.93%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.6154,                   Accuracy: 14679/60000 (24.47%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.2773,                   Accuracy: 12743/60000 (21.24%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.6122,                   Accuracy: 11826/60000 (19.71%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.3331,                   Accuracy: 11054/60000 (18.42%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.6659,                   Accuracy: 11298/60000 (18.83%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.7409,                   Accuracy: 14137/60000 (23.56%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.5459,                   Accuracy: 17553/60000 (29.25%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.4902,                   Accuracy: 20862/60000 (34.77%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.5518,                   Accuracy: 24431/60000 (40.72%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.6648,                   Accuracy: 26552/60000 (44.25%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.1257,                   Accuracy: 25682/60000 (42.80%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.7371,                   Accuracy: 26625/60000 (44.38%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.6207,                   Accuracy: 25019/60000 (41.70%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.2436,                   Accuracy: 22060/60000 (36.77%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.1504,                   Accuracy: 20001/60000 (33.33%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.9792,                   Accuracy: 18678/60000 (31.13%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.8717,                   Accuracy: 16625/60000 (27.71%)
-= Testing Rotation 250 =-
Test set: Average loss: 5.9161,                   Accuracy: 15308/60000 (25.51%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.7508,                   Accuracy: 13959/60000 (23.26%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.9442,                   Accuracy: 11639/60000 (19.40%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.7057,                   Accuracy: 10397/60000 (17.33%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.4329,                   Accuracy: 10157/60000 (16.93%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.8038,                   Accuracy: 12059/60000 (20.10%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.6153,                   Accuracy: 19883/60000 (33.14%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.2449,                   Accuracy: 31869/60000 (53.12%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.1157,                   Accuracy: 43959/60000 (73.26%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3453,                   Accuracy: 54012/60000 (90.02%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0883,                   Accuracy: 58447/60000 (97.41%)
{0: tensor(98.2983), 10: tensor(97.5367), 20: tensor(94.3883), 30: tensor(84.8383), 40: tensor(69.7033), 50: tensor(53.7183), 60: tensor(38.7050), 70: tensor(29.9283), 80: tensor(24.4650), 90: tensor(21.2383), 100: tensor(19.7100), 110: tensor(18.4233), 120: tensor(18.8300), 130: tensor(23.5617), 140: tensor(29.2550), 150: tensor(34.7700), 160: tensor(40.7183), 170: tensor(44.2533), 180: tensor(42.8033), 190: tensor(44.3750), 200: tensor(41.6983), 210: tensor(36.7667), 220: tensor(33.3350), 230: tensor(31.1300), 240: tensor(27.7083), 250: tensor(25.5133), 260: tensor(23.2650), 270: tensor(19.3983), 280: tensor(17.3283), 290: tensor(16.9283), 300: tensor(20.0983), 310: tensor(33.1383), 320: tensor(53.1150), 330: tensor(73.2650), 340: tensor(90.0200), 350: tensor(97.4117)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=65, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.6875,                   Accuracy: 598/2000.0 (29.90%)



-= Testing valid =-
Test set: Average loss: 0.5952,                   Accuracy: 1644/2000.0 (82.20%)



-= Testing valid =-
Test set: Average loss: 0.1887,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.3477,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1894,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.1311,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 10 train accuracy: 97.81%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0554,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 20 train accuracy: 98.55%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 30 train accuracy: 99.26%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.36%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.66%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0543,                   Accuracy: 59098/60000 (98.50%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0926,                   Accuracy: 58489/60000 (97.48%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2558,                   Accuracy: 55915/60000 (93.19%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7627,                   Accuracy: 48409/60000 (80.68%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.6940,                   Accuracy: 37197/60000 (61.99%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.7889,                   Accuracy: 26801/60000 (44.67%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.9816,                   Accuracy: 17891/60000 (29.82%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.8149,                   Accuracy: 12100/60000 (20.17%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.4989,                   Accuracy: 9182/60000 (15.30%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.2312,                   Accuracy: 8108/60000 (13.51%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.3309,                   Accuracy: 8364/60000 (13.94%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.6081,                   Accuracy: 9152/60000 (15.25%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.8999,                   Accuracy: 10962/60000 (18.27%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.6407,                   Accuracy: 14238/60000 (23.73%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.3357,                   Accuracy: 17829/60000 (29.72%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.1367,                   Accuracy: 21765/60000 (36.28%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.1648,                   Accuracy: 25425/60000 (42.38%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.4377,                   Accuracy: 27082/60000 (45.14%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.7910,                   Accuracy: 27840/60000 (46.40%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.5399,                   Accuracy: 27956/60000 (46.59%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.5234,                   Accuracy: 25387/60000 (42.31%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.4200,                   Accuracy: 21696/60000 (36.16%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.2893,                   Accuracy: 17842/60000 (29.74%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.2192,                   Accuracy: 14984/60000 (24.97%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.3055,                   Accuracy: 12310/60000 (20.52%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.4779,                   Accuracy: 10257/60000 (17.09%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.5868,                   Accuracy: 9311/60000 (15.52%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.8768,                   Accuracy: 8518/60000 (14.20%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.6761,                   Accuracy: 8277/60000 (13.80%)
-= Testing Rotation 290 =-
Test set: Average loss: 6.2904,                   Accuracy: 8574/60000 (14.29%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.8158,                   Accuracy: 10612/60000 (17.69%)
-= Testing Rotation 310 =-
Test set: Average loss: 4.3212,                   Accuracy: 18231/60000 (30.39%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.5999,                   Accuracy: 30372/60000 (50.62%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.1139,                   Accuracy: 44691/60000 (74.49%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3070,                   Accuracy: 54966/60000 (91.61%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0853,                   Accuracy: 58497/60000 (97.50%)
{0: tensor(98.4967), 10: tensor(97.4817), 20: tensor(93.1917), 30: tensor(80.6817), 40: tensor(61.9950), 50: tensor(44.6683), 60: tensor(29.8183), 70: tensor(20.1667), 80: tensor(15.3033), 90: tensor(13.5133), 100: tensor(13.9400), 110: tensor(15.2533), 120: tensor(18.2700), 130: tensor(23.7300), 140: tensor(29.7150), 150: tensor(36.2750), 160: tensor(42.3750), 170: tensor(45.1367), 180: tensor(46.4000), 190: tensor(46.5933), 200: tensor(42.3117), 210: tensor(36.1600), 220: tensor(29.7367), 230: tensor(24.9733), 240: tensor(20.5167), 250: tensor(17.0950), 260: tensor(15.5183), 270: tensor(14.1967), 280: tensor(13.7950), 290: tensor(14.2900), 300: tensor(17.6867), 310: tensor(30.3850), 320: tensor(50.6200), 330: tensor(74.4850), 340: tensor(91.6100), 350: tensor(97.4950)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=66, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5150,                   Accuracy: 460/2000.0 (23.00%)



-= Testing valid =-
Test set: Average loss: 0.5976,                   Accuracy: 1618/2000.0 (80.90%)



-= Testing valid =-
Test set: Average loss: 0.5340,                   Accuracy: 1660/2000.0 (83.00%)



-= Testing valid =-
Test set: Average loss: 0.3046,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.1219,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1175,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0600,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 10 train accuracy: 97.82%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0520,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 20 train accuracy: 98.91%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0453,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.43%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 40 train accuracy: 99.47%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0268,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.69%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0450,                   Accuracy: 59222/60000 (98.70%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0754,                   Accuracy: 58714/60000 (97.86%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1951,                   Accuracy: 56842/60000 (94.74%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5981,                   Accuracy: 50503/60000 (84.17%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.2991,                   Accuracy: 41233/60000 (68.72%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.2710,                   Accuracy: 31096/60000 (51.83%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.4897,                   Accuracy: 21951/60000 (36.58%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.3853,                   Accuracy: 16064/60000 (26.77%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.1030,                   Accuracy: 13075/60000 (21.79%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.5003,                   Accuracy: 12552/60000 (20.92%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.8166,                   Accuracy: 11190/60000 (18.65%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.1153,                   Accuracy: 10569/60000 (17.61%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.2591,                   Accuracy: 11750/60000 (19.58%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.3535,                   Accuracy: 14417/60000 (24.03%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.2698,                   Accuracy: 18147/60000 (30.25%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.1152,                   Accuracy: 21982/60000 (36.64%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.4526,                   Accuracy: 24790/60000 (41.32%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.4908,                   Accuracy: 25676/60000 (42.79%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.7336,                   Accuracy: 25387/60000 (42.31%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.6162,                   Accuracy: 25664/60000 (42.77%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.7174,                   Accuracy: 24136/60000 (40.23%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.5572,                   Accuracy: 20712/60000 (34.52%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.6083,                   Accuracy: 17916/60000 (29.86%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.6873,                   Accuracy: 15446/60000 (25.74%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.7942,                   Accuracy: 13356/60000 (22.26%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.7317,                   Accuracy: 12189/60000 (20.32%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.4677,                   Accuracy: 11539/60000 (19.23%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.3892,                   Accuracy: 10738/60000 (17.90%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.9798,                   Accuracy: 9159/60000 (15.27%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.3447,                   Accuracy: 9302/60000 (15.50%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.5618,                   Accuracy: 12132/60000 (20.22%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.3569,                   Accuracy: 20097/60000 (33.49%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.9897,                   Accuracy: 32851/60000 (54.75%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8315,                   Accuracy: 47027/60000 (78.38%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2384,                   Accuracy: 55867/60000 (93.11%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0675,                   Accuracy: 58816/60000 (98.03%)
{0: tensor(98.7033), 10: tensor(97.8567), 20: tensor(94.7367), 30: tensor(84.1717), 40: tensor(68.7217), 50: tensor(51.8267), 60: tensor(36.5850), 70: tensor(26.7733), 80: tensor(21.7917), 90: tensor(20.9200), 100: tensor(18.6500), 110: tensor(17.6150), 120: tensor(19.5833), 130: tensor(24.0283), 140: tensor(30.2450), 150: tensor(36.6367), 160: tensor(41.3167), 170: tensor(42.7933), 180: tensor(42.3117), 190: tensor(42.7733), 200: tensor(40.2267), 210: tensor(34.5200), 220: tensor(29.8600), 230: tensor(25.7433), 240: tensor(22.2600), 250: tensor(20.3150), 260: tensor(19.2317), 270: tensor(17.8967), 280: tensor(15.2650), 290: tensor(15.5033), 300: tensor(20.2200), 310: tensor(33.4950), 320: tensor(54.7517), 330: tensor(78.3783), 340: tensor(93.1117), 350: tensor(98.0267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=67, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 0.9575,                   Accuracy: 1345/2000.0 (67.25%)



-= Testing valid =-
Test set: Average loss: 0.4905,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.1787,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1663,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1117,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.2125,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 10 train accuracy: 97.56%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0628,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 20 train accuracy: 98.75%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 30 train accuracy: 99.32%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.51%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.62%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0576,                   Accuracy: 58997/60000 (98.33%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1054,                   Accuracy: 58210/60000 (97.02%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2752,                   Accuracy: 55476/60000 (92.46%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.8105,                   Accuracy: 47541/60000 (79.24%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.7284,                   Accuracy: 36799/60000 (61.33%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.9627,                   Accuracy: 26231/60000 (43.72%)
-= Testing Rotation 60 =-
Test set: Average loss: 4.2190,                   Accuracy: 18074/60000 (30.12%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.9669,                   Accuracy: 13443/60000 (22.41%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.4769,                   Accuracy: 10735/60000 (17.89%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.7029,                   Accuracy: 10791/60000 (17.99%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.6529,                   Accuracy: 11313/60000 (18.85%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.7019,                   Accuracy: 11939/60000 (19.90%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.6169,                   Accuracy: 13656/60000 (22.76%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.6926,                   Accuracy: 16309/60000 (27.18%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.7887,                   Accuracy: 19883/60000 (33.14%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.9800,                   Accuracy: 24062/60000 (40.10%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.3305,                   Accuracy: 26533/60000 (44.22%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.4721,                   Accuracy: 27305/60000 (45.51%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.7509,                   Accuracy: 27627/60000 (46.04%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.3027,                   Accuracy: 27783/60000 (46.31%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.2661,                   Accuracy: 25651/60000 (42.75%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.4455,                   Accuracy: 21472/60000 (35.79%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.4091,                   Accuracy: 17740/60000 (29.57%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.4771,                   Accuracy: 15355/60000 (25.59%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.5922,                   Accuracy: 12985/60000 (21.64%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.5051,                   Accuracy: 11387/60000 (18.98%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.3717,                   Accuracy: 10577/60000 (17.63%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.2755,                   Accuracy: 9714/60000 (16.19%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.8214,                   Accuracy: 9500/60000 (15.83%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.3759,                   Accuracy: 10091/60000 (16.82%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.5779,                   Accuracy: 13293/60000 (22.16%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.4390,                   Accuracy: 21083/60000 (35.14%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.9514,                   Accuracy: 34514/60000 (57.52%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7897,                   Accuracy: 47739/60000 (79.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2199,                   Accuracy: 56078/60000 (93.46%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0781,                   Accuracy: 58625/60000 (97.71%)
{0: tensor(98.3283), 10: tensor(97.0167), 20: tensor(92.4600), 30: tensor(79.2350), 40: tensor(61.3317), 50: tensor(43.7183), 60: tensor(30.1233), 70: tensor(22.4050), 80: tensor(17.8917), 90: tensor(17.9850), 100: tensor(18.8550), 110: tensor(19.8983), 120: tensor(22.7600), 130: tensor(27.1817), 140: tensor(33.1383), 150: tensor(40.1033), 160: tensor(44.2217), 170: tensor(45.5083), 180: tensor(46.0450), 190: tensor(46.3050), 200: tensor(42.7517), 210: tensor(35.7867), 220: tensor(29.5667), 230: tensor(25.5917), 240: tensor(21.6417), 250: tensor(18.9783), 260: tensor(17.6283), 270: tensor(16.1900), 280: tensor(15.8333), 290: tensor(16.8183), 300: tensor(22.1550), 310: tensor(35.1383), 320: tensor(57.5233), 330: tensor(79.5650), 340: tensor(93.4633), 350: tensor(97.7083)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=68, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.1829,                   Accuracy: 346/2000.0 (17.30%)



-= Testing valid =-
Test set: Average loss: 0.5373,                   Accuracy: 1709/2000.0 (85.45%)



-= Testing valid =-
Test set: Average loss: 0.1586,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1818,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1175,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1554,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 10 train accuracy: 98.00%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0472,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 20 train accuracy: 98.49%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.36%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 40 train accuracy: 99.38%, valid accuracy 99.35%
-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.60%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0526,                   Accuracy: 59068/60000 (98.45%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0776,                   Accuracy: 58636/60000 (97.73%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1721,                   Accuracy: 57069/60000 (95.11%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4774,                   Accuracy: 52275/60000 (87.12%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.1353,                   Accuracy: 43346/60000 (72.24%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.0731,                   Accuracy: 33234/60000 (55.39%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.1157,                   Accuracy: 24447/60000 (40.74%)
-= Testing Rotation 70 =-
Test set: Average loss: 3.9896,                   Accuracy: 17794/60000 (29.66%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.5681,                   Accuracy: 13835/60000 (23.06%)
-= Testing Rotation 90 =-
Test set: Average loss: 4.8942,                   Accuracy: 12397/60000 (20.66%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.0741,                   Accuracy: 11306/60000 (18.84%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.3751,                   Accuracy: 10699/60000 (17.83%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.3977,                   Accuracy: 12436/60000 (20.73%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.3632,                   Accuracy: 15624/60000 (26.04%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.2428,                   Accuracy: 19355/60000 (32.26%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.3392,                   Accuracy: 22749/60000 (37.92%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.7621,                   Accuracy: 24915/60000 (41.53%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.0822,                   Accuracy: 25970/60000 (43.28%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.4887,                   Accuracy: 26397/60000 (43.99%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.2442,                   Accuracy: 26585/60000 (44.31%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.2084,                   Accuracy: 25375/60000 (42.29%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.0334,                   Accuracy: 22349/60000 (37.25%)
-= Testing Rotation 220 =-
Test set: Average loss: 5.9061,                   Accuracy: 19370/60000 (32.28%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.9744,                   Accuracy: 16796/60000 (27.99%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.9695,                   Accuracy: 14882/60000 (24.80%)
-= Testing Rotation 250 =-
Test set: Average loss: 5.9705,                   Accuracy: 13097/60000 (21.83%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.7538,                   Accuracy: 12883/60000 (21.47%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.7403,                   Accuracy: 11852/60000 (19.75%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.3673,                   Accuracy: 10642/60000 (17.74%)
-= Testing Rotation 290 =-
Test set: Average loss: 4.8242,                   Accuracy: 10325/60000 (17.21%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.0563,                   Accuracy: 12799/60000 (21.33%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.0427,                   Accuracy: 20388/60000 (33.98%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.8287,                   Accuracy: 32823/60000 (54.71%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7709,                   Accuracy: 47194/60000 (78.66%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2352,                   Accuracy: 55746/60000 (92.91%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0823,                   Accuracy: 58501/60000 (97.50%)
{0: tensor(98.4467), 10: tensor(97.7267), 20: tensor(95.1150), 30: tensor(87.1250), 40: tensor(72.2433), 50: tensor(55.3900), 60: tensor(40.7450), 70: tensor(29.6567), 80: tensor(23.0583), 90: tensor(20.6617), 100: tensor(18.8433), 110: tensor(17.8317), 120: tensor(20.7267), 130: tensor(26.0400), 140: tensor(32.2583), 150: tensor(37.9150), 160: tensor(41.5250), 170: tensor(43.2833), 180: tensor(43.9950), 190: tensor(44.3083), 200: tensor(42.2917), 210: tensor(37.2483), 220: tensor(32.2833), 230: tensor(27.9933), 240: tensor(24.8033), 250: tensor(21.8283), 260: tensor(21.4717), 270: tensor(19.7533), 280: tensor(17.7367), 290: tensor(17.2083), 300: tensor(21.3317), 310: tensor(33.9800), 320: tensor(54.7050), 330: tensor(78.6567), 340: tensor(92.9100), 350: tensor(97.5017)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=69, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 0.9987,                   Accuracy: 1505/2000.0 (75.25%)



-= Testing valid =-
Test set: Average loss: 1.2091,                   Accuracy: 1269/2000.0 (63.45%)



-= Testing valid =-
Test set: Average loss: 0.1674,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1326,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1772,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0709,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0715,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0619,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 10 train accuracy: 97.49%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0486,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 20 train accuracy: 98.74%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0218,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0341,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0240,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 30 train accuracy: 99.24%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0184,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0171,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0214,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0200,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0203,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 40 train accuracy: 99.54%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0193,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0197,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0191,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0185,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0178,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0200,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0173,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0196,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0178,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 50 train accuracy: 99.53%, valid accuracy 99.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0542,                   Accuracy: 59058/60000 (98.43%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1002,                   Accuracy: 58323/60000 (97.21%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2700,                   Accuracy: 55618/60000 (92.70%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.8133,                   Accuracy: 47740/60000 (79.57%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.9393,                   Accuracy: 34704/60000 (57.84%)
-= Testing Rotation 50 =-
Test set: Average loss: 3.4366,                   Accuracy: 23006/60000 (38.34%)
-= Testing Rotation 60 =-
Test set: Average loss: 4.8712,                   Accuracy: 15148/60000 (25.25%)
-= Testing Rotation 70 =-
Test set: Average loss: 5.7357,                   Accuracy: 10718/60000 (17.86%)
-= Testing Rotation 80 =-
Test set: Average loss: 6.1135,                   Accuracy: 8949/60000 (14.91%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.2816,                   Accuracy: 9847/60000 (16.41%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.0701,                   Accuracy: 10949/60000 (18.25%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.1591,                   Accuracy: 11824/60000 (19.71%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.3642,                   Accuracy: 13199/60000 (22.00%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.2952,                   Accuracy: 15674/60000 (26.12%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.2306,                   Accuracy: 18596/60000 (30.99%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.1373,                   Accuracy: 22692/60000 (37.82%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.2680,                   Accuracy: 25388/60000 (42.31%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.5759,                   Accuracy: 27219/60000 (45.37%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.9089,                   Accuracy: 27775/60000 (46.29%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.8615,                   Accuracy: 27666/60000 (46.11%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.9459,                   Accuracy: 25125/60000 (41.88%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.8994,                   Accuracy: 21437/60000 (35.73%)
-= Testing Rotation 220 =-
Test set: Average loss: 7.0378,                   Accuracy: 17687/60000 (29.48%)
-= Testing Rotation 230 =-
Test set: Average loss: 7.2540,                   Accuracy: 14935/60000 (24.89%)
-= Testing Rotation 240 =-
Test set: Average loss: 7.4079,                   Accuracy: 12424/60000 (20.71%)
-= Testing Rotation 250 =-
Test set: Average loss: 7.3887,                   Accuracy: 10395/60000 (17.33%)
-= Testing Rotation 260 =-
Test set: Average loss: 7.2033,                   Accuracy: 9513/60000 (15.85%)
-= Testing Rotation 270 =-
Test set: Average loss: 7.1030,                   Accuracy: 8741/60000 (14.57%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.4084,                   Accuracy: 9205/60000 (15.34%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.8552,                   Accuracy: 9975/60000 (16.62%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.9820,                   Accuracy: 12561/60000 (20.93%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.6870,                   Accuracy: 19900/60000 (33.17%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1547,                   Accuracy: 32593/60000 (54.32%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9397,                   Accuracy: 46267/60000 (77.11%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2617,                   Accuracy: 55583/60000 (92.64%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0777,                   Accuracy: 58620/60000 (97.70%)
{0: tensor(98.4300), 10: tensor(97.2050), 20: tensor(92.6967), 30: tensor(79.5667), 40: tensor(57.8400), 50: tensor(38.3433), 60: tensor(25.2467), 70: tensor(17.8633), 80: tensor(14.9150), 90: tensor(16.4117), 100: tensor(18.2483), 110: tensor(19.7067), 120: tensor(21.9983), 130: tensor(26.1233), 140: tensor(30.9933), 150: tensor(37.8200), 160: tensor(42.3133), 170: tensor(45.3650), 180: tensor(46.2917), 190: tensor(46.1100), 200: tensor(41.8750), 210: tensor(35.7283), 220: tensor(29.4783), 230: tensor(24.8917), 240: tensor(20.7067), 250: tensor(17.3250), 260: tensor(15.8550), 270: tensor(14.5683), 280: tensor(15.3417), 290: tensor(16.6250), 300: tensor(20.9350), 310: tensor(33.1667), 320: tensor(54.3217), 330: tensor(77.1117), 340: tensor(92.6383), 350: tensor(97.7000)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=70, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 0.9630,                   Accuracy: 1618/2000.0 (80.90%)



-= Testing valid =-
Test set: Average loss: 0.2743,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.1431,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.4565,                   Accuracy: 1686/2000.0 (84.30%)



-= Testing valid =-
Test set: Average loss: 0.1366,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1546,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.0738,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1178,                   Accuracy: 1919/2000.0 (95.95%)



Epoch 10 train accuracy: 97.79%, valid accuracy 95.95%
-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0547,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0450,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 20 train accuracy: 98.79%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 30 train accuracy: 99.56%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.55%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0260,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0255,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.71%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0493,                   Accuracy: 59157/60000 (98.60%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0775,                   Accuracy: 58696/60000 (97.83%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1734,                   Accuracy: 57227/60000 (95.38%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4871,                   Accuracy: 52242/60000 (87.07%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.1040,                   Accuracy: 43434/60000 (72.39%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.0728,                   Accuracy: 32842/60000 (54.74%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.2056,                   Accuracy: 23109/60000 (38.51%)
-= Testing Rotation 70 =-
Test set: Average loss: 3.9973,                   Accuracy: 17008/60000 (28.35%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.6625,                   Accuracy: 12640/60000 (21.07%)
-= Testing Rotation 90 =-
Test set: Average loss: 4.9916,                   Accuracy: 12464/60000 (20.77%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.2228,                   Accuracy: 12118/60000 (20.20%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.6442,                   Accuracy: 11796/60000 (19.66%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.9041,                   Accuracy: 12622/60000 (21.04%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.0436,                   Accuracy: 14918/60000 (24.86%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.0002,                   Accuracy: 18212/60000 (30.35%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.9849,                   Accuracy: 22159/60000 (36.93%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.2447,                   Accuracy: 24717/60000 (41.19%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.5604,                   Accuracy: 26403/60000 (44.01%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.0426,                   Accuracy: 26764/60000 (44.61%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.8072,                   Accuracy: 27062/60000 (45.10%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.7228,                   Accuracy: 25413/60000 (42.35%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.3875,                   Accuracy: 22809/60000 (38.01%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.1991,                   Accuracy: 20066/60000 (33.44%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.1256,                   Accuracy: 17271/60000 (28.78%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.1366,                   Accuracy: 14478/60000 (24.13%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.1402,                   Accuracy: 12426/60000 (20.71%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.0278,                   Accuracy: 10964/60000 (18.27%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.0119,                   Accuracy: 9764/60000 (16.27%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.7793,                   Accuracy: 8868/60000 (14.78%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.4071,                   Accuracy: 8747/60000 (14.58%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.6605,                   Accuracy: 11396/60000 (18.99%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.5359,                   Accuracy: 18998/60000 (31.66%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1325,                   Accuracy: 31561/60000 (52.60%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8928,                   Accuracy: 46072/60000 (76.79%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2652,                   Accuracy: 55400/60000 (92.33%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0819,                   Accuracy: 58544/60000 (97.57%)
{0: tensor(98.5950), 10: tensor(97.8267), 20: tensor(95.3783), 30: tensor(87.0700), 40: tensor(72.3900), 50: tensor(54.7367), 60: tensor(38.5150), 70: tensor(28.3467), 80: tensor(21.0667), 90: tensor(20.7733), 100: tensor(20.1967), 110: tensor(19.6600), 120: tensor(21.0367), 130: tensor(24.8633), 140: tensor(30.3533), 150: tensor(36.9317), 160: tensor(41.1950), 170: tensor(44.0050), 180: tensor(44.6067), 190: tensor(45.1033), 200: tensor(42.3550), 210: tensor(38.0150), 220: tensor(33.4433), 230: tensor(28.7850), 240: tensor(24.1300), 250: tensor(20.7100), 260: tensor(18.2733), 270: tensor(16.2733), 280: tensor(14.7800), 290: tensor(14.5783), 300: tensor(18.9933), 310: tensor(31.6633), 320: tensor(52.6017), 330: tensor(76.7867), 340: tensor(92.3333), 350: tensor(97.5733)}
