Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=41, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2565,                   Accuracy: 485/2000.0 (24.25%)



-= Testing valid =-
Test set: Average loss: 1.2873,                   Accuracy: 1039/2000.0 (51.95%)



-= Testing valid =-
Test set: Average loss: 1.1631,                   Accuracy: 1222/2000.0 (61.10%)



-= Testing valid =-
Test set: Average loss: 0.9283,                   Accuracy: 1448/2000.0 (72.40%)



-= Testing valid =-
Test set: Average loss: 0.5110,                   Accuracy: 1666/2000.0 (83.30%)



-= Testing valid =-
Test set: Average loss: 0.4228,                   Accuracy: 1721/2000.0 (86.05%)



-= Testing valid =-
Test set: Average loss: 0.2357,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2731,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.2191,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2891,                   Accuracy: 1812/2000.0 (90.60%)



Epoch 10 train accuracy: 93.74%, valid accuracy 90.60%
-= Testing valid =-
Test set: Average loss: 0.1630,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1609,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1874,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1471,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1528,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1908,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1351,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1365,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1256,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1319,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 20 train accuracy: 95.95%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.1292,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1192,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1120,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1137,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1106,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0947,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1021,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1115,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 30 train accuracy: 96.75%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 40 train accuracy: 96.97%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0909,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 50 train accuracy: 97.14%, valid accuracy 97.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1150,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1257,                   Accuracy: 57772/60000 (96.29%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1175,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1193,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1192,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1189,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1156,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1166,                   Accuracy: 57939/60000 (96.57%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1172,                   Accuracy: 57926/60000 (96.54%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1150,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1257,                   Accuracy: 57772/60000 (96.29%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1175,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1193,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1192,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1189,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1156,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1166,                   Accuracy: 57939/60000 (96.57%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1172,                   Accuracy: 57926/60000 (96.54%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1150,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1257,                   Accuracy: 57772/60000 (96.29%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1175,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1193,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1192,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1189,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1156,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1166,                   Accuracy: 57939/60000 (96.57%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1172,                   Accuracy: 57926/60000 (96.54%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1150,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1257,                   Accuracy: 57772/60000 (96.29%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1175,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1193,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1192,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1189,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1156,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1166,                   Accuracy: 57939/60000 (96.57%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1172,                   Accuracy: 57926/60000 (96.54%)
{0: tensor(96.7317), 10: tensor(96.2867), 20: tensor(96.6050), 30: tensor(96.5483), 40: tensor(96.4717), 50: tensor(96.5117), 60: tensor(96.5600), 70: tensor(96.5650), 80: tensor(96.5433), 90: tensor(96.7317), 100: tensor(96.2867), 110: tensor(96.6050), 120: tensor(96.5483), 130: tensor(96.4717), 140: tensor(96.5117), 150: tensor(96.5600), 160: tensor(96.5650), 170: tensor(96.5433), 180: tensor(96.7317), 190: tensor(96.2867), 200: tensor(96.6050), 210: tensor(96.5483), 220: tensor(96.4717), 230: tensor(96.5117), 240: tensor(96.5600), 250: tensor(96.5650), 260: tensor(96.5433), 270: tensor(96.7317), 280: tensor(96.2867), 290: tensor(96.6050), 300: tensor(96.5483), 310: tensor(96.4717), 320: tensor(96.5117), 330: tensor(96.5600), 340: tensor(96.5650), 350: tensor(96.5433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=42, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.3633,                   Accuracy: 244/2000.0 (12.20%)



-= Testing valid =-
Test set: Average loss: 2.9252,                   Accuracy: 322/2000.0 (16.10%)



-= Testing valid =-
Test set: Average loss: 1.1271,                   Accuracy: 1219/2000.0 (60.95%)



-= Testing valid =-
Test set: Average loss: 3.1777,                   Accuracy: 512/2000.0 (25.60%)



-= Testing valid =-
Test set: Average loss: 2.4487,                   Accuracy: 648/2000.0 (32.40%)



-= Testing valid =-
Test set: Average loss: 0.4925,                   Accuracy: 1684/2000.0 (84.20%)



-= Testing valid =-
Test set: Average loss: 0.2976,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2891,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.2485,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.3404,                   Accuracy: 1772/2000.0 (88.60%)



Epoch 10 train accuracy: 92.69%, valid accuracy 88.60%
-= Testing valid =-
Test set: Average loss: 0.1852,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.2012,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.2112,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.2358,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.1572,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1356,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1393,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1422,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1482,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1191,                   Accuracy: 1921/2000.0 (96.05%)



Epoch 20 train accuracy: 95.46%, valid accuracy 96.05%
-= Testing valid =-
Test set: Average loss: 0.1084,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1243,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1255,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1070,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1033,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1050,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1195,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1211,                   Accuracy: 1920/2000.0 (96.00%)



Epoch 30 train accuracy: 96.12%, valid accuracy 96.00%
-= Testing valid =-
Test set: Average loss: 0.1213,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1075,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0964,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1082,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 40 train accuracy: 96.75%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 50 train accuracy: 97.25%, valid accuracy 97.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1048,                   Accuracy: 58159/60000 (96.93%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1173,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1151,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1191,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1257,                   Accuracy: 57785/60000 (96.31%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1304,                   Accuracy: 57713/60000 (96.19%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1245,                   Accuracy: 57800/60000 (96.33%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1169,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1135,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1048,                   Accuracy: 58159/60000 (96.93%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1173,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1151,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1191,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1257,                   Accuracy: 57785/60000 (96.31%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1304,                   Accuracy: 57713/60000 (96.19%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1245,                   Accuracy: 57800/60000 (96.33%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1169,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1135,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1048,                   Accuracy: 58159/60000 (96.93%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1173,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1151,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1191,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1257,                   Accuracy: 57785/60000 (96.31%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1304,                   Accuracy: 57713/60000 (96.19%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1245,                   Accuracy: 57800/60000 (96.33%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1169,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1135,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1048,                   Accuracy: 58159/60000 (96.93%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1173,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1151,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1191,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1257,                   Accuracy: 57785/60000 (96.31%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1304,                   Accuracy: 57713/60000 (96.19%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1245,                   Accuracy: 57800/60000 (96.33%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1169,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1135,                   Accuracy: 57989/60000 (96.65%)
{0: tensor(96.9317), 10: tensor(96.4783), 20: tensor(96.6050), 30: tensor(96.4850), 40: tensor(96.3083), 50: tensor(96.1883), 60: tensor(96.3333), 70: tensor(96.6150), 80: tensor(96.6483), 90: tensor(96.9317), 100: tensor(96.4783), 110: tensor(96.6050), 120: tensor(96.4850), 130: tensor(96.3083), 140: tensor(96.1883), 150: tensor(96.3333), 160: tensor(96.6150), 170: tensor(96.6483), 180: tensor(96.9317), 190: tensor(96.4783), 200: tensor(96.6050), 210: tensor(96.4850), 220: tensor(96.3083), 230: tensor(96.1883), 240: tensor(96.3333), 250: tensor(96.6150), 260: tensor(96.6483), 270: tensor(96.9317), 280: tensor(96.4783), 290: tensor(96.6050), 300: tensor(96.4850), 310: tensor(96.3083), 320: tensor(96.1883), 330: tensor(96.3333), 340: tensor(96.6150), 350: tensor(96.6483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=43, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6155,                   Accuracy: 319/2000.0 (15.95%)



-= Testing valid =-
Test set: Average loss: 1.4387,                   Accuracy: 1006/2000.0 (50.30%)



-= Testing valid =-
Test set: Average loss: 0.8827,                   Accuracy: 1442/2000.0 (72.10%)



-= Testing valid =-
Test set: Average loss: 1.6486,                   Accuracy: 657/2000.0 (32.85%)



-= Testing valid =-
Test set: Average loss: 0.4326,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.6701,                   Accuracy: 1557/2000.0 (77.85%)



-= Testing valid =-
Test set: Average loss: 0.2570,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2939,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.3146,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.1917,                   Accuracy: 1878/2000.0 (93.90%)



Epoch 10 train accuracy: 93.49%, valid accuracy 93.90%
-= Testing valid =-
Test set: Average loss: 0.1342,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1276,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1249,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1094,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1244,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1103,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1284,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1052,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 20 train accuracy: 95.71%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0877,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 30 train accuracy: 96.41%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 40 train accuracy: 97.22%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0807,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 50 train accuracy: 97.43%, valid accuracy 97.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1007,                   Accuracy: 58227/60000 (97.04%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1136,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1114,                   Accuracy: 58033/60000 (96.72%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1112,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1065,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1021,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1009,                   Accuracy: 58189/60000 (96.98%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1011,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1032,                   Accuracy: 58124/60000 (96.87%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1007,                   Accuracy: 58227/60000 (97.04%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1136,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1114,                   Accuracy: 58033/60000 (96.72%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1112,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1065,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1021,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1009,                   Accuracy: 58189/60000 (96.98%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1011,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1032,                   Accuracy: 58124/60000 (96.87%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1007,                   Accuracy: 58227/60000 (97.04%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1136,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1114,                   Accuracy: 58033/60000 (96.72%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1112,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1065,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1021,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1009,                   Accuracy: 58189/60000 (96.98%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1011,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1032,                   Accuracy: 58124/60000 (96.87%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1007,                   Accuracy: 58227/60000 (97.04%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1136,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1114,                   Accuracy: 58033/60000 (96.72%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1112,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1065,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1021,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1009,                   Accuracy: 58189/60000 (96.98%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1011,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1032,                   Accuracy: 58124/60000 (96.87%)
{0: tensor(97.0450), 10: tensor(96.6167), 20: tensor(96.7217), 30: tensor(96.7500), 40: tensor(96.8217), 50: tensor(96.9217), 60: tensor(96.9817), 70: tensor(96.9217), 80: tensor(96.8733), 90: tensor(97.0450), 100: tensor(96.6167), 110: tensor(96.7217), 120: tensor(96.7500), 130: tensor(96.8217), 140: tensor(96.9217), 150: tensor(96.9817), 160: tensor(96.9217), 170: tensor(96.8733), 180: tensor(97.0450), 190: tensor(96.6167), 200: tensor(96.7217), 210: tensor(96.7500), 220: tensor(96.8217), 230: tensor(96.9217), 240: tensor(96.9817), 250: tensor(96.9217), 260: tensor(96.8733), 270: tensor(97.0450), 280: tensor(96.6167), 290: tensor(96.7217), 300: tensor(96.7500), 310: tensor(96.8217), 320: tensor(96.9217), 330: tensor(96.9817), 340: tensor(96.9217), 350: tensor(96.8733)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=44, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 7.0081,                   Accuracy: 245/2000.0 (12.25%)



-= Testing valid =-
Test set: Average loss: 1.3995,                   Accuracy: 930/2000.0 (46.50%)



-= Testing valid =-
Test set: Average loss: 1.4760,                   Accuracy: 1001/2000.0 (50.05%)



-= Testing valid =-
Test set: Average loss: 0.7161,                   Accuracy: 1527/2000.0 (76.35%)



-= Testing valid =-
Test set: Average loss: 0.4737,                   Accuracy: 1667/2000.0 (83.35%)



-= Testing valid =-
Test set: Average loss: 0.3797,                   Accuracy: 1747/2000.0 (87.35%)



-= Testing valid =-
Test set: Average loss: 0.2697,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.6064,                   Accuracy: 1591/2000.0 (79.55%)



-= Testing valid =-
Test set: Average loss: 0.1678,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.2614,                   Accuracy: 1832/2000.0 (91.60%)



Epoch 10 train accuracy: 93.49%, valid accuracy 91.60%
-= Testing valid =-
Test set: Average loss: 0.1932,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1985,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1305,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1052,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1389,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1412,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.2092,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.1328,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.2411,                   Accuracy: 1838/2000.0 (91.90%)



Epoch 20 train accuracy: 95.74%, valid accuracy 91.90%
-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0708,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 30 train accuracy: 96.41%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0707,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 40 train accuracy: 97.11%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0720,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0807,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0711,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 50 train accuracy: 97.36%, valid accuracy 97.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1099,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1229,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1171,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1238,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1232,                   Accuracy: 57817/60000 (96.36%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1229,                   Accuracy: 57823/60000 (96.37%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1191,                   Accuracy: 57890/60000 (96.48%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1136,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1120,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1099,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1229,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1171,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1238,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1232,                   Accuracy: 57817/60000 (96.36%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1229,                   Accuracy: 57823/60000 (96.37%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1191,                   Accuracy: 57890/60000 (96.48%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1136,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1120,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1099,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1229,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1171,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1238,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1232,                   Accuracy: 57817/60000 (96.36%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1229,                   Accuracy: 57823/60000 (96.37%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1191,                   Accuracy: 57890/60000 (96.48%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1136,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1120,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1099,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1229,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1171,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1238,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1232,                   Accuracy: 57817/60000 (96.36%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1229,                   Accuracy: 57823/60000 (96.37%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1191,                   Accuracy: 57890/60000 (96.48%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1136,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1120,                   Accuracy: 57985/60000 (96.64%)
{0: tensor(96.8750), 10: tensor(96.3567), 20: tensor(96.5717), 30: tensor(96.4100), 40: tensor(96.3617), 50: tensor(96.3717), 60: tensor(96.4833), 70: tensor(96.6633), 80: tensor(96.6417), 90: tensor(96.8750), 100: tensor(96.3567), 110: tensor(96.5717), 120: tensor(96.4100), 130: tensor(96.3617), 140: tensor(96.3717), 150: tensor(96.4833), 160: tensor(96.6633), 170: tensor(96.6417), 180: tensor(96.8750), 190: tensor(96.3567), 200: tensor(96.5717), 210: tensor(96.4100), 220: tensor(96.3617), 230: tensor(96.3717), 240: tensor(96.4833), 250: tensor(96.6633), 260: tensor(96.6417), 270: tensor(96.8750), 280: tensor(96.3567), 290: tensor(96.5717), 300: tensor(96.4100), 310: tensor(96.3617), 320: tensor(96.3717), 330: tensor(96.4833), 340: tensor(96.6633), 350: tensor(96.6417)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=45, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.5453,                   Accuracy: 299/2000.0 (14.95%)



-= Testing valid =-
Test set: Average loss: 3.4564,                   Accuracy: 220/2000.0 (11.00%)



-= Testing valid =-
Test set: Average loss: 1.1966,                   Accuracy: 1140/2000.0 (57.00%)



-= Testing valid =-
Test set: Average loss: 0.9393,                   Accuracy: 1416/2000.0 (70.80%)



-= Testing valid =-
Test set: Average loss: 0.5536,                   Accuracy: 1596/2000.0 (79.80%)



-= Testing valid =-
Test set: Average loss: 0.3582,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.4768,                   Accuracy: 1711/2000.0 (85.55%)



-= Testing valid =-
Test set: Average loss: 0.2974,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.1759,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1921,                   Accuracy: 1874/2000.0 (93.70%)



Epoch 10 train accuracy: 93.61%, valid accuracy 93.70%
-= Testing valid =-
Test set: Average loss: 0.1951,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.1705,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1836,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1895,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.1703,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1569,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1901,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1154,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1245,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1804,                   Accuracy: 1882/2000.0 (94.10%)



Epoch 20 train accuracy: 95.31%, valid accuracy 94.10%
-= Testing valid =-
Test set: Average loss: 0.1114,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1188,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 30 train accuracy: 96.56%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 40 train accuracy: 96.86%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0825,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 50 train accuracy: 97.19%, valid accuracy 97.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1066,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1096,                   Accuracy: 58031/60000 (96.72%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1085,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1084,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1086,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1102,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1113,                   Accuracy: 57993/60000 (96.65%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1130,                   Accuracy: 57997/60000 (96.66%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1111,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1066,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1096,                   Accuracy: 58031/60000 (96.72%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1085,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1084,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1086,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1102,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1113,                   Accuracy: 57993/60000 (96.65%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1130,                   Accuracy: 57997/60000 (96.66%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1111,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1066,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1096,                   Accuracy: 58031/60000 (96.72%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1085,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1084,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1086,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1102,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1113,                   Accuracy: 57993/60000 (96.65%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1130,                   Accuracy: 57997/60000 (96.66%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1111,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1066,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1096,                   Accuracy: 58031/60000 (96.72%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1085,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1084,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1086,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1102,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1113,                   Accuracy: 57993/60000 (96.65%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1130,                   Accuracy: 57997/60000 (96.66%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1111,                   Accuracy: 57986/60000 (96.64%)
{0: tensor(96.8383), 10: tensor(96.7183), 20: tensor(96.7700), 30: tensor(96.7867), 40: tensor(96.7850), 50: tensor(96.7433), 60: tensor(96.6550), 70: tensor(96.6617), 80: tensor(96.6433), 90: tensor(96.8383), 100: tensor(96.7183), 110: tensor(96.7700), 120: tensor(96.7867), 130: tensor(96.7850), 140: tensor(96.7433), 150: tensor(96.6550), 160: tensor(96.6617), 170: tensor(96.6433), 180: tensor(96.8383), 190: tensor(96.7183), 200: tensor(96.7700), 210: tensor(96.7867), 220: tensor(96.7850), 230: tensor(96.7433), 240: tensor(96.6550), 250: tensor(96.6617), 260: tensor(96.6433), 270: tensor(96.8383), 280: tensor(96.7183), 290: tensor(96.7700), 300: tensor(96.7867), 310: tensor(96.7850), 320: tensor(96.7433), 330: tensor(96.6550), 340: tensor(96.6617), 350: tensor(96.6433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=46, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2038,                   Accuracy: 212/2000.0 (10.60%)



-= Testing valid =-
Test set: Average loss: 2.1544,                   Accuracy: 511/2000.0 (25.55%)



-= Testing valid =-
Test set: Average loss: 1.1405,                   Accuracy: 1122/2000.0 (56.10%)



-= Testing valid =-
Test set: Average loss: 1.6775,                   Accuracy: 925/2000.0 (46.25%)



-= Testing valid =-
Test set: Average loss: 0.5582,                   Accuracy: 1637/2000.0 (81.85%)



-= Testing valid =-
Test set: Average loss: 0.3926,                   Accuracy: 1735/2000.0 (86.75%)



-= Testing valid =-
Test set: Average loss: 0.3492,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.4828,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.3164,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.4824,                   Accuracy: 1740/2000.0 (87.00%)



Epoch 10 train accuracy: 92.76%, valid accuracy 87.00%
-= Testing valid =-
Test set: Average loss: 0.1515,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1718,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1143,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1393,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1440,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1147,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1124,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1137,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1190,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 20 train accuracy: 95.49%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.1137,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0909,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 30 train accuracy: 96.28%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0807,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0752,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0715,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 40 train accuracy: 96.62%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0715,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0691,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0704,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 50 train accuracy: 97.12%, valid accuracy 97.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1022,                   Accuracy: 58141/60000 (96.90%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1219,                   Accuracy: 57759/60000 (96.26%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1153,                   Accuracy: 57867/60000 (96.44%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1109,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1159,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1186,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1169,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1178,                   Accuracy: 57844/60000 (96.41%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1113,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1022,                   Accuracy: 58141/60000 (96.90%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1219,                   Accuracy: 57759/60000 (96.26%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1153,                   Accuracy: 57867/60000 (96.44%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1109,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1159,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1186,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1169,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1178,                   Accuracy: 57844/60000 (96.41%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1113,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1022,                   Accuracy: 58141/60000 (96.90%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1219,                   Accuracy: 57759/60000 (96.26%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1153,                   Accuracy: 57867/60000 (96.44%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1109,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1159,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1186,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1169,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1178,                   Accuracy: 57844/60000 (96.41%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1113,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1022,                   Accuracy: 58141/60000 (96.90%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1219,                   Accuracy: 57759/60000 (96.26%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1153,                   Accuracy: 57867/60000 (96.44%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1109,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1159,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1186,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1169,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1178,                   Accuracy: 57844/60000 (96.41%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1113,                   Accuracy: 57967/60000 (96.61%)
{0: tensor(96.9017), 10: tensor(96.2650), 20: tensor(96.4450), 30: tensor(96.6150), 40: tensor(96.4817), 50: tensor(96.4117), 60: tensor(96.4100), 70: tensor(96.4067), 80: tensor(96.6117), 90: tensor(96.9017), 100: tensor(96.2650), 110: tensor(96.4450), 120: tensor(96.6150), 130: tensor(96.4817), 140: tensor(96.4117), 150: tensor(96.4100), 160: tensor(96.4067), 170: tensor(96.6117), 180: tensor(96.9017), 190: tensor(96.2650), 200: tensor(96.4450), 210: tensor(96.6150), 220: tensor(96.4817), 230: tensor(96.4117), 240: tensor(96.4100), 250: tensor(96.4067), 260: tensor(96.6117), 270: tensor(96.9017), 280: tensor(96.2650), 290: tensor(96.4450), 300: tensor(96.6150), 310: tensor(96.4817), 320: tensor(96.4117), 330: tensor(96.4100), 340: tensor(96.4067), 350: tensor(96.6117)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=47, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.4483,                   Accuracy: 218/2000.0 (10.90%)



-= Testing valid =-
Test set: Average loss: 4.7286,                   Accuracy: 216/2000.0 (10.80%)



-= Testing valid =-
Test set: Average loss: 1.6768,                   Accuracy: 758/2000.0 (37.90%)



-= Testing valid =-
Test set: Average loss: 1.2599,                   Accuracy: 1097/2000.0 (54.85%)



-= Testing valid =-
Test set: Average loss: 1.9577,                   Accuracy: 904/2000.0 (45.20%)



-= Testing valid =-
Test set: Average loss: 0.5266,                   Accuracy: 1643/2000.0 (82.15%)



-= Testing valid =-
Test set: Average loss: 0.3924,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.2534,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2580,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2871,                   Accuracy: 1818/2000.0 (90.90%)



Epoch 10 train accuracy: 93.47%, valid accuracy 90.90%
-= Testing valid =-
Test set: Average loss: 0.1500,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1641,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1598,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1501,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1825,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1312,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.2055,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.1540,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1342,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1510,                   Accuracy: 1910/2000.0 (95.50%)



Epoch 20 train accuracy: 95.90%, valid accuracy 95.50%
-= Testing valid =-
Test set: Average loss: 0.1260,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1282,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1163,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1264,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1046,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1414,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1071,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1182,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1175,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1185,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 30 train accuracy: 96.88%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1033,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 40 train accuracy: 97.29%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1017,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 50 train accuracy: 97.22%, valid accuracy 97.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1099,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1206,                   Accuracy: 57766/60000 (96.28%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1126,                   Accuracy: 57903/60000 (96.50%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1152,                   Accuracy: 57856/60000 (96.43%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1139,                   Accuracy: 57909/60000 (96.51%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1159,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1131,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1113,                   Accuracy: 58002/60000 (96.67%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1124,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1099,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1206,                   Accuracy: 57766/60000 (96.28%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1126,                   Accuracy: 57903/60000 (96.50%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1152,                   Accuracy: 57856/60000 (96.43%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1139,                   Accuracy: 57909/60000 (96.51%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1159,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1131,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1113,                   Accuracy: 58002/60000 (96.67%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1124,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1099,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1206,                   Accuracy: 57766/60000 (96.28%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1126,                   Accuracy: 57903/60000 (96.50%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1152,                   Accuracy: 57856/60000 (96.43%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1139,                   Accuracy: 57909/60000 (96.51%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1159,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1131,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1113,                   Accuracy: 58002/60000 (96.67%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1124,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1099,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1206,                   Accuracy: 57766/60000 (96.28%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1126,                   Accuracy: 57903/60000 (96.50%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1152,                   Accuracy: 57856/60000 (96.43%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1139,                   Accuracy: 57909/60000 (96.51%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1159,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1131,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1113,                   Accuracy: 58002/60000 (96.67%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1124,                   Accuracy: 57968/60000 (96.61%)
{0: tensor(96.7333), 10: tensor(96.2767), 20: tensor(96.5050), 30: tensor(96.4267), 40: tensor(96.5150), 50: tensor(96.5217), 60: tensor(96.6200), 70: tensor(96.6700), 80: tensor(96.6133), 90: tensor(96.7333), 100: tensor(96.2767), 110: tensor(96.5050), 120: tensor(96.4267), 130: tensor(96.5150), 140: tensor(96.5217), 150: tensor(96.6200), 160: tensor(96.6700), 170: tensor(96.6133), 180: tensor(96.7333), 190: tensor(96.2767), 200: tensor(96.5050), 210: tensor(96.4267), 220: tensor(96.5150), 230: tensor(96.5217), 240: tensor(96.6200), 250: tensor(96.6700), 260: tensor(96.6133), 270: tensor(96.7333), 280: tensor(96.2767), 290: tensor(96.5050), 300: tensor(96.4267), 310: tensor(96.5150), 320: tensor(96.5217), 330: tensor(96.6200), 340: tensor(96.6700), 350: tensor(96.6133)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=48, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0526,                   Accuracy: 436/2000.0 (21.80%)



-= Testing valid =-
Test set: Average loss: 2.2328,                   Accuracy: 553/2000.0 (27.65%)



-= Testing valid =-
Test set: Average loss: 1.4630,                   Accuracy: 900/2000.0 (45.00%)



-= Testing valid =-
Test set: Average loss: 1.3340,                   Accuracy: 974/2000.0 (48.70%)



-= Testing valid =-
Test set: Average loss: 0.4902,                   Accuracy: 1673/2000.0 (83.65%)



-= Testing valid =-
Test set: Average loss: 0.7225,                   Accuracy: 1518/2000.0 (75.90%)



-= Testing valid =-
Test set: Average loss: 0.3772,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.2713,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.4835,                   Accuracy: 1719/2000.0 (85.95%)



-= Testing valid =-
Test set: Average loss: 0.2850,                   Accuracy: 1807/2000.0 (90.35%)



Epoch 10 train accuracy: 92.99%, valid accuracy 90.35%
-= Testing valid =-
Test set: Average loss: 0.1445,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1831,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1597,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1221,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1455,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1419,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1108,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1306,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.2000,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.1230,                   Accuracy: 1908/2000.0 (95.40%)



Epoch 20 train accuracy: 95.53%, valid accuracy 95.40%
-= Testing valid =-
Test set: Average loss: 0.1158,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1934/2000.0 (96.70%)



Epoch 30 train accuracy: 96.36%, valid accuracy 96.70%
-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0775,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 40 train accuracy: 96.66%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 50 train accuracy: 97.09%, valid accuracy 97.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1092,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1171,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1122,                   Accuracy: 58032/60000 (96.72%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1162,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1146,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1109,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1079,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1064,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1096,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1092,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1171,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1122,                   Accuracy: 58032/60000 (96.72%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1162,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1146,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1109,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1079,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1064,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1096,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1092,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1171,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1122,                   Accuracy: 58032/60000 (96.72%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1162,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1146,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1109,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1079,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1064,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1096,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1092,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1171,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1122,                   Accuracy: 58032/60000 (96.72%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1162,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1146,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1109,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1079,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1064,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1096,                   Accuracy: 58010/60000 (96.68%)
{0: tensor(96.7467), 10: tensor(96.4300), 20: tensor(96.7200), 30: tensor(96.5367), 40: tensor(96.6117), 50: tensor(96.6800), 60: tensor(96.7167), 70: tensor(96.8667), 80: tensor(96.6833), 90: tensor(96.7467), 100: tensor(96.4300), 110: tensor(96.7200), 120: tensor(96.5367), 130: tensor(96.6117), 140: tensor(96.6800), 150: tensor(96.7167), 160: tensor(96.8667), 170: tensor(96.6833), 180: tensor(96.7467), 190: tensor(96.4300), 200: tensor(96.7200), 210: tensor(96.5367), 220: tensor(96.6117), 230: tensor(96.6800), 240: tensor(96.7167), 250: tensor(96.8667), 260: tensor(96.6833), 270: tensor(96.7467), 280: tensor(96.4300), 290: tensor(96.7200), 300: tensor(96.5367), 310: tensor(96.6117), 320: tensor(96.6800), 330: tensor(96.7167), 340: tensor(96.8667), 350: tensor(96.6833)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=49, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8465,                   Accuracy: 638/2000.0 (31.90%)



-= Testing valid =-
Test set: Average loss: 1.4566,                   Accuracy: 988/2000.0 (49.40%)



-= Testing valid =-
Test set: Average loss: 1.7587,                   Accuracy: 960/2000.0 (48.00%)



-= Testing valid =-
Test set: Average loss: 0.4921,                   Accuracy: 1736/2000.0 (86.80%)



-= Testing valid =-
Test set: Average loss: 0.7010,                   Accuracy: 1486/2000.0 (74.30%)



-= Testing valid =-
Test set: Average loss: 0.2415,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.1890,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.2483,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.1924,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1524,                   Accuracy: 1899/2000.0 (94.95%)



Epoch 10 train accuracy: 93.60%, valid accuracy 94.95%
-= Testing valid =-
Test set: Average loss: 0.1436,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1297,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.0926,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1074,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 20 train accuracy: 95.68%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0790,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 30 train accuracy: 96.29%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0701,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0646,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0684,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 40 train accuracy: 97.11%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0626,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0645,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0628,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0628,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0638,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 50 train accuracy: 97.32%, valid accuracy 97.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0983,                   Accuracy: 58208/60000 (97.01%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1077,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1098,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1169,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1197,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1195,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1136,                   Accuracy: 57958/60000 (96.60%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1062,                   Accuracy: 58094/60000 (96.82%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1021,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0983,                   Accuracy: 58208/60000 (97.01%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1077,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1098,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1169,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1197,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1195,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1136,                   Accuracy: 57958/60000 (96.60%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1062,                   Accuracy: 58094/60000 (96.82%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1021,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0983,                   Accuracy: 58208/60000 (97.01%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1077,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1098,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1169,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1197,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1195,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1136,                   Accuracy: 57958/60000 (96.60%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1062,                   Accuracy: 58094/60000 (96.82%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1021,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0983,                   Accuracy: 58208/60000 (97.01%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1077,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1098,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1169,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1197,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1195,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1136,                   Accuracy: 57958/60000 (96.60%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1062,                   Accuracy: 58094/60000 (96.82%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1021,                   Accuracy: 58153/60000 (96.92%)
{0: tensor(97.0133), 10: tensor(96.6650), 20: tensor(96.6667), 30: tensor(96.4767), 40: tensor(96.4483), 50: tensor(96.4817), 60: tensor(96.5967), 70: tensor(96.8233), 80: tensor(96.9217), 90: tensor(97.0133), 100: tensor(96.6650), 110: tensor(96.6667), 120: tensor(96.4767), 130: tensor(96.4483), 140: tensor(96.4817), 150: tensor(96.5967), 160: tensor(96.8233), 170: tensor(96.9217), 180: tensor(97.0133), 190: tensor(96.6650), 200: tensor(96.6667), 210: tensor(96.4767), 220: tensor(96.4483), 230: tensor(96.4817), 240: tensor(96.5967), 250: tensor(96.8233), 260: tensor(96.9217), 270: tensor(97.0133), 280: tensor(96.6650), 290: tensor(96.6667), 300: tensor(96.4767), 310: tensor(96.4483), 320: tensor(96.4817), 330: tensor(96.5967), 340: tensor(96.8233), 350: tensor(96.9217)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=50, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.1042,                   Accuracy: 242/2000.0 (12.10%)



-= Testing valid =-
Test set: Average loss: 1.4831,                   Accuracy: 898/2000.0 (44.90%)



-= Testing valid =-
Test set: Average loss: 0.9053,                   Accuracy: 1351/2000.0 (67.55%)



-= Testing valid =-
Test set: Average loss: 0.6406,                   Accuracy: 1585/2000.0 (79.25%)



-= Testing valid =-
Test set: Average loss: 0.3507,                   Accuracy: 1768/2000.0 (88.40%)



-= Testing valid =-
Test set: Average loss: 0.4866,                   Accuracy: 1671/2000.0 (83.55%)



-= Testing valid =-
Test set: Average loss: 0.3557,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.2034,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.2216,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2267,                   Accuracy: 1859/2000.0 (92.95%)



Epoch 10 train accuracy: 93.32%, valid accuracy 92.95%
-= Testing valid =-
Test set: Average loss: 0.1444,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1547,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1325,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1147,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1411,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1491,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 20 train accuracy: 95.91%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 30 train accuracy: 96.68%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.0718,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0708,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 40 train accuracy: 97.30%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0621,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0618,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0618,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0606,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 50 train accuracy: 97.31%, valid accuracy 98.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0887,                   Accuracy: 58441/60000 (97.40%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0957,                   Accuracy: 58281/60000 (97.14%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0919,                   Accuracy: 58330/60000 (97.22%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0915,                   Accuracy: 58334/60000 (97.22%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0912,                   Accuracy: 58351/60000 (97.25%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0928,                   Accuracy: 58298/60000 (97.16%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0911,                   Accuracy: 58309/60000 (97.18%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0887,                   Accuracy: 58397/60000 (97.33%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.0913,                   Accuracy: 58340/60000 (97.23%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0887,                   Accuracy: 58441/60000 (97.40%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.0957,                   Accuracy: 58281/60000 (97.14%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.0919,                   Accuracy: 58330/60000 (97.22%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.0915,                   Accuracy: 58334/60000 (97.22%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.0912,                   Accuracy: 58351/60000 (97.25%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.0928,                   Accuracy: 58298/60000 (97.16%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.0911,                   Accuracy: 58309/60000 (97.18%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.0887,                   Accuracy: 58397/60000 (97.33%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.0913,                   Accuracy: 58340/60000 (97.23%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0887,                   Accuracy: 58441/60000 (97.40%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.0957,                   Accuracy: 58281/60000 (97.14%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.0919,                   Accuracy: 58330/60000 (97.22%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.0915,                   Accuracy: 58334/60000 (97.22%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.0912,                   Accuracy: 58351/60000 (97.25%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.0928,                   Accuracy: 58298/60000 (97.16%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.0911,                   Accuracy: 58309/60000 (97.18%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.0887,                   Accuracy: 58397/60000 (97.33%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.0913,                   Accuracy: 58340/60000 (97.23%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0887,                   Accuracy: 58441/60000 (97.40%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.0957,                   Accuracy: 58281/60000 (97.14%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0919,                   Accuracy: 58330/60000 (97.22%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.0915,                   Accuracy: 58334/60000 (97.22%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.0912,                   Accuracy: 58351/60000 (97.25%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.0928,                   Accuracy: 58298/60000 (97.16%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0911,                   Accuracy: 58309/60000 (97.18%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0887,                   Accuracy: 58397/60000 (97.33%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0913,                   Accuracy: 58340/60000 (97.23%)
{0: tensor(97.4017), 10: tensor(97.1350), 20: tensor(97.2167), 30: tensor(97.2233), 40: tensor(97.2517), 50: tensor(97.1633), 60: tensor(97.1817), 70: tensor(97.3283), 80: tensor(97.2333), 90: tensor(97.4017), 100: tensor(97.1350), 110: tensor(97.2167), 120: tensor(97.2233), 130: tensor(97.2517), 140: tensor(97.1633), 150: tensor(97.1817), 160: tensor(97.3283), 170: tensor(97.2333), 180: tensor(97.4017), 190: tensor(97.1350), 200: tensor(97.2167), 210: tensor(97.2233), 220: tensor(97.2517), 230: tensor(97.1633), 240: tensor(97.1817), 250: tensor(97.3283), 260: tensor(97.2333), 270: tensor(97.4017), 280: tensor(97.1350), 290: tensor(97.2167), 300: tensor(97.2233), 310: tensor(97.2517), 320: tensor(97.1633), 330: tensor(97.1817), 340: tensor(97.3283), 350: tensor(97.2333)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=51, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.7859,                   Accuracy: 220/2000.0 (11.00%)



-= Testing valid =-
Test set: Average loss: 1.9366,                   Accuracy: 674/2000.0 (33.70%)



-= Testing valid =-
Test set: Average loss: 1.1350,                   Accuracy: 1152/2000.0 (57.60%)



-= Testing valid =-
Test set: Average loss: 1.7309,                   Accuracy: 1034/2000.0 (51.70%)



-= Testing valid =-
Test set: Average loss: 0.5801,                   Accuracy: 1578/2000.0 (78.90%)



-= Testing valid =-
Test set: Average loss: 0.4455,                   Accuracy: 1725/2000.0 (86.25%)



-= Testing valid =-
Test set: Average loss: 0.1956,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2510,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.3531,                   Accuracy: 1764/2000.0 (88.20%)



-= Testing valid =-
Test set: Average loss: 0.2232,                   Accuracy: 1853/2000.0 (92.65%)



Epoch 10 train accuracy: 93.19%, valid accuracy 92.65%
-= Testing valid =-
Test set: Average loss: 0.1891,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1457,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1312,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1219,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1238,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1156,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1360,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1104,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1193,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1058,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 20 train accuracy: 95.41%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.1011,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0909,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 30 train accuracy: 96.32%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 40 train accuracy: 97.09%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0802,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 50 train accuracy: 97.28%, valid accuracy 98.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0964,                   Accuracy: 58308/60000 (97.18%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1052,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1034,                   Accuracy: 58132/60000 (96.89%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1065,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1085,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1110,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1078,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1050,                   Accuracy: 58119/60000 (96.86%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1013,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0964,                   Accuracy: 58308/60000 (97.18%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1052,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1034,                   Accuracy: 58132/60000 (96.89%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1065,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1085,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1110,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1078,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1050,                   Accuracy: 58119/60000 (96.86%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1013,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0964,                   Accuracy: 58308/60000 (97.18%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1052,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1034,                   Accuracy: 58132/60000 (96.89%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1065,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1085,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1110,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1078,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1050,                   Accuracy: 58119/60000 (96.86%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1013,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0964,                   Accuracy: 58308/60000 (97.18%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1052,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1034,                   Accuracy: 58132/60000 (96.89%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1065,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1085,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1110,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1078,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1050,                   Accuracy: 58119/60000 (96.86%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1013,                   Accuracy: 58165/60000 (96.94%)
{0: tensor(97.1800), 10: tensor(96.8333), 20: tensor(96.8867), 30: tensor(96.8333), 40: tensor(96.7400), 50: tensor(96.6833), 60: tensor(96.8217), 70: tensor(96.8650), 80: tensor(96.9417), 90: tensor(97.1800), 100: tensor(96.8333), 110: tensor(96.8867), 120: tensor(96.8333), 130: tensor(96.7400), 140: tensor(96.6833), 150: tensor(96.8217), 160: tensor(96.8650), 170: tensor(96.9417), 180: tensor(97.1800), 190: tensor(96.8333), 200: tensor(96.8867), 210: tensor(96.8333), 220: tensor(96.7400), 230: tensor(96.6833), 240: tensor(96.8217), 250: tensor(96.8650), 260: tensor(96.9417), 270: tensor(97.1800), 280: tensor(96.8333), 290: tensor(96.8867), 300: tensor(96.8333), 310: tensor(96.7400), 320: tensor(96.6833), 330: tensor(96.8217), 340: tensor(96.8650), 350: tensor(96.9417)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=52, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.4092,                   Accuracy: 182/2000.0 (9.10%)



-= Testing valid =-
Test set: Average loss: 1.2324,                   Accuracy: 1105/2000.0 (55.25%)



-= Testing valid =-
Test set: Average loss: 2.3469,                   Accuracy: 763/2000.0 (38.15%)



-= Testing valid =-
Test set: Average loss: 2.9980,                   Accuracy: 682/2000.0 (34.10%)



-= Testing valid =-
Test set: Average loss: 0.8304,                   Accuracy: 1409/2000.0 (70.45%)



-= Testing valid =-
Test set: Average loss: 0.3149,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.3718,                   Accuracy: 1760/2000.0 (88.00%)



-= Testing valid =-
Test set: Average loss: 0.3354,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.4173,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.2463,                   Accuracy: 1839/2000.0 (91.95%)



Epoch 10 train accuracy: 93.35%, valid accuracy 91.95%
-= Testing valid =-
Test set: Average loss: 0.2148,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.1852,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.2337,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.1750,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1650,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1661,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1710,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1511,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1617,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1571,                   Accuracy: 1901/2000.0 (95.05%)



Epoch 20 train accuracy: 95.79%, valid accuracy 95.05%
-= Testing valid =-
Test set: Average loss: 0.1447,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1503,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1299,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1258,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1311,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1299,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1133,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1285,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1362,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1187,                   Accuracy: 1921/2000.0 (96.05%)



Epoch 30 train accuracy: 96.71%, valid accuracy 96.05%
-= Testing valid =-
Test set: Average loss: 0.1099,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1171,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1098,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1112,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1020,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1086,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 40 train accuracy: 97.36%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1010,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 50 train accuracy: 97.06%, valid accuracy 96.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1139,                   Accuracy: 58012/60000 (96.69%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1350,                   Accuracy: 57551/60000 (95.92%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1204,                   Accuracy: 57906/60000 (96.51%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1264,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1263,                   Accuracy: 57797/60000 (96.33%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1243,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1207,                   Accuracy: 57934/60000 (96.56%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1168,                   Accuracy: 57977/60000 (96.63%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1228,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1139,                   Accuracy: 58012/60000 (96.69%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1350,                   Accuracy: 57551/60000 (95.92%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1204,                   Accuracy: 57906/60000 (96.51%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1264,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1263,                   Accuracy: 57797/60000 (96.33%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1243,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1207,                   Accuracy: 57934/60000 (96.56%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1168,                   Accuracy: 57977/60000 (96.63%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1228,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1139,                   Accuracy: 58012/60000 (96.69%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1350,                   Accuracy: 57551/60000 (95.92%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1204,                   Accuracy: 57906/60000 (96.51%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1264,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1263,                   Accuracy: 57797/60000 (96.33%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1243,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1207,                   Accuracy: 57934/60000 (96.56%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1168,                   Accuracy: 57977/60000 (96.63%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1228,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1139,                   Accuracy: 58012/60000 (96.69%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1350,                   Accuracy: 57551/60000 (95.92%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1204,                   Accuracy: 57906/60000 (96.51%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1264,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1263,                   Accuracy: 57797/60000 (96.33%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1243,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1207,                   Accuracy: 57934/60000 (96.56%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1168,                   Accuracy: 57977/60000 (96.63%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1228,                   Accuracy: 57894/60000 (96.49%)
{0: tensor(96.6867), 10: tensor(95.9183), 20: tensor(96.5100), 30: tensor(96.3400), 40: tensor(96.3283), 50: tensor(96.3833), 60: tensor(96.5567), 70: tensor(96.6283), 80: tensor(96.4900), 90: tensor(96.6867), 100: tensor(95.9183), 110: tensor(96.5100), 120: tensor(96.3400), 130: tensor(96.3283), 140: tensor(96.3833), 150: tensor(96.5567), 160: tensor(96.6283), 170: tensor(96.4900), 180: tensor(96.6867), 190: tensor(95.9183), 200: tensor(96.5100), 210: tensor(96.3400), 220: tensor(96.3283), 230: tensor(96.3833), 240: tensor(96.5567), 250: tensor(96.6283), 260: tensor(96.4900), 270: tensor(96.6867), 280: tensor(95.9183), 290: tensor(96.5100), 300: tensor(96.3400), 310: tensor(96.3283), 320: tensor(96.3833), 330: tensor(96.5567), 340: tensor(96.6283), 350: tensor(96.4900)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=53, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.9307,                   Accuracy: 350/2000.0 (17.50%)



-= Testing valid =-
Test set: Average loss: 1.3514,                   Accuracy: 858/2000.0 (42.90%)



-= Testing valid =-
Test set: Average loss: 2.1730,                   Accuracy: 694/2000.0 (34.70%)



-= Testing valid =-
Test set: Average loss: 0.8838,                   Accuracy: 1437/2000.0 (71.85%)



-= Testing valid =-
Test set: Average loss: 0.3677,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.3636,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.4506,                   Accuracy: 1688/2000.0 (84.40%)



-= Testing valid =-
Test set: Average loss: 0.2368,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2473,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.1926,                   Accuracy: 1886/2000.0 (94.30%)



Epoch 10 train accuracy: 93.43%, valid accuracy 94.30%
-= Testing valid =-
Test set: Average loss: 0.1615,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1856,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1443,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1362,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1396,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1579,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1491,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1404,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1500,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1444,                   Accuracy: 1906/2000.0 (95.30%)



Epoch 20 train accuracy: 95.95%, valid accuracy 95.30%
-= Testing valid =-
Test set: Average loss: 0.1290,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1094,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1102,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1211,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1070,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1106,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1046,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1050,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 30 train accuracy: 96.81%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1012,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0981,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1037,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1117,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0882,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 40 train accuracy: 97.30%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 50 train accuracy: 97.30%, valid accuracy 97.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1098,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1174,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1138,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1141,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1138,                   Accuracy: 58042/60000 (96.74%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1140,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1121,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1131,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1097,                   Accuracy: 58080/60000 (96.80%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1098,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1174,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1138,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1141,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1138,                   Accuracy: 58042/60000 (96.74%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1140,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1121,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1131,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1097,                   Accuracy: 58080/60000 (96.80%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1098,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1174,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1138,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1141,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1138,                   Accuracy: 58042/60000 (96.74%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1140,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1121,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1131,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1097,                   Accuracy: 58080/60000 (96.80%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1098,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1174,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1138,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1141,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1138,                   Accuracy: 58042/60000 (96.74%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1140,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1121,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1131,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1097,                   Accuracy: 58080/60000 (96.80%)
{0: tensor(96.7800), 10: tensor(96.5217), 20: tensor(96.6233), 30: tensor(96.6267), 40: tensor(96.7367), 50: tensor(96.7467), 60: tensor(96.8167), 70: tensor(96.7267), 80: tensor(96.8000), 90: tensor(96.7800), 100: tensor(96.5217), 110: tensor(96.6233), 120: tensor(96.6267), 130: tensor(96.7367), 140: tensor(96.7467), 150: tensor(96.8167), 160: tensor(96.7267), 170: tensor(96.8000), 180: tensor(96.7800), 190: tensor(96.5217), 200: tensor(96.6233), 210: tensor(96.6267), 220: tensor(96.7367), 230: tensor(96.7467), 240: tensor(96.8167), 250: tensor(96.7267), 260: tensor(96.8000), 270: tensor(96.7800), 280: tensor(96.5217), 290: tensor(96.6233), 300: tensor(96.6267), 310: tensor(96.7367), 320: tensor(96.7467), 330: tensor(96.8167), 340: tensor(96.7267), 350: tensor(96.8000)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=54, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3230,                   Accuracy: 409/2000.0 (20.45%)



-= Testing valid =-
Test set: Average loss: 1.4555,                   Accuracy: 1081/2000.0 (54.05%)



-= Testing valid =-
Test set: Average loss: 1.3394,                   Accuracy: 916/2000.0 (45.80%)



-= Testing valid =-
Test set: Average loss: 1.1912,                   Accuracy: 1239/2000.0 (61.95%)



-= Testing valid =-
Test set: Average loss: 0.4047,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.5341,                   Accuracy: 1638/2000.0 (81.90%)



-= Testing valid =-
Test set: Average loss: 0.4179,                   Accuracy: 1732/2000.0 (86.60%)



-= Testing valid =-
Test set: Average loss: 0.3484,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.2171,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.3734,                   Accuracy: 1770/2000.0 (88.50%)



Epoch 10 train accuracy: 92.56%, valid accuracy 88.50%
-= Testing valid =-
Test set: Average loss: 0.1461,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1529,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1169,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1265,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1275,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1287,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1198,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1343,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1419,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1127,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 20 train accuracy: 95.96%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.1223,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1059,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 30 train accuracy: 96.47%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0910,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 40 train accuracy: 96.56%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 50 train accuracy: 97.24%, valid accuracy 97.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1053,                   Accuracy: 58198/60000 (97.00%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1153,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1111,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1115,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1130,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1135,                   Accuracy: 58026/60000 (96.71%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1128,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1136,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1133,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1053,                   Accuracy: 58198/60000 (97.00%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1153,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1111,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1115,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1130,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1135,                   Accuracy: 58026/60000 (96.71%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1128,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1136,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1133,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1053,                   Accuracy: 58198/60000 (97.00%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1153,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1111,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1115,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1130,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1135,                   Accuracy: 58026/60000 (96.71%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1128,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1136,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1133,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1053,                   Accuracy: 58198/60000 (97.00%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1153,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1111,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1115,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1130,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1135,                   Accuracy: 58026/60000 (96.71%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1128,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1136,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1133,                   Accuracy: 58020/60000 (96.70%)
{0: tensor(96.9967), 10: tensor(96.6217), 20: tensor(96.8100), 30: tensor(96.8083), 40: tensor(96.7300), 50: tensor(96.7100), 60: tensor(96.7500), 70: tensor(96.7017), 80: tensor(96.7000), 90: tensor(96.9967), 100: tensor(96.6217), 110: tensor(96.8100), 120: tensor(96.8083), 130: tensor(96.7300), 140: tensor(96.7100), 150: tensor(96.7500), 160: tensor(96.7017), 170: tensor(96.7000), 180: tensor(96.9967), 190: tensor(96.6217), 200: tensor(96.8100), 210: tensor(96.8083), 220: tensor(96.7300), 230: tensor(96.7100), 240: tensor(96.7500), 250: tensor(96.7017), 260: tensor(96.7000), 270: tensor(96.9967), 280: tensor(96.6217), 290: tensor(96.8100), 300: tensor(96.8083), 310: tensor(96.7300), 320: tensor(96.7100), 330: tensor(96.7500), 340: tensor(96.7017), 350: tensor(96.7000)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=55, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3417,                   Accuracy: 451/2000.0 (22.55%)



-= Testing valid =-
Test set: Average loss: 1.4495,                   Accuracy: 1069/2000.0 (53.45%)



-= Testing valid =-
Test set: Average loss: 0.8704,                   Accuracy: 1395/2000.0 (69.75%)



-= Testing valid =-
Test set: Average loss: 0.7833,                   Accuracy: 1445/2000.0 (72.25%)



-= Testing valid =-
Test set: Average loss: 0.5562,                   Accuracy: 1636/2000.0 (81.80%)



-= Testing valid =-
Test set: Average loss: 0.4830,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.3478,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.3281,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.2778,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2753,                   Accuracy: 1831/2000.0 (91.55%)



Epoch 10 train accuracy: 92.54%, valid accuracy 91.55%
-= Testing valid =-
Test set: Average loss: 0.1745,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1642,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1504,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1682,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1320,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1302,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1356,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1188,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1567,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1587,                   Accuracy: 1908/2000.0 (95.40%)



Epoch 20 train accuracy: 95.45%, valid accuracy 95.40%
-= Testing valid =-
Test set: Average loss: 0.1193,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1108,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1037,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 30 train accuracy: 96.40%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0910,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 40 train accuracy: 97.05%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 50 train accuracy: 97.10%, valid accuracy 97.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1023,                   Accuracy: 58201/60000 (97.00%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1094,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1051,                   Accuracy: 58164/60000 (96.94%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1061,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1059,                   Accuracy: 58162/60000 (96.94%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1051,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1026,                   Accuracy: 58138/60000 (96.90%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0994,                   Accuracy: 58215/60000 (97.03%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1051,                   Accuracy: 58127/60000 (96.88%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1023,                   Accuracy: 58201/60000 (97.00%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1094,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1051,                   Accuracy: 58164/60000 (96.94%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1061,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1059,                   Accuracy: 58162/60000 (96.94%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1051,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1026,                   Accuracy: 58138/60000 (96.90%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.0994,                   Accuracy: 58215/60000 (97.03%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1051,                   Accuracy: 58127/60000 (96.88%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1023,                   Accuracy: 58201/60000 (97.00%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1094,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1051,                   Accuracy: 58164/60000 (96.94%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1061,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1059,                   Accuracy: 58162/60000 (96.94%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1051,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1026,                   Accuracy: 58138/60000 (96.90%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.0994,                   Accuracy: 58215/60000 (97.03%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1051,                   Accuracy: 58127/60000 (96.88%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1023,                   Accuracy: 58201/60000 (97.00%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1094,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1051,                   Accuracy: 58164/60000 (96.94%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1061,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1059,                   Accuracy: 58162/60000 (96.94%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1051,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1026,                   Accuracy: 58138/60000 (96.90%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0994,                   Accuracy: 58215/60000 (97.03%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1051,                   Accuracy: 58127/60000 (96.88%)
{0: tensor(97.0017), 10: tensor(96.7333), 20: tensor(96.9400), 30: tensor(96.8917), 40: tensor(96.9367), 50: tensor(96.8483), 60: tensor(96.8967), 70: tensor(97.0250), 80: tensor(96.8783), 90: tensor(97.0017), 100: tensor(96.7333), 110: tensor(96.9400), 120: tensor(96.8917), 130: tensor(96.9367), 140: tensor(96.8483), 150: tensor(96.8967), 160: tensor(97.0250), 170: tensor(96.8783), 180: tensor(97.0017), 190: tensor(96.7333), 200: tensor(96.9400), 210: tensor(96.8917), 220: tensor(96.9367), 230: tensor(96.8483), 240: tensor(96.8967), 250: tensor(97.0250), 260: tensor(96.8783), 270: tensor(97.0017), 280: tensor(96.7333), 290: tensor(96.9400), 300: tensor(96.8917), 310: tensor(96.9367), 320: tensor(96.8483), 330: tensor(96.8967), 340: tensor(97.0250), 350: tensor(96.8783)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=56, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7135,                   Accuracy: 848/2000.0 (42.40%)



-= Testing valid =-
Test set: Average loss: 1.4546,                   Accuracy: 975/2000.0 (48.75%)



-= Testing valid =-
Test set: Average loss: 0.8917,                   Accuracy: 1315/2000.0 (65.75%)



-= Testing valid =-
Test set: Average loss: 1.2279,                   Accuracy: 1111/2000.0 (55.55%)



-= Testing valid =-
Test set: Average loss: 0.3936,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.2299,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.3186,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.1962,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.2311,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.1951,                   Accuracy: 1869/2000.0 (93.45%)



Epoch 10 train accuracy: 94.05%, valid accuracy 93.45%
-= Testing valid =-
Test set: Average loss: 0.1919,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1984,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1149,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1085,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1582,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1221,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1252,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1279,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1295,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 20 train accuracy: 95.82%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0756,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 30 train accuracy: 96.50%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0742,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0734,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 40 train accuracy: 97.11%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0656,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 50 train accuracy: 97.38%, valid accuracy 97.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0984,                   Accuracy: 58290/60000 (97.15%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1040,                   Accuracy: 58162/60000 (96.94%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1017,                   Accuracy: 58145/60000 (96.91%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1044,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1068,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1116,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1106,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1076,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.0990,                   Accuracy: 58278/60000 (97.13%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0984,                   Accuracy: 58290/60000 (97.15%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1040,                   Accuracy: 58162/60000 (96.94%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1017,                   Accuracy: 58145/60000 (96.91%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1044,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1068,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1116,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1106,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1076,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.0990,                   Accuracy: 58278/60000 (97.13%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0984,                   Accuracy: 58290/60000 (97.15%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1040,                   Accuracy: 58162/60000 (96.94%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1017,                   Accuracy: 58145/60000 (96.91%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1044,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1068,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1116,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1106,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1076,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.0990,                   Accuracy: 58278/60000 (97.13%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0984,                   Accuracy: 58290/60000 (97.15%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1040,                   Accuracy: 58162/60000 (96.94%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1017,                   Accuracy: 58145/60000 (96.91%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1044,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1068,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1116,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1106,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1076,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0990,                   Accuracy: 58278/60000 (97.13%)
{0: tensor(97.1500), 10: tensor(96.9367), 20: tensor(96.9083), 30: tensor(96.8467), 40: tensor(96.7450), 50: tensor(96.7333), 60: tensor(96.7583), 70: tensor(96.8567), 80: tensor(97.1300), 90: tensor(97.1500), 100: tensor(96.9367), 110: tensor(96.9083), 120: tensor(96.8467), 130: tensor(96.7450), 140: tensor(96.7333), 150: tensor(96.7583), 160: tensor(96.8567), 170: tensor(97.1300), 180: tensor(97.1500), 190: tensor(96.9367), 200: tensor(96.9083), 210: tensor(96.8467), 220: tensor(96.7450), 230: tensor(96.7333), 240: tensor(96.7583), 250: tensor(96.8567), 260: tensor(97.1300), 270: tensor(97.1500), 280: tensor(96.9367), 290: tensor(96.9083), 300: tensor(96.8467), 310: tensor(96.7450), 320: tensor(96.7333), 330: tensor(96.7583), 340: tensor(96.8567), 350: tensor(97.1300)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=57, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9906,                   Accuracy: 515/2000.0 (25.75%)



-= Testing valid =-
Test set: Average loss: 1.5700,                   Accuracy: 788/2000.0 (39.40%)



-= Testing valid =-
Test set: Average loss: 0.7014,                   Accuracy: 1624/2000.0 (81.20%)



-= Testing valid =-
Test set: Average loss: 0.5537,                   Accuracy: 1608/2000.0 (80.40%)



-= Testing valid =-
Test set: Average loss: 0.3509,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.4499,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.2302,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.3114,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.2912,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2784,                   Accuracy: 1823/2000.0 (91.15%)



Epoch 10 train accuracy: 93.19%, valid accuracy 91.15%
-= Testing valid =-
Test set: Average loss: 0.1478,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1688,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1671,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1473,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1308,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1442,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1419,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1370,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1248,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1265,                   Accuracy: 1923/2000.0 (96.15%)



Epoch 20 train accuracy: 95.76%, valid accuracy 96.15%
-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1147,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1084,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1195,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1232,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1152,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1196,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 30 train accuracy: 96.46%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0978,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0937,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 40 train accuracy: 96.91%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 50 train accuracy: 97.44%, valid accuracy 97.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1117,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1166,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1166,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1217,                   Accuracy: 57855/60000 (96.43%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1253,                   Accuracy: 57837/60000 (96.39%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1272,                   Accuracy: 57812/60000 (96.35%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1245,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1188,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1131,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1117,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1166,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1166,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1217,                   Accuracy: 57855/60000 (96.43%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1253,                   Accuracy: 57837/60000 (96.39%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1272,                   Accuracy: 57812/60000 (96.35%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1245,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1188,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1131,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1117,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1166,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1166,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1217,                   Accuracy: 57855/60000 (96.43%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1253,                   Accuracy: 57837/60000 (96.39%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1272,                   Accuracy: 57812/60000 (96.35%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1245,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1188,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1131,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1117,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1166,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1166,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1217,                   Accuracy: 57855/60000 (96.43%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1253,                   Accuracy: 57837/60000 (96.39%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1272,                   Accuracy: 57812/60000 (96.35%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1245,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1188,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1131,                   Accuracy: 58036/60000 (96.73%)
{0: tensor(96.7467), 10: tensor(96.5317), 20: tensor(96.5683), 30: tensor(96.4250), 40: tensor(96.3950), 50: tensor(96.3533), 60: tensor(96.4467), 70: tensor(96.6450), 80: tensor(96.7267), 90: tensor(96.7467), 100: tensor(96.5317), 110: tensor(96.5683), 120: tensor(96.4250), 130: tensor(96.3950), 140: tensor(96.3533), 150: tensor(96.4467), 160: tensor(96.6450), 170: tensor(96.7267), 180: tensor(96.7467), 190: tensor(96.5317), 200: tensor(96.5683), 210: tensor(96.4250), 220: tensor(96.3950), 230: tensor(96.3533), 240: tensor(96.4467), 250: tensor(96.6450), 260: tensor(96.7267), 270: tensor(96.7467), 280: tensor(96.5317), 290: tensor(96.5683), 300: tensor(96.4250), 310: tensor(96.3950), 320: tensor(96.3533), 330: tensor(96.4467), 340: tensor(96.6450), 350: tensor(96.7267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=58, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.1887,                   Accuracy: 393/2000.0 (19.65%)



-= Testing valid =-
Test set: Average loss: 2.0803,                   Accuracy: 556/2000.0 (27.80%)



-= Testing valid =-
Test set: Average loss: 1.1158,                   Accuracy: 1173/2000.0 (58.65%)



-= Testing valid =-
Test set: Average loss: 0.4618,                   Accuracy: 1729/2000.0 (86.45%)



-= Testing valid =-
Test set: Average loss: 0.3955,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.5441,                   Accuracy: 1650/2000.0 (82.50%)



-= Testing valid =-
Test set: Average loss: 0.1928,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1678,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.2604,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2811,                   Accuracy: 1821/2000.0 (91.05%)



Epoch 10 train accuracy: 93.32%, valid accuracy 91.05%
-= Testing valid =-
Test set: Average loss: 0.1164,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1591,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1261,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1844,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1860,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1311,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1393,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1367,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1169,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 20 train accuracy: 95.81%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.1074,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1107,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1934/2000.0 (96.70%)



Epoch 30 train accuracy: 96.76%, valid accuracy 96.70%
-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 40 train accuracy: 97.19%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 50 train accuracy: 97.53%, valid accuracy 97.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1113,                   Accuracy: 58069/60000 (96.78%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1276,                   Accuracy: 57689/60000 (96.15%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1220,                   Accuracy: 57767/60000 (96.28%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1237,                   Accuracy: 57747/60000 (96.25%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1230,                   Accuracy: 57754/60000 (96.26%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1201,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1171,                   Accuracy: 57898/60000 (96.50%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1170,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1173,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1113,                   Accuracy: 58069/60000 (96.78%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1276,                   Accuracy: 57689/60000 (96.15%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1220,                   Accuracy: 57767/60000 (96.28%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1237,                   Accuracy: 57747/60000 (96.25%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1230,                   Accuracy: 57754/60000 (96.26%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1201,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1171,                   Accuracy: 57898/60000 (96.50%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1170,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1173,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1113,                   Accuracy: 58069/60000 (96.78%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1276,                   Accuracy: 57689/60000 (96.15%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1220,                   Accuracy: 57767/60000 (96.28%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1237,                   Accuracy: 57747/60000 (96.25%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1230,                   Accuracy: 57754/60000 (96.26%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1201,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1171,                   Accuracy: 57898/60000 (96.50%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1170,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1173,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1113,                   Accuracy: 58069/60000 (96.78%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1276,                   Accuracy: 57689/60000 (96.15%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1220,                   Accuracy: 57767/60000 (96.28%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1237,                   Accuracy: 57747/60000 (96.25%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1230,                   Accuracy: 57754/60000 (96.26%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1201,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1171,                   Accuracy: 57898/60000 (96.50%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1170,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1173,                   Accuracy: 57878/60000 (96.46%)
{0: tensor(96.7817), 10: tensor(96.1483), 20: tensor(96.2783), 30: tensor(96.2450), 40: tensor(96.2567), 50: tensor(96.4300), 60: tensor(96.4967), 70: tensor(96.5717), 80: tensor(96.4633), 90: tensor(96.7817), 100: tensor(96.1483), 110: tensor(96.2783), 120: tensor(96.2450), 130: tensor(96.2567), 140: tensor(96.4300), 150: tensor(96.4967), 160: tensor(96.5717), 170: tensor(96.4633), 180: tensor(96.7817), 190: tensor(96.1483), 200: tensor(96.2783), 210: tensor(96.2450), 220: tensor(96.2567), 230: tensor(96.4300), 240: tensor(96.4967), 250: tensor(96.5717), 260: tensor(96.4633), 270: tensor(96.7817), 280: tensor(96.1483), 290: tensor(96.2783), 300: tensor(96.2450), 310: tensor(96.2567), 320: tensor(96.4300), 330: tensor(96.4967), 340: tensor(96.5717), 350: tensor(96.4633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=59, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6774,                   Accuracy: 353/2000.0 (17.65%)



-= Testing valid =-
Test set: Average loss: 1.6586,                   Accuracy: 732/2000.0 (36.60%)



-= Testing valid =-
Test set: Average loss: 1.1297,                   Accuracy: 1092/2000.0 (54.60%)



-= Testing valid =-
Test set: Average loss: 0.8505,                   Accuracy: 1372/2000.0 (68.60%)



-= Testing valid =-
Test set: Average loss: 0.9130,                   Accuracy: 1396/2000.0 (69.80%)



-= Testing valid =-
Test set: Average loss: 0.4858,                   Accuracy: 1674/2000.0 (83.70%)



-= Testing valid =-
Test set: Average loss: 0.8005,                   Accuracy: 1475/2000.0 (73.75%)



-= Testing valid =-
Test set: Average loss: 0.4362,                   Accuracy: 1719/2000.0 (85.95%)



-= Testing valid =-
Test set: Average loss: 0.2439,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.3187,                   Accuracy: 1799/2000.0 (89.95%)



Epoch 10 train accuracy: 93.11%, valid accuracy 89.95%
-= Testing valid =-
Test set: Average loss: 0.1582,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.2598,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2062,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.1557,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1622,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1573,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1817,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1339,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1324,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1451,                   Accuracy: 1910/2000.0 (95.50%)



Epoch 20 train accuracy: 95.41%, valid accuracy 95.50%
-= Testing valid =-
Test set: Average loss: 0.1510,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1236,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1219,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1309,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1564,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1389,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1098,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1235,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1200,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1273,                   Accuracy: 1918/2000.0 (95.90%)



Epoch 30 train accuracy: 96.32%, valid accuracy 95.90%
-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1083,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1166,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1042,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1194,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1092,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1085,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1061,                   Accuracy: 1930/2000.0 (96.50%)



Epoch 40 train accuracy: 97.01%, valid accuracy 96.50%
-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1086,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1046,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 50 train accuracy: 97.16%, valid accuracy 96.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1158,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1242,                   Accuracy: 57763/60000 (96.27%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1244,                   Accuracy: 57734/60000 (96.22%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1306,                   Accuracy: 57660/60000 (96.10%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1306,                   Accuracy: 57604/60000 (96.01%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1278,                   Accuracy: 57729/60000 (96.21%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1198,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1125,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1115,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1158,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1242,                   Accuracy: 57763/60000 (96.27%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1244,                   Accuracy: 57734/60000 (96.22%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1306,                   Accuracy: 57660/60000 (96.10%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1306,                   Accuracy: 57604/60000 (96.01%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1278,                   Accuracy: 57729/60000 (96.21%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1198,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1125,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1115,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1158,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1242,                   Accuracy: 57763/60000 (96.27%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1244,                   Accuracy: 57734/60000 (96.22%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1306,                   Accuracy: 57660/60000 (96.10%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1306,                   Accuracy: 57604/60000 (96.01%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1278,                   Accuracy: 57729/60000 (96.21%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1198,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1125,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1115,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1158,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1242,                   Accuracy: 57763/60000 (96.27%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1244,                   Accuracy: 57734/60000 (96.22%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1306,                   Accuracy: 57660/60000 (96.10%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1306,                   Accuracy: 57604/60000 (96.01%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1278,                   Accuracy: 57729/60000 (96.21%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1198,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1125,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1115,                   Accuracy: 58004/60000 (96.67%)
{0: tensor(96.5550), 10: tensor(96.2717), 20: tensor(96.2233), 30: tensor(96.1000), 40: tensor(96.0067), 50: tensor(96.2150), 60: tensor(96.4433), 70: tensor(96.6333), 80: tensor(96.6733), 90: tensor(96.5550), 100: tensor(96.2717), 110: tensor(96.2233), 120: tensor(96.1000), 130: tensor(96.0067), 140: tensor(96.2150), 150: tensor(96.4433), 160: tensor(96.6333), 170: tensor(96.6733), 180: tensor(96.5550), 190: tensor(96.2717), 200: tensor(96.2233), 210: tensor(96.1000), 220: tensor(96.0067), 230: tensor(96.2150), 240: tensor(96.4433), 250: tensor(96.6333), 260: tensor(96.6733), 270: tensor(96.5550), 280: tensor(96.2717), 290: tensor(96.2233), 300: tensor(96.1000), 310: tensor(96.0067), 320: tensor(96.2150), 330: tensor(96.4433), 340: tensor(96.6333), 350: tensor(96.6733)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=60, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 7.1126,                   Accuracy: 235/2000.0 (11.75%)



-= Testing valid =-
Test set: Average loss: 4.0758,                   Accuracy: 279/2000.0 (13.95%)



-= Testing valid =-
Test set: Average loss: 1.9255,                   Accuracy: 642/2000.0 (32.10%)



-= Testing valid =-
Test set: Average loss: 3.0268,                   Accuracy: 644/2000.0 (32.20%)



-= Testing valid =-
Test set: Average loss: 0.7576,                   Accuracy: 1510/2000.0 (75.50%)



-= Testing valid =-
Test set: Average loss: 0.5266,                   Accuracy: 1562/2000.0 (78.10%)



-= Testing valid =-
Test set: Average loss: 0.4218,                   Accuracy: 1735/2000.0 (86.75%)



-= Testing valid =-
Test set: Average loss: 0.3118,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2443,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.1698,                   Accuracy: 1893/2000.0 (94.65%)



Epoch 10 train accuracy: 91.76%, valid accuracy 94.65%
-= Testing valid =-
Test set: Average loss: 0.1677,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1520,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1930,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1598,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1291,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.2276,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.1326,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1151,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 20 train accuracy: 95.26%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1150,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 30 train accuracy: 95.94%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 40 train accuracy: 96.50%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0756,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0736,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 50 train accuracy: 96.86%, valid accuracy 97.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0996,                   Accuracy: 58228/60000 (97.05%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1114,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1106,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1161,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1188,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1186,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1125,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1072,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1074,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0996,                   Accuracy: 58228/60000 (97.05%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1114,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1106,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1161,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1188,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1186,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1125,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1072,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1074,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0996,                   Accuracy: 58228/60000 (97.05%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1114,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1106,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1161,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1188,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1186,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1125,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1072,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1074,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0996,                   Accuracy: 58228/60000 (97.05%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1114,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1106,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1161,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1188,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1186,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1125,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1072,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1074,                   Accuracy: 58097/60000 (96.83%)
{0: tensor(97.0467), 10: tensor(96.6033), 20: tensor(96.7083), 30: tensor(96.4750), 40: tensor(96.4183), 50: tensor(96.3600), 60: tensor(96.6133), 70: tensor(96.7350), 80: tensor(96.8283), 90: tensor(97.0467), 100: tensor(96.6033), 110: tensor(96.7083), 120: tensor(96.4750), 130: tensor(96.4183), 140: tensor(96.3600), 150: tensor(96.6133), 160: tensor(96.7350), 170: tensor(96.8283), 180: tensor(97.0467), 190: tensor(96.6033), 200: tensor(96.7083), 210: tensor(96.4750), 220: tensor(96.4183), 230: tensor(96.3600), 240: tensor(96.6133), 250: tensor(96.7350), 260: tensor(96.8283), 270: tensor(97.0467), 280: tensor(96.6033), 290: tensor(96.7083), 300: tensor(96.4750), 310: tensor(96.4183), 320: tensor(96.3600), 330: tensor(96.6133), 340: tensor(96.7350), 350: tensor(96.8283)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=61, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2948,                   Accuracy: 452/2000.0 (22.60%)



-= Testing valid =-
Test set: Average loss: 1.5849,                   Accuracy: 753/2000.0 (37.65%)



-= Testing valid =-
Test set: Average loss: 0.7601,                   Accuracy: 1512/2000.0 (75.60%)



-= Testing valid =-
Test set: Average loss: 0.6417,                   Accuracy: 1581/2000.0 (79.05%)



-= Testing valid =-
Test set: Average loss: 0.8769,                   Accuracy: 1415/2000.0 (70.75%)



-= Testing valid =-
Test set: Average loss: 0.3418,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.2893,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.3952,                   Accuracy: 1749/2000.0 (87.45%)



-= Testing valid =-
Test set: Average loss: 0.1977,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.2372,                   Accuracy: 1858/2000.0 (92.90%)



Epoch 10 train accuracy: 93.19%, valid accuracy 92.90%
-= Testing valid =-
Test set: Average loss: 0.2125,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1591,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1799,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1454,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1880,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1586,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1330,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1481,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1154,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1612,                   Accuracy: 1899/2000.0 (94.95%)



Epoch 20 train accuracy: 95.21%, valid accuracy 94.95%
-= Testing valid =-
Test set: Average loss: 0.1145,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1071,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1154,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1217,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1130,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1083,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1127,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1234,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 30 train accuracy: 96.32%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1037,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1053,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0909,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1094,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 40 train accuracy: 96.61%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 50 train accuracy: 97.41%, valid accuracy 97.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1197,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1318,                   Accuracy: 57627/60000 (96.04%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1242,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1251,                   Accuracy: 57821/60000 (96.37%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1271,                   Accuracy: 57761/60000 (96.27%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1265,                   Accuracy: 57758/60000 (96.26%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1249,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1214,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1208,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1197,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1318,                   Accuracy: 57627/60000 (96.04%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1242,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1251,                   Accuracy: 57821/60000 (96.37%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1271,                   Accuracy: 57761/60000 (96.27%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1265,                   Accuracy: 57758/60000 (96.26%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1249,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1214,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1208,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1197,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1318,                   Accuracy: 57627/60000 (96.04%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1242,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1251,                   Accuracy: 57821/60000 (96.37%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1271,                   Accuracy: 57761/60000 (96.27%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1265,                   Accuracy: 57758/60000 (96.26%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1249,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1214,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1208,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1197,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1318,                   Accuracy: 57627/60000 (96.04%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1242,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1251,                   Accuracy: 57821/60000 (96.37%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1271,                   Accuracy: 57761/60000 (96.27%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1265,                   Accuracy: 57758/60000 (96.26%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1249,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1214,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1208,                   Accuracy: 57876/60000 (96.46%)
{0: tensor(96.6067), 10: tensor(96.0450), 20: tensor(96.4017), 30: tensor(96.3683), 40: tensor(96.2683), 50: tensor(96.2633), 60: tensor(96.3400), 70: tensor(96.4633), 80: tensor(96.4600), 90: tensor(96.6067), 100: tensor(96.0450), 110: tensor(96.4017), 120: tensor(96.3683), 130: tensor(96.2683), 140: tensor(96.2633), 150: tensor(96.3400), 160: tensor(96.4633), 170: tensor(96.4600), 180: tensor(96.6067), 190: tensor(96.0450), 200: tensor(96.4017), 210: tensor(96.3683), 220: tensor(96.2683), 230: tensor(96.2633), 240: tensor(96.3400), 250: tensor(96.4633), 260: tensor(96.4600), 270: tensor(96.6067), 280: tensor(96.0450), 290: tensor(96.4017), 300: tensor(96.3683), 310: tensor(96.2683), 320: tensor(96.2633), 330: tensor(96.3400), 340: tensor(96.4633), 350: tensor(96.4600)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=62, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.7265,                   Accuracy: 229/2000.0 (11.45%)



-= Testing valid =-
Test set: Average loss: 7.3191,                   Accuracy: 202/2000.0 (10.10%)



-= Testing valid =-
Test set: Average loss: 1.2426,                   Accuracy: 1055/2000.0 (52.75%)



-= Testing valid =-
Test set: Average loss: 0.6183,                   Accuracy: 1641/2000.0 (82.05%)



-= Testing valid =-
Test set: Average loss: 0.5757,                   Accuracy: 1560/2000.0 (78.00%)



-= Testing valid =-
Test set: Average loss: 0.5991,                   Accuracy: 1624/2000.0 (81.20%)



-= Testing valid =-
Test set: Average loss: 0.3843,                   Accuracy: 1759/2000.0 (87.95%)



-= Testing valid =-
Test set: Average loss: 0.2666,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2330,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2592,                   Accuracy: 1834/2000.0 (91.70%)



Epoch 10 train accuracy: 92.86%, valid accuracy 91.70%
-= Testing valid =-
Test set: Average loss: 0.1634,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1712,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1807,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.2064,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.1391,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1795,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1476,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1446,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1440,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1191,                   Accuracy: 1930/2000.0 (96.50%)



Epoch 20 train accuracy: 95.59%, valid accuracy 96.50%
-= Testing valid =-
Test set: Average loss: 0.1713,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1174,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1158,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1132,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1083,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1235,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1053,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1161,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1161,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 30 train accuracy: 96.68%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.1141,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1164,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1213,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1064,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0937,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 40 train accuracy: 96.79%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0947,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 50 train accuracy: 97.28%, valid accuracy 97.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1098,                   Accuracy: 58035/60000 (96.72%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1212,                   Accuracy: 57752/60000 (96.25%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1158,                   Accuracy: 57900/60000 (96.50%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1176,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1171,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1162,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1142,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1108,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1100,                   Accuracy: 58019/60000 (96.70%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1098,                   Accuracy: 58035/60000 (96.72%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1212,                   Accuracy: 57752/60000 (96.25%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1158,                   Accuracy: 57900/60000 (96.50%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1176,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1171,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1162,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1142,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1108,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1100,                   Accuracy: 58019/60000 (96.70%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1098,                   Accuracy: 58035/60000 (96.72%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1212,                   Accuracy: 57752/60000 (96.25%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1158,                   Accuracy: 57900/60000 (96.50%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1176,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1171,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1162,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1142,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1108,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1100,                   Accuracy: 58019/60000 (96.70%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1098,                   Accuracy: 58035/60000 (96.72%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1212,                   Accuracy: 57752/60000 (96.25%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1158,                   Accuracy: 57900/60000 (96.50%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1176,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1171,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1162,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1142,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1108,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1100,                   Accuracy: 58019/60000 (96.70%)
{0: tensor(96.7250), 10: tensor(96.2533), 20: tensor(96.5000), 30: tensor(96.4017), 40: tensor(96.4983), 50: tensor(96.5333), 60: tensor(96.6017), 70: tensor(96.7417), 80: tensor(96.6983), 90: tensor(96.7250), 100: tensor(96.2533), 110: tensor(96.5000), 120: tensor(96.4017), 130: tensor(96.4983), 140: tensor(96.5333), 150: tensor(96.6017), 160: tensor(96.7417), 170: tensor(96.6983), 180: tensor(96.7250), 190: tensor(96.2533), 200: tensor(96.5000), 210: tensor(96.4017), 220: tensor(96.4983), 230: tensor(96.5333), 240: tensor(96.6017), 250: tensor(96.7417), 260: tensor(96.6983), 270: tensor(96.7250), 280: tensor(96.2533), 290: tensor(96.5000), 300: tensor(96.4017), 310: tensor(96.4983), 320: tensor(96.5333), 330: tensor(96.6017), 340: tensor(96.7417), 350: tensor(96.6983)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=63, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0830,                   Accuracy: 506/2000.0 (25.30%)



-= Testing valid =-
Test set: Average loss: 5.1669,                   Accuracy: 191/2000.0 (9.55%)



-= Testing valid =-
Test set: Average loss: 1.6690,                   Accuracy: 904/2000.0 (45.20%)



-= Testing valid =-
Test set: Average loss: 0.6050,                   Accuracy: 1626/2000.0 (81.30%)



-= Testing valid =-
Test set: Average loss: 0.6085,                   Accuracy: 1617/2000.0 (80.85%)



-= Testing valid =-
Test set: Average loss: 0.4312,                   Accuracy: 1736/2000.0 (86.80%)



-= Testing valid =-
Test set: Average loss: 0.3430,                   Accuracy: 1777/2000.0 (88.85%)



-= Testing valid =-
Test set: Average loss: 0.3456,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.1713,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.2482,                   Accuracy: 1830/2000.0 (91.50%)



Epoch 10 train accuracy: 93.56%, valid accuracy 91.50%
-= Testing valid =-
Test set: Average loss: 0.1536,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1443,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1979,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1475,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1528,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1470,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1490,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1304,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1438,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1150,                   Accuracy: 1915/2000.0 (95.75%)



Epoch 20 train accuracy: 95.88%, valid accuracy 95.75%
-= Testing valid =-
Test set: Average loss: 0.1036,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1328,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1021,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1253,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1269,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1085,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 30 train accuracy: 96.59%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0909,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 40 train accuracy: 97.40%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 50 train accuracy: 97.30%, valid accuracy 97.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1062,                   Accuracy: 58137/60000 (96.89%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1123,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1143,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1228,                   Accuracy: 57848/60000 (96.41%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1212,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1192,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1150,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1095,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1050,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1062,                   Accuracy: 58137/60000 (96.89%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1123,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1143,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1228,                   Accuracy: 57848/60000 (96.41%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1212,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1192,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1150,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1095,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1050,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1062,                   Accuracy: 58137/60000 (96.89%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1123,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1143,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1228,                   Accuracy: 57848/60000 (96.41%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1212,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1192,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1150,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1095,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1050,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1062,                   Accuracy: 58137/60000 (96.89%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1123,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1143,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1228,                   Accuracy: 57848/60000 (96.41%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1212,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1192,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1150,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1095,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1050,                   Accuracy: 58100/60000 (96.83%)
{0: tensor(96.8950), 10: tensor(96.6217), 20: tensor(96.6933), 30: tensor(96.4133), 40: tensor(96.4583), 50: tensor(96.5617), 60: tensor(96.6650), 70: tensor(96.8283), 80: tensor(96.8333), 90: tensor(96.8950), 100: tensor(96.6217), 110: tensor(96.6933), 120: tensor(96.4133), 130: tensor(96.4583), 140: tensor(96.5617), 150: tensor(96.6650), 160: tensor(96.8283), 170: tensor(96.8333), 180: tensor(96.8950), 190: tensor(96.6217), 200: tensor(96.6933), 210: tensor(96.4133), 220: tensor(96.4583), 230: tensor(96.5617), 240: tensor(96.6650), 250: tensor(96.8283), 260: tensor(96.8333), 270: tensor(96.8950), 280: tensor(96.6217), 290: tensor(96.6933), 300: tensor(96.4133), 310: tensor(96.4583), 320: tensor(96.5617), 330: tensor(96.6650), 340: tensor(96.8283), 350: tensor(96.8333)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=64, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.1711,                   Accuracy: 240/2000.0 (12.00%)



-= Testing valid =-
Test set: Average loss: 1.9575,                   Accuracy: 701/2000.0 (35.05%)



-= Testing valid =-
Test set: Average loss: 0.8997,                   Accuracy: 1442/2000.0 (72.10%)



-= Testing valid =-
Test set: Average loss: 1.2439,                   Accuracy: 1040/2000.0 (52.00%)



-= Testing valid =-
Test set: Average loss: 0.6461,                   Accuracy: 1543/2000.0 (77.15%)



-= Testing valid =-
Test set: Average loss: 1.4486,                   Accuracy: 1215/2000.0 (60.75%)



-= Testing valid =-
Test set: Average loss: 0.4330,                   Accuracy: 1732/2000.0 (86.60%)



-= Testing valid =-
Test set: Average loss: 0.3578,                   Accuracy: 1777/2000.0 (88.85%)



-= Testing valid =-
Test set: Average loss: 0.1976,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1577,                   Accuracy: 1901/2000.0 (95.05%)



Epoch 10 train accuracy: 93.29%, valid accuracy 95.05%
-= Testing valid =-
Test set: Average loss: 0.1499,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1262,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1737,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1530,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1274,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1396,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1200,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1330,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1135,                   Accuracy: 1915/2000.0 (95.75%)



Epoch 20 train accuracy: 95.69%, valid accuracy 95.75%
-= Testing valid =-
Test set: Average loss: 0.1183,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1050,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1165,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1058,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0919,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 30 train accuracy: 96.91%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0877,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 40 train accuracy: 97.10%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 50 train accuracy: 97.06%, valid accuracy 97.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1052,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1099,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1116,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1168,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1216,                   Accuracy: 57862/60000 (96.44%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1239,                   Accuracy: 57799/60000 (96.33%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1186,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1117,                   Accuracy: 58007/60000 (96.68%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1074,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1052,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1099,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1116,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1168,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1216,                   Accuracy: 57862/60000 (96.44%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1239,                   Accuracy: 57799/60000 (96.33%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1186,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1117,                   Accuracy: 58007/60000 (96.68%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1074,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1052,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1099,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1116,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1168,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1216,                   Accuracy: 57862/60000 (96.44%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1239,                   Accuracy: 57799/60000 (96.33%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1186,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1117,                   Accuracy: 58007/60000 (96.68%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1074,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1052,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1099,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1116,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1168,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1216,                   Accuracy: 57862/60000 (96.44%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1239,                   Accuracy: 57799/60000 (96.33%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1186,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1117,                   Accuracy: 58007/60000 (96.68%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1074,                   Accuracy: 58059/60000 (96.76%)
{0: tensor(96.8800), 10: tensor(96.7333), 20: tensor(96.7567), 30: tensor(96.5933), 40: tensor(96.4367), 50: tensor(96.3317), 60: tensor(96.4600), 70: tensor(96.6783), 80: tensor(96.7650), 90: tensor(96.8800), 100: tensor(96.7333), 110: tensor(96.7567), 120: tensor(96.5933), 130: tensor(96.4367), 140: tensor(96.3317), 150: tensor(96.4600), 160: tensor(96.6783), 170: tensor(96.7650), 180: tensor(96.8800), 190: tensor(96.7333), 200: tensor(96.7567), 210: tensor(96.5933), 220: tensor(96.4367), 230: tensor(96.3317), 240: tensor(96.4600), 250: tensor(96.6783), 260: tensor(96.7650), 270: tensor(96.8800), 280: tensor(96.7333), 290: tensor(96.7567), 300: tensor(96.5933), 310: tensor(96.4367), 320: tensor(96.3317), 330: tensor(96.4600), 340: tensor(96.6783), 350: tensor(96.7650)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=65, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1592,                   Accuracy: 608/2000.0 (30.40%)



-= Testing valid =-
Test set: Average loss: 1.5596,                   Accuracy: 986/2000.0 (49.30%)



-= Testing valid =-
Test set: Average loss: 1.3022,                   Accuracy: 1034/2000.0 (51.70%)



-= Testing valid =-
Test set: Average loss: 2.3064,                   Accuracy: 651/2000.0 (32.55%)



-= Testing valid =-
Test set: Average loss: 0.3564,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.3602,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.2206,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2570,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2927,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.1479,                   Accuracy: 1917/2000.0 (95.85%)



Epoch 10 train accuracy: 93.20%, valid accuracy 95.85%
-= Testing valid =-
Test set: Average loss: 0.1244,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1296,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1293,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1174,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1161,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1328,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1211,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1455,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1283,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1089,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 20 train accuracy: 95.82%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 30 train accuracy: 96.51%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 40 train accuracy: 96.96%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0715,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0718,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0707,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0691,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 50 train accuracy: 97.20%, valid accuracy 97.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1075,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1207,                   Accuracy: 57763/60000 (96.27%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1116,                   Accuracy: 58032/60000 (96.72%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1142,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1130,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1105,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1106,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1089,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1088,                   Accuracy: 58019/60000 (96.70%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1075,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1207,                   Accuracy: 57763/60000 (96.27%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1116,                   Accuracy: 58032/60000 (96.72%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1142,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1130,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1105,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1106,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1089,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1088,                   Accuracy: 58019/60000 (96.70%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1075,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1207,                   Accuracy: 57763/60000 (96.27%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1116,                   Accuracy: 58032/60000 (96.72%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1142,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1130,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1105,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1106,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1089,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1088,                   Accuracy: 58019/60000 (96.70%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1075,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1207,                   Accuracy: 57763/60000 (96.27%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1116,                   Accuracy: 58032/60000 (96.72%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1142,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1130,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1105,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1106,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1089,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1088,                   Accuracy: 58019/60000 (96.70%)
{0: tensor(96.7850), 10: tensor(96.2717), 20: tensor(96.7200), 30: tensor(96.6767), 40: tensor(96.7350), 50: tensor(96.6450), 60: tensor(96.6750), 70: tensor(96.7633), 80: tensor(96.6983), 90: tensor(96.7850), 100: tensor(96.2717), 110: tensor(96.7200), 120: tensor(96.6767), 130: tensor(96.7350), 140: tensor(96.6450), 150: tensor(96.6750), 160: tensor(96.7633), 170: tensor(96.6983), 180: tensor(96.7850), 190: tensor(96.2717), 200: tensor(96.7200), 210: tensor(96.6767), 220: tensor(96.7350), 230: tensor(96.6450), 240: tensor(96.6750), 250: tensor(96.7633), 260: tensor(96.6983), 270: tensor(96.7850), 280: tensor(96.2717), 290: tensor(96.7200), 300: tensor(96.6767), 310: tensor(96.7350), 320: tensor(96.6450), 330: tensor(96.6750), 340: tensor(96.7633), 350: tensor(96.6983)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=66, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.0142,                   Accuracy: 224/2000.0 (11.20%)



-= Testing valid =-
Test set: Average loss: 1.5227,                   Accuracy: 941/2000.0 (47.05%)



-= Testing valid =-
Test set: Average loss: 1.4643,                   Accuracy: 1061/2000.0 (53.05%)



-= Testing valid =-
Test set: Average loss: 0.7327,                   Accuracy: 1550/2000.0 (77.50%)



-= Testing valid =-
Test set: Average loss: 0.3505,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.3034,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.4437,                   Accuracy: 1730/2000.0 (86.50%)



-= Testing valid =-
Test set: Average loss: 0.3324,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.2343,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.1810,                   Accuracy: 1879/2000.0 (93.95%)



Epoch 10 train accuracy: 93.09%, valid accuracy 93.95%
-= Testing valid =-
Test set: Average loss: 0.1452,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1734,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1307,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1384,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1224,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1546,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1357,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1249,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1077,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1491,                   Accuracy: 1911/2000.0 (95.55%)



Epoch 20 train accuracy: 96.05%, valid accuracy 95.55%
-= Testing valid =-
Test set: Average loss: 0.1076,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1134,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1162,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1106,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1184,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1010,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 30 train accuracy: 96.61%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0926,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1934/2000.0 (96.70%)



Epoch 40 train accuracy: 96.94%, valid accuracy 96.70%
-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0964,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 50 train accuracy: 97.22%, valid accuracy 97.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1168,                   Accuracy: 57905/60000 (96.51%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1242,                   Accuracy: 57678/60000 (96.13%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1159,                   Accuracy: 57903/60000 (96.50%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1204,                   Accuracy: 57797/60000 (96.33%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1233,                   Accuracy: 57743/60000 (96.24%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1243,                   Accuracy: 57742/60000 (96.24%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1271,                   Accuracy: 57686/60000 (96.14%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1232,                   Accuracy: 57724/60000 (96.21%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1195,                   Accuracy: 57785/60000 (96.31%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1168,                   Accuracy: 57905/60000 (96.51%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1242,                   Accuracy: 57678/60000 (96.13%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1159,                   Accuracy: 57903/60000 (96.50%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1204,                   Accuracy: 57797/60000 (96.33%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1233,                   Accuracy: 57743/60000 (96.24%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1243,                   Accuracy: 57742/60000 (96.24%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1271,                   Accuracy: 57686/60000 (96.14%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1232,                   Accuracy: 57724/60000 (96.21%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1195,                   Accuracy: 57785/60000 (96.31%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1168,                   Accuracy: 57905/60000 (96.51%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1242,                   Accuracy: 57678/60000 (96.13%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1159,                   Accuracy: 57903/60000 (96.50%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1204,                   Accuracy: 57797/60000 (96.33%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1233,                   Accuracy: 57743/60000 (96.24%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1243,                   Accuracy: 57742/60000 (96.24%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1271,                   Accuracy: 57686/60000 (96.14%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1232,                   Accuracy: 57724/60000 (96.21%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1195,                   Accuracy: 57785/60000 (96.31%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1168,                   Accuracy: 57905/60000 (96.51%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1242,                   Accuracy: 57678/60000 (96.13%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1159,                   Accuracy: 57903/60000 (96.50%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1204,                   Accuracy: 57797/60000 (96.33%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1233,                   Accuracy: 57743/60000 (96.24%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1243,                   Accuracy: 57742/60000 (96.24%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1271,                   Accuracy: 57686/60000 (96.14%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1232,                   Accuracy: 57724/60000 (96.21%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1195,                   Accuracy: 57785/60000 (96.31%)
{0: tensor(96.5083), 10: tensor(96.1300), 20: tensor(96.5050), 30: tensor(96.3283), 40: tensor(96.2383), 50: tensor(96.2367), 60: tensor(96.1433), 70: tensor(96.2067), 80: tensor(96.3083), 90: tensor(96.5083), 100: tensor(96.1300), 110: tensor(96.5050), 120: tensor(96.3283), 130: tensor(96.2383), 140: tensor(96.2367), 150: tensor(96.1433), 160: tensor(96.2067), 170: tensor(96.3083), 180: tensor(96.5083), 190: tensor(96.1300), 200: tensor(96.5050), 210: tensor(96.3283), 220: tensor(96.2383), 230: tensor(96.2367), 240: tensor(96.1433), 250: tensor(96.2067), 260: tensor(96.3083), 270: tensor(96.5083), 280: tensor(96.1300), 290: tensor(96.5050), 300: tensor(96.3283), 310: tensor(96.2383), 320: tensor(96.2367), 330: tensor(96.1433), 340: tensor(96.2067), 350: tensor(96.3083)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=67, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0900,                   Accuracy: 562/2000.0 (28.10%)



-= Testing valid =-
Test set: Average loss: 1.7100,                   Accuracy: 690/2000.0 (34.50%)



-= Testing valid =-
Test set: Average loss: 1.4836,                   Accuracy: 860/2000.0 (43.00%)



-= Testing valid =-
Test set: Average loss: 1.3984,                   Accuracy: 1041/2000.0 (52.05%)



-= Testing valid =-
Test set: Average loss: 0.6888,                   Accuracy: 1548/2000.0 (77.40%)



-= Testing valid =-
Test set: Average loss: 1.0155,                   Accuracy: 1337/2000.0 (66.85%)



-= Testing valid =-
Test set: Average loss: 0.3399,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.2905,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2257,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.1595,                   Accuracy: 1900/2000.0 (95.00%)



Epoch 10 train accuracy: 93.55%, valid accuracy 95.00%
-= Testing valid =-
Test set: Average loss: 0.1506,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1629,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1270,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1411,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1522,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1591,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1067,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1247,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1243,                   Accuracy: 1917/2000.0 (95.85%)



Epoch 20 train accuracy: 95.66%, valid accuracy 95.85%
-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1085,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 30 train accuracy: 96.40%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 40 train accuracy: 97.05%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0683,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0658,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 50 train accuracy: 97.06%, valid accuracy 97.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1061,                   Accuracy: 58171/60000 (96.95%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1140,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1114,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1132,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1144,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1134,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1087,                   Accuracy: 58092/60000 (96.82%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1056,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1070,                   Accuracy: 58116/60000 (96.86%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1061,                   Accuracy: 58171/60000 (96.95%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1140,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1114,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1132,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1144,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1134,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1087,                   Accuracy: 58092/60000 (96.82%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1056,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1070,                   Accuracy: 58116/60000 (96.86%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1061,                   Accuracy: 58171/60000 (96.95%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1140,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1114,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1132,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1144,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1134,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1087,                   Accuracy: 58092/60000 (96.82%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1056,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1070,                   Accuracy: 58116/60000 (96.86%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1061,                   Accuracy: 58171/60000 (96.95%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1140,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1114,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1132,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1144,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1134,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1087,                   Accuracy: 58092/60000 (96.82%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1056,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1070,                   Accuracy: 58116/60000 (96.86%)
{0: tensor(96.9517), 10: tensor(96.6150), 20: tensor(96.7600), 30: tensor(96.6233), 40: tensor(96.5633), 50: tensor(96.6050), 60: tensor(96.8200), 70: tensor(96.8283), 80: tensor(96.8600), 90: tensor(96.9517), 100: tensor(96.6150), 110: tensor(96.7600), 120: tensor(96.6233), 130: tensor(96.5633), 140: tensor(96.6050), 150: tensor(96.8200), 160: tensor(96.8283), 170: tensor(96.8600), 180: tensor(96.9517), 190: tensor(96.6150), 200: tensor(96.7600), 210: tensor(96.6233), 220: tensor(96.5633), 230: tensor(96.6050), 240: tensor(96.8200), 250: tensor(96.8283), 260: tensor(96.8600), 270: tensor(96.9517), 280: tensor(96.6150), 290: tensor(96.7600), 300: tensor(96.6233), 310: tensor(96.5633), 320: tensor(96.6050), 330: tensor(96.8200), 340: tensor(96.8283), 350: tensor(96.8600)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=68, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0925,                   Accuracy: 515/2000.0 (25.75%)



-= Testing valid =-
Test set: Average loss: 1.8363,                   Accuracy: 752/2000.0 (37.60%)



-= Testing valid =-
Test set: Average loss: 1.4346,                   Accuracy: 890/2000.0 (44.50%)



-= Testing valid =-
Test set: Average loss: 1.1521,                   Accuracy: 1162/2000.0 (58.10%)



-= Testing valid =-
Test set: Average loss: 0.5111,                   Accuracy: 1689/2000.0 (84.45%)



-= Testing valid =-
Test set: Average loss: 0.5127,                   Accuracy: 1684/2000.0 (84.20%)



-= Testing valid =-
Test set: Average loss: 0.2838,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2412,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.3691,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.2944,                   Accuracy: 1823/2000.0 (91.15%)



Epoch 10 train accuracy: 93.38%, valid accuracy 91.15%
-= Testing valid =-
Test set: Average loss: 0.1744,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1607,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1587,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1453,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1374,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1335,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1425,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1400,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1383,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1184,                   Accuracy: 1930/2000.0 (96.50%)



Epoch 20 train accuracy: 95.32%, valid accuracy 96.50%
-= Testing valid =-
Test set: Average loss: 0.1188,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1260,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1161,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1168,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1034,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1079,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1934/2000.0 (96.70%)



Epoch 30 train accuracy: 96.68%, valid accuracy 96.70%
-= Testing valid =-
Test set: Average loss: 0.1051,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 40 train accuracy: 96.79%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 50 train accuracy: 97.29%, valid accuracy 97.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1033,                   Accuracy: 58177/60000 (96.96%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1147,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1078,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1082,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1092,                   Accuracy: 58075/60000 (96.79%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1117,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1085,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1086,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1082,                   Accuracy: 58066/60000 (96.78%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1033,                   Accuracy: 58177/60000 (96.96%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1147,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1078,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1082,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1092,                   Accuracy: 58075/60000 (96.79%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1117,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1085,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1086,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1082,                   Accuracy: 58066/60000 (96.78%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1033,                   Accuracy: 58177/60000 (96.96%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1147,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1078,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1082,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1092,                   Accuracy: 58075/60000 (96.79%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1117,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1085,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1086,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1082,                   Accuracy: 58066/60000 (96.78%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1033,                   Accuracy: 58177/60000 (96.96%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1147,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1078,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1082,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1092,                   Accuracy: 58075/60000 (96.79%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1117,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1085,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1086,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1082,                   Accuracy: 58066/60000 (96.78%)
{0: tensor(96.9617), 10: tensor(96.6000), 20: tensor(96.7500), 30: tensor(96.7650), 40: tensor(96.7917), 50: tensor(96.7117), 60: tensor(96.8100), 70: tensor(96.8667), 80: tensor(96.7767), 90: tensor(96.9617), 100: tensor(96.6000), 110: tensor(96.7500), 120: tensor(96.7650), 130: tensor(96.7917), 140: tensor(96.7117), 150: tensor(96.8100), 160: tensor(96.8667), 170: tensor(96.7767), 180: tensor(96.9617), 190: tensor(96.6000), 200: tensor(96.7500), 210: tensor(96.7650), 220: tensor(96.7917), 230: tensor(96.7117), 240: tensor(96.8100), 250: tensor(96.8667), 260: tensor(96.7767), 270: tensor(96.9617), 280: tensor(96.6000), 290: tensor(96.7500), 300: tensor(96.7650), 310: tensor(96.7917), 320: tensor(96.7117), 330: tensor(96.8100), 340: tensor(96.8667), 350: tensor(96.7767)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=69, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.2760,                   Accuracy: 266/2000.0 (13.30%)



-= Testing valid =-
Test set: Average loss: 1.9745,                   Accuracy: 577/2000.0 (28.85%)



-= Testing valid =-
Test set: Average loss: 1.8806,                   Accuracy: 719/2000.0 (35.95%)



-= Testing valid =-
Test set: Average loss: 2.4751,                   Accuracy: 524/2000.0 (26.20%)



-= Testing valid =-
Test set: Average loss: 0.3674,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.3666,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.2793,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.4288,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.3278,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.2253,                   Accuracy: 1864/2000.0 (93.20%)



Epoch 10 train accuracy: 93.68%, valid accuracy 93.20%
-= Testing valid =-
Test set: Average loss: 0.1836,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.1870,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1787,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1951,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1799,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.2079,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1481,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1464,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1568,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1500,                   Accuracy: 1910/2000.0 (95.50%)



Epoch 20 train accuracy: 96.06%, valid accuracy 95.50%
-= Testing valid =-
Test set: Average loss: 0.1494,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1352,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1378,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1256,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1286,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1152,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1135,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1594,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1281,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1461,                   Accuracy: 1910/2000.0 (95.50%)



Epoch 30 train accuracy: 97.10%, valid accuracy 95.50%
-= Testing valid =-
Test set: Average loss: 0.1270,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1171,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1194,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1108,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1140,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1114,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1132,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1173,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1068,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1088,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 40 train accuracy: 96.99%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.1091,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1061,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1106,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 50 train accuracy: 97.31%, valid accuracy 96.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1104,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1190,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1156,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1142,                   Accuracy: 58031/60000 (96.72%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1143,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1143,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1120,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1129,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1138,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1104,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1190,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1156,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1142,                   Accuracy: 58031/60000 (96.72%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1143,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1143,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1120,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1129,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1138,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1104,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1190,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1156,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1142,                   Accuracy: 58031/60000 (96.72%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1143,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1143,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1120,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1129,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1138,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1104,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1190,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1156,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1142,                   Accuracy: 58031/60000 (96.72%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1143,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1143,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1120,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1129,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1138,                   Accuracy: 57964/60000 (96.61%)
{0: tensor(96.7583), 10: tensor(96.4350), 20: tensor(96.5950), 30: tensor(96.7183), 40: tensor(96.7550), 50: tensor(96.6267), 60: tensor(96.7417), 70: tensor(96.7000), 80: tensor(96.6067), 90: tensor(96.7583), 100: tensor(96.4350), 110: tensor(96.5950), 120: tensor(96.7183), 130: tensor(96.7550), 140: tensor(96.6267), 150: tensor(96.7417), 160: tensor(96.7000), 170: tensor(96.6067), 180: tensor(96.7583), 190: tensor(96.4350), 200: tensor(96.5950), 210: tensor(96.7183), 220: tensor(96.7550), 230: tensor(96.6267), 240: tensor(96.7417), 250: tensor(96.7000), 260: tensor(96.6067), 270: tensor(96.7583), 280: tensor(96.4350), 290: tensor(96.5950), 300: tensor(96.7183), 310: tensor(96.7550), 320: tensor(96.6267), 330: tensor(96.7417), 340: tensor(96.7000), 350: tensor(96.6067)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=70, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.3570,                   Accuracy: 217/2000.0 (10.85%)



-= Testing valid =-
Test set: Average loss: 2.4234,                   Accuracy: 477/2000.0 (23.85%)



-= Testing valid =-
Test set: Average loss: 0.8669,                   Accuracy: 1458/2000.0 (72.90%)



-= Testing valid =-
Test set: Average loss: 0.8240,                   Accuracy: 1439/2000.0 (71.95%)



-= Testing valid =-
Test set: Average loss: 1.0328,                   Accuracy: 1232/2000.0 (61.60%)



-= Testing valid =-
Test set: Average loss: 0.4271,                   Accuracy: 1732/2000.0 (86.60%)



-= Testing valid =-
Test set: Average loss: 0.3254,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.3545,                   Accuracy: 1764/2000.0 (88.20%)



-= Testing valid =-
Test set: Average loss: 0.3084,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.1901,                   Accuracy: 1890/2000.0 (94.50%)



Epoch 10 train accuracy: 92.72%, valid accuracy 94.50%
-= Testing valid =-
Test set: Average loss: 0.2020,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1695,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1647,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1824,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.2023,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2010,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.1945,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1702,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1496,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1354,                   Accuracy: 1915/2000.0 (95.75%)



Epoch 20 train accuracy: 95.25%, valid accuracy 95.75%
-= Testing valid =-
Test set: Average loss: 0.1219,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1341,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1160,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1148,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1217,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1148,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1072,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1279,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 30 train accuracy: 96.24%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.1064,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1140,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1097,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1074,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0981,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1012,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 40 train accuracy: 96.79%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1066,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1020,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 50 train accuracy: 96.99%, valid accuracy 96.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1224,                   Accuracy: 57805/60000 (96.34%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1309,                   Accuracy: 57687/60000 (96.14%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1306,                   Accuracy: 57698/60000 (96.16%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1324,                   Accuracy: 57701/60000 (96.17%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1354,                   Accuracy: 57666/60000 (96.11%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1357,                   Accuracy: 57662/60000 (96.10%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1320,                   Accuracy: 57709/60000 (96.18%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1278,                   Accuracy: 57721/60000 (96.20%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1231,                   Accuracy: 57809/60000 (96.35%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1224,                   Accuracy: 57805/60000 (96.34%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1309,                   Accuracy: 57687/60000 (96.14%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1306,                   Accuracy: 57698/60000 (96.16%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1324,                   Accuracy: 57701/60000 (96.17%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1354,                   Accuracy: 57666/60000 (96.11%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1357,                   Accuracy: 57662/60000 (96.10%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1320,                   Accuracy: 57709/60000 (96.18%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1278,                   Accuracy: 57721/60000 (96.20%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1231,                   Accuracy: 57809/60000 (96.35%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1224,                   Accuracy: 57805/60000 (96.34%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1309,                   Accuracy: 57687/60000 (96.14%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1306,                   Accuracy: 57698/60000 (96.16%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1324,                   Accuracy: 57701/60000 (96.17%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1354,                   Accuracy: 57666/60000 (96.11%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1357,                   Accuracy: 57662/60000 (96.10%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1320,                   Accuracy: 57709/60000 (96.18%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1278,                   Accuracy: 57721/60000 (96.20%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1231,                   Accuracy: 57809/60000 (96.35%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1224,                   Accuracy: 57805/60000 (96.34%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1309,                   Accuracy: 57687/60000 (96.14%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1306,                   Accuracy: 57698/60000 (96.16%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1324,                   Accuracy: 57701/60000 (96.17%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1354,                   Accuracy: 57666/60000 (96.11%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1357,                   Accuracy: 57662/60000 (96.10%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1320,                   Accuracy: 57709/60000 (96.18%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1278,                   Accuracy: 57721/60000 (96.20%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1231,                   Accuracy: 57809/60000 (96.35%)
{0: tensor(96.3417), 10: tensor(96.1450), 20: tensor(96.1633), 30: tensor(96.1683), 40: tensor(96.1100), 50: tensor(96.1033), 60: tensor(96.1817), 70: tensor(96.2017), 80: tensor(96.3483), 90: tensor(96.3417), 100: tensor(96.1450), 110: tensor(96.1633), 120: tensor(96.1683), 130: tensor(96.1100), 140: tensor(96.1033), 150: tensor(96.1817), 160: tensor(96.2017), 170: tensor(96.3483), 180: tensor(96.3417), 190: tensor(96.1450), 200: tensor(96.1633), 210: tensor(96.1683), 220: tensor(96.1100), 230: tensor(96.1033), 240: tensor(96.1817), 250: tensor(96.2017), 260: tensor(96.3483), 270: tensor(96.3417), 280: tensor(96.1450), 290: tensor(96.1633), 300: tensor(96.1683), 310: tensor(96.1100), 320: tensor(96.1033), 330: tensor(96.1817), 340: tensor(96.2017), 350: tensor(96.3483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=41, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1224,                   Accuracy: 492/2000.0 (24.60%)



-= Testing valid =-
Test set: Average loss: 1.5357,                   Accuracy: 837/2000.0 (41.85%)



-= Testing valid =-
Test set: Average loss: 1.1769,                   Accuracy: 1211/2000.0 (60.55%)



-= Testing valid =-
Test set: Average loss: 1.0521,                   Accuracy: 1372/2000.0 (68.60%)



-= Testing valid =-
Test set: Average loss: 0.3334,                   Accuracy: 1780/2000.0 (89.00%)



-= Testing valid =-
Test set: Average loss: 0.2428,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.3027,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2563,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2630,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.1850,                   Accuracy: 1881/2000.0 (94.05%)



Epoch 10 train accuracy: 93.66%, valid accuracy 94.05%
-= Testing valid =-
Test set: Average loss: 0.1696,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1733,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1393,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1372,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1172,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1157,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1235,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1324,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1428,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1305,                   Accuracy: 1922/2000.0 (96.10%)



Epoch 20 train accuracy: 95.70%, valid accuracy 96.10%
-= Testing valid =-
Test set: Average loss: 0.1048,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1077,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1114,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1304,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1121,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1224,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1187,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 30 train accuracy: 96.49%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1020,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1048,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1003,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1146,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 40 train accuracy: 96.81%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1012,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 50 train accuracy: 97.29%, valid accuracy 97.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1167,                   Accuracy: 57983/60000 (96.64%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1432,                   Accuracy: 57518/60000 (95.86%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1433,                   Accuracy: 57549/60000 (95.92%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1440,                   Accuracy: 57600/60000 (96.00%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1434,                   Accuracy: 57575/60000 (95.96%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1419,                   Accuracy: 57552/60000 (95.92%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1374,                   Accuracy: 57591/60000 (95.99%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1362,                   Accuracy: 57550/60000 (95.92%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1363,                   Accuracy: 57521/60000 (95.87%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1250,                   Accuracy: 57808/60000 (96.35%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1532,                   Accuracy: 57310/60000 (95.52%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1542,                   Accuracy: 57263/60000 (95.44%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1542,                   Accuracy: 57328/60000 (95.55%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1555,                   Accuracy: 57347/60000 (95.58%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1566,                   Accuracy: 57245/60000 (95.41%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1531,                   Accuracy: 57264/60000 (95.44%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1491,                   Accuracy: 57279/60000 (95.46%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1508,                   Accuracy: 57216/60000 (95.36%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1329,                   Accuracy: 57583/60000 (95.97%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1585,                   Accuracy: 57152/60000 (95.25%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1541,                   Accuracy: 57207/60000 (95.35%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1517,                   Accuracy: 57360/60000 (95.60%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1508,                   Accuracy: 57407/60000 (95.68%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1494,                   Accuracy: 57382/60000 (95.64%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1435,                   Accuracy: 57442/60000 (95.74%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1390,                   Accuracy: 57466/60000 (95.78%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1391,                   Accuracy: 57478/60000 (95.80%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1214,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1457,                   Accuracy: 57419/60000 (95.70%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1413,                   Accuracy: 57518/60000 (95.86%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1412,                   Accuracy: 57613/60000 (96.02%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1391,                   Accuracy: 57641/60000 (96.07%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1360,                   Accuracy: 57664/60000 (96.11%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1298,                   Accuracy: 57744/60000 (96.24%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1285,                   Accuracy: 57717/60000 (96.19%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1288,                   Accuracy: 57708/60000 (96.18%)
{0: tensor(96.6383), 10: tensor(95.8633), 20: tensor(95.9150), 30: tensor(96.), 40: tensor(95.9583), 50: tensor(95.9200), 60: tensor(95.9850), 70: tensor(95.9167), 80: tensor(95.8683), 90: tensor(96.3467), 100: tensor(95.5167), 110: tensor(95.4383), 120: tensor(95.5467), 130: tensor(95.5783), 140: tensor(95.4083), 150: tensor(95.4400), 160: tensor(95.4650), 170: tensor(95.3600), 180: tensor(95.9717), 190: tensor(95.2533), 200: tensor(95.3450), 210: tensor(95.6000), 220: tensor(95.6783), 230: tensor(95.6367), 240: tensor(95.7367), 250: tensor(95.7767), 260: tensor(95.7967), 270: tensor(96.4300), 280: tensor(95.6983), 290: tensor(95.8633), 300: tensor(96.0217), 310: tensor(96.0683), 320: tensor(96.1067), 330: tensor(96.2400), 340: tensor(96.1950), 350: tensor(96.1800)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=42, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5328,                   Accuracy: 198/2000.0 (9.90%)



-= Testing valid =-
Test set: Average loss: 1.3178,                   Accuracy: 1073/2000.0 (53.65%)



-= Testing valid =-
Test set: Average loss: 0.7289,                   Accuracy: 1560/2000.0 (78.00%)



-= Testing valid =-
Test set: Average loss: 0.6536,                   Accuracy: 1612/2000.0 (80.60%)



-= Testing valid =-
Test set: Average loss: 0.3774,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.3783,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.2804,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.1672,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1974,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1719,                   Accuracy: 1894/2000.0 (94.70%)



Epoch 10 train accuracy: 93.78%, valid accuracy 94.70%
-= Testing valid =-
Test set: Average loss: 0.1425,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1636,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1439,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1017,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1716,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1250,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1400,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1920/2000.0 (96.00%)



Epoch 20 train accuracy: 95.54%, valid accuracy 96.00%
-= Testing valid =-
Test set: Average loss: 0.1133,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1101,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 30 train accuracy: 96.76%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 40 train accuracy: 97.04%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0720,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 50 train accuracy: 97.40%, valid accuracy 97.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1009,                   Accuracy: 58281/60000 (97.14%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1115,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1092,                   Accuracy: 58057/60000 (96.76%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1153,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1177,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1176,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1168,                   Accuracy: 57966/60000 (96.61%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1105,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1088,                   Accuracy: 58026/60000 (96.71%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1083,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1195,                   Accuracy: 57856/60000 (96.43%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1181,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1260,                   Accuracy: 57694/60000 (96.16%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1264,                   Accuracy: 57724/60000 (96.21%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1256,                   Accuracy: 57742/60000 (96.24%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1237,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1153,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1138,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1114,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1212,                   Accuracy: 57802/60000 (96.34%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1188,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1230,                   Accuracy: 57764/60000 (96.27%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1226,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1200,                   Accuracy: 57890/60000 (96.48%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1152,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1061,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1037,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1010,                   Accuracy: 58259/60000 (97.10%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1108,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1085,                   Accuracy: 58075/60000 (96.79%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1126,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1159,                   Accuracy: 57977/60000 (96.63%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1149,                   Accuracy: 58017/60000 (96.69%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1108,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1043,                   Accuracy: 58160/60000 (96.93%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1021,                   Accuracy: 58237/60000 (97.06%)
{0: tensor(97.1350), 10: tensor(96.7533), 20: tensor(96.7617), 30: tensor(96.5617), 40: tensor(96.6033), 50: tensor(96.5933), 60: tensor(96.6100), 70: tensor(96.7283), 80: tensor(96.7100), 90: tensor(96.8333), 100: tensor(96.4267), 110: tensor(96.4117), 120: tensor(96.1567), 130: tensor(96.2067), 140: tensor(96.2367), 150: tensor(96.2600), 160: tensor(96.5250), 170: tensor(96.4850), 180: tensor(96.6200), 190: tensor(96.3367), 200: tensor(96.4167), 210: tensor(96.2733), 220: tensor(96.3767), 230: tensor(96.4833), 240: tensor(96.6400), 250: tensor(96.8383), 260: tensor(96.9100), 270: tensor(97.0983), 280: tensor(96.7583), 290: tensor(96.7917), 300: tensor(96.6767), 310: tensor(96.6283), 320: tensor(96.6950), 330: tensor(96.8283), 340: tensor(96.9333), 350: tensor(97.0617)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=43, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.6449,                   Accuracy: 886/2000.0 (44.30%)



-= Testing valid =-
Test set: Average loss: 1.3411,                   Accuracy: 977/2000.0 (48.85%)



-= Testing valid =-
Test set: Average loss: 1.2330,                   Accuracy: 1163/2000.0 (58.15%)



-= Testing valid =-
Test set: Average loss: 1.0956,                   Accuracy: 1244/2000.0 (62.20%)



-= Testing valid =-
Test set: Average loss: 0.6975,                   Accuracy: 1565/2000.0 (78.25%)



-= Testing valid =-
Test set: Average loss: 0.6971,                   Accuracy: 1550/2000.0 (77.50%)



-= Testing valid =-
Test set: Average loss: 0.4453,                   Accuracy: 1680/2000.0 (84.00%)



-= Testing valid =-
Test set: Average loss: 0.2231,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2182,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.2713,                   Accuracy: 1810/2000.0 (90.50%)



Epoch 10 train accuracy: 92.80%, valid accuracy 90.50%
-= Testing valid =-
Test set: Average loss: 0.1640,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.2606,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.1515,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1782,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1567,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1332,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1617,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1491,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1429,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1064,                   Accuracy: 1934/2000.0 (96.70%)



Epoch 20 train accuracy: 95.20%, valid accuracy 96.70%
-= Testing valid =-
Test set: Average loss: 0.1237,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1069,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1316,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1162,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 30 train accuracy: 96.26%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 40 train accuracy: 96.64%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0910,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 50 train accuracy: 96.93%, valid accuracy 97.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1161,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1348,                   Accuracy: 57641/60000 (96.07%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1318,                   Accuracy: 57677/60000 (96.13%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1311,                   Accuracy: 57718/60000 (96.20%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1313,                   Accuracy: 57740/60000 (96.23%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1301,                   Accuracy: 57728/60000 (96.21%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1256,                   Accuracy: 57797/60000 (96.33%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1206,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1252,                   Accuracy: 57738/60000 (96.23%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1161,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1355,                   Accuracy: 57588/60000 (95.98%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1309,                   Accuracy: 57714/60000 (96.19%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1322,                   Accuracy: 57713/60000 (96.19%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1329,                   Accuracy: 57669/60000 (96.11%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1329,                   Accuracy: 57648/60000 (96.08%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1279,                   Accuracy: 57733/60000 (96.22%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1229,                   Accuracy: 57799/60000 (96.33%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1278,                   Accuracy: 57690/60000 (96.15%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1183,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1345,                   Accuracy: 57613/60000 (96.02%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1293,                   Accuracy: 57715/60000 (96.19%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1306,                   Accuracy: 57714/60000 (96.19%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1306,                   Accuracy: 57744/60000 (96.24%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1296,                   Accuracy: 57707/60000 (96.18%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1263,                   Accuracy: 57783/60000 (96.31%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1201,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1242,                   Accuracy: 57766/60000 (96.28%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1168,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1331,                   Accuracy: 57635/60000 (96.06%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1299,                   Accuracy: 57706/60000 (96.18%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1302,                   Accuracy: 57734/60000 (96.22%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1301,                   Accuracy: 57753/60000 (96.25%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1278,                   Accuracy: 57757/60000 (96.26%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1246,                   Accuracy: 57845/60000 (96.41%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1201,                   Accuracy: 57910/60000 (96.52%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1224,                   Accuracy: 57801/60000 (96.33%)
{0: tensor(96.6583), 10: tensor(96.0683), 20: tensor(96.1283), 30: tensor(96.1967), 40: tensor(96.2333), 50: tensor(96.2133), 60: tensor(96.3283), 70: tensor(96.4433), 80: tensor(96.2300), 90: tensor(96.6917), 100: tensor(95.9800), 110: tensor(96.1900), 120: tensor(96.1883), 130: tensor(96.1150), 140: tensor(96.0800), 150: tensor(96.2217), 160: tensor(96.3317), 170: tensor(96.1500), 180: tensor(96.5250), 190: tensor(96.0217), 200: tensor(96.1917), 210: tensor(96.1900), 220: tensor(96.2400), 230: tensor(96.1783), 240: tensor(96.3050), 250: tensor(96.4783), 260: tensor(96.2767), 270: tensor(96.5867), 280: tensor(96.0583), 290: tensor(96.1767), 300: tensor(96.2233), 310: tensor(96.2550), 320: tensor(96.2617), 330: tensor(96.4083), 340: tensor(96.5167), 350: tensor(96.3350)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=44, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2385,                   Accuracy: 378/2000.0 (18.90%)



-= Testing valid =-
Test set: Average loss: 1.6166,                   Accuracy: 835/2000.0 (41.75%)



-= Testing valid =-
Test set: Average loss: 1.0371,                   Accuracy: 1310/2000.0 (65.50%)



-= Testing valid =-
Test set: Average loss: 0.8404,                   Accuracy: 1406/2000.0 (70.30%)



-= Testing valid =-
Test set: Average loss: 0.4698,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.3514,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.2171,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.2267,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.2006,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1981,                   Accuracy: 1871/2000.0 (93.55%)



Epoch 10 train accuracy: 92.82%, valid accuracy 93.55%
-= Testing valid =-
Test set: Average loss: 0.1370,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1433,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1444,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1992,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.1217,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1287,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1175,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1143,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1305,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1086,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 20 train accuracy: 95.71%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 30 train accuracy: 96.80%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 40 train accuracy: 96.82%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0674,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 50 train accuracy: 97.06%, valid accuracy 97.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1017,                   Accuracy: 58203/60000 (97.00%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1098,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1067,                   Accuracy: 58152/60000 (96.92%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1107,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1129,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1162,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1155,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1116,                   Accuracy: 58022/60000 (96.70%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1120,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1031,                   Accuracy: 58142/60000 (96.90%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1095,                   Accuracy: 58035/60000 (96.72%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1054,                   Accuracy: 58144/60000 (96.91%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1088,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1132,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1193,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1197,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1155,                   Accuracy: 57940/60000 (96.57%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1143,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1071,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1104,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1068,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1107,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1140,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1195,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1196,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1137,                   Accuracy: 58002/60000 (96.67%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1103,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1044,                   Accuracy: 58163/60000 (96.94%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1097,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1077,                   Accuracy: 58127/60000 (96.88%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1126,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1137,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1164,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1169,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1114,                   Accuracy: 58033/60000 (96.72%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1088,                   Accuracy: 58088/60000 (96.81%)
{0: tensor(97.0050), 10: tensor(96.7833), 20: tensor(96.9200), 30: tensor(96.7667), 40: tensor(96.7383), 50: tensor(96.6033), 60: tensor(96.6150), 70: tensor(96.7033), 80: tensor(96.7050), 90: tensor(96.9033), 100: tensor(96.7250), 110: tensor(96.9067), 120: tensor(96.7833), 130: tensor(96.6767), 140: tensor(96.4600), 150: tensor(96.4400), 160: tensor(96.5667), 170: tensor(96.5717), 180: tensor(96.8017), 190: tensor(96.6417), 200: tensor(96.8167), 210: tensor(96.7167), 220: tensor(96.6733), 230: tensor(96.4717), 240: tensor(96.5367), 250: tensor(96.6700), 260: tensor(96.7333), 270: tensor(96.9383), 280: tensor(96.7300), 290: tensor(96.8783), 300: tensor(96.7000), 310: tensor(96.7083), 320: tensor(96.5950), 330: tensor(96.6767), 340: tensor(96.7217), 350: tensor(96.8133)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=45, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.7239,                   Accuracy: 221/2000.0 (11.05%)



-= Testing valid =-
Test set: Average loss: 1.9755,                   Accuracy: 544/2000.0 (27.20%)



-= Testing valid =-
Test set: Average loss: 1.4056,                   Accuracy: 973/2000.0 (48.65%)



-= Testing valid =-
Test set: Average loss: 1.6600,                   Accuracy: 932/2000.0 (46.60%)



-= Testing valid =-
Test set: Average loss: 0.4260,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.5854,                   Accuracy: 1652/2000.0 (82.60%)



-= Testing valid =-
Test set: Average loss: 0.2434,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2117,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2456,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.3042,                   Accuracy: 1800/2000.0 (90.00%)



Epoch 10 train accuracy: 93.04%, valid accuracy 90.00%
-= Testing valid =-
Test set: Average loss: 0.1504,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1167,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1329,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1511,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1303,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1149,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1042,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1119,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1216,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 20 train accuracy: 95.79%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.1010,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1092,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 30 train accuracy: 96.66%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0798,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0790,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 40 train accuracy: 96.90%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0720,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0742,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 50 train accuracy: 96.95%, valid accuracy 97.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0983,                   Accuracy: 58303/60000 (97.17%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1056,                   Accuracy: 58169/60000 (96.95%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1084,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1152,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1148,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1092,                   Accuracy: 58089/60000 (96.82%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1071,                   Accuracy: 58160/60000 (96.93%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0997,                   Accuracy: 58257/60000 (97.10%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1006,                   Accuracy: 58189/60000 (96.98%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1018,                   Accuracy: 58244/60000 (97.07%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1103,                   Accuracy: 58067/60000 (96.78%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1110,                   Accuracy: 58032/60000 (96.72%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1184,                   Accuracy: 57909/60000 (96.51%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1172,                   Accuracy: 57955/60000 (96.59%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1122,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1093,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1004,                   Accuracy: 58244/60000 (97.07%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1030,                   Accuracy: 58137/60000 (96.89%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1033,                   Accuracy: 58185/60000 (96.97%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1111,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1105,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1173,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1147,                   Accuracy: 57966/60000 (96.61%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1088,                   Accuracy: 58073/60000 (96.79%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1041,                   Accuracy: 58179/60000 (96.96%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.0959,                   Accuracy: 58322/60000 (97.20%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.0962,                   Accuracy: 58293/60000 (97.15%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0980,                   Accuracy: 58273/60000 (97.12%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1052,                   Accuracy: 58190/60000 (96.98%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1072,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1143,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1132,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1071,                   Accuracy: 58137/60000 (96.89%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1039,                   Accuracy: 58225/60000 (97.04%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0965,                   Accuracy: 58314/60000 (97.19%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0962,                   Accuracy: 58287/60000 (97.14%)
{0: tensor(97.1717), 10: tensor(96.9483), 20: tensor(96.8017), 30: tensor(96.6483), 40: tensor(96.7017), 50: tensor(96.8150), 60: tensor(96.9333), 70: tensor(97.0950), 80: tensor(96.9817), 90: tensor(97.0733), 100: tensor(96.7783), 110: tensor(96.7200), 120: tensor(96.5150), 130: tensor(96.5917), 140: tensor(96.6733), 150: tensor(96.7667), 160: tensor(97.0733), 170: tensor(96.8950), 180: tensor(96.9750), 190: tensor(96.7050), 200: tensor(96.7867), 210: tensor(96.5583), 220: tensor(96.6100), 230: tensor(96.7883), 240: tensor(96.9650), 250: tensor(97.2033), 260: tensor(97.1550), 270: tensor(97.1217), 280: tensor(96.9833), 290: tensor(96.8800), 300: tensor(96.6767), 310: tensor(96.7550), 320: tensor(96.8950), 330: tensor(97.0417), 340: tensor(97.1900), 350: tensor(97.1450)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=46, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.8291,                   Accuracy: 361/2000.0 (18.05%)



-= Testing valid =-
Test set: Average loss: 2.0518,                   Accuracy: 503/2000.0 (25.15%)



-= Testing valid =-
Test set: Average loss: 2.7036,                   Accuracy: 480/2000.0 (24.00%)



-= Testing valid =-
Test set: Average loss: 1.2241,                   Accuracy: 1174/2000.0 (58.70%)



-= Testing valid =-
Test set: Average loss: 0.7467,                   Accuracy: 1557/2000.0 (77.85%)



-= Testing valid =-
Test set: Average loss: 0.2894,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.2053,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.2075,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.3690,                   Accuracy: 1765/2000.0 (88.25%)



-= Testing valid =-
Test set: Average loss: 0.5781,                   Accuracy: 1629/2000.0 (81.45%)



Epoch 10 train accuracy: 93.70%, valid accuracy 81.45%
-= Testing valid =-
Test set: Average loss: 0.1134,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1585,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1258,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1225,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1402,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0882,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 20 train accuracy: 95.89%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0798,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0752,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 30 train accuracy: 96.78%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0658,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0657,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 40 train accuracy: 96.86%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0637,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0637,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0623,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0647,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0629,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0620,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0712,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 50 train accuracy: 97.43%, valid accuracy 97.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0965,                   Accuracy: 58256/60000 (97.09%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1116,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1031,                   Accuracy: 58091/60000 (96.82%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1010,                   Accuracy: 58177/60000 (96.96%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1051,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1073,                   Accuracy: 58087/60000 (96.81%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1078,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1070,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1111,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0975,                   Accuracy: 58232/60000 (97.05%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1128,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1027,                   Accuracy: 58087/60000 (96.81%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1021,                   Accuracy: 58132/60000 (96.89%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1043,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1059,                   Accuracy: 58096/60000 (96.83%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1084,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1051,                   Accuracy: 58116/60000 (96.86%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1101,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0963,                   Accuracy: 58248/60000 (97.08%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1073,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1026,                   Accuracy: 58152/60000 (96.92%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1052,                   Accuracy: 58076/60000 (96.79%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1038,                   Accuracy: 58115/60000 (96.86%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1049,                   Accuracy: 58122/60000 (96.87%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1071,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1042,                   Accuracy: 58133/60000 (96.89%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1085,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0953,                   Accuracy: 58307/60000 (97.18%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1061,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1021,                   Accuracy: 58117/60000 (96.86%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1026,                   Accuracy: 58113/60000 (96.86%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1041,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1065,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1075,                   Accuracy: 58064/60000 (96.77%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1065,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1103,                   Accuracy: 58030/60000 (96.72%)
{0: tensor(97.0933), 10: tensor(96.6167), 20: tensor(96.8183), 30: tensor(96.9617), 40: tensor(96.8083), 50: tensor(96.8117), 60: tensor(96.7700), 70: tensor(96.8133), 80: tensor(96.6833), 90: tensor(97.0533), 100: tensor(96.5600), 110: tensor(96.8117), 120: tensor(96.8867), 130: tensor(96.8750), 140: tensor(96.8267), 150: tensor(96.7350), 160: tensor(96.8600), 170: tensor(96.6917), 180: tensor(97.0800), 190: tensor(96.7433), 200: tensor(96.9200), 210: tensor(96.7933), 220: tensor(96.8583), 230: tensor(96.8700), 240: tensor(96.8083), 250: tensor(96.8883), 260: tensor(96.7850), 270: tensor(97.1783), 280: tensor(96.7700), 290: tensor(96.8617), 300: tensor(96.8550), 310: tensor(96.8750), 320: tensor(96.8683), 330: tensor(96.7733), 340: tensor(96.8217), 350: tensor(96.7167)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=47, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9938,                   Accuracy: 569/2000.0 (28.45%)



-= Testing valid =-
Test set: Average loss: 1.7121,                   Accuracy: 712/2000.0 (35.60%)



-= Testing valid =-
Test set: Average loss: 1.1557,                   Accuracy: 1201/2000.0 (60.05%)



-= Testing valid =-
Test set: Average loss: 0.6525,                   Accuracy: 1607/2000.0 (80.35%)



-= Testing valid =-
Test set: Average loss: 0.4538,                   Accuracy: 1705/2000.0 (85.25%)



-= Testing valid =-
Test set: Average loss: 0.4678,                   Accuracy: 1721/2000.0 (86.05%)



-= Testing valid =-
Test set: Average loss: 0.1852,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1809,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.2978,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2260,                   Accuracy: 1867/2000.0 (93.35%)



Epoch 10 train accuracy: 93.60%, valid accuracy 93.35%
-= Testing valid =-
Test set: Average loss: 0.1774,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1267,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1606,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1716,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1708,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1382,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1461,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1783,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1759,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1294,                   Accuracy: 1930/2000.0 (96.50%)



Epoch 20 train accuracy: 96.30%, valid accuracy 96.50%
-= Testing valid =-
Test set: Average loss: 0.1198,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1171,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1440,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1057,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1420,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1127,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1275,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1358,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1342,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1160,                   Accuracy: 1928/2000.0 (96.40%)



Epoch 30 train accuracy: 96.82%, valid accuracy 96.40%
-= Testing valid =-
Test set: Average loss: 0.1120,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1112,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1122,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1150,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1148,                   Accuracy: 1930/2000.0 (96.50%)



Epoch 40 train accuracy: 97.09%, valid accuracy 96.50%
-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1086,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1089,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 50 train accuracy: 97.28%, valid accuracy 97.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1092,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1216,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1167,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1146,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1110,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1084,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1045,                   Accuracy: 58156/60000 (96.93%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1013,                   Accuracy: 58205/60000 (97.01%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1104,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1089,                   Accuracy: 58057/60000 (96.76%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1214,                   Accuracy: 57853/60000 (96.42%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1187,                   Accuracy: 57909/60000 (96.51%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1214,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1152,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1129,                   Accuracy: 58032/60000 (96.72%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1112,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1045,                   Accuracy: 58160/60000 (96.93%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1126,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1127,                   Accuracy: 58012/60000 (96.69%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1232,                   Accuracy: 57836/60000 (96.39%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1193,                   Accuracy: 57870/60000 (96.45%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1214,                   Accuracy: 57856/60000 (96.43%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1129,                   Accuracy: 58012/60000 (96.69%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1119,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1091,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1048,                   Accuracy: 58154/60000 (96.92%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1136,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1120,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1237,                   Accuracy: 57837/60000 (96.39%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1183,                   Accuracy: 57926/60000 (96.54%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1153,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1099,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1083,                   Accuracy: 58110/60000 (96.85%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1038,                   Accuracy: 58208/60000 (97.01%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1025,                   Accuracy: 58232/60000 (97.05%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1114,                   Accuracy: 58018/60000 (96.70%)
{0: tensor(96.8450), 10: tensor(96.4400), 20: tensor(96.5533), 30: tensor(96.7300), 40: tensor(96.7800), 50: tensor(96.8717), 60: tensor(96.9267), 70: tensor(97.0083), 80: tensor(96.6933), 90: tensor(96.7617), 100: tensor(96.4217), 110: tensor(96.5150), 120: tensor(96.4483), 130: tensor(96.6167), 140: tensor(96.7200), 150: tensor(96.6933), 160: tensor(96.9333), 170: tensor(96.5833), 180: tensor(96.6867), 190: tensor(96.3933), 200: tensor(96.4500), 210: tensor(96.4267), 220: tensor(96.6867), 230: tensor(96.7667), 240: tensor(96.8333), 250: tensor(96.9233), 260: tensor(96.6200), 270: tensor(96.7383), 280: tensor(96.3950), 290: tensor(96.5433), 300: tensor(96.7083), 310: tensor(96.7967), 320: tensor(96.8500), 330: tensor(97.0133), 340: tensor(97.0533), 350: tensor(96.6967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=48, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.8513,                   Accuracy: 166/2000.0 (8.30%)



-= Testing valid =-
Test set: Average loss: 1.4547,                   Accuracy: 870/2000.0 (43.50%)



-= Testing valid =-
Test set: Average loss: 2.2426,                   Accuracy: 537/2000.0 (26.85%)



-= Testing valid =-
Test set: Average loss: 1.0553,                   Accuracy: 1366/2000.0 (68.30%)



-= Testing valid =-
Test set: Average loss: 0.8957,                   Accuracy: 1455/2000.0 (72.75%)



-= Testing valid =-
Test set: Average loss: 0.2857,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2746,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.7265,                   Accuracy: 1579/2000.0 (78.95%)



-= Testing valid =-
Test set: Average loss: 0.2545,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.1600,                   Accuracy: 1890/2000.0 (94.50%)



Epoch 10 train accuracy: 92.31%, valid accuracy 94.50%
-= Testing valid =-
Test set: Average loss: 0.1456,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1474,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.2591,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.1516,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1263,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1329,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1099,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 20 train accuracy: 95.32%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1011,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.0964,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 30 train accuracy: 96.22%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0711,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0678,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 40 train accuracy: 96.35%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0657,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0600,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0637,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 50 train accuracy: 96.80%, valid accuracy 97.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1127,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1191,                   Accuracy: 57910/60000 (96.52%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1190,                   Accuracy: 57881/60000 (96.47%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1251,                   Accuracy: 57794/60000 (96.32%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1291,                   Accuracy: 57739/60000 (96.23%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1286,                   Accuracy: 57780/60000 (96.30%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1271,                   Accuracy: 57785/60000 (96.31%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1240,                   Accuracy: 57813/60000 (96.36%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1253,                   Accuracy: 57807/60000 (96.35%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1209,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1271,                   Accuracy: 57718/60000 (96.20%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1287,                   Accuracy: 57667/60000 (96.11%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1362,                   Accuracy: 57550/60000 (95.92%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1415,                   Accuracy: 57467/60000 (95.78%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1414,                   Accuracy: 57449/60000 (95.75%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1385,                   Accuracy: 57528/60000 (95.88%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1353,                   Accuracy: 57536/60000 (95.89%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1350,                   Accuracy: 57545/60000 (95.91%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1275,                   Accuracy: 57738/60000 (96.23%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1320,                   Accuracy: 57635/60000 (96.06%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1290,                   Accuracy: 57654/60000 (96.09%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1332,                   Accuracy: 57582/60000 (95.97%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1352,                   Accuracy: 57544/60000 (95.91%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1317,                   Accuracy: 57640/60000 (96.07%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1263,                   Accuracy: 57773/60000 (96.29%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1218,                   Accuracy: 57822/60000 (96.37%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1194,                   Accuracy: 57914/60000 (96.52%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1158,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1205,                   Accuracy: 57852/60000 (96.42%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1183,                   Accuracy: 57912/60000 (96.52%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1224,                   Accuracy: 57863/60000 (96.44%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1242,                   Accuracy: 57837/60000 (96.39%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1219,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1192,                   Accuracy: 57944/60000 (96.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1149,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1151,                   Accuracy: 58003/60000 (96.67%)
{0: tensor(96.7517), 10: tensor(96.5167), 20: tensor(96.4683), 30: tensor(96.3233), 40: tensor(96.2317), 50: tensor(96.3000), 60: tensor(96.3083), 70: tensor(96.3550), 80: tensor(96.3450), 90: tensor(96.4983), 100: tensor(96.1967), 110: tensor(96.1117), 120: tensor(95.9167), 130: tensor(95.7783), 140: tensor(95.7483), 150: tensor(95.8800), 160: tensor(95.8933), 170: tensor(95.9083), 180: tensor(96.2300), 190: tensor(96.0583), 200: tensor(96.0900), 210: tensor(95.9700), 220: tensor(95.9067), 230: tensor(96.0667), 240: tensor(96.2883), 250: tensor(96.3700), 260: tensor(96.5233), 270: tensor(96.6117), 280: tensor(96.4200), 290: tensor(96.5200), 300: tensor(96.4383), 310: tensor(96.3950), 320: tensor(96.4917), 330: tensor(96.5733), 340: tensor(96.6683), 350: tensor(96.6717)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=49, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3642,                   Accuracy: 450/2000.0 (22.50%)



-= Testing valid =-
Test set: Average loss: 2.6359,                   Accuracy: 432/2000.0 (21.60%)



-= Testing valid =-
Test set: Average loss: 1.5353,                   Accuracy: 1058/2000.0 (52.90%)



-= Testing valid =-
Test set: Average loss: 0.4941,                   Accuracy: 1707/2000.0 (85.35%)



-= Testing valid =-
Test set: Average loss: 0.9161,                   Accuracy: 1395/2000.0 (69.75%)



-= Testing valid =-
Test set: Average loss: 0.2709,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.3874,                   Accuracy: 1755/2000.0 (87.75%)



-= Testing valid =-
Test set: Average loss: 0.2680,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.1416,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1572,                   Accuracy: 1890/2000.0 (94.50%)



Epoch 10 train accuracy: 93.25%, valid accuracy 94.50%
-= Testing valid =-
Test set: Average loss: 0.1176,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1467,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1083,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1593,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1108,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1221,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1122,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.2162,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1923/2000.0 (96.15%)



Epoch 20 train accuracy: 95.49%, valid accuracy 96.15%
-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0687,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 30 train accuracy: 96.61%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0647,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0636,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0734,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0646,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0607,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 40 train accuracy: 96.95%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0620,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0602,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0590,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0650,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0585,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 50 train accuracy: 96.90%, valid accuracy 98.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1022,                   Accuracy: 58168/60000 (96.95%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1116,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1109,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1127,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1192,                   Accuracy: 57812/60000 (96.35%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1246,                   Accuracy: 57803/60000 (96.34%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1228,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1188,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1149,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0985,                   Accuracy: 58253/60000 (97.09%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1061,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1037,                   Accuracy: 58144/60000 (96.91%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1072,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1144,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1201,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1223,                   Accuracy: 57822/60000 (96.37%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1165,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1148,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0985,                   Accuracy: 58216/60000 (97.03%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1097,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1024,                   Accuracy: 58161/60000 (96.93%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1073,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1137,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1196,                   Accuracy: 57867/60000 (96.44%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1225,                   Accuracy: 57802/60000 (96.34%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1182,                   Accuracy: 57882/60000 (96.47%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1167,                   Accuracy: 57865/60000 (96.44%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1014,                   Accuracy: 58147/60000 (96.91%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1164,                   Accuracy: 57825/60000 (96.38%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1090,                   Accuracy: 57982/60000 (96.64%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1125,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1193,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1245,                   Accuracy: 57768/60000 (96.28%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1235,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1214,                   Accuracy: 57848/60000 (96.41%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1180,                   Accuracy: 57854/60000 (96.42%)
{0: tensor(96.9467), 10: tensor(96.5867), 20: tensor(96.6333), 30: tensor(96.5850), 40: tensor(96.3533), 50: tensor(96.3383), 60: tensor(96.3600), 70: tensor(96.5583), 80: tensor(96.5950), 90: tensor(97.0883), 100: tensor(96.8167), 110: tensor(96.9067), 120: tensor(96.7550), 130: tensor(96.5717), 140: tensor(96.4300), 150: tensor(96.3700), 160: tensor(96.6200), 170: tensor(96.5533), 180: tensor(97.0267), 190: tensor(96.6600), 200: tensor(96.9350), 210: tensor(96.6883), 220: tensor(96.5717), 230: tensor(96.4450), 240: tensor(96.3367), 250: tensor(96.4700), 260: tensor(96.4417), 270: tensor(96.9117), 280: tensor(96.3750), 290: tensor(96.6367), 300: tensor(96.5350), 310: tensor(96.3567), 320: tensor(96.2800), 330: tensor(96.3567), 340: tensor(96.4133), 350: tensor(96.4233)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=50, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8161,                   Accuracy: 775/2000.0 (38.75%)



-= Testing valid =-
Test set: Average loss: 4.2679,                   Accuracy: 211/2000.0 (10.55%)



-= Testing valid =-
Test set: Average loss: 0.9385,                   Accuracy: 1390/2000.0 (69.50%)



-= Testing valid =-
Test set: Average loss: 1.0714,                   Accuracy: 1353/2000.0 (67.65%)



-= Testing valid =-
Test set: Average loss: 0.5332,                   Accuracy: 1651/2000.0 (82.55%)



-= Testing valid =-
Test set: Average loss: 0.6182,                   Accuracy: 1637/2000.0 (81.85%)



-= Testing valid =-
Test set: Average loss: 0.2958,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2998,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.2573,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2230,                   Accuracy: 1852/2000.0 (92.60%)



Epoch 10 train accuracy: 92.57%, valid accuracy 92.60%
-= Testing valid =-
Test set: Average loss: 0.2011,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.1576,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1531,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.2052,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.1792,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.2107,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.1439,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1432,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1332,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1307,                   Accuracy: 1915/2000.0 (95.75%)



Epoch 20 train accuracy: 95.82%, valid accuracy 95.75%
-= Testing valid =-
Test set: Average loss: 0.1142,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1034,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1034,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1072,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1104,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1003,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 30 train accuracy: 96.12%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 40 train accuracy: 96.78%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 50 train accuracy: 96.99%, valid accuracy 97.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1062,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1165,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1123,                   Accuracy: 57978/60000 (96.63%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1132,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1138,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1163,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1159,                   Accuracy: 57977/60000 (96.63%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1117,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1161,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1065,                   Accuracy: 58118/60000 (96.86%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1161,                   Accuracy: 57909/60000 (96.51%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1126,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1163,                   Accuracy: 57863/60000 (96.44%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1153,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1175,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1189,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1128,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1151,                   Accuracy: 57924/60000 (96.54%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1074,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1167,                   Accuracy: 57854/60000 (96.42%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1135,                   Accuracy: 57901/60000 (96.50%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1169,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1149,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1168,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1178,                   Accuracy: 57888/60000 (96.48%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1129,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1124,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1064,                   Accuracy: 58122/60000 (96.87%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1158,                   Accuracy: 57912/60000 (96.52%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1123,                   Accuracy: 57931/60000 (96.55%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1127,                   Accuracy: 57965/60000 (96.61%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1136,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1161,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1155,                   Accuracy: 57983/60000 (96.64%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1125,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1144,                   Accuracy: 57942/60000 (96.57%)
{0: tensor(96.8667), 10: tensor(96.5750), 20: tensor(96.6300), 30: tensor(96.6183), 40: tensor(96.6517), 50: tensor(96.6400), 60: tensor(96.6283), 70: tensor(96.6917), 80: tensor(96.4467), 90: tensor(96.8633), 100: tensor(96.5150), 110: tensor(96.5700), 120: tensor(96.4383), 130: tensor(96.5350), 140: tensor(96.5383), 150: tensor(96.4300), 160: tensor(96.6450), 170: tensor(96.5400), 180: tensor(96.8283), 190: tensor(96.4233), 200: tensor(96.5017), 210: tensor(96.3833), 220: tensor(96.5533), 230: tensor(96.5350), 240: tensor(96.4800), 250: tensor(96.6767), 260: tensor(96.6417), 270: tensor(96.8700), 280: tensor(96.5200), 290: tensor(96.5517), 300: tensor(96.6083), 310: tensor(96.6450), 320: tensor(96.6133), 330: tensor(96.6383), 340: tensor(96.6900), 350: tensor(96.5700)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=51, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.9719,                   Accuracy: 256/2000.0 (12.80%)



-= Testing valid =-
Test set: Average loss: 2.6509,                   Accuracy: 431/2000.0 (21.55%)



-= Testing valid =-
Test set: Average loss: 0.7641,                   Accuracy: 1563/2000.0 (78.15%)



-= Testing valid =-
Test set: Average loss: 0.7609,                   Accuracy: 1524/2000.0 (76.20%)



-= Testing valid =-
Test set: Average loss: 0.2432,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.4866,                   Accuracy: 1706/2000.0 (85.30%)



-= Testing valid =-
Test set: Average loss: 0.2116,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1985,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.2011,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.2069,                   Accuracy: 1879/2000.0 (93.95%)



Epoch 10 train accuracy: 93.15%, valid accuracy 93.95%
-= Testing valid =-
Test set: Average loss: 0.1124,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1481,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1194,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1514,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1220,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1175,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 20 train accuracy: 95.74%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1030,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1066,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 30 train accuracy: 96.60%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.1020,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 40 train accuracy: 96.94%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 50 train accuracy: 97.20%, valid accuracy 97.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1105,                   Accuracy: 58106/60000 (96.84%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1184,                   Accuracy: 57975/60000 (96.62%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1132,                   Accuracy: 58019/60000 (96.70%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1131,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1133,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1136,                   Accuracy: 58012/60000 (96.69%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1155,                   Accuracy: 58022/60000 (96.70%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1126,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1209,                   Accuracy: 57844/60000 (96.41%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1187,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1310,                   Accuracy: 57707/60000 (96.18%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1238,                   Accuracy: 57805/60000 (96.34%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1184,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1201,                   Accuracy: 57897/60000 (96.50%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1223,                   Accuracy: 57827/60000 (96.38%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1240,                   Accuracy: 57770/60000 (96.28%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1250,                   Accuracy: 57734/60000 (96.22%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1338,                   Accuracy: 57486/60000 (95.81%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1265,                   Accuracy: 57752/60000 (96.25%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1369,                   Accuracy: 57516/60000 (95.86%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1254,                   Accuracy: 57714/60000 (96.19%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1204,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1174,                   Accuracy: 57939/60000 (96.57%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1180,                   Accuracy: 57873/60000 (96.46%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1197,                   Accuracy: 57854/60000 (96.42%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1157,                   Accuracy: 57918/60000 (96.53%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1201,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1159,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1207,                   Accuracy: 57909/60000 (96.51%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1129,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1139,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1110,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1106,                   Accuracy: 58075/60000 (96.79%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1127,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1075,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1116,                   Accuracy: 58035/60000 (96.72%)
{0: tensor(96.8433), 10: tensor(96.6250), 20: tensor(96.6983), 30: tensor(96.7800), 40: tensor(96.7317), 50: tensor(96.6867), 60: tensor(96.7033), 70: tensor(96.6750), 80: tensor(96.4067), 90: tensor(96.5350), 100: tensor(96.1783), 110: tensor(96.3417), 120: tensor(96.5750), 130: tensor(96.4950), 140: tensor(96.3783), 150: tensor(96.2833), 160: tensor(96.2233), 170: tensor(95.8100), 180: tensor(96.2533), 190: tensor(95.8600), 200: tensor(96.1900), 210: tensor(96.4183), 220: tensor(96.5650), 230: tensor(96.4550), 240: tensor(96.4233), 250: tensor(96.5300), 260: tensor(96.3567), 270: tensor(96.5933), 280: tensor(96.5150), 290: tensor(96.6683), 300: tensor(96.7400), 310: tensor(96.8017), 320: tensor(96.7917), 330: tensor(96.7600), 340: tensor(96.8767), 350: tensor(96.7250)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=52, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0220,                   Accuracy: 423/2000.0 (21.15%)



-= Testing valid =-
Test set: Average loss: 1.4140,                   Accuracy: 1065/2000.0 (53.25%)



-= Testing valid =-
Test set: Average loss: 0.9012,                   Accuracy: 1381/2000.0 (69.05%)



-= Testing valid =-
Test set: Average loss: 0.7731,                   Accuracy: 1410/2000.0 (70.50%)



-= Testing valid =-
Test set: Average loss: 0.4236,                   Accuracy: 1736/2000.0 (86.80%)



-= Testing valid =-
Test set: Average loss: 0.3443,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.2343,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.3451,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.1929,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2439,                   Accuracy: 1854/2000.0 (92.70%)



Epoch 10 train accuracy: 93.64%, valid accuracy 92.70%
-= Testing valid =-
Test set: Average loss: 0.1742,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1368,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1741,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1539,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1868,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1407,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1115,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1683,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1525,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.2244,                   Accuracy: 1865/2000.0 (93.25%)



Epoch 20 train accuracy: 95.64%, valid accuracy 93.25%
-= Testing valid =-
Test set: Average loss: 0.1071,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1323,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1238,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1244,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1413,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1130,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1260,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 30 train accuracy: 96.57%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1356,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1104,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1100,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1080,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0978,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 40 train accuracy: 96.72%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0926,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1053,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 50 train accuracy: 97.43%, valid accuracy 97.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1062,                   Accuracy: 58173/60000 (96.96%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1117,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1096,                   Accuracy: 58076/60000 (96.79%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1185,                   Accuracy: 57946/60000 (96.58%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1178,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1172,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1132,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1031,                   Accuracy: 58207/60000 (97.01%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1061,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1109,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1179,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1163,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1245,                   Accuracy: 57796/60000 (96.33%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1267,                   Accuracy: 57795/60000 (96.32%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1271,                   Accuracy: 57754/60000 (96.26%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1251,                   Accuracy: 57811/60000 (96.35%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1130,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1183,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1175,                   Accuracy: 57914/60000 (96.52%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1248,                   Accuracy: 57733/60000 (96.22%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1194,                   Accuracy: 57842/60000 (96.40%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1237,                   Accuracy: 57862/60000 (96.44%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1238,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1220,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1173,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1055,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1094,                   Accuracy: 58042/60000 (96.74%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1098,                   Accuracy: 58077/60000 (96.79%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1157,                   Accuracy: 57930/60000 (96.55%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1110,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1183,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1151,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1131,                   Accuracy: 58066/60000 (96.78%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1088,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0989,                   Accuracy: 58272/60000 (97.12%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1015,                   Accuracy: 58229/60000 (97.05%)
{0: tensor(96.9550), 10: tensor(96.7467), 20: tensor(96.7933), 30: tensor(96.5767), 40: tensor(96.6183), 50: tensor(96.6483), 60: tensor(96.7833), 70: tensor(97.0117), 80: tensor(96.8767), 90: tensor(96.7717), 100: tensor(96.5117), 110: tensor(96.5383), 120: tensor(96.3267), 130: tensor(96.3250), 140: tensor(96.2567), 150: tensor(96.3517), 160: tensor(96.6217), 170: tensor(96.4533), 180: tensor(96.5233), 190: tensor(96.2217), 200: tensor(96.4033), 210: tensor(96.4367), 220: tensor(96.4350), 230: tensor(96.4167), 240: tensor(96.5683), 250: tensor(96.8450), 260: tensor(96.7367), 270: tensor(96.7950), 280: tensor(96.5500), 290: tensor(96.7333), 300: tensor(96.6483), 310: tensor(96.6933), 320: tensor(96.7767), 330: tensor(96.8917), 340: tensor(97.1200), 350: tensor(97.0483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=53, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1747,                   Accuracy: 441/2000.0 (22.05%)



-= Testing valid =-
Test set: Average loss: 1.6159,                   Accuracy: 836/2000.0 (41.80%)



-= Testing valid =-
Test set: Average loss: 1.9425,                   Accuracy: 839/2000.0 (41.95%)



-= Testing valid =-
Test set: Average loss: 0.6130,                   Accuracy: 1527/2000.0 (76.35%)



-= Testing valid =-
Test set: Average loss: 0.3536,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.4664,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.2653,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2301,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.3747,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.2016,                   Accuracy: 1878/2000.0 (93.90%)



Epoch 10 train accuracy: 94.11%, valid accuracy 93.90%
-= Testing valid =-
Test set: Average loss: 0.1975,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1552,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1566,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1799,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1743,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1529,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.2545,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.1810,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.2654,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.1243,                   Accuracy: 1930/2000.0 (96.50%)



Epoch 20 train accuracy: 95.82%, valid accuracy 96.50%
-= Testing valid =-
Test set: Average loss: 0.1152,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1190,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1129,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1216,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1251,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1171,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1217,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1102,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1231,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1141,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 30 train accuracy: 96.93%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 40 train accuracy: 97.06%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1033,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1015,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 50 train accuracy: 97.50%, valid accuracy 97.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1092,                   Accuracy: 58149/60000 (96.92%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1124,                   Accuracy: 58096/60000 (96.83%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1132,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1210,                   Accuracy: 57896/60000 (96.49%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1202,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1199,                   Accuracy: 57897/60000 (96.50%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1214,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1169,                   Accuracy: 57977/60000 (96.63%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1178,                   Accuracy: 57977/60000 (96.63%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1152,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1185,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1185,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1281,                   Accuracy: 57789/60000 (96.32%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1257,                   Accuracy: 57811/60000 (96.35%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1251,                   Accuracy: 57803/60000 (96.34%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1257,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1196,                   Accuracy: 57902/60000 (96.50%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1225,                   Accuracy: 57881/60000 (96.47%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1183,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1218,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1177,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1271,                   Accuracy: 57776/60000 (96.29%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1248,                   Accuracy: 57848/60000 (96.41%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1236,                   Accuracy: 57810/60000 (96.35%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1222,                   Accuracy: 57890/60000 (96.48%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1154,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1135,                   Accuracy: 58084/60000 (96.81%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1110,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1137,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1118,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1193,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1195,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1186,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1182,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1128,                   Accuracy: 58077/60000 (96.79%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1104,                   Accuracy: 58148/60000 (96.91%)
{0: tensor(96.9150), 10: tensor(96.8267), 20: tensor(96.7167), 30: tensor(96.4933), 40: tensor(96.5717), 50: tensor(96.4950), 60: tensor(96.5367), 70: tensor(96.6283), 80: tensor(96.6283), 90: tensor(96.6667), 100: tensor(96.5700), 110: tensor(96.5550), 120: tensor(96.3150), 130: tensor(96.3517), 140: tensor(96.3383), 150: tensor(96.3650), 160: tensor(96.5033), 170: tensor(96.4683), 180: tensor(96.5950), 190: tensor(96.4467), 200: tensor(96.5317), 210: tensor(96.2933), 220: tensor(96.4133), 230: tensor(96.3500), 240: tensor(96.4833), 250: tensor(96.6417), 260: tensor(96.8067), 270: tensor(96.8467), 280: tensor(96.7467), 290: tensor(96.7633), 300: tensor(96.5683), 310: tensor(96.5717), 320: tensor(96.5600), 330: tensor(96.6633), 340: tensor(96.7950), 350: tensor(96.9133)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=54, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0057,                   Accuracy: 548/2000.0 (27.40%)



-= Testing valid =-
Test set: Average loss: 2.7992,                   Accuracy: 319/2000.0 (15.95%)



-= Testing valid =-
Test set: Average loss: 0.9530,                   Accuracy: 1332/2000.0 (66.60%)



-= Testing valid =-
Test set: Average loss: 2.0258,                   Accuracy: 732/2000.0 (36.60%)



-= Testing valid =-
Test set: Average loss: 0.8406,                   Accuracy: 1419/2000.0 (70.95%)



-= Testing valid =-
Test set: Average loss: 0.3488,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.2815,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2609,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.1949,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.1954,                   Accuracy: 1882/2000.0 (94.10%)



Epoch 10 train accuracy: 92.79%, valid accuracy 94.10%
-= Testing valid =-
Test set: Average loss: 0.1471,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1645,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1567,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1417,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1449,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1432,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1279,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1340,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1441,                   Accuracy: 1910/2000.0 (95.50%)



Epoch 20 train accuracy: 94.80%, valid accuracy 95.50%
-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1100,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1123,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 30 train accuracy: 96.65%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 40 train accuracy: 96.96%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 50 train accuracy: 97.39%, valid accuracy 97.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1097,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1235,                   Accuracy: 57857/60000 (96.43%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1222,                   Accuracy: 57916/60000 (96.53%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1265,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1271,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1261,                   Accuracy: 57825/60000 (96.38%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1205,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1156,                   Accuracy: 58042/60000 (96.74%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1183,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1152,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1320,                   Accuracy: 57660/60000 (96.10%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1290,                   Accuracy: 57747/60000 (96.25%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1347,                   Accuracy: 57644/60000 (96.07%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1359,                   Accuracy: 57619/60000 (96.03%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1369,                   Accuracy: 57599/60000 (96.00%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1303,                   Accuracy: 57719/60000 (96.20%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1230,                   Accuracy: 57825/60000 (96.38%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1285,                   Accuracy: 57630/60000 (96.05%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1216,                   Accuracy: 57833/60000 (96.39%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1366,                   Accuracy: 57537/60000 (95.89%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1300,                   Accuracy: 57686/60000 (96.14%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1342,                   Accuracy: 57660/60000 (96.10%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1346,                   Accuracy: 57661/60000 (96.10%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1349,                   Accuracy: 57646/60000 (96.08%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1273,                   Accuracy: 57801/60000 (96.33%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1169,                   Accuracy: 57975/60000 (96.62%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1189,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1128,                   Accuracy: 58057/60000 (96.76%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1256,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1217,                   Accuracy: 57910/60000 (96.52%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1262,                   Accuracy: 57873/60000 (96.46%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1266,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1260,                   Accuracy: 57839/60000 (96.40%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1190,                   Accuracy: 57994/60000 (96.66%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1115,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1115,                   Accuracy: 58030/60000 (96.72%)
{0: tensor(96.8767), 10: tensor(96.4283), 20: tensor(96.5267), 30: tensor(96.4533), 40: tensor(96.3600), 50: tensor(96.3750), 60: tensor(96.5933), 70: tensor(96.7367), 80: tensor(96.4400), 90: tensor(96.6883), 100: tensor(96.1000), 110: tensor(96.2450), 120: tensor(96.0733), 130: tensor(96.0317), 140: tensor(95.9983), 150: tensor(96.1983), 160: tensor(96.3750), 170: tensor(96.0500), 180: tensor(96.3883), 190: tensor(95.8950), 200: tensor(96.1433), 210: tensor(96.1000), 220: tensor(96.1017), 230: tensor(96.0767), 240: tensor(96.3350), 250: tensor(96.6250), 260: tensor(96.4633), 270: tensor(96.7617), 280: tensor(96.3567), 290: tensor(96.5167), 300: tensor(96.4550), 310: tensor(96.4117), 320: tensor(96.3983), 330: tensor(96.6567), 340: tensor(96.8767), 350: tensor(96.7167)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=55, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8596,                   Accuracy: 547/2000.0 (27.35%)



-= Testing valid =-
Test set: Average loss: 1.8228,                   Accuracy: 697/2000.0 (34.85%)



-= Testing valid =-
Test set: Average loss: 0.8125,                   Accuracy: 1454/2000.0 (72.70%)



-= Testing valid =-
Test set: Average loss: 0.3929,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.3403,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.5290,                   Accuracy: 1645/2000.0 (82.25%)



-= Testing valid =-
Test set: Average loss: 0.3237,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.2690,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.1821,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1324,                   Accuracy: 1918/2000.0 (95.90%)



Epoch 10 train accuracy: 93.29%, valid accuracy 95.90%
-= Testing valid =-
Test set: Average loss: 0.1488,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1261,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1293,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1296,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1604,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1511,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1410,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1080,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 20 train accuracy: 95.70%, valid accuracy 96.45%
-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 30 train accuracy: 96.39%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0807,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 40 train accuracy: 96.90%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0662,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0664,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0683,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 50 train accuracy: 96.64%, valid accuracy 97.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0996,                   Accuracy: 58256/60000 (97.09%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1072,                   Accuracy: 58087/60000 (96.81%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1000,                   Accuracy: 58218/60000 (97.03%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1015,                   Accuracy: 58207/60000 (97.01%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1037,                   Accuracy: 58164/60000 (96.94%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1048,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1103,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1101,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1146,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1086,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1188,                   Accuracy: 57844/60000 (96.41%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1090,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1098,                   Accuracy: 58012/60000 (96.69%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1122,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1144,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1187,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1203,                   Accuracy: 57778/60000 (96.30%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1307,                   Accuracy: 57548/60000 (95.91%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1163,                   Accuracy: 57880/60000 (96.47%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1248,                   Accuracy: 57693/60000 (96.15%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1107,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1063,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1084,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1078,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1106,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1114,                   Accuracy: 58019/60000 (96.70%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1148,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1034,                   Accuracy: 58177/60000 (96.96%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1096,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1002,                   Accuracy: 58219/60000 (97.03%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.0991,                   Accuracy: 58241/60000 (97.07%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1009,                   Accuracy: 58236/60000 (97.06%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1014,                   Accuracy: 58205/60000 (97.01%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1055,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1049,                   Accuracy: 58161/60000 (96.93%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1052,                   Accuracy: 58152/60000 (96.92%)
{0: tensor(97.0933), 10: tensor(96.8117), 20: tensor(97.0300), 30: tensor(97.0117), 40: tensor(96.9400), 50: tensor(96.8917), 60: tensor(96.6817), 70: tensor(96.7400), 80: tensor(96.5783), 90: tensor(96.7400), 100: tensor(96.4067), 110: tensor(96.7317), 120: tensor(96.6867), 130: tensor(96.6017), 140: tensor(96.5367), 150: tensor(96.4100), 160: tensor(96.2967), 170: tensor(95.9133), 180: tensor(96.4667), 190: tensor(96.1550), 200: tensor(96.6583), 210: tensor(96.8367), 220: tensor(96.7600), 230: tensor(96.7700), 240: tensor(96.7167), 250: tensor(96.6983), 260: tensor(96.5633), 270: tensor(96.9617), 280: tensor(96.7267), 290: tensor(97.0317), 300: tensor(97.0683), 310: tensor(97.0600), 320: tensor(97.0083), 330: tensor(96.9217), 340: tensor(96.9350), 350: tensor(96.9200)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=56, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2116,                   Accuracy: 453/2000.0 (22.65%)



-= Testing valid =-
Test set: Average loss: 0.9132,                   Accuracy: 1380/2000.0 (69.00%)



-= Testing valid =-
Test set: Average loss: 0.5454,                   Accuracy: 1716/2000.0 (85.80%)



-= Testing valid =-
Test set: Average loss: 0.5110,                   Accuracy: 1704/2000.0 (85.20%)



-= Testing valid =-
Test set: Average loss: 0.3839,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.1965,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.3366,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.1810,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1725,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1606,                   Accuracy: 1896/2000.0 (94.80%)



Epoch 10 train accuracy: 93.60%, valid accuracy 94.80%
-= Testing valid =-
Test set: Average loss: 0.1323,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1182,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1496,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1150,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1375,                   Accuracy: 1920/2000.0 (96.00%)



Epoch 20 train accuracy: 95.88%, valid accuracy 96.00%
-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0734,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 30 train accuracy: 96.69%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0738,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0825,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 40 train accuracy: 96.70%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0742,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0684,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0646,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0645,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0641,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0701,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 50 train accuracy: 97.36%, valid accuracy 97.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1006,                   Accuracy: 58174/60000 (96.96%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1114,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1096,                   Accuracy: 57993/60000 (96.65%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1093,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1053,                   Accuracy: 58080/60000 (96.80%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1065,                   Accuracy: 58127/60000 (96.88%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1052,                   Accuracy: 58151/60000 (96.92%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1015,                   Accuracy: 58209/60000 (97.01%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1051,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1005,                   Accuracy: 58181/60000 (96.97%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1103,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1073,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1065,                   Accuracy: 58096/60000 (96.83%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1055,                   Accuracy: 58104/60000 (96.84%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1078,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1066,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1057,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1099,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1025,                   Accuracy: 58136/60000 (96.89%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1113,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1063,                   Accuracy: 58076/60000 (96.79%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1044,                   Accuracy: 58110/60000 (96.85%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1029,                   Accuracy: 58155/60000 (96.93%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1052,                   Accuracy: 58162/60000 (96.94%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1042,                   Accuracy: 58162/60000 (96.94%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1044,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1063,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1006,                   Accuracy: 58166/60000 (96.94%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1107,                   Accuracy: 57978/60000 (96.63%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1080,                   Accuracy: 58032/60000 (96.72%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1069,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1038,                   Accuracy: 58139/60000 (96.90%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1049,                   Accuracy: 58140/60000 (96.90%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1041,                   Accuracy: 58158/60000 (96.93%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1014,                   Accuracy: 58173/60000 (96.96%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1038,                   Accuracy: 58134/60000 (96.89%)
{0: tensor(96.9567), 10: tensor(96.6267), 20: tensor(96.6550), 30: tensor(96.7000), 40: tensor(96.8000), 50: tensor(96.8783), 60: tensor(96.9183), 70: tensor(97.0150), 80: tensor(96.8167), 90: tensor(96.9683), 100: tensor(96.6817), 110: tensor(96.7500), 120: tensor(96.8267), 130: tensor(96.8400), 140: tensor(96.8083), 150: tensor(96.8467), 160: tensor(96.8683), 170: tensor(96.6633), 180: tensor(96.8933), 190: tensor(96.5933), 200: tensor(96.7933), 210: tensor(96.8500), 220: tensor(96.9250), 230: tensor(96.9367), 240: tensor(96.9367), 250: tensor(96.8683), 260: tensor(96.8333), 270: tensor(96.9433), 280: tensor(96.6300), 290: tensor(96.7200), 300: tensor(96.7533), 310: tensor(96.8983), 320: tensor(96.9000), 330: tensor(96.9300), 340: tensor(96.9550), 350: tensor(96.8900)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=57, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.5288,                   Accuracy: 260/2000.0 (13.00%)



-= Testing valid =-
Test set: Average loss: 1.2488,                   Accuracy: 1133/2000.0 (56.65%)



-= Testing valid =-
Test set: Average loss: 0.6138,                   Accuracy: 1652/2000.0 (82.60%)



-= Testing valid =-
Test set: Average loss: 0.4667,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.3143,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.3169,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.3171,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.4331,                   Accuracy: 1739/2000.0 (86.95%)



-= Testing valid =-
Test set: Average loss: 0.2676,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.1892,                   Accuracy: 1881/2000.0 (94.05%)



Epoch 10 train accuracy: 93.54%, valid accuracy 94.05%
-= Testing valid =-
Test set: Average loss: 0.1661,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1614,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1452,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1279,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1348,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1662,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1273,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1876,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.1707,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1388,                   Accuracy: 1908/2000.0 (95.40%)



Epoch 20 train accuracy: 95.76%, valid accuracy 95.40%
-= Testing valid =-
Test set: Average loss: 0.1086,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1240,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1020,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1092,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1187,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 30 train accuracy: 96.47%, valid accuracy 96.45%
-= Testing valid =-
Test set: Average loss: 0.1147,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 40 train accuracy: 96.91%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0825,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 50 train accuracy: 97.21%, valid accuracy 97.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1064,                   Accuracy: 58178/60000 (96.96%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1133,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1109,                   Accuracy: 58042/60000 (96.74%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1097,                   Accuracy: 58115/60000 (96.86%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1163,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1219,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1224,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1241,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1185,                   Accuracy: 57909/60000 (96.51%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1100,                   Accuracy: 58104/60000 (96.84%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1187,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1132,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1132,                   Accuracy: 57997/60000 (96.66%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1201,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1262,                   Accuracy: 57802/60000 (96.34%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1299,                   Accuracy: 57725/60000 (96.21%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1301,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1252,                   Accuracy: 57765/60000 (96.28%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1159,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1209,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1144,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1154,                   Accuracy: 57954/60000 (96.59%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1182,                   Accuracy: 57918/60000 (96.53%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1235,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1273,                   Accuracy: 57794/60000 (96.32%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1248,                   Accuracy: 57813/60000 (96.36%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1197,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1112,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1148,                   Accuracy: 58026/60000 (96.71%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1108,                   Accuracy: 58057/60000 (96.76%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1104,                   Accuracy: 58098/60000 (96.83%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1142,                   Accuracy: 58066/60000 (96.78%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1189,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1198,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1195,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1144,                   Accuracy: 57996/60000 (96.66%)
{0: tensor(96.9633), 10: tensor(96.7400), 20: tensor(96.7367), 30: tensor(96.8583), 40: tensor(96.6800), 50: tensor(96.4850), 60: tensor(96.5183), 70: tensor(96.4300), 80: tensor(96.5150), 90: tensor(96.8400), 100: tensor(96.5317), 110: tensor(96.6400), 120: tensor(96.6617), 130: tensor(96.4983), 140: tensor(96.3367), 150: tensor(96.2083), 160: tensor(96.1417), 170: tensor(96.2750), 180: tensor(96.5950), 190: tensor(96.4483), 200: tensor(96.6000), 210: tensor(96.5900), 220: tensor(96.5300), 230: tensor(96.4483), 240: tensor(96.3233), 250: tensor(96.3550), 260: tensor(96.4717), 270: tensor(96.8100), 280: tensor(96.7100), 290: tensor(96.7617), 300: tensor(96.8300), 310: tensor(96.7767), 320: tensor(96.6033), 330: tensor(96.5283), 340: tensor(96.5450), 350: tensor(96.6600)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=58, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.2636,                   Accuracy: 253/2000.0 (12.65%)



-= Testing valid =-
Test set: Average loss: 1.6317,                   Accuracy: 724/2000.0 (36.20%)



-= Testing valid =-
Test set: Average loss: 1.2840,                   Accuracy: 982/2000.0 (49.10%)



-= Testing valid =-
Test set: Average loss: 0.6584,                   Accuracy: 1534/2000.0 (76.70%)



-= Testing valid =-
Test set: Average loss: 0.4660,                   Accuracy: 1672/2000.0 (83.60%)



-= Testing valid =-
Test set: Average loss: 0.3617,                   Accuracy: 1760/2000.0 (88.00%)



-= Testing valid =-
Test set: Average loss: 0.5464,                   Accuracy: 1676/2000.0 (83.80%)



-= Testing valid =-
Test set: Average loss: 0.2306,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.1784,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.2393,                   Accuracy: 1855/2000.0 (92.75%)



Epoch 10 train accuracy: 93.51%, valid accuracy 92.75%
-= Testing valid =-
Test set: Average loss: 0.1586,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1566,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1336,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1633,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1559,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1181,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1435,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1282,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1446,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1164,                   Accuracy: 1928/2000.0 (96.40%)



Epoch 20 train accuracy: 95.69%, valid accuracy 96.40%
-= Testing valid =-
Test set: Average loss: 0.1327,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1037,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 30 train accuracy: 96.25%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0882,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 40 train accuracy: 96.88%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 50 train accuracy: 97.34%, valid accuracy 97.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1101,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1256,                   Accuracy: 57712/60000 (96.19%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1162,                   Accuracy: 57853/60000 (96.42%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1169,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1186,                   Accuracy: 57896/60000 (96.49%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1235,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1229,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1183,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1189,                   Accuracy: 57840/60000 (96.40%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1142,                   Accuracy: 57954/60000 (96.59%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1294,                   Accuracy: 57620/60000 (96.03%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1196,                   Accuracy: 57808/60000 (96.35%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1204,                   Accuracy: 57827/60000 (96.38%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1219,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1275,                   Accuracy: 57748/60000 (96.25%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1254,                   Accuracy: 57715/60000 (96.19%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1212,                   Accuracy: 57821/60000 (96.37%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1290,                   Accuracy: 57640/60000 (96.07%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1178,                   Accuracy: 57880/60000 (96.47%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1277,                   Accuracy: 57621/60000 (96.04%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1205,                   Accuracy: 57762/60000 (96.27%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1201,                   Accuracy: 57807/60000 (96.35%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1196,                   Accuracy: 57874/60000 (96.46%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1236,                   Accuracy: 57803/60000 (96.34%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1176,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1152,                   Accuracy: 57914/60000 (96.52%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1242,                   Accuracy: 57702/60000 (96.17%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1120,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1230,                   Accuracy: 57729/60000 (96.21%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1175,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1165,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1166,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1213,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1174,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1147,                   Accuracy: 57940/60000 (96.57%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1160,                   Accuracy: 57916/60000 (96.53%)
{0: tensor(96.7667), 10: tensor(96.1867), 20: tensor(96.4217), 30: tensor(96.5550), 40: tensor(96.4933), 50: tensor(96.3817), 60: tensor(96.3600), 70: tensor(96.4717), 80: tensor(96.4000), 90: tensor(96.5900), 100: tensor(96.0333), 110: tensor(96.3467), 120: tensor(96.3783), 130: tensor(96.3567), 140: tensor(96.2467), 150: tensor(96.1917), 160: tensor(96.3683), 170: tensor(96.0667), 180: tensor(96.4667), 190: tensor(96.0350), 200: tensor(96.2700), 210: tensor(96.3450), 220: tensor(96.4567), 230: tensor(96.3383), 240: tensor(96.4533), 250: tensor(96.5233), 260: tensor(96.1700), 270: tensor(96.7117), 280: tensor(96.2150), 290: tensor(96.4633), 300: tensor(96.5067), 310: tensor(96.5583), 320: tensor(96.4783), 330: tensor(96.5750), 340: tensor(96.5667), 350: tensor(96.5267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=59, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.1046,                   Accuracy: 236/2000.0 (11.80%)



-= Testing valid =-
Test set: Average loss: 1.8014,                   Accuracy: 620/2000.0 (31.00%)



-= Testing valid =-
Test set: Average loss: 1.4340,                   Accuracy: 1048/2000.0 (52.40%)



-= Testing valid =-
Test set: Average loss: 1.5205,                   Accuracy: 896/2000.0 (44.80%)



-= Testing valid =-
Test set: Average loss: 0.3477,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.5922,                   Accuracy: 1637/2000.0 (81.85%)



-= Testing valid =-
Test set: Average loss: 0.4135,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 0.2615,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2307,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.1818,                   Accuracy: 1889/2000.0 (94.45%)



Epoch 10 train accuracy: 92.99%, valid accuracy 94.45%
-= Testing valid =-
Test set: Average loss: 0.1588,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1854,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.2602,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.1761,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1274,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1558,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1917,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1337,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1687,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1521,                   Accuracy: 1914/2000.0 (95.70%)



Epoch 20 train accuracy: 95.84%, valid accuracy 95.70%
-= Testing valid =-
Test set: Average loss: 0.1250,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1219,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1265,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1112,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1115,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1315,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1110,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 30 train accuracy: 96.57%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0937,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1080,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1145,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 40 train accuracy: 96.75%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.1071,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1017,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1091,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 50 train accuracy: 97.28%, valid accuracy 97.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1096,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1193,                   Accuracy: 57860/60000 (96.43%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1217,                   Accuracy: 57807/60000 (96.35%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1313,                   Accuracy: 57655/60000 (96.09%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1336,                   Accuracy: 57562/60000 (95.94%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1322,                   Accuracy: 57626/60000 (96.04%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1274,                   Accuracy: 57755/60000 (96.26%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1176,                   Accuracy: 57924/60000 (96.54%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1152,                   Accuracy: 57939/60000 (96.57%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1138,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1245,                   Accuracy: 57723/60000 (96.21%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1256,                   Accuracy: 57699/60000 (96.17%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1369,                   Accuracy: 57506/60000 (95.84%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1394,                   Accuracy: 57432/60000 (95.72%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1387,                   Accuracy: 57449/60000 (95.75%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1359,                   Accuracy: 57567/60000 (95.94%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1217,                   Accuracy: 57808/60000 (96.35%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1227,                   Accuracy: 57753/60000 (96.25%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1181,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1252,                   Accuracy: 57705/60000 (96.18%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1246,                   Accuracy: 57723/60000 (96.21%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1327,                   Accuracy: 57618/60000 (96.03%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1326,                   Accuracy: 57590/60000 (95.98%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1319,                   Accuracy: 57617/60000 (96.03%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1280,                   Accuracy: 57729/60000 (96.21%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1146,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1148,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1112,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1186,                   Accuracy: 57865/60000 (96.44%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1200,                   Accuracy: 57837/60000 (96.39%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1285,                   Accuracy: 57712/60000 (96.19%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1287,                   Accuracy: 57679/60000 (96.13%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1269,                   Accuracy: 57752/60000 (96.25%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1226,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1132,                   Accuracy: 58049/60000 (96.75%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1095,                   Accuracy: 58083/60000 (96.81%)
{0: tensor(96.8133), 10: tensor(96.4333), 20: tensor(96.3450), 30: tensor(96.0917), 40: tensor(95.9367), 50: tensor(96.0433), 60: tensor(96.2583), 70: tensor(96.5400), 80: tensor(96.5650), 90: tensor(96.6200), 100: tensor(96.2050), 110: tensor(96.1650), 120: tensor(95.8433), 130: tensor(95.7200), 140: tensor(95.7483), 150: tensor(95.9450), 160: tensor(96.3467), 170: tensor(96.2550), 180: tensor(96.4183), 190: tensor(96.1750), 200: tensor(96.2050), 210: tensor(96.0300), 220: tensor(95.9833), 230: tensor(96.0283), 240: tensor(96.2150), 250: tensor(96.6483), 260: tensor(96.6333), 270: tensor(96.7333), 280: tensor(96.4417), 290: tensor(96.3950), 300: tensor(96.1867), 310: tensor(96.1317), 320: tensor(96.2533), 330: tensor(96.4583), 340: tensor(96.7483), 350: tensor(96.8050)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=60, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1228,                   Accuracy: 514/2000.0 (25.70%)



-= Testing valid =-
Test set: Average loss: 1.1652,                   Accuracy: 1250/2000.0 (62.50%)



-= Testing valid =-
Test set: Average loss: 0.7351,                   Accuracy: 1573/2000.0 (78.65%)



-= Testing valid =-
Test set: Average loss: 0.5497,                   Accuracy: 1637/2000.0 (81.85%)



-= Testing valid =-
Test set: Average loss: 0.2305,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.2944,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.1678,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.2053,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.1519,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1617,                   Accuracy: 1902/2000.0 (95.10%)



Epoch 10 train accuracy: 93.70%, valid accuracy 95.10%
-= Testing valid =-
Test set: Average loss: 0.1298,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1191,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1082,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1691,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1034,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1173,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0981,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1152,                   Accuracy: 1928/2000.0 (96.40%)



Epoch 20 train accuracy: 95.75%, valid accuracy 96.40%
-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1210,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 30 train accuracy: 96.74%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0715,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0677,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 40 train accuracy: 96.78%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0756,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 50 train accuracy: 97.20%, valid accuracy 97.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0869,                   Accuracy: 58433/60000 (97.39%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0987,                   Accuracy: 58216/60000 (97.03%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0963,                   Accuracy: 58240/60000 (97.07%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1006,                   Accuracy: 58218/60000 (97.03%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1055,                   Accuracy: 58124/60000 (96.87%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1069,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1027,                   Accuracy: 58167/60000 (96.94%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0996,                   Accuracy: 58161/60000 (96.93%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.0989,                   Accuracy: 58188/60000 (96.98%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0892,                   Accuracy: 58363/60000 (97.27%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1002,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.0976,                   Accuracy: 58169/60000 (96.95%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1019,                   Accuracy: 58134/60000 (96.89%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1094,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1120,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1094,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1062,                   Accuracy: 58002/60000 (96.67%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1070,                   Accuracy: 57983/60000 (96.64%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0942,                   Accuracy: 58242/60000 (97.07%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1077,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1005,                   Accuracy: 58106/60000 (96.84%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1021,                   Accuracy: 58131/60000 (96.89%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1081,                   Accuracy: 58069/60000 (96.78%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1098,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1053,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1018,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1005,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0896,                   Accuracy: 58352/60000 (97.25%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1032,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0980,                   Accuracy: 58183/60000 (96.97%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1007,                   Accuracy: 58184/60000 (96.97%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1047,                   Accuracy: 58151/60000 (96.92%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1054,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0994,                   Accuracy: 58227/60000 (97.04%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0973,                   Accuracy: 58203/60000 (97.00%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0951,                   Accuracy: 58243/60000 (97.07%)
{0: tensor(97.3883), 10: tensor(97.0267), 20: tensor(97.0667), 30: tensor(97.0300), 40: tensor(96.8733), 50: tensor(96.8100), 60: tensor(96.9450), 70: tensor(96.9350), 80: tensor(96.9800), 90: tensor(97.2717), 100: tensor(96.9100), 110: tensor(96.9483), 120: tensor(96.8900), 130: tensor(96.6917), 140: tensor(96.5883), 150: tensor(96.6417), 160: tensor(96.6700), 170: tensor(96.6383), 180: tensor(97.0700), 190: tensor(96.6333), 200: tensor(96.8433), 210: tensor(96.8850), 220: tensor(96.7817), 230: tensor(96.6800), 240: tensor(96.7850), 250: tensor(96.8333), 260: tensor(96.9217), 270: tensor(97.2533), 280: tensor(96.8767), 290: tensor(96.9717), 300: tensor(96.9733), 310: tensor(96.9183), 320: tensor(96.8800), 330: tensor(97.0450), 340: tensor(97.0050), 350: tensor(97.0717)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=61, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1439,                   Accuracy: 388/2000.0 (19.40%)



-= Testing valid =-
Test set: Average loss: 1.4966,                   Accuracy: 858/2000.0 (42.90%)



-= Testing valid =-
Test set: Average loss: 2.8872,                   Accuracy: 456/2000.0 (22.80%)



-= Testing valid =-
Test set: Average loss: 0.8372,                   Accuracy: 1467/2000.0 (73.35%)



-= Testing valid =-
Test set: Average loss: 0.4727,                   Accuracy: 1731/2000.0 (86.55%)



-= Testing valid =-
Test set: Average loss: 0.3118,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3168,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.1936,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.3929,                   Accuracy: 1752/2000.0 (87.60%)



-= Testing valid =-
Test set: Average loss: 0.2663,                   Accuracy: 1826/2000.0 (91.30%)



Epoch 10 train accuracy: 92.68%, valid accuracy 91.30%
-= Testing valid =-
Test set: Average loss: 0.1618,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1860,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1637,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1655,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1739,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1239,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1240,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1418,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1273,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1476,                   Accuracy: 1916/2000.0 (95.80%)



Epoch 20 train accuracy: 95.05%, valid accuracy 95.80%
-= Testing valid =-
Test set: Average loss: 0.1021,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1185,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1304,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1250,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1111,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1171,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1209,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1121,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 30 train accuracy: 96.16%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1071,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1151,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1148,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0926,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 40 train accuracy: 96.50%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 50 train accuracy: 96.94%, valid accuracy 97.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1107,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1223,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1180,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1242,                   Accuracy: 57871/60000 (96.45%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1202,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1176,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1170,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1099,                   Accuracy: 58083/60000 (96.81%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1181,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1176,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1296,                   Accuracy: 57684/60000 (96.14%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1247,                   Accuracy: 57785/60000 (96.31%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1305,                   Accuracy: 57698/60000 (96.16%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1263,                   Accuracy: 57809/60000 (96.35%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1243,                   Accuracy: 57810/60000 (96.35%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1236,                   Accuracy: 57855/60000 (96.43%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1168,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1277,                   Accuracy: 57629/60000 (96.05%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1224,                   Accuracy: 57810/60000 (96.35%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1349,                   Accuracy: 57538/60000 (95.90%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1275,                   Accuracy: 57706/60000 (96.18%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1306,                   Accuracy: 57696/60000 (96.16%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1238,                   Accuracy: 57865/60000 (96.44%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1218,                   Accuracy: 57871/60000 (96.45%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1181,                   Accuracy: 57959/60000 (96.60%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1110,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1184,                   Accuracy: 57853/60000 (96.42%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1129,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1249,                   Accuracy: 57795/60000 (96.32%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1191,                   Accuracy: 57926/60000 (96.54%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1240,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1186,                   Accuracy: 57982/60000 (96.64%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1164,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1134,                   Accuracy: 58077/60000 (96.79%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1060,                   Accuracy: 58187/60000 (96.98%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1118,                   Accuracy: 58061/60000 (96.77%)
{0: tensor(96.8567), 10: tensor(96.4533), 20: tensor(96.6200), 30: tensor(96.4517), 40: tensor(96.6267), 50: tensor(96.6417), 60: tensor(96.7300), 70: tensor(96.8050), 80: tensor(96.4850), 90: tensor(96.5550), 100: tensor(96.1400), 110: tensor(96.3083), 120: tensor(96.1633), 130: tensor(96.3483), 140: tensor(96.3500), 150: tensor(96.4250), 160: tensor(96.5250), 170: tensor(96.0483), 180: tensor(96.3500), 190: tensor(95.8967), 200: tensor(96.1767), 210: tensor(96.1600), 220: tensor(96.4417), 230: tensor(96.4517), 240: tensor(96.5983), 250: tensor(96.7333), 260: tensor(96.4217), 270: tensor(96.6917), 280: tensor(96.3250), 290: tensor(96.5433), 300: tensor(96.4767), 310: tensor(96.6367), 320: tensor(96.7167), 330: tensor(96.7950), 340: tensor(96.9783), 350: tensor(96.7683)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=62, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6812,                   Accuracy: 212/2000.0 (10.60%)



-= Testing valid =-
Test set: Average loss: 1.4583,                   Accuracy: 996/2000.0 (49.80%)



-= Testing valid =-
Test set: Average loss: 1.3445,                   Accuracy: 1059/2000.0 (52.95%)



-= Testing valid =-
Test set: Average loss: 1.3451,                   Accuracy: 1085/2000.0 (54.25%)



-= Testing valid =-
Test set: Average loss: 0.3989,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.5690,                   Accuracy: 1647/2000.0 (82.35%)



-= Testing valid =-
Test set: Average loss: 0.2560,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.5780,                   Accuracy: 1618/2000.0 (80.90%)



-= Testing valid =-
Test set: Average loss: 0.3781,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.2231,                   Accuracy: 1869/2000.0 (93.45%)



Epoch 10 train accuracy: 92.78%, valid accuracy 93.45%
-= Testing valid =-
Test set: Average loss: 0.2010,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.1789,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2225,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1547,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1352,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1816,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1166,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1364,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1664,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1643,                   Accuracy: 1896/2000.0 (94.80%)



Epoch 20 train accuracy: 95.44%, valid accuracy 94.80%
-= Testing valid =-
Test set: Average loss: 0.1395,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1221,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1197,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1395,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1192,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1085,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1127,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1036,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1157,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1126,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 30 train accuracy: 96.35%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.1128,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1052,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1058,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1240,                   Accuracy: 1921/2000.0 (96.05%)



Epoch 40 train accuracy: 96.85%, valid accuracy 96.05%
-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1058,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1011,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 50 train accuracy: 97.01%, valid accuracy 97.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1081,                   Accuracy: 58141/60000 (96.90%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1239,                   Accuracy: 57810/60000 (96.35%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1200,                   Accuracy: 57810/60000 (96.35%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1242,                   Accuracy: 57755/60000 (96.26%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1328,                   Accuracy: 57635/60000 (96.06%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1395,                   Accuracy: 57549/60000 (95.92%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1388,                   Accuracy: 57556/60000 (95.93%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1336,                   Accuracy: 57629/60000 (96.05%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1288,                   Accuracy: 57728/60000 (96.21%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1088,                   Accuracy: 58079/60000 (96.80%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1251,                   Accuracy: 57766/60000 (96.28%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1222,                   Accuracy: 57748/60000 (96.25%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1270,                   Accuracy: 57655/60000 (96.09%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1355,                   Accuracy: 57586/60000 (95.98%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1447,                   Accuracy: 57430/60000 (95.72%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1441,                   Accuracy: 57419/60000 (95.70%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1384,                   Accuracy: 57500/60000 (95.83%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1337,                   Accuracy: 57576/60000 (95.96%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1093,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1280,                   Accuracy: 57675/60000 (96.12%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1191,                   Accuracy: 57813/60000 (96.36%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1235,                   Accuracy: 57742/60000 (96.24%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1299,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1388,                   Accuracy: 57547/60000 (95.91%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1375,                   Accuracy: 57559/60000 (95.93%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1338,                   Accuracy: 57653/60000 (96.09%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1263,                   Accuracy: 57760/60000 (96.27%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1069,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1250,                   Accuracy: 57744/60000 (96.24%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1165,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1200,                   Accuracy: 57837/60000 (96.39%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1282,                   Accuracy: 57743/60000 (96.24%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1343,                   Accuracy: 57670/60000 (96.12%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1332,                   Accuracy: 57662/60000 (96.10%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1309,                   Accuracy: 57718/60000 (96.20%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1245,                   Accuracy: 57810/60000 (96.35%)
{0: tensor(96.9017), 10: tensor(96.3500), 20: tensor(96.3500), 30: tensor(96.2583), 40: tensor(96.0583), 50: tensor(95.9150), 60: tensor(95.9267), 70: tensor(96.0483), 80: tensor(96.2133), 90: tensor(96.7983), 100: tensor(96.2767), 110: tensor(96.2467), 120: tensor(96.0917), 130: tensor(95.9767), 140: tensor(95.7167), 150: tensor(95.6983), 160: tensor(95.8333), 170: tensor(95.9600), 180: tensor(96.7467), 190: tensor(96.1250), 200: tensor(96.3550), 210: tensor(96.2367), 220: tensor(96.1417), 230: tensor(95.9117), 240: tensor(95.9317), 250: tensor(96.0883), 260: tensor(96.2667), 270: tensor(96.8533), 280: tensor(96.2400), 290: tensor(96.4750), 300: tensor(96.3950), 310: tensor(96.2383), 320: tensor(96.1167), 330: tensor(96.1033), 340: tensor(96.1967), 350: tensor(96.3500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=63, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9494,                   Accuracy: 577/2000.0 (28.85%)



-= Testing valid =-
Test set: Average loss: 2.3054,                   Accuracy: 361/2000.0 (18.05%)



-= Testing valid =-
Test set: Average loss: 1.7402,                   Accuracy: 782/2000.0 (39.10%)



-= Testing valid =-
Test set: Average loss: 0.9032,                   Accuracy: 1434/2000.0 (71.70%)



-= Testing valid =-
Test set: Average loss: 0.8195,                   Accuracy: 1458/2000.0 (72.90%)



-= Testing valid =-
Test set: Average loss: 0.3342,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.4504,                   Accuracy: 1711/2000.0 (85.55%)



-= Testing valid =-
Test set: Average loss: 0.2331,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.3050,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.2450,                   Accuracy: 1850/2000.0 (92.50%)



Epoch 10 train accuracy: 93.61%, valid accuracy 92.50%
-= Testing valid =-
Test set: Average loss: 0.1688,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.2051,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.1354,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1783,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1712,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1583,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1377,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1256,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1551,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1414,                   Accuracy: 1914/2000.0 (95.70%)



Epoch 20 train accuracy: 95.51%, valid accuracy 95.70%
-= Testing valid =-
Test set: Average loss: 0.1185,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1275,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1218,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1150,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1033,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1033,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 30 train accuracy: 96.71%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0976,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0978,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 40 train accuracy: 97.34%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 50 train accuracy: 97.25%, valid accuracy 97.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1149,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1199,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1257,                   Accuracy: 57728/60000 (96.21%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1326,                   Accuracy: 57605/60000 (96.01%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1319,                   Accuracy: 57653/60000 (96.09%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1325,                   Accuracy: 57613/60000 (96.02%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1293,                   Accuracy: 57715/60000 (96.19%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1199,                   Accuracy: 57905/60000 (96.51%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1175,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1101,                   Accuracy: 58067/60000 (96.78%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1135,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1162,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1231,                   Accuracy: 57810/60000 (96.35%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1239,                   Accuracy: 57817/60000 (96.36%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1256,                   Accuracy: 57803/60000 (96.34%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1237,                   Accuracy: 57849/60000 (96.42%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1152,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1119,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1078,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1125,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1128,                   Accuracy: 57979/60000 (96.63%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1202,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1223,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1251,                   Accuracy: 57822/60000 (96.37%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1247,                   Accuracy: 57813/60000 (96.36%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1170,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1138,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1118,                   Accuracy: 58042/60000 (96.74%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1189,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1203,                   Accuracy: 57820/60000 (96.37%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1297,                   Accuracy: 57662/60000 (96.10%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1298,                   Accuracy: 57672/60000 (96.12%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1317,                   Accuracy: 57679/60000 (96.13%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1306,                   Accuracy: 57732/60000 (96.22%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1237,                   Accuracy: 57820/60000 (96.37%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1200,                   Accuracy: 57906/60000 (96.51%)
{0: tensor(96.6117), 10: tensor(96.4017), 20: tensor(96.2133), 30: tensor(96.0083), 40: tensor(96.0883), 50: tensor(96.0217), 60: tensor(96.1917), 70: tensor(96.5083), 80: tensor(96.6017), 90: tensor(96.7783), 100: tensor(96.6667), 110: tensor(96.5133), 120: tensor(96.3500), 130: tensor(96.3617), 140: tensor(96.3383), 150: tensor(96.4150), 160: tensor(96.6917), 170: tensor(96.7667), 180: tensor(96.8483), 190: tensor(96.6633), 200: tensor(96.6317), 210: tensor(96.4100), 220: tensor(96.4167), 230: tensor(96.3700), 240: tensor(96.3550), 250: tensor(96.6583), 260: tensor(96.7267), 270: tensor(96.7367), 280: tensor(96.4533), 290: tensor(96.3667), 300: tensor(96.1033), 310: tensor(96.1200), 320: tensor(96.1317), 330: tensor(96.2200), 340: tensor(96.3667), 350: tensor(96.5100)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=64, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 6.0886,                   Accuracy: 233/2000.0 (11.65%)



-= Testing valid =-
Test set: Average loss: 1.6715,                   Accuracy: 824/2000.0 (41.20%)



-= Testing valid =-
Test set: Average loss: 2.0465,                   Accuracy: 680/2000.0 (34.00%)



-= Testing valid =-
Test set: Average loss: 0.5376,                   Accuracy: 1706/2000.0 (85.30%)



-= Testing valid =-
Test set: Average loss: 0.3504,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.6518,                   Accuracy: 1585/2000.0 (79.25%)



-= Testing valid =-
Test set: Average loss: 0.3235,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.3274,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.2670,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2542,                   Accuracy: 1827/2000.0 (91.35%)



Epoch 10 train accuracy: 93.00%, valid accuracy 91.35%
-= Testing valid =-
Test set: Average loss: 0.1598,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1413,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1625,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.2163,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1396,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1506,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1308,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1371,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1280,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1176,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 20 train accuracy: 95.41%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.1353,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1249,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1261,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1251,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1225,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1011,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1231,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 30 train accuracy: 96.46%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1099,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1137,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1103,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0976,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1034,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 40 train accuracy: 97.16%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0976,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0981,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 50 train accuracy: 97.29%, valid accuracy 96.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1030,                   Accuracy: 58188/60000 (96.98%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1156,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1143,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1153,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1134,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1110,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1103,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1098,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1141,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1133,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1267,                   Accuracy: 57732/60000 (96.22%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1243,                   Accuracy: 57768/60000 (96.28%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1256,                   Accuracy: 57767/60000 (96.28%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1234,                   Accuracy: 57823/60000 (96.37%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1216,                   Accuracy: 57828/60000 (96.38%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1216,                   Accuracy: 57751/60000 (96.25%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1174,                   Accuracy: 57803/60000 (96.34%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1243,                   Accuracy: 57654/60000 (96.09%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1202,                   Accuracy: 57775/60000 (96.29%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1292,                   Accuracy: 57667/60000 (96.11%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1261,                   Accuracy: 57716/60000 (96.19%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1248,                   Accuracy: 57770/60000 (96.28%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1193,                   Accuracy: 57874/60000 (96.46%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1148,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1110,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1054,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1091,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1058,                   Accuracy: 58111/60000 (96.85%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1164,                   Accuracy: 57993/60000 (96.65%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1143,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1148,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1110,                   Accuracy: 58096/60000 (96.83%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1066,                   Accuracy: 58159/60000 (96.93%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1043,                   Accuracy: 58174/60000 (96.96%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1015,                   Accuracy: 58188/60000 (96.98%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1044,                   Accuracy: 58121/60000 (96.87%)
{0: tensor(96.9800), 10: tensor(96.6267), 20: tensor(96.7083), 30: tensor(96.6833), 40: tensor(96.7467), 50: tensor(96.7583), 60: tensor(96.7283), 70: tensor(96.6900), 80: tensor(96.4617), 90: tensor(96.5950), 100: tensor(96.2200), 110: tensor(96.2800), 120: tensor(96.2783), 130: tensor(96.3717), 140: tensor(96.3800), 150: tensor(96.2517), 160: tensor(96.3383), 170: tensor(96.0900), 180: tensor(96.2917), 190: tensor(96.1117), 200: tensor(96.1933), 210: tensor(96.2833), 220: tensor(96.4567), 230: tensor(96.5800), 240: tensor(96.6200), 250: tensor(96.7850), 260: tensor(96.6667), 270: tensor(96.8517), 280: tensor(96.6550), 290: tensor(96.6967), 300: tensor(96.7650), 310: tensor(96.8267), 320: tensor(96.9317), 330: tensor(96.9567), 340: tensor(96.9800), 350: tensor(96.8683)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=65, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.9408,                   Accuracy: 337/2000.0 (16.85%)



-= Testing valid =-
Test set: Average loss: 1.9840,                   Accuracy: 621/2000.0 (31.05%)



-= Testing valid =-
Test set: Average loss: 2.0613,                   Accuracy: 655/2000.0 (32.75%)



-= Testing valid =-
Test set: Average loss: 0.3648,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.3914,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.2475,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.2018,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.2527,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.1954,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1482,                   Accuracy: 1921/2000.0 (96.05%)



Epoch 10 train accuracy: 93.80%, valid accuracy 96.05%
-= Testing valid =-
Test set: Average loss: 0.1460,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1352,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1140,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1363,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 20 train accuracy: 95.72%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1003,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 30 train accuracy: 96.78%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0746,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 40 train accuracy: 96.99%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0736,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 50 train accuracy: 97.24%, valid accuracy 97.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0962,                   Accuracy: 58318/60000 (97.20%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1113,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0997,                   Accuracy: 58218/60000 (97.03%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1048,                   Accuracy: 58136/60000 (96.89%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1077,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1102,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1094,                   Accuracy: 58069/60000 (96.78%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1057,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1086,                   Accuracy: 58083/60000 (96.81%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1029,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1210,                   Accuracy: 57776/60000 (96.29%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1072,                   Accuracy: 58049/60000 (96.75%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1093,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1143,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1181,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1149,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1112,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1145,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1043,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1158,                   Accuracy: 57859/60000 (96.43%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1061,                   Accuracy: 58067/60000 (96.78%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1081,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1107,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1138,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1093,                   Accuracy: 58057/60000 (96.76%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1041,                   Accuracy: 58178/60000 (96.96%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1071,                   Accuracy: 58119/60000 (96.86%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0970,                   Accuracy: 58286/60000 (97.14%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1065,                   Accuracy: 58098/60000 (96.83%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0989,                   Accuracy: 58222/60000 (97.04%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1028,                   Accuracy: 58172/60000 (96.95%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1052,                   Accuracy: 58138/60000 (96.90%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1067,                   Accuracy: 58136/60000 (96.89%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1048,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1007,                   Accuracy: 58252/60000 (97.09%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1024,                   Accuracy: 58224/60000 (97.04%)
{0: tensor(97.1967), 10: tensor(96.6433), 20: tensor(97.0300), 30: tensor(96.8933), 40: tensor(96.8567), 50: tensor(96.7517), 60: tensor(96.7817), 70: tensor(96.8800), 80: tensor(96.8050), 90: tensor(96.9100), 100: tensor(96.2933), 110: tensor(96.7483), 120: tensor(96.7867), 130: tensor(96.6800), 140: tensor(96.4850), 150: tensor(96.5683), 160: tensor(96.6533), 170: tensor(96.5450), 180: tensor(96.8800), 190: tensor(96.4317), 200: tensor(96.7783), 210: tensor(96.7867), 220: tensor(96.7333), 230: tensor(96.6683), 240: tensor(96.7617), 250: tensor(96.9633), 260: tensor(96.8650), 270: tensor(97.1433), 280: tensor(96.8300), 290: tensor(97.0367), 300: tensor(96.9533), 310: tensor(96.8967), 320: tensor(96.8933), 330: tensor(96.9500), 340: tensor(97.0867), 350: tensor(97.0400)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=66, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9419,                   Accuracy: 529/2000.0 (26.45%)



-= Testing valid =-
Test set: Average loss: 1.8743,                   Accuracy: 626/2000.0 (31.30%)



-= Testing valid =-
Test set: Average loss: 2.0494,                   Accuracy: 560/2000.0 (28.00%)



-= Testing valid =-
Test set: Average loss: 1.9238,                   Accuracy: 740/2000.0 (37.00%)



-= Testing valid =-
Test set: Average loss: 1.0287,                   Accuracy: 1307/2000.0 (65.35%)



-= Testing valid =-
Test set: Average loss: 1.2867,                   Accuracy: 1301/2000.0 (65.05%)



-= Testing valid =-
Test set: Average loss: 0.4614,                   Accuracy: 1729/2000.0 (86.45%)



-= Testing valid =-
Test set: Average loss: 0.3218,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.2593,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.3786,                   Accuracy: 1761/2000.0 (88.05%)



Epoch 10 train accuracy: 93.01%, valid accuracy 88.05%
-= Testing valid =-
Test set: Average loss: 0.1931,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.1964,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1432,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.2006,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.1347,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1304,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1267,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.2222,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1502,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1186,                   Accuracy: 1921/2000.0 (96.05%)



Epoch 20 train accuracy: 95.53%, valid accuracy 96.05%
-= Testing valid =-
Test set: Average loss: 0.1263,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1147,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1249,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1103,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1068,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 30 train accuracy: 96.54%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0964,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0964,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 40 train accuracy: 96.72%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 50 train accuracy: 97.06%, valid accuracy 97.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1233,                   Accuracy: 57890/60000 (96.48%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1339,                   Accuracy: 57694/60000 (96.16%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1323,                   Accuracy: 57656/60000 (96.09%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1416,                   Accuracy: 57541/60000 (95.90%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1477,                   Accuracy: 57477/60000 (95.79%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1488,                   Accuracy: 57446/60000 (95.74%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1488,                   Accuracy: 57413/60000 (95.69%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1346,                   Accuracy: 57615/60000 (96.03%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1327,                   Accuracy: 57606/60000 (96.01%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1365,                   Accuracy: 57601/60000 (96.00%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1517,                   Accuracy: 57209/60000 (95.35%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1495,                   Accuracy: 57237/60000 (95.39%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1623,                   Accuracy: 57084/60000 (95.14%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1684,                   Accuracy: 56970/60000 (94.95%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1708,                   Accuracy: 56926/60000 (94.88%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1703,                   Accuracy: 56901/60000 (94.83%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1504,                   Accuracy: 57215/60000 (95.36%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1493,                   Accuracy: 57243/60000 (95.40%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1495,                   Accuracy: 57271/60000 (95.45%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1542,                   Accuracy: 57134/60000 (95.22%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1516,                   Accuracy: 57176/60000 (95.29%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1586,                   Accuracy: 57110/60000 (95.18%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1562,                   Accuracy: 57245/60000 (95.41%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1547,                   Accuracy: 57252/60000 (95.42%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1484,                   Accuracy: 57333/60000 (95.56%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1320,                   Accuracy: 57645/60000 (96.07%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1310,                   Accuracy: 57601/60000 (96.00%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1285,                   Accuracy: 57772/60000 (96.29%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1310,                   Accuracy: 57663/60000 (96.11%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1297,                   Accuracy: 57661/60000 (96.10%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1373,                   Accuracy: 57608/60000 (96.01%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1381,                   Accuracy: 57647/60000 (96.08%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1381,                   Accuracy: 57647/60000 (96.08%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1340,                   Accuracy: 57724/60000 (96.21%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1226,                   Accuracy: 57856/60000 (96.43%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1214,                   Accuracy: 57895/60000 (96.49%)
{0: tensor(96.4833), 10: tensor(96.1567), 20: tensor(96.0933), 30: tensor(95.9017), 40: tensor(95.7950), 50: tensor(95.7433), 60: tensor(95.6883), 70: tensor(96.0250), 80: tensor(96.0100), 90: tensor(96.0017), 100: tensor(95.3483), 110: tensor(95.3950), 120: tensor(95.1400), 130: tensor(94.9500), 140: tensor(94.8767), 150: tensor(94.8350), 160: tensor(95.3583), 170: tensor(95.4050), 180: tensor(95.4517), 190: tensor(95.2233), 200: tensor(95.2933), 210: tensor(95.1833), 220: tensor(95.4083), 230: tensor(95.4200), 240: tensor(95.5550), 250: tensor(96.0750), 260: tensor(96.0017), 270: tensor(96.2867), 280: tensor(96.1050), 290: tensor(96.1017), 300: tensor(96.0133), 310: tensor(96.0783), 320: tensor(96.0783), 330: tensor(96.2067), 340: tensor(96.4267), 350: tensor(96.4917)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=67, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7444,                   Accuracy: 673/2000.0 (33.65%)



-= Testing valid =-
Test set: Average loss: 3.7373,                   Accuracy: 510/2000.0 (25.50%)



-= Testing valid =-
Test set: Average loss: 2.3658,                   Accuracy: 501/2000.0 (25.05%)



-= Testing valid =-
Test set: Average loss: 0.7085,                   Accuracy: 1562/2000.0 (78.10%)



-= Testing valid =-
Test set: Average loss: 0.3790,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 1.2453,                   Accuracy: 1260/2000.0 (63.00%)



-= Testing valid =-
Test set: Average loss: 1.3928,                   Accuracy: 1152/2000.0 (57.60%)



-= Testing valid =-
Test set: Average loss: 0.1900,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.4322,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.1677,                   Accuracy: 1885/2000.0 (94.25%)



Epoch 10 train accuracy: 93.41%, valid accuracy 94.25%
-= Testing valid =-
Test set: Average loss: 0.1900,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.1603,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1074,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1327,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1972,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1173,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1416,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1200,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 20 train accuracy: 95.46%, valid accuracy 96.45%
-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 30 train accuracy: 96.72%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 40 train accuracy: 96.69%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0709,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0707,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 50 train accuracy: 97.28%, valid accuracy 98.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0981,                   Accuracy: 58341/60000 (97.24%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1096,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1039,                   Accuracy: 58232/60000 (97.05%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1054,                   Accuracy: 58152/60000 (96.92%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1051,                   Accuracy: 58152/60000 (96.92%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1075,                   Accuracy: 58079/60000 (96.80%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1068,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1051,                   Accuracy: 58187/60000 (96.98%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1080,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1063,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1208,                   Accuracy: 57857/60000 (96.43%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1136,                   Accuracy: 57990/60000 (96.65%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1167,                   Accuracy: 57924/60000 (96.54%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1148,                   Accuracy: 57946/60000 (96.58%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1187,                   Accuracy: 57845/60000 (96.41%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1161,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1145,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1203,                   Accuracy: 57822/60000 (96.37%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1127,                   Accuracy: 58011/60000 (96.68%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1202,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1153,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1142,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1094,                   Accuracy: 58080/60000 (96.80%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1086,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1074,                   Accuracy: 58118/60000 (96.86%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1034,                   Accuracy: 58238/60000 (97.06%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1094,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1006,                   Accuracy: 58280/60000 (97.13%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1066,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1039,                   Accuracy: 58198/60000 (97.00%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1037,                   Accuracy: 58188/60000 (96.98%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1016,                   Accuracy: 58216/60000 (97.03%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1009,                   Accuracy: 58174/60000 (96.96%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1010,                   Accuracy: 58222/60000 (97.04%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0977,                   Accuracy: 58308/60000 (97.18%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1020,                   Accuracy: 58222/60000 (97.04%)
{0: tensor(97.2350), 10: tensor(96.8483), 20: tensor(97.0533), 30: tensor(96.9200), 40: tensor(96.9200), 50: tensor(96.7983), 60: tensor(96.8383), 70: tensor(96.9783), 80: tensor(96.8167), 90: tensor(96.9100), 100: tensor(96.4283), 110: tensor(96.6500), 120: tensor(96.5400), 130: tensor(96.5767), 140: tensor(96.4083), 150: tensor(96.6017), 160: tensor(96.6433), 170: tensor(96.3700), 180: tensor(96.6850), 190: tensor(96.4850), 200: tensor(96.5883), 210: tensor(96.5700), 220: tensor(96.8000), 230: tensor(96.7400), 240: tensor(96.8633), 250: tensor(97.0633), 260: tensor(96.7833), 270: tensor(97.1333), 280: tensor(96.9217), 290: tensor(96.9967), 300: tensor(96.9800), 310: tensor(97.0267), 320: tensor(96.9567), 330: tensor(97.0367), 340: tensor(97.1800), 350: tensor(97.0367)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=68, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0105,                   Accuracy: 529/2000.0 (26.45%)



-= Testing valid =-
Test set: Average loss: 1.7504,                   Accuracy: 683/2000.0 (34.15%)



-= Testing valid =-
Test set: Average loss: 1.3846,                   Accuracy: 926/2000.0 (46.30%)



-= Testing valid =-
Test set: Average loss: 0.9529,                   Accuracy: 1368/2000.0 (68.40%)



-= Testing valid =-
Test set: Average loss: 1.7328,                   Accuracy: 892/2000.0 (44.60%)



-= Testing valid =-
Test set: Average loss: 0.4237,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.6306,                   Accuracy: 1628/2000.0 (81.40%)



-= Testing valid =-
Test set: Average loss: 0.3503,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.2031,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.1781,                   Accuracy: 1881/2000.0 (94.05%)



Epoch 10 train accuracy: 93.25%, valid accuracy 94.05%
-= Testing valid =-
Test set: Average loss: 0.1866,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.2030,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1973,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1410,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1546,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1874,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.1438,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1339,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1602,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1314,                   Accuracy: 1913/2000.0 (95.65%)



Epoch 20 train accuracy: 95.79%, valid accuracy 95.65%
-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1464,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1132,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1100,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1258,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1371,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1170,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1474,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1610,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1034,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 30 train accuracy: 96.60%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1225,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1106,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1141,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1083,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1033,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 40 train accuracy: 96.93%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.1140,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 50 train accuracy: 97.15%, valid accuracy 97.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0996,                   Accuracy: 58280/60000 (97.13%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1165,                   Accuracy: 57916/60000 (96.53%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1081,                   Accuracy: 58034/60000 (96.72%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1035,                   Accuracy: 58149/60000 (96.92%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1023,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1027,                   Accuracy: 58178/60000 (96.96%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1048,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1107,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1187,                   Accuracy: 57848/60000 (96.41%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1076,                   Accuracy: 58113/60000 (96.86%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1259,                   Accuracy: 57703/60000 (96.17%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1148,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1125,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1108,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1111,                   Accuracy: 57983/60000 (96.64%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1145,                   Accuracy: 57901/60000 (96.50%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1195,                   Accuracy: 57836/60000 (96.39%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1283,                   Accuracy: 57603/60000 (96.00%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1154,                   Accuracy: 57916/60000 (96.53%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1316,                   Accuracy: 57557/60000 (95.93%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1175,                   Accuracy: 57803/60000 (96.34%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1122,                   Accuracy: 57975/60000 (96.62%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1084,                   Accuracy: 58017/60000 (96.69%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1084,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1092,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1132,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1167,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1053,                   Accuracy: 58152/60000 (96.92%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1203,                   Accuracy: 57798/60000 (96.33%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1089,                   Accuracy: 57997/60000 (96.66%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1022,                   Accuracy: 58159/60000 (96.93%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.0997,                   Accuracy: 58206/60000 (97.01%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.0995,                   Accuracy: 58207/60000 (97.01%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1002,                   Accuracy: 58267/60000 (97.11%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1062,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1099,                   Accuracy: 58067/60000 (96.78%)
{0: tensor(97.1333), 10: tensor(96.5267), 20: tensor(96.7233), 30: tensor(96.9150), 40: tensor(96.9500), 50: tensor(96.9633), 60: tensor(96.8800), 70: tensor(96.6633), 80: tensor(96.4133), 90: tensor(96.8550), 100: tensor(96.1717), 110: tensor(96.5067), 120: tensor(96.6183), 130: tensor(96.6817), 140: tensor(96.6383), 150: tensor(96.5017), 160: tensor(96.3933), 170: tensor(96.0050), 180: tensor(96.5267), 190: tensor(95.9283), 200: tensor(96.3383), 210: tensor(96.6250), 220: tensor(96.6950), 230: tensor(96.7000), 240: tensor(96.6967), 250: tensor(96.6233), 260: tensor(96.5317), 270: tensor(96.9200), 280: tensor(96.3300), 290: tensor(96.6617), 300: tensor(96.9317), 310: tensor(97.0100), 320: tensor(97.0117), 330: tensor(97.1117), 340: tensor(96.8533), 350: tensor(96.7783)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=69, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2035,                   Accuracy: 414/2000.0 (20.70%)



-= Testing valid =-
Test set: Average loss: 1.7121,                   Accuracy: 753/2000.0 (37.65%)



-= Testing valid =-
Test set: Average loss: 1.7505,                   Accuracy: 780/2000.0 (39.00%)



-= Testing valid =-
Test set: Average loss: 3.1634,                   Accuracy: 606/2000.0 (30.30%)



-= Testing valid =-
Test set: Average loss: 0.4325,                   Accuracy: 1720/2000.0 (86.00%)



-= Testing valid =-
Test set: Average loss: 0.2609,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.4682,                   Accuracy: 1699/2000.0 (84.95%)



-= Testing valid =-
Test set: Average loss: 0.2415,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.1912,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.1949,                   Accuracy: 1876/2000.0 (93.80%)



Epoch 10 train accuracy: 93.75%, valid accuracy 93.80%
-= Testing valid =-
Test set: Average loss: 0.1614,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1801,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1416,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1479,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1569,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1283,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1120,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1251,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1425,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1216,                   Accuracy: 1923/2000.0 (96.15%)



Epoch 20 train accuracy: 95.84%, valid accuracy 96.15%
-= Testing valid =-
Test set: Average loss: 0.1131,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1097,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1134,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1187,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1243,                   Accuracy: 1921/2000.0 (96.05%)



Epoch 30 train accuracy: 96.68%, valid accuracy 96.05%
-= Testing valid =-
Test set: Average loss: 0.1042,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1010,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0919,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1200,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1071,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 40 train accuracy: 96.86%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 50 train accuracy: 97.12%, valid accuracy 96.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0995,                   Accuracy: 58239/60000 (97.07%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1090,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1106,                   Accuracy: 58066/60000 (96.78%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1173,                   Accuracy: 57955/60000 (96.59%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1198,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1201,                   Accuracy: 57905/60000 (96.51%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1164,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1098,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1050,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0996,                   Accuracy: 58258/60000 (97.10%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1087,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1103,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1159,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1211,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1225,                   Accuracy: 57825/60000 (96.38%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1195,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1125,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1131,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1016,                   Accuracy: 58198/60000 (97.00%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1109,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1098,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1166,                   Accuracy: 57930/60000 (96.55%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1201,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1219,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1190,                   Accuracy: 57860/60000 (96.43%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1116,                   Accuracy: 57975/60000 (96.62%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1112,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1004,                   Accuracy: 58219/60000 (97.03%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1092,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1094,                   Accuracy: 58076/60000 (96.79%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1178,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1188,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1194,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1177,                   Accuracy: 57912/60000 (96.52%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1097,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1055,                   Accuracy: 58100/60000 (96.83%)
{0: tensor(97.0650), 10: tensor(96.6717), 20: tensor(96.7767), 30: tensor(96.5917), 40: tensor(96.5333), 50: tensor(96.5083), 60: tensor(96.5850), 70: tensor(96.7750), 80: tensor(96.8450), 90: tensor(97.0967), 100: tensor(96.7083), 110: tensor(96.7333), 120: tensor(96.6433), 130: tensor(96.4900), 140: tensor(96.3750), 150: tensor(96.3767), 160: tensor(96.5883), 170: tensor(96.5950), 180: tensor(96.9967), 190: tensor(96.6633), 200: tensor(96.7567), 210: tensor(96.5500), 220: tensor(96.5133), 230: tensor(96.3817), 240: tensor(96.4333), 250: tensor(96.6250), 260: tensor(96.6017), 270: tensor(97.0317), 280: tensor(96.6883), 290: tensor(96.7933), 300: tensor(96.5750), 310: tensor(96.4917), 320: tensor(96.4717), 330: tensor(96.5200), 340: tensor(96.7433), 350: tensor(96.8333)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=70, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0326,                   Accuracy: 534/2000.0 (26.70%)



-= Testing valid =-
Test set: Average loss: 1.6762,                   Accuracy: 876/2000.0 (43.80%)



-= Testing valid =-
Test set: Average loss: 0.8194,                   Accuracy: 1419/2000.0 (70.95%)



-= Testing valid =-
Test set: Average loss: 0.6603,                   Accuracy: 1562/2000.0 (78.10%)



-= Testing valid =-
Test set: Average loss: 0.5779,                   Accuracy: 1652/2000.0 (82.60%)



-= Testing valid =-
Test set: Average loss: 0.3089,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3108,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.2539,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2285,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.1691,                   Accuracy: 1897/2000.0 (94.85%)



Epoch 10 train accuracy: 94.26%, valid accuracy 94.85%
-= Testing valid =-
Test set: Average loss: 0.1627,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1385,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1878,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.2130,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1459,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1611,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1627,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1353,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1820,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1834,                   Accuracy: 1893/2000.0 (94.65%)



Epoch 20 train accuracy: 96.11%, valid accuracy 94.65%
-= Testing valid =-
Test set: Average loss: 0.1392,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1272,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1651,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1301,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1328,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1508,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1275,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1525,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1345,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1468,                   Accuracy: 1915/2000.0 (95.75%)



Epoch 30 train accuracy: 96.68%, valid accuracy 95.75%
-= Testing valid =-
Test set: Average loss: 0.1333,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1233,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1239,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1208,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1422,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1192,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1382,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1296,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1126,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 40 train accuracy: 96.81%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.1117,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1199,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1165,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1181,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1171,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1193,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1163,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1171,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1187,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 50 train accuracy: 97.18%, valid accuracy 96.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1061,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1320,                   Accuracy: 57657/60000 (96.10%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1228,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1178,                   Accuracy: 57928/60000 (96.55%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1181,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1159,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1116,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1104,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1151,                   Accuracy: 57924/60000 (96.54%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1044,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1286,                   Accuracy: 57674/60000 (96.12%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1209,                   Accuracy: 57840/60000 (96.40%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1169,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1172,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1164,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1125,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1100,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1157,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1041,                   Accuracy: 58163/60000 (96.94%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1240,                   Accuracy: 57763/60000 (96.27%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1185,                   Accuracy: 57901/60000 (96.50%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1169,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1158,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1156,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1115,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1114,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1181,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1062,                   Accuracy: 58139/60000 (96.90%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1267,                   Accuracy: 57753/60000 (96.25%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1216,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1180,                   Accuracy: 57924/60000 (96.54%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1175,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1163,                   Accuracy: 57979/60000 (96.63%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1115,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1125,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1182,                   Accuracy: 57895/60000 (96.49%)
{0: tensor(96.9217), 10: tensor(96.0950), 20: tensor(96.4017), 30: tensor(96.5467), 40: tensor(96.4600), 50: tensor(96.5850), 60: tensor(96.6900), 70: tensor(96.7067), 80: tensor(96.5400), 90: tensor(96.9217), 100: tensor(96.1233), 110: tensor(96.4000), 120: tensor(96.5183), 130: tensor(96.4817), 140: tensor(96.5617), 150: tensor(96.6750), 160: tensor(96.6450), 170: tensor(96.5550), 180: tensor(96.9383), 190: tensor(96.2717), 200: tensor(96.5017), 210: tensor(96.5183), 220: tensor(96.5250), 230: tensor(96.6017), 240: tensor(96.6683), 250: tensor(96.6800), 260: tensor(96.4983), 270: tensor(96.8983), 280: tensor(96.2550), 290: tensor(96.4167), 300: tensor(96.5400), 310: tensor(96.4733), 320: tensor(96.6317), 330: tensor(96.7067), 340: tensor(96.6767), 350: tensor(96.4917)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=41, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2689,                   Accuracy: 399/2000.0 (19.95%)



-= Testing valid =-
Test set: Average loss: 2.7091,                   Accuracy: 512/2000.0 (25.60%)



-= Testing valid =-
Test set: Average loss: 1.6267,                   Accuracy: 939/2000.0 (46.95%)



-= Testing valid =-
Test set: Average loss: 0.9894,                   Accuracy: 1266/2000.0 (63.30%)



-= Testing valid =-
Test set: Average loss: 0.3553,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.2728,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2873,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.4563,                   Accuracy: 1739/2000.0 (86.95%)



-= Testing valid =-
Test set: Average loss: 0.1953,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.3430,                   Accuracy: 1778/2000.0 (88.90%)



Epoch 10 train accuracy: 93.79%, valid accuracy 88.90%
-= Testing valid =-
Test set: Average loss: 0.1546,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1447,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.2050,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.1643,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1277,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1458,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1332,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1524,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1801,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1368,                   Accuracy: 1922/2000.0 (96.10%)



Epoch 20 train accuracy: 95.50%, valid accuracy 96.10%
-= Testing valid =-
Test set: Average loss: 0.1391,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1174,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1245,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1210,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1253,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1222,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1163,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1312,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1201,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1058,                   Accuracy: 1934/2000.0 (96.70%)



Epoch 30 train accuracy: 96.29%, valid accuracy 96.70%
-= Testing valid =-
Test set: Average loss: 0.1162,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1145,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1053,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0964,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1036,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 40 train accuracy: 97.01%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1067,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0986,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0978,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1010,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 50 train accuracy: 96.99%, valid accuracy 96.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1126,                   Accuracy: 58035/60000 (96.72%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1247,                   Accuracy: 57802/60000 (96.34%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1168,                   Accuracy: 57916/60000 (96.53%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1119,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1129,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1145,                   Accuracy: 57982/60000 (96.64%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1164,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1211,                   Accuracy: 57805/60000 (96.34%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1256,                   Accuracy: 57774/60000 (96.29%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1186,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1341,                   Accuracy: 57547/60000 (95.91%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1247,                   Accuracy: 57708/60000 (96.18%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1206,                   Accuracy: 57794/60000 (96.32%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1209,                   Accuracy: 57811/60000 (96.35%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1235,                   Accuracy: 57786/60000 (96.31%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1267,                   Accuracy: 57695/60000 (96.16%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1296,                   Accuracy: 57612/60000 (96.02%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1381,                   Accuracy: 57472/60000 (95.79%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1270,                   Accuracy: 57679/60000 (96.13%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1404,                   Accuracy: 57391/60000 (95.65%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1293,                   Accuracy: 57609/60000 (96.01%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1232,                   Accuracy: 57758/60000 (96.26%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1203,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1210,                   Accuracy: 57833/60000 (96.39%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1218,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1241,                   Accuracy: 57732/60000 (96.22%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1295,                   Accuracy: 57644/60000 (96.07%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1184,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1289,                   Accuracy: 57684/60000 (96.14%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1193,                   Accuracy: 57838/60000 (96.40%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1134,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1121,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1124,                   Accuracy: 57997/60000 (96.66%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1131,                   Accuracy: 57990/60000 (96.65%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1165,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1205,                   Accuracy: 57883/60000 (96.47%)
{0: tensor(96.7250), 10: tensor(96.3367), 20: tensor(96.5267), 30: tensor(96.6817), 40: tensor(96.6467), 50: tensor(96.6367), 60: tensor(96.5367), 70: tensor(96.3417), 80: tensor(96.2900), 90: tensor(96.4617), 100: tensor(95.9117), 110: tensor(96.1800), 120: tensor(96.3233), 130: tensor(96.3517), 140: tensor(96.3100), 150: tensor(96.1583), 160: tensor(96.0200), 170: tensor(95.7867), 180: tensor(96.1317), 190: tensor(95.6517), 200: tensor(96.0150), 210: tensor(96.2633), 220: tensor(96.3400), 230: tensor(96.3883), 240: tensor(96.3400), 250: tensor(96.2200), 260: tensor(96.0733), 270: tensor(96.4783), 280: tensor(96.1400), 290: tensor(96.3967), 300: tensor(96.6600), 310: tensor(96.6900), 320: tensor(96.6617), 330: tensor(96.6500), 340: tensor(96.4783), 350: tensor(96.4717)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=42, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0232,                   Accuracy: 416/2000.0 (20.80%)



-= Testing valid =-
Test set: Average loss: 2.1736,                   Accuracy: 456/2000.0 (22.80%)



-= Testing valid =-
Test set: Average loss: 2.0716,                   Accuracy: 727/2000.0 (36.35%)



-= Testing valid =-
Test set: Average loss: 0.7570,                   Accuracy: 1497/2000.0 (74.85%)



-= Testing valid =-
Test set: Average loss: 0.9872,                   Accuracy: 1379/2000.0 (68.95%)



-= Testing valid =-
Test set: Average loss: 0.5660,                   Accuracy: 1661/2000.0 (83.05%)



-= Testing valid =-
Test set: Average loss: 0.2993,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.3586,                   Accuracy: 1730/2000.0 (86.50%)



-= Testing valid =-
Test set: Average loss: 0.3500,                   Accuracy: 1755/2000.0 (87.75%)



-= Testing valid =-
Test set: Average loss: 0.2930,                   Accuracy: 1830/2000.0 (91.50%)



Epoch 10 train accuracy: 93.57%, valid accuracy 91.50%
-= Testing valid =-
Test set: Average loss: 0.2063,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.2276,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.1839,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.2327,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.1283,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1483,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1607,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1998,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.2129,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2024,                   Accuracy: 1883/2000.0 (94.15%)



Epoch 20 train accuracy: 95.71%, valid accuracy 94.15%
-= Testing valid =-
Test set: Average loss: 0.1450,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1242,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1681,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1051,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1356,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1104,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1457,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1445,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1199,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1686,                   Accuracy: 1891/2000.0 (94.55%)



Epoch 30 train accuracy: 96.60%, valid accuracy 94.55%
-= Testing valid =-
Test set: Average loss: 0.1281,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1399,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1446,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1289,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1318,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1390,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1293,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1325,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1064,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1274,                   Accuracy: 1918/2000.0 (95.90%)



Epoch 40 train accuracy: 97.20%, valid accuracy 95.90%
-= Testing valid =-
Test set: Average loss: 0.1308,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1314,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1288,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1199,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1483,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1223,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1276,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1193,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1195,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1229,                   Accuracy: 1921/2000.0 (96.05%)



Epoch 50 train accuracy: 97.31%, valid accuracy 96.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1314,                   Accuracy: 57704/60000 (96.17%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1371,                   Accuracy: 57581/60000 (95.97%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1370,                   Accuracy: 57594/60000 (95.99%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1425,                   Accuracy: 57488/60000 (95.81%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1508,                   Accuracy: 57332/60000 (95.55%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1559,                   Accuracy: 57306/60000 (95.51%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1522,                   Accuracy: 57376/60000 (95.63%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1456,                   Accuracy: 57478/60000 (95.80%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1435,                   Accuracy: 57516/60000 (95.86%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1369,                   Accuracy: 57578/60000 (95.96%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1432,                   Accuracy: 57437/60000 (95.73%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1425,                   Accuracy: 57429/60000 (95.71%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1468,                   Accuracy: 57348/60000 (95.58%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1544,                   Accuracy: 57239/60000 (95.40%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1613,                   Accuracy: 57120/60000 (95.20%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1577,                   Accuracy: 57167/60000 (95.28%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1488,                   Accuracy: 57346/60000 (95.58%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1471,                   Accuracy: 57349/60000 (95.58%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1392,                   Accuracy: 57494/60000 (95.82%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1501,                   Accuracy: 57218/60000 (95.36%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1410,                   Accuracy: 57421/60000 (95.70%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1452,                   Accuracy: 57407/60000 (95.68%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1522,                   Accuracy: 57243/60000 (95.40%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1570,                   Accuracy: 57138/60000 (95.23%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1542,                   Accuracy: 57234/60000 (95.39%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1429,                   Accuracy: 57438/60000 (95.73%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1393,                   Accuracy: 57522/60000 (95.87%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1317,                   Accuracy: 57700/60000 (96.17%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1385,                   Accuracy: 57516/60000 (95.86%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1338,                   Accuracy: 57623/60000 (96.04%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1387,                   Accuracy: 57568/60000 (95.95%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1464,                   Accuracy: 57441/60000 (95.74%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1496,                   Accuracy: 57411/60000 (95.68%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1476,                   Accuracy: 57451/60000 (95.75%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1398,                   Accuracy: 57554/60000 (95.92%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1370,                   Accuracy: 57620/60000 (96.03%)
{0: tensor(96.1733), 10: tensor(95.9683), 20: tensor(95.9900), 30: tensor(95.8133), 40: tensor(95.5533), 50: tensor(95.5100), 60: tensor(95.6267), 70: tensor(95.7967), 80: tensor(95.8600), 90: tensor(95.9633), 100: tensor(95.7283), 110: tensor(95.7150), 120: tensor(95.5800), 130: tensor(95.3983), 140: tensor(95.2000), 150: tensor(95.2783), 160: tensor(95.5767), 170: tensor(95.5817), 180: tensor(95.8233), 190: tensor(95.3633), 200: tensor(95.7017), 210: tensor(95.6783), 220: tensor(95.4050), 230: tensor(95.2300), 240: tensor(95.3900), 250: tensor(95.7300), 260: tensor(95.8700), 270: tensor(96.1667), 280: tensor(95.8600), 290: tensor(96.0383), 300: tensor(95.9467), 310: tensor(95.7350), 320: tensor(95.6850), 330: tensor(95.7517), 340: tensor(95.9233), 350: tensor(96.0333)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=43, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 7.9803,                   Accuracy: 205/2000.0 (10.25%)



-= Testing valid =-
Test set: Average loss: 1.7938,                   Accuracy: 659/2000.0 (32.95%)



-= Testing valid =-
Test set: Average loss: 0.8225,                   Accuracy: 1513/2000.0 (75.65%)



-= Testing valid =-
Test set: Average loss: 1.4275,                   Accuracy: 997/2000.0 (49.85%)



-= Testing valid =-
Test set: Average loss: 0.4098,                   Accuracy: 1712/2000.0 (85.60%)



-= Testing valid =-
Test set: Average loss: 0.5556,                   Accuracy: 1655/2000.0 (82.75%)



-= Testing valid =-
Test set: Average loss: 0.2264,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.4909,                   Accuracy: 1714/2000.0 (85.70%)



-= Testing valid =-
Test set: Average loss: 0.2125,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.1981,                   Accuracy: 1875/2000.0 (93.75%)



Epoch 10 train accuracy: 93.20%, valid accuracy 93.75%
-= Testing valid =-
Test set: Average loss: 0.1742,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1163,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1602,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1108,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1120,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1294,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1428,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1361,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 20 train accuracy: 94.91%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1048,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 30 train accuracy: 96.62%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 40 train accuracy: 97.10%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 50 train accuracy: 97.18%, valid accuracy 97.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1051,                   Accuracy: 58189/60000 (96.98%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1142,                   Accuracy: 57975/60000 (96.62%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1109,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1118,                   Accuracy: 57981/60000 (96.64%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1123,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1124,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1118,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1116,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1138,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1102,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1199,                   Accuracy: 57860/60000 (96.43%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1176,                   Accuracy: 57865/60000 (96.44%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1175,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1184,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1188,                   Accuracy: 57879/60000 (96.46%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1183,                   Accuracy: 57898/60000 (96.50%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1158,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1174,                   Accuracy: 57902/60000 (96.50%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1139,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1228,                   Accuracy: 57801/60000 (96.33%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1182,                   Accuracy: 57828/60000 (96.38%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1182,                   Accuracy: 57840/60000 (96.40%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1159,                   Accuracy: 57910/60000 (96.52%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1151,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1135,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1103,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1124,                   Accuracy: 58029/60000 (96.71%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1071,                   Accuracy: 58130/60000 (96.88%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1152,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1103,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1115,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1099,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1095,                   Accuracy: 58075/60000 (96.79%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1080,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1073,                   Accuracy: 58161/60000 (96.93%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1098,                   Accuracy: 58096/60000 (96.83%)
{0: tensor(96.9817), 10: tensor(96.6250), 20: tensor(96.6450), 30: tensor(96.6350), 40: tensor(96.6817), 50: tensor(96.7017), 60: tensor(96.7383), 70: tensor(96.7700), 80: tensor(96.6400), 90: tensor(96.7267), 100: tensor(96.4333), 110: tensor(96.4417), 120: tensor(96.4433), 130: tensor(96.4617), 140: tensor(96.4650), 150: tensor(96.4967), 160: tensor(96.5350), 170: tensor(96.5033), 180: tensor(96.5783), 190: tensor(96.3350), 200: tensor(96.3800), 210: tensor(96.4000), 220: tensor(96.5167), 230: tensor(96.6150), 240: tensor(96.6433), 250: tensor(96.7850), 260: tensor(96.7150), 270: tensor(96.8833), 280: tensor(96.6050), 290: tensor(96.7117), 300: tensor(96.6667), 310: tensor(96.7017), 320: tensor(96.7917), 330: tensor(96.8567), 340: tensor(96.9350), 350: tensor(96.8267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=44, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 8.0828,                   Accuracy: 238/2000.0 (11.90%)



-= Testing valid =-
Test set: Average loss: 1.8831,                   Accuracy: 640/2000.0 (32.00%)



-= Testing valid =-
Test set: Average loss: 1.5587,                   Accuracy: 856/2000.0 (42.80%)



-= Testing valid =-
Test set: Average loss: 0.8550,                   Accuracy: 1340/2000.0 (67.00%)



-= Testing valid =-
Test set: Average loss: 0.4443,                   Accuracy: 1725/2000.0 (86.25%)



-= Testing valid =-
Test set: Average loss: 0.3072,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.4560,                   Accuracy: 1709/2000.0 (85.45%)



-= Testing valid =-
Test set: Average loss: 0.1904,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1407,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.2658,                   Accuracy: 1834/2000.0 (91.70%)



Epoch 10 train accuracy: 93.22%, valid accuracy 91.70%
-= Testing valid =-
Test set: Average loss: 0.2751,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.1150,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1400,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1202,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1121,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1200,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1431,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1099,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 20 train accuracy: 95.43%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.1099,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1093,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.0877,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0650,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 30 train accuracy: 96.24%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0756,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0641,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0655,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 40 train accuracy: 97.31%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0646,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0638,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 50 train accuracy: 97.14%, valid accuracy 97.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1041,                   Accuracy: 58189/60000 (96.98%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1148,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1130,                   Accuracy: 57949/60000 (96.58%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1183,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1203,                   Accuracy: 57790/60000 (96.32%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1242,                   Accuracy: 57726/60000 (96.21%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1220,                   Accuracy: 57749/60000 (96.25%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1145,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1152,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1105,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1244,                   Accuracy: 57704/60000 (96.17%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1224,                   Accuracy: 57701/60000 (96.17%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1285,                   Accuracy: 57592/60000 (95.99%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1302,                   Accuracy: 57559/60000 (95.93%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1332,                   Accuracy: 57492/60000 (95.82%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1318,                   Accuracy: 57557/60000 (95.93%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1225,                   Accuracy: 57696/60000 (96.16%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1228,                   Accuracy: 57768/60000 (96.28%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1183,                   Accuracy: 57848/60000 (96.41%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1306,                   Accuracy: 57533/60000 (95.89%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1262,                   Accuracy: 57596/60000 (95.99%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1283,                   Accuracy: 57597/60000 (96.00%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1263,                   Accuracy: 57613/60000 (96.02%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1272,                   Accuracy: 57652/60000 (96.09%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1247,                   Accuracy: 57700/60000 (96.17%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1143,                   Accuracy: 57865/60000 (96.44%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1130,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1093,                   Accuracy: 58035/60000 (96.72%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1185,                   Accuracy: 57792/60000 (96.32%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1156,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1181,                   Accuracy: 57823/60000 (96.37%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1173,                   Accuracy: 57833/60000 (96.39%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1185,                   Accuracy: 57836/60000 (96.39%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1157,                   Accuracy: 57903/60000 (96.50%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1072,                   Accuracy: 58064/60000 (96.77%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1076,                   Accuracy: 58088/60000 (96.81%)
{0: tensor(96.9817), 10: tensor(96.5250), 20: tensor(96.5817), 30: tensor(96.4017), 40: tensor(96.3167), 50: tensor(96.2100), 60: tensor(96.2483), 70: tensor(96.5533), 80: tensor(96.5633), 90: tensor(96.7567), 100: tensor(96.1733), 110: tensor(96.1683), 120: tensor(95.9867), 130: tensor(95.9317), 140: tensor(95.8200), 150: tensor(95.9283), 160: tensor(96.1600), 170: tensor(96.2800), 180: tensor(96.4133), 190: tensor(95.8883), 200: tensor(95.9933), 210: tensor(95.9950), 220: tensor(96.0217), 230: tensor(96.0867), 240: tensor(96.1667), 250: tensor(96.4417), 260: tensor(96.6117), 270: tensor(96.7250), 280: tensor(96.3200), 290: tensor(96.3600), 300: tensor(96.3717), 310: tensor(96.3883), 320: tensor(96.3933), 330: tensor(96.5050), 340: tensor(96.7733), 350: tensor(96.8133)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=45, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0882,                   Accuracy: 362/2000.0 (18.10%)



-= Testing valid =-
Test set: Average loss: 1.8463,                   Accuracy: 669/2000.0 (33.45%)



-= Testing valid =-
Test set: Average loss: 2.8240,                   Accuracy: 438/2000.0 (21.90%)



-= Testing valid =-
Test set: Average loss: 1.0128,                   Accuracy: 1266/2000.0 (63.30%)



-= Testing valid =-
Test set: Average loss: 0.8632,                   Accuracy: 1400/2000.0 (70.00%)



-= Testing valid =-
Test set: Average loss: 0.4386,                   Accuracy: 1749/2000.0 (87.45%)



-= Testing valid =-
Test set: Average loss: 0.3012,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.4197,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.1952,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.4898,                   Accuracy: 1727/2000.0 (86.35%)



Epoch 10 train accuracy: 93.24%, valid accuracy 86.35%
-= Testing valid =-
Test set: Average loss: 0.1489,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1687,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1502,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1302,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1489,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1777,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1152,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1262,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1481,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1259,                   Accuracy: 1912/2000.0 (95.60%)



Epoch 20 train accuracy: 95.44%, valid accuracy 95.60%
-= Testing valid =-
Test set: Average loss: 0.1107,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0986,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1097,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0947,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1003,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 30 train accuracy: 96.36%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 40 train accuracy: 96.88%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0802,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 50 train accuracy: 97.11%, valid accuracy 97.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1107,                   Accuracy: 58104/60000 (96.84%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1154,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1145,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1159,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1144,                   Accuracy: 57958/60000 (96.60%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1134,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1136,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1140,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1164,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1178,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1220,                   Accuracy: 57776/60000 (96.29%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1229,                   Accuracy: 57791/60000 (96.32%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1270,                   Accuracy: 57676/60000 (96.13%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1246,                   Accuracy: 57723/60000 (96.21%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1232,                   Accuracy: 57759/60000 (96.26%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1269,                   Accuracy: 57693/60000 (96.15%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1226,                   Accuracy: 57780/60000 (96.30%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1254,                   Accuracy: 57698/60000 (96.16%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1247,                   Accuracy: 57753/60000 (96.25%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1284,                   Accuracy: 57640/60000 (96.07%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1273,                   Accuracy: 57670/60000 (96.12%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1298,                   Accuracy: 57630/60000 (96.05%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1216,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1185,                   Accuracy: 57888/60000 (96.48%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1195,                   Accuracy: 57852/60000 (96.42%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1129,                   Accuracy: 58011/60000 (96.68%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1141,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1143,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1185,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1174,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1175,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1126,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1099,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1088,                   Accuracy: 58080/60000 (96.80%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1074,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1090,                   Accuracy: 58099/60000 (96.83%)
{0: tensor(96.8400), 10: tensor(96.5683), 20: tensor(96.6117), 30: tensor(96.6000), 40: tensor(96.5967), 50: tensor(96.6067), 60: tensor(96.6333), 70: tensor(96.6483), 80: tensor(96.5183), 90: tensor(96.5533), 100: tensor(96.2933), 110: tensor(96.3183), 120: tensor(96.1267), 130: tensor(96.2050), 140: tensor(96.2650), 150: tensor(96.1550), 160: tensor(96.3000), 170: tensor(96.1633), 180: tensor(96.2550), 190: tensor(96.0667), 200: tensor(96.1167), 210: tensor(96.0500), 220: tensor(96.3567), 230: tensor(96.4800), 240: tensor(96.4200), 250: tensor(96.6850), 260: tensor(96.6183), 270: tensor(96.6817), 280: tensor(96.4350), 290: tensor(96.5133), 300: tensor(96.4733), 310: tensor(96.7000), 320: tensor(96.7517), 330: tensor(96.8000), 340: tensor(96.8683), 350: tensor(96.8317)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=46, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6993,                   Accuracy: 212/2000.0 (10.60%)



-= Testing valid =-
Test set: Average loss: 1.1867,                   Accuracy: 1152/2000.0 (57.60%)



-= Testing valid =-
Test set: Average loss: 1.1238,                   Accuracy: 1241/2000.0 (62.05%)



-= Testing valid =-
Test set: Average loss: 0.5188,                   Accuracy: 1716/2000.0 (85.80%)



-= Testing valid =-
Test set: Average loss: 0.4999,                   Accuracy: 1705/2000.0 (85.25%)



-= Testing valid =-
Test set: Average loss: 0.4010,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.2259,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2412,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2237,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2016,                   Accuracy: 1866/2000.0 (93.30%)



Epoch 10 train accuracy: 92.91%, valid accuracy 93.30%
-= Testing valid =-
Test set: Average loss: 0.1382,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1309,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1225,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1228,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1374,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1451,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1323,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1541,                   Accuracy: 1894/2000.0 (94.70%)



Epoch 20 train accuracy: 95.49%, valid accuracy 94.70%
-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1150,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1059,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 30 train accuracy: 96.44%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0674,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0622,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0678,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 40 train accuracy: 96.82%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0650,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0686,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0664,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0659,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 50 train accuracy: 97.16%, valid accuracy 98.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1055,                   Accuracy: 58147/60000 (96.91%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1127,                   Accuracy: 58011/60000 (96.68%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1103,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1064,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1040,                   Accuracy: 58180/60000 (96.97%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1035,                   Accuracy: 58195/60000 (96.99%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1045,                   Accuracy: 58186/60000 (96.98%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1046,                   Accuracy: 58175/60000 (96.96%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1075,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1058,                   Accuracy: 58152/60000 (96.92%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1157,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1101,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1074,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1049,                   Accuracy: 58158/60000 (96.93%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1045,                   Accuracy: 58172/60000 (96.95%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1068,                   Accuracy: 58110/60000 (96.85%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1040,                   Accuracy: 58169/60000 (96.95%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1072,                   Accuracy: 58116/60000 (96.86%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1058,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1129,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1078,                   Accuracy: 58089/60000 (96.82%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1080,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1051,                   Accuracy: 58130/60000 (96.88%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1038,                   Accuracy: 58183/60000 (96.97%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1057,                   Accuracy: 58142/60000 (96.90%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1038,                   Accuracy: 58204/60000 (97.01%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1076,                   Accuracy: 58131/60000 (96.89%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1048,                   Accuracy: 58180/60000 (96.97%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1097,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1082,                   Accuracy: 58138/60000 (96.90%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1063,                   Accuracy: 58150/60000 (96.92%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1037,                   Accuracy: 58160/60000 (96.93%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1032,                   Accuracy: 58192/60000 (96.99%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1036,                   Accuracy: 58188/60000 (96.98%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1055,                   Accuracy: 58154/60000 (96.92%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1084,                   Accuracy: 58120/60000 (96.87%)
{0: tensor(96.9117), 10: tensor(96.6850), 20: tensor(96.7667), 30: tensor(96.9500), 40: tensor(96.9667), 50: tensor(96.9917), 60: tensor(96.9767), 70: tensor(96.9583), 80: tensor(96.8567), 90: tensor(96.9200), 100: tensor(96.5283), 110: tensor(96.7117), 120: tensor(96.8800), 130: tensor(96.9300), 140: tensor(96.9533), 150: tensor(96.8500), 160: tensor(96.9483), 170: tensor(96.8600), 180: tensor(96.8767), 190: tensor(96.6633), 200: tensor(96.8150), 210: tensor(96.8367), 220: tensor(96.8833), 230: tensor(96.9717), 240: tensor(96.9033), 250: tensor(97.0067), 260: tensor(96.8850), 270: tensor(96.9667), 280: tensor(96.7717), 290: tensor(96.8967), 300: tensor(96.9167), 310: tensor(96.9333), 320: tensor(96.9867), 330: tensor(96.9800), 340: tensor(96.9233), 350: tensor(96.8667)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=47, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1134,                   Accuracy: 624/2000.0 (31.20%)



-= Testing valid =-
Test set: Average loss: 1.1404,                   Accuracy: 1217/2000.0 (60.85%)



-= Testing valid =-
Test set: Average loss: 2.2765,                   Accuracy: 507/2000.0 (25.35%)



-= Testing valid =-
Test set: Average loss: 0.9153,                   Accuracy: 1420/2000.0 (71.00%)



-= Testing valid =-
Test set: Average loss: 0.4127,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.8176,                   Accuracy: 1513/2000.0 (75.65%)



-= Testing valid =-
Test set: Average loss: 0.3812,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.4756,                   Accuracy: 1697/2000.0 (84.85%)



-= Testing valid =-
Test set: Average loss: 0.2242,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.2228,                   Accuracy: 1871/2000.0 (93.55%)



Epoch 10 train accuracy: 94.06%, valid accuracy 93.55%
-= Testing valid =-
Test set: Average loss: 0.2076,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1562,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1737,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1754,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1341,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1413,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1308,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1122,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.2077,                   Accuracy: 1872/2000.0 (93.60%)



Epoch 20 train accuracy: 95.61%, valid accuracy 93.60%
-= Testing valid =-
Test set: Average loss: 0.1188,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1197,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1109,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1094,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1333,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1075,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1075,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1161,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1051,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 30 train accuracy: 96.65%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.1103,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1072,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0978,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1048,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1101,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1051,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 40 train accuracy: 96.90%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0976,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 50 train accuracy: 97.07%, valid accuracy 97.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1043,                   Accuracy: 58205/60000 (97.01%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1140,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1163,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1217,                   Accuracy: 57897/60000 (96.50%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1229,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1225,                   Accuracy: 57860/60000 (96.43%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1165,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1114,                   Accuracy: 58033/60000 (96.72%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1114,                   Accuracy: 58032/60000 (96.72%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1069,                   Accuracy: 58140/60000 (96.90%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1183,                   Accuracy: 57867/60000 (96.44%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1195,                   Accuracy: 57813/60000 (96.36%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1235,                   Accuracy: 57817/60000 (96.36%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1253,                   Accuracy: 57791/60000 (96.32%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1280,                   Accuracy: 57728/60000 (96.21%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1216,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1162,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1168,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1112,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1228,                   Accuracy: 57721/60000 (96.20%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1200,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1234,                   Accuracy: 57788/60000 (96.31%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1239,                   Accuracy: 57805/60000 (96.34%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1244,                   Accuracy: 57799/60000 (96.33%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1183,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1115,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1106,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1063,                   Accuracy: 58154/60000 (96.92%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1159,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1157,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1214,                   Accuracy: 57924/60000 (96.54%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1215,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1206,                   Accuracy: 57898/60000 (96.50%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1151,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1087,                   Accuracy: 58095/60000 (96.82%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1080,                   Accuracy: 58093/60000 (96.82%)
{0: tensor(97.0083), 10: tensor(96.6883), 20: tensor(96.5717), 30: tensor(96.4950), 40: tensor(96.4717), 50: tensor(96.4333), 60: tensor(96.5750), 70: tensor(96.7217), 80: tensor(96.7200), 90: tensor(96.9000), 100: tensor(96.4450), 110: tensor(96.3550), 120: tensor(96.3617), 130: tensor(96.3183), 140: tensor(96.2133), 150: tensor(96.3567), 160: tensor(96.4917), 170: tensor(96.4400), 180: tensor(96.7383), 190: tensor(96.2017), 200: tensor(96.3567), 210: tensor(96.3133), 220: tensor(96.3417), 230: tensor(96.3317), 240: tensor(96.4600), 250: tensor(96.6733), 260: tensor(96.7167), 270: tensor(96.9233), 280: tensor(96.5350), 290: tensor(96.5750), 300: tensor(96.5400), 310: tensor(96.5350), 320: tensor(96.4967), 330: tensor(96.6833), 340: tensor(96.8250), 350: tensor(96.8217)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=48, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 13.1751,                   Accuracy: 217/2000.0 (10.85%)



-= Testing valid =-
Test set: Average loss: 2.4631,                   Accuracy: 222/2000.0 (11.10%)



-= Testing valid =-
Test set: Average loss: 3.4140,                   Accuracy: 420/2000.0 (21.00%)



-= Testing valid =-
Test set: Average loss: 1.8256,                   Accuracy: 800/2000.0 (40.00%)



-= Testing valid =-
Test set: Average loss: 1.5359,                   Accuracy: 969/2000.0 (48.45%)



-= Testing valid =-
Test set: Average loss: 0.6155,                   Accuracy: 1600/2000.0 (80.00%)



-= Testing valid =-
Test set: Average loss: 0.5890,                   Accuracy: 1649/2000.0 (82.45%)



-= Testing valid =-
Test set: Average loss: 0.1919,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1897,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.2282,                   Accuracy: 1859/2000.0 (92.95%)



Epoch 10 train accuracy: 92.03%, valid accuracy 92.95%
-= Testing valid =-
Test set: Average loss: 0.1993,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1410,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1777,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1215,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1448,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1126,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.2169,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.1842,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 20 train accuracy: 95.20%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.1118,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1052,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1182,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 30 train accuracy: 96.25%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0720,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 40 train accuracy: 96.95%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0752,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0657,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 50 train accuracy: 96.62%, valid accuracy 97.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1087,                   Accuracy: 58075/60000 (96.79%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1145,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1214,                   Accuracy: 57809/60000 (96.35%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1307,                   Accuracy: 57658/60000 (96.10%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1329,                   Accuracy: 57595/60000 (95.99%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1301,                   Accuracy: 57601/60000 (96.00%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1271,                   Accuracy: 57678/60000 (96.13%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1187,                   Accuracy: 57818/60000 (96.36%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1177,                   Accuracy: 57863/60000 (96.44%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1152,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1199,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1261,                   Accuracy: 57747/60000 (96.25%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1369,                   Accuracy: 57488/60000 (95.81%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1392,                   Accuracy: 57475/60000 (95.79%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1371,                   Accuracy: 57462/60000 (95.77%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1331,                   Accuracy: 57541/60000 (95.90%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1252,                   Accuracy: 57699/60000 (96.17%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1224,                   Accuracy: 57767/60000 (96.28%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1186,                   Accuracy: 57873/60000 (96.46%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1240,                   Accuracy: 57775/60000 (96.29%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1264,                   Accuracy: 57733/60000 (96.22%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1350,                   Accuracy: 57538/60000 (95.90%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1328,                   Accuracy: 57616/60000 (96.03%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1287,                   Accuracy: 57669/60000 (96.11%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1236,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1146,                   Accuracy: 57930/60000 (96.55%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1112,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1107,                   Accuracy: 58034/60000 (96.72%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1168,                   Accuracy: 57909/60000 (96.51%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1214,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1287,                   Accuracy: 57684/60000 (96.14%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1284,                   Accuracy: 57694/60000 (96.16%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1228,                   Accuracy: 57763/60000 (96.27%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1188,                   Accuracy: 57871/60000 (96.45%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1108,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1089,                   Accuracy: 58015/60000 (96.69%)
{0: tensor(96.7917), 10: tensor(96.5583), 20: tensor(96.3483), 30: tensor(96.0967), 40: tensor(95.9917), 50: tensor(96.0017), 60: tensor(96.1300), 70: tensor(96.3633), 80: tensor(96.4383), 90: tensor(96.5633), 100: tensor(96.4117), 110: tensor(96.2450), 120: tensor(95.8133), 130: tensor(95.7917), 140: tensor(95.7700), 150: tensor(95.9017), 160: tensor(96.1650), 170: tensor(96.2783), 180: tensor(96.4550), 190: tensor(96.2917), 200: tensor(96.2217), 210: tensor(95.8967), 220: tensor(96.0267), 230: tensor(96.1150), 240: tensor(96.2600), 250: tensor(96.5500), 260: tensor(96.6800), 270: tensor(96.7233), 280: tensor(96.5150), 290: tensor(96.4183), 300: tensor(96.1400), 310: tensor(96.1567), 320: tensor(96.2717), 330: tensor(96.4517), 340: tensor(96.6167), 350: tensor(96.6917)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=49, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9155,                   Accuracy: 526/2000.0 (26.30%)



-= Testing valid =-
Test set: Average loss: 1.6339,                   Accuracy: 734/2000.0 (36.70%)



-= Testing valid =-
Test set: Average loss: 1.7463,                   Accuracy: 743/2000.0 (37.15%)



-= Testing valid =-
Test set: Average loss: 0.5837,                   Accuracy: 1658/2000.0 (82.90%)



-= Testing valid =-
Test set: Average loss: 2.3770,                   Accuracy: 903/2000.0 (45.15%)



-= Testing valid =-
Test set: Average loss: 0.5523,                   Accuracy: 1597/2000.0 (79.85%)



-= Testing valid =-
Test set: Average loss: 0.3969,                   Accuracy: 1722/2000.0 (86.10%)



-= Testing valid =-
Test set: Average loss: 0.3606,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.2991,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.3531,                   Accuracy: 1774/2000.0 (88.70%)



Epoch 10 train accuracy: 92.25%, valid accuracy 88.70%
-= Testing valid =-
Test set: Average loss: 0.1470,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1442,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1531,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1329,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1467,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1598,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1542,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1235,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1288,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1565,                   Accuracy: 1888/2000.0 (94.40%)



Epoch 20 train accuracy: 95.31%, valid accuracy 94.40%
-= Testing valid =-
Test set: Average loss: 0.1213,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.1202,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1233,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 30 train accuracy: 96.55%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 40 train accuracy: 96.68%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0775,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 50 train accuracy: 96.75%, valid accuracy 97.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1240,                   Accuracy: 57797/60000 (96.33%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1302,                   Accuracy: 57629/60000 (96.05%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1310,                   Accuracy: 57577/60000 (95.96%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1325,                   Accuracy: 57581/60000 (95.97%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1300,                   Accuracy: 57647/60000 (96.08%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1266,                   Accuracy: 57735/60000 (96.22%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1245,                   Accuracy: 57779/60000 (96.30%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1217,                   Accuracy: 57817/60000 (96.36%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1260,                   Accuracy: 57663/60000 (96.11%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1229,                   Accuracy: 57776/60000 (96.29%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1291,                   Accuracy: 57642/60000 (96.07%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1322,                   Accuracy: 57531/60000 (95.89%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1349,                   Accuracy: 57494/60000 (95.82%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1304,                   Accuracy: 57623/60000 (96.04%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1283,                   Accuracy: 57697/60000 (96.16%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1264,                   Accuracy: 57716/60000 (96.19%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1244,                   Accuracy: 57743/60000 (96.24%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1261,                   Accuracy: 57669/60000 (96.11%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1244,                   Accuracy: 57769/60000 (96.28%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1317,                   Accuracy: 57576/60000 (95.96%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1314,                   Accuracy: 57565/60000 (95.94%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1346,                   Accuracy: 57520/60000 (95.87%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1306,                   Accuracy: 57611/60000 (96.02%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1281,                   Accuracy: 57665/60000 (96.11%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1278,                   Accuracy: 57701/60000 (96.17%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1247,                   Accuracy: 57738/60000 (96.23%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1263,                   Accuracy: 57723/60000 (96.21%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1247,                   Accuracy: 57798/60000 (96.33%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1326,                   Accuracy: 57586/60000 (95.98%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1304,                   Accuracy: 57634/60000 (96.06%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1336,                   Accuracy: 57594/60000 (95.99%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1308,                   Accuracy: 57649/60000 (96.08%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1281,                   Accuracy: 57728/60000 (96.21%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1267,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1235,                   Accuracy: 57769/60000 (96.28%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1279,                   Accuracy: 57649/60000 (96.08%)
{0: tensor(96.3283), 10: tensor(96.0483), 20: tensor(95.9617), 30: tensor(95.9683), 40: tensor(96.0783), 50: tensor(96.2250), 60: tensor(96.2983), 70: tensor(96.3617), 80: tensor(96.1050), 90: tensor(96.2933), 100: tensor(96.0700), 110: tensor(95.8850), 120: tensor(95.8233), 130: tensor(96.0383), 140: tensor(96.1617), 150: tensor(96.1933), 160: tensor(96.2383), 170: tensor(96.1150), 180: tensor(96.2817), 190: tensor(95.9600), 200: tensor(95.9417), 210: tensor(95.8667), 220: tensor(96.0183), 230: tensor(96.1083), 240: tensor(96.1683), 250: tensor(96.2300), 260: tensor(96.2050), 270: tensor(96.3300), 280: tensor(95.9767), 290: tensor(96.0567), 300: tensor(95.9900), 310: tensor(96.0817), 320: tensor(96.2133), 330: tensor(96.2600), 340: tensor(96.2817), 350: tensor(96.0817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=50, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3449,                   Accuracy: 209/2000.0 (10.45%)



-= Testing valid =-
Test set: Average loss: 1.5938,                   Accuracy: 765/2000.0 (38.25%)



-= Testing valid =-
Test set: Average loss: 1.3480,                   Accuracy: 1012/2000.0 (50.60%)



-= Testing valid =-
Test set: Average loss: 0.7710,                   Accuracy: 1497/2000.0 (74.85%)



-= Testing valid =-
Test set: Average loss: 1.3999,                   Accuracy: 1130/2000.0 (56.50%)



-= Testing valid =-
Test set: Average loss: 0.4861,                   Accuracy: 1699/2000.0 (84.95%)



-= Testing valid =-
Test set: Average loss: 0.4450,                   Accuracy: 1723/2000.0 (86.15%)



-= Testing valid =-
Test set: Average loss: 0.3192,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.5681,                   Accuracy: 1586/2000.0 (79.30%)



-= Testing valid =-
Test set: Average loss: 0.3560,                   Accuracy: 1783/2000.0 (89.15%)



Epoch 10 train accuracy: 93.50%, valid accuracy 89.15%
-= Testing valid =-
Test set: Average loss: 0.2137,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1693,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.2540,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.1633,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1430,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1386,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1894,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1708,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1630,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1588,                   Accuracy: 1902/2000.0 (95.10%)



Epoch 20 train accuracy: 95.85%, valid accuracy 95.10%
-= Testing valid =-
Test set: Average loss: 0.1312,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1496,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1235,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1147,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1602,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1175,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1544,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1096,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1173,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 30 train accuracy: 96.75%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.1136,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1109,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1288,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1233,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1096,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1075,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1068,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 40 train accuracy: 97.06%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0937,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 50 train accuracy: 97.34%, valid accuracy 96.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1147,                   Accuracy: 58029/60000 (96.71%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1233,                   Accuracy: 57859/60000 (96.43%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1212,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1256,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1278,                   Accuracy: 57805/60000 (96.34%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1287,                   Accuracy: 57842/60000 (96.40%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1324,                   Accuracy: 57807/60000 (96.35%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1290,                   Accuracy: 57794/60000 (96.32%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1251,                   Accuracy: 57817/60000 (96.36%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1195,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1319,                   Accuracy: 57691/60000 (96.15%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1265,                   Accuracy: 57791/60000 (96.32%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1305,                   Accuracy: 57738/60000 (96.23%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1333,                   Accuracy: 57659/60000 (96.10%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1361,                   Accuracy: 57643/60000 (96.07%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1375,                   Accuracy: 57618/60000 (96.03%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1343,                   Accuracy: 57644/60000 (96.07%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1307,                   Accuracy: 57670/60000 (96.12%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1226,                   Accuracy: 57843/60000 (96.40%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1298,                   Accuracy: 57699/60000 (96.17%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1263,                   Accuracy: 57762/60000 (96.27%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1288,                   Accuracy: 57744/60000 (96.24%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1296,                   Accuracy: 57765/60000 (96.28%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1324,                   Accuracy: 57727/60000 (96.21%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1325,                   Accuracy: 57757/60000 (96.26%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1267,                   Accuracy: 57832/60000 (96.39%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1239,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1162,                   Accuracy: 57977/60000 (96.63%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1202,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1194,                   Accuracy: 57931/60000 (96.55%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1242,                   Accuracy: 57860/60000 (96.43%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1245,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1260,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1285,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1232,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1206,                   Accuracy: 57964/60000 (96.61%)
{0: tensor(96.7150), 10: tensor(96.4317), 20: tensor(96.5183), 30: tensor(96.4433), 40: tensor(96.3417), 50: tensor(96.4033), 60: tensor(96.3450), 70: tensor(96.3233), 80: tensor(96.3617), 90: tensor(96.5833), 100: tensor(96.1517), 110: tensor(96.3183), 120: tensor(96.2300), 130: tensor(96.0983), 140: tensor(96.0717), 150: tensor(96.0300), 160: tensor(96.0733), 170: tensor(96.1167), 180: tensor(96.4050), 190: tensor(96.1650), 200: tensor(96.2700), 210: tensor(96.2400), 220: tensor(96.2750), 230: tensor(96.2117), 240: tensor(96.2617), 250: tensor(96.3867), 260: tensor(96.4100), 270: tensor(96.6283), 280: tensor(96.5133), 290: tensor(96.5517), 300: tensor(96.4333), 310: tensor(96.4717), 320: tensor(96.4533), 330: tensor(96.4350), 340: tensor(96.5217), 350: tensor(96.6067)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=51, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.8066,                   Accuracy: 225/2000.0 (11.25%)



-= Testing valid =-
Test set: Average loss: 1.5893,                   Accuracy: 858/2000.0 (42.90%)



-= Testing valid =-
Test set: Average loss: 2.1524,                   Accuracy: 700/2000.0 (35.00%)



-= Testing valid =-
Test set: Average loss: 0.4800,                   Accuracy: 1736/2000.0 (86.80%)



-= Testing valid =-
Test set: Average loss: 0.4828,                   Accuracy: 1686/2000.0 (84.30%)



-= Testing valid =-
Test set: Average loss: 0.3201,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2300,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.3075,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.1673,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1981,                   Accuracy: 1874/2000.0 (93.70%)



Epoch 10 train accuracy: 93.15%, valid accuracy 93.70%
-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1304,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1289,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1316,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1169,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1104,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1665,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.0877,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 20 train accuracy: 96.18%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 30 train accuracy: 96.78%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 40 train accuracy: 97.09%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0710,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0691,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 50 train accuracy: 97.20%, valid accuracy 98.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1096,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1260,                   Accuracy: 57663/60000 (96.11%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1205,                   Accuracy: 57787/60000 (96.31%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1156,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1112,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1114,                   Accuracy: 57966/60000 (96.61%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1083,                   Accuracy: 58094/60000 (96.82%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1084,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1142,                   Accuracy: 57931/60000 (96.55%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1080,                   Accuracy: 58083/60000 (96.81%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1257,                   Accuracy: 57643/60000 (96.07%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1181,                   Accuracy: 57821/60000 (96.37%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1140,                   Accuracy: 57928/60000 (96.55%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1100,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1121,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1113,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1135,                   Accuracy: 57916/60000 (96.53%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1240,                   Accuracy: 57692/60000 (96.15%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1133,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1312,                   Accuracy: 57508/60000 (95.85%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1222,                   Accuracy: 57711/60000 (96.18%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1172,                   Accuracy: 57873/60000 (96.46%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1108,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1122,                   Accuracy: 57940/60000 (96.57%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1120,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1143,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1267,                   Accuracy: 57659/60000 (96.10%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1144,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1304,                   Accuracy: 57509/60000 (95.85%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1237,                   Accuracy: 57701/60000 (96.17%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1188,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1123,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1107,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1090,                   Accuracy: 58087/60000 (96.81%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1096,                   Accuracy: 58034/60000 (96.72%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1170,                   Accuracy: 57870/60000 (96.45%)
{0: tensor(96.7750), 10: tensor(96.1050), 20: tensor(96.3117), 30: tensor(96.5683), 40: tensor(96.5333), 50: tensor(96.6100), 60: tensor(96.8233), 70: tensor(96.7717), 80: tensor(96.5517), 90: tensor(96.8050), 100: tensor(96.0717), 110: tensor(96.3683), 120: tensor(96.5467), 130: tensor(96.6217), 140: tensor(96.5383), 150: tensor(96.6650), 160: tensor(96.5267), 170: tensor(96.1533), 180: tensor(96.6117), 190: tensor(95.8467), 200: tensor(96.1850), 210: tensor(96.4550), 220: tensor(96.6017), 230: tensor(96.5667), 240: tensor(96.6167), 250: tensor(96.5317), 260: tensor(96.0983), 270: tensor(96.6117), 280: tensor(95.8483), 290: tensor(96.1683), 300: tensor(96.4300), 310: tensor(96.5450), 320: tensor(96.6200), 330: tensor(96.8117), 340: tensor(96.7233), 350: tensor(96.4500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=52, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3192,                   Accuracy: 416/2000.0 (20.80%)



-= Testing valid =-
Test set: Average loss: 2.1409,                   Accuracy: 625/2000.0 (31.25%)



-= Testing valid =-
Test set: Average loss: 0.8873,                   Accuracy: 1354/2000.0 (67.70%)



-= Testing valid =-
Test set: Average loss: 1.1075,                   Accuracy: 1169/2000.0 (58.45%)



-= Testing valid =-
Test set: Average loss: 0.6697,                   Accuracy: 1567/2000.0 (78.35%)



-= Testing valid =-
Test set: Average loss: 0.4435,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.2823,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.3222,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.2634,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2371,                   Accuracy: 1859/2000.0 (92.95%)



Epoch 10 train accuracy: 93.36%, valid accuracy 92.95%
-= Testing valid =-
Test set: Average loss: 0.1659,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1809,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1700,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1565,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1698,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1438,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1822,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1959,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1648,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1253,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 20 train accuracy: 95.95%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.1380,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1389,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1508,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1148,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1306,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1303,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1608,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1372,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1309,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1221,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 30 train accuracy: 96.61%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.1313,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1302,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1160,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1292,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1088,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1236,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1185,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1347,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1096,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 40 train accuracy: 97.15%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.1097,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1037,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1134,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1079,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1092,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1193,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1126,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 50 train accuracy: 97.16%, valid accuracy 97.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1074,                   Accuracy: 58230/60000 (97.05%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1141,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1146,                   Accuracy: 58075/60000 (96.79%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1214,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1236,                   Accuracy: 57966/60000 (96.61%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1249,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1216,                   Accuracy: 58028/60000 (96.71%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1170,                   Accuracy: 58094/60000 (96.82%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1123,                   Accuracy: 58130/60000 (96.88%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1065,                   Accuracy: 58254/60000 (97.09%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1121,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1128,                   Accuracy: 58111/60000 (96.85%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1196,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1237,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1257,                   Accuracy: 57930/60000 (96.55%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1228,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1202,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1187,                   Accuracy: 57983/60000 (96.64%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1118,                   Accuracy: 58129/60000 (96.88%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1167,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1182,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1249,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1275,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1278,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1264,                   Accuracy: 57928/60000 (96.55%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1215,                   Accuracy: 57979/60000 (96.63%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1190,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1121,                   Accuracy: 58122/60000 (96.87%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1188,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1189,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1270,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1281,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1285,                   Accuracy: 57870/60000 (96.45%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1260,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1191,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1139,                   Accuracy: 58086/60000 (96.81%)
{0: tensor(97.0500), 10: tensor(96.7417), 20: tensor(96.7917), 30: tensor(96.6333), 40: tensor(96.6100), 50: tensor(96.5450), 60: tensor(96.7133), 70: tensor(96.8233), 80: tensor(96.8833), 90: tensor(97.0900), 100: tensor(96.8083), 110: tensor(96.8517), 120: tensor(96.6833), 130: tensor(96.6150), 140: tensor(96.5500), 150: tensor(96.6883), 160: tensor(96.6717), 170: tensor(96.6383), 180: tensor(96.8817), 190: tensor(96.6883), 200: tensor(96.6200), 210: tensor(96.5333), 220: tensor(96.4717), 230: tensor(96.4717), 240: tensor(96.5467), 250: tensor(96.6317), 260: tensor(96.5933), 270: tensor(96.8700), 280: tensor(96.5450), 290: tensor(96.6000), 300: tensor(96.4733), 310: tensor(96.4467), 320: tensor(96.4500), 330: tensor(96.5750), 340: tensor(96.7300), 350: tensor(96.8100)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=53, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1748,                   Accuracy: 543/2000.0 (27.15%)



-= Testing valid =-
Test set: Average loss: 1.1740,                   Accuracy: 1145/2000.0 (57.25%)



-= Testing valid =-
Test set: Average loss: 1.1168,                   Accuracy: 1112/2000.0 (55.60%)



-= Testing valid =-
Test set: Average loss: 0.8419,                   Accuracy: 1404/2000.0 (70.20%)



-= Testing valid =-
Test set: Average loss: 0.3155,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.2722,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 1.2554,                   Accuracy: 1188/2000.0 (59.40%)



-= Testing valid =-
Test set: Average loss: 0.3189,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2812,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2030,                   Accuracy: 1876/2000.0 (93.80%)



Epoch 10 train accuracy: 94.29%, valid accuracy 93.80%
-= Testing valid =-
Test set: Average loss: 0.1957,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1358,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1688,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.2324,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1437,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1256,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1807,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1347,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1451,                   Accuracy: 1914/2000.0 (95.70%)



Epoch 20 train accuracy: 95.97%, valid accuracy 95.70%
-= Testing valid =-
Test set: Average loss: 0.1170,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1153,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1180,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1058,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1347,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1051,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1080,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1261,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 30 train accuracy: 96.70%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.1129,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 40 train accuracy: 97.31%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1020,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 50 train accuracy: 97.32%, valid accuracy 97.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0970,                   Accuracy: 58285/60000 (97.14%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1029,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1025,                   Accuracy: 58197/60000 (97.00%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1097,                   Accuracy: 58077/60000 (96.79%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1102,                   Accuracy: 58098/60000 (96.83%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1096,                   Accuracy: 58154/60000 (96.92%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1090,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1027,                   Accuracy: 58230/60000 (97.05%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1040,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1010,                   Accuracy: 58176/60000 (96.96%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1063,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1067,                   Accuracy: 58084/60000 (96.81%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1147,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1148,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1138,                   Accuracy: 58033/60000 (96.72%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1148,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1051,                   Accuracy: 58154/60000 (96.92%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1057,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1037,                   Accuracy: 58138/60000 (96.90%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1080,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1056,                   Accuracy: 58091/60000 (96.82%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1136,                   Accuracy: 57949/60000 (96.58%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1127,                   Accuracy: 58022/60000 (96.70%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1114,                   Accuracy: 58074/60000 (96.79%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1118,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1021,                   Accuracy: 58221/60000 (97.04%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1003,                   Accuracy: 58238/60000 (97.06%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0984,                   Accuracy: 58248/60000 (97.08%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1030,                   Accuracy: 58147/60000 (96.91%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1012,                   Accuracy: 58207/60000 (97.01%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1089,                   Accuracy: 58073/60000 (96.79%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1087,                   Accuracy: 58132/60000 (96.89%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1072,                   Accuracy: 58180/60000 (96.97%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1068,                   Accuracy: 58185/60000 (96.97%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1000,                   Accuracy: 58282/60000 (97.14%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0997,                   Accuracy: 58249/60000 (97.08%)
{0: tensor(97.1417), 10: tensor(96.9500), 20: tensor(96.9950), 30: tensor(96.7950), 40: tensor(96.8300), 50: tensor(96.9233), 60: tensor(96.9417), 70: tensor(97.0500), 80: tensor(96.9100), 90: tensor(96.9600), 100: tensor(96.8283), 110: tensor(96.8067), 120: tensor(96.5600), 130: tensor(96.6900), 140: tensor(96.7217), 150: tensor(96.6600), 160: tensor(96.9233), 170: tensor(96.8667), 180: tensor(96.8967), 190: tensor(96.7533), 200: tensor(96.8183), 210: tensor(96.5817), 220: tensor(96.7033), 230: tensor(96.7900), 240: tensor(96.7283), 250: tensor(97.0350), 260: tensor(97.0633), 270: tensor(97.0800), 280: tensor(96.9117), 290: tensor(97.0117), 300: tensor(96.7883), 310: tensor(96.8867), 320: tensor(96.9667), 330: tensor(96.9750), 340: tensor(97.1367), 350: tensor(97.0817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=54, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9295,                   Accuracy: 481/2000.0 (24.05%)



-= Testing valid =-
Test set: Average loss: 1.7583,                   Accuracy: 749/2000.0 (37.45%)



-= Testing valid =-
Test set: Average loss: 1.5827,                   Accuracy: 1040/2000.0 (52.00%)



-= Testing valid =-
Test set: Average loss: 0.7526,                   Accuracy: 1534/2000.0 (76.70%)



-= Testing valid =-
Test set: Average loss: 0.4875,                   Accuracy: 1696/2000.0 (84.80%)



-= Testing valid =-
Test set: Average loss: 0.2862,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2660,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2189,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2275,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1854,                   Accuracy: 1900/2000.0 (95.00%)



Epoch 10 train accuracy: 92.54%, valid accuracy 95.00%
-= Testing valid =-
Test set: Average loss: 0.1785,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1469,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1342,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1548,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1466,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1269,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1535,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1462,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1323,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1154,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 20 train accuracy: 95.25%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1177,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1187,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1243,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1107,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 30 train accuracy: 96.18%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0947,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 40 train accuracy: 96.76%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 50 train accuracy: 97.05%, valid accuracy 97.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1140,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1225,                   Accuracy: 57867/60000 (96.44%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1220,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1281,                   Accuracy: 57802/60000 (96.34%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1313,                   Accuracy: 57729/60000 (96.21%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1313,                   Accuracy: 57752/60000 (96.25%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1273,                   Accuracy: 57798/60000 (96.33%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1253,                   Accuracy: 57725/60000 (96.21%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1253,                   Accuracy: 57708/60000 (96.18%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1186,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1281,                   Accuracy: 57731/60000 (96.22%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1273,                   Accuracy: 57773/60000 (96.29%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1351,                   Accuracy: 57657/60000 (96.10%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1367,                   Accuracy: 57617/60000 (96.03%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1373,                   Accuracy: 57541/60000 (95.90%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1359,                   Accuracy: 57609/60000 (96.01%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1333,                   Accuracy: 57565/60000 (95.94%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1377,                   Accuracy: 57342/60000 (95.57%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1289,                   Accuracy: 57669/60000 (96.11%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1394,                   Accuracy: 57420/60000 (95.70%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1332,                   Accuracy: 57643/60000 (96.07%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1378,                   Accuracy: 57554/60000 (95.92%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1351,                   Accuracy: 57597/60000 (96.00%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1330,                   Accuracy: 57653/60000 (96.09%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1302,                   Accuracy: 57659/60000 (96.10%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1249,                   Accuracy: 57739/60000 (96.23%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1269,                   Accuracy: 57641/60000 (96.07%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1202,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1288,                   Accuracy: 57719/60000 (96.20%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1250,                   Accuracy: 57799/60000 (96.33%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1290,                   Accuracy: 57776/60000 (96.29%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1296,                   Accuracy: 57726/60000 (96.21%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1283,                   Accuracy: 57791/60000 (96.32%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1230,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1198,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1190,                   Accuracy: 57880/60000 (96.47%)
{0: tensor(96.6450), 10: tensor(96.4450), 20: tensor(96.4617), 30: tensor(96.3367), 40: tensor(96.2150), 50: tensor(96.2533), 60: tensor(96.3300), 70: tensor(96.2083), 80: tensor(96.1800), 90: tensor(96.5283), 100: tensor(96.2183), 110: tensor(96.2883), 120: tensor(96.0950), 130: tensor(96.0283), 140: tensor(95.9017), 150: tensor(96.0150), 160: tensor(95.9417), 170: tensor(95.5700), 180: tensor(96.1150), 190: tensor(95.7000), 200: tensor(96.0717), 210: tensor(95.9233), 220: tensor(95.9950), 230: tensor(96.0883), 240: tensor(96.0983), 250: tensor(96.2317), 260: tensor(96.0683), 270: tensor(96.4400), 280: tensor(96.1983), 290: tensor(96.3317), 300: tensor(96.2933), 310: tensor(96.2100), 320: tensor(96.3183), 330: tensor(96.4533), 340: tensor(96.4600), 350: tensor(96.4667)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=55, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.4214,                   Accuracy: 288/2000.0 (14.40%)



-= Testing valid =-
Test set: Average loss: 1.6711,                   Accuracy: 806/2000.0 (40.30%)



-= Testing valid =-
Test set: Average loss: 1.1916,                   Accuracy: 1141/2000.0 (57.05%)



-= Testing valid =-
Test set: Average loss: 1.9765,                   Accuracy: 816/2000.0 (40.80%)



-= Testing valid =-
Test set: Average loss: 0.4288,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.2560,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2532,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2993,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.2102,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.3348,                   Accuracy: 1795/2000.0 (89.75%)



Epoch 10 train accuracy: 92.26%, valid accuracy 89.75%
-= Testing valid =-
Test set: Average loss: 0.1856,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1795,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1574,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1782,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1394,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1408,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1787,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1214,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1372,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1570,                   Accuracy: 1907/2000.0 (95.35%)



Epoch 20 train accuracy: 95.40%, valid accuracy 95.35%
-= Testing valid =-
Test set: Average loss: 0.1297,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1135,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1209,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1176,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1179,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1085,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1173,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1133,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 30 train accuracy: 96.21%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.1086,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1115,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1017,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1192,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1052,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 40 train accuracy: 96.64%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0910,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0877,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 50 train accuracy: 96.91%, valid accuracy 97.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1163,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1203,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1167,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1210,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1162,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1149,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1166,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1160,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1177,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1173,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1229,                   Accuracy: 57873/60000 (96.46%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1180,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1223,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1187,                   Accuracy: 57925/60000 (96.54%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1184,                   Accuracy: 57902/60000 (96.50%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1194,                   Accuracy: 57900/60000 (96.50%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1179,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1208,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1203,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1241,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1197,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1243,                   Accuracy: 57852/60000 (96.42%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1192,                   Accuracy: 57892/60000 (96.49%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1182,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1188,                   Accuracy: 57918/60000 (96.53%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1163,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1195,                   Accuracy: 57906/60000 (96.51%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1181,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1206,                   Accuracy: 57898/60000 (96.50%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1176,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1226,                   Accuracy: 57881/60000 (96.47%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1166,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1152,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1165,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1150,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1169,                   Accuracy: 57967/60000 (96.61%)
{0: tensor(96.7267), 10: tensor(96.5383), 20: tensor(96.6400), 30: tensor(96.5583), 40: tensor(96.6467), 50: tensor(96.5950), 60: tensor(96.6033), 70: tensor(96.6533), 80: tensor(96.6233), 90: tensor(96.7400), 100: tensor(96.4550), 110: tensor(96.6233), 120: tensor(96.4750), 130: tensor(96.5417), 140: tensor(96.5033), 150: tensor(96.5000), 160: tensor(96.5850), 170: tensor(96.5250), 180: tensor(96.5717), 190: tensor(96.3767), 200: tensor(96.5450), 210: tensor(96.4200), 220: tensor(96.4867), 230: tensor(96.5617), 240: tensor(96.5300), 250: tensor(96.6033), 260: tensor(96.5100), 270: tensor(96.6433), 280: tensor(96.4967), 290: tensor(96.6000), 300: tensor(96.4683), 310: tensor(96.6400), 320: tensor(96.6050), 330: tensor(96.6167), 340: tensor(96.6967), 350: tensor(96.6117)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=56, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6731,                   Accuracy: 442/2000.0 (22.10%)



-= Testing valid =-
Test set: Average loss: 2.0932,                   Accuracy: 447/2000.0 (22.35%)



-= Testing valid =-
Test set: Average loss: 1.3221,                   Accuracy: 1086/2000.0 (54.30%)



-= Testing valid =-
Test set: Average loss: 1.4921,                   Accuracy: 1178/2000.0 (58.90%)



-= Testing valid =-
Test set: Average loss: 1.8136,                   Accuracy: 902/2000.0 (45.10%)



-= Testing valid =-
Test set: Average loss: 0.4399,                   Accuracy: 1737/2000.0 (86.85%)



-= Testing valid =-
Test set: Average loss: 0.3594,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.2876,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.3673,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.2425,                   Accuracy: 1857/2000.0 (92.85%)



Epoch 10 train accuracy: 93.20%, valid accuracy 92.85%
-= Testing valid =-
Test set: Average loss: 0.2011,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1376,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1750,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1977,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.1575,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1618,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1689,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1726,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1117,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1172,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 20 train accuracy: 95.81%, valid accuracy 96.45%
-= Testing valid =-
Test set: Average loss: 0.1174,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1217,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1103,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1091,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1223,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1150,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1183,                   Accuracy: 1920/2000.0 (96.00%)



Epoch 30 train accuracy: 96.51%, valid accuracy 96.00%
-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1030,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1011,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 40 train accuracy: 97.06%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0825,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 50 train accuracy: 97.28%, valid accuracy 97.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1212,                   Accuracy: 57881/60000 (96.47%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1318,                   Accuracy: 57690/60000 (96.15%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1265,                   Accuracy: 57757/60000 (96.26%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1252,                   Accuracy: 57770/60000 (96.28%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1211,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1187,                   Accuracy: 57890/60000 (96.48%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1187,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1167,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1227,                   Accuracy: 57806/60000 (96.34%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1208,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1327,                   Accuracy: 57653/60000 (96.09%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1239,                   Accuracy: 57808/60000 (96.35%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1206,                   Accuracy: 57862/60000 (96.44%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1181,                   Accuracy: 57865/60000 (96.44%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1151,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1148,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1150,                   Accuracy: 57966/60000 (96.61%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1193,                   Accuracy: 57909/60000 (96.51%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1175,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1274,                   Accuracy: 57768/60000 (96.28%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1213,                   Accuracy: 57821/60000 (96.37%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1189,                   Accuracy: 57905/60000 (96.51%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1157,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1128,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1129,                   Accuracy: 58007/60000 (96.68%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1129,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1199,                   Accuracy: 57879/60000 (96.46%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1172,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1258,                   Accuracy: 57789/60000 (96.32%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1242,                   Accuracy: 57817/60000 (96.36%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1236,                   Accuracy: 57813/60000 (96.36%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1197,                   Accuracy: 57871/60000 (96.45%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1172,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1174,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1159,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1239,                   Accuracy: 57789/60000 (96.32%)
{0: tensor(96.4683), 10: tensor(96.1500), 20: tensor(96.2617), 30: tensor(96.2833), 40: tensor(96.4183), 50: tensor(96.4833), 60: tensor(96.5217), 70: tensor(96.5450), 80: tensor(96.3433), 90: tensor(96.5183), 100: tensor(96.0883), 110: tensor(96.3467), 120: tensor(96.4367), 130: tensor(96.4417), 140: tensor(96.5867), 150: tensor(96.6067), 160: tensor(96.6100), 170: tensor(96.5150), 180: tensor(96.5367), 190: tensor(96.2800), 200: tensor(96.3683), 210: tensor(96.5083), 220: tensor(96.5600), 230: tensor(96.6633), 240: tensor(96.6783), 250: tensor(96.6733), 260: tensor(96.4650), 270: tensor(96.5450), 280: tensor(96.3150), 290: tensor(96.3617), 300: tensor(96.3550), 310: tensor(96.4517), 320: tensor(96.5067), 330: tensor(96.5183), 340: tensor(96.4817), 350: tensor(96.3150)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=57, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0924,                   Accuracy: 485/2000.0 (24.25%)



-= Testing valid =-
Test set: Average loss: 2.9787,                   Accuracy: 384/2000.0 (19.20%)



-= Testing valid =-
Test set: Average loss: 0.9901,                   Accuracy: 1268/2000.0 (63.40%)



-= Testing valid =-
Test set: Average loss: 0.7195,                   Accuracy: 1522/2000.0 (76.10%)



-= Testing valid =-
Test set: Average loss: 0.2418,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.3265,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.4828,                   Accuracy: 1660/2000.0 (83.00%)



-= Testing valid =-
Test set: Average loss: 0.5099,                   Accuracy: 1659/2000.0 (82.95%)



-= Testing valid =-
Test set: Average loss: 0.2955,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.2392,                   Accuracy: 1848/2000.0 (92.40%)



Epoch 10 train accuracy: 93.43%, valid accuracy 92.40%
-= Testing valid =-
Test set: Average loss: 0.2159,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.1667,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1358,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1581,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1453,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1452,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1368,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1163,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1322,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 20 train accuracy: 96.07%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.1191,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1262,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1064,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1202,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1225,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1183,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1114,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1067,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 30 train accuracy: 96.32%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1051,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 40 train accuracy: 96.75%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 50 train accuracy: 97.28%, valid accuracy 97.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1099,                   Accuracy: 58118/60000 (96.86%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1158,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1134,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1183,                   Accuracy: 57965/60000 (96.61%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1178,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1156,                   Accuracy: 58026/60000 (96.71%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1148,                   Accuracy: 58002/60000 (96.67%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1116,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1167,                   Accuracy: 57949/60000 (96.58%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1144,                   Accuracy: 57981/60000 (96.64%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1207,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1198,                   Accuracy: 57825/60000 (96.38%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1236,                   Accuracy: 57792/60000 (96.32%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1245,                   Accuracy: 57781/60000 (96.30%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1221,                   Accuracy: 57825/60000 (96.38%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1222,                   Accuracy: 57874/60000 (96.46%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1165,                   Accuracy: 57928/60000 (96.55%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1199,                   Accuracy: 57874/60000 (96.46%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1173,                   Accuracy: 57912/60000 (96.52%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1236,                   Accuracy: 57763/60000 (96.27%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1171,                   Accuracy: 57880/60000 (96.47%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1200,                   Accuracy: 57856/60000 (96.43%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1187,                   Accuracy: 57902/60000 (96.50%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1160,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1144,                   Accuracy: 58026/60000 (96.71%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1082,                   Accuracy: 58094/60000 (96.82%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1110,                   Accuracy: 58076/60000 (96.79%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1101,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1166,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1111,                   Accuracy: 58042/60000 (96.74%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1149,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1132,                   Accuracy: 58035/60000 (96.72%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1114,                   Accuracy: 58064/60000 (96.77%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1097,                   Accuracy: 58091/60000 (96.82%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1059,                   Accuracy: 58136/60000 (96.89%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1097,                   Accuracy: 58099/60000 (96.83%)
{0: tensor(96.8633), 10: tensor(96.6400), 20: tensor(96.6583), 30: tensor(96.6083), 40: tensor(96.5833), 50: tensor(96.7100), 60: tensor(96.6700), 70: tensor(96.7467), 80: tensor(96.5817), 90: tensor(96.6350), 100: tensor(96.4100), 110: tensor(96.3750), 120: tensor(96.3200), 130: tensor(96.3017), 140: tensor(96.3750), 150: tensor(96.4567), 160: tensor(96.5467), 170: tensor(96.4567), 180: tensor(96.5200), 190: tensor(96.2717), 200: tensor(96.4667), 210: tensor(96.4267), 220: tensor(96.5033), 230: tensor(96.6067), 240: tensor(96.7100), 250: tensor(96.8233), 260: tensor(96.7933), 270: tensor(96.8367), 280: tensor(96.5633), 290: tensor(96.7367), 300: tensor(96.6750), 310: tensor(96.7250), 320: tensor(96.7733), 330: tensor(96.8183), 340: tensor(96.8933), 350: tensor(96.8317)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=58, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5714,                   Accuracy: 407/2000.0 (20.35%)



-= Testing valid =-
Test set: Average loss: 1.1123,                   Accuracy: 1239/2000.0 (61.95%)



-= Testing valid =-
Test set: Average loss: 0.6845,                   Accuracy: 1560/2000.0 (78.00%)



-= Testing valid =-
Test set: Average loss: 0.8184,                   Accuracy: 1320/2000.0 (66.00%)



-= Testing valid =-
Test set: Average loss: 0.2913,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.3067,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2286,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.1515,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1637,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.2416,                   Accuracy: 1850/2000.0 (92.50%)



Epoch 10 train accuracy: 94.03%, valid accuracy 92.50%
-= Testing valid =-
Test set: Average loss: 0.2060,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1501,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1034,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1153,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1592,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1068,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1195,                   Accuracy: 1918/2000.0 (95.90%)



Epoch 20 train accuracy: 95.81%, valid accuracy 95.90%
-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1098,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 30 train accuracy: 96.72%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0775,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 40 train accuracy: 97.06%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0686,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0619,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0674,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 50 train accuracy: 97.25%, valid accuracy 97.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0929,                   Accuracy: 58350/60000 (97.25%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1014,                   Accuracy: 58172/60000 (96.95%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1019,                   Accuracy: 58131/60000 (96.89%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1071,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1100,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1079,                   Accuracy: 58087/60000 (96.81%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1039,                   Accuracy: 58162/60000 (96.94%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0983,                   Accuracy: 58242/60000 (97.07%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.0993,                   Accuracy: 58210/60000 (97.02%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0980,                   Accuracy: 58215/60000 (97.03%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1098,                   Accuracy: 57978/60000 (96.63%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1120,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1168,                   Accuracy: 57862/60000 (96.44%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1174,                   Accuracy: 57859/60000 (96.43%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1157,                   Accuracy: 57925/60000 (96.54%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1098,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1045,                   Accuracy: 58080/60000 (96.80%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1072,                   Accuracy: 57993/60000 (96.65%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1030,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1141,                   Accuracy: 57880/60000 (96.47%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1132,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1167,                   Accuracy: 57856/60000 (96.43%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1146,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1129,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1059,                   Accuracy: 58136/60000 (96.89%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.0995,                   Accuracy: 58197/60000 (97.00%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1010,                   Accuracy: 58173/60000 (96.96%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0958,                   Accuracy: 58289/60000 (97.15%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1034,                   Accuracy: 58130/60000 (96.88%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1024,                   Accuracy: 58150/60000 (96.92%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1067,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1068,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1054,                   Accuracy: 58111/60000 (96.85%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1006,                   Accuracy: 58230/60000 (97.05%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0941,                   Accuracy: 58298/60000 (97.16%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0953,                   Accuracy: 58316/60000 (97.19%)
{0: tensor(97.2500), 10: tensor(96.9533), 20: tensor(96.8850), 30: tensor(96.8017), 40: tensor(96.6967), 50: tensor(96.8117), 60: tensor(96.9367), 70: tensor(97.0700), 80: tensor(97.0167), 90: tensor(97.0250), 100: tensor(96.6300), 110: tensor(96.5833), 120: tensor(96.4367), 130: tensor(96.4317), 140: tensor(96.5417), 150: tensor(96.7467), 160: tensor(96.8000), 170: tensor(96.6550), 180: tensor(96.8567), 190: tensor(96.4667), 200: tensor(96.5350), 210: tensor(96.4267), 220: tensor(96.5383), 230: tensor(96.6600), 240: tensor(96.8933), 250: tensor(96.9950), 260: tensor(96.9550), 270: tensor(97.1483), 280: tensor(96.8833), 290: tensor(96.9167), 300: tensor(96.7700), 310: tensor(96.7550), 320: tensor(96.8517), 330: tensor(97.0500), 340: tensor(97.1633), 350: tensor(97.1933)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=59, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4031,                   Accuracy: 387/2000.0 (19.35%)



-= Testing valid =-
Test set: Average loss: 1.8010,                   Accuracy: 614/2000.0 (30.70%)



-= Testing valid =-
Test set: Average loss: 1.5687,                   Accuracy: 861/2000.0 (43.05%)



-= Testing valid =-
Test set: Average loss: 1.4379,                   Accuracy: 1038/2000.0 (51.90%)



-= Testing valid =-
Test set: Average loss: 0.5505,                   Accuracy: 1643/2000.0 (82.15%)



-= Testing valid =-
Test set: Average loss: 0.5284,                   Accuracy: 1654/2000.0 (82.70%)



-= Testing valid =-
Test set: Average loss: 0.4499,                   Accuracy: 1710/2000.0 (85.50%)



-= Testing valid =-
Test set: Average loss: 0.2399,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2356,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2418,                   Accuracy: 1866/2000.0 (93.30%)



Epoch 10 train accuracy: 93.34%, valid accuracy 93.30%
-= Testing valid =-
Test set: Average loss: 0.2146,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.1812,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1966,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1987,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1781,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2206,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.1834,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.2068,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.1886,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1406,                   Accuracy: 1907/2000.0 (95.35%)



Epoch 20 train accuracy: 95.56%, valid accuracy 95.35%
-= Testing valid =-
Test set: Average loss: 0.1417,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1191,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1391,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1298,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1248,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1282,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1323,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1219,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1227,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1296,                   Accuracy: 1917/2000.0 (95.85%)



Epoch 30 train accuracy: 96.69%, valid accuracy 95.85%
-= Testing valid =-
Test set: Average loss: 0.1070,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1164,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1130,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1133,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1189,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1115,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1163,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1169,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 40 train accuracy: 96.85%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1020,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1103,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1076,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 50 train accuracy: 97.28%, valid accuracy 96.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1058,                   Accuracy: 58067/60000 (96.78%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1202,                   Accuracy: 57788/60000 (96.31%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1141,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1129,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1176,                   Accuracy: 57909/60000 (96.51%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1204,                   Accuracy: 57854/60000 (96.42%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1194,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1189,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1200,                   Accuracy: 57795/60000 (96.32%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1077,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1225,                   Accuracy: 57716/60000 (96.19%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1160,                   Accuracy: 57855/60000 (96.43%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1139,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1186,                   Accuracy: 57838/60000 (96.40%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1223,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1233,                   Accuracy: 57751/60000 (96.25%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1209,                   Accuracy: 57777/60000 (96.29%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1225,                   Accuracy: 57730/60000 (96.22%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1092,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1245,                   Accuracy: 57682/60000 (96.14%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1136,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1111,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1148,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1186,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1188,                   Accuracy: 57836/60000 (96.39%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1153,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1191,                   Accuracy: 57797/60000 (96.33%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1060,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1207,                   Accuracy: 57760/60000 (96.27%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1111,                   Accuracy: 57978/60000 (96.63%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1106,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1146,                   Accuracy: 57983/60000 (96.64%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1174,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1161,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1150,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1181,                   Accuracy: 57857/60000 (96.43%)
{0: tensor(96.7783), 10: tensor(96.3133), 20: tensor(96.5350), 30: tensor(96.6467), 40: tensor(96.5150), 50: tensor(96.4233), 60: tensor(96.4483), 70: tensor(96.3817), 80: tensor(96.3250), 90: tensor(96.7467), 100: tensor(96.1933), 110: tensor(96.4250), 120: tensor(96.6267), 130: tensor(96.3967), 140: tensor(96.2600), 150: tensor(96.2517), 160: tensor(96.2950), 170: tensor(96.2167), 180: tensor(96.6467), 190: tensor(96.1367), 200: tensor(96.4917), 210: tensor(96.6400), 220: tensor(96.5717), 230: tensor(96.4100), 240: tensor(96.3933), 250: tensor(96.4617), 260: tensor(96.3283), 270: tensor(96.7450), 280: tensor(96.2667), 290: tensor(96.6300), 300: tensor(96.6883), 310: tensor(96.6383), 320: tensor(96.5617), 330: tensor(96.5750), 340: tensor(96.5800), 350: tensor(96.4283)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=60, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9793,                   Accuracy: 491/2000.0 (24.55%)



-= Testing valid =-
Test set: Average loss: 2.6290,                   Accuracy: 208/2000.0 (10.40%)



-= Testing valid =-
Test set: Average loss: 1.2919,                   Accuracy: 1094/2000.0 (54.70%)



-= Testing valid =-
Test set: Average loss: 0.8811,                   Accuracy: 1458/2000.0 (72.90%)



-= Testing valid =-
Test set: Average loss: 1.6712,                   Accuracy: 1083/2000.0 (54.15%)



-= Testing valid =-
Test set: Average loss: 0.3012,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.3004,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.2327,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.1708,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.2596,                   Accuracy: 1823/2000.0 (91.15%)



Epoch 10 train accuracy: 92.79%, valid accuracy 91.15%
-= Testing valid =-
Test set: Average loss: 0.1287,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1316,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1528,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1339,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1221,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1053,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1048,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1103,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1398,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 20 train accuracy: 95.41%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0825,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 30 train accuracy: 96.49%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 40 train accuracy: 97.14%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0807,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0738,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0734,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 50 train accuracy: 96.96%, valid accuracy 97.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1006,                   Accuracy: 58220/60000 (97.03%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1103,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1071,                   Accuracy: 58083/60000 (96.81%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1122,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1134,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1119,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1101,                   Accuracy: 58073/60000 (96.79%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1052,                   Accuracy: 58175/60000 (96.96%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1086,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0996,                   Accuracy: 58226/60000 (97.04%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1105,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1092,                   Accuracy: 58034/60000 (96.72%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1148,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1171,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1165,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1150,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1100,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1131,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1057,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1176,                   Accuracy: 57822/60000 (96.37%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1142,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1192,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1201,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1181,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1157,                   Accuracy: 57954/60000 (96.59%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1110,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1137,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1053,                   Accuracy: 58101/60000 (96.83%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1156,                   Accuracy: 57893/60000 (96.49%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1112,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1166,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1158,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1134,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1108,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1062,                   Accuracy: 58138/60000 (96.90%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1097,                   Accuracy: 58078/60000 (96.80%)
{0: tensor(97.0333), 10: tensor(96.7167), 20: tensor(96.8050), 30: tensor(96.7283), 40: tensor(96.7450), 50: tensor(96.8083), 60: tensor(96.7883), 70: tensor(96.9583), 80: tensor(96.7450), 90: tensor(97.0433), 100: tensor(96.6517), 110: tensor(96.7233), 120: tensor(96.5883), 130: tensor(96.6267), 140: tensor(96.6233), 150: tensor(96.6167), 160: tensor(96.6967), 170: tensor(96.6267), 180: tensor(96.8133), 190: tensor(96.3700), 200: tensor(96.5350), 210: tensor(96.4467), 220: tensor(96.4983), 230: tensor(96.5633), 240: tensor(96.5900), 250: tensor(96.6600), 260: tensor(96.6167), 270: tensor(96.8350), 280: tensor(96.4883), 290: tensor(96.6633), 300: tensor(96.5750), 310: tensor(96.6467), 320: tensor(96.7550), 330: tensor(96.7667), 340: tensor(96.8967), 350: tensor(96.7967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=61, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5979,                   Accuracy: 415/2000.0 (20.75%)



-= Testing valid =-
Test set: Average loss: 1.3677,                   Accuracy: 1092/2000.0 (54.60%)



-= Testing valid =-
Test set: Average loss: 1.7804,                   Accuracy: 776/2000.0 (38.80%)



-= Testing valid =-
Test set: Average loss: 0.5796,                   Accuracy: 1639/2000.0 (81.95%)



-= Testing valid =-
Test set: Average loss: 1.0087,                   Accuracy: 1287/2000.0 (64.35%)



-= Testing valid =-
Test set: Average loss: 0.5395,                   Accuracy: 1652/2000.0 (82.60%)



-= Testing valid =-
Test set: Average loss: 0.4230,                   Accuracy: 1709/2000.0 (85.45%)



-= Testing valid =-
Test set: Average loss: 0.3144,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.3699,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.1558,                   Accuracy: 1901/2000.0 (95.05%)



Epoch 10 train accuracy: 92.81%, valid accuracy 95.05%
-= Testing valid =-
Test set: Average loss: 0.2275,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.2413,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.1903,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1521,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1841,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1686,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1604,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1749,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1810,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1444,                   Accuracy: 1913/2000.0 (95.65%)



Epoch 20 train accuracy: 95.00%, valid accuracy 95.65%
-= Testing valid =-
Test set: Average loss: 0.1450,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1075,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1382,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1080,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1325,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1153,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1264,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1170,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1126,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1186,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 30 train accuracy: 96.31%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.1086,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1148,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1245,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1083,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1103,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1120,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1239,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1128,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1164,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 40 train accuracy: 96.76%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.1187,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1033,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1136,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1076,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1124,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1070,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1046,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 50 train accuracy: 97.06%, valid accuracy 97.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1222,                   Accuracy: 57930/60000 (96.55%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1262,                   Accuracy: 57770/60000 (96.28%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1254,                   Accuracy: 57831/60000 (96.39%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1370,                   Accuracy: 57673/60000 (96.12%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1384,                   Accuracy: 57674/60000 (96.12%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1393,                   Accuracy: 57613/60000 (96.02%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1371,                   Accuracy: 57614/60000 (96.02%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1272,                   Accuracy: 57776/60000 (96.29%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1257,                   Accuracy: 57810/60000 (96.35%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1273,                   Accuracy: 57802/60000 (96.34%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1348,                   Accuracy: 57570/60000 (95.95%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1318,                   Accuracy: 57715/60000 (96.19%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1427,                   Accuracy: 57500/60000 (95.83%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1449,                   Accuracy: 57482/60000 (95.80%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1463,                   Accuracy: 57412/60000 (95.69%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1466,                   Accuracy: 57415/60000 (95.69%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1351,                   Accuracy: 57604/60000 (96.01%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1354,                   Accuracy: 57582/60000 (95.97%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1336,                   Accuracy: 57627/60000 (96.04%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1344,                   Accuracy: 57583/60000 (95.97%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1334,                   Accuracy: 57616/60000 (96.03%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1437,                   Accuracy: 57482/60000 (95.80%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1420,                   Accuracy: 57522/60000 (95.87%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1409,                   Accuracy: 57545/60000 (95.91%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1401,                   Accuracy: 57533/60000 (95.89%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1268,                   Accuracy: 57773/60000 (96.29%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1294,                   Accuracy: 57741/60000 (96.24%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1256,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1244,                   Accuracy: 57797/60000 (96.33%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1255,                   Accuracy: 57795/60000 (96.32%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1364,                   Accuracy: 57660/60000 (96.10%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1352,                   Accuracy: 57690/60000 (96.15%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1345,                   Accuracy: 57705/60000 (96.18%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1330,                   Accuracy: 57728/60000 (96.21%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1213,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1225,                   Accuracy: 57901/60000 (96.50%)
{0: tensor(96.5500), 10: tensor(96.2833), 20: tensor(96.3850), 30: tensor(96.1217), 40: tensor(96.1233), 50: tensor(96.0217), 60: tensor(96.0233), 70: tensor(96.2933), 80: tensor(96.3500), 90: tensor(96.3367), 100: tensor(95.9500), 110: tensor(96.1917), 120: tensor(95.8333), 130: tensor(95.8033), 140: tensor(95.6867), 150: tensor(95.6917), 160: tensor(96.0067), 170: tensor(95.9700), 180: tensor(96.0450), 190: tensor(95.9717), 200: tensor(96.0267), 210: tensor(95.8033), 220: tensor(95.8700), 230: tensor(95.9083), 240: tensor(95.8883), 250: tensor(96.2883), 260: tensor(96.2350), 270: tensor(96.3767), 280: tensor(96.3283), 290: tensor(96.3250), 300: tensor(96.1000), 310: tensor(96.1500), 320: tensor(96.1750), 330: tensor(96.2133), 340: tensor(96.5250), 350: tensor(96.5017)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=62, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1031,                   Accuracy: 451/2000.0 (22.55%)



-= Testing valid =-
Test set: Average loss: 1.7904,                   Accuracy: 591/2000.0 (29.55%)



-= Testing valid =-
Test set: Average loss: 1.4146,                   Accuracy: 1056/2000.0 (52.80%)



-= Testing valid =-
Test set: Average loss: 0.9039,                   Accuracy: 1323/2000.0 (66.15%)



-= Testing valid =-
Test set: Average loss: 0.4967,                   Accuracy: 1707/2000.0 (85.35%)



-= Testing valid =-
Test set: Average loss: 0.3380,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.2290,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2592,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.1987,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1886,                   Accuracy: 1891/2000.0 (94.55%)



Epoch 10 train accuracy: 93.09%, valid accuracy 94.55%
-= Testing valid =-
Test set: Average loss: 0.1594,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1553,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1523,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1879,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1295,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1960,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1882,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1279,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1249,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1607,                   Accuracy: 1890/2000.0 (94.50%)



Epoch 20 train accuracy: 95.96%, valid accuracy 94.50%
-= Testing valid =-
Test set: Average loss: 0.1460,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1208,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1195,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1196,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1531,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1225,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1252,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1156,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1190,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 30 train accuracy: 96.35%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0926,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0947,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1077,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1186,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 40 train accuracy: 96.79%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 50 train accuracy: 97.20%, valid accuracy 97.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1110,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1235,                   Accuracy: 57800/60000 (96.33%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1212,                   Accuracy: 57842/60000 (96.40%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1241,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1250,                   Accuracy: 57821/60000 (96.37%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1236,                   Accuracy: 57805/60000 (96.34%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1230,                   Accuracy: 57815/60000 (96.36%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1195,                   Accuracy: 57836/60000 (96.39%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1211,                   Accuracy: 57810/60000 (96.35%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1230,                   Accuracy: 57763/60000 (96.27%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1405,                   Accuracy: 57432/60000 (95.72%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1372,                   Accuracy: 57463/60000 (95.77%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1401,                   Accuracy: 57427/60000 (95.71%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1433,                   Accuracy: 57356/60000 (95.59%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1441,                   Accuracy: 57292/60000 (95.49%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1442,                   Accuracy: 57269/60000 (95.45%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1401,                   Accuracy: 57329/60000 (95.55%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1424,                   Accuracy: 57317/60000 (95.53%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1386,                   Accuracy: 57417/60000 (95.69%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1569,                   Accuracy: 57045/60000 (95.07%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1492,                   Accuracy: 57174/60000 (95.29%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1474,                   Accuracy: 57260/60000 (95.43%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1437,                   Accuracy: 57329/60000 (95.55%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1412,                   Accuracy: 57300/60000 (95.50%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1383,                   Accuracy: 57399/60000 (95.67%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1272,                   Accuracy: 57619/60000 (96.03%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1277,                   Accuracy: 57638/60000 (96.06%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1205,                   Accuracy: 57787/60000 (96.31%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1321,                   Accuracy: 57617/60000 (96.03%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1264,                   Accuracy: 57719/60000 (96.20%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1268,                   Accuracy: 57761/60000 (96.27%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1243,                   Accuracy: 57802/60000 (96.34%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1200,                   Accuracy: 57880/60000 (96.47%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1187,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1110,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1126,                   Accuracy: 57991/60000 (96.65%)
{0: tensor(96.6967), 10: tensor(96.3333), 20: tensor(96.4033), 30: tensor(96.4183), 40: tensor(96.3683), 50: tensor(96.3417), 60: tensor(96.3583), 70: tensor(96.3933), 80: tensor(96.3500), 90: tensor(96.2717), 100: tensor(95.7200), 110: tensor(95.7717), 120: tensor(95.7117), 130: tensor(95.5933), 140: tensor(95.4867), 150: tensor(95.4483), 160: tensor(95.5483), 170: tensor(95.5283), 180: tensor(95.6950), 190: tensor(95.0750), 200: tensor(95.2900), 210: tensor(95.4333), 220: tensor(95.5483), 230: tensor(95.5000), 240: tensor(95.6650), 250: tensor(96.0317), 260: tensor(96.0633), 270: tensor(96.3117), 280: tensor(96.0283), 290: tensor(96.1983), 300: tensor(96.2683), 310: tensor(96.3367), 320: tensor(96.4667), 330: tensor(96.4467), 340: tensor(96.6883), 350: tensor(96.6517)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=63, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4541,                   Accuracy: 410/2000.0 (20.50%)



-= Testing valid =-
Test set: Average loss: 1.3868,                   Accuracy: 1015/2000.0 (50.75%)



-= Testing valid =-
Test set: Average loss: 1.3396,                   Accuracy: 1069/2000.0 (53.45%)



-= Testing valid =-
Test set: Average loss: 0.6266,                   Accuracy: 1609/2000.0 (80.45%)



-= Testing valid =-
Test set: Average loss: 0.4161,                   Accuracy: 1756/2000.0 (87.80%)



-= Testing valid =-
Test set: Average loss: 0.4511,                   Accuracy: 1717/2000.0 (85.85%)



-= Testing valid =-
Test set: Average loss: 0.2494,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.3518,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.1827,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.3221,                   Accuracy: 1798/2000.0 (89.90%)



Epoch 10 train accuracy: 93.74%, valid accuracy 89.90%
-= Testing valid =-
Test set: Average loss: 0.1819,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1443,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1765,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1544,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1315,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1757,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1297,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1343,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1429,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1413,                   Accuracy: 1915/2000.0 (95.75%)



Epoch 20 train accuracy: 95.82%, valid accuracy 95.75%
-= Testing valid =-
Test set: Average loss: 0.1182,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1258,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1309,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1264,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1190,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1201,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1153,                   Accuracy: 1934/2000.0 (96.70%)



Epoch 30 train accuracy: 96.81%, valid accuracy 96.70%
-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1057,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 40 train accuracy: 97.20%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 50 train accuracy: 97.34%, valid accuracy 97.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1176,                   Accuracy: 57979/60000 (96.63%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1210,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1263,                   Accuracy: 57840/60000 (96.40%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1361,                   Accuracy: 57680/60000 (96.13%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1361,                   Accuracy: 57694/60000 (96.16%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1350,                   Accuracy: 57721/60000 (96.20%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1308,                   Accuracy: 57786/60000 (96.31%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1229,                   Accuracy: 57892/60000 (96.49%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1212,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1216,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1237,                   Accuracy: 57805/60000 (96.34%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1296,                   Accuracy: 57768/60000 (96.28%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1408,                   Accuracy: 57545/60000 (95.91%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1412,                   Accuracy: 57565/60000 (95.94%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1437,                   Accuracy: 57498/60000 (95.83%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1381,                   Accuracy: 57575/60000 (95.96%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1275,                   Accuracy: 57741/60000 (96.24%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1257,                   Accuracy: 57739/60000 (96.23%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1245,                   Accuracy: 57798/60000 (96.33%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1273,                   Accuracy: 57716/60000 (96.19%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1288,                   Accuracy: 57725/60000 (96.21%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1390,                   Accuracy: 57549/60000 (95.92%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1391,                   Accuracy: 57623/60000 (96.04%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1386,                   Accuracy: 57666/60000 (96.11%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1329,                   Accuracy: 57733/60000 (96.22%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1217,                   Accuracy: 57854/60000 (96.42%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1156,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1193,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1231,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1251,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1349,                   Accuracy: 57718/60000 (96.20%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1349,                   Accuracy: 57720/60000 (96.20%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1326,                   Accuracy: 57783/60000 (96.31%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1280,                   Accuracy: 57836/60000 (96.39%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1187,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1139,                   Accuracy: 57997/60000 (96.66%)
{0: tensor(96.6317), 10: tensor(96.4400), 20: tensor(96.4000), 30: tensor(96.1333), 40: tensor(96.1567), 50: tensor(96.2017), 60: tensor(96.3100), 70: tensor(96.4867), 80: tensor(96.4733), 90: tensor(96.4767), 100: tensor(96.3417), 110: tensor(96.2800), 120: tensor(95.9083), 130: tensor(95.9417), 140: tensor(95.8300), 150: tensor(95.9583), 160: tensor(96.2350), 170: tensor(96.2317), 180: tensor(96.3300), 190: tensor(96.1933), 200: tensor(96.2083), 210: tensor(95.9150), 220: tensor(96.0383), 230: tensor(96.1100), 240: tensor(96.2217), 250: tensor(96.4233), 260: tensor(96.6233), 270: tensor(96.5617), 280: tensor(96.3650), 290: tensor(96.4467), 300: tensor(96.1967), 310: tensor(96.2000), 320: tensor(96.3050), 330: tensor(96.3933), 340: tensor(96.5783), 350: tensor(96.6617)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=64, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.8740,                   Accuracy: 233/2000.0 (11.65%)



-= Testing valid =-
Test set: Average loss: 1.6412,                   Accuracy: 872/2000.0 (43.60%)



-= Testing valid =-
Test set: Average loss: 0.9835,                   Accuracy: 1345/2000.0 (67.25%)



-= Testing valid =-
Test set: Average loss: 0.9522,                   Accuracy: 1453/2000.0 (72.65%)



-= Testing valid =-
Test set: Average loss: 0.7424,                   Accuracy: 1552/2000.0 (77.60%)



-= Testing valid =-
Test set: Average loss: 0.3650,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.3527,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.3169,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.2848,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2522,                   Accuracy: 1853/2000.0 (92.65%)



Epoch 10 train accuracy: 92.66%, valid accuracy 92.65%
-= Testing valid =-
Test set: Average loss: 0.1695,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1537,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1473,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1552,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1468,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1400,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1423,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1441,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1383,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1127,                   Accuracy: 1930/2000.0 (96.50%)



Epoch 20 train accuracy: 95.01%, valid accuracy 96.50%
-= Testing valid =-
Test set: Average loss: 0.1162,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1344,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1224,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1282,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1166,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1268,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1089,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1261,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1934/2000.0 (96.70%)



Epoch 30 train accuracy: 96.24%, valid accuracy 96.70%
-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1192,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1021,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1161,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 40 train accuracy: 96.25%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1020,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1050,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 50 train accuracy: 96.78%, valid accuracy 96.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1098,                   Accuracy: 58079/60000 (96.80%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1237,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1184,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1259,                   Accuracy: 57777/60000 (96.29%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1290,                   Accuracy: 57751/60000 (96.25%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1277,                   Accuracy: 57765/60000 (96.28%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1282,                   Accuracy: 57784/60000 (96.31%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1220,                   Accuracy: 57809/60000 (96.35%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1249,                   Accuracy: 57766/60000 (96.28%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1174,                   Accuracy: 57928/60000 (96.55%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1325,                   Accuracy: 57599/60000 (96.00%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1262,                   Accuracy: 57720/60000 (96.20%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1312,                   Accuracy: 57645/60000 (96.07%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1360,                   Accuracy: 57573/60000 (95.96%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1367,                   Accuracy: 57511/60000 (95.85%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1355,                   Accuracy: 57557/60000 (95.93%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1312,                   Accuracy: 57637/60000 (96.06%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1345,                   Accuracy: 57549/60000 (95.92%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1243,                   Accuracy: 57744/60000 (96.24%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1368,                   Accuracy: 57467/60000 (95.78%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1277,                   Accuracy: 57652/60000 (96.09%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1305,                   Accuracy: 57663/60000 (96.11%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1325,                   Accuracy: 57676/60000 (96.13%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1310,                   Accuracy: 57677/60000 (96.13%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1301,                   Accuracy: 57654/60000 (96.09%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1231,                   Accuracy: 57823/60000 (96.37%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1286,                   Accuracy: 57701/60000 (96.17%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1148,                   Accuracy: 57955/60000 (96.59%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1269,                   Accuracy: 57720/60000 (96.20%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1192,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1253,                   Accuracy: 57794/60000 (96.32%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1259,                   Accuracy: 57823/60000 (96.37%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1238,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1224,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1165,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1198,                   Accuracy: 57892/60000 (96.49%)
{0: tensor(96.7983), 10: tensor(96.3650), 20: tensor(96.5067), 30: tensor(96.2950), 40: tensor(96.2517), 50: tensor(96.2750), 60: tensor(96.3067), 70: tensor(96.3483), 80: tensor(96.2767), 90: tensor(96.5467), 100: tensor(95.9983), 110: tensor(96.2000), 120: tensor(96.0750), 130: tensor(95.9550), 140: tensor(95.8517), 150: tensor(95.9283), 160: tensor(96.0617), 170: tensor(95.9150), 180: tensor(96.2400), 190: tensor(95.7783), 200: tensor(96.0867), 210: tensor(96.1050), 220: tensor(96.1267), 230: tensor(96.1283), 240: tensor(96.0900), 250: tensor(96.3717), 260: tensor(96.1683), 270: tensor(96.5917), 280: tensor(96.2000), 290: tensor(96.4467), 300: tensor(96.3233), 310: tensor(96.3717), 320: tensor(96.4483), 330: tensor(96.4983), 340: tensor(96.5850), 350: tensor(96.4867)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=65, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8183,                   Accuracy: 612/2000.0 (30.60%)



-= Testing valid =-
Test set: Average loss: 3.0802,                   Accuracy: 385/2000.0 (19.25%)



-= Testing valid =-
Test set: Average loss: 1.5447,                   Accuracy: 876/2000.0 (43.80%)



-= Testing valid =-
Test set: Average loss: 0.5649,                   Accuracy: 1618/2000.0 (80.90%)



-= Testing valid =-
Test set: Average loss: 1.1246,                   Accuracy: 1326/2000.0 (66.30%)



-= Testing valid =-
Test set: Average loss: 0.5821,                   Accuracy: 1627/2000.0 (81.35%)



-= Testing valid =-
Test set: Average loss: 0.1725,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.3905,                   Accuracy: 1745/2000.0 (87.25%)



-= Testing valid =-
Test set: Average loss: 0.6915,                   Accuracy: 1590/2000.0 (79.50%)



-= Testing valid =-
Test set: Average loss: 0.2544,                   Accuracy: 1830/2000.0 (91.50%)



Epoch 10 train accuracy: 93.31%, valid accuracy 91.50%
-= Testing valid =-
Test set: Average loss: 0.1857,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1827,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1772,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1723,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1930,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1263,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1243,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1363,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.2133,                   Accuracy: 1886/2000.0 (94.30%)



Epoch 20 train accuracy: 95.55%, valid accuracy 94.30%
-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1176,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1069,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1129,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1163,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1082,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 30 train accuracy: 96.89%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 40 train accuracy: 97.04%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0790,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 50 train accuracy: 97.14%, valid accuracy 97.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1199,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1396,                   Accuracy: 57447/60000 (95.75%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1343,                   Accuracy: 57609/60000 (96.01%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1408,                   Accuracy: 57508/60000 (95.85%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1455,                   Accuracy: 57417/60000 (95.69%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1488,                   Accuracy: 57374/60000 (95.62%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1415,                   Accuracy: 57503/60000 (95.84%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1331,                   Accuracy: 57607/60000 (96.01%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1306,                   Accuracy: 57672/60000 (96.12%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1168,                   Accuracy: 57916/60000 (96.53%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1399,                   Accuracy: 57418/60000 (95.70%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1324,                   Accuracy: 57590/60000 (95.98%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1404,                   Accuracy: 57467/60000 (95.78%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1444,                   Accuracy: 57409/60000 (95.68%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1497,                   Accuracy: 57356/60000 (95.59%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1435,                   Accuracy: 57452/60000 (95.75%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1328,                   Accuracy: 57567/60000 (95.94%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1309,                   Accuracy: 57620/60000 (96.03%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1187,                   Accuracy: 57873/60000 (96.46%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1401,                   Accuracy: 57421/60000 (95.70%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1325,                   Accuracy: 57570/60000 (95.95%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1422,                   Accuracy: 57436/60000 (95.73%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1464,                   Accuracy: 57372/60000 (95.62%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1502,                   Accuracy: 57326/60000 (95.54%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1477,                   Accuracy: 57376/60000 (95.63%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1355,                   Accuracy: 57523/60000 (95.87%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1329,                   Accuracy: 57588/60000 (95.98%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1211,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1388,                   Accuracy: 57501/60000 (95.83%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1336,                   Accuracy: 57612/60000 (96.02%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1434,                   Accuracy: 57438/60000 (95.73%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1473,                   Accuracy: 57376/60000 (95.63%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1506,                   Accuracy: 57355/60000 (95.59%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1463,                   Accuracy: 57416/60000 (95.69%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1358,                   Accuracy: 57513/60000 (95.86%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1326,                   Accuracy: 57632/60000 (96.05%)
{0: tensor(96.4533), 10: tensor(95.7450), 20: tensor(96.0150), 30: tensor(95.8467), 40: tensor(95.6950), 50: tensor(95.6233), 60: tensor(95.8383), 70: tensor(96.0117), 80: tensor(96.1200), 90: tensor(96.5267), 100: tensor(95.6967), 110: tensor(95.9833), 120: tensor(95.7783), 130: tensor(95.6817), 140: tensor(95.5933), 150: tensor(95.7533), 160: tensor(95.9450), 170: tensor(96.0333), 180: tensor(96.4550), 190: tensor(95.7017), 200: tensor(95.9500), 210: tensor(95.7267), 220: tensor(95.6200), 230: tensor(95.5433), 240: tensor(95.6267), 250: tensor(95.8717), 260: tensor(95.9800), 270: tensor(96.3817), 280: tensor(95.8350), 290: tensor(96.0200), 300: tensor(95.7300), 310: tensor(95.6267), 320: tensor(95.5917), 330: tensor(95.6933), 340: tensor(95.8550), 350: tensor(96.0533)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=66, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6200,                   Accuracy: 238/2000.0 (11.90%)



-= Testing valid =-
Test set: Average loss: 3.3996,                   Accuracy: 374/2000.0 (18.70%)



-= Testing valid =-
Test set: Average loss: 1.9424,                   Accuracy: 638/2000.0 (31.90%)



-= Testing valid =-
Test set: Average loss: 5.0293,                   Accuracy: 283/2000.0 (14.15%)



-= Testing valid =-
Test set: Average loss: 1.1023,                   Accuracy: 1288/2000.0 (64.40%)



-= Testing valid =-
Test set: Average loss: 0.2853,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.4494,                   Accuracy: 1713/2000.0 (85.65%)



-= Testing valid =-
Test set: Average loss: 0.2368,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2136,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.3237,                   Accuracy: 1814/2000.0 (90.70%)



Epoch 10 train accuracy: 92.61%, valid accuracy 90.70%
-= Testing valid =-
Test set: Average loss: 0.1704,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1616,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1873,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1464,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1721,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1769,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1128,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1194,                   Accuracy: 1918/2000.0 (95.90%)



Epoch 20 train accuracy: 95.59%, valid accuracy 95.90%
-= Testing valid =-
Test set: Average loss: 0.1209,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1088,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1262,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1160,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1093,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 30 train accuracy: 96.30%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 40 train accuracy: 96.96%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 50 train accuracy: 96.80%, valid accuracy 97.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0973,                   Accuracy: 58227/60000 (97.04%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1135,                   Accuracy: 57916/60000 (96.53%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1093,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1131,                   Accuracy: 57982/60000 (96.64%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1160,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1164,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1130,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1072,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1088,                   Accuracy: 58019/60000 (96.70%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1012,                   Accuracy: 58169/60000 (96.95%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1198,                   Accuracy: 57776/60000 (96.29%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1161,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1170,                   Accuracy: 57852/60000 (96.42%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1197,                   Accuracy: 57805/60000 (96.34%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1203,                   Accuracy: 57769/60000 (96.28%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1173,                   Accuracy: 57823/60000 (96.37%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1133,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1135,                   Accuracy: 57859/60000 (96.43%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1046,                   Accuracy: 58095/60000 (96.82%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1145,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1165,                   Accuracy: 57818/60000 (96.36%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1174,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1186,                   Accuracy: 57857/60000 (96.43%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1173,                   Accuracy: 57863/60000 (96.44%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1147,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1085,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1104,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1002,                   Accuracy: 58191/60000 (96.99%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1082,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1094,                   Accuracy: 58019/60000 (96.70%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1126,                   Accuracy: 58002/60000 (96.67%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1138,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1126,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1093,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1030,                   Accuracy: 58159/60000 (96.93%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1053,                   Accuracy: 58062/60000 (96.77%)
{0: tensor(97.0450), 10: tensor(96.5267), 20: tensor(96.6967), 30: tensor(96.6367), 40: tensor(96.5600), 50: tensor(96.4900), 60: tensor(96.5950), 70: tensor(96.7650), 80: tensor(96.6983), 90: tensor(96.9483), 100: tensor(96.2933), 110: tensor(96.3833), 120: tensor(96.4200), 130: tensor(96.3417), 140: tensor(96.2817), 150: tensor(96.3717), 160: tensor(96.4917), 170: tensor(96.4317), 180: tensor(96.8250), 190: tensor(96.4717), 200: tensor(96.3633), 210: tensor(96.4717), 220: tensor(96.4283), 230: tensor(96.4383), 240: tensor(96.5133), 250: tensor(96.7333), 260: tensor(96.5700), 270: tensor(96.9850), 280: tensor(96.7333), 290: tensor(96.6983), 300: tensor(96.6700), 310: tensor(96.6333), 320: tensor(96.6767), 330: tensor(96.7567), 340: tensor(96.9317), 350: tensor(96.7700)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=67, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.9139,                   Accuracy: 539/2000.0 (26.95%)



-= Testing valid =-
Test set: Average loss: 1.9138,                   Accuracy: 797/2000.0 (39.85%)



-= Testing valid =-
Test set: Average loss: 1.2634,                   Accuracy: 1055/2000.0 (52.75%)



-= Testing valid =-
Test set: Average loss: 0.7380,                   Accuracy: 1512/2000.0 (75.60%)



-= Testing valid =-
Test set: Average loss: 0.7962,                   Accuracy: 1574/2000.0 (78.70%)



-= Testing valid =-
Test set: Average loss: 0.4932,                   Accuracy: 1664/2000.0 (83.20%)



-= Testing valid =-
Test set: Average loss: 0.2557,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2049,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.2004,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.2880,                   Accuracy: 1812/2000.0 (90.60%)



Epoch 10 train accuracy: 92.90%, valid accuracy 90.60%
-= Testing valid =-
Test set: Average loss: 0.1547,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1612,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1255,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1757,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1215,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1323,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1117,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1231,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1225,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1326,                   Accuracy: 1918/2000.0 (95.90%)



Epoch 20 train accuracy: 95.64%, valid accuracy 95.90%
-= Testing valid =-
Test set: Average loss: 0.1050,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1255,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1208,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 30 train accuracy: 96.38%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 40 train accuracy: 97.01%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0709,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0691,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 50 train accuracy: 97.11%, valid accuracy 97.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1076,                   Accuracy: 58113/60000 (96.86%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1108,                   Accuracy: 57966/60000 (96.61%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1049,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1074,                   Accuracy: 58110/60000 (96.85%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1108,                   Accuracy: 58061/60000 (96.77%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1139,                   Accuracy: 58026/60000 (96.71%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1176,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1151,                   Accuracy: 57990/60000 (96.65%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1145,                   Accuracy: 57983/60000 (96.64%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1137,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1186,                   Accuracy: 57776/60000 (96.29%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1117,                   Accuracy: 57949/60000 (96.58%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1155,                   Accuracy: 57893/60000 (96.49%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1160,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1196,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1249,                   Accuracy: 57751/60000 (96.25%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1191,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1208,                   Accuracy: 57849/60000 (96.42%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1192,                   Accuracy: 57838/60000 (96.40%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1220,                   Accuracy: 57711/60000 (96.18%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1139,                   Accuracy: 57888/60000 (96.48%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1173,                   Accuracy: 57848/60000 (96.41%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1162,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1187,                   Accuracy: 57898/60000 (96.50%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1205,                   Accuracy: 57862/60000 (96.44%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1141,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1140,                   Accuracy: 58012/60000 (96.69%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1111,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1132,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1065,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1090,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1108,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1130,                   Accuracy: 58019/60000 (96.70%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1136,                   Accuracy: 58033/60000 (96.72%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1106,                   Accuracy: 58105/60000 (96.84%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1089,                   Accuracy: 58101/60000 (96.83%)
{0: tensor(96.8550), 10: tensor(96.6100), 20: tensor(96.8683), 30: tensor(96.8500), 40: tensor(96.7683), 50: tensor(96.7100), 60: tensor(96.5633), 70: tensor(96.6500), 80: tensor(96.6383), 90: tensor(96.5700), 100: tensor(96.2933), 110: tensor(96.5817), 120: tensor(96.4883), 130: tensor(96.5450), 140: tensor(96.4483), 150: tensor(96.2517), 160: tensor(96.4300), 170: tensor(96.4150), 180: tensor(96.3967), 190: tensor(96.1850), 200: tensor(96.4800), 210: tensor(96.4133), 220: tensor(96.4983), 230: tensor(96.4967), 240: tensor(96.4367), 250: tensor(96.6717), 260: tensor(96.6867), 270: tensor(96.7750), 280: tensor(96.5333), 290: tensor(96.8100), 300: tensor(96.7700), 310: tensor(96.7267), 320: tensor(96.6983), 330: tensor(96.7217), 340: tensor(96.8417), 350: tensor(96.8350)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=68, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7371,                   Accuracy: 826/2000.0 (41.30%)



-= Testing valid =-
Test set: Average loss: 1.4062,                   Accuracy: 971/2000.0 (48.55%)



-= Testing valid =-
Test set: Average loss: 1.5358,                   Accuracy: 904/2000.0 (45.20%)



-= Testing valid =-
Test set: Average loss: 0.8773,                   Accuracy: 1326/2000.0 (66.30%)



-= Testing valid =-
Test set: Average loss: 0.4135,                   Accuracy: 1733/2000.0 (86.65%)



-= Testing valid =-
Test set: Average loss: 0.2758,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.3322,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.2076,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.3951,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.4342,                   Accuracy: 1731/2000.0 (86.55%)



Epoch 10 train accuracy: 93.10%, valid accuracy 86.55%
-= Testing valid =-
Test set: Average loss: 0.1786,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1467,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1285,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1211,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1471,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1341,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1458,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1886,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1352,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1339,                   Accuracy: 1918/2000.0 (95.90%)



Epoch 20 train accuracy: 95.62%, valid accuracy 95.90%
-= Testing valid =-
Test set: Average loss: 0.1216,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1424,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1165,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1036,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1082,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1118,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 30 train accuracy: 96.51%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0986,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1101,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 40 train accuracy: 96.90%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0981,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0986,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 50 train accuracy: 97.26%, valid accuracy 97.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1159,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1318,                   Accuracy: 57665/60000 (96.11%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1313,                   Accuracy: 57637/60000 (96.06%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1318,                   Accuracy: 57689/60000 (96.15%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1337,                   Accuracy: 57682/60000 (96.14%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1331,                   Accuracy: 57659/60000 (96.10%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1285,                   Accuracy: 57762/60000 (96.27%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1283,                   Accuracy: 57717/60000 (96.19%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1306,                   Accuracy: 57692/60000 (96.15%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1216,                   Accuracy: 57857/60000 (96.43%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1389,                   Accuracy: 57457/60000 (95.76%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1385,                   Accuracy: 57468/60000 (95.78%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1402,                   Accuracy: 57525/60000 (95.88%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1398,                   Accuracy: 57492/60000 (95.82%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1395,                   Accuracy: 57512/60000 (95.85%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1356,                   Accuracy: 57556/60000 (95.93%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1313,                   Accuracy: 57598/60000 (96.00%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1352,                   Accuracy: 57552/60000 (95.92%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1245,                   Accuracy: 57743/60000 (96.24%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1405,                   Accuracy: 57382/60000 (95.64%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1367,                   Accuracy: 57482/60000 (95.80%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1384,                   Accuracy: 57513/60000 (95.86%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1360,                   Accuracy: 57590/60000 (95.98%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1353,                   Accuracy: 57583/60000 (95.97%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1291,                   Accuracy: 57703/60000 (96.17%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1244,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1267,                   Accuracy: 57754/60000 (96.26%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1169,                   Accuracy: 57931/60000 (96.55%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1315,                   Accuracy: 57631/60000 (96.05%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1291,                   Accuracy: 57712/60000 (96.19%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1303,                   Accuracy: 57705/60000 (96.18%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1307,                   Accuracy: 57739/60000 (96.23%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1301,                   Accuracy: 57733/60000 (96.22%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1246,                   Accuracy: 57843/60000 (96.40%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1237,                   Accuracy: 57812/60000 (96.35%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1245,                   Accuracy: 57862/60000 (96.44%)
{0: tensor(96.6517), 10: tensor(96.1083), 20: tensor(96.0617), 30: tensor(96.1483), 40: tensor(96.1367), 50: tensor(96.0983), 60: tensor(96.2700), 70: tensor(96.1950), 80: tensor(96.1533), 90: tensor(96.4283), 100: tensor(95.7617), 110: tensor(95.7800), 120: tensor(95.8750), 130: tensor(95.8200), 140: tensor(95.8533), 150: tensor(95.9267), 160: tensor(95.9967), 170: tensor(95.9200), 180: tensor(96.2383), 190: tensor(95.6367), 200: tensor(95.8033), 210: tensor(95.8550), 220: tensor(95.9833), 230: tensor(95.9717), 240: tensor(96.1717), 250: tensor(96.2600), 260: tensor(96.2567), 270: tensor(96.5517), 280: tensor(96.0517), 290: tensor(96.1867), 300: tensor(96.1750), 310: tensor(96.2317), 320: tensor(96.2217), 330: tensor(96.4050), 340: tensor(96.3533), 350: tensor(96.4367)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=69, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0146,                   Accuracy: 495/2000.0 (24.75%)



-= Testing valid =-
Test set: Average loss: 2.1957,                   Accuracy: 519/2000.0 (25.95%)



-= Testing valid =-
Test set: Average loss: 1.8580,                   Accuracy: 813/2000.0 (40.65%)



-= Testing valid =-
Test set: Average loss: 0.8060,                   Accuracy: 1486/2000.0 (74.30%)



-= Testing valid =-
Test set: Average loss: 0.6056,                   Accuracy: 1635/2000.0 (81.75%)



-= Testing valid =-
Test set: Average loss: 0.3653,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.5246,                   Accuracy: 1665/2000.0 (83.25%)



-= Testing valid =-
Test set: Average loss: 0.2219,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2233,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.3477,                   Accuracy: 1778/2000.0 (88.90%)



Epoch 10 train accuracy: 94.00%, valid accuracy 88.90%
-= Testing valid =-
Test set: Average loss: 0.1702,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1606,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1387,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1289,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1641,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1375,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1795,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1340,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1656,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1223,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 20 train accuracy: 95.97%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.1288,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1132,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1223,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1347,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1066,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1195,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1203,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1077,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 30 train accuracy: 96.55%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1010,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1122,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 40 train accuracy: 97.09%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0981,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 50 train accuracy: 97.32%, valid accuracy 97.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1128,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1202,                   Accuracy: 57906/60000 (96.51%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1220,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1237,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1234,                   Accuracy: 57893/60000 (96.49%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1242,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1218,                   Accuracy: 57959/60000 (96.60%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1168,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1166,                   Accuracy: 58042/60000 (96.74%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1114,                   Accuracy: 58089/60000 (96.82%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1186,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1196,                   Accuracy: 57900/60000 (96.50%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1251,                   Accuracy: 57879/60000 (96.46%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1234,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1253,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1248,                   Accuracy: 57890/60000 (96.48%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1163,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1176,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1133,                   Accuracy: 58028/60000 (96.71%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1212,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1171,                   Accuracy: 57958/60000 (96.60%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1231,                   Accuracy: 57893/60000 (96.49%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1214,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1235,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1247,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1177,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1184,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1137,                   Accuracy: 58076/60000 (96.79%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1216,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1188,                   Accuracy: 57939/60000 (96.57%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1219,                   Accuracy: 57916/60000 (96.53%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1219,                   Accuracy: 57918/60000 (96.53%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1233,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1222,                   Accuracy: 57946/60000 (96.58%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1180,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1176,                   Accuracy: 58005/60000 (96.68%)
{0: tensor(96.8133), 10: tensor(96.5100), 20: tensor(96.4400), 30: tensor(96.4583), 40: tensor(96.4883), 50: tensor(96.5183), 60: tensor(96.5983), 70: tensor(96.6800), 80: tensor(96.7367), 90: tensor(96.8150), 100: tensor(96.5450), 110: tensor(96.5000), 120: tensor(96.4650), 130: tensor(96.4533), 140: tensor(96.4400), 150: tensor(96.4833), 160: tensor(96.7283), 170: tensor(96.5850), 180: tensor(96.7133), 190: tensor(96.4850), 200: tensor(96.5967), 210: tensor(96.4883), 220: tensor(96.5700), 230: tensor(96.4750), 240: tensor(96.4583), 250: tensor(96.6400), 260: tensor(96.5750), 270: tensor(96.7933), 280: tensor(96.4850), 290: tensor(96.5650), 300: tensor(96.5267), 310: tensor(96.5300), 320: tensor(96.5367), 330: tensor(96.5767), 340: tensor(96.6583), 350: tensor(96.6750)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=70, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.9785,                   Accuracy: 225/2000.0 (11.25%)



-= Testing valid =-
Test set: Average loss: 2.5073,                   Accuracy: 319/2000.0 (15.95%)



-= Testing valid =-
Test set: Average loss: 2.2120,                   Accuracy: 662/2000.0 (33.10%)



-= Testing valid =-
Test set: Average loss: 0.5819,                   Accuracy: 1644/2000.0 (82.20%)



-= Testing valid =-
Test set: Average loss: 0.3068,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.3369,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.3395,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.2276,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2510,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.1849,                   Accuracy: 1889/2000.0 (94.45%)



Epoch 10 train accuracy: 94.03%, valid accuracy 94.45%
-= Testing valid =-
Test set: Average loss: 0.1544,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1660,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1313,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1517,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1189,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1499,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1351,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1313,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1484,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1192,                   Accuracy: 1921/2000.0 (96.05%)



Epoch 20 train accuracy: 95.62%, valid accuracy 96.05%
-= Testing valid =-
Test set: Average loss: 0.1084,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1365,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1198,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1099,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1175,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 30 train accuracy: 96.51%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0919,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 40 train accuracy: 96.96%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0882,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 50 train accuracy: 97.30%, valid accuracy 97.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0987,                   Accuracy: 58268/60000 (97.11%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1056,                   Accuracy: 58147/60000 (96.91%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1042,                   Accuracy: 58158/60000 (96.93%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1105,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1141,                   Accuracy: 58017/60000 (96.69%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1138,                   Accuracy: 58031/60000 (96.72%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1148,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1140,                   Accuracy: 57946/60000 (96.58%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1171,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1073,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1126,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1126,                   Accuracy: 57926/60000 (96.54%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1182,                   Accuracy: 57900/60000 (96.50%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1210,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1209,                   Accuracy: 57844/60000 (96.41%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1215,                   Accuracy: 57835/60000 (96.39%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1212,                   Accuracy: 57805/60000 (96.34%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1198,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1125,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1216,                   Accuracy: 57746/60000 (96.24%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1122,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1172,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1165,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1148,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1137,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1104,                   Accuracy: 58061/60000 (96.77%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1073,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1009,                   Accuracy: 58220/60000 (97.03%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1092,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1026,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1092,                   Accuracy: 58106/60000 (96.84%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1107,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1089,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1087,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1058,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1066,                   Accuracy: 58111/60000 (96.85%)
{0: tensor(97.1133), 10: tensor(96.9117), 20: tensor(96.9300), 30: tensor(96.7717), 40: tensor(96.6950), 50: tensor(96.7183), 60: tensor(96.6267), 70: tensor(96.5767), 80: tensor(96.4917), 90: tensor(96.7833), 100: tensor(96.6133), 110: tensor(96.5433), 120: tensor(96.5000), 130: tensor(96.4533), 140: tensor(96.4067), 150: tensor(96.3917), 160: tensor(96.3417), 170: tensor(96.4017), 180: tensor(96.6200), 190: tensor(96.2433), 200: tensor(96.5550), 210: tensor(96.4900), 220: tensor(96.6033), 230: tensor(96.6167), 240: tensor(96.6917), 250: tensor(96.7683), 260: tensor(96.8567), 270: tensor(97.0333), 280: tensor(96.6583), 290: tensor(96.9500), 300: tensor(96.8433), 310: tensor(96.8167), 320: tensor(96.8483), 330: tensor(96.8750), 340: tensor(96.8800), 350: tensor(96.8517)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=41, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.2488,                   Accuracy: 256/2000.0 (12.80%)



-= Testing valid =-
Test set: Average loss: 3.4273,                   Accuracy: 288/2000.0 (14.40%)



-= Testing valid =-
Test set: Average loss: 2.0951,                   Accuracy: 561/2000.0 (28.05%)



-= Testing valid =-
Test set: Average loss: 1.9424,                   Accuracy: 610/2000.0 (30.50%)



-= Testing valid =-
Test set: Average loss: 2.3318,                   Accuracy: 528/2000.0 (26.40%)



-= Testing valid =-
Test set: Average loss: 2.3656,                   Accuracy: 626/2000.0 (31.30%)



-= Testing valid =-
Test set: Average loss: 2.2628,                   Accuracy: 711/2000.0 (35.55%)



-= Testing valid =-
Test set: Average loss: 1.2727,                   Accuracy: 1101/2000.0 (55.05%)



-= Testing valid =-
Test set: Average loss: 1.1661,                   Accuracy: 1174/2000.0 (58.70%)



-= Testing valid =-
Test set: Average loss: 1.6499,                   Accuracy: 972/2000.0 (48.60%)



Epoch 10 train accuracy: 72.34%, valid accuracy 48.60%
-= Testing valid =-
Test set: Average loss: 0.7958,                   Accuracy: 1452/2000.0 (72.60%)



-= Testing valid =-
Test set: Average loss: 0.7180,                   Accuracy: 1502/2000.0 (75.10%)



-= Testing valid =-
Test set: Average loss: 0.7068,                   Accuracy: 1580/2000.0 (79.00%)



-= Testing valid =-
Test set: Average loss: 0.9065,                   Accuracy: 1333/2000.0 (66.65%)



-= Testing valid =-
Test set: Average loss: 0.7358,                   Accuracy: 1506/2000.0 (75.30%)



-= Testing valid =-
Test set: Average loss: 0.7987,                   Accuracy: 1478/2000.0 (73.90%)



-= Testing valid =-
Test set: Average loss: 0.8936,                   Accuracy: 1380/2000.0 (69.00%)



-= Testing valid =-
Test set: Average loss: 0.8669,                   Accuracy: 1421/2000.0 (71.05%)



-= Testing valid =-
Test set: Average loss: 1.0399,                   Accuracy: 1322/2000.0 (66.10%)



-= Testing valid =-
Test set: Average loss: 0.3968,                   Accuracy: 1749/2000.0 (87.45%)



Epoch 20 train accuracy: 86.06%, valid accuracy 87.45%
-= Testing valid =-
Test set: Average loss: 0.6863,                   Accuracy: 1509/2000.0 (75.45%)



-= Testing valid =-
Test set: Average loss: 0.5986,                   Accuracy: 1586/2000.0 (79.30%)



-= Testing valid =-
Test set: Average loss: 0.8231,                   Accuracy: 1481/2000.0 (74.05%)



-= Testing valid =-
Test set: Average loss: 0.4962,                   Accuracy: 1665/2000.0 (83.25%)



-= Testing valid =-
Test set: Average loss: 0.5971,                   Accuracy: 1575/2000.0 (78.75%)



-= Testing valid =-
Test set: Average loss: 0.6073,                   Accuracy: 1568/2000.0 (78.40%)



-= Testing valid =-
Test set: Average loss: 0.5151,                   Accuracy: 1642/2000.0 (82.10%)



-= Testing valid =-
Test set: Average loss: 0.6686,                   Accuracy: 1546/2000.0 (77.30%)



-= Testing valid =-
Test set: Average loss: 0.4760,                   Accuracy: 1691/2000.0 (84.55%)



-= Testing valid =-
Test set: Average loss: 0.6094,                   Accuracy: 1589/2000.0 (79.45%)



Epoch 30 train accuracy: 88.19%, valid accuracy 79.45%
-= Testing valid =-
Test set: Average loss: 0.4973,                   Accuracy: 1669/2000.0 (83.45%)



-= Testing valid =-
Test set: Average loss: 0.7339,                   Accuracy: 1501/2000.0 (75.05%)



-= Testing valid =-
Test set: Average loss: 0.5168,                   Accuracy: 1647/2000.0 (82.35%)



-= Testing valid =-
Test set: Average loss: 0.5196,                   Accuracy: 1656/2000.0 (82.80%)



-= Testing valid =-
Test set: Average loss: 0.3802,                   Accuracy: 1748/2000.0 (87.40%)



-= Testing valid =-
Test set: Average loss: 0.4002,                   Accuracy: 1736/2000.0 (86.80%)



-= Testing valid =-
Test set: Average loss: 0.4944,                   Accuracy: 1665/2000.0 (83.25%)



-= Testing valid =-
Test set: Average loss: 0.4455,                   Accuracy: 1706/2000.0 (85.30%)



-= Testing valid =-
Test set: Average loss: 0.4535,                   Accuracy: 1697/2000.0 (84.85%)



-= Testing valid =-
Test set: Average loss: 0.4013,                   Accuracy: 1753/2000.0 (87.65%)



Epoch 40 train accuracy: 89.72%, valid accuracy 87.65%
-= Testing valid =-
Test set: Average loss: 0.4042,                   Accuracy: 1740/2000.0 (87.00%)



-= Testing valid =-
Test set: Average loss: 0.4384,                   Accuracy: 1704/2000.0 (85.20%)



-= Testing valid =-
Test set: Average loss: 0.4440,                   Accuracy: 1702/2000.0 (85.10%)



-= Testing valid =-
Test set: Average loss: 0.4260,                   Accuracy: 1725/2000.0 (86.25%)



-= Testing valid =-
Test set: Average loss: 0.4068,                   Accuracy: 1739/2000.0 (86.95%)



-= Testing valid =-
Test set: Average loss: 0.4735,                   Accuracy: 1687/2000.0 (84.35%)



-= Testing valid =-
Test set: Average loss: 0.4613,                   Accuracy: 1693/2000.0 (84.65%)



-= Testing valid =-
Test set: Average loss: 0.4451,                   Accuracy: 1708/2000.0 (85.40%)



-= Testing valid =-
Test set: Average loss: 0.4631,                   Accuracy: 1697/2000.0 (84.85%)



-= Testing valid =-
Test set: Average loss: 0.4802,                   Accuracy: 1680/2000.0 (84.00%)



Epoch 50 train accuracy: 90.66%, valid accuracy 84.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.4253,                   Accuracy: 51899/60000 (86.50%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.4087,                   Accuracy: 52231/60000 (87.05%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.4240,                   Accuracy: 52138/60000 (86.90%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4680,                   Accuracy: 51261/60000 (85.43%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.4749,                   Accuracy: 50982/60000 (84.97%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.5042,                   Accuracy: 50018/60000 (83.36%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5222,                   Accuracy: 49198/60000 (82.00%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.5101,                   Accuracy: 49343/60000 (82.24%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5307,                   Accuracy: 48736/60000 (81.23%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5287,                   Accuracy: 49389/60000 (82.32%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.4993,                   Accuracy: 50133/60000 (83.56%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.5417,                   Accuracy: 49526/60000 (82.54%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5789,                   Accuracy: 48743/60000 (81.24%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.5806,                   Accuracy: 48386/60000 (80.64%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.5725,                   Accuracy: 47934/60000 (79.89%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5549,                   Accuracy: 48006/60000 (80.01%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.5011,                   Accuracy: 49865/60000 (83.11%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.4411,                   Accuracy: 50967/60000 (84.94%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.4221,                   Accuracy: 51623/60000 (86.04%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3836,                   Accuracy: 52568/60000 (87.61%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3845,                   Accuracy: 52741/60000 (87.90%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3985,                   Accuracy: 52704/60000 (87.84%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4005,                   Accuracy: 52781/60000 (87.97%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4149,                   Accuracy: 52566/60000 (87.61%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4270,                   Accuracy: 52311/60000 (87.18%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.4340,                   Accuracy: 52011/60000 (86.68%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.4440,                   Accuracy: 51335/60000 (85.56%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4771,                   Accuracy: 50852/60000 (84.75%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4525,                   Accuracy: 51433/60000 (85.72%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.4953,                   Accuracy: 50903/60000 (84.84%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5175,                   Accuracy: 50675/60000 (84.46%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.5236,                   Accuracy: 50556/60000 (84.26%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.5173,                   Accuracy: 50164/60000 (83.61%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5034,                   Accuracy: 50038/60000 (83.40%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.4593,                   Accuracy: 51415/60000 (85.69%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.4260,                   Accuracy: 51801/60000 (86.33%)
{0: tensor(86.4983), 10: tensor(87.0517), 20: tensor(86.8967), 30: tensor(85.4350), 40: tensor(84.9700), 50: tensor(83.3633), 60: tensor(81.9967), 70: tensor(82.2383), 80: tensor(81.2267), 90: tensor(82.3150), 100: tensor(83.5550), 110: tensor(82.5433), 120: tensor(81.2383), 130: tensor(80.6433), 140: tensor(79.8900), 150: tensor(80.0100), 160: tensor(83.1083), 170: tensor(84.9450), 180: tensor(86.0383), 190: tensor(87.6133), 200: tensor(87.9017), 210: tensor(87.8400), 220: tensor(87.9683), 230: tensor(87.6100), 240: tensor(87.1850), 250: tensor(86.6850), 260: tensor(85.5583), 270: tensor(84.7533), 280: tensor(85.7217), 290: tensor(84.8383), 300: tensor(84.4583), 310: tensor(84.2600), 320: tensor(83.6067), 330: tensor(83.3967), 340: tensor(85.6917), 350: tensor(86.3350)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=42, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2639,                   Accuracy: 317/2000.0 (15.85%)



-= Testing valid =-
Test set: Average loss: 3.6554,                   Accuracy: 260/2000.0 (13.00%)



-= Testing valid =-
Test set: Average loss: 1.9233,                   Accuracy: 623/2000.0 (31.15%)



-= Testing valid =-
Test set: Average loss: 1.5446,                   Accuracy: 923/2000.0 (46.15%)



-= Testing valid =-
Test set: Average loss: 1.4845,                   Accuracy: 947/2000.0 (47.35%)



-= Testing valid =-
Test set: Average loss: 1.3232,                   Accuracy: 1111/2000.0 (55.55%)



-= Testing valid =-
Test set: Average loss: 1.5089,                   Accuracy: 957/2000.0 (47.85%)



-= Testing valid =-
Test set: Average loss: 0.9079,                   Accuracy: 1426/2000.0 (71.30%)



-= Testing valid =-
Test set: Average loss: 1.6425,                   Accuracy: 980/2000.0 (49.00%)



-= Testing valid =-
Test set: Average loss: 0.8047,                   Accuracy: 1448/2000.0 (72.40%)



Epoch 10 train accuracy: 69.97%, valid accuracy 72.40%
-= Testing valid =-
Test set: Average loss: 1.0900,                   Accuracy: 1206/2000.0 (60.30%)



-= Testing valid =-
Test set: Average loss: 1.1425,                   Accuracy: 1268/2000.0 (63.40%)



-= Testing valid =-
Test set: Average loss: 0.7237,                   Accuracy: 1517/2000.0 (75.85%)



-= Testing valid =-
Test set: Average loss: 1.0021,                   Accuracy: 1241/2000.0 (62.05%)



-= Testing valid =-
Test set: Average loss: 0.7872,                   Accuracy: 1478/2000.0 (73.90%)



-= Testing valid =-
Test set: Average loss: 0.5486,                   Accuracy: 1635/2000.0 (81.75%)



-= Testing valid =-
Test set: Average loss: 0.5836,                   Accuracy: 1586/2000.0 (79.30%)



-= Testing valid =-
Test set: Average loss: 0.6338,                   Accuracy: 1562/2000.0 (78.10%)



-= Testing valid =-
Test set: Average loss: 0.9464,                   Accuracy: 1254/2000.0 (62.70%)



-= Testing valid =-
Test set: Average loss: 0.3712,                   Accuracy: 1756/2000.0 (87.80%)



Epoch 20 train accuracy: 83.95%, valid accuracy 87.80%
-= Testing valid =-
Test set: Average loss: 0.4371,                   Accuracy: 1715/2000.0 (85.75%)



-= Testing valid =-
Test set: Average loss: 0.3733,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 0.3138,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.4101,                   Accuracy: 1732/2000.0 (86.60%)



-= Testing valid =-
Test set: Average loss: 0.2827,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.3492,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.4226,                   Accuracy: 1736/2000.0 (86.80%)



-= Testing valid =-
Test set: Average loss: 0.4038,                   Accuracy: 1729/2000.0 (86.45%)



-= Testing valid =-
Test set: Average loss: 0.3973,                   Accuracy: 1730/2000.0 (86.50%)



-= Testing valid =-
Test set: Average loss: 0.4905,                   Accuracy: 1651/2000.0 (82.55%)



Epoch 30 train accuracy: 89.12%, valid accuracy 82.55%
-= Testing valid =-
Test set: Average loss: 0.3293,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.4149,                   Accuracy: 1673/2000.0 (83.65%)



-= Testing valid =-
Test set: Average loss: 0.4151,                   Accuracy: 1692/2000.0 (84.60%)



-= Testing valid =-
Test set: Average loss: 0.4061,                   Accuracy: 1722/2000.0 (86.10%)



-= Testing valid =-
Test set: Average loss: 0.3030,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.2977,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.3610,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.3678,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.2704,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.3365,                   Accuracy: 1785/2000.0 (89.25%)



Epoch 40 train accuracy: 89.96%, valid accuracy 89.25%
-= Testing valid =-
Test set: Average loss: 0.3565,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.3541,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.3810,                   Accuracy: 1747/2000.0 (87.35%)



-= Testing valid =-
Test set: Average loss: 0.3358,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.3020,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.3608,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.3916,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.2996,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.3265,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.3251,                   Accuracy: 1784/2000.0 (89.20%)



Epoch 50 train accuracy: 89.69%, valid accuracy 89.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3419,                   Accuracy: 54150/60000 (90.25%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3404,                   Accuracy: 54084/60000 (90.14%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3501,                   Accuracy: 53987/60000 (89.98%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3604,                   Accuracy: 53737/60000 (89.56%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3705,                   Accuracy: 53401/60000 (89.00%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3714,                   Accuracy: 53465/60000 (89.11%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3761,                   Accuracy: 53455/60000 (89.09%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3809,                   Accuracy: 53315/60000 (88.86%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3902,                   Accuracy: 53102/60000 (88.50%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4055,                   Accuracy: 52855/60000 (88.09%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.4469,                   Accuracy: 51887/60000 (86.48%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.4881,                   Accuracy: 51014/60000 (85.02%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5173,                   Accuracy: 50209/60000 (83.68%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.5401,                   Accuracy: 49422/60000 (82.37%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.5388,                   Accuracy: 49384/60000 (82.31%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5273,                   Accuracy: 49475/60000 (82.46%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.5149,                   Accuracy: 49571/60000 (82.62%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.4784,                   Accuracy: 50337/60000 (83.89%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.4579,                   Accuracy: 50784/60000 (84.64%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.4607,                   Accuracy: 50762/60000 (84.60%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.4693,                   Accuracy: 50555/60000 (84.26%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4740,                   Accuracy: 50404/60000 (84.01%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4799,                   Accuracy: 50193/60000 (83.65%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4781,                   Accuracy: 50257/60000 (83.76%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4712,                   Accuracy: 50449/60000 (84.08%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.4593,                   Accuracy: 50746/60000 (84.58%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.4200,                   Accuracy: 51816/60000 (86.36%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4118,                   Accuracy: 52163/60000 (86.94%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3979,                   Accuracy: 52680/60000 (87.80%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3995,                   Accuracy: 52900/60000 (88.17%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3948,                   Accuracy: 53066/60000 (88.44%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.4009,                   Accuracy: 53014/60000 (88.36%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3935,                   Accuracy: 53181/60000 (88.64%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3833,                   Accuracy: 53353/60000 (88.92%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3704,                   Accuracy: 53619/60000 (89.36%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3511,                   Accuracy: 53955/60000 (89.93%)
{0: tensor(90.2500), 10: tensor(90.1400), 20: tensor(89.9783), 30: tensor(89.5617), 40: tensor(89.0017), 50: tensor(89.1083), 60: tensor(89.0917), 70: tensor(88.8583), 80: tensor(88.5033), 90: tensor(88.0917), 100: tensor(86.4783), 110: tensor(85.0233), 120: tensor(83.6817), 130: tensor(82.3700), 140: tensor(82.3067), 150: tensor(82.4583), 160: tensor(82.6183), 170: tensor(83.8950), 180: tensor(84.6400), 190: tensor(84.6033), 200: tensor(84.2583), 210: tensor(84.0067), 220: tensor(83.6550), 230: tensor(83.7617), 240: tensor(84.0817), 250: tensor(84.5767), 260: tensor(86.3600), 270: tensor(86.9383), 280: tensor(87.8000), 290: tensor(88.1667), 300: tensor(88.4433), 310: tensor(88.3567), 320: tensor(88.6350), 330: tensor(88.9217), 340: tensor(89.3650), 350: tensor(89.9250)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=43, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 6.7251,                   Accuracy: 258/2000.0 (12.90%)



-= Testing valid =-
Test set: Average loss: 5.9768,                   Accuracy: 260/2000.0 (13.00%)



-= Testing valid =-
Test set: Average loss: 3.1104,                   Accuracy: 322/2000.0 (16.10%)



-= Testing valid =-
Test set: Average loss: 1.3930,                   Accuracy: 937/2000.0 (46.85%)



-= Testing valid =-
Test set: Average loss: 1.5779,                   Accuracy: 796/2000.0 (39.80%)



-= Testing valid =-
Test set: Average loss: 1.1616,                   Accuracy: 1211/2000.0 (60.55%)



-= Testing valid =-
Test set: Average loss: 1.5781,                   Accuracy: 933/2000.0 (46.65%)



-= Testing valid =-
Test set: Average loss: 1.1983,                   Accuracy: 1190/2000.0 (59.50%)



-= Testing valid =-
Test set: Average loss: 1.1074,                   Accuracy: 1208/2000.0 (60.40%)



-= Testing valid =-
Test set: Average loss: 2.2803,                   Accuracy: 713/2000.0 (35.65%)



Epoch 10 train accuracy: 68.94%, valid accuracy 35.65%
-= Testing valid =-
Test set: Average loss: 0.7556,                   Accuracy: 1575/2000.0 (78.75%)



-= Testing valid =-
Test set: Average loss: 0.7277,                   Accuracy: 1548/2000.0 (77.40%)



-= Testing valid =-
Test set: Average loss: 0.6124,                   Accuracy: 1632/2000.0 (81.60%)



-= Testing valid =-
Test set: Average loss: 0.8148,                   Accuracy: 1407/2000.0 (70.35%)



-= Testing valid =-
Test set: Average loss: 0.7772,                   Accuracy: 1493/2000.0 (74.65%)



-= Testing valid =-
Test set: Average loss: 0.6568,                   Accuracy: 1510/2000.0 (75.50%)



-= Testing valid =-
Test set: Average loss: 0.7653,                   Accuracy: 1501/2000.0 (75.05%)



-= Testing valid =-
Test set: Average loss: 0.3535,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.4698,                   Accuracy: 1724/2000.0 (86.20%)



-= Testing valid =-
Test set: Average loss: 0.8117,                   Accuracy: 1419/2000.0 (70.95%)



Epoch 20 train accuracy: 85.29%, valid accuracy 70.95%
-= Testing valid =-
Test set: Average loss: 0.5785,                   Accuracy: 1593/2000.0 (79.65%)



-= Testing valid =-
Test set: Average loss: 0.3865,                   Accuracy: 1764/2000.0 (88.20%)



-= Testing valid =-
Test set: Average loss: 0.3505,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.5927,                   Accuracy: 1565/2000.0 (78.25%)



-= Testing valid =-
Test set: Average loss: 0.4043,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.3396,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.3334,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.3333,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.5060,                   Accuracy: 1670/2000.0 (83.50%)



-= Testing valid =-
Test set: Average loss: 0.3172,                   Accuracy: 1821/2000.0 (91.05%)



Epoch 30 train accuracy: 88.95%, valid accuracy 91.05%
-= Testing valid =-
Test set: Average loss: 0.3528,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.3064,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.3759,                   Accuracy: 1780/2000.0 (89.00%)



-= Testing valid =-
Test set: Average loss: 0.3466,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.4113,                   Accuracy: 1749/2000.0 (87.45%)



-= Testing valid =-
Test set: Average loss: 0.3479,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.3962,                   Accuracy: 1764/2000.0 (88.20%)



-= Testing valid =-
Test set: Average loss: 0.3350,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.3320,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.4002,                   Accuracy: 1762/2000.0 (88.10%)



Epoch 40 train accuracy: 90.21%, valid accuracy 88.10%
-= Testing valid =-
Test set: Average loss: 0.3860,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 0.3240,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.3075,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.3308,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.3252,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.3131,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2657,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2834,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.3011,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.3456,                   Accuracy: 1793/2000.0 (89.65%)



Epoch 50 train accuracy: 90.34%, valid accuracy 89.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3145,                   Accuracy: 54237/60000 (90.39%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3393,                   Accuracy: 53716/60000 (89.53%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3526,                   Accuracy: 53522/60000 (89.20%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3828,                   Accuracy: 52957/60000 (88.26%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3959,                   Accuracy: 52608/60000 (87.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.4043,                   Accuracy: 52517/60000 (87.53%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.4033,                   Accuracy: 52519/60000 (87.53%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3910,                   Accuracy: 52825/60000 (88.04%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3753,                   Accuracy: 52963/60000 (88.27%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3838,                   Accuracy: 52920/60000 (88.20%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3935,                   Accuracy: 52655/60000 (87.76%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.4018,                   Accuracy: 52374/60000 (87.29%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4127,                   Accuracy: 52150/60000 (86.92%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4040,                   Accuracy: 52276/60000 (87.13%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3850,                   Accuracy: 52711/60000 (87.85%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3713,                   Accuracy: 52966/60000 (88.28%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3639,                   Accuracy: 53060/60000 (88.43%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3415,                   Accuracy: 53506/60000 (89.18%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3335,                   Accuracy: 53709/60000 (89.51%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3483,                   Accuracy: 53424/60000 (89.04%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3662,                   Accuracy: 53194/60000 (88.66%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3781,                   Accuracy: 53009/60000 (88.35%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3818,                   Accuracy: 52941/60000 (88.24%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3773,                   Accuracy: 53106/60000 (88.51%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3657,                   Accuracy: 53313/60000 (88.86%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3534,                   Accuracy: 53491/60000 (89.15%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3331,                   Accuracy: 53765/60000 (89.61%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3279,                   Accuracy: 53967/60000 (89.94%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3229,                   Accuracy: 54090/60000 (90.15%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3411,                   Accuracy: 53735/60000 (89.56%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3446,                   Accuracy: 53592/60000 (89.32%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3383,                   Accuracy: 53618/60000 (89.36%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3323,                   Accuracy: 53737/60000 (89.56%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3262,                   Accuracy: 53853/60000 (89.75%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3254,                   Accuracy: 53944/60000 (89.91%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3120,                   Accuracy: 54170/60000 (90.28%)
{0: tensor(90.3950), 10: tensor(89.5267), 20: tensor(89.2033), 30: tensor(88.2617), 40: tensor(87.6800), 50: tensor(87.5283), 60: tensor(87.5317), 70: tensor(88.0417), 80: tensor(88.2717), 90: tensor(88.2000), 100: tensor(87.7583), 110: tensor(87.2900), 120: tensor(86.9167), 130: tensor(87.1267), 140: tensor(87.8517), 150: tensor(88.2767), 160: tensor(88.4333), 170: tensor(89.1767), 180: tensor(89.5150), 190: tensor(89.0400), 200: tensor(88.6567), 210: tensor(88.3483), 220: tensor(88.2350), 230: tensor(88.5100), 240: tensor(88.8550), 250: tensor(89.1517), 260: tensor(89.6083), 270: tensor(89.9450), 280: tensor(90.1500), 290: tensor(89.5583), 300: tensor(89.3200), 310: tensor(89.3633), 320: tensor(89.5617), 330: tensor(89.7550), 340: tensor(89.9067), 350: tensor(90.2833)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=44, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.3159,                   Accuracy: 252/2000.0 (12.60%)



-= Testing valid =-
Test set: Average loss: 1.7559,                   Accuracy: 590/2000.0 (29.50%)



-= Testing valid =-
Test set: Average loss: 2.1058,                   Accuracy: 692/2000.0 (34.60%)



-= Testing valid =-
Test set: Average loss: 2.3662,                   Accuracy: 495/2000.0 (24.75%)



-= Testing valid =-
Test set: Average loss: 1.3269,                   Accuracy: 1030/2000.0 (51.50%)



-= Testing valid =-
Test set: Average loss: 1.5819,                   Accuracy: 927/2000.0 (46.35%)



-= Testing valid =-
Test set: Average loss: 1.0185,                   Accuracy: 1296/2000.0 (64.80%)



-= Testing valid =-
Test set: Average loss: 1.2936,                   Accuracy: 1131/2000.0 (56.55%)



-= Testing valid =-
Test set: Average loss: 0.8815,                   Accuracy: 1399/2000.0 (69.95%)



-= Testing valid =-
Test set: Average loss: 0.6269,                   Accuracy: 1589/2000.0 (79.45%)



Epoch 10 train accuracy: 76.04%, valid accuracy 79.45%
-= Testing valid =-
Test set: Average loss: 0.6994,                   Accuracy: 1475/2000.0 (73.75%)



-= Testing valid =-
Test set: Average loss: 0.4614,                   Accuracy: 1725/2000.0 (86.25%)



-= Testing valid =-
Test set: Average loss: 0.5495,                   Accuracy: 1656/2000.0 (82.80%)



-= Testing valid =-
Test set: Average loss: 0.5189,                   Accuracy: 1653/2000.0 (82.65%)



-= Testing valid =-
Test set: Average loss: 0.5445,                   Accuracy: 1624/2000.0 (81.20%)



-= Testing valid =-
Test set: Average loss: 0.5332,                   Accuracy: 1631/2000.0 (81.55%)



-= Testing valid =-
Test set: Average loss: 0.3230,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.3459,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3883,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.3980,                   Accuracy: 1744/2000.0 (87.20%)



Epoch 20 train accuracy: 86.38%, valid accuracy 87.20%
-= Testing valid =-
Test set: Average loss: 0.2979,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.3179,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.2688,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.3273,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.4133,                   Accuracy: 1709/2000.0 (85.45%)



-= Testing valid =-
Test set: Average loss: 0.3223,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.4101,                   Accuracy: 1717/2000.0 (85.85%)



-= Testing valid =-
Test set: Average loss: 0.3966,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.2652,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2521,                   Accuracy: 1851/2000.0 (92.55%)



Epoch 30 train accuracy: 88.57%, valid accuracy 92.55%
-= Testing valid =-
Test set: Average loss: 0.2352,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2751,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2140,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.2564,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2110,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.2727,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2892,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2218,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2849,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.2793,                   Accuracy: 1818/2000.0 (90.90%)



Epoch 40 train accuracy: 89.89%, valid accuracy 90.90%
-= Testing valid =-
Test set: Average loss: 0.2725,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2528,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2608,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2635,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2295,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2647,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2608,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2602,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2729,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2788,                   Accuracy: 1823/2000.0 (91.15%)



Epoch 50 train accuracy: 90.88%, valid accuracy 91.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2539,                   Accuracy: 55533/60000 (92.56%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2516,                   Accuracy: 55426/60000 (92.38%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2575,                   Accuracy: 55339/60000 (92.23%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2637,                   Accuracy: 55275/60000 (92.12%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2698,                   Accuracy: 55084/60000 (91.81%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2764,                   Accuracy: 54931/60000 (91.55%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2788,                   Accuracy: 54834/60000 (91.39%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2864,                   Accuracy: 54654/60000 (91.09%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2917,                   Accuracy: 54536/60000 (90.89%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3113,                   Accuracy: 54113/60000 (90.19%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3269,                   Accuracy: 53715/60000 (89.53%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3511,                   Accuracy: 53330/60000 (88.88%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3718,                   Accuracy: 52921/60000 (88.20%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3899,                   Accuracy: 52447/60000 (87.41%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.4078,                   Accuracy: 52037/60000 (86.73%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4087,                   Accuracy: 51822/60000 (86.37%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4124,                   Accuracy: 51529/60000 (85.88%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3955,                   Accuracy: 51825/60000 (86.38%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3805,                   Accuracy: 52200/60000 (87.00%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3628,                   Accuracy: 52681/60000 (87.80%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3626,                   Accuracy: 52651/60000 (87.75%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3531,                   Accuracy: 52901/60000 (88.17%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3445,                   Accuracy: 53121/60000 (88.54%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3408,                   Accuracy: 53300/60000 (88.83%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3312,                   Accuracy: 53423/60000 (89.04%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3329,                   Accuracy: 53437/60000 (89.06%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3178,                   Accuracy: 53716/60000 (89.53%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3073,                   Accuracy: 54186/60000 (90.31%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3011,                   Accuracy: 54315/60000 (90.53%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3075,                   Accuracy: 54374/60000 (90.62%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3045,                   Accuracy: 54402/60000 (90.67%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2997,                   Accuracy: 54600/60000 (91.00%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2948,                   Accuracy: 54695/60000 (91.16%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2836,                   Accuracy: 54929/60000 (91.55%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2713,                   Accuracy: 55177/60000 (91.96%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2545,                   Accuracy: 55481/60000 (92.47%)
{0: tensor(92.5550), 10: tensor(92.3767), 20: tensor(92.2317), 30: tensor(92.1250), 40: tensor(91.8067), 50: tensor(91.5517), 60: tensor(91.3900), 70: tensor(91.0900), 80: tensor(90.8933), 90: tensor(90.1883), 100: tensor(89.5250), 110: tensor(88.8833), 120: tensor(88.2017), 130: tensor(87.4117), 140: tensor(86.7283), 150: tensor(86.3700), 160: tensor(85.8817), 170: tensor(86.3750), 180: tensor(87.), 190: tensor(87.8017), 200: tensor(87.7517), 210: tensor(88.1683), 220: tensor(88.5350), 230: tensor(88.8333), 240: tensor(89.0383), 250: tensor(89.0617), 260: tensor(89.5267), 270: tensor(90.3100), 280: tensor(90.5250), 290: tensor(90.6233), 300: tensor(90.6700), 310: tensor(91.), 320: tensor(91.1583), 330: tensor(91.5483), 340: tensor(91.9617), 350: tensor(92.4683)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=45, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.9763,                   Accuracy: 222/2000.0 (11.10%)



-= Testing valid =-
Test set: Average loss: 3.6276,                   Accuracy: 294/2000.0 (14.70%)



-= Testing valid =-
Test set: Average loss: 1.3789,                   Accuracy: 1025/2000.0 (51.25%)



-= Testing valid =-
Test set: Average loss: 2.5678,                   Accuracy: 469/2000.0 (23.45%)



-= Testing valid =-
Test set: Average loss: 2.1301,                   Accuracy: 635/2000.0 (31.75%)



-= Testing valid =-
Test set: Average loss: 1.3232,                   Accuracy: 1030/2000.0 (51.50%)



-= Testing valid =-
Test set: Average loss: 1.6002,                   Accuracy: 985/2000.0 (49.25%)



-= Testing valid =-
Test set: Average loss: 1.5181,                   Accuracy: 980/2000.0 (49.00%)



-= Testing valid =-
Test set: Average loss: 0.8256,                   Accuracy: 1455/2000.0 (72.75%)



-= Testing valid =-
Test set: Average loss: 0.8540,                   Accuracy: 1414/2000.0 (70.70%)



Epoch 10 train accuracy: 69.61%, valid accuracy 70.70%
-= Testing valid =-
Test set: Average loss: 0.8956,                   Accuracy: 1309/2000.0 (65.45%)



-= Testing valid =-
Test set: Average loss: 0.7871,                   Accuracy: 1437/2000.0 (71.85%)



-= Testing valid =-
Test set: Average loss: 0.5484,                   Accuracy: 1630/2000.0 (81.50%)



-= Testing valid =-
Test set: Average loss: 0.5206,                   Accuracy: 1662/2000.0 (83.10%)



-= Testing valid =-
Test set: Average loss: 0.7471,                   Accuracy: 1402/2000.0 (70.10%)



-= Testing valid =-
Test set: Average loss: 0.6892,                   Accuracy: 1457/2000.0 (72.85%)



-= Testing valid =-
Test set: Average loss: 0.6416,                   Accuracy: 1536/2000.0 (76.80%)



-= Testing valid =-
Test set: Average loss: 0.5469,                   Accuracy: 1645/2000.0 (82.25%)



-= Testing valid =-
Test set: Average loss: 0.4560,                   Accuracy: 1693/2000.0 (84.65%)



-= Testing valid =-
Test set: Average loss: 0.4041,                   Accuracy: 1718/2000.0 (85.90%)



Epoch 20 train accuracy: 85.07%, valid accuracy 85.90%
-= Testing valid =-
Test set: Average loss: 0.3032,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.3406,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.4007,                   Accuracy: 1719/2000.0 (85.95%)



-= Testing valid =-
Test set: Average loss: 0.2958,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.3357,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.3013,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.2706,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.3248,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.2825,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.3579,                   Accuracy: 1747/2000.0 (87.35%)



Epoch 30 train accuracy: 88.57%, valid accuracy 87.35%
-= Testing valid =-
Test set: Average loss: 0.3321,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.3121,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.2990,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.3364,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.3175,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.3095,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2801,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2905,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2805,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2879,                   Accuracy: 1817/2000.0 (90.85%)



Epoch 40 train accuracy: 89.62%, valid accuracy 90.85%
-= Testing valid =-
Test set: Average loss: 0.2363,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2726,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.3012,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.2596,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2664,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2666,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2734,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2725,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.2603,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2452,                   Accuracy: 1838/2000.0 (91.90%)



Epoch 50 train accuracy: 90.65%, valid accuracy 91.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2833,                   Accuracy: 54952/60000 (91.59%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2910,                   Accuracy: 54726/60000 (91.21%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2978,                   Accuracy: 54635/60000 (91.06%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3174,                   Accuracy: 54270/60000 (90.45%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3289,                   Accuracy: 53928/60000 (89.88%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3419,                   Accuracy: 53644/60000 (89.41%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3529,                   Accuracy: 53369/60000 (88.95%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3641,                   Accuracy: 53060/60000 (88.43%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3532,                   Accuracy: 53212/60000 (88.69%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3765,                   Accuracy: 52816/60000 (88.03%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3768,                   Accuracy: 52824/60000 (88.04%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.4038,                   Accuracy: 52411/60000 (87.35%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4347,                   Accuracy: 51798/60000 (86.33%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4300,                   Accuracy: 51844/60000 (86.41%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.4193,                   Accuracy: 52120/60000 (86.87%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4074,                   Accuracy: 52335/60000 (87.22%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3864,                   Accuracy: 52708/60000 (87.85%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3608,                   Accuracy: 53108/60000 (88.51%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3585,                   Accuracy: 53128/60000 (88.55%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3570,                   Accuracy: 53170/60000 (88.62%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3496,                   Accuracy: 53336/60000 (88.89%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3483,                   Accuracy: 53492/60000 (89.15%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3449,                   Accuracy: 53599/60000 (89.33%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3422,                   Accuracy: 53680/60000 (89.47%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3419,                   Accuracy: 53840/60000 (89.73%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3294,                   Accuracy: 54037/60000 (90.06%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3008,                   Accuracy: 54558/60000 (90.93%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3088,                   Accuracy: 54512/60000 (90.85%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3062,                   Accuracy: 54505/60000 (90.84%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3281,                   Accuracy: 54185/60000 (90.31%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3516,                   Accuracy: 53658/60000 (89.43%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3571,                   Accuracy: 53434/60000 (89.06%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3534,                   Accuracy: 53553/60000 (89.25%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3382,                   Accuracy: 53771/60000 (89.62%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3231,                   Accuracy: 54085/60000 (90.14%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2920,                   Accuracy: 54748/60000 (91.25%)
{0: tensor(91.5867), 10: tensor(91.2100), 20: tensor(91.0583), 30: tensor(90.4500), 40: tensor(89.8800), 50: tensor(89.4067), 60: tensor(88.9483), 70: tensor(88.4333), 80: tensor(88.6867), 90: tensor(88.0267), 100: tensor(88.0400), 110: tensor(87.3517), 120: tensor(86.3300), 130: tensor(86.4067), 140: tensor(86.8667), 150: tensor(87.2250), 160: tensor(87.8467), 170: tensor(88.5133), 180: tensor(88.5467), 190: tensor(88.6167), 200: tensor(88.8933), 210: tensor(89.1533), 220: tensor(89.3317), 230: tensor(89.4667), 240: tensor(89.7333), 250: tensor(90.0617), 260: tensor(90.9300), 270: tensor(90.8533), 280: tensor(90.8417), 290: tensor(90.3083), 300: tensor(89.4300), 310: tensor(89.0567), 320: tensor(89.2550), 330: tensor(89.6183), 340: tensor(90.1417), 350: tensor(91.2467)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=46, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.9948,                   Accuracy: 243/2000.0 (12.15%)



-= Testing valid =-
Test set: Average loss: 2.7369,                   Accuracy: 316/2000.0 (15.80%)



-= Testing valid =-
Test set: Average loss: 2.9691,                   Accuracy: 509/2000.0 (25.45%)



-= Testing valid =-
Test set: Average loss: 1.6456,                   Accuracy: 871/2000.0 (43.55%)



-= Testing valid =-
Test set: Average loss: 1.3475,                   Accuracy: 1052/2000.0 (52.60%)



-= Testing valid =-
Test set: Average loss: 2.4332,                   Accuracy: 610/2000.0 (30.50%)



-= Testing valid =-
Test set: Average loss: 1.2672,                   Accuracy: 1036/2000.0 (51.80%)



-= Testing valid =-
Test set: Average loss: 1.0002,                   Accuracy: 1301/2000.0 (65.05%)



-= Testing valid =-
Test set: Average loss: 1.0984,                   Accuracy: 1241/2000.0 (62.05%)



-= Testing valid =-
Test set: Average loss: 0.7870,                   Accuracy: 1543/2000.0 (77.15%)



Epoch 10 train accuracy: 71.54%, valid accuracy 77.15%
-= Testing valid =-
Test set: Average loss: 0.6597,                   Accuracy: 1563/2000.0 (78.15%)



-= Testing valid =-
Test set: Average loss: 0.9441,                   Accuracy: 1290/2000.0 (64.50%)



-= Testing valid =-
Test set: Average loss: 0.5968,                   Accuracy: 1609/2000.0 (80.45%)



-= Testing valid =-
Test set: Average loss: 0.5186,                   Accuracy: 1706/2000.0 (85.30%)



-= Testing valid =-
Test set: Average loss: 0.5309,                   Accuracy: 1633/2000.0 (81.65%)



-= Testing valid =-
Test set: Average loss: 0.4091,                   Accuracy: 1752/2000.0 (87.60%)



-= Testing valid =-
Test set: Average loss: 0.3496,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.4154,                   Accuracy: 1717/2000.0 (85.85%)



-= Testing valid =-
Test set: Average loss: 0.6427,                   Accuracy: 1515/2000.0 (75.75%)



-= Testing valid =-
Test set: Average loss: 0.3902,                   Accuracy: 1694/2000.0 (84.70%)



Epoch 20 train accuracy: 85.12%, valid accuracy 84.70%
-= Testing valid =-
Test set: Average loss: 0.3528,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.3260,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.2319,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.3102,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.3080,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2918,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.2837,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.3002,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.3220,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.2851,                   Accuracy: 1813/2000.0 (90.65%)



Epoch 30 train accuracy: 87.99%, valid accuracy 90.65%
-= Testing valid =-
Test set: Average loss: 0.2721,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.2556,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2717,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2732,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2946,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.3509,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.2489,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2819,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.3078,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.2486,                   Accuracy: 1840/2000.0 (92.00%)



Epoch 40 train accuracy: 89.04%, valid accuracy 92.00%
-= Testing valid =-
Test set: Average loss: 0.2610,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2699,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2542,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2702,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2695,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2436,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2835,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2667,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2733,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2640,                   Accuracy: 1830/2000.0 (91.50%)



Epoch 50 train accuracy: 89.80%, valid accuracy 91.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2640,                   Accuracy: 55541/60000 (92.57%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2607,                   Accuracy: 55572/60000 (92.62%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2692,                   Accuracy: 55417/60000 (92.36%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2804,                   Accuracy: 55201/60000 (92.00%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2890,                   Accuracy: 54916/60000 (91.53%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3025,                   Accuracy: 54605/60000 (91.01%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3242,                   Accuracy: 53979/60000 (89.96%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3473,                   Accuracy: 53392/60000 (88.99%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3594,                   Accuracy: 53094/60000 (88.49%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3995,                   Accuracy: 52150/60000 (86.92%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.4189,                   Accuracy: 51545/60000 (85.91%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.4437,                   Accuracy: 50861/60000 (84.77%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4649,                   Accuracy: 50274/60000 (83.79%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4694,                   Accuracy: 50139/60000 (83.57%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.4850,                   Accuracy: 49753/60000 (82.92%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4993,                   Accuracy: 49171/60000 (81.95%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.5019,                   Accuracy: 49032/60000 (81.72%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.4886,                   Accuracy: 49338/60000 (82.23%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.4670,                   Accuracy: 49870/60000 (83.12%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.4598,                   Accuracy: 50077/60000 (83.46%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.4550,                   Accuracy: 50076/60000 (83.46%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4457,                   Accuracy: 50315/60000 (83.86%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4341,                   Accuracy: 50568/60000 (84.28%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4154,                   Accuracy: 51124/60000 (85.21%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3950,                   Accuracy: 51594/60000 (85.99%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3771,                   Accuracy: 52197/60000 (87.00%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3592,                   Accuracy: 52629/60000 (87.71%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3695,                   Accuracy: 52751/60000 (87.92%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3661,                   Accuracy: 53000/60000 (88.33%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3635,                   Accuracy: 53160/60000 (88.60%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3654,                   Accuracy: 53217/60000 (88.69%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3531,                   Accuracy: 53544/60000 (89.24%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3339,                   Accuracy: 54099/60000 (90.17%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3177,                   Accuracy: 54435/60000 (90.72%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2921,                   Accuracy: 55017/60000 (91.69%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2642,                   Accuracy: 55503/60000 (92.50%)
{0: tensor(92.5683), 10: tensor(92.6200), 20: tensor(92.3617), 30: tensor(92.0017), 40: tensor(91.5267), 50: tensor(91.0083), 60: tensor(89.9650), 70: tensor(88.9867), 80: tensor(88.4900), 90: tensor(86.9167), 100: tensor(85.9083), 110: tensor(84.7683), 120: tensor(83.7900), 130: tensor(83.5650), 140: tensor(82.9217), 150: tensor(81.9517), 160: tensor(81.7200), 170: tensor(82.2300), 180: tensor(83.1167), 190: tensor(83.4617), 200: tensor(83.4600), 210: tensor(83.8583), 220: tensor(84.2800), 230: tensor(85.2067), 240: tensor(85.9900), 250: tensor(86.9950), 260: tensor(87.7150), 270: tensor(87.9183), 280: tensor(88.3333), 290: tensor(88.6000), 300: tensor(88.6950), 310: tensor(89.2400), 320: tensor(90.1650), 330: tensor(90.7250), 340: tensor(91.6950), 350: tensor(92.5050)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=47, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 9.0178,                   Accuracy: 217/2000.0 (10.85%)



-= Testing valid =-
Test set: Average loss: 3.5893,                   Accuracy: 272/2000.0 (13.60%)



-= Testing valid =-
Test set: Average loss: 2.7570,                   Accuracy: 496/2000.0 (24.80%)



-= Testing valid =-
Test set: Average loss: 1.2164,                   Accuracy: 1063/2000.0 (53.15%)



-= Testing valid =-
Test set: Average loss: 1.5887,                   Accuracy: 709/2000.0 (35.45%)



-= Testing valid =-
Test set: Average loss: 1.2171,                   Accuracy: 1145/2000.0 (57.25%)



-= Testing valid =-
Test set: Average loss: 1.0872,                   Accuracy: 1243/2000.0 (62.15%)



-= Testing valid =-
Test set: Average loss: 1.3146,                   Accuracy: 1156/2000.0 (57.80%)



-= Testing valid =-
Test set: Average loss: 1.6467,                   Accuracy: 1014/2000.0 (50.70%)



-= Testing valid =-
Test set: Average loss: 0.7232,                   Accuracy: 1505/2000.0 (75.25%)



Epoch 10 train accuracy: 78.50%, valid accuracy 75.25%
-= Testing valid =-
Test set: Average loss: 0.4712,                   Accuracy: 1701/2000.0 (85.05%)



-= Testing valid =-
Test set: Average loss: 0.7461,                   Accuracy: 1520/2000.0 (76.00%)



-= Testing valid =-
Test set: Average loss: 0.4608,                   Accuracy: 1690/2000.0 (84.50%)



-= Testing valid =-
Test set: Average loss: 0.3553,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.5140,                   Accuracy: 1679/2000.0 (83.95%)



-= Testing valid =-
Test set: Average loss: 0.4081,                   Accuracy: 1719/2000.0 (85.95%)



-= Testing valid =-
Test set: Average loss: 0.2520,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2823,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.3538,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.4749,                   Accuracy: 1698/2000.0 (84.90%)



Epoch 20 train accuracy: 87.16%, valid accuracy 84.90%
-= Testing valid =-
Test set: Average loss: 0.3649,                   Accuracy: 1765/2000.0 (88.25%)



-= Testing valid =-
Test set: Average loss: 0.2543,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.3623,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.2776,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.3051,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.3446,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.3027,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.2609,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2735,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.3617,                   Accuracy: 1762/2000.0 (88.10%)



Epoch 30 train accuracy: 89.32%, valid accuracy 88.10%
-= Testing valid =-
Test set: Average loss: 0.2517,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2564,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.2618,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2862,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.2580,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.2431,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2871,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.2593,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2175,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.3034,                   Accuracy: 1797/2000.0 (89.85%)



Epoch 40 train accuracy: 90.74%, valid accuracy 89.85%
-= Testing valid =-
Test set: Average loss: 0.2530,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.2696,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2470,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2383,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2671,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2777,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2370,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2415,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2549,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2675,                   Accuracy: 1822/2000.0 (91.10%)



Epoch 50 train accuracy: 91.11%, valid accuracy 91.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2301,                   Accuracy: 55683/60000 (92.81%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2413,                   Accuracy: 55436/60000 (92.39%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2434,                   Accuracy: 55384/60000 (92.31%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2429,                   Accuracy: 55380/60000 (92.30%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2435,                   Accuracy: 55393/60000 (92.32%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2414,                   Accuracy: 55379/60000 (92.30%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2396,                   Accuracy: 55366/60000 (92.28%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2358,                   Accuracy: 55496/60000 (92.49%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2399,                   Accuracy: 55315/60000 (92.19%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2313,                   Accuracy: 55572/60000 (92.62%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2490,                   Accuracy: 55134/60000 (91.89%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2504,                   Accuracy: 55231/60000 (92.05%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.2584,                   Accuracy: 55109/60000 (91.85%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.2722,                   Accuracy: 54800/60000 (91.33%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.2776,                   Accuracy: 54716/60000 (91.19%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.2833,                   Accuracy: 54579/60000 (90.96%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2816,                   Accuracy: 54633/60000 (91.06%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.2850,                   Accuracy: 54427/60000 (90.71%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.2750,                   Accuracy: 54689/60000 (91.15%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.2875,                   Accuracy: 54488/60000 (90.81%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2709,                   Accuracy: 54843/60000 (91.40%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.2684,                   Accuracy: 54882/60000 (91.47%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.2593,                   Accuracy: 55082/60000 (91.80%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.2551,                   Accuracy: 55200/60000 (92.00%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.2477,                   Accuracy: 55383/60000 (92.31%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2467,                   Accuracy: 55408/60000 (92.35%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2550,                   Accuracy: 55156/60000 (91.93%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2411,                   Accuracy: 55504/60000 (92.51%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2551,                   Accuracy: 55226/60000 (92.04%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2480,                   Accuracy: 55399/60000 (92.33%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2452,                   Accuracy: 55530/60000 (92.55%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2439,                   Accuracy: 55521/60000 (92.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2449,                   Accuracy: 55488/60000 (92.48%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2459,                   Accuracy: 55421/60000 (92.37%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2438,                   Accuracy: 55447/60000 (92.41%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2430,                   Accuracy: 55392/60000 (92.32%)
{0: tensor(92.8050), 10: tensor(92.3933), 20: tensor(92.3067), 30: tensor(92.3000), 40: tensor(92.3217), 50: tensor(92.2983), 60: tensor(92.2767), 70: tensor(92.4933), 80: tensor(92.1917), 90: tensor(92.6200), 100: tensor(91.8900), 110: tensor(92.0517), 120: tensor(91.8483), 130: tensor(91.3333), 140: tensor(91.1933), 150: tensor(90.9650), 160: tensor(91.0550), 170: tensor(90.7117), 180: tensor(91.1483), 190: tensor(90.8133), 200: tensor(91.4050), 210: tensor(91.4700), 220: tensor(91.8033), 230: tensor(92.), 240: tensor(92.3050), 250: tensor(92.3467), 260: tensor(91.9267), 270: tensor(92.5067), 280: tensor(92.0433), 290: tensor(92.3317), 300: tensor(92.5500), 310: tensor(92.5350), 320: tensor(92.4800), 330: tensor(92.3683), 340: tensor(92.4117), 350: tensor(92.3200)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=48, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 6.1550,                   Accuracy: 224/2000.0 (11.20%)



-= Testing valid =-
Test set: Average loss: 2.0946,                   Accuracy: 492/2000.0 (24.60%)



-= Testing valid =-
Test set: Average loss: 1.6829,                   Accuracy: 844/2000.0 (42.20%)



-= Testing valid =-
Test set: Average loss: 1.5099,                   Accuracy: 897/2000.0 (44.85%)



-= Testing valid =-
Test set: Average loss: 2.8113,                   Accuracy: 447/2000.0 (22.35%)



-= Testing valid =-
Test set: Average loss: 2.1856,                   Accuracy: 654/2000.0 (32.70%)



-= Testing valid =-
Test set: Average loss: 1.1506,                   Accuracy: 1240/2000.0 (62.00%)



-= Testing valid =-
Test set: Average loss: 1.0329,                   Accuracy: 1358/2000.0 (67.90%)



-= Testing valid =-
Test set: Average loss: 1.2863,                   Accuracy: 1085/2000.0 (54.25%)



-= Testing valid =-
Test set: Average loss: 1.2707,                   Accuracy: 1018/2000.0 (50.90%)



Epoch 10 train accuracy: 68.44%, valid accuracy 50.90%
-= Testing valid =-
Test set: Average loss: 1.1841,                   Accuracy: 1129/2000.0 (56.45%)



-= Testing valid =-
Test set: Average loss: 1.3221,                   Accuracy: 1005/2000.0 (50.25%)



-= Testing valid =-
Test set: Average loss: 1.3362,                   Accuracy: 1083/2000.0 (54.15%)



-= Testing valid =-
Test set: Average loss: 0.8742,                   Accuracy: 1396/2000.0 (69.80%)



-= Testing valid =-
Test set: Average loss: 0.6943,                   Accuracy: 1543/2000.0 (77.15%)



-= Testing valid =-
Test set: Average loss: 0.6551,                   Accuracy: 1519/2000.0 (75.95%)



-= Testing valid =-
Test set: Average loss: 0.5371,                   Accuracy: 1636/2000.0 (81.80%)



-= Testing valid =-
Test set: Average loss: 0.4277,                   Accuracy: 1719/2000.0 (85.95%)



-= Testing valid =-
Test set: Average loss: 0.5375,                   Accuracy: 1627/2000.0 (81.35%)



-= Testing valid =-
Test set: Average loss: 0.3783,                   Accuracy: 1757/2000.0 (87.85%)



Epoch 20 train accuracy: 85.14%, valid accuracy 87.85%
-= Testing valid =-
Test set: Average loss: 0.4372,                   Accuracy: 1724/2000.0 (86.20%)



-= Testing valid =-
Test set: Average loss: 0.4255,                   Accuracy: 1715/2000.0 (85.75%)



-= Testing valid =-
Test set: Average loss: 0.3956,                   Accuracy: 1740/2000.0 (87.00%)



-= Testing valid =-
Test set: Average loss: 0.4130,                   Accuracy: 1730/2000.0 (86.50%)



-= Testing valid =-
Test set: Average loss: 0.4231,                   Accuracy: 1714/2000.0 (85.70%)



-= Testing valid =-
Test set: Average loss: 0.3915,                   Accuracy: 1745/2000.0 (87.25%)



-= Testing valid =-
Test set: Average loss: 0.4291,                   Accuracy: 1715/2000.0 (85.75%)



-= Testing valid =-
Test set: Average loss: 0.3812,                   Accuracy: 1755/2000.0 (87.75%)



-= Testing valid =-
Test set: Average loss: 0.4845,                   Accuracy: 1659/2000.0 (82.95%)



-= Testing valid =-
Test set: Average loss: 0.3176,                   Accuracy: 1776/2000.0 (88.80%)



Epoch 30 train accuracy: 88.09%, valid accuracy 88.80%
-= Testing valid =-
Test set: Average loss: 0.2772,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.3646,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.3636,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.3695,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.3009,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.2977,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.2885,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2938,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2691,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.3261,                   Accuracy: 1795/2000.0 (89.75%)



Epoch 40 train accuracy: 89.44%, valid accuracy 89.75%
-= Testing valid =-
Test set: Average loss: 0.2632,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.3122,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.2893,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.3029,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.3136,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.3083,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.2819,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.3060,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.2903,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.3260,                   Accuracy: 1791/2000.0 (89.55%)



Epoch 50 train accuracy: 90.26%, valid accuracy 89.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3080,                   Accuracy: 54545/60000 (90.91%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3158,                   Accuracy: 54308/60000 (90.51%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3066,                   Accuracy: 54542/60000 (90.90%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3256,                   Accuracy: 54039/60000 (90.07%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3294,                   Accuracy: 53995/60000 (89.99%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3359,                   Accuracy: 53949/60000 (89.92%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3369,                   Accuracy: 53964/60000 (89.94%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3199,                   Accuracy: 54413/60000 (90.69%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3271,                   Accuracy: 54109/60000 (90.18%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3206,                   Accuracy: 54296/60000 (90.49%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3292,                   Accuracy: 54027/60000 (90.04%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3247,                   Accuracy: 54259/60000 (90.43%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3611,                   Accuracy: 53372/60000 (88.95%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3520,                   Accuracy: 53559/60000 (89.26%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3601,                   Accuracy: 53440/60000 (89.07%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3570,                   Accuracy: 53386/60000 (88.98%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3520,                   Accuracy: 53336/60000 (88.89%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3578,                   Accuracy: 53137/60000 (88.56%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3469,                   Accuracy: 53431/60000 (89.05%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3736,                   Accuracy: 52840/60000 (88.07%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3945,                   Accuracy: 52373/60000 (87.29%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4268,                   Accuracy: 51641/60000 (86.07%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4473,                   Accuracy: 51144/60000 (85.24%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4593,                   Accuracy: 50832/60000 (84.72%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4541,                   Accuracy: 50960/60000 (84.93%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.4405,                   Accuracy: 51260/60000 (85.43%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.4452,                   Accuracy: 50997/60000 (85.00%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4192,                   Accuracy: 51808/60000 (86.35%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4091,                   Accuracy: 52162/60000 (86.94%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3972,                   Accuracy: 52466/60000 (87.44%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.4145,                   Accuracy: 52233/60000 (87.06%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3939,                   Accuracy: 52773/60000 (87.96%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3889,                   Accuracy: 52954/60000 (88.26%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3825,                   Accuracy: 53021/60000 (88.37%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3523,                   Accuracy: 53559/60000 (89.26%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3409,                   Accuracy: 53792/60000 (89.65%)
{0: tensor(90.9083), 10: tensor(90.5133), 20: tensor(90.9033), 30: tensor(90.0650), 40: tensor(89.9917), 50: tensor(89.9150), 60: tensor(89.9400), 70: tensor(90.6883), 80: tensor(90.1817), 90: tensor(90.4933), 100: tensor(90.0450), 110: tensor(90.4317), 120: tensor(88.9533), 130: tensor(89.2650), 140: tensor(89.0667), 150: tensor(88.9767), 160: tensor(88.8933), 170: tensor(88.5617), 180: tensor(89.0517), 190: tensor(88.0667), 200: tensor(87.2883), 210: tensor(86.0683), 220: tensor(85.2400), 230: tensor(84.7200), 240: tensor(84.9333), 250: tensor(85.4333), 260: tensor(84.9950), 270: tensor(86.3467), 280: tensor(86.9367), 290: tensor(87.4433), 300: tensor(87.0550), 310: tensor(87.9550), 320: tensor(88.2567), 330: tensor(88.3683), 340: tensor(89.2650), 350: tensor(89.6533)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=49, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.9675,                   Accuracy: 549/2000.0 (27.45%)



-= Testing valid =-
Test set: Average loss: 4.9673,                   Accuracy: 245/2000.0 (12.25%)



-= Testing valid =-
Test set: Average loss: 1.7021,                   Accuracy: 692/2000.0 (34.60%)



-= Testing valid =-
Test set: Average loss: 1.2589,                   Accuracy: 1096/2000.0 (54.80%)



-= Testing valid =-
Test set: Average loss: 1.3713,                   Accuracy: 967/2000.0 (48.35%)



-= Testing valid =-
Test set: Average loss: 1.1366,                   Accuracy: 1222/2000.0 (61.10%)



-= Testing valid =-
Test set: Average loss: 1.1349,                   Accuracy: 1201/2000.0 (60.05%)



-= Testing valid =-
Test set: Average loss: 0.9237,                   Accuracy: 1338/2000.0 (66.90%)



-= Testing valid =-
Test set: Average loss: 0.9729,                   Accuracy: 1397/2000.0 (69.85%)



-= Testing valid =-
Test set: Average loss: 1.0127,                   Accuracy: 1288/2000.0 (64.40%)



Epoch 10 train accuracy: 69.11%, valid accuracy 64.40%
-= Testing valid =-
Test set: Average loss: 1.1131,                   Accuracy: 1198/2000.0 (59.90%)



-= Testing valid =-
Test set: Average loss: 0.8323,                   Accuracy: 1452/2000.0 (72.60%)



-= Testing valid =-
Test set: Average loss: 0.8535,                   Accuracy: 1424/2000.0 (71.20%)



-= Testing valid =-
Test set: Average loss: 0.6020,                   Accuracy: 1655/2000.0 (82.75%)



-= Testing valid =-
Test set: Average loss: 0.6245,                   Accuracy: 1598/2000.0 (79.90%)



-= Testing valid =-
Test set: Average loss: 0.5232,                   Accuracy: 1690/2000.0 (84.50%)



-= Testing valid =-
Test set: Average loss: 0.4312,                   Accuracy: 1760/2000.0 (88.00%)



-= Testing valid =-
Test set: Average loss: 0.4279,                   Accuracy: 1726/2000.0 (86.30%)



-= Testing valid =-
Test set: Average loss: 0.4288,                   Accuracy: 1738/2000.0 (86.90%)



-= Testing valid =-
Test set: Average loss: 0.4452,                   Accuracy: 1705/2000.0 (85.25%)



Epoch 20 train accuracy: 84.16%, valid accuracy 85.25%
-= Testing valid =-
Test set: Average loss: 0.3614,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.3001,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.3125,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.2947,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.3199,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.3456,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.3057,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2849,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.2589,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2811,                   Accuracy: 1810/2000.0 (90.50%)



Epoch 30 train accuracy: 88.60%, valid accuracy 90.50%
-= Testing valid =-
Test set: Average loss: 0.2782,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2776,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2287,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2703,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2246,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2371,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2573,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2467,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2669,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2469,                   Accuracy: 1838/2000.0 (91.90%)



Epoch 40 train accuracy: 90.00%, valid accuracy 91.90%
-= Testing valid =-
Test set: Average loss: 0.2631,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2645,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2617,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2475,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2587,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2443,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2508,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2598,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2521,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2468,                   Accuracy: 1836/2000.0 (91.80%)



Epoch 50 train accuracy: 90.60%, valid accuracy 91.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2482,                   Accuracy: 55428/60000 (92.38%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2638,                   Accuracy: 55105/60000 (91.84%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2532,                   Accuracy: 55364/60000 (92.27%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2524,                   Accuracy: 55447/60000 (92.41%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2502,                   Accuracy: 55530/60000 (92.55%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2536,                   Accuracy: 55486/60000 (92.48%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2601,                   Accuracy: 55295/60000 (92.16%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2631,                   Accuracy: 55208/60000 (92.01%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2700,                   Accuracy: 54973/60000 (91.62%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2743,                   Accuracy: 54895/60000 (91.49%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3056,                   Accuracy: 54178/60000 (90.30%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3222,                   Accuracy: 53914/60000 (89.86%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3400,                   Accuracy: 53627/60000 (89.38%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3543,                   Accuracy: 53260/60000 (88.77%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3677,                   Accuracy: 52969/60000 (88.28%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3714,                   Accuracy: 52778/60000 (87.96%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3630,                   Accuracy: 52836/60000 (88.06%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3699,                   Accuracy: 52630/60000 (87.72%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3545,                   Accuracy: 52963/60000 (88.27%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3755,                   Accuracy: 52634/60000 (87.72%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3589,                   Accuracy: 52873/60000 (88.12%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3630,                   Accuracy: 52860/60000 (88.10%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3603,                   Accuracy: 53019/60000 (88.36%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3564,                   Accuracy: 53057/60000 (88.43%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3421,                   Accuracy: 53401/60000 (89.00%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3287,                   Accuracy: 53605/60000 (89.34%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3183,                   Accuracy: 53869/60000 (89.78%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2991,                   Accuracy: 54329/60000 (90.55%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3112,                   Accuracy: 54049/60000 (90.08%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2950,                   Accuracy: 54653/60000 (91.09%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2899,                   Accuracy: 54846/60000 (91.41%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2805,                   Accuracy: 55052/60000 (91.75%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2737,                   Accuracy: 55188/60000 (91.98%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2716,                   Accuracy: 55173/60000 (91.96%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2635,                   Accuracy: 55238/60000 (92.06%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2588,                   Accuracy: 55246/60000 (92.08%)
{0: tensor(92.3800), 10: tensor(91.8417), 20: tensor(92.2733), 30: tensor(92.4117), 40: tensor(92.5500), 50: tensor(92.4767), 60: tensor(92.1583), 70: tensor(92.0133), 80: tensor(91.6217), 90: tensor(91.4917), 100: tensor(90.2967), 110: tensor(89.8567), 120: tensor(89.3783), 130: tensor(88.7667), 140: tensor(88.2817), 150: tensor(87.9633), 160: tensor(88.0600), 170: tensor(87.7167), 180: tensor(88.2717), 190: tensor(87.7233), 200: tensor(88.1217), 210: tensor(88.1000), 220: tensor(88.3650), 230: tensor(88.4283), 240: tensor(89.0017), 250: tensor(89.3417), 260: tensor(89.7817), 270: tensor(90.5483), 280: tensor(90.0817), 290: tensor(91.0883), 300: tensor(91.4100), 310: tensor(91.7533), 320: tensor(91.9800), 330: tensor(91.9550), 340: tensor(92.0633), 350: tensor(92.0767)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=50, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.7281,                   Accuracy: 247/2000.0 (12.35%)



-= Testing valid =-
Test set: Average loss: 1.8512,                   Accuracy: 700/2000.0 (35.00%)



-= Testing valid =-
Test set: Average loss: 1.8551,                   Accuracy: 742/2000.0 (37.10%)



-= Testing valid =-
Test set: Average loss: 1.4527,                   Accuracy: 973/2000.0 (48.65%)



-= Testing valid =-
Test set: Average loss: 1.4063,                   Accuracy: 953/2000.0 (47.65%)



-= Testing valid =-
Test set: Average loss: 1.0882,                   Accuracy: 1211/2000.0 (60.55%)



-= Testing valid =-
Test set: Average loss: 0.9819,                   Accuracy: 1360/2000.0 (68.00%)



-= Testing valid =-
Test set: Average loss: 0.7928,                   Accuracy: 1510/2000.0 (75.50%)



-= Testing valid =-
Test set: Average loss: 1.0134,                   Accuracy: 1261/2000.0 (63.05%)



-= Testing valid =-
Test set: Average loss: 0.8501,                   Accuracy: 1406/2000.0 (70.30%)



Epoch 10 train accuracy: 72.78%, valid accuracy 70.30%
-= Testing valid =-
Test set: Average loss: 0.6416,                   Accuracy: 1617/2000.0 (80.85%)



-= Testing valid =-
Test set: Average loss: 0.6233,                   Accuracy: 1634/2000.0 (81.70%)



-= Testing valid =-
Test set: Average loss: 0.6643,                   Accuracy: 1546/2000.0 (77.30%)



-= Testing valid =-
Test set: Average loss: 0.5660,                   Accuracy: 1665/2000.0 (83.25%)



-= Testing valid =-
Test set: Average loss: 0.5010,                   Accuracy: 1670/2000.0 (83.50%)



-= Testing valid =-
Test set: Average loss: 0.4761,                   Accuracy: 1710/2000.0 (85.50%)



-= Testing valid =-
Test set: Average loss: 0.9143,                   Accuracy: 1369/2000.0 (68.45%)



-= Testing valid =-
Test set: Average loss: 0.5129,                   Accuracy: 1648/2000.0 (82.40%)



-= Testing valid =-
Test set: Average loss: 0.5211,                   Accuracy: 1682/2000.0 (84.10%)



-= Testing valid =-
Test set: Average loss: 0.5841,                   Accuracy: 1588/2000.0 (79.40%)



Epoch 20 train accuracy: 84.71%, valid accuracy 79.40%
-= Testing valid =-
Test set: Average loss: 0.4624,                   Accuracy: 1711/2000.0 (85.55%)



-= Testing valid =-
Test set: Average loss: 0.4041,                   Accuracy: 1742/2000.0 (87.10%)



-= Testing valid =-
Test set: Average loss: 0.4556,                   Accuracy: 1670/2000.0 (83.50%)



-= Testing valid =-
Test set: Average loss: 0.3693,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 0.4151,                   Accuracy: 1716/2000.0 (85.80%)



-= Testing valid =-
Test set: Average loss: 0.4188,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.4185,                   Accuracy: 1689/2000.0 (84.45%)



-= Testing valid =-
Test set: Average loss: 0.4353,                   Accuracy: 1680/2000.0 (84.00%)



-= Testing valid =-
Test set: Average loss: 0.3990,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.3983,                   Accuracy: 1742/2000.0 (87.10%)



Epoch 30 train accuracy: 87.97%, valid accuracy 87.10%
-= Testing valid =-
Test set: Average loss: 0.3057,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.3760,                   Accuracy: 1728/2000.0 (86.40%)



-= Testing valid =-
Test set: Average loss: 0.3653,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.4218,                   Accuracy: 1705/2000.0 (85.25%)



-= Testing valid =-
Test set: Average loss: 0.3073,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.2419,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.3072,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.2752,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.3014,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.2974,                   Accuracy: 1807/2000.0 (90.35%)



Epoch 40 train accuracy: 89.35%, valid accuracy 90.35%
-= Testing valid =-
Test set: Average loss: 0.2961,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2931,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.2822,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2851,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2625,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2641,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2655,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.3372,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.2818,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2597,                   Accuracy: 1834/2000.0 (91.70%)



Epoch 50 train accuracy: 89.88%, valid accuracy 91.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2880,                   Accuracy: 54968/60000 (91.61%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2849,                   Accuracy: 55017/60000 (91.69%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2830,                   Accuracy: 55065/60000 (91.78%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2860,                   Accuracy: 55034/60000 (91.72%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2849,                   Accuracy: 55013/60000 (91.69%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2852,                   Accuracy: 55066/60000 (91.78%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2920,                   Accuracy: 54843/60000 (91.40%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2940,                   Accuracy: 54751/60000 (91.25%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2919,                   Accuracy: 54677/60000 (91.13%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2935,                   Accuracy: 54707/60000 (91.18%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2992,                   Accuracy: 54521/60000 (90.87%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2967,                   Accuracy: 54637/60000 (91.06%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3153,                   Accuracy: 54258/60000 (90.43%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3276,                   Accuracy: 53908/60000 (89.85%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3391,                   Accuracy: 53617/60000 (89.36%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3556,                   Accuracy: 53029/60000 (88.38%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3603,                   Accuracy: 52796/60000 (87.99%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3461,                   Accuracy: 53189/60000 (88.65%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3646,                   Accuracy: 52550/60000 (87.58%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3756,                   Accuracy: 52211/60000 (87.02%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3928,                   Accuracy: 51596/60000 (85.99%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4108,                   Accuracy: 51001/60000 (85.00%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4189,                   Accuracy: 50865/60000 (84.78%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4200,                   Accuracy: 50897/60000 (84.83%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4044,                   Accuracy: 51402/60000 (85.67%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3917,                   Accuracy: 51955/60000 (86.59%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3573,                   Accuracy: 52864/60000 (88.11%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3662,                   Accuracy: 52623/60000 (87.71%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3587,                   Accuracy: 52973/60000 (88.29%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3544,                   Accuracy: 53065/60000 (88.44%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3578,                   Accuracy: 53075/60000 (88.46%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3493,                   Accuracy: 53308/60000 (88.85%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3389,                   Accuracy: 53573/60000 (89.29%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3235,                   Accuracy: 53955/60000 (89.93%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3078,                   Accuracy: 54415/60000 (90.69%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2879,                   Accuracy: 54872/60000 (91.45%)
{0: tensor(91.6133), 10: tensor(91.6950), 20: tensor(91.7750), 30: tensor(91.7233), 40: tensor(91.6883), 50: tensor(91.7767), 60: tensor(91.4050), 70: tensor(91.2517), 80: tensor(91.1283), 90: tensor(91.1783), 100: tensor(90.8683), 110: tensor(91.0617), 120: tensor(90.4300), 130: tensor(89.8467), 140: tensor(89.3617), 150: tensor(88.3817), 160: tensor(87.9933), 170: tensor(88.6483), 180: tensor(87.5833), 190: tensor(87.0183), 200: tensor(85.9933), 210: tensor(85.0017), 220: tensor(84.7750), 230: tensor(84.8283), 240: tensor(85.6700), 250: tensor(86.5917), 260: tensor(88.1067), 270: tensor(87.7050), 280: tensor(88.2883), 290: tensor(88.4417), 300: tensor(88.4583), 310: tensor(88.8467), 320: tensor(89.2883), 330: tensor(89.9250), 340: tensor(90.6917), 350: tensor(91.4533)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=51, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.6406,                   Accuracy: 232/2000.0 (11.60%)



-= Testing valid =-
Test set: Average loss: 3.4608,                   Accuracy: 276/2000.0 (13.80%)



-= Testing valid =-
Test set: Average loss: 2.0093,                   Accuracy: 633/2000.0 (31.65%)



-= Testing valid =-
Test set: Average loss: 1.7573,                   Accuracy: 718/2000.0 (35.90%)



-= Testing valid =-
Test set: Average loss: 1.8048,                   Accuracy: 600/2000.0 (30.00%)



-= Testing valid =-
Test set: Average loss: 1.6884,                   Accuracy: 887/2000.0 (44.35%)



-= Testing valid =-
Test set: Average loss: 1.6958,                   Accuracy: 798/2000.0 (39.90%)



-= Testing valid =-
Test set: Average loss: 1.4748,                   Accuracy: 813/2000.0 (40.65%)



-= Testing valid =-
Test set: Average loss: 1.0859,                   Accuracy: 1299/2000.0 (64.95%)



-= Testing valid =-
Test set: Average loss: 1.2359,                   Accuracy: 1161/2000.0 (58.05%)



Epoch 10 train accuracy: 66.75%, valid accuracy 58.05%
-= Testing valid =-
Test set: Average loss: 1.2695,                   Accuracy: 1143/2000.0 (57.15%)



-= Testing valid =-
Test set: Average loss: 0.9260,                   Accuracy: 1334/2000.0 (66.70%)



-= Testing valid =-
Test set: Average loss: 1.1892,                   Accuracy: 1197/2000.0 (59.85%)



-= Testing valid =-
Test set: Average loss: 0.9899,                   Accuracy: 1262/2000.0 (63.10%)



-= Testing valid =-
Test set: Average loss: 1.4219,                   Accuracy: 1116/2000.0 (55.80%)



-= Testing valid =-
Test set: Average loss: 0.8068,                   Accuracy: 1406/2000.0 (70.30%)



-= Testing valid =-
Test set: Average loss: 0.7653,                   Accuracy: 1495/2000.0 (74.75%)



-= Testing valid =-
Test set: Average loss: 0.5059,                   Accuracy: 1676/2000.0 (83.80%)



-= Testing valid =-
Test set: Average loss: 0.4757,                   Accuracy: 1665/2000.0 (83.25%)



-= Testing valid =-
Test set: Average loss: 0.6693,                   Accuracy: 1531/2000.0 (76.55%)



Epoch 20 train accuracy: 85.71%, valid accuracy 76.55%
-= Testing valid =-
Test set: Average loss: 0.5531,                   Accuracy: 1635/2000.0 (81.75%)



-= Testing valid =-
Test set: Average loss: 0.4644,                   Accuracy: 1681/2000.0 (84.05%)



-= Testing valid =-
Test set: Average loss: 0.4834,                   Accuracy: 1662/2000.0 (83.10%)



-= Testing valid =-
Test set: Average loss: 0.4858,                   Accuracy: 1679/2000.0 (83.95%)



-= Testing valid =-
Test set: Average loss: 0.3668,                   Accuracy: 1768/2000.0 (88.40%)



-= Testing valid =-
Test set: Average loss: 0.4450,                   Accuracy: 1721/2000.0 (86.05%)



-= Testing valid =-
Test set: Average loss: 0.6044,                   Accuracy: 1549/2000.0 (77.45%)



-= Testing valid =-
Test set: Average loss: 0.4257,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.3541,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.4193,                   Accuracy: 1722/2000.0 (86.10%)



Epoch 30 train accuracy: 88.75%, valid accuracy 86.10%
-= Testing valid =-
Test set: Average loss: 0.3773,                   Accuracy: 1740/2000.0 (87.00%)



-= Testing valid =-
Test set: Average loss: 0.3391,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.3401,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.3114,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.4573,                   Accuracy: 1678/2000.0 (83.90%)



-= Testing valid =-
Test set: Average loss: 0.3762,                   Accuracy: 1749/2000.0 (87.45%)



-= Testing valid =-
Test set: Average loss: 0.3696,                   Accuracy: 1756/2000.0 (87.80%)



-= Testing valid =-
Test set: Average loss: 0.3392,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.3103,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.3295,                   Accuracy: 1784/2000.0 (89.20%)



Epoch 40 train accuracy: 90.14%, valid accuracy 89.20%
-= Testing valid =-
Test set: Average loss: 0.3082,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2954,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.3124,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.2926,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.2739,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.3286,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.3347,                   Accuracy: 1777/2000.0 (88.85%)



-= Testing valid =-
Test set: Average loss: 0.3178,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.3213,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.3152,                   Accuracy: 1803/2000.0 (90.15%)



Epoch 50 train accuracy: 90.36%, valid accuracy 90.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2981,                   Accuracy: 54619/60000 (91.03%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2959,                   Accuracy: 54471/60000 (90.79%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2977,                   Accuracy: 54633/60000 (91.06%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3031,                   Accuracy: 54541/60000 (90.90%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3026,                   Accuracy: 54587/60000 (90.98%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3046,                   Accuracy: 54552/60000 (90.92%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3115,                   Accuracy: 54364/60000 (90.61%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3176,                   Accuracy: 54349/60000 (90.58%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3198,                   Accuracy: 54180/60000 (90.30%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3382,                   Accuracy: 53829/60000 (89.71%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3727,                   Accuracy: 53030/60000 (88.38%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3974,                   Accuracy: 52600/60000 (87.67%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4192,                   Accuracy: 52094/60000 (86.82%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4187,                   Accuracy: 51956/60000 (86.59%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.4119,                   Accuracy: 52077/60000 (86.79%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4025,                   Accuracy: 52219/60000 (87.03%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3969,                   Accuracy: 52301/60000 (87.17%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3870,                   Accuracy: 52258/60000 (87.10%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3754,                   Accuracy: 52721/60000 (87.87%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3809,                   Accuracy: 52606/60000 (87.68%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3867,                   Accuracy: 52544/60000 (87.57%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3832,                   Accuracy: 52580/60000 (87.63%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3785,                   Accuracy: 52706/60000 (87.84%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3705,                   Accuracy: 52876/60000 (88.13%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3605,                   Accuracy: 53082/60000 (88.47%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3593,                   Accuracy: 53172/60000 (88.62%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3397,                   Accuracy: 53527/60000 (89.21%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3395,                   Accuracy: 53679/60000 (89.46%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3481,                   Accuracy: 53583/60000 (89.31%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3554,                   Accuracy: 53529/60000 (89.21%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3595,                   Accuracy: 53456/60000 (89.09%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3535,                   Accuracy: 53514/60000 (89.19%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3430,                   Accuracy: 53827/60000 (89.71%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3336,                   Accuracy: 53860/60000 (89.77%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3235,                   Accuracy: 54132/60000 (90.22%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3029,                   Accuracy: 54454/60000 (90.76%)
{0: tensor(91.0317), 10: tensor(90.7850), 20: tensor(91.0550), 30: tensor(90.9017), 40: tensor(90.9783), 50: tensor(90.9200), 60: tensor(90.6067), 70: tensor(90.5817), 80: tensor(90.3000), 90: tensor(89.7150), 100: tensor(88.3833), 110: tensor(87.6667), 120: tensor(86.8233), 130: tensor(86.5933), 140: tensor(86.7950), 150: tensor(87.0317), 160: tensor(87.1683), 170: tensor(87.0967), 180: tensor(87.8683), 190: tensor(87.6767), 200: tensor(87.5733), 210: tensor(87.6333), 220: tensor(87.8433), 230: tensor(88.1267), 240: tensor(88.4700), 250: tensor(88.6200), 260: tensor(89.2117), 270: tensor(89.4650), 280: tensor(89.3050), 290: tensor(89.2150), 300: tensor(89.0933), 310: tensor(89.1900), 320: tensor(89.7117), 330: tensor(89.7667), 340: tensor(90.2200), 350: tensor(90.7567)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=52, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3205,                   Accuracy: 540/2000.0 (27.00%)



-= Testing valid =-
Test set: Average loss: 3.3511,                   Accuracy: 281/2000.0 (14.05%)



-= Testing valid =-
Test set: Average loss: 2.7841,                   Accuracy: 399/2000.0 (19.95%)



-= Testing valid =-
Test set: Average loss: 2.2239,                   Accuracy: 644/2000.0 (32.20%)



-= Testing valid =-
Test set: Average loss: 1.9889,                   Accuracy: 556/2000.0 (27.80%)



-= Testing valid =-
Test set: Average loss: 1.3771,                   Accuracy: 902/2000.0 (45.10%)



-= Testing valid =-
Test set: Average loss: 1.1112,                   Accuracy: 1187/2000.0 (59.35%)



-= Testing valid =-
Test set: Average loss: 1.5362,                   Accuracy: 1057/2000.0 (52.85%)



-= Testing valid =-
Test set: Average loss: 1.0887,                   Accuracy: 1238/2000.0 (61.90%)



-= Testing valid =-
Test set: Average loss: 1.3590,                   Accuracy: 1045/2000.0 (52.25%)



Epoch 10 train accuracy: 76.18%, valid accuracy 52.25%
-= Testing valid =-
Test set: Average loss: 0.7620,                   Accuracy: 1376/2000.0 (68.80%)



-= Testing valid =-
Test set: Average loss: 0.8423,                   Accuracy: 1390/2000.0 (69.50%)



-= Testing valid =-
Test set: Average loss: 0.7644,                   Accuracy: 1527/2000.0 (76.35%)



-= Testing valid =-
Test set: Average loss: 0.6728,                   Accuracy: 1561/2000.0 (78.05%)



-= Testing valid =-
Test set: Average loss: 0.6437,                   Accuracy: 1562/2000.0 (78.10%)



-= Testing valid =-
Test set: Average loss: 0.3730,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.4715,                   Accuracy: 1684/2000.0 (84.20%)



-= Testing valid =-
Test set: Average loss: 0.6150,                   Accuracy: 1540/2000.0 (77.00%)



-= Testing valid =-
Test set: Average loss: 0.3765,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.5134,                   Accuracy: 1663/2000.0 (83.15%)



Epoch 20 train accuracy: 87.21%, valid accuracy 83.15%
-= Testing valid =-
Test set: Average loss: 0.2924,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.3369,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.3561,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.3192,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.3304,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.2849,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.3679,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 0.3007,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2572,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.3053,                   Accuracy: 1807/2000.0 (90.35%)



Epoch 30 train accuracy: 90.53%, valid accuracy 90.35%
-= Testing valid =-
Test set: Average loss: 0.3268,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.2609,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2604,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.2696,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2716,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2351,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.3234,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.3436,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.3620,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.3574,                   Accuracy: 1757/2000.0 (87.85%)



Epoch 40 train accuracy: 91.84%, valid accuracy 87.85%
-= Testing valid =-
Test set: Average loss: 0.2833,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.2568,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2629,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.3146,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.2602,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2802,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2892,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2363,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2691,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2834,                   Accuracy: 1808/2000.0 (90.40%)



Epoch 50 train accuracy: 92.10%, valid accuracy 90.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2732,                   Accuracy: 55294/60000 (92.16%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2952,                   Accuracy: 54655/60000 (91.09%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3125,                   Accuracy: 54477/60000 (90.79%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3224,                   Accuracy: 54244/60000 (90.41%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3226,                   Accuracy: 54256/60000 (90.43%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3208,                   Accuracy: 54312/60000 (90.52%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3142,                   Accuracy: 54371/60000 (90.62%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3151,                   Accuracy: 54260/60000 (90.43%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3069,                   Accuracy: 54247/60000 (90.41%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3100,                   Accuracy: 54242/60000 (90.40%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3386,                   Accuracy: 53513/60000 (89.19%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3689,                   Accuracy: 52892/60000 (88.15%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3746,                   Accuracy: 52850/60000 (88.08%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3927,                   Accuracy: 52424/60000 (87.37%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.4131,                   Accuracy: 52099/60000 (86.83%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4171,                   Accuracy: 51960/60000 (86.60%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4234,                   Accuracy: 51744/60000 (86.24%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.4184,                   Accuracy: 51716/60000 (86.19%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.4162,                   Accuracy: 51925/60000 (86.54%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.4095,                   Accuracy: 52107/60000 (86.85%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.4133,                   Accuracy: 52147/60000 (86.91%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3988,                   Accuracy: 52431/60000 (87.39%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3804,                   Accuracy: 52734/60000 (87.89%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3620,                   Accuracy: 53123/60000 (88.54%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3349,                   Accuracy: 53633/60000 (89.39%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3125,                   Accuracy: 54097/60000 (90.16%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2817,                   Accuracy: 54726/60000 (91.21%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2703,                   Accuracy: 55035/60000 (91.72%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2601,                   Accuracy: 55138/60000 (91.90%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2543,                   Accuracy: 55504/60000 (92.51%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2531,                   Accuracy: 55638/60000 (92.73%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2515,                   Accuracy: 55725/60000 (92.88%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2599,                   Accuracy: 55544/60000 (92.57%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2656,                   Accuracy: 55376/60000 (92.29%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2702,                   Accuracy: 55295/60000 (92.16%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2599,                   Accuracy: 55347/60000 (92.25%)
{0: tensor(92.1567), 10: tensor(91.0917), 20: tensor(90.7950), 30: tensor(90.4067), 40: tensor(90.4267), 50: tensor(90.5200), 60: tensor(90.6183), 70: tensor(90.4333), 80: tensor(90.4117), 90: tensor(90.4033), 100: tensor(89.1883), 110: tensor(88.1533), 120: tensor(88.0833), 130: tensor(87.3733), 140: tensor(86.8317), 150: tensor(86.6000), 160: tensor(86.2400), 170: tensor(86.1933), 180: tensor(86.5417), 190: tensor(86.8450), 200: tensor(86.9117), 210: tensor(87.3850), 220: tensor(87.8900), 230: tensor(88.5383), 240: tensor(89.3883), 250: tensor(90.1617), 260: tensor(91.2100), 270: tensor(91.7250), 280: tensor(91.8967), 290: tensor(92.5067), 300: tensor(92.7300), 310: tensor(92.8750), 320: tensor(92.5733), 330: tensor(92.2933), 340: tensor(92.1583), 350: tensor(92.2450)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=53, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.5021,                   Accuracy: 208/2000.0 (10.40%)



-= Testing valid =-
Test set: Average loss: 6.0874,                   Accuracy: 206/2000.0 (10.30%)



-= Testing valid =-
Test set: Average loss: 2.0564,                   Accuracy: 491/2000.0 (24.55%)



-= Testing valid =-
Test set: Average loss: 4.1787,                   Accuracy: 355/2000.0 (17.75%)



-= Testing valid =-
Test set: Average loss: 1.6731,                   Accuracy: 851/2000.0 (42.55%)



-= Testing valid =-
Test set: Average loss: 1.5292,                   Accuracy: 960/2000.0 (48.00%)



-= Testing valid =-
Test set: Average loss: 1.5999,                   Accuracy: 979/2000.0 (48.95%)



-= Testing valid =-
Test set: Average loss: 2.2460,                   Accuracy: 586/2000.0 (29.30%)



-= Testing valid =-
Test set: Average loss: 1.6217,                   Accuracy: 770/2000.0 (38.50%)



-= Testing valid =-
Test set: Average loss: 1.5429,                   Accuracy: 954/2000.0 (47.70%)



Epoch 10 train accuracy: 71.21%, valid accuracy 47.70%
-= Testing valid =-
Test set: Average loss: 1.1955,                   Accuracy: 1066/2000.0 (53.30%)



-= Testing valid =-
Test set: Average loss: 0.9637,                   Accuracy: 1314/2000.0 (65.70%)



-= Testing valid =-
Test set: Average loss: 1.0535,                   Accuracy: 1165/2000.0 (58.25%)



-= Testing valid =-
Test set: Average loss: 0.9011,                   Accuracy: 1301/2000.0 (65.05%)



-= Testing valid =-
Test set: Average loss: 0.7659,                   Accuracy: 1378/2000.0 (68.90%)



-= Testing valid =-
Test set: Average loss: 0.9571,                   Accuracy: 1291/2000.0 (64.55%)



-= Testing valid =-
Test set: Average loss: 0.7426,                   Accuracy: 1457/2000.0 (72.85%)



-= Testing valid =-
Test set: Average loss: 0.8211,                   Accuracy: 1359/2000.0 (67.95%)



-= Testing valid =-
Test set: Average loss: 0.9375,                   Accuracy: 1222/2000.0 (61.10%)



-= Testing valid =-
Test set: Average loss: 1.0268,                   Accuracy: 1374/2000.0 (68.70%)



Epoch 20 train accuracy: 84.95%, valid accuracy 68.70%
-= Testing valid =-
Test set: Average loss: 0.5876,                   Accuracy: 1609/2000.0 (80.45%)



-= Testing valid =-
Test set: Average loss: 0.4786,                   Accuracy: 1700/2000.0 (85.00%)



-= Testing valid =-
Test set: Average loss: 0.4440,                   Accuracy: 1714/2000.0 (85.70%)



-= Testing valid =-
Test set: Average loss: 0.5502,                   Accuracy: 1642/2000.0 (82.10%)



-= Testing valid =-
Test set: Average loss: 0.4688,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.3623,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.2787,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.6550,                   Accuracy: 1548/2000.0 (77.40%)



-= Testing valid =-
Test set: Average loss: 0.3771,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.3262,                   Accuracy: 1790/2000.0 (89.50%)



Epoch 30 train accuracy: 88.10%, valid accuracy 89.50%
-= Testing valid =-
Test set: Average loss: 0.3878,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.3808,                   Accuracy: 1765/2000.0 (88.25%)



-= Testing valid =-
Test set: Average loss: 0.4127,                   Accuracy: 1739/2000.0 (86.95%)



-= Testing valid =-
Test set: Average loss: 0.3554,                   Accuracy: 1777/2000.0 (88.85%)



-= Testing valid =-
Test set: Average loss: 0.4592,                   Accuracy: 1676/2000.0 (83.80%)



-= Testing valid =-
Test set: Average loss: 0.4347,                   Accuracy: 1694/2000.0 (84.70%)



-= Testing valid =-
Test set: Average loss: 0.2745,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2979,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.3236,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.3367,                   Accuracy: 1797/2000.0 (89.85%)



Epoch 40 train accuracy: 89.99%, valid accuracy 89.85%
-= Testing valid =-
Test set: Average loss: 0.3701,                   Accuracy: 1747/2000.0 (87.35%)



-= Testing valid =-
Test set: Average loss: 0.3345,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.3268,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.3624,                   Accuracy: 1765/2000.0 (88.25%)



-= Testing valid =-
Test set: Average loss: 0.3036,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2904,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.3420,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.3087,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.2861,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2870,                   Accuracy: 1827/2000.0 (91.35%)



Epoch 50 train accuracy: 90.81%, valid accuracy 91.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3242,                   Accuracy: 54461/60000 (90.77%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3356,                   Accuracy: 53997/60000 (90.00%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3620,                   Accuracy: 53517/60000 (89.19%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4106,                   Accuracy: 52495/60000 (87.49%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.4343,                   Accuracy: 51999/60000 (86.67%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.4555,                   Accuracy: 51812/60000 (86.35%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.4752,                   Accuracy: 51470/60000 (85.78%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.4694,                   Accuracy: 51653/60000 (86.09%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4420,                   Accuracy: 51956/60000 (86.59%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4415,                   Accuracy: 51881/60000 (86.47%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.4119,                   Accuracy: 52320/60000 (87.20%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.4201,                   Accuracy: 51969/60000 (86.61%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4249,                   Accuracy: 51833/60000 (86.39%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4053,                   Accuracy: 52092/60000 (86.82%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3950,                   Accuracy: 52220/60000 (87.03%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3894,                   Accuracy: 52417/60000 (87.36%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3717,                   Accuracy: 52770/60000 (87.95%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3393,                   Accuracy: 53556/60000 (89.26%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3523,                   Accuracy: 53375/60000 (88.96%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3382,                   Accuracy: 53746/60000 (89.58%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3650,                   Accuracy: 53229/60000 (88.71%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4080,                   Accuracy: 52491/60000 (87.49%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4335,                   Accuracy: 51987/60000 (86.64%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4508,                   Accuracy: 51737/60000 (86.23%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4601,                   Accuracy: 51567/60000 (85.94%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.4366,                   Accuracy: 52192/60000 (86.99%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3976,                   Accuracy: 52880/60000 (88.13%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3860,                   Accuracy: 53311/60000 (88.85%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3484,                   Accuracy: 53973/60000 (89.96%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3423,                   Accuracy: 54217/60000 (90.36%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3423,                   Accuracy: 54271/60000 (90.45%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3279,                   Accuracy: 54503/60000 (90.84%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3196,                   Accuracy: 54683/60000 (91.14%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3214,                   Accuracy: 54617/60000 (91.03%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3162,                   Accuracy: 54701/60000 (91.17%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3016,                   Accuracy: 54786/60000 (91.31%)
{0: tensor(90.7683), 10: tensor(89.9950), 20: tensor(89.1950), 30: tensor(87.4917), 40: tensor(86.6650), 50: tensor(86.3533), 60: tensor(85.7833), 70: tensor(86.0883), 80: tensor(86.5933), 90: tensor(86.4683), 100: tensor(87.2000), 110: tensor(86.6150), 120: tensor(86.3883), 130: tensor(86.8200), 140: tensor(87.0333), 150: tensor(87.3617), 160: tensor(87.9500), 170: tensor(89.2600), 180: tensor(88.9583), 190: tensor(89.5767), 200: tensor(88.7150), 210: tensor(87.4850), 220: tensor(86.6450), 230: tensor(86.2283), 240: tensor(85.9450), 250: tensor(86.9867), 260: tensor(88.1333), 270: tensor(88.8517), 280: tensor(89.9550), 290: tensor(90.3617), 300: tensor(90.4517), 310: tensor(90.8383), 320: tensor(91.1383), 330: tensor(91.0283), 340: tensor(91.1683), 350: tensor(91.3100)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=54, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1670,                   Accuracy: 459/2000.0 (22.95%)



-= Testing valid =-
Test set: Average loss: 3.4273,                   Accuracy: 277/2000.0 (13.85%)



-= Testing valid =-
Test set: Average loss: 2.2686,                   Accuracy: 580/2000.0 (29.00%)



-= Testing valid =-
Test set: Average loss: 2.7981,                   Accuracy: 513/2000.0 (25.65%)



-= Testing valid =-
Test set: Average loss: 1.5694,                   Accuracy: 918/2000.0 (45.90%)



-= Testing valid =-
Test set: Average loss: 1.8011,                   Accuracy: 775/2000.0 (38.75%)



-= Testing valid =-
Test set: Average loss: 1.2711,                   Accuracy: 1129/2000.0 (56.45%)



-= Testing valid =-
Test set: Average loss: 1.5070,                   Accuracy: 997/2000.0 (49.85%)



-= Testing valid =-
Test set: Average loss: 0.9015,                   Accuracy: 1335/2000.0 (66.75%)



-= Testing valid =-
Test set: Average loss: 0.8234,                   Accuracy: 1500/2000.0 (75.00%)



Epoch 10 train accuracy: 76.36%, valid accuracy 75.00%
-= Testing valid =-
Test set: Average loss: 0.7859,                   Accuracy: 1438/2000.0 (71.90%)



-= Testing valid =-
Test set: Average loss: 0.7721,                   Accuracy: 1445/2000.0 (72.25%)



-= Testing valid =-
Test set: Average loss: 0.4533,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.6155,                   Accuracy: 1580/2000.0 (79.00%)



-= Testing valid =-
Test set: Average loss: 0.3430,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.3850,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.2775,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2453,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.3394,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.3251,                   Accuracy: 1805/2000.0 (90.25%)



Epoch 20 train accuracy: 87.34%, valid accuracy 90.25%
-= Testing valid =-
Test set: Average loss: 0.3396,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.3255,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.2693,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2558,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2063,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.2121,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.2436,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.2193,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2352,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2455,                   Accuracy: 1840/2000.0 (92.00%)



Epoch 30 train accuracy: 90.20%, valid accuracy 92.00%
-= Testing valid =-
Test set: Average loss: 0.1910,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2087,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2195,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2246,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.1994,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.2013,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.2350,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.2007,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1990,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.2117,                   Accuracy: 1867/2000.0 (93.35%)



Epoch 40 train accuracy: 91.43%, valid accuracy 93.35%
-= Testing valid =-
Test set: Average loss: 0.2091,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.2042,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1833,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1842,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.2077,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2124,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.1999,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1917,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1872,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1875,                   Accuracy: 1890/2000.0 (94.50%)



Epoch 50 train accuracy: 91.65%, valid accuracy 94.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2208,                   Accuracy: 56040/60000 (93.40%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2273,                   Accuracy: 55880/60000 (93.13%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2271,                   Accuracy: 55917/60000 (93.19%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2250,                   Accuracy: 55977/60000 (93.29%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2270,                   Accuracy: 55922/60000 (93.20%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2293,                   Accuracy: 55905/60000 (93.18%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2307,                   Accuracy: 55846/60000 (93.08%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2341,                   Accuracy: 55756/60000 (92.93%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2315,                   Accuracy: 55701/60000 (92.83%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2227,                   Accuracy: 55910/60000 (93.18%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2367,                   Accuracy: 55616/60000 (92.69%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2389,                   Accuracy: 55606/60000 (92.68%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.2491,                   Accuracy: 55488/60000 (92.48%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.2535,                   Accuracy: 55391/60000 (92.32%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.2626,                   Accuracy: 55234/60000 (92.06%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.2675,                   Accuracy: 55068/60000 (91.78%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2646,                   Accuracy: 55066/60000 (91.78%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.2667,                   Accuracy: 54871/60000 (91.45%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.2700,                   Accuracy: 54911/60000 (91.52%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.2788,                   Accuracy: 54748/60000 (91.25%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2871,                   Accuracy: 54640/60000 (91.07%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.2912,                   Accuracy: 54500/60000 (90.83%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.2878,                   Accuracy: 54607/60000 (91.01%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.2884,                   Accuracy: 54557/60000 (90.93%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.2850,                   Accuracy: 54589/60000 (90.98%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2781,                   Accuracy: 54707/60000 (91.18%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2617,                   Accuracy: 54976/60000 (91.63%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2502,                   Accuracy: 55212/60000 (92.02%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2548,                   Accuracy: 55117/60000 (91.86%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2506,                   Accuracy: 55303/60000 (92.17%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2564,                   Accuracy: 55198/60000 (92.00%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2544,                   Accuracy: 55262/60000 (92.10%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2515,                   Accuracy: 55356/60000 (92.26%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2404,                   Accuracy: 55592/60000 (92.65%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2326,                   Accuracy: 55743/60000 (92.90%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2235,                   Accuracy: 55888/60000 (93.15%)
{0: tensor(93.4000), 10: tensor(93.1333), 20: tensor(93.1950), 30: tensor(93.2950), 40: tensor(93.2033), 50: tensor(93.1750), 60: tensor(93.0767), 70: tensor(92.9267), 80: tensor(92.8350), 90: tensor(93.1833), 100: tensor(92.6933), 110: tensor(92.6767), 120: tensor(92.4800), 130: tensor(92.3183), 140: tensor(92.0567), 150: tensor(91.7800), 160: tensor(91.7767), 170: tensor(91.4517), 180: tensor(91.5183), 190: tensor(91.2467), 200: tensor(91.0667), 210: tensor(90.8333), 220: tensor(91.0117), 230: tensor(90.9283), 240: tensor(90.9817), 250: tensor(91.1783), 260: tensor(91.6267), 270: tensor(92.0200), 280: tensor(91.8617), 290: tensor(92.1717), 300: tensor(91.9967), 310: tensor(92.1033), 320: tensor(92.2600), 330: tensor(92.6533), 340: tensor(92.9050), 350: tensor(93.1467)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=55, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 8.0547,                   Accuracy: 250/2000.0 (12.50%)



-= Testing valid =-
Test set: Average loss: 2.9930,                   Accuracy: 333/2000.0 (16.65%)



-= Testing valid =-
Test set: Average loss: 1.4917,                   Accuracy: 937/2000.0 (46.85%)



-= Testing valid =-
Test set: Average loss: 1.2726,                   Accuracy: 1113/2000.0 (55.65%)



-= Testing valid =-
Test set: Average loss: 1.7652,                   Accuracy: 861/2000.0 (43.05%)



-= Testing valid =-
Test set: Average loss: 1.4975,                   Accuracy: 1003/2000.0 (50.15%)



-= Testing valid =-
Test set: Average loss: 1.4637,                   Accuracy: 893/2000.0 (44.65%)



-= Testing valid =-
Test set: Average loss: 1.0753,                   Accuracy: 1195/2000.0 (59.75%)



-= Testing valid =-
Test set: Average loss: 1.4972,                   Accuracy: 916/2000.0 (45.80%)



-= Testing valid =-
Test set: Average loss: 1.0933,                   Accuracy: 1278/2000.0 (63.90%)



Epoch 10 train accuracy: 73.34%, valid accuracy 63.90%
-= Testing valid =-
Test set: Average loss: 0.5234,                   Accuracy: 1699/2000.0 (84.95%)



-= Testing valid =-
Test set: Average loss: 0.7199,                   Accuracy: 1493/2000.0 (74.65%)



-= Testing valid =-
Test set: Average loss: 0.6052,                   Accuracy: 1585/2000.0 (79.25%)



-= Testing valid =-
Test set: Average loss: 0.4265,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.4816,                   Accuracy: 1672/2000.0 (83.60%)



-= Testing valid =-
Test set: Average loss: 0.4654,                   Accuracy: 1676/2000.0 (83.80%)



-= Testing valid =-
Test set: Average loss: 0.3737,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.4235,                   Accuracy: 1738/2000.0 (86.90%)



-= Testing valid =-
Test set: Average loss: 0.2701,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2751,                   Accuracy: 1843/2000.0 (92.15%)



Epoch 20 train accuracy: 86.60%, valid accuracy 92.15%
-= Testing valid =-
Test set: Average loss: 0.3291,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.3063,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.2546,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.3401,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.3486,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.3010,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.3183,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3627,                   Accuracy: 1751/2000.0 (87.55%)



-= Testing valid =-
Test set: Average loss: 0.3801,                   Accuracy: 1756/2000.0 (87.80%)



-= Testing valid =-
Test set: Average loss: 0.3796,                   Accuracy: 1743/2000.0 (87.15%)



Epoch 30 train accuracy: 89.06%, valid accuracy 87.15%
-= Testing valid =-
Test set: Average loss: 0.2977,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3003,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.3121,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.3024,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.2647,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2814,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2565,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2671,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.2454,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.2710,                   Accuracy: 1826/2000.0 (91.30%)



Epoch 40 train accuracy: 89.46%, valid accuracy 91.30%
-= Testing valid =-
Test set: Average loss: 0.2708,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.2566,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2570,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2731,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2539,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2434,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2415,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2734,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2976,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2432,                   Accuracy: 1847/2000.0 (92.35%)



Epoch 50 train accuracy: 90.84%, valid accuracy 92.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3326,                   Accuracy: 54637/60000 (91.06%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3502,                   Accuracy: 54318/60000 (90.53%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3772,                   Accuracy: 53812/60000 (89.69%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4084,                   Accuracy: 53142/60000 (88.57%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.4263,                   Accuracy: 52625/60000 (87.71%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.4424,                   Accuracy: 52210/60000 (87.02%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.4529,                   Accuracy: 51914/60000 (86.52%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.4507,                   Accuracy: 51894/60000 (86.49%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4291,                   Accuracy: 52301/60000 (87.17%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4368,                   Accuracy: 52238/60000 (87.06%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.4814,                   Accuracy: 51219/60000 (85.36%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.5122,                   Accuracy: 50396/60000 (83.99%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5559,                   Accuracy: 49203/60000 (82.00%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.5931,                   Accuracy: 48091/60000 (80.15%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.6332,                   Accuracy: 46745/60000 (77.91%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6548,                   Accuracy: 46052/60000 (76.75%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.6413,                   Accuracy: 46486/60000 (77.48%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.5820,                   Accuracy: 47995/60000 (79.99%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.5755,                   Accuracy: 47888/60000 (79.81%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.5540,                   Accuracy: 48737/60000 (81.23%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.5411,                   Accuracy: 49137/60000 (81.89%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5260,                   Accuracy: 49587/60000 (82.64%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.5117,                   Accuracy: 50128/60000 (83.55%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.5022,                   Accuracy: 50537/60000 (84.23%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4827,                   Accuracy: 51200/60000 (85.33%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.4593,                   Accuracy: 51788/60000 (86.31%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.4163,                   Accuracy: 52807/60000 (88.01%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4054,                   Accuracy: 52987/60000 (88.31%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4074,                   Accuracy: 53013/60000 (88.36%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.4041,                   Accuracy: 53083/60000 (88.47%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.4082,                   Accuracy: 53006/60000 (88.34%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3983,                   Accuracy: 53322/60000 (88.87%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3911,                   Accuracy: 53483/60000 (89.14%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3833,                   Accuracy: 53679/60000 (89.46%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3598,                   Accuracy: 54178/60000 (90.30%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3407,                   Accuracy: 54439/60000 (90.73%)
{0: tensor(91.0617), 10: tensor(90.5300), 20: tensor(89.6867), 30: tensor(88.5700), 40: tensor(87.7083), 50: tensor(87.0167), 60: tensor(86.5233), 70: tensor(86.4900), 80: tensor(87.1683), 90: tensor(87.0633), 100: tensor(85.3650), 110: tensor(83.9933), 120: tensor(82.0050), 130: tensor(80.1517), 140: tensor(77.9083), 150: tensor(76.7533), 160: tensor(77.4767), 170: tensor(79.9917), 180: tensor(79.8133), 190: tensor(81.2283), 200: tensor(81.8950), 210: tensor(82.6450), 220: tensor(83.5467), 230: tensor(84.2283), 240: tensor(85.3333), 250: tensor(86.3133), 260: tensor(88.0117), 270: tensor(88.3117), 280: tensor(88.3550), 290: tensor(88.4717), 300: tensor(88.3433), 310: tensor(88.8700), 320: tensor(89.1383), 330: tensor(89.4650), 340: tensor(90.2967), 350: tensor(90.7317)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=56, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1988,                   Accuracy: 443/2000.0 (22.15%)



-= Testing valid =-
Test set: Average loss: 1.5615,                   Accuracy: 859/2000.0 (42.95%)



-= Testing valid =-
Test set: Average loss: 1.3251,                   Accuracy: 1036/2000.0 (51.80%)



-= Testing valid =-
Test set: Average loss: 2.0541,                   Accuracy: 690/2000.0 (34.50%)



-= Testing valid =-
Test set: Average loss: 2.2057,                   Accuracy: 587/2000.0 (29.35%)



-= Testing valid =-
Test set: Average loss: 0.9159,                   Accuracy: 1411/2000.0 (70.55%)



-= Testing valid =-
Test set: Average loss: 1.8208,                   Accuracy: 798/2000.0 (39.90%)



-= Testing valid =-
Test set: Average loss: 1.0678,                   Accuracy: 1369/2000.0 (68.45%)



-= Testing valid =-
Test set: Average loss: 1.1988,                   Accuracy: 1174/2000.0 (58.70%)



-= Testing valid =-
Test set: Average loss: 0.8693,                   Accuracy: 1401/2000.0 (70.05%)



Epoch 10 train accuracy: 73.34%, valid accuracy 70.05%
-= Testing valid =-
Test set: Average loss: 0.5605,                   Accuracy: 1625/2000.0 (81.25%)



-= Testing valid =-
Test set: Average loss: 0.6484,                   Accuracy: 1556/2000.0 (77.80%)



-= Testing valid =-
Test set: Average loss: 1.0118,                   Accuracy: 1350/2000.0 (67.50%)



-= Testing valid =-
Test set: Average loss: 0.7679,                   Accuracy: 1424/2000.0 (71.20%)



-= Testing valid =-
Test set: Average loss: 0.4165,                   Accuracy: 1730/2000.0 (86.50%)



-= Testing valid =-
Test set: Average loss: 0.4720,                   Accuracy: 1665/2000.0 (83.25%)



-= Testing valid =-
Test set: Average loss: 0.6653,                   Accuracy: 1515/2000.0 (75.75%)



-= Testing valid =-
Test set: Average loss: 0.4794,                   Accuracy: 1714/2000.0 (85.70%)



-= Testing valid =-
Test set: Average loss: 0.8355,                   Accuracy: 1460/2000.0 (73.00%)



-= Testing valid =-
Test set: Average loss: 0.4107,                   Accuracy: 1705/2000.0 (85.25%)



Epoch 20 train accuracy: 86.53%, valid accuracy 85.25%
-= Testing valid =-
Test set: Average loss: 0.3494,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.5203,                   Accuracy: 1656/2000.0 (82.80%)



-= Testing valid =-
Test set: Average loss: 0.3659,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.3720,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.3574,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.3989,                   Accuracy: 1740/2000.0 (87.00%)



-= Testing valid =-
Test set: Average loss: 0.3854,                   Accuracy: 1760/2000.0 (88.00%)



-= Testing valid =-
Test set: Average loss: 0.4311,                   Accuracy: 1730/2000.0 (86.50%)



-= Testing valid =-
Test set: Average loss: 0.3476,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.4629,                   Accuracy: 1670/2000.0 (83.50%)



Epoch 30 train accuracy: 88.86%, valid accuracy 83.50%
-= Testing valid =-
Test set: Average loss: 0.3283,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.4591,                   Accuracy: 1682/2000.0 (84.10%)



-= Testing valid =-
Test set: Average loss: 0.2891,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.3079,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.3294,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.2627,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.3225,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.2971,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2847,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2337,                   Accuracy: 1871/2000.0 (93.55%)



Epoch 40 train accuracy: 90.15%, valid accuracy 93.55%
-= Testing valid =-
Test set: Average loss: 0.3001,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.3411,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.2723,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.3131,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.3354,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.3150,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.2440,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2911,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.3402,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.2859,                   Accuracy: 1831/2000.0 (91.55%)



Epoch 50 train accuracy: 90.25%, valid accuracy 91.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2759,                   Accuracy: 55187/60000 (91.98%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2722,                   Accuracy: 55181/60000 (91.97%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2904,                   Accuracy: 54887/60000 (91.48%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2953,                   Accuracy: 54743/60000 (91.24%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3094,                   Accuracy: 54386/60000 (90.64%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3190,                   Accuracy: 54127/60000 (90.21%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3197,                   Accuracy: 54025/60000 (90.04%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3342,                   Accuracy: 53761/60000 (89.60%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3171,                   Accuracy: 54044/60000 (90.07%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3248,                   Accuracy: 54044/60000 (90.07%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3197,                   Accuracy: 54174/60000 (90.29%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3340,                   Accuracy: 53809/60000 (89.68%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3348,                   Accuracy: 53819/60000 (89.70%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3395,                   Accuracy: 53702/60000 (89.50%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3538,                   Accuracy: 53441/60000 (89.07%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3539,                   Accuracy: 53394/60000 (88.99%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3590,                   Accuracy: 53347/60000 (88.91%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3519,                   Accuracy: 53342/60000 (88.90%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3787,                   Accuracy: 52788/60000 (87.98%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3646,                   Accuracy: 52968/60000 (88.28%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3812,                   Accuracy: 52480/60000 (87.47%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3715,                   Accuracy: 52663/60000 (87.77%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3699,                   Accuracy: 52767/60000 (87.94%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3512,                   Accuracy: 53290/60000 (88.82%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3286,                   Accuracy: 53754/60000 (89.59%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3205,                   Accuracy: 54114/60000 (90.19%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3028,                   Accuracy: 54325/60000 (90.54%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2913,                   Accuracy: 54687/60000 (91.14%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2882,                   Accuracy: 54857/60000 (91.43%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2960,                   Accuracy: 54681/60000 (91.14%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2962,                   Accuracy: 54839/60000 (91.40%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3022,                   Accuracy: 54655/60000 (91.09%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3016,                   Accuracy: 54658/60000 (91.10%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2899,                   Accuracy: 54872/60000 (91.45%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2833,                   Accuracy: 54930/60000 (91.55%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2717,                   Accuracy: 55087/60000 (91.81%)
{0: tensor(91.9783), 10: tensor(91.9683), 20: tensor(91.4783), 30: tensor(91.2383), 40: tensor(90.6433), 50: tensor(90.2117), 60: tensor(90.0417), 70: tensor(89.6017), 80: tensor(90.0733), 90: tensor(90.0733), 100: tensor(90.2900), 110: tensor(89.6817), 120: tensor(89.6983), 130: tensor(89.5033), 140: tensor(89.0683), 150: tensor(88.9900), 160: tensor(88.9117), 170: tensor(88.9033), 180: tensor(87.9800), 190: tensor(88.2800), 200: tensor(87.4667), 210: tensor(87.7717), 220: tensor(87.9450), 230: tensor(88.8167), 240: tensor(89.5900), 250: tensor(90.1900), 260: tensor(90.5417), 270: tensor(91.1450), 280: tensor(91.4283), 290: tensor(91.1350), 300: tensor(91.3983), 310: tensor(91.0917), 320: tensor(91.0967), 330: tensor(91.4533), 340: tensor(91.5500), 350: tensor(91.8117)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=57, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2363,                   Accuracy: 501/2000.0 (25.05%)



-= Testing valid =-
Test set: Average loss: 3.2543,                   Accuracy: 381/2000.0 (19.05%)



-= Testing valid =-
Test set: Average loss: 1.4121,                   Accuracy: 997/2000.0 (49.85%)



-= Testing valid =-
Test set: Average loss: 1.1086,                   Accuracy: 1263/2000.0 (63.15%)



-= Testing valid =-
Test set: Average loss: 2.0041,                   Accuracy: 766/2000.0 (38.30%)



-= Testing valid =-
Test set: Average loss: 1.0987,                   Accuracy: 1230/2000.0 (61.50%)



-= Testing valid =-
Test set: Average loss: 1.6845,                   Accuracy: 948/2000.0 (47.40%)



-= Testing valid =-
Test set: Average loss: 1.1006,                   Accuracy: 1287/2000.0 (64.35%)



-= Testing valid =-
Test set: Average loss: 0.8875,                   Accuracy: 1434/2000.0 (71.70%)



-= Testing valid =-
Test set: Average loss: 0.8771,                   Accuracy: 1407/2000.0 (70.35%)



Epoch 10 train accuracy: 78.50%, valid accuracy 70.35%
-= Testing valid =-
Test set: Average loss: 0.4843,                   Accuracy: 1712/2000.0 (85.60%)



-= Testing valid =-
Test set: Average loss: 0.6493,                   Accuracy: 1581/2000.0 (79.05%)



-= Testing valid =-
Test set: Average loss: 0.5474,                   Accuracy: 1657/2000.0 (82.85%)



-= Testing valid =-
Test set: Average loss: 0.5600,                   Accuracy: 1650/2000.0 (82.50%)



-= Testing valid =-
Test set: Average loss: 0.5109,                   Accuracy: 1667/2000.0 (83.35%)



-= Testing valid =-
Test set: Average loss: 0.7668,                   Accuracy: 1446/2000.0 (72.30%)



-= Testing valid =-
Test set: Average loss: 0.3997,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.4392,                   Accuracy: 1720/2000.0 (86.00%)



-= Testing valid =-
Test set: Average loss: 0.4015,                   Accuracy: 1731/2000.0 (86.55%)



-= Testing valid =-
Test set: Average loss: 0.3157,                   Accuracy: 1801/2000.0 (90.05%)



Epoch 20 train accuracy: 86.64%, valid accuracy 90.05%
-= Testing valid =-
Test set: Average loss: 0.4220,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.2927,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.3817,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.3760,                   Accuracy: 1768/2000.0 (88.40%)



-= Testing valid =-
Test set: Average loss: 0.3283,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.3382,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.2961,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.3332,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.3135,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.3486,                   Accuracy: 1791/2000.0 (89.55%)



Epoch 30 train accuracy: 89.64%, valid accuracy 89.55%
-= Testing valid =-
Test set: Average loss: 0.3327,                   Accuracy: 1777/2000.0 (88.85%)



-= Testing valid =-
Test set: Average loss: 0.2711,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2778,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.2667,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2585,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2313,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.3059,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.3211,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.2568,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2656,                   Accuracy: 1824/2000.0 (91.20%)



Epoch 40 train accuracy: 90.25%, valid accuracy 91.20%
-= Testing valid =-
Test set: Average loss: 0.3034,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.2977,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.2823,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.2861,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.3403,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.2814,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2584,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2439,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2594,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2939,                   Accuracy: 1807/2000.0 (90.35%)



Epoch 50 train accuracy: 91.05%, valid accuracy 90.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2468,                   Accuracy: 55583/60000 (92.64%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2469,                   Accuracy: 55547/60000 (92.58%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2545,                   Accuracy: 55419/60000 (92.36%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2687,                   Accuracy: 55181/60000 (91.97%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2823,                   Accuracy: 54897/60000 (91.50%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2987,                   Accuracy: 54512/60000 (90.85%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3148,                   Accuracy: 54086/60000 (90.14%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3287,                   Accuracy: 53797/60000 (89.66%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3297,                   Accuracy: 53662/60000 (89.44%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3457,                   Accuracy: 53327/60000 (88.88%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3578,                   Accuracy: 52987/60000 (88.31%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3708,                   Accuracy: 52681/60000 (87.80%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3773,                   Accuracy: 52533/60000 (87.56%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3814,                   Accuracy: 52441/60000 (87.40%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3754,                   Accuracy: 52612/60000 (87.69%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3670,                   Accuracy: 52809/60000 (88.01%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3618,                   Accuracy: 53012/60000 (88.35%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3350,                   Accuracy: 53437/60000 (89.06%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3272,                   Accuracy: 53808/60000 (89.68%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3189,                   Accuracy: 53965/60000 (89.94%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3230,                   Accuracy: 53801/60000 (89.67%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3184,                   Accuracy: 54003/60000 (90.00%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3215,                   Accuracy: 53955/60000 (89.93%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3210,                   Accuracy: 54079/60000 (90.13%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3197,                   Accuracy: 54124/60000 (90.21%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3124,                   Accuracy: 54286/60000 (90.48%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2918,                   Accuracy: 54796/60000 (91.33%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2981,                   Accuracy: 54719/60000 (91.20%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2876,                   Accuracy: 54852/60000 (91.42%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2925,                   Accuracy: 54843/60000 (91.40%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2911,                   Accuracy: 54885/60000 (91.47%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2867,                   Accuracy: 54982/60000 (91.64%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2803,                   Accuracy: 55103/60000 (91.84%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2718,                   Accuracy: 55219/60000 (92.03%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2616,                   Accuracy: 55401/60000 (92.33%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2418,                   Accuracy: 55692/60000 (92.82%)
{0: tensor(92.6383), 10: tensor(92.5783), 20: tensor(92.3650), 30: tensor(91.9683), 40: tensor(91.4950), 50: tensor(90.8533), 60: tensor(90.1433), 70: tensor(89.6617), 80: tensor(89.4367), 90: tensor(88.8783), 100: tensor(88.3117), 110: tensor(87.8017), 120: tensor(87.5550), 130: tensor(87.4017), 140: tensor(87.6867), 150: tensor(88.0150), 160: tensor(88.3533), 170: tensor(89.0617), 180: tensor(89.6800), 190: tensor(89.9417), 200: tensor(89.6683), 210: tensor(90.0050), 220: tensor(89.9250), 230: tensor(90.1317), 240: tensor(90.2067), 250: tensor(90.4767), 260: tensor(91.3267), 270: tensor(91.1983), 280: tensor(91.4200), 290: tensor(91.4050), 300: tensor(91.4750), 310: tensor(91.6367), 320: tensor(91.8383), 330: tensor(92.0317), 340: tensor(92.3350), 350: tensor(92.8200)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=58, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 8.2689,                   Accuracy: 249/2000.0 (12.45%)



-= Testing valid =-
Test set: Average loss: 3.9888,                   Accuracy: 251/2000.0 (12.55%)



-= Testing valid =-
Test set: Average loss: 1.6139,                   Accuracy: 831/2000.0 (41.55%)



-= Testing valid =-
Test set: Average loss: 3.7396,                   Accuracy: 543/2000.0 (27.15%)



-= Testing valid =-
Test set: Average loss: 2.2460,                   Accuracy: 859/2000.0 (42.95%)



-= Testing valid =-
Test set: Average loss: 1.3472,                   Accuracy: 1095/2000.0 (54.75%)



-= Testing valid =-
Test set: Average loss: 1.1800,                   Accuracy: 1200/2000.0 (60.00%)



-= Testing valid =-
Test set: Average loss: 0.9446,                   Accuracy: 1337/2000.0 (66.85%)



-= Testing valid =-
Test set: Average loss: 1.4577,                   Accuracy: 950/2000.0 (47.50%)



-= Testing valid =-
Test set: Average loss: 0.7875,                   Accuracy: 1496/2000.0 (74.80%)



Epoch 10 train accuracy: 73.51%, valid accuracy 74.80%
-= Testing valid =-
Test set: Average loss: 0.7255,                   Accuracy: 1551/2000.0 (77.55%)



-= Testing valid =-
Test set: Average loss: 0.7401,                   Accuracy: 1544/2000.0 (77.20%)



-= Testing valid =-
Test set: Average loss: 0.6712,                   Accuracy: 1590/2000.0 (79.50%)



-= Testing valid =-
Test set: Average loss: 0.6630,                   Accuracy: 1560/2000.0 (78.00%)



-= Testing valid =-
Test set: Average loss: 0.4150,                   Accuracy: 1740/2000.0 (87.00%)



-= Testing valid =-
Test set: Average loss: 0.5447,                   Accuracy: 1644/2000.0 (82.20%)



-= Testing valid =-
Test set: Average loss: 0.3904,                   Accuracy: 1780/2000.0 (89.00%)



-= Testing valid =-
Test set: Average loss: 0.4913,                   Accuracy: 1708/2000.0 (85.40%)



-= Testing valid =-
Test set: Average loss: 0.4260,                   Accuracy: 1718/2000.0 (85.90%)



-= Testing valid =-
Test set: Average loss: 0.5377,                   Accuracy: 1656/2000.0 (82.80%)



Epoch 20 train accuracy: 87.03%, valid accuracy 82.80%
-= Testing valid =-
Test set: Average loss: 0.3662,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.4027,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.3739,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.3819,                   Accuracy: 1752/2000.0 (87.60%)



-= Testing valid =-
Test set: Average loss: 0.2789,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.3164,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.2569,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2679,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2939,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.3624,                   Accuracy: 1767/2000.0 (88.35%)



Epoch 30 train accuracy: 89.15%, valid accuracy 88.35%
-= Testing valid =-
Test set: Average loss: 0.3000,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.3411,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.3053,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.2852,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.3121,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2953,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2853,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2328,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2411,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2401,                   Accuracy: 1853/2000.0 (92.65%)



Epoch 40 train accuracy: 90.24%, valid accuracy 92.65%
-= Testing valid =-
Test set: Average loss: 0.2645,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2371,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.2405,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.2471,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2451,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.2283,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2646,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2893,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2539,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2492,                   Accuracy: 1839/2000.0 (91.95%)



Epoch 50 train accuracy: 90.86%, valid accuracy 91.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2885,                   Accuracy: 54798/60000 (91.33%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2810,                   Accuracy: 54929/60000 (91.55%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2862,                   Accuracy: 55040/60000 (91.73%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2973,                   Accuracy: 54858/60000 (91.43%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3049,                   Accuracy: 54667/60000 (91.11%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3055,                   Accuracy: 54683/60000 (91.14%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3114,                   Accuracy: 54547/60000 (90.91%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3038,                   Accuracy: 54641/60000 (91.07%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2994,                   Accuracy: 54559/60000 (90.93%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3139,                   Accuracy: 54291/60000 (90.49%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3202,                   Accuracy: 54016/60000 (90.03%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3373,                   Accuracy: 53650/60000 (89.42%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3556,                   Accuracy: 53330/60000 (88.88%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3696,                   Accuracy: 52879/60000 (88.13%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3687,                   Accuracy: 52881/60000 (88.14%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3647,                   Accuracy: 52971/60000 (88.29%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3576,                   Accuracy: 53079/60000 (88.46%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3373,                   Accuracy: 53432/60000 (89.05%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3476,                   Accuracy: 53125/60000 (88.54%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3542,                   Accuracy: 52981/60000 (88.30%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3732,                   Accuracy: 52648/60000 (87.75%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3904,                   Accuracy: 52361/60000 (87.27%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4072,                   Accuracy: 51977/60000 (86.63%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4134,                   Accuracy: 51844/60000 (86.41%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4149,                   Accuracy: 51720/60000 (86.20%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.4015,                   Accuracy: 52105/60000 (86.84%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3667,                   Accuracy: 52883/60000 (88.14%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3653,                   Accuracy: 53059/60000 (88.43%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3416,                   Accuracy: 53474/60000 (89.12%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3567,                   Accuracy: 53358/60000 (88.93%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3666,                   Accuracy: 53207/60000 (88.68%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3591,                   Accuracy: 53387/60000 (88.98%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3456,                   Accuracy: 53769/60000 (89.61%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3354,                   Accuracy: 53912/60000 (89.85%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3222,                   Accuracy: 54079/60000 (90.13%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2904,                   Accuracy: 54669/60000 (91.11%)
{0: tensor(91.3300), 10: tensor(91.5483), 20: tensor(91.7333), 30: tensor(91.4300), 40: tensor(91.1117), 50: tensor(91.1383), 60: tensor(90.9117), 70: tensor(91.0683), 80: tensor(90.9317), 90: tensor(90.4850), 100: tensor(90.0267), 110: tensor(89.4167), 120: tensor(88.8833), 130: tensor(88.1317), 140: tensor(88.1350), 150: tensor(88.2850), 160: tensor(88.4650), 170: tensor(89.0533), 180: tensor(88.5417), 190: tensor(88.3017), 200: tensor(87.7467), 210: tensor(87.2683), 220: tensor(86.6283), 230: tensor(86.4067), 240: tensor(86.2000), 250: tensor(86.8417), 260: tensor(88.1383), 270: tensor(88.4317), 280: tensor(89.1233), 290: tensor(88.9300), 300: tensor(88.6783), 310: tensor(88.9783), 320: tensor(89.6150), 330: tensor(89.8533), 340: tensor(90.1317), 350: tensor(91.1150)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=59, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 13.1406,                   Accuracy: 233/2000.0 (11.65%)



-= Testing valid =-
Test set: Average loss: 2.3779,                   Accuracy: 358/2000.0 (17.90%)



-= Testing valid =-
Test set: Average loss: 1.9580,                   Accuracy: 533/2000.0 (26.65%)



-= Testing valid =-
Test set: Average loss: 1.4131,                   Accuracy: 911/2000.0 (45.55%)



-= Testing valid =-
Test set: Average loss: 2.2679,                   Accuracy: 508/2000.0 (25.40%)



-= Testing valid =-
Test set: Average loss: 1.6193,                   Accuracy: 876/2000.0 (43.80%)



-= Testing valid =-
Test set: Average loss: 1.1122,                   Accuracy: 1245/2000.0 (62.25%)



-= Testing valid =-
Test set: Average loss: 1.0012,                   Accuracy: 1304/2000.0 (65.20%)



-= Testing valid =-
Test set: Average loss: 0.9125,                   Accuracy: 1407/2000.0 (70.35%)



-= Testing valid =-
Test set: Average loss: 0.9455,                   Accuracy: 1400/2000.0 (70.00%)



Epoch 10 train accuracy: 74.10%, valid accuracy 70.00%
-= Testing valid =-
Test set: Average loss: 0.7163,                   Accuracy: 1550/2000.0 (77.50%)



-= Testing valid =-
Test set: Average loss: 0.7525,                   Accuracy: 1508/2000.0 (75.40%)



-= Testing valid =-
Test set: Average loss: 0.6487,                   Accuracy: 1592/2000.0 (79.60%)



-= Testing valid =-
Test set: Average loss: 0.6862,                   Accuracy: 1568/2000.0 (78.40%)



-= Testing valid =-
Test set: Average loss: 0.7375,                   Accuracy: 1501/2000.0 (75.05%)



-= Testing valid =-
Test set: Average loss: 0.4738,                   Accuracy: 1688/2000.0 (84.40%)



-= Testing valid =-
Test set: Average loss: 0.5146,                   Accuracy: 1669/2000.0 (83.45%)



-= Testing valid =-
Test set: Average loss: 0.5443,                   Accuracy: 1630/2000.0 (81.50%)



-= Testing valid =-
Test set: Average loss: 0.3264,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.3684,                   Accuracy: 1742/2000.0 (87.10%)



Epoch 20 train accuracy: 85.09%, valid accuracy 87.10%
-= Testing valid =-
Test set: Average loss: 0.2974,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.3248,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.3116,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.2975,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.2995,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.2527,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2438,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2317,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2811,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.2779,                   Accuracy: 1797/2000.0 (89.85%)



Epoch 30 train accuracy: 88.36%, valid accuracy 89.85%
-= Testing valid =-
Test set: Average loss: 0.2490,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2444,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2882,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2584,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.2366,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2169,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.2577,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2570,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2200,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2396,                   Accuracy: 1832/2000.0 (91.60%)



Epoch 40 train accuracy: 89.89%, valid accuracy 91.60%
-= Testing valid =-
Test set: Average loss: 0.2624,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2287,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2457,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2458,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2536,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2429,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2787,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.2535,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.2571,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2272,                   Accuracy: 1843/2000.0 (92.15%)



Epoch 50 train accuracy: 90.32%, valid accuracy 92.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2594,                   Accuracy: 55171/60000 (91.95%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2918,                   Accuracy: 54629/60000 (91.05%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2766,                   Accuracy: 54854/60000 (91.42%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2883,                   Accuracy: 54498/60000 (90.83%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2886,                   Accuracy: 54536/60000 (90.89%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2953,                   Accuracy: 54356/60000 (90.59%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2970,                   Accuracy: 54230/60000 (90.38%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3003,                   Accuracy: 54179/60000 (90.30%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3244,                   Accuracy: 53538/60000 (89.23%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3105,                   Accuracy: 53839/60000 (89.73%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3386,                   Accuracy: 53371/60000 (88.95%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3083,                   Accuracy: 53841/60000 (89.74%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3050,                   Accuracy: 53841/60000 (89.74%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3053,                   Accuracy: 53874/60000 (89.79%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3077,                   Accuracy: 53778/60000 (89.63%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.2996,                   Accuracy: 53907/60000 (89.85%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2989,                   Accuracy: 54052/60000 (90.09%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3305,                   Accuracy: 53629/60000 (89.38%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3067,                   Accuracy: 54056/60000 (90.09%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3586,                   Accuracy: 53140/60000 (88.57%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3390,                   Accuracy: 53407/60000 (89.01%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3421,                   Accuracy: 53290/60000 (88.82%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3417,                   Accuracy: 53287/60000 (88.81%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3416,                   Accuracy: 53304/60000 (88.84%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3261,                   Accuracy: 53528/60000 (89.21%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3074,                   Accuracy: 53873/60000 (89.79%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3010,                   Accuracy: 53999/60000 (90.00%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2687,                   Accuracy: 54654/60000 (91.09%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2807,                   Accuracy: 54460/60000 (90.77%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2462,                   Accuracy: 55276/60000 (92.13%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2384,                   Accuracy: 55403/60000 (92.34%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2366,                   Accuracy: 55559/60000 (92.60%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2390,                   Accuracy: 55560/60000 (92.60%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2419,                   Accuracy: 55502/60000 (92.50%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2461,                   Accuracy: 55432/60000 (92.39%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2636,                   Accuracy: 55140/60000 (91.90%)
{0: tensor(91.9517), 10: tensor(91.0483), 20: tensor(91.4233), 30: tensor(90.8300), 40: tensor(90.8933), 50: tensor(90.5933), 60: tensor(90.3833), 70: tensor(90.2983), 80: tensor(89.2300), 90: tensor(89.7317), 100: tensor(88.9517), 110: tensor(89.7350), 120: tensor(89.7350), 130: tensor(89.7900), 140: tensor(89.6300), 150: tensor(89.8450), 160: tensor(90.0867), 170: tensor(89.3817), 180: tensor(90.0933), 190: tensor(88.5667), 200: tensor(89.0117), 210: tensor(88.8167), 220: tensor(88.8117), 230: tensor(88.8400), 240: tensor(89.2133), 250: tensor(89.7883), 260: tensor(89.9983), 270: tensor(91.0900), 280: tensor(90.7667), 290: tensor(92.1267), 300: tensor(92.3383), 310: tensor(92.5983), 320: tensor(92.6000), 330: tensor(92.5033), 340: tensor(92.3867), 350: tensor(91.9000)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=60, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 10.3265,                   Accuracy: 232/2000.0 (11.60%)



-= Testing valid =-
Test set: Average loss: 1.9107,                   Accuracy: 601/2000.0 (30.05%)



-= Testing valid =-
Test set: Average loss: 2.5093,                   Accuracy: 417/2000.0 (20.85%)



-= Testing valid =-
Test set: Average loss: 2.3429,                   Accuracy: 553/2000.0 (27.65%)



-= Testing valid =-
Test set: Average loss: 1.3179,                   Accuracy: 1123/2000.0 (56.15%)



-= Testing valid =-
Test set: Average loss: 1.8624,                   Accuracy: 742/2000.0 (37.10%)



-= Testing valid =-
Test set: Average loss: 1.8341,                   Accuracy: 1013/2000.0 (50.65%)



-= Testing valid =-
Test set: Average loss: 1.8157,                   Accuracy: 827/2000.0 (41.35%)



-= Testing valid =-
Test set: Average loss: 2.3607,                   Accuracy: 677/2000.0 (33.85%)



-= Testing valid =-
Test set: Average loss: 0.9098,                   Accuracy: 1426/2000.0 (71.30%)



Epoch 10 train accuracy: 69.89%, valid accuracy 71.30%
-= Testing valid =-
Test set: Average loss: 1.0465,                   Accuracy: 1284/2000.0 (64.20%)



-= Testing valid =-
Test set: Average loss: 1.0570,                   Accuracy: 1292/2000.0 (64.60%)



-= Testing valid =-
Test set: Average loss: 0.6856,                   Accuracy: 1567/2000.0 (78.35%)



-= Testing valid =-
Test set: Average loss: 0.8579,                   Accuracy: 1402/2000.0 (70.10%)



-= Testing valid =-
Test set: Average loss: 0.8063,                   Accuracy: 1398/2000.0 (69.90%)



-= Testing valid =-
Test set: Average loss: 0.6725,                   Accuracy: 1503/2000.0 (75.15%)



-= Testing valid =-
Test set: Average loss: 0.6990,                   Accuracy: 1487/2000.0 (74.35%)



-= Testing valid =-
Test set: Average loss: 0.5045,                   Accuracy: 1652/2000.0 (82.60%)



-= Testing valid =-
Test set: Average loss: 0.5355,                   Accuracy: 1651/2000.0 (82.55%)



-= Testing valid =-
Test set: Average loss: 0.4719,                   Accuracy: 1677/2000.0 (83.85%)



Epoch 20 train accuracy: 84.60%, valid accuracy 83.85%
-= Testing valid =-
Test set: Average loss: 0.5065,                   Accuracy: 1652/2000.0 (82.60%)



-= Testing valid =-
Test set: Average loss: 0.4591,                   Accuracy: 1687/2000.0 (84.35%)



-= Testing valid =-
Test set: Average loss: 0.4882,                   Accuracy: 1664/2000.0 (83.20%)



-= Testing valid =-
Test set: Average loss: 0.4877,                   Accuracy: 1648/2000.0 (82.40%)



-= Testing valid =-
Test set: Average loss: 0.3465,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.3526,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.5031,                   Accuracy: 1654/2000.0 (82.70%)



-= Testing valid =-
Test set: Average loss: 0.3284,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.4031,                   Accuracy: 1714/2000.0 (85.70%)



-= Testing valid =-
Test set: Average loss: 0.4015,                   Accuracy: 1725/2000.0 (86.25%)



Epoch 30 train accuracy: 88.35%, valid accuracy 86.25%
-= Testing valid =-
Test set: Average loss: 0.3526,                   Accuracy: 1768/2000.0 (88.40%)



-= Testing valid =-
Test set: Average loss: 0.3997,                   Accuracy: 1713/2000.0 (85.65%)



-= Testing valid =-
Test set: Average loss: 0.3435,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.3592,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.3129,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.3404,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.2739,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.3299,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.2546,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.3429,                   Accuracy: 1787/2000.0 (89.35%)



Epoch 40 train accuracy: 89.30%, valid accuracy 89.35%
-= Testing valid =-
Test set: Average loss: 0.2853,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2721,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.2739,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2946,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2871,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.3316,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.3305,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.3026,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2999,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.3141,                   Accuracy: 1801/2000.0 (90.05%)



Epoch 50 train accuracy: 90.24%, valid accuracy 90.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3092,                   Accuracy: 54723/60000 (91.21%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3049,                   Accuracy: 54860/60000 (91.43%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3215,                   Accuracy: 54526/60000 (90.88%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3364,                   Accuracy: 54147/60000 (90.25%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3427,                   Accuracy: 53985/60000 (89.97%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3446,                   Accuracy: 53965/60000 (89.94%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3459,                   Accuracy: 53840/60000 (89.73%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3433,                   Accuracy: 53815/60000 (89.69%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3404,                   Accuracy: 53665/60000 (89.44%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3662,                   Accuracy: 52900/60000 (88.17%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3883,                   Accuracy: 52417/60000 (87.36%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.4351,                   Accuracy: 50925/60000 (84.88%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4793,                   Accuracy: 49453/60000 (82.42%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.5124,                   Accuracy: 48378/60000 (80.63%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.5374,                   Accuracy: 47654/60000 (79.42%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5523,                   Accuracy: 47278/60000 (78.80%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.5488,                   Accuracy: 47603/60000 (79.34%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.5138,                   Accuracy: 48879/60000 (81.46%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.5249,                   Accuracy: 48650/60000 (81.08%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.4896,                   Accuracy: 49974/60000 (83.29%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.4952,                   Accuracy: 49819/60000 (83.03%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4886,                   Accuracy: 50096/60000 (83.49%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4527,                   Accuracy: 51141/60000 (85.24%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4294,                   Accuracy: 51701/60000 (86.17%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4035,                   Accuracy: 52269/60000 (87.11%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3773,                   Accuracy: 52905/60000 (88.18%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3457,                   Accuracy: 53467/60000 (89.11%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3390,                   Accuracy: 53755/60000 (89.59%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3309,                   Accuracy: 53944/60000 (89.91%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3288,                   Accuracy: 54074/60000 (90.12%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3415,                   Accuracy: 53834/60000 (89.72%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3400,                   Accuracy: 53983/60000 (89.97%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3332,                   Accuracy: 54180/60000 (90.30%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3324,                   Accuracy: 54249/60000 (90.42%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3213,                   Accuracy: 54553/60000 (90.92%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3033,                   Accuracy: 54839/60000 (91.40%)
{0: tensor(91.2050), 10: tensor(91.4333), 20: tensor(90.8767), 30: tensor(90.2450), 40: tensor(89.9750), 50: tensor(89.9417), 60: tensor(89.7333), 70: tensor(89.6917), 80: tensor(89.4417), 90: tensor(88.1667), 100: tensor(87.3617), 110: tensor(84.8750), 120: tensor(82.4217), 130: tensor(80.6300), 140: tensor(79.4233), 150: tensor(78.7967), 160: tensor(79.3383), 170: tensor(81.4650), 180: tensor(81.0833), 190: tensor(83.2900), 200: tensor(83.0317), 210: tensor(83.4933), 220: tensor(85.2350), 230: tensor(86.1683), 240: tensor(87.1150), 250: tensor(88.1750), 260: tensor(89.1117), 270: tensor(89.5917), 280: tensor(89.9067), 290: tensor(90.1233), 300: tensor(89.7233), 310: tensor(89.9717), 320: tensor(90.3000), 330: tensor(90.4150), 340: tensor(90.9217), 350: tensor(91.3983)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=61, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6156,                   Accuracy: 276/2000.0 (13.80%)



-= Testing valid =-
Test set: Average loss: 2.4617,                   Accuracy: 472/2000.0 (23.60%)



-= Testing valid =-
Test set: Average loss: 2.7144,                   Accuracy: 379/2000.0 (18.95%)



-= Testing valid =-
Test set: Average loss: 1.4251,                   Accuracy: 1062/2000.0 (53.10%)



-= Testing valid =-
Test set: Average loss: 1.2950,                   Accuracy: 1097/2000.0 (54.85%)



-= Testing valid =-
Test set: Average loss: 1.8410,                   Accuracy: 859/2000.0 (42.95%)



-= Testing valid =-
Test set: Average loss: 1.5688,                   Accuracy: 945/2000.0 (47.25%)



-= Testing valid =-
Test set: Average loss: 1.0667,                   Accuracy: 1310/2000.0 (65.50%)



-= Testing valid =-
Test set: Average loss: 0.8568,                   Accuracy: 1402/2000.0 (70.10%)



-= Testing valid =-
Test set: Average loss: 0.8278,                   Accuracy: 1455/2000.0 (72.75%)



Epoch 10 train accuracy: 77.78%, valid accuracy 72.75%
-= Testing valid =-
Test set: Average loss: 0.6026,                   Accuracy: 1586/2000.0 (79.30%)



-= Testing valid =-
Test set: Average loss: 0.7345,                   Accuracy: 1536/2000.0 (76.80%)



-= Testing valid =-
Test set: Average loss: 0.8361,                   Accuracy: 1456/2000.0 (72.80%)



-= Testing valid =-
Test set: Average loss: 0.3852,                   Accuracy: 1737/2000.0 (86.85%)



-= Testing valid =-
Test set: Average loss: 0.5169,                   Accuracy: 1648/2000.0 (82.40%)



-= Testing valid =-
Test set: Average loss: 0.5103,                   Accuracy: 1671/2000.0 (83.55%)



-= Testing valid =-
Test set: Average loss: 0.5055,                   Accuracy: 1663/2000.0 (83.15%)



-= Testing valid =-
Test set: Average loss: 0.3870,                   Accuracy: 1729/2000.0 (86.45%)



-= Testing valid =-
Test set: Average loss: 0.4401,                   Accuracy: 1699/2000.0 (84.95%)



-= Testing valid =-
Test set: Average loss: 0.2960,                   Accuracy: 1809/2000.0 (90.45%)



Epoch 20 train accuracy: 87.15%, valid accuracy 90.45%
-= Testing valid =-
Test set: Average loss: 0.3105,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3434,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.3000,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.3050,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.3970,                   Accuracy: 1729/2000.0 (86.45%)



-= Testing valid =-
Test set: Average loss: 0.3487,                   Accuracy: 1737/2000.0 (86.85%)



-= Testing valid =-
Test set: Average loss: 0.2968,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.3052,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.3164,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3085,                   Accuracy: 1805/2000.0 (90.25%)



Epoch 30 train accuracy: 89.60%, valid accuracy 90.25%
-= Testing valid =-
Test set: Average loss: 0.3193,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.2676,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2506,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2866,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.3074,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.2616,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2722,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2561,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2641,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.3359,                   Accuracy: 1763/2000.0 (88.15%)



Epoch 40 train accuracy: 90.28%, valid accuracy 88.15%
-= Testing valid =-
Test set: Average loss: 0.3542,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.2962,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3009,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.2662,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2709,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2612,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2921,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.3027,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.3418,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.2926,                   Accuracy: 1800/2000.0 (90.00%)



Epoch 50 train accuracy: 91.26%, valid accuracy 90.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2881,                   Accuracy: 54726/60000 (91.21%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2965,                   Accuracy: 54489/60000 (90.82%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3223,                   Accuracy: 53992/60000 (89.99%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3698,                   Accuracy: 53033/60000 (88.39%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3696,                   Accuracy: 53014/60000 (88.36%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3649,                   Accuracy: 53227/60000 (88.71%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3591,                   Accuracy: 53420/60000 (89.03%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3332,                   Accuracy: 53849/60000 (89.75%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3177,                   Accuracy: 54079/60000 (90.13%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3181,                   Accuracy: 54198/60000 (90.33%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3167,                   Accuracy: 54082/60000 (90.14%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3107,                   Accuracy: 54282/60000 (90.47%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3148,                   Accuracy: 54213/60000 (90.36%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3041,                   Accuracy: 54336/60000 (90.56%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.2968,                   Accuracy: 54430/60000 (90.72%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.2962,                   Accuracy: 54409/60000 (90.68%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2791,                   Accuracy: 54753/60000 (91.25%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.2646,                   Accuracy: 55032/60000 (91.72%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.2707,                   Accuracy: 55084/60000 (91.81%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.2780,                   Accuracy: 54930/60000 (91.55%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2946,                   Accuracy: 54646/60000 (91.08%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3168,                   Accuracy: 54322/60000 (90.54%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3295,                   Accuracy: 54028/60000 (90.05%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3348,                   Accuracy: 53905/60000 (89.84%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3379,                   Accuracy: 53767/60000 (89.61%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3231,                   Accuracy: 54007/60000 (90.01%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3129,                   Accuracy: 54045/60000 (90.07%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3079,                   Accuracy: 54246/60000 (90.41%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3006,                   Accuracy: 54395/60000 (90.66%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3067,                   Accuracy: 54308/60000 (90.51%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3042,                   Accuracy: 54443/60000 (90.74%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2934,                   Accuracy: 54655/60000 (91.09%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2818,                   Accuracy: 54963/60000 (91.61%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2771,                   Accuracy: 55094/60000 (91.82%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2728,                   Accuracy: 55153/60000 (91.92%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2703,                   Accuracy: 54989/60000 (91.65%)
{0: tensor(91.2100), 10: tensor(90.8150), 20: tensor(89.9867), 30: tensor(88.3883), 40: tensor(88.3567), 50: tensor(88.7117), 60: tensor(89.0333), 70: tensor(89.7483), 80: tensor(90.1317), 90: tensor(90.3300), 100: tensor(90.1367), 110: tensor(90.4700), 120: tensor(90.3550), 130: tensor(90.5600), 140: tensor(90.7167), 150: tensor(90.6817), 160: tensor(91.2550), 170: tensor(91.7200), 180: tensor(91.8067), 190: tensor(91.5500), 200: tensor(91.0767), 210: tensor(90.5367), 220: tensor(90.0467), 230: tensor(89.8417), 240: tensor(89.6117), 250: tensor(90.0117), 260: tensor(90.0750), 270: tensor(90.4100), 280: tensor(90.6583), 290: tensor(90.5133), 300: tensor(90.7383), 310: tensor(91.0917), 320: tensor(91.6050), 330: tensor(91.8233), 340: tensor(91.9217), 350: tensor(91.6483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=62, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2688,                   Accuracy: 352/2000.0 (17.60%)



-= Testing valid =-
Test set: Average loss: 2.9653,                   Accuracy: 335/2000.0 (16.75%)



-= Testing valid =-
Test set: Average loss: 2.5558,                   Accuracy: 433/2000.0 (21.65%)



-= Testing valid =-
Test set: Average loss: 2.3383,                   Accuracy: 538/2000.0 (26.90%)



-= Testing valid =-
Test set: Average loss: 1.9763,                   Accuracy: 697/2000.0 (34.85%)



-= Testing valid =-
Test set: Average loss: 1.2648,                   Accuracy: 1082/2000.0 (54.10%)



-= Testing valid =-
Test set: Average loss: 1.2732,                   Accuracy: 1126/2000.0 (56.30%)



-= Testing valid =-
Test set: Average loss: 1.8567,                   Accuracy: 759/2000.0 (37.95%)



-= Testing valid =-
Test set: Average loss: 3.1034,                   Accuracy: 649/2000.0 (32.45%)



-= Testing valid =-
Test set: Average loss: 1.0792,                   Accuracy: 1231/2000.0 (61.55%)



Epoch 10 train accuracy: 72.62%, valid accuracy 61.55%
-= Testing valid =-
Test set: Average loss: 1.8479,                   Accuracy: 874/2000.0 (43.70%)



-= Testing valid =-
Test set: Average loss: 1.1987,                   Accuracy: 1164/2000.0 (58.20%)



-= Testing valid =-
Test set: Average loss: 0.9436,                   Accuracy: 1378/2000.0 (68.90%)



-= Testing valid =-
Test set: Average loss: 1.2510,                   Accuracy: 1328/2000.0 (66.40%)



-= Testing valid =-
Test set: Average loss: 0.6050,                   Accuracy: 1632/2000.0 (81.60%)



-= Testing valid =-
Test set: Average loss: 0.4414,                   Accuracy: 1745/2000.0 (87.25%)



-= Testing valid =-
Test set: Average loss: 0.6416,                   Accuracy: 1549/2000.0 (77.45%)



-= Testing valid =-
Test set: Average loss: 0.5696,                   Accuracy: 1615/2000.0 (80.75%)



-= Testing valid =-
Test set: Average loss: 0.5403,                   Accuracy: 1665/2000.0 (83.25%)



-= Testing valid =-
Test set: Average loss: 0.7075,                   Accuracy: 1539/2000.0 (76.95%)



Epoch 20 train accuracy: 86.74%, valid accuracy 76.95%
-= Testing valid =-
Test set: Average loss: 0.6082,                   Accuracy: 1594/2000.0 (79.70%)



-= Testing valid =-
Test set: Average loss: 0.6192,                   Accuracy: 1578/2000.0 (78.90%)



-= Testing valid =-
Test set: Average loss: 0.5463,                   Accuracy: 1623/2000.0 (81.15%)



-= Testing valid =-
Test set: Average loss: 0.5291,                   Accuracy: 1663/2000.0 (83.15%)



-= Testing valid =-
Test set: Average loss: 0.4593,                   Accuracy: 1730/2000.0 (86.50%)



-= Testing valid =-
Test set: Average loss: 0.5588,                   Accuracy: 1651/2000.0 (82.55%)



-= Testing valid =-
Test set: Average loss: 0.4756,                   Accuracy: 1719/2000.0 (85.95%)



-= Testing valid =-
Test set: Average loss: 0.5458,                   Accuracy: 1654/2000.0 (82.70%)



-= Testing valid =-
Test set: Average loss: 0.5594,                   Accuracy: 1614/2000.0 (80.70%)



-= Testing valid =-
Test set: Average loss: 0.5334,                   Accuracy: 1655/2000.0 (82.75%)



Epoch 30 train accuracy: 87.97%, valid accuracy 82.75%
-= Testing valid =-
Test set: Average loss: 0.4797,                   Accuracy: 1696/2000.0 (84.80%)



-= Testing valid =-
Test set: Average loss: 0.5430,                   Accuracy: 1637/2000.0 (81.85%)



-= Testing valid =-
Test set: Average loss: 0.3689,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.4506,                   Accuracy: 1720/2000.0 (86.00%)



-= Testing valid =-
Test set: Average loss: 0.4373,                   Accuracy: 1740/2000.0 (87.00%)



-= Testing valid =-
Test set: Average loss: 0.6511,                   Accuracy: 1562/2000.0 (78.10%)



-= Testing valid =-
Test set: Average loss: 0.4487,                   Accuracy: 1720/2000.0 (86.00%)



-= Testing valid =-
Test set: Average loss: 0.4601,                   Accuracy: 1698/2000.0 (84.90%)



-= Testing valid =-
Test set: Average loss: 0.4358,                   Accuracy: 1728/2000.0 (86.40%)



-= Testing valid =-
Test set: Average loss: 0.5498,                   Accuracy: 1640/2000.0 (82.00%)



Epoch 40 train accuracy: 90.44%, valid accuracy 82.00%
-= Testing valid =-
Test set: Average loss: 0.4031,                   Accuracy: 1749/2000.0 (87.45%)



-= Testing valid =-
Test set: Average loss: 0.4113,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.4160,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.3867,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 0.4537,                   Accuracy: 1710/2000.0 (85.50%)



-= Testing valid =-
Test set: Average loss: 0.3938,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.4848,                   Accuracy: 1694/2000.0 (84.70%)



-= Testing valid =-
Test set: Average loss: 0.4649,                   Accuracy: 1705/2000.0 (85.25%)



-= Testing valid =-
Test set: Average loss: 0.4159,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.4468,                   Accuracy: 1712/2000.0 (85.60%)



Epoch 50 train accuracy: 90.53%, valid accuracy 85.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3721,                   Accuracy: 53390/60000 (88.98%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3545,                   Accuracy: 53614/60000 (89.36%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3891,                   Accuracy: 53030/60000 (88.38%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4206,                   Accuracy: 52495/60000 (87.49%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.4184,                   Accuracy: 52441/60000 (87.40%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.4155,                   Accuracy: 52509/60000 (87.51%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.4143,                   Accuracy: 52556/60000 (87.59%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3864,                   Accuracy: 53150/60000 (88.58%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3525,                   Accuracy: 53788/60000 (89.65%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3696,                   Accuracy: 53508/60000 (89.18%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3685,                   Accuracy: 53425/60000 (89.04%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.4062,                   Accuracy: 52915/60000 (88.19%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4230,                   Accuracy: 52462/60000 (87.44%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4186,                   Accuracy: 52556/60000 (87.59%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.4242,                   Accuracy: 52398/60000 (87.33%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4287,                   Accuracy: 52263/60000 (87.11%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4153,                   Accuracy: 52484/60000 (87.47%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3931,                   Accuracy: 52851/60000 (88.08%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3951,                   Accuracy: 52884/60000 (88.14%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3829,                   Accuracy: 52958/60000 (88.26%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.4022,                   Accuracy: 52798/60000 (88.00%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4156,                   Accuracy: 52657/60000 (87.76%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4124,                   Accuracy: 52792/60000 (87.99%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4168,                   Accuracy: 52616/60000 (87.69%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4362,                   Accuracy: 52242/60000 (87.07%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.4362,                   Accuracy: 52097/60000 (86.83%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.4117,                   Accuracy: 52449/60000 (87.42%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4442,                   Accuracy: 51760/60000 (86.27%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4294,                   Accuracy: 51931/60000 (86.55%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.4569,                   Accuracy: 51597/60000 (86.00%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.4623,                   Accuracy: 51520/60000 (85.87%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.4350,                   Accuracy: 52098/60000 (86.83%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.4178,                   Accuracy: 52457/60000 (87.43%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4118,                   Accuracy: 52607/60000 (87.68%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3951,                   Accuracy: 52912/60000 (88.19%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3648,                   Accuracy: 53484/60000 (89.14%)
{0: tensor(88.9833), 10: tensor(89.3567), 20: tensor(88.3833), 30: tensor(87.4917), 40: tensor(87.4017), 50: tensor(87.5150), 60: tensor(87.5933), 70: tensor(88.5833), 80: tensor(89.6467), 90: tensor(89.1800), 100: tensor(89.0417), 110: tensor(88.1917), 120: tensor(87.4367), 130: tensor(87.5933), 140: tensor(87.3300), 150: tensor(87.1050), 160: tensor(87.4733), 170: tensor(88.0850), 180: tensor(88.1400), 190: tensor(88.2633), 200: tensor(87.9967), 210: tensor(87.7617), 220: tensor(87.9867), 230: tensor(87.6933), 240: tensor(87.0700), 250: tensor(86.8283), 260: tensor(87.4150), 270: tensor(86.2667), 280: tensor(86.5517), 290: tensor(85.9950), 300: tensor(85.8667), 310: tensor(86.8300), 320: tensor(87.4283), 330: tensor(87.6783), 340: tensor(88.1867), 350: tensor(89.1400)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=63, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 11.4588,                   Accuracy: 229/2000.0 (11.45%)



-= Testing valid =-
Test set: Average loss: 2.0267,                   Accuracy: 604/2000.0 (30.20%)



-= Testing valid =-
Test set: Average loss: 1.5845,                   Accuracy: 783/2000.0 (39.15%)



-= Testing valid =-
Test set: Average loss: 1.6937,                   Accuracy: 794/2000.0 (39.70%)



-= Testing valid =-
Test set: Average loss: 1.7016,                   Accuracy: 826/2000.0 (41.30%)



-= Testing valid =-
Test set: Average loss: 1.6139,                   Accuracy: 1037/2000.0 (51.85%)



-= Testing valid =-
Test set: Average loss: 0.8728,                   Accuracy: 1343/2000.0 (67.15%)



-= Testing valid =-
Test set: Average loss: 0.9378,                   Accuracy: 1424/2000.0 (71.20%)



-= Testing valid =-
Test set: Average loss: 1.6310,                   Accuracy: 1085/2000.0 (54.25%)



-= Testing valid =-
Test set: Average loss: 0.6271,                   Accuracy: 1657/2000.0 (82.85%)



Epoch 10 train accuracy: 75.22%, valid accuracy 82.85%
-= Testing valid =-
Test set: Average loss: 0.9268,                   Accuracy: 1490/2000.0 (74.50%)



-= Testing valid =-
Test set: Average loss: 0.6146,                   Accuracy: 1557/2000.0 (77.85%)



-= Testing valid =-
Test set: Average loss: 0.6775,                   Accuracy: 1510/2000.0 (75.50%)



-= Testing valid =-
Test set: Average loss: 0.9870,                   Accuracy: 1434/2000.0 (71.70%)



-= Testing valid =-
Test set: Average loss: 0.4514,                   Accuracy: 1701/2000.0 (85.05%)



-= Testing valid =-
Test set: Average loss: 0.6160,                   Accuracy: 1520/2000.0 (76.00%)



-= Testing valid =-
Test set: Average loss: 0.7574,                   Accuracy: 1496/2000.0 (74.80%)



-= Testing valid =-
Test set: Average loss: 0.5222,                   Accuracy: 1678/2000.0 (83.90%)



-= Testing valid =-
Test set: Average loss: 0.6167,                   Accuracy: 1559/2000.0 (77.95%)



-= Testing valid =-
Test set: Average loss: 0.5381,                   Accuracy: 1640/2000.0 (82.00%)



Epoch 20 train accuracy: 85.46%, valid accuracy 82.00%
-= Testing valid =-
Test set: Average loss: 0.5475,                   Accuracy: 1565/2000.0 (78.25%)



-= Testing valid =-
Test set: Average loss: 0.3408,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.3499,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.2756,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.7291,                   Accuracy: 1532/2000.0 (76.60%)



-= Testing valid =-
Test set: Average loss: 0.4196,                   Accuracy: 1748/2000.0 (87.40%)



-= Testing valid =-
Test set: Average loss: 0.6117,                   Accuracy: 1553/2000.0 (77.65%)



-= Testing valid =-
Test set: Average loss: 0.3489,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.5320,                   Accuracy: 1570/2000.0 (78.50%)



-= Testing valid =-
Test set: Average loss: 0.2859,                   Accuracy: 1826/2000.0 (91.30%)



Epoch 30 train accuracy: 89.81%, valid accuracy 91.30%
-= Testing valid =-
Test set: Average loss: 0.3409,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.3774,                   Accuracy: 1739/2000.0 (86.95%)



-= Testing valid =-
Test set: Average loss: 0.4432,                   Accuracy: 1664/2000.0 (83.20%)



-= Testing valid =-
Test set: Average loss: 0.5057,                   Accuracy: 1596/2000.0 (79.80%)



-= Testing valid =-
Test set: Average loss: 0.3754,                   Accuracy: 1739/2000.0 (86.95%)



-= Testing valid =-
Test set: Average loss: 0.4423,                   Accuracy: 1665/2000.0 (83.25%)



-= Testing valid =-
Test set: Average loss: 0.5808,                   Accuracy: 1535/2000.0 (76.75%)



-= Testing valid =-
Test set: Average loss: 0.3583,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.4467,                   Accuracy: 1683/2000.0 (84.15%)



-= Testing valid =-
Test set: Average loss: 0.5240,                   Accuracy: 1610/2000.0 (80.50%)



Epoch 40 train accuracy: 90.35%, valid accuracy 80.50%
-= Testing valid =-
Test set: Average loss: 0.4068,                   Accuracy: 1711/2000.0 (85.55%)



-= Testing valid =-
Test set: Average loss: 0.4611,                   Accuracy: 1654/2000.0 (82.70%)



-= Testing valid =-
Test set: Average loss: 0.4869,                   Accuracy: 1622/2000.0 (81.10%)



-= Testing valid =-
Test set: Average loss: 0.5111,                   Accuracy: 1610/2000.0 (80.50%)



-= Testing valid =-
Test set: Average loss: 0.4994,                   Accuracy: 1618/2000.0 (80.90%)



-= Testing valid =-
Test set: Average loss: 0.4996,                   Accuracy: 1609/2000.0 (80.45%)



-= Testing valid =-
Test set: Average loss: 0.4393,                   Accuracy: 1673/2000.0 (83.65%)



-= Testing valid =-
Test set: Average loss: 0.6204,                   Accuracy: 1591/2000.0 (79.55%)



-= Testing valid =-
Test set: Average loss: 0.5335,                   Accuracy: 1621/2000.0 (81.05%)



-= Testing valid =-
Test set: Average loss: 0.3281,                   Accuracy: 1790/2000.0 (89.50%)



Epoch 50 train accuracy: 90.47%, valid accuracy 89.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3020,                   Accuracy: 54787/60000 (91.31%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3080,                   Accuracy: 54523/60000 (90.87%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3155,                   Accuracy: 54361/60000 (90.60%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3368,                   Accuracy: 53933/60000 (89.89%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3471,                   Accuracy: 53699/60000 (89.50%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3566,                   Accuracy: 53437/60000 (89.06%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3647,                   Accuracy: 53270/60000 (88.78%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3643,                   Accuracy: 53316/60000 (88.86%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3752,                   Accuracy: 53000/60000 (88.33%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3920,                   Accuracy: 52635/60000 (87.72%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.4074,                   Accuracy: 52327/60000 (87.21%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.4165,                   Accuracy: 52073/60000 (86.79%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4365,                   Accuracy: 51649/60000 (86.08%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4409,                   Accuracy: 51402/60000 (85.67%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.4419,                   Accuracy: 51330/60000 (85.55%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4340,                   Accuracy: 51387/60000 (85.64%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4361,                   Accuracy: 51279/60000 (85.46%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.4232,                   Accuracy: 51581/60000 (85.97%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.4041,                   Accuracy: 52012/60000 (86.69%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3898,                   Accuracy: 52425/60000 (87.38%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3883,                   Accuracy: 52570/60000 (87.62%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3910,                   Accuracy: 52598/60000 (87.66%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4050,                   Accuracy: 52413/60000 (87.36%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4194,                   Accuracy: 52102/60000 (86.84%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4317,                   Accuracy: 51860/60000 (86.43%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.4326,                   Accuracy: 51784/60000 (86.31%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.4194,                   Accuracy: 52005/60000 (86.68%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4065,                   Accuracy: 52350/60000 (87.25%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3870,                   Accuracy: 52863/60000 (88.11%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3802,                   Accuracy: 53196/60000 (88.66%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3681,                   Accuracy: 53554/60000 (89.26%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3526,                   Accuracy: 53981/60000 (89.97%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3420,                   Accuracy: 54271/60000 (90.45%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3307,                   Accuracy: 54453/60000 (90.75%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3189,                   Accuracy: 54584/60000 (90.97%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3119,                   Accuracy: 54613/60000 (91.02%)
{0: tensor(91.3117), 10: tensor(90.8717), 20: tensor(90.6017), 30: tensor(89.8883), 40: tensor(89.4983), 50: tensor(89.0617), 60: tensor(88.7833), 70: tensor(88.8600), 80: tensor(88.3333), 90: tensor(87.7250), 100: tensor(87.2117), 110: tensor(86.7883), 120: tensor(86.0817), 130: tensor(85.6700), 140: tensor(85.5500), 150: tensor(85.6450), 160: tensor(85.4650), 170: tensor(85.9683), 180: tensor(86.6867), 190: tensor(87.3750), 200: tensor(87.6167), 210: tensor(87.6633), 220: tensor(87.3550), 230: tensor(86.8367), 240: tensor(86.4333), 250: tensor(86.3067), 260: tensor(86.6750), 270: tensor(87.2500), 280: tensor(88.1050), 290: tensor(88.6600), 300: tensor(89.2567), 310: tensor(89.9683), 320: tensor(90.4517), 330: tensor(90.7550), 340: tensor(90.9733), 350: tensor(91.0217)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=64, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8872,                   Accuracy: 652/2000.0 (32.60%)



-= Testing valid =-
Test set: Average loss: 3.6715,                   Accuracy: 252/2000.0 (12.60%)



-= Testing valid =-
Test set: Average loss: 1.5427,                   Accuracy: 845/2000.0 (42.25%)



-= Testing valid =-
Test set: Average loss: 2.6450,                   Accuracy: 496/2000.0 (24.80%)



-= Testing valid =-
Test set: Average loss: 1.8457,                   Accuracy: 647/2000.0 (32.35%)



-= Testing valid =-
Test set: Average loss: 1.4834,                   Accuracy: 991/2000.0 (49.55%)



-= Testing valid =-
Test set: Average loss: 1.3540,                   Accuracy: 1031/2000.0 (51.55%)



-= Testing valid =-
Test set: Average loss: 1.1723,                   Accuracy: 1150/2000.0 (57.50%)



-= Testing valid =-
Test set: Average loss: 0.7180,                   Accuracy: 1563/2000.0 (78.15%)



-= Testing valid =-
Test set: Average loss: 1.2961,                   Accuracy: 1114/2000.0 (55.70%)



Epoch 10 train accuracy: 73.36%, valid accuracy 55.70%
-= Testing valid =-
Test set: Average loss: 0.6787,                   Accuracy: 1556/2000.0 (77.80%)



-= Testing valid =-
Test set: Average loss: 0.5293,                   Accuracy: 1682/2000.0 (84.10%)



-= Testing valid =-
Test set: Average loss: 0.6178,                   Accuracy: 1594/2000.0 (79.70%)



-= Testing valid =-
Test set: Average loss: 0.3330,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.4030,                   Accuracy: 1737/2000.0 (86.85%)



-= Testing valid =-
Test set: Average loss: 0.3379,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.4358,                   Accuracy: 1716/2000.0 (85.80%)



-= Testing valid =-
Test set: Average loss: 0.2606,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2655,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.3643,                   Accuracy: 1757/2000.0 (87.85%)



Epoch 20 train accuracy: 86.75%, valid accuracy 87.85%
-= Testing valid =-
Test set: Average loss: 0.2680,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2601,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.1935,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.2544,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2107,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2250,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2880,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.1945,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.2238,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2566,                   Accuracy: 1835/2000.0 (91.75%)



Epoch 30 train accuracy: 89.12%, valid accuracy 91.75%
-= Testing valid =-
Test set: Average loss: 0.2838,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.1929,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.2438,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2351,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2219,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2374,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2139,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2361,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2595,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.1814,                   Accuracy: 1886/2000.0 (94.30%)



Epoch 40 train accuracy: 90.40%, valid accuracy 94.30%
-= Testing valid =-
Test set: Average loss: 0.1721,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1982,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2028,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.1916,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.2268,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2020,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.1885,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.2145,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2024,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1934,                   Accuracy: 1873/2000.0 (93.65%)



Epoch 50 train accuracy: 91.09%, valid accuracy 93.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2453,                   Accuracy: 55504/60000 (92.51%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2506,                   Accuracy: 55251/60000 (92.08%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2619,                   Accuracy: 55197/60000 (92.00%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2755,                   Accuracy: 55001/60000 (91.67%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2863,                   Accuracy: 54727/60000 (91.21%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3000,                   Accuracy: 54443/60000 (90.74%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3096,                   Accuracy: 54188/60000 (90.31%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3066,                   Accuracy: 54189/60000 (90.32%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3033,                   Accuracy: 54173/60000 (90.29%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2989,                   Accuracy: 54309/60000 (90.51%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2982,                   Accuracy: 54316/60000 (90.53%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2993,                   Accuracy: 54292/60000 (90.49%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.2959,                   Accuracy: 54450/60000 (90.75%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.2944,                   Accuracy: 54496/60000 (90.83%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.2939,                   Accuracy: 54461/60000 (90.77%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.2924,                   Accuracy: 54495/60000 (90.82%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2902,                   Accuracy: 54511/60000 (90.85%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.2814,                   Accuracy: 54626/60000 (91.04%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.2845,                   Accuracy: 54638/60000 (91.06%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.2874,                   Accuracy: 54557/60000 (90.93%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2949,                   Accuracy: 54475/60000 (90.79%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3069,                   Accuracy: 54128/60000 (90.21%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3038,                   Accuracy: 54323/60000 (90.54%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.2951,                   Accuracy: 54486/60000 (90.81%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.2918,                   Accuracy: 54589/60000 (90.98%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2797,                   Accuracy: 54846/60000 (91.41%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2655,                   Accuracy: 55038/60000 (91.73%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2615,                   Accuracy: 55162/60000 (91.94%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2623,                   Accuracy: 55093/60000 (91.82%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2585,                   Accuracy: 55288/60000 (92.15%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2628,                   Accuracy: 55263/60000 (92.11%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2625,                   Accuracy: 55265/60000 (92.11%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2630,                   Accuracy: 55248/60000 (92.08%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2594,                   Accuracy: 55255/60000 (92.09%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2579,                   Accuracy: 55314/60000 (92.19%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2471,                   Accuracy: 55364/60000 (92.27%)
{0: tensor(92.5067), 10: tensor(92.0850), 20: tensor(91.9950), 30: tensor(91.6683), 40: tensor(91.2117), 50: tensor(90.7383), 60: tensor(90.3133), 70: tensor(90.3150), 80: tensor(90.2883), 90: tensor(90.5150), 100: tensor(90.5267), 110: tensor(90.4867), 120: tensor(90.7500), 130: tensor(90.8267), 140: tensor(90.7683), 150: tensor(90.8250), 160: tensor(90.8517), 170: tensor(91.0433), 180: tensor(91.0633), 190: tensor(90.9283), 200: tensor(90.7917), 210: tensor(90.2133), 220: tensor(90.5383), 230: tensor(90.8100), 240: tensor(90.9817), 250: tensor(91.4100), 260: tensor(91.7300), 270: tensor(91.9367), 280: tensor(91.8217), 290: tensor(92.1467), 300: tensor(92.1050), 310: tensor(92.1083), 320: tensor(92.0800), 330: tensor(92.0917), 340: tensor(92.1900), 350: tensor(92.2733)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=65, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6497,                   Accuracy: 387/2000.0 (19.35%)



-= Testing valid =-
Test set: Average loss: 2.5308,                   Accuracy: 526/2000.0 (26.30%)



-= Testing valid =-
Test set: Average loss: 2.1983,                   Accuracy: 620/2000.0 (31.00%)



-= Testing valid =-
Test set: Average loss: 1.3193,                   Accuracy: 1006/2000.0 (50.30%)



-= Testing valid =-
Test set: Average loss: 1.5322,                   Accuracy: 863/2000.0 (43.15%)



-= Testing valid =-
Test set: Average loss: 1.6778,                   Accuracy: 838/2000.0 (41.90%)



-= Testing valid =-
Test set: Average loss: 1.1257,                   Accuracy: 1247/2000.0 (62.35%)



-= Testing valid =-
Test set: Average loss: 1.6545,                   Accuracy: 921/2000.0 (46.05%)



-= Testing valid =-
Test set: Average loss: 0.8468,                   Accuracy: 1470/2000.0 (73.50%)



-= Testing valid =-
Test set: Average loss: 1.3650,                   Accuracy: 1033/2000.0 (51.65%)



Epoch 10 train accuracy: 73.66%, valid accuracy 51.65%
-= Testing valid =-
Test set: Average loss: 0.5769,                   Accuracy: 1653/2000.0 (82.65%)



-= Testing valid =-
Test set: Average loss: 0.5311,                   Accuracy: 1653/2000.0 (82.65%)



-= Testing valid =-
Test set: Average loss: 0.4966,                   Accuracy: 1692/2000.0 (84.60%)



-= Testing valid =-
Test set: Average loss: 0.4341,                   Accuracy: 1710/2000.0 (85.50%)



-= Testing valid =-
Test set: Average loss: 0.3698,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.3542,                   Accuracy: 1740/2000.0 (87.00%)



-= Testing valid =-
Test set: Average loss: 0.4704,                   Accuracy: 1679/2000.0 (83.95%)



-= Testing valid =-
Test set: Average loss: 0.3117,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.2674,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.3559,                   Accuracy: 1767/2000.0 (88.35%)



Epoch 20 train accuracy: 86.46%, valid accuracy 88.35%
-= Testing valid =-
Test set: Average loss: 0.2873,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2697,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.3274,                   Accuracy: 1777/2000.0 (88.85%)



-= Testing valid =-
Test set: Average loss: 0.2886,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.2074,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2301,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.2759,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2519,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2457,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2893,                   Accuracy: 1814/2000.0 (90.70%)



Epoch 30 train accuracy: 89.28%, valid accuracy 90.70%
-= Testing valid =-
Test set: Average loss: 0.2195,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.2529,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2167,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.2143,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.2060,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.2462,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2112,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.2165,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2559,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2317,                   Accuracy: 1855/2000.0 (92.75%)



Epoch 40 train accuracy: 90.49%, valid accuracy 92.75%
-= Testing valid =-
Test set: Average loss: 0.2155,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2193,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1965,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.2085,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.2165,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2637,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2289,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.2036,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.2073,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.2117,                   Accuracy: 1872/2000.0 (93.60%)



Epoch 50 train accuracy: 90.78%, valid accuracy 93.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2312,                   Accuracy: 55715/60000 (92.86%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2621,                   Accuracy: 55058/60000 (91.76%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2410,                   Accuracy: 55451/60000 (92.42%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2384,                   Accuracy: 55505/60000 (92.51%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2376,                   Accuracy: 55467/60000 (92.44%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2385,                   Accuracy: 55436/60000 (92.39%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2389,                   Accuracy: 55387/60000 (92.31%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2403,                   Accuracy: 55390/60000 (92.32%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2526,                   Accuracy: 55085/60000 (91.81%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2445,                   Accuracy: 55237/60000 (92.06%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2857,                   Accuracy: 54410/60000 (90.68%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2745,                   Accuracy: 54627/60000 (91.04%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.2722,                   Accuracy: 54666/60000 (91.11%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.2731,                   Accuracy: 54661/60000 (91.10%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.2738,                   Accuracy: 54623/60000 (91.04%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.2734,                   Accuracy: 54609/60000 (91.01%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2704,                   Accuracy: 54755/60000 (91.26%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.2792,                   Accuracy: 54585/60000 (90.97%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.2596,                   Accuracy: 54998/60000 (91.66%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.2891,                   Accuracy: 54448/60000 (90.75%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2793,                   Accuracy: 54632/60000 (91.05%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.2820,                   Accuracy: 54519/60000 (90.86%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.2851,                   Accuracy: 54502/60000 (90.84%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.2851,                   Accuracy: 54538/60000 (90.90%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.2832,                   Accuracy: 54609/60000 (91.01%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2799,                   Accuracy: 54625/60000 (91.04%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2711,                   Accuracy: 54822/60000 (91.37%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2493,                   Accuracy: 55278/60000 (92.13%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2696,                   Accuracy: 54991/60000 (91.65%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2552,                   Accuracy: 55212/60000 (92.02%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2548,                   Accuracy: 55259/60000 (92.10%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2580,                   Accuracy: 55097/60000 (91.83%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2585,                   Accuracy: 55071/60000 (91.79%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2571,                   Accuracy: 55181/60000 (91.97%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2527,                   Accuracy: 55245/60000 (92.07%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2573,                   Accuracy: 55170/60000 (91.95%)
{0: tensor(92.8583), 10: tensor(91.7633), 20: tensor(92.4183), 30: tensor(92.5083), 40: tensor(92.4450), 50: tensor(92.3933), 60: tensor(92.3117), 70: tensor(92.3167), 80: tensor(91.8083), 90: tensor(92.0617), 100: tensor(90.6833), 110: tensor(91.0450), 120: tensor(91.1100), 130: tensor(91.1017), 140: tensor(91.0383), 150: tensor(91.0150), 160: tensor(91.2583), 170: tensor(90.9750), 180: tensor(91.6633), 190: tensor(90.7467), 200: tensor(91.0533), 210: tensor(90.8650), 220: tensor(90.8367), 230: tensor(90.8967), 240: tensor(91.0150), 250: tensor(91.0417), 260: tensor(91.3700), 270: tensor(92.1300), 280: tensor(91.6517), 290: tensor(92.0200), 300: tensor(92.0983), 310: tensor(91.8283), 320: tensor(91.7850), 330: tensor(91.9683), 340: tensor(92.0750), 350: tensor(91.9500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=66, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.2236,                   Accuracy: 213/2000.0 (10.65%)



-= Testing valid =-
Test set: Average loss: 3.2491,                   Accuracy: 356/2000.0 (17.80%)



-= Testing valid =-
Test set: Average loss: 1.7581,                   Accuracy: 849/2000.0 (42.45%)



-= Testing valid =-
Test set: Average loss: 1.4293,                   Accuracy: 956/2000.0 (47.80%)



-= Testing valid =-
Test set: Average loss: 1.1412,                   Accuracy: 1204/2000.0 (60.20%)



-= Testing valid =-
Test set: Average loss: 1.3807,                   Accuracy: 1018/2000.0 (50.90%)



-= Testing valid =-
Test set: Average loss: 1.2701,                   Accuracy: 1116/2000.0 (55.80%)



-= Testing valid =-
Test set: Average loss: 0.8456,                   Accuracy: 1395/2000.0 (69.75%)



-= Testing valid =-
Test set: Average loss: 1.0069,                   Accuracy: 1290/2000.0 (64.50%)



-= Testing valid =-
Test set: Average loss: 1.1056,                   Accuracy: 1269/2000.0 (63.45%)



Epoch 10 train accuracy: 80.50%, valid accuracy 63.45%
-= Testing valid =-
Test set: Average loss: 0.4096,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.6281,                   Accuracy: 1584/2000.0 (79.20%)



-= Testing valid =-
Test set: Average loss: 0.4703,                   Accuracy: 1677/2000.0 (83.85%)



-= Testing valid =-
Test set: Average loss: 0.5427,                   Accuracy: 1623/2000.0 (81.15%)



-= Testing valid =-
Test set: Average loss: 0.4586,                   Accuracy: 1719/2000.0 (85.95%)



-= Testing valid =-
Test set: Average loss: 0.6757,                   Accuracy: 1534/2000.0 (76.70%)



-= Testing valid =-
Test set: Average loss: 0.4366,                   Accuracy: 1721/2000.0 (86.05%)



-= Testing valid =-
Test set: Average loss: 0.5619,                   Accuracy: 1615/2000.0 (80.75%)



-= Testing valid =-
Test set: Average loss: 0.3454,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.3326,                   Accuracy: 1811/2000.0 (90.55%)



Epoch 20 train accuracy: 87.39%, valid accuracy 90.55%
-= Testing valid =-
Test set: Average loss: 0.3258,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3800,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.4270,                   Accuracy: 1735/2000.0 (86.75%)



-= Testing valid =-
Test set: Average loss: 0.3576,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.2842,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.4184,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.3013,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.3252,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.3690,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.3137,                   Accuracy: 1801/2000.0 (90.05%)



Epoch 30 train accuracy: 89.94%, valid accuracy 90.05%
-= Testing valid =-
Test set: Average loss: 0.2868,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.3143,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.2905,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2955,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2932,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2636,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2755,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.3543,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.2721,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2932,                   Accuracy: 1827/2000.0 (91.35%)



Epoch 40 train accuracy: 90.56%, valid accuracy 91.35%
-= Testing valid =-
Test set: Average loss: 0.2783,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2481,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.2374,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2424,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.2681,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2587,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.2701,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2699,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2628,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2581,                   Accuracy: 1845/2000.0 (92.25%)



Epoch 50 train accuracy: 91.19%, valid accuracy 92.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2661,                   Accuracy: 55051/60000 (91.75%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2847,                   Accuracy: 54655/60000 (91.09%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2961,                   Accuracy: 54666/60000 (91.11%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3088,                   Accuracy: 54440/60000 (90.73%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3120,                   Accuracy: 54369/60000 (90.61%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3151,                   Accuracy: 54292/60000 (90.49%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3112,                   Accuracy: 54328/60000 (90.55%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3155,                   Accuracy: 54215/60000 (90.36%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2929,                   Accuracy: 54592/60000 (90.99%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2917,                   Accuracy: 54705/60000 (91.18%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2780,                   Accuracy: 54915/60000 (91.53%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2890,                   Accuracy: 54836/60000 (91.39%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.2865,                   Accuracy: 54821/60000 (91.37%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.2821,                   Accuracy: 54888/60000 (91.48%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.2820,                   Accuracy: 54806/60000 (91.34%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.2885,                   Accuracy: 54621/60000 (91.04%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2914,                   Accuracy: 54501/60000 (90.83%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.2718,                   Accuracy: 54868/60000 (91.45%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.2833,                   Accuracy: 54621/60000 (91.04%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3144,                   Accuracy: 53870/60000 (89.78%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3303,                   Accuracy: 53683/60000 (89.47%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3502,                   Accuracy: 53173/60000 (88.62%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3592,                   Accuracy: 52932/60000 (88.22%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3605,                   Accuracy: 52904/60000 (88.17%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3506,                   Accuracy: 53105/60000 (88.51%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3399,                   Accuracy: 53440/60000 (89.07%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3052,                   Accuracy: 54201/60000 (90.33%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2936,                   Accuracy: 54588/60000 (90.98%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2841,                   Accuracy: 54674/60000 (91.12%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3000,                   Accuracy: 54545/60000 (90.91%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3031,                   Accuracy: 54483/60000 (90.81%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3045,                   Accuracy: 54355/60000 (90.59%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3044,                   Accuracy: 54334/60000 (90.56%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2980,                   Accuracy: 54471/60000 (90.79%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2884,                   Accuracy: 54558/60000 (90.93%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2697,                   Accuracy: 54931/60000 (91.55%)
{0: tensor(91.7517), 10: tensor(91.0917), 20: tensor(91.1100), 30: tensor(90.7333), 40: tensor(90.6150), 50: tensor(90.4867), 60: tensor(90.5467), 70: tensor(90.3583), 80: tensor(90.9867), 90: tensor(91.1750), 100: tensor(91.5250), 110: tensor(91.3933), 120: tensor(91.3683), 130: tensor(91.4800), 140: tensor(91.3433), 150: tensor(91.0350), 160: tensor(90.8350), 170: tensor(91.4467), 180: tensor(91.0350), 190: tensor(89.7833), 200: tensor(89.4717), 210: tensor(88.6217), 220: tensor(88.2200), 230: tensor(88.1733), 240: tensor(88.5083), 250: tensor(89.0667), 260: tensor(90.3350), 270: tensor(90.9800), 280: tensor(91.1233), 290: tensor(90.9083), 300: tensor(90.8050), 310: tensor(90.5917), 320: tensor(90.5567), 330: tensor(90.7850), 340: tensor(90.9300), 350: tensor(91.5517)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=67, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.9143,                   Accuracy: 228/2000.0 (11.40%)



-= Testing valid =-
Test set: Average loss: 5.7184,                   Accuracy: 249/2000.0 (12.45%)



-= Testing valid =-
Test set: Average loss: 2.1432,                   Accuracy: 555/2000.0 (27.75%)



-= Testing valid =-
Test set: Average loss: 1.3697,                   Accuracy: 1015/2000.0 (50.75%)



-= Testing valid =-
Test set: Average loss: 1.2820,                   Accuracy: 1135/2000.0 (56.75%)



-= Testing valid =-
Test set: Average loss: 1.6061,                   Accuracy: 780/2000.0 (39.00%)



-= Testing valid =-
Test set: Average loss: 1.5085,                   Accuracy: 912/2000.0 (45.60%)



-= Testing valid =-
Test set: Average loss: 1.5008,                   Accuracy: 991/2000.0 (49.55%)



-= Testing valid =-
Test set: Average loss: 0.6209,                   Accuracy: 1576/2000.0 (78.80%)



-= Testing valid =-
Test set: Average loss: 0.8867,                   Accuracy: 1366/2000.0 (68.30%)



Epoch 10 train accuracy: 76.84%, valid accuracy 68.30%
-= Testing valid =-
Test set: Average loss: 0.5281,                   Accuracy: 1661/2000.0 (83.05%)



-= Testing valid =-
Test set: Average loss: 0.5673,                   Accuracy: 1612/2000.0 (80.60%)



-= Testing valid =-
Test set: Average loss: 0.4322,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.4574,                   Accuracy: 1707/2000.0 (85.35%)



-= Testing valid =-
Test set: Average loss: 0.3990,                   Accuracy: 1749/2000.0 (87.45%)



-= Testing valid =-
Test set: Average loss: 0.4346,                   Accuracy: 1717/2000.0 (85.85%)



-= Testing valid =-
Test set: Average loss: 0.5750,                   Accuracy: 1637/2000.0 (81.85%)



-= Testing valid =-
Test set: Average loss: 0.3043,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.3862,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.2838,                   Accuracy: 1816/2000.0 (90.80%)



Epoch 20 train accuracy: 86.84%, valid accuracy 90.80%
-= Testing valid =-
Test set: Average loss: 0.2955,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2690,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2950,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.2403,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.3110,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.3817,                   Accuracy: 1735/2000.0 (86.75%)



-= Testing valid =-
Test set: Average loss: 0.3294,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.2575,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2947,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.3280,                   Accuracy: 1779/2000.0 (88.95%)



Epoch 30 train accuracy: 89.72%, valid accuracy 88.95%
-= Testing valid =-
Test set: Average loss: 0.2124,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2726,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2599,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2569,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.3186,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.2391,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.2847,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2774,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2496,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.2639,                   Accuracy: 1827/2000.0 (91.35%)



Epoch 40 train accuracy: 89.89%, valid accuracy 91.35%
-= Testing valid =-
Test set: Average loss: 0.2380,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2528,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2305,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.2255,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.2521,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2536,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2088,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2341,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2372,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2344,                   Accuracy: 1845/2000.0 (92.25%)



Epoch 50 train accuracy: 90.50%, valid accuracy 92.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2731,                   Accuracy: 55242/60000 (92.07%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2862,                   Accuracy: 54964/60000 (91.61%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2853,                   Accuracy: 55074/60000 (91.79%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2982,                   Accuracy: 54850/60000 (91.42%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2979,                   Accuracy: 54795/60000 (91.32%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2939,                   Accuracy: 54860/60000 (91.43%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2965,                   Accuracy: 54673/60000 (91.12%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2920,                   Accuracy: 54699/60000 (91.17%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2846,                   Accuracy: 54737/60000 (91.23%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2742,                   Accuracy: 54922/60000 (91.54%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2798,                   Accuracy: 54806/60000 (91.34%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2818,                   Accuracy: 54818/60000 (91.36%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.2913,                   Accuracy: 54669/60000 (91.11%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.2906,                   Accuracy: 54707/60000 (91.18%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.2935,                   Accuracy: 54652/60000 (91.09%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.2953,                   Accuracy: 54668/60000 (91.11%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3062,                   Accuracy: 54452/60000 (90.75%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3077,                   Accuracy: 54342/60000 (90.57%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3222,                   Accuracy: 54059/60000 (90.10%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3470,                   Accuracy: 53487/60000 (89.14%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3615,                   Accuracy: 53163/60000 (88.61%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3722,                   Accuracy: 53043/60000 (88.40%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3580,                   Accuracy: 53285/60000 (88.81%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3410,                   Accuracy: 53682/60000 (89.47%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3240,                   Accuracy: 54061/60000 (90.10%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3109,                   Accuracy: 54336/60000 (90.56%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2905,                   Accuracy: 54649/60000 (91.08%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2831,                   Accuracy: 54799/60000 (91.33%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2920,                   Accuracy: 54624/60000 (91.04%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2973,                   Accuracy: 54563/60000 (90.94%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3002,                   Accuracy: 54535/60000 (90.89%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2983,                   Accuracy: 54717/60000 (91.19%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2886,                   Accuracy: 54899/60000 (91.50%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2879,                   Accuracy: 54943/60000 (91.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2858,                   Accuracy: 55006/60000 (91.68%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2728,                   Accuracy: 55216/60000 (92.03%)
{0: tensor(92.0700), 10: tensor(91.6067), 20: tensor(91.7900), 30: tensor(91.4167), 40: tensor(91.3250), 50: tensor(91.4333), 60: tensor(91.1217), 70: tensor(91.1650), 80: tensor(91.2283), 90: tensor(91.5367), 100: tensor(91.3433), 110: tensor(91.3633), 120: tensor(91.1150), 130: tensor(91.1783), 140: tensor(91.0867), 150: tensor(91.1133), 160: tensor(90.7533), 170: tensor(90.5700), 180: tensor(90.0983), 190: tensor(89.1450), 200: tensor(88.6050), 210: tensor(88.4050), 220: tensor(88.8083), 230: tensor(89.4700), 240: tensor(90.1017), 250: tensor(90.5600), 260: tensor(91.0817), 270: tensor(91.3317), 280: tensor(91.0400), 290: tensor(90.9383), 300: tensor(90.8917), 310: tensor(91.1950), 320: tensor(91.4983), 330: tensor(91.5717), 340: tensor(91.6767), 350: tensor(92.0267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=68, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.7844,                   Accuracy: 213/2000.0 (10.65%)



-= Testing valid =-
Test set: Average loss: 3.4783,                   Accuracy: 331/2000.0 (16.55%)



-= Testing valid =-
Test set: Average loss: 1.3593,                   Accuracy: 1023/2000.0 (51.15%)



-= Testing valid =-
Test set: Average loss: 1.4800,                   Accuracy: 861/2000.0 (43.05%)



-= Testing valid =-
Test set: Average loss: 1.7108,                   Accuracy: 884/2000.0 (44.20%)



-= Testing valid =-
Test set: Average loss: 1.4163,                   Accuracy: 1027/2000.0 (51.35%)



-= Testing valid =-
Test set: Average loss: 1.3906,                   Accuracy: 1062/2000.0 (53.10%)



-= Testing valid =-
Test set: Average loss: 0.9667,                   Accuracy: 1269/2000.0 (63.45%)



-= Testing valid =-
Test set: Average loss: 0.8070,                   Accuracy: 1455/2000.0 (72.75%)



-= Testing valid =-
Test set: Average loss: 1.0742,                   Accuracy: 1228/2000.0 (61.40%)



Epoch 10 train accuracy: 70.88%, valid accuracy 61.40%
-= Testing valid =-
Test set: Average loss: 0.7822,                   Accuracy: 1478/2000.0 (73.90%)



-= Testing valid =-
Test set: Average loss: 0.9299,                   Accuracy: 1299/2000.0 (64.95%)



-= Testing valid =-
Test set: Average loss: 1.0096,                   Accuracy: 1230/2000.0 (61.50%)



-= Testing valid =-
Test set: Average loss: 0.6655,                   Accuracy: 1626/2000.0 (81.30%)



-= Testing valid =-
Test set: Average loss: 0.6112,                   Accuracy: 1586/2000.0 (79.30%)



-= Testing valid =-
Test set: Average loss: 0.9308,                   Accuracy: 1317/2000.0 (65.85%)



-= Testing valid =-
Test set: Average loss: 0.4738,                   Accuracy: 1701/2000.0 (85.05%)



-= Testing valid =-
Test set: Average loss: 0.6234,                   Accuracy: 1553/2000.0 (77.65%)



-= Testing valid =-
Test set: Average loss: 0.9607,                   Accuracy: 1284/2000.0 (64.20%)



-= Testing valid =-
Test set: Average loss: 0.6209,                   Accuracy: 1539/2000.0 (76.95%)



Epoch 20 train accuracy: 85.60%, valid accuracy 76.95%
-= Testing valid =-
Test set: Average loss: 0.4346,                   Accuracy: 1729/2000.0 (86.45%)



-= Testing valid =-
Test set: Average loss: 0.4705,                   Accuracy: 1689/2000.0 (84.45%)



-= Testing valid =-
Test set: Average loss: 0.3503,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3214,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.4237,                   Accuracy: 1723/2000.0 (86.15%)



-= Testing valid =-
Test set: Average loss: 0.4779,                   Accuracy: 1668/2000.0 (83.40%)



-= Testing valid =-
Test set: Average loss: 0.4886,                   Accuracy: 1661/2000.0 (83.05%)



-= Testing valid =-
Test set: Average loss: 0.5596,                   Accuracy: 1645/2000.0 (82.25%)



-= Testing valid =-
Test set: Average loss: 0.4542,                   Accuracy: 1689/2000.0 (84.45%)



-= Testing valid =-
Test set: Average loss: 0.5909,                   Accuracy: 1585/2000.0 (79.25%)



Epoch 30 train accuracy: 89.94%, valid accuracy 79.25%
-= Testing valid =-
Test set: Average loss: 0.4504,                   Accuracy: 1708/2000.0 (85.40%)



-= Testing valid =-
Test set: Average loss: 0.3930,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.4204,                   Accuracy: 1728/2000.0 (86.40%)



-= Testing valid =-
Test set: Average loss: 0.3923,                   Accuracy: 1745/2000.0 (87.25%)



-= Testing valid =-
Test set: Average loss: 0.5698,                   Accuracy: 1582/2000.0 (79.10%)



-= Testing valid =-
Test set: Average loss: 0.4095,                   Accuracy: 1731/2000.0 (86.55%)



-= Testing valid =-
Test set: Average loss: 0.3306,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.4131,                   Accuracy: 1730/2000.0 (86.50%)



-= Testing valid =-
Test set: Average loss: 0.4331,                   Accuracy: 1731/2000.0 (86.55%)



-= Testing valid =-
Test set: Average loss: 0.3900,                   Accuracy: 1757/2000.0 (87.85%)



Epoch 40 train accuracy: 90.07%, valid accuracy 87.85%
-= Testing valid =-
Test set: Average loss: 0.3793,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.3646,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.3717,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.3382,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.3441,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.4141,                   Accuracy: 1732/2000.0 (86.60%)



-= Testing valid =-
Test set: Average loss: 0.3819,                   Accuracy: 1768/2000.0 (88.40%)



-= Testing valid =-
Test set: Average loss: 0.3714,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.3685,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.4260,                   Accuracy: 1732/2000.0 (86.60%)



Epoch 50 train accuracy: 91.00%, valid accuracy 86.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3634,                   Accuracy: 53360/60000 (88.93%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3809,                   Accuracy: 53013/60000 (88.36%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3889,                   Accuracy: 52740/60000 (87.90%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4042,                   Accuracy: 52335/60000 (87.22%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.4063,                   Accuracy: 52191/60000 (86.99%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.4117,                   Accuracy: 52040/60000 (86.73%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.4043,                   Accuracy: 52047/60000 (86.75%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.4073,                   Accuracy: 51951/60000 (86.58%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3914,                   Accuracy: 52289/60000 (87.15%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4078,                   Accuracy: 51816/60000 (86.36%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.4206,                   Accuracy: 51576/60000 (85.96%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.4558,                   Accuracy: 50734/60000 (84.56%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4729,                   Accuracy: 50295/60000 (83.82%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4804,                   Accuracy: 50225/60000 (83.71%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.4852,                   Accuracy: 50248/60000 (83.75%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4731,                   Accuracy: 50552/60000 (84.25%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4571,                   Accuracy: 51017/60000 (85.03%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.4209,                   Accuracy: 51862/60000 (86.44%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.4052,                   Accuracy: 52303/60000 (87.17%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3963,                   Accuracy: 52537/60000 (87.56%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3972,                   Accuracy: 52451/60000 (87.42%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3944,                   Accuracy: 52476/60000 (87.46%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3861,                   Accuracy: 52760/60000 (87.93%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3773,                   Accuracy: 52968/60000 (88.28%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3586,                   Accuracy: 53306/60000 (88.84%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3471,                   Accuracy: 53526/60000 (89.21%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3257,                   Accuracy: 53914/60000 (89.86%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3285,                   Accuracy: 53943/60000 (89.90%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3393,                   Accuracy: 53761/60000 (89.60%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3444,                   Accuracy: 53658/60000 (89.43%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3592,                   Accuracy: 53357/60000 (88.93%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3738,                   Accuracy: 53102/60000 (88.50%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3847,                   Accuracy: 52966/60000 (88.28%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3797,                   Accuracy: 53072/60000 (88.45%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3790,                   Accuracy: 53192/60000 (88.65%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3581,                   Accuracy: 53424/60000 (89.04%)
{0: tensor(88.9333), 10: tensor(88.3550), 20: tensor(87.9000), 30: tensor(87.2250), 40: tensor(86.9850), 50: tensor(86.7333), 60: tensor(86.7450), 70: tensor(86.5850), 80: tensor(87.1483), 90: tensor(86.3600), 100: tensor(85.9600), 110: tensor(84.5567), 120: tensor(83.8250), 130: tensor(83.7083), 140: tensor(83.7467), 150: tensor(84.2533), 160: tensor(85.0283), 170: tensor(86.4367), 180: tensor(87.1717), 190: tensor(87.5617), 200: tensor(87.4183), 210: tensor(87.4600), 220: tensor(87.9333), 230: tensor(88.2800), 240: tensor(88.8433), 250: tensor(89.2100), 260: tensor(89.8567), 270: tensor(89.9050), 280: tensor(89.6017), 290: tensor(89.4300), 300: tensor(88.9283), 310: tensor(88.5033), 320: tensor(88.2767), 330: tensor(88.4533), 340: tensor(88.6533), 350: tensor(89.0400)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=69, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 11.5998,                   Accuracy: 237/2000.0 (11.85%)



-= Testing valid =-
Test set: Average loss: 2.7754,                   Accuracy: 353/2000.0 (17.65%)



-= Testing valid =-
Test set: Average loss: 4.3363,                   Accuracy: 275/2000.0 (13.75%)



-= Testing valid =-
Test set: Average loss: 1.5885,                   Accuracy: 825/2000.0 (41.25%)



-= Testing valid =-
Test set: Average loss: 2.3887,                   Accuracy: 592/2000.0 (29.60%)



-= Testing valid =-
Test set: Average loss: 1.7437,                   Accuracy: 789/2000.0 (39.45%)



-= Testing valid =-
Test set: Average loss: 2.3477,                   Accuracy: 514/2000.0 (25.70%)



-= Testing valid =-
Test set: Average loss: 1.8114,                   Accuracy: 793/2000.0 (39.65%)



-= Testing valid =-
Test set: Average loss: 1.2435,                   Accuracy: 1089/2000.0 (54.45%)



-= Testing valid =-
Test set: Average loss: 0.9848,                   Accuracy: 1290/2000.0 (64.50%)



Epoch 10 train accuracy: 64.71%, valid accuracy 64.50%
-= Testing valid =-
Test set: Average loss: 1.0590,                   Accuracy: 1226/2000.0 (61.30%)



-= Testing valid =-
Test set: Average loss: 0.7516,                   Accuracy: 1524/2000.0 (76.20%)



-= Testing valid =-
Test set: Average loss: 1.1985,                   Accuracy: 1152/2000.0 (57.60%)



-= Testing valid =-
Test set: Average loss: 0.7655,                   Accuracy: 1510/2000.0 (75.50%)



-= Testing valid =-
Test set: Average loss: 0.6531,                   Accuracy: 1578/2000.0 (78.90%)



-= Testing valid =-
Test set: Average loss: 0.8460,                   Accuracy: 1366/2000.0 (68.30%)



-= Testing valid =-
Test set: Average loss: 0.7763,                   Accuracy: 1449/2000.0 (72.45%)



-= Testing valid =-
Test set: Average loss: 0.6680,                   Accuracy: 1505/2000.0 (75.25%)



-= Testing valid =-
Test set: Average loss: 0.8590,                   Accuracy: 1469/2000.0 (73.45%)



-= Testing valid =-
Test set: Average loss: 0.4111,                   Accuracy: 1745/2000.0 (87.25%)



Epoch 20 train accuracy: 81.11%, valid accuracy 87.25%
-= Testing valid =-
Test set: Average loss: 0.4628,                   Accuracy: 1690/2000.0 (84.50%)



-= Testing valid =-
Test set: Average loss: 0.4606,                   Accuracy: 1696/2000.0 (84.80%)



-= Testing valid =-
Test set: Average loss: 0.4412,                   Accuracy: 1708/2000.0 (85.40%)



-= Testing valid =-
Test set: Average loss: 0.4062,                   Accuracy: 1731/2000.0 (86.55%)



-= Testing valid =-
Test set: Average loss: 0.3067,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.3680,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.4225,                   Accuracy: 1744/2000.0 (87.20%)



-= Testing valid =-
Test set: Average loss: 0.4541,                   Accuracy: 1701/2000.0 (85.05%)



-= Testing valid =-
Test set: Average loss: 0.3636,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.2918,                   Accuracy: 1823/2000.0 (91.15%)



Epoch 30 train accuracy: 86.43%, valid accuracy 91.15%
-= Testing valid =-
Test set: Average loss: 0.3347,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.3865,                   Accuracy: 1760/2000.0 (88.00%)



-= Testing valid =-
Test set: Average loss: 0.3388,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.3167,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.3388,                   Accuracy: 1780/2000.0 (89.00%)



-= Testing valid =-
Test set: Average loss: 0.2876,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.3074,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.2638,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.3439,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.3701,                   Accuracy: 1772/2000.0 (88.60%)



Epoch 40 train accuracy: 87.82%, valid accuracy 88.60%
-= Testing valid =-
Test set: Average loss: 0.3591,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.3738,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.3132,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.3011,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.3169,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.3159,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.2684,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2357,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.3409,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.2771,                   Accuracy: 1826/2000.0 (91.30%)



Epoch 50 train accuracy: 88.75%, valid accuracy 91.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2878,                   Accuracy: 54777/60000 (91.29%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3079,                   Accuracy: 54260/60000 (90.43%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3170,                   Accuracy: 54107/60000 (90.18%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3289,                   Accuracy: 53801/60000 (89.67%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3402,                   Accuracy: 53597/60000 (89.33%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3541,                   Accuracy: 53449/60000 (89.08%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3637,                   Accuracy: 53166/60000 (88.61%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3718,                   Accuracy: 53063/60000 (88.44%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3868,                   Accuracy: 52650/60000 (87.75%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3691,                   Accuracy: 53076/60000 (88.46%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3952,                   Accuracy: 52441/60000 (87.40%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3791,                   Accuracy: 52836/60000 (88.06%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3860,                   Accuracy: 52773/60000 (87.96%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3934,                   Accuracy: 52430/60000 (87.38%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3905,                   Accuracy: 52476/60000 (87.46%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3926,                   Accuracy: 52166/60000 (86.94%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3832,                   Accuracy: 52358/60000 (87.26%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3643,                   Accuracy: 52883/60000 (88.14%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3523,                   Accuracy: 53278/60000 (88.80%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3444,                   Accuracy: 53508/60000 (89.18%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3425,                   Accuracy: 53562/60000 (89.27%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3314,                   Accuracy: 53914/60000 (89.86%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3349,                   Accuracy: 53899/60000 (89.83%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3335,                   Accuracy: 53950/60000 (89.92%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3248,                   Accuracy: 54335/60000 (90.56%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3331,                   Accuracy: 54181/60000 (90.30%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3381,                   Accuracy: 53919/60000 (89.86%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2995,                   Accuracy: 54753/60000 (91.25%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3215,                   Accuracy: 54071/60000 (90.12%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2972,                   Accuracy: 54675/60000 (91.12%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2930,                   Accuracy: 54869/60000 (91.45%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2868,                   Accuracy: 54973/60000 (91.62%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2836,                   Accuracy: 54938/60000 (91.56%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2824,                   Accuracy: 54950/60000 (91.58%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2789,                   Accuracy: 55009/60000 (91.68%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2752,                   Accuracy: 54927/60000 (91.54%)
{0: tensor(91.2950), 10: tensor(90.4333), 20: tensor(90.1783), 30: tensor(89.6683), 40: tensor(89.3283), 50: tensor(89.0817), 60: tensor(88.6100), 70: tensor(88.4383), 80: tensor(87.7500), 90: tensor(88.4600), 100: tensor(87.4017), 110: tensor(88.0600), 120: tensor(87.9550), 130: tensor(87.3833), 140: tensor(87.4600), 150: tensor(86.9433), 160: tensor(87.2633), 170: tensor(88.1383), 180: tensor(88.7967), 190: tensor(89.1800), 200: tensor(89.2700), 210: tensor(89.8567), 220: tensor(89.8317), 230: tensor(89.9167), 240: tensor(90.5583), 250: tensor(90.3017), 260: tensor(89.8650), 270: tensor(91.2550), 280: tensor(90.1183), 290: tensor(91.1250), 300: tensor(91.4483), 310: tensor(91.6217), 320: tensor(91.5633), 330: tensor(91.5833), 340: tensor(91.6817), 350: tensor(91.5450)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=70, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0628,                   Accuracy: 373/2000.0 (18.65%)



-= Testing valid =-
Test set: Average loss: 1.6129,                   Accuracy: 822/2000.0 (41.10%)



-= Testing valid =-
Test set: Average loss: 1.6443,                   Accuracy: 815/2000.0 (40.75%)



-= Testing valid =-
Test set: Average loss: 1.6049,                   Accuracy: 865/2000.0 (43.25%)



-= Testing valid =-
Test set: Average loss: 2.1773,                   Accuracy: 685/2000.0 (34.25%)



-= Testing valid =-
Test set: Average loss: 1.2652,                   Accuracy: 1128/2000.0 (56.40%)



-= Testing valid =-
Test set: Average loss: 0.8504,                   Accuracy: 1444/2000.0 (72.20%)



-= Testing valid =-
Test set: Average loss: 0.8889,                   Accuracy: 1426/2000.0 (71.30%)



-= Testing valid =-
Test set: Average loss: 0.8254,                   Accuracy: 1461/2000.0 (73.05%)



-= Testing valid =-
Test set: Average loss: 0.8473,                   Accuracy: 1455/2000.0 (72.75%)



Epoch 10 train accuracy: 79.30%, valid accuracy 72.75%
-= Testing valid =-
Test set: Average loss: 0.6406,                   Accuracy: 1576/2000.0 (78.80%)



-= Testing valid =-
Test set: Average loss: 0.6161,                   Accuracy: 1559/2000.0 (77.95%)



-= Testing valid =-
Test set: Average loss: 0.5458,                   Accuracy: 1632/2000.0 (81.60%)



-= Testing valid =-
Test set: Average loss: 0.3673,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3525,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.3481,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.4242,                   Accuracy: 1725/2000.0 (86.25%)



-= Testing valid =-
Test set: Average loss: 0.5386,                   Accuracy: 1634/2000.0 (81.70%)



-= Testing valid =-
Test set: Average loss: 0.2598,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.3028,                   Accuracy: 1821/2000.0 (91.05%)



Epoch 20 train accuracy: 88.39%, valid accuracy 91.05%
-= Testing valid =-
Test set: Average loss: 0.2863,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.3756,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 0.2915,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.2812,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.2809,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.3305,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.2075,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.2650,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.3365,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.2401,                   Accuracy: 1851/2000.0 (92.55%)



Epoch 30 train accuracy: 90.45%, valid accuracy 92.55%
-= Testing valid =-
Test set: Average loss: 0.2523,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2491,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2556,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2651,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.3236,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.2282,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2255,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2063,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.2002,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.2146,                   Accuracy: 1871/2000.0 (93.55%)



Epoch 40 train accuracy: 91.86%, valid accuracy 93.55%
-= Testing valid =-
Test set: Average loss: 0.2043,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.2297,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.2044,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.2479,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2390,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2988,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.2809,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.2351,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2379,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2089,                   Accuracy: 1871/2000.0 (93.55%)



Epoch 50 train accuracy: 92.26%, valid accuracy 93.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2128,                   Accuracy: 56173/60000 (93.62%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2290,                   Accuracy: 55879/60000 (93.13%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2260,                   Accuracy: 56012/60000 (93.35%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2359,                   Accuracy: 55843/60000 (93.07%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2369,                   Accuracy: 55806/60000 (93.01%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2401,                   Accuracy: 55755/60000 (92.93%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2489,                   Accuracy: 55521/60000 (92.54%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2558,                   Accuracy: 55376/60000 (92.29%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2540,                   Accuracy: 55348/60000 (92.25%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2706,                   Accuracy: 55030/60000 (91.72%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2912,                   Accuracy: 54490/60000 (90.82%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2970,                   Accuracy: 54590/60000 (90.98%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.2989,                   Accuracy: 54630/60000 (91.05%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.2995,                   Accuracy: 54558/60000 (90.93%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.2984,                   Accuracy: 54559/60000 (90.93%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.2959,                   Accuracy: 54578/60000 (90.96%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3021,                   Accuracy: 54214/60000 (90.36%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3076,                   Accuracy: 54064/60000 (90.11%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.2996,                   Accuracy: 54190/60000 (90.32%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3257,                   Accuracy: 53820/60000 (89.70%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3142,                   Accuracy: 53901/60000 (89.83%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3047,                   Accuracy: 54185/60000 (90.31%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.2961,                   Accuracy: 54363/60000 (90.61%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.2905,                   Accuracy: 54443/60000 (90.74%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.2854,                   Accuracy: 54631/60000 (91.05%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2900,                   Accuracy: 54528/60000 (90.88%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2813,                   Accuracy: 54618/60000 (91.03%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2686,                   Accuracy: 54964/60000 (91.61%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2733,                   Accuracy: 54895/60000 (91.49%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2704,                   Accuracy: 54982/60000 (91.64%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2684,                   Accuracy: 55058/60000 (91.76%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2603,                   Accuracy: 55258/60000 (92.10%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2461,                   Accuracy: 55540/60000 (92.57%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2345,                   Accuracy: 55770/60000 (92.95%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2249,                   Accuracy: 56005/60000 (93.34%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2181,                   Accuracy: 56043/60000 (93.40%)
{0: tensor(93.6217), 10: tensor(93.1317), 20: tensor(93.3533), 30: tensor(93.0717), 40: tensor(93.0100), 50: tensor(92.9250), 60: tensor(92.5350), 70: tensor(92.2933), 80: tensor(92.2467), 90: tensor(91.7167), 100: tensor(90.8167), 110: tensor(90.9833), 120: tensor(91.0500), 130: tensor(90.9300), 140: tensor(90.9317), 150: tensor(90.9633), 160: tensor(90.3567), 170: tensor(90.1067), 180: tensor(90.3167), 190: tensor(89.7000), 200: tensor(89.8350), 210: tensor(90.3083), 220: tensor(90.6050), 230: tensor(90.7383), 240: tensor(91.0517), 250: tensor(90.8800), 260: tensor(91.0300), 270: tensor(91.6067), 280: tensor(91.4917), 290: tensor(91.6367), 300: tensor(91.7633), 310: tensor(92.0967), 320: tensor(92.5667), 330: tensor(92.9500), 340: tensor(93.3417), 350: tensor(93.4050)}
