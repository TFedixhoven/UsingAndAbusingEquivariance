Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=11, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6427,                   Accuracy: 225/2000.0 (11.25%)



-= Testing valid =-
Test set: Average loss: 4.9841,                   Accuracy: 225/2000.0 (11.25%)



-= Testing valid =-
Test set: Average loss: 1.4516,                   Accuracy: 976/2000.0 (48.80%)



-= Testing valid =-
Test set: Average loss: 1.9114,                   Accuracy: 832/2000.0 (41.60%)



-= Testing valid =-
Test set: Average loss: 1.0236,                   Accuracy: 1326/2000.0 (66.30%)



-= Testing valid =-
Test set: Average loss: 0.5616,                   Accuracy: 1633/2000.0 (81.65%)



-= Testing valid =-
Test set: Average loss: 0.4157,                   Accuracy: 1740/2000.0 (87.00%)



-= Testing valid =-
Test set: Average loss: 0.2349,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.1805,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.3704,                   Accuracy: 1733/2000.0 (86.65%)



Epoch 10 train accuracy: 93.35%, valid accuracy 86.65%
-= Testing valid =-
Test set: Average loss: 0.1720,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1482,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1127,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.2141,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1149,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1250,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1320,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1309,                   Accuracy: 1910/2000.0 (95.50%)



Epoch 20 train accuracy: 95.69%, valid accuracy 95.50%
-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0981,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 30 train accuracy: 96.65%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0734,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 40 train accuracy: 97.29%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0734,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 50 train accuracy: 97.41%, valid accuracy 97.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1060,                   Accuracy: 58145/60000 (96.91%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1210,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1138,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1209,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1207,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1176,                   Accuracy: 57925/60000 (96.54%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1138,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1096,                   Accuracy: 58083/60000 (96.81%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1079,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1060,                   Accuracy: 58145/60000 (96.91%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1210,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1138,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1209,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1207,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1176,                   Accuracy: 57925/60000 (96.54%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1138,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1096,                   Accuracy: 58083/60000 (96.81%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1079,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1060,                   Accuracy: 58145/60000 (96.91%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1210,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1138,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1209,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1207,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1176,                   Accuracy: 57925/60000 (96.54%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1138,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1096,                   Accuracy: 58083/60000 (96.81%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1079,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1060,                   Accuracy: 58145/60000 (96.91%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1210,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1138,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1209,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1207,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1176,                   Accuracy: 57925/60000 (96.54%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1138,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1096,                   Accuracy: 58083/60000 (96.81%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1079,                   Accuracy: 58097/60000 (96.83%)
{0: tensor(96.9083), 10: tensor(96.3650), 20: tensor(96.6417), 30: tensor(96.4633), 40: tensor(96.4433), 50: tensor(96.5417), 60: tensor(96.6600), 70: tensor(96.8050), 80: tensor(96.8283), 90: tensor(96.9083), 100: tensor(96.3650), 110: tensor(96.6417), 120: tensor(96.4633), 130: tensor(96.4433), 140: tensor(96.5417), 150: tensor(96.6600), 160: tensor(96.8050), 170: tensor(96.8283), 180: tensor(96.9083), 190: tensor(96.3650), 200: tensor(96.6417), 210: tensor(96.4633), 220: tensor(96.4433), 230: tensor(96.5417), 240: tensor(96.6600), 250: tensor(96.8050), 260: tensor(96.8283), 270: tensor(96.9083), 280: tensor(96.3650), 290: tensor(96.6417), 300: tensor(96.4633), 310: tensor(96.4433), 320: tensor(96.5417), 330: tensor(96.6600), 340: tensor(96.8050), 350: tensor(96.8283)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=12, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8503,                   Accuracy: 476/2000.0 (23.80%)



-= Testing valid =-
Test set: Average loss: 1.5426,                   Accuracy: 815/2000.0 (40.75%)



-= Testing valid =-
Test set: Average loss: 0.8517,                   Accuracy: 1438/2000.0 (71.90%)



-= Testing valid =-
Test set: Average loss: 0.4002,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.3714,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.6759,                   Accuracy: 1567/2000.0 (78.35%)



-= Testing valid =-
Test set: Average loss: 0.3078,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.3274,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.1750,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1588,                   Accuracy: 1908/2000.0 (95.40%)



Epoch 10 train accuracy: 94.18%, valid accuracy 95.40%
-= Testing valid =-
Test set: Average loss: 0.1285,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1176,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1165,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0978,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1150,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 20 train accuracy: 96.22%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 30 train accuracy: 96.89%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0775,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 40 train accuracy: 97.05%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0718,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0710,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0710,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 50 train accuracy: 97.46%, valid accuracy 97.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0959,                   Accuracy: 58279/60000 (97.13%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1090,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1140,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1182,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1188,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1181,                   Accuracy: 57901/60000 (96.50%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1100,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1057,                   Accuracy: 58101/60000 (96.83%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.0989,                   Accuracy: 58197/60000 (97.00%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0959,                   Accuracy: 58279/60000 (97.13%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1090,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1140,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1182,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1188,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1181,                   Accuracy: 57901/60000 (96.50%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1100,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1057,                   Accuracy: 58101/60000 (96.83%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.0989,                   Accuracy: 58197/60000 (97.00%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0959,                   Accuracy: 58279/60000 (97.13%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1090,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1140,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1182,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1188,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1181,                   Accuracy: 57901/60000 (96.50%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1100,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1057,                   Accuracy: 58101/60000 (96.83%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.0989,                   Accuracy: 58197/60000 (97.00%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0959,                   Accuracy: 58279/60000 (97.13%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1090,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1140,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1182,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1188,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1181,                   Accuracy: 57901/60000 (96.50%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1100,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1057,                   Accuracy: 58101/60000 (96.83%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0989,                   Accuracy: 58197/60000 (97.00%)
{0: tensor(97.1317), 10: tensor(96.7267), 20: tensor(96.5833), 30: tensor(96.4117), 40: tensor(96.4483), 50: tensor(96.5017), 60: tensor(96.7667), 70: tensor(96.8350), 80: tensor(96.9950), 90: tensor(97.1317), 100: tensor(96.7267), 110: tensor(96.5833), 120: tensor(96.4117), 130: tensor(96.4483), 140: tensor(96.5017), 150: tensor(96.7667), 160: tensor(96.8350), 170: tensor(96.9950), 180: tensor(97.1317), 190: tensor(96.7267), 200: tensor(96.5833), 210: tensor(96.4117), 220: tensor(96.4483), 230: tensor(96.5017), 240: tensor(96.7667), 250: tensor(96.8350), 260: tensor(96.9950), 270: tensor(97.1317), 280: tensor(96.7267), 290: tensor(96.5833), 300: tensor(96.4117), 310: tensor(96.4483), 320: tensor(96.5017), 330: tensor(96.7667), 340: tensor(96.8350), 350: tensor(96.9950)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=13, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6567,                   Accuracy: 375/2000.0 (18.75%)



-= Testing valid =-
Test set: Average loss: 2.3163,                   Accuracy: 421/2000.0 (21.05%)



-= Testing valid =-
Test set: Average loss: 1.8386,                   Accuracy: 548/2000.0 (27.40%)



-= Testing valid =-
Test set: Average loss: 1.4456,                   Accuracy: 1041/2000.0 (52.05%)



-= Testing valid =-
Test set: Average loss: 0.7682,                   Accuracy: 1431/2000.0 (71.55%)



-= Testing valid =-
Test set: Average loss: 1.0488,                   Accuracy: 1270/2000.0 (63.50%)



-= Testing valid =-
Test set: Average loss: 0.2248,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.4643,                   Accuracy: 1682/2000.0 (84.10%)



-= Testing valid =-
Test set: Average loss: 0.1614,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.2280,                   Accuracy: 1859/2000.0 (92.95%)



Epoch 10 train accuracy: 93.14%, valid accuracy 92.95%
-= Testing valid =-
Test set: Average loss: 0.1599,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1439,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1564,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1334,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1532,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1170,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1160,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1099,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1208,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 20 train accuracy: 95.34%, valid accuracy 96.45%
-= Testing valid =-
Test set: Average loss: 0.1147,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1146,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1061,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1059,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 30 train accuracy: 96.53%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 40 train accuracy: 97.00%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 50 train accuracy: 97.21%, valid accuracy 97.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1125,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1121,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1082,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1093,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1092,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1133,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1125,                   Accuracy: 57955/60000 (96.59%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1131,                   Accuracy: 57978/60000 (96.63%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1128,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1125,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1121,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1082,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1093,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1092,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1133,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1125,                   Accuracy: 57955/60000 (96.59%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1131,                   Accuracy: 57978/60000 (96.63%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1128,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1125,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1121,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1082,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1093,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1092,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1133,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1125,                   Accuracy: 57955/60000 (96.59%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1131,                   Accuracy: 57978/60000 (96.63%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1128,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1125,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1121,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1082,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1093,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1092,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1133,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1125,                   Accuracy: 57955/60000 (96.59%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1131,                   Accuracy: 57978/60000 (96.63%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1128,                   Accuracy: 57988/60000 (96.65%)
{0: tensor(96.6467), 10: tensor(96.5550), 20: tensor(96.6933), 30: tensor(96.7283), 40: tensor(96.7583), 50: tensor(96.5867), 60: tensor(96.5917), 70: tensor(96.6300), 80: tensor(96.6467), 90: tensor(96.6467), 100: tensor(96.5550), 110: tensor(96.6933), 120: tensor(96.7283), 130: tensor(96.7583), 140: tensor(96.5867), 150: tensor(96.5917), 160: tensor(96.6300), 170: tensor(96.6467), 180: tensor(96.6467), 190: tensor(96.5550), 200: tensor(96.6933), 210: tensor(96.7283), 220: tensor(96.7583), 230: tensor(96.5867), 240: tensor(96.5917), 250: tensor(96.6300), 260: tensor(96.6467), 270: tensor(96.6467), 280: tensor(96.5550), 290: tensor(96.6933), 300: tensor(96.7283), 310: tensor(96.7583), 320: tensor(96.5867), 330: tensor(96.5917), 340: tensor(96.6300), 350: tensor(96.6467)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=14, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.9144,                   Accuracy: 232/2000.0 (11.60%)



-= Testing valid =-
Test set: Average loss: 1.8781,                   Accuracy: 571/2000.0 (28.55%)



-= Testing valid =-
Test set: Average loss: 0.9907,                   Accuracy: 1401/2000.0 (70.05%)



-= Testing valid =-
Test set: Average loss: 0.4816,                   Accuracy: 1748/2000.0 (87.40%)



-= Testing valid =-
Test set: Average loss: 0.3495,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.2771,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2940,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.2090,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.2255,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.1808,                   Accuracy: 1888/2000.0 (94.40%)



Epoch 10 train accuracy: 93.40%, valid accuracy 94.40%
-= Testing valid =-
Test set: Average loss: 0.1962,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1511,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1416,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1312,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1728,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1442,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1227,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1184,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1345,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1274,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 20 train accuracy: 95.90%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.1079,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1077,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1100,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0926,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1182,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1159,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 30 train accuracy: 96.53%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 40 train accuracy: 97.10%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0790,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 50 train accuracy: 97.03%, valid accuracy 97.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1101,                   Accuracy: 58099/60000 (96.83%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1265,                   Accuracy: 57708/60000 (96.18%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1210,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1226,                   Accuracy: 57822/60000 (96.37%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1253,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1247,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1197,                   Accuracy: 57949/60000 (96.58%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1198,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1148,                   Accuracy: 57979/60000 (96.63%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1101,                   Accuracy: 58099/60000 (96.83%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1265,                   Accuracy: 57708/60000 (96.18%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1210,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1226,                   Accuracy: 57822/60000 (96.37%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1253,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1247,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1197,                   Accuracy: 57949/60000 (96.58%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1198,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1148,                   Accuracy: 57979/60000 (96.63%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1101,                   Accuracy: 58099/60000 (96.83%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1265,                   Accuracy: 57708/60000 (96.18%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1210,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1226,                   Accuracy: 57822/60000 (96.37%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1253,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1247,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1197,                   Accuracy: 57949/60000 (96.58%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1198,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1148,                   Accuracy: 57979/60000 (96.63%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1101,                   Accuracy: 58099/60000 (96.83%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1265,                   Accuracy: 57708/60000 (96.18%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1210,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1226,                   Accuracy: 57822/60000 (96.37%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1253,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1247,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1197,                   Accuracy: 57949/60000 (96.58%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1198,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1148,                   Accuracy: 57979/60000 (96.63%)
{0: tensor(96.8317), 10: tensor(96.1800), 20: tensor(96.4167), 30: tensor(96.3700), 40: tensor(96.4183), 50: tensor(96.4433), 60: tensor(96.5817), 70: tensor(96.5250), 80: tensor(96.6317), 90: tensor(96.8317), 100: tensor(96.1800), 110: tensor(96.4167), 120: tensor(96.3700), 130: tensor(96.4183), 140: tensor(96.4433), 150: tensor(96.5817), 160: tensor(96.5250), 170: tensor(96.6317), 180: tensor(96.8317), 190: tensor(96.1800), 200: tensor(96.4167), 210: tensor(96.3700), 220: tensor(96.4183), 230: tensor(96.4433), 240: tensor(96.5817), 250: tensor(96.5250), 260: tensor(96.6317), 270: tensor(96.8317), 280: tensor(96.1800), 290: tensor(96.4167), 300: tensor(96.3700), 310: tensor(96.4183), 320: tensor(96.4433), 330: tensor(96.5817), 340: tensor(96.5250), 350: tensor(96.6317)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=15, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.5970,                   Accuracy: 229/2000.0 (11.45%)



-= Testing valid =-
Test set: Average loss: 1.3570,                   Accuracy: 1034/2000.0 (51.70%)



-= Testing valid =-
Test set: Average loss: 0.9968,                   Accuracy: 1360/2000.0 (68.00%)



-= Testing valid =-
Test set: Average loss: 0.4163,                   Accuracy: 1724/2000.0 (86.20%)



-= Testing valid =-
Test set: Average loss: 0.3700,                   Accuracy: 1780/2000.0 (89.00%)



-= Testing valid =-
Test set: Average loss: 0.4087,                   Accuracy: 1724/2000.0 (86.20%)



-= Testing valid =-
Test set: Average loss: 0.2105,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2717,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.2454,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.1595,                   Accuracy: 1908/2000.0 (95.40%)



Epoch 10 train accuracy: 93.93%, valid accuracy 95.40%
-= Testing valid =-
Test set: Average loss: 0.1344,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1431,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1377,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1336,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1072,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1046,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1266,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 20 train accuracy: 95.94%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 30 train accuracy: 96.64%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0719,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0687,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0636,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0619,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 40 train accuracy: 97.11%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0633,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0602,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0603,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 50 train accuracy: 97.25%, valid accuracy 98.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1065,                   Accuracy: 58117/60000 (96.86%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1185,                   Accuracy: 57821/60000 (96.37%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1153,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1211,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1202,                   Accuracy: 57870/60000 (96.45%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1191,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1142,                   Accuracy: 57982/60000 (96.64%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1099,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1115,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1065,                   Accuracy: 58117/60000 (96.86%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1185,                   Accuracy: 57821/60000 (96.37%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1153,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1211,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1202,                   Accuracy: 57870/60000 (96.45%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1191,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1142,                   Accuracy: 57982/60000 (96.64%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1099,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1115,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1065,                   Accuracy: 58117/60000 (96.86%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1185,                   Accuracy: 57821/60000 (96.37%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1153,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1211,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1202,                   Accuracy: 57870/60000 (96.45%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1191,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1142,                   Accuracy: 57982/60000 (96.64%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1099,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1115,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1065,                   Accuracy: 58117/60000 (96.86%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1185,                   Accuracy: 57821/60000 (96.37%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1153,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1211,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1202,                   Accuracy: 57870/60000 (96.45%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1191,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1142,                   Accuracy: 57982/60000 (96.64%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1099,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1115,                   Accuracy: 58046/60000 (96.74%)
{0: tensor(96.8617), 10: tensor(96.3683), 20: tensor(96.5783), 30: tensor(96.3767), 40: tensor(96.4500), 50: tensor(96.4767), 60: tensor(96.6367), 70: tensor(96.7633), 80: tensor(96.7433), 90: tensor(96.8617), 100: tensor(96.3683), 110: tensor(96.5783), 120: tensor(96.3767), 130: tensor(96.4500), 140: tensor(96.4767), 150: tensor(96.6367), 160: tensor(96.7633), 170: tensor(96.7433), 180: tensor(96.8617), 190: tensor(96.3683), 200: tensor(96.5783), 210: tensor(96.3767), 220: tensor(96.4500), 230: tensor(96.4767), 240: tensor(96.6367), 250: tensor(96.7633), 260: tensor(96.7433), 270: tensor(96.8617), 280: tensor(96.3683), 290: tensor(96.5783), 300: tensor(96.3767), 310: tensor(96.4500), 320: tensor(96.4767), 330: tensor(96.6367), 340: tensor(96.7633), 350: tensor(96.7433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=16, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0007,                   Accuracy: 506/2000.0 (25.30%)



-= Testing valid =-
Test set: Average loss: 2.0766,                   Accuracy: 710/2000.0 (35.50%)



-= Testing valid =-
Test set: Average loss: 0.8334,                   Accuracy: 1398/2000.0 (69.90%)



-= Testing valid =-
Test set: Average loss: 1.2207,                   Accuracy: 1154/2000.0 (57.70%)



-= Testing valid =-
Test set: Average loss: 0.5536,                   Accuracy: 1631/2000.0 (81.55%)



-= Testing valid =-
Test set: Average loss: 0.5732,                   Accuracy: 1650/2000.0 (82.50%)



-= Testing valid =-
Test set: Average loss: 0.3366,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.1969,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2681,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2489,                   Accuracy: 1832/2000.0 (91.60%)



Epoch 10 train accuracy: 94.31%, valid accuracy 91.60%
-= Testing valid =-
Test set: Average loss: 0.1785,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.2010,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2179,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1525,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1568,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1057,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1172,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1582,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1051,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1458,                   Accuracy: 1912/2000.0 (95.60%)



Epoch 20 train accuracy: 95.68%, valid accuracy 95.60%
-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1187,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1092,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1499,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0964,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1093,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 30 train accuracy: 97.01%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1293,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1058,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1097,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1191,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 40 train accuracy: 97.28%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 50 train accuracy: 97.60%, valid accuracy 97.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1154,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1265,                   Accuracy: 57713/60000 (96.19%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1264,                   Accuracy: 57731/60000 (96.22%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1266,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1253,                   Accuracy: 57744/60000 (96.24%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1219,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1189,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1166,                   Accuracy: 57892/60000 (96.49%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1129,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1154,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1265,                   Accuracy: 57713/60000 (96.19%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1264,                   Accuracy: 57731/60000 (96.22%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1266,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1253,                   Accuracy: 57744/60000 (96.24%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1219,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1189,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1166,                   Accuracy: 57892/60000 (96.49%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1129,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1154,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1265,                   Accuracy: 57713/60000 (96.19%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1264,                   Accuracy: 57731/60000 (96.22%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1266,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1253,                   Accuracy: 57744/60000 (96.24%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1219,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1189,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1166,                   Accuracy: 57892/60000 (96.49%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1129,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1154,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1265,                   Accuracy: 57713/60000 (96.19%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1264,                   Accuracy: 57731/60000 (96.22%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1266,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1253,                   Accuracy: 57744/60000 (96.24%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1219,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1189,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1166,                   Accuracy: 57892/60000 (96.49%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1129,                   Accuracy: 57998/60000 (96.66%)
{0: tensor(96.6583), 10: tensor(96.1883), 20: tensor(96.2183), 30: tensor(96.2600), 40: tensor(96.2400), 50: tensor(96.4117), 60: tensor(96.4783), 70: tensor(96.4867), 80: tensor(96.6633), 90: tensor(96.6583), 100: tensor(96.1883), 110: tensor(96.2183), 120: tensor(96.2600), 130: tensor(96.2400), 140: tensor(96.4117), 150: tensor(96.4783), 160: tensor(96.4867), 170: tensor(96.6633), 180: tensor(96.6583), 190: tensor(96.1883), 200: tensor(96.2183), 210: tensor(96.2600), 220: tensor(96.2400), 230: tensor(96.4117), 240: tensor(96.4783), 250: tensor(96.4867), 260: tensor(96.6633), 270: tensor(96.6583), 280: tensor(96.1883), 290: tensor(96.2183), 300: tensor(96.2600), 310: tensor(96.2400), 320: tensor(96.4117), 330: tensor(96.4783), 340: tensor(96.4867), 350: tensor(96.6633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=17, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4724,                   Accuracy: 466/2000.0 (23.30%)



-= Testing valid =-
Test set: Average loss: 7.9204,                   Accuracy: 188/2000.0 (9.40%)



-= Testing valid =-
Test set: Average loss: 1.8588,                   Accuracy: 802/2000.0 (40.10%)



-= Testing valid =-
Test set: Average loss: 1.7757,                   Accuracy: 1013/2000.0 (50.65%)



-= Testing valid =-
Test set: Average loss: 6.3809,                   Accuracy: 439/2000.0 (21.95%)



-= Testing valid =-
Test set: Average loss: 0.9485,                   Accuracy: 1459/2000.0 (72.95%)



-= Testing valid =-
Test set: Average loss: 0.7780,                   Accuracy: 1474/2000.0 (73.70%)



-= Testing valid =-
Test set: Average loss: 0.3365,                   Accuracy: 1764/2000.0 (88.20%)



-= Testing valid =-
Test set: Average loss: 0.4319,                   Accuracy: 1697/2000.0 (84.85%)



-= Testing valid =-
Test set: Average loss: 0.2302,                   Accuracy: 1850/2000.0 (92.50%)



Epoch 10 train accuracy: 93.38%, valid accuracy 92.50%
-= Testing valid =-
Test set: Average loss: 0.1941,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.2931,                   Accuracy: 1780/2000.0 (89.00%)



-= Testing valid =-
Test set: Average loss: 0.2028,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.1294,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1656,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1692,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1392,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1117,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1330,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1239,                   Accuracy: 1919/2000.0 (95.95%)



Epoch 20 train accuracy: 95.69%, valid accuracy 95.95%
-= Testing valid =-
Test set: Average loss: 0.1210,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1057,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1074,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 30 train accuracy: 96.30%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0877,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 40 train accuracy: 97.09%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 50 train accuracy: 97.34%, valid accuracy 97.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1092,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1275,                   Accuracy: 57765/60000 (96.28%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1233,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1246,                   Accuracy: 57914/60000 (96.52%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1265,                   Accuracy: 57844/60000 (96.41%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1231,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1181,                   Accuracy: 58002/60000 (96.67%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1175,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1176,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1092,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1275,                   Accuracy: 57765/60000 (96.28%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1233,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1246,                   Accuracy: 57914/60000 (96.52%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1265,                   Accuracy: 57844/60000 (96.41%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1231,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1181,                   Accuracy: 58002/60000 (96.67%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1175,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1176,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1092,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1275,                   Accuracy: 57765/60000 (96.28%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1233,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1246,                   Accuracy: 57914/60000 (96.52%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1265,                   Accuracy: 57844/60000 (96.41%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1231,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1181,                   Accuracy: 58002/60000 (96.67%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1175,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1176,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1092,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1275,                   Accuracy: 57765/60000 (96.28%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1233,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1246,                   Accuracy: 57914/60000 (96.52%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1265,                   Accuracy: 57844/60000 (96.41%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1231,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1181,                   Accuracy: 58002/60000 (96.67%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1175,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1176,                   Accuracy: 57963/60000 (96.61%)
{0: tensor(96.8917), 10: tensor(96.2750), 20: tensor(96.4467), 30: tensor(96.5233), 40: tensor(96.4067), 50: tensor(96.5283), 60: tensor(96.6700), 70: tensor(96.6967), 80: tensor(96.6050), 90: tensor(96.8917), 100: tensor(96.2750), 110: tensor(96.4467), 120: tensor(96.5233), 130: tensor(96.4067), 140: tensor(96.5283), 150: tensor(96.6700), 160: tensor(96.6967), 170: tensor(96.6050), 180: tensor(96.8917), 190: tensor(96.2750), 200: tensor(96.4467), 210: tensor(96.5233), 220: tensor(96.4067), 230: tensor(96.5283), 240: tensor(96.6700), 250: tensor(96.6967), 260: tensor(96.6050), 270: tensor(96.8917), 280: tensor(96.2750), 290: tensor(96.4467), 300: tensor(96.5233), 310: tensor(96.4067), 320: tensor(96.5283), 330: tensor(96.6700), 340: tensor(96.6967), 350: tensor(96.6050)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=18, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5425,                   Accuracy: 217/2000.0 (10.85%)



-= Testing valid =-
Test set: Average loss: 1.4647,                   Accuracy: 939/2000.0 (46.95%)



-= Testing valid =-
Test set: Average loss: 1.0350,                   Accuracy: 1379/2000.0 (68.95%)



-= Testing valid =-
Test set: Average loss: 1.1117,                   Accuracy: 1112/2000.0 (55.60%)



-= Testing valid =-
Test set: Average loss: 0.6599,                   Accuracy: 1530/2000.0 (76.50%)



-= Testing valid =-
Test set: Average loss: 0.6352,                   Accuracy: 1597/2000.0 (79.85%)



-= Testing valid =-
Test set: Average loss: 0.3269,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.2857,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2542,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.1977,                   Accuracy: 1879/2000.0 (93.95%)



Epoch 10 train accuracy: 93.79%, valid accuracy 93.95%
-= Testing valid =-
Test set: Average loss: 0.1726,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1485,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1296,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1508,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1405,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1628,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1307,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1285,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1165,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1761,                   Accuracy: 1889/2000.0 (94.45%)



Epoch 20 train accuracy: 95.91%, valid accuracy 94.45%
-= Testing valid =-
Test set: Average loss: 0.1253,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1104,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1137,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1017,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1079,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 30 train accuracy: 96.91%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 40 train accuracy: 97.20%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 50 train accuracy: 97.32%, valid accuracy 97.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0950,                   Accuracy: 58310/60000 (97.18%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1077,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1054,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1037,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1028,                   Accuracy: 58147/60000 (96.91%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1000,                   Accuracy: 58166/60000 (96.94%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0953,                   Accuracy: 58293/60000 (97.15%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0963,                   Accuracy: 58272/60000 (97.12%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.0952,                   Accuracy: 58253/60000 (97.09%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0950,                   Accuracy: 58310/60000 (97.18%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1077,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1054,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1037,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1028,                   Accuracy: 58147/60000 (96.91%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1000,                   Accuracy: 58166/60000 (96.94%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.0953,                   Accuracy: 58293/60000 (97.15%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.0963,                   Accuracy: 58272/60000 (97.12%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.0952,                   Accuracy: 58253/60000 (97.09%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0950,                   Accuracy: 58310/60000 (97.18%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1077,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1054,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1037,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1028,                   Accuracy: 58147/60000 (96.91%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1000,                   Accuracy: 58166/60000 (96.94%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.0953,                   Accuracy: 58293/60000 (97.15%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.0963,                   Accuracy: 58272/60000 (97.12%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.0952,                   Accuracy: 58253/60000 (97.09%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0950,                   Accuracy: 58310/60000 (97.18%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1077,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1054,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1037,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1028,                   Accuracy: 58147/60000 (96.91%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1000,                   Accuracy: 58166/60000 (96.94%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0953,                   Accuracy: 58293/60000 (97.15%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0963,                   Accuracy: 58272/60000 (97.12%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0952,                   Accuracy: 58253/60000 (97.09%)
{0: tensor(97.1833), 10: tensor(96.7517), 20: tensor(96.8717), 30: tensor(96.9417), 40: tensor(96.9117), 50: tensor(96.9433), 60: tensor(97.1550), 70: tensor(97.1200), 80: tensor(97.0883), 90: tensor(97.1833), 100: tensor(96.7517), 110: tensor(96.8717), 120: tensor(96.9417), 130: tensor(96.9117), 140: tensor(96.9433), 150: tensor(97.1550), 160: tensor(97.1200), 170: tensor(97.0883), 180: tensor(97.1833), 190: tensor(96.7517), 200: tensor(96.8717), 210: tensor(96.9417), 220: tensor(96.9117), 230: tensor(96.9433), 240: tensor(97.1550), 250: tensor(97.1200), 260: tensor(97.0883), 270: tensor(97.1833), 280: tensor(96.7517), 290: tensor(96.8717), 300: tensor(96.9417), 310: tensor(96.9117), 320: tensor(96.9433), 330: tensor(97.1550), 340: tensor(97.1200), 350: tensor(97.0883)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=19, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.4247,                   Accuracy: 267/2000.0 (13.35%)



-= Testing valid =-
Test set: Average loss: 2.5928,                   Accuracy: 420/2000.0 (21.00%)



-= Testing valid =-
Test set: Average loss: 2.2599,                   Accuracy: 654/2000.0 (32.70%)



-= Testing valid =-
Test set: Average loss: 1.0182,                   Accuracy: 1337/2000.0 (66.85%)



-= Testing valid =-
Test set: Average loss: 1.0497,                   Accuracy: 1221/2000.0 (61.05%)



-= Testing valid =-
Test set: Average loss: 0.5184,                   Accuracy: 1670/2000.0 (83.50%)



-= Testing valid =-
Test set: Average loss: 0.3648,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.2988,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.3621,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.2363,                   Accuracy: 1837/2000.0 (91.85%)



Epoch 10 train accuracy: 93.05%, valid accuracy 91.85%
-= Testing valid =-
Test set: Average loss: 0.1493,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1557,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1383,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1606,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1392,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1489,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1218,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1197,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1267,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1502,                   Accuracy: 1902/2000.0 (95.10%)



Epoch 20 train accuracy: 95.84%, valid accuracy 95.10%
-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1050,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1211,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1010,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1053,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 30 train accuracy: 96.45%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1059,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 40 train accuracy: 97.03%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 50 train accuracy: 97.39%, valid accuracy 97.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0986,                   Accuracy: 58272/60000 (97.12%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1169,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1107,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1069,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1127,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1139,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1088,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1078,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1142,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0986,                   Accuracy: 58272/60000 (97.12%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1169,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1107,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1069,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1127,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1139,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1088,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1078,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1142,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0986,                   Accuracy: 58272/60000 (97.12%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1169,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1107,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1069,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1127,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1139,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1088,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1078,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1142,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0986,                   Accuracy: 58272/60000 (97.12%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1169,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1107,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1069,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1127,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1139,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1088,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1078,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1142,                   Accuracy: 57923/60000 (96.54%)
{0: tensor(97.1200), 10: tensor(96.4717), 20: tensor(96.6833), 30: tensor(96.7267), 40: tensor(96.5533), 50: tensor(96.5783), 60: tensor(96.7283), 70: tensor(96.7833), 80: tensor(96.5383), 90: tensor(97.1200), 100: tensor(96.4717), 110: tensor(96.6833), 120: tensor(96.7267), 130: tensor(96.5533), 140: tensor(96.5783), 150: tensor(96.7283), 160: tensor(96.7833), 170: tensor(96.5383), 180: tensor(97.1200), 190: tensor(96.4717), 200: tensor(96.6833), 210: tensor(96.7267), 220: tensor(96.5533), 230: tensor(96.5783), 240: tensor(96.7283), 250: tensor(96.7833), 260: tensor(96.5383), 270: tensor(97.1200), 280: tensor(96.4717), 290: tensor(96.6833), 300: tensor(96.7267), 310: tensor(96.5533), 320: tensor(96.5783), 330: tensor(96.7283), 340: tensor(96.7833), 350: tensor(96.5383)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=20, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.8110,                   Accuracy: 222/2000.0 (11.10%)



-= Testing valid =-
Test set: Average loss: 2.4050,                   Accuracy: 517/2000.0 (25.85%)



-= Testing valid =-
Test set: Average loss: 1.1354,                   Accuracy: 1127/2000.0 (56.35%)



-= Testing valid =-
Test set: Average loss: 0.7410,                   Accuracy: 1521/2000.0 (76.05%)



-= Testing valid =-
Test set: Average loss: 0.2790,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.3110,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.2956,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.2587,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.1982,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1723,                   Accuracy: 1887/2000.0 (94.35%)



Epoch 10 train accuracy: 93.72%, valid accuracy 94.35%
-= Testing valid =-
Test set: Average loss: 0.1430,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1242,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1304,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1146,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1229,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1222,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1036,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1082,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1177,                   Accuracy: 1922/2000.0 (96.10%)



Epoch 20 train accuracy: 96.16%, valid accuracy 96.10%
-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0981,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0910,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 30 train accuracy: 96.71%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 40 train accuracy: 96.96%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 50 train accuracy: 97.36%, valid accuracy 97.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0974,                   Accuracy: 58264/60000 (97.11%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1057,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1044,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1103,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1121,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1142,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1142,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1100,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1036,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0974,                   Accuracy: 58264/60000 (97.11%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1057,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1044,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1103,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1121,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1142,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1142,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1100,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1036,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0974,                   Accuracy: 58264/60000 (97.11%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1057,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1044,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1103,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1121,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1142,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1142,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1100,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1036,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0974,                   Accuracy: 58264/60000 (97.11%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1057,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1044,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1103,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1121,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1142,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1142,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1100,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1036,                   Accuracy: 58125/60000 (96.88%)
{0: tensor(97.1067), 10: tensor(96.8017), 20: tensor(96.8750), 30: tensor(96.7333), 40: tensor(96.7300), 50: tensor(96.6517), 60: tensor(96.6117), 70: tensor(96.6900), 80: tensor(96.8750), 90: tensor(97.1067), 100: tensor(96.8017), 110: tensor(96.8750), 120: tensor(96.7333), 130: tensor(96.7300), 140: tensor(96.6517), 150: tensor(96.6117), 160: tensor(96.6900), 170: tensor(96.8750), 180: tensor(97.1067), 190: tensor(96.8017), 200: tensor(96.8750), 210: tensor(96.7333), 220: tensor(96.7300), 230: tensor(96.6517), 240: tensor(96.6117), 250: tensor(96.6900), 260: tensor(96.8750), 270: tensor(97.1067), 280: tensor(96.8017), 290: tensor(96.8750), 300: tensor(96.7333), 310: tensor(96.7300), 320: tensor(96.6517), 330: tensor(96.6117), 340: tensor(96.6900), 350: tensor(96.8750)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=21, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.8661,                   Accuracy: 232/2000.0 (11.60%)



-= Testing valid =-
Test set: Average loss: 3.0663,                   Accuracy: 424/2000.0 (21.20%)



-= Testing valid =-
Test set: Average loss: 3.0448,                   Accuracy: 603/2000.0 (30.15%)



-= Testing valid =-
Test set: Average loss: 1.1716,                   Accuracy: 1179/2000.0 (58.95%)



-= Testing valid =-
Test set: Average loss: 1.7603,                   Accuracy: 845/2000.0 (42.25%)



-= Testing valid =-
Test set: Average loss: 0.5937,                   Accuracy: 1606/2000.0 (80.30%)



-= Testing valid =-
Test set: Average loss: 0.5835,                   Accuracy: 1607/2000.0 (80.35%)



-= Testing valid =-
Test set: Average loss: 0.3422,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.2123,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.3417,                   Accuracy: 1777/2000.0 (88.85%)



Epoch 10 train accuracy: 92.45%, valid accuracy 88.85%
-= Testing valid =-
Test set: Average loss: 0.2179,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1635,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1662,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1823,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.1303,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1403,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1473,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1604,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1302,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.2359,                   Accuracy: 1821/2000.0 (91.05%)



Epoch 20 train accuracy: 95.34%, valid accuracy 91.05%
-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1149,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 30 train accuracy: 96.36%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 40 train accuracy: 96.69%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0711,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0677,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0658,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 50 train accuracy: 97.00%, valid accuracy 97.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1025,                   Accuracy: 58199/60000 (97.00%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1034,                   Accuracy: 58111/60000 (96.85%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1026,                   Accuracy: 58154/60000 (96.92%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1085,                   Accuracy: 58033/60000 (96.72%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1153,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1186,                   Accuracy: 57873/60000 (96.46%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1191,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1152,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1089,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1025,                   Accuracy: 58199/60000 (97.00%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1034,                   Accuracy: 58111/60000 (96.85%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1026,                   Accuracy: 58154/60000 (96.92%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1085,                   Accuracy: 58033/60000 (96.72%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1153,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1186,                   Accuracy: 57873/60000 (96.46%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1191,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1152,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1089,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1025,                   Accuracy: 58199/60000 (97.00%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1034,                   Accuracy: 58111/60000 (96.85%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1026,                   Accuracy: 58154/60000 (96.92%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1085,                   Accuracy: 58033/60000 (96.72%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1153,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1186,                   Accuracy: 57873/60000 (96.46%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1191,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1152,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1089,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1025,                   Accuracy: 58199/60000 (97.00%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1034,                   Accuracy: 58111/60000 (96.85%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1026,                   Accuracy: 58154/60000 (96.92%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1085,                   Accuracy: 58033/60000 (96.72%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1153,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1186,                   Accuracy: 57873/60000 (96.46%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1191,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1152,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1089,                   Accuracy: 58071/60000 (96.79%)
{0: tensor(96.9983), 10: tensor(96.8517), 20: tensor(96.9233), 30: tensor(96.7217), 40: tensor(96.5600), 50: tensor(96.4550), 60: tensor(96.4583), 70: tensor(96.5533), 80: tensor(96.7850), 90: tensor(96.9983), 100: tensor(96.8517), 110: tensor(96.9233), 120: tensor(96.7217), 130: tensor(96.5600), 140: tensor(96.4550), 150: tensor(96.4583), 160: tensor(96.5533), 170: tensor(96.7850), 180: tensor(96.9983), 190: tensor(96.8517), 200: tensor(96.9233), 210: tensor(96.7217), 220: tensor(96.5600), 230: tensor(96.4550), 240: tensor(96.4583), 250: tensor(96.5533), 260: tensor(96.7850), 270: tensor(96.9983), 280: tensor(96.8517), 290: tensor(96.9233), 300: tensor(96.7217), 310: tensor(96.5600), 320: tensor(96.4550), 330: tensor(96.4583), 340: tensor(96.5533), 350: tensor(96.7850)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=22, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.2314,                   Accuracy: 245/2000.0 (12.25%)



-= Testing valid =-
Test set: Average loss: 2.7275,                   Accuracy: 370/2000.0 (18.50%)



-= Testing valid =-
Test set: Average loss: 1.0677,                   Accuracy: 1300/2000.0 (65.00%)



-= Testing valid =-
Test set: Average loss: 1.1476,                   Accuracy: 1191/2000.0 (59.55%)



-= Testing valid =-
Test set: Average loss: 0.4279,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.3052,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.4122,                   Accuracy: 1705/2000.0 (85.25%)



-= Testing valid =-
Test set: Average loss: 0.3621,                   Accuracy: 1760/2000.0 (88.00%)



-= Testing valid =-
Test set: Average loss: 0.1783,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.3314,                   Accuracy: 1799/2000.0 (89.95%)



Epoch 10 train accuracy: 92.38%, valid accuracy 89.95%
-= Testing valid =-
Test set: Average loss: 0.1729,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1603,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1432,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.2323,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.1227,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1259,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1363,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1034,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1286,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1080,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 20 train accuracy: 95.41%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1100,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1091,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1234,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1130,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 30 train accuracy: 96.60%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 40 train accuracy: 96.69%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0775,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 50 train accuracy: 97.01%, valid accuracy 97.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1057,                   Accuracy: 58115/60000 (96.86%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1195,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1144,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1157,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1137,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1140,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1109,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1098,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1100,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1057,                   Accuracy: 58115/60000 (96.86%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1195,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1144,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1157,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1137,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1140,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1109,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1098,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1100,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1057,                   Accuracy: 58115/60000 (96.86%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1195,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1144,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1157,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1137,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1140,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1109,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1098,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1100,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1057,                   Accuracy: 58115/60000 (96.86%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1195,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1144,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1157,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1137,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1140,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1109,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1098,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1100,                   Accuracy: 58043/60000 (96.74%)
{0: tensor(96.8583), 10: tensor(96.4600), 20: tensor(96.6817), 30: tensor(96.5700), 40: tensor(96.6733), 50: tensor(96.5883), 60: tensor(96.7167), 70: tensor(96.7533), 80: tensor(96.7383), 90: tensor(96.8583), 100: tensor(96.4600), 110: tensor(96.6817), 120: tensor(96.5700), 130: tensor(96.6733), 140: tensor(96.5883), 150: tensor(96.7167), 160: tensor(96.7533), 170: tensor(96.7383), 180: tensor(96.8583), 190: tensor(96.4600), 200: tensor(96.6817), 210: tensor(96.5700), 220: tensor(96.6733), 230: tensor(96.5883), 240: tensor(96.7167), 250: tensor(96.7533), 260: tensor(96.7383), 270: tensor(96.8583), 280: tensor(96.4600), 290: tensor(96.6817), 300: tensor(96.5700), 310: tensor(96.6733), 320: tensor(96.5883), 330: tensor(96.7167), 340: tensor(96.7533), 350: tensor(96.7383)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=23, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4859,                   Accuracy: 322/2000.0 (16.10%)



-= Testing valid =-
Test set: Average loss: 2.1657,                   Accuracy: 423/2000.0 (21.15%)



-= Testing valid =-
Test set: Average loss: 1.2642,                   Accuracy: 1040/2000.0 (52.00%)



-= Testing valid =-
Test set: Average loss: 1.0679,                   Accuracy: 1169/2000.0 (58.45%)



-= Testing valid =-
Test set: Average loss: 0.7442,                   Accuracy: 1544/2000.0 (77.20%)



-= Testing valid =-
Test set: Average loss: 0.7365,                   Accuracy: 1460/2000.0 (73.00%)



-= Testing valid =-
Test set: Average loss: 0.3877,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.5564,                   Accuracy: 1698/2000.0 (84.90%)



-= Testing valid =-
Test set: Average loss: 0.5533,                   Accuracy: 1642/2000.0 (82.10%)



-= Testing valid =-
Test set: Average loss: 0.1873,                   Accuracy: 1885/2000.0 (94.25%)



Epoch 10 train accuracy: 91.82%, valid accuracy 94.25%
-= Testing valid =-
Test set: Average loss: 0.2742,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.1896,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1728,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1937,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1891,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1979,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1861,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1795,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1399,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1622,                   Accuracy: 1907/2000.0 (95.35%)



Epoch 20 train accuracy: 95.12%, valid accuracy 95.35%
-= Testing valid =-
Test set: Average loss: 0.1333,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1426,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1447,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1433,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1472,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1396,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1282,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1264,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1684,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1315,                   Accuracy: 1923/2000.0 (96.15%)



Epoch 30 train accuracy: 96.16%, valid accuracy 96.15%
-= Testing valid =-
Test set: Average loss: 0.1141,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1229,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1185,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1211,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1126,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1117,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1086,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1229,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1228,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 40 train accuracy: 96.76%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.0986,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1085,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1093,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1059,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1070,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1099,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 50 train accuracy: 96.88%, valid accuracy 96.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1165,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1196,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1140,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1134,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1144,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1147,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1160,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1150,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1188,                   Accuracy: 57928/60000 (96.55%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1165,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1196,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1140,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1134,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1144,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1147,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1160,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1150,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1188,                   Accuracy: 57928/60000 (96.55%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1165,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1196,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1140,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1134,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1144,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1147,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1160,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1150,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1188,                   Accuracy: 57928/60000 (96.55%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1165,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1196,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1140,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1134,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1144,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1147,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1160,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1150,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1188,                   Accuracy: 57928/60000 (96.55%)
{0: tensor(96.5883), 10: tensor(96.4717), 20: tensor(96.6133), 30: tensor(96.6667), 40: tensor(96.6633), 50: tensor(96.6583), 60: tensor(96.6183), 70: tensor(96.6400), 80: tensor(96.5467), 90: tensor(96.5883), 100: tensor(96.4717), 110: tensor(96.6133), 120: tensor(96.6667), 130: tensor(96.6633), 140: tensor(96.6583), 150: tensor(96.6183), 160: tensor(96.6400), 170: tensor(96.5467), 180: tensor(96.5883), 190: tensor(96.4717), 200: tensor(96.6133), 210: tensor(96.6667), 220: tensor(96.6633), 230: tensor(96.6583), 240: tensor(96.6183), 250: tensor(96.6400), 260: tensor(96.5467), 270: tensor(96.5883), 280: tensor(96.4717), 290: tensor(96.6133), 300: tensor(96.6667), 310: tensor(96.6633), 320: tensor(96.6583), 330: tensor(96.6183), 340: tensor(96.6400), 350: tensor(96.5467)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=24, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 7.8210,                   Accuracy: 223/2000.0 (11.15%)



-= Testing valid =-
Test set: Average loss: 2.2330,                   Accuracy: 492/2000.0 (24.60%)



-= Testing valid =-
Test set: Average loss: 1.5961,                   Accuracy: 881/2000.0 (44.05%)



-= Testing valid =-
Test set: Average loss: 0.5731,                   Accuracy: 1650/2000.0 (82.50%)



-= Testing valid =-
Test set: Average loss: 0.3676,                   Accuracy: 1765/2000.0 (88.25%)



-= Testing valid =-
Test set: Average loss: 0.2874,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.3034,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.2843,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.2966,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.2020,                   Accuracy: 1872/2000.0 (93.60%)



Epoch 10 train accuracy: 93.66%, valid accuracy 93.60%
-= Testing valid =-
Test set: Average loss: 0.1370,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1362,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1546,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1136,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1907,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1011,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1052,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1411,                   Accuracy: 1900/2000.0 (95.00%)



Epoch 20 train accuracy: 96.05%, valid accuracy 95.00%
-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 30 train accuracy: 96.57%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0712,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0712,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0636,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 40 train accuracy: 96.99%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0632,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0630,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0629,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0641,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0604,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0605,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 50 train accuracy: 97.32%, valid accuracy 98.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0982,                   Accuracy: 58244/60000 (97.07%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0998,                   Accuracy: 58192/60000 (96.99%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1001,                   Accuracy: 58206/60000 (97.01%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1067,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1097,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1134,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1118,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1046,                   Accuracy: 58178/60000 (96.96%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.0997,                   Accuracy: 58238/60000 (97.06%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0982,                   Accuracy: 58244/60000 (97.07%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.0998,                   Accuracy: 58192/60000 (96.99%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1001,                   Accuracy: 58206/60000 (97.01%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1067,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1097,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1134,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1118,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1046,                   Accuracy: 58178/60000 (96.96%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.0997,                   Accuracy: 58238/60000 (97.06%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0982,                   Accuracy: 58244/60000 (97.07%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.0998,                   Accuracy: 58192/60000 (96.99%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1001,                   Accuracy: 58206/60000 (97.01%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1067,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1097,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1134,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1118,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1046,                   Accuracy: 58178/60000 (96.96%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.0997,                   Accuracy: 58238/60000 (97.06%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0982,                   Accuracy: 58244/60000 (97.07%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.0998,                   Accuracy: 58192/60000 (96.99%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1001,                   Accuracy: 58206/60000 (97.01%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1067,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1097,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1134,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1118,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1046,                   Accuracy: 58178/60000 (96.96%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0997,                   Accuracy: 58238/60000 (97.06%)
{0: tensor(97.0733), 10: tensor(96.9867), 20: tensor(97.0100), 30: tensor(96.8133), 40: tensor(96.6900), 50: tensor(96.7017), 60: tensor(96.6883), 70: tensor(96.9633), 80: tensor(97.0633), 90: tensor(97.0733), 100: tensor(96.9867), 110: tensor(97.0100), 120: tensor(96.8133), 130: tensor(96.6900), 140: tensor(96.7017), 150: tensor(96.6883), 160: tensor(96.9633), 170: tensor(97.0633), 180: tensor(97.0733), 190: tensor(96.9867), 200: tensor(97.0100), 210: tensor(96.8133), 220: tensor(96.6900), 230: tensor(96.7017), 240: tensor(96.6883), 250: tensor(96.9633), 260: tensor(97.0633), 270: tensor(97.0733), 280: tensor(96.9867), 290: tensor(97.0100), 300: tensor(96.8133), 310: tensor(96.6900), 320: tensor(96.7017), 330: tensor(96.6883), 340: tensor(96.9633), 350: tensor(97.0633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=25, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.6884,                   Accuracy: 803/2000.0 (40.15%)



-= Testing valid =-
Test set: Average loss: 1.5993,                   Accuracy: 759/2000.0 (37.95%)



-= Testing valid =-
Test set: Average loss: 1.2406,                   Accuracy: 1115/2000.0 (55.75%)



-= Testing valid =-
Test set: Average loss: 0.6736,                   Accuracy: 1563/2000.0 (78.15%)



-= Testing valid =-
Test set: Average loss: 0.3948,                   Accuracy: 1735/2000.0 (86.75%)



-= Testing valid =-
Test set: Average loss: 0.2912,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.3620,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.2089,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2887,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2584,                   Accuracy: 1850/2000.0 (92.50%)



Epoch 10 train accuracy: 92.43%, valid accuracy 92.50%
-= Testing valid =-
Test set: Average loss: 0.1383,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1518,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1206,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1110,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1140,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1202,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1139,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1397,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1179,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 20 train accuracy: 95.57%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0978,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0926,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0937,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 30 train accuracy: 96.30%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 40 train accuracy: 97.03%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0802,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 50 train accuracy: 97.11%, valid accuracy 98.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1041,                   Accuracy: 58203/60000 (97.00%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1081,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1046,                   Accuracy: 58158/60000 (96.93%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1050,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1070,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1089,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1087,                   Accuracy: 58080/60000 (96.80%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1070,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1057,                   Accuracy: 58185/60000 (96.97%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1041,                   Accuracy: 58203/60000 (97.00%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1081,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1046,                   Accuracy: 58158/60000 (96.93%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1050,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1070,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1089,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1087,                   Accuracy: 58080/60000 (96.80%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1070,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1057,                   Accuracy: 58185/60000 (96.97%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1041,                   Accuracy: 58203/60000 (97.00%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1081,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1046,                   Accuracy: 58158/60000 (96.93%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1050,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1070,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1089,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1087,                   Accuracy: 58080/60000 (96.80%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1070,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1057,                   Accuracy: 58185/60000 (96.97%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1041,                   Accuracy: 58203/60000 (97.00%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1081,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1046,                   Accuracy: 58158/60000 (96.93%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1050,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1070,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1089,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1087,                   Accuracy: 58080/60000 (96.80%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1070,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1057,                   Accuracy: 58185/60000 (96.97%)
{0: tensor(97.0050), 10: tensor(96.8467), 20: tensor(96.9300), 30: tensor(96.9100), 40: tensor(96.8667), 50: tensor(96.7750), 60: tensor(96.8000), 70: tensor(96.8683), 80: tensor(96.9750), 90: tensor(97.0050), 100: tensor(96.8467), 110: tensor(96.9300), 120: tensor(96.9100), 130: tensor(96.8667), 140: tensor(96.7750), 150: tensor(96.8000), 160: tensor(96.8683), 170: tensor(96.9750), 180: tensor(97.0050), 190: tensor(96.8467), 200: tensor(96.9300), 210: tensor(96.9100), 220: tensor(96.8667), 230: tensor(96.7750), 240: tensor(96.8000), 250: tensor(96.8683), 260: tensor(96.9750), 270: tensor(97.0050), 280: tensor(96.8467), 290: tensor(96.9300), 300: tensor(96.9100), 310: tensor(96.8667), 320: tensor(96.7750), 330: tensor(96.8000), 340: tensor(96.8683), 350: tensor(96.9750)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=26, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.9326,                   Accuracy: 212/2000.0 (10.60%)



-= Testing valid =-
Test set: Average loss: 2.8185,                   Accuracy: 270/2000.0 (13.50%)



-= Testing valid =-
Test set: Average loss: 1.6425,                   Accuracy: 873/2000.0 (43.65%)



-= Testing valid =-
Test set: Average loss: 0.8781,                   Accuracy: 1405/2000.0 (70.25%)



-= Testing valid =-
Test set: Average loss: 0.7052,                   Accuracy: 1515/2000.0 (75.75%)



-= Testing valid =-
Test set: Average loss: 0.4228,                   Accuracy: 1768/2000.0 (88.40%)



-= Testing valid =-
Test set: Average loss: 0.3036,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.4019,                   Accuracy: 1759/2000.0 (87.95%)



-= Testing valid =-
Test set: Average loss: 0.2625,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2479,                   Accuracy: 1843/2000.0 (92.15%)



Epoch 10 train accuracy: 93.59%, valid accuracy 92.15%
-= Testing valid =-
Test set: Average loss: 0.1710,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1848,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1663,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1611,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.2167,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.1912,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1602,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1603,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1657,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1374,                   Accuracy: 1903/2000.0 (95.15%)



Epoch 20 train accuracy: 95.81%, valid accuracy 95.15%
-= Testing valid =-
Test set: Average loss: 0.1810,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1360,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1465,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1489,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1510,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1320,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1233,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1412,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1388,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1413,                   Accuracy: 1917/2000.0 (95.85%)



Epoch 30 train accuracy: 96.90%, valid accuracy 95.85%
-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1202,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1209,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1531,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1336,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1317,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1369,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1300,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1297,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 40 train accuracy: 97.11%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.1142,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1134,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1159,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1236,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1102,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1206,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1108,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1184,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1203,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1163,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 50 train accuracy: 97.31%, valid accuracy 96.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1198,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1180,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1178,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1192,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1192,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1182,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1182,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1175,                   Accuracy: 57931/60000 (96.55%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1166,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1198,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1180,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1178,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1192,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1192,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1182,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1182,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1175,                   Accuracy: 57931/60000 (96.55%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1166,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1198,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1180,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1178,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1192,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1192,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1182,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1182,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1175,                   Accuracy: 57931/60000 (96.55%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1166,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1198,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1180,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1178,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1192,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1192,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1182,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1182,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1175,                   Accuracy: 57931/60000 (96.55%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1166,                   Accuracy: 57976/60000 (96.63%)
{0: tensor(96.5800), 10: tensor(96.6067), 20: tensor(96.6017), 30: tensor(96.6450), 40: tensor(96.5933), 50: tensor(96.6217), 60: tensor(96.6150), 70: tensor(96.5517), 80: tensor(96.6267), 90: tensor(96.5800), 100: tensor(96.6067), 110: tensor(96.6017), 120: tensor(96.6450), 130: tensor(96.5933), 140: tensor(96.6217), 150: tensor(96.6150), 160: tensor(96.5517), 170: tensor(96.6267), 180: tensor(96.5800), 190: tensor(96.6067), 200: tensor(96.6017), 210: tensor(96.6450), 220: tensor(96.5933), 230: tensor(96.6217), 240: tensor(96.6150), 250: tensor(96.5517), 260: tensor(96.6267), 270: tensor(96.5800), 280: tensor(96.6067), 290: tensor(96.6017), 300: tensor(96.6450), 310: tensor(96.5933), 320: tensor(96.6217), 330: tensor(96.6150), 340: tensor(96.5517), 350: tensor(96.6267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=27, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 8.4076,                   Accuracy: 337/2000.0 (16.85%)



-= Testing valid =-
Test set: Average loss: 1.9931,                   Accuracy: 527/2000.0 (26.35%)



-= Testing valid =-
Test set: Average loss: 1.0491,                   Accuracy: 1220/2000.0 (61.00%)



-= Testing valid =-
Test set: Average loss: 0.5147,                   Accuracy: 1650/2000.0 (82.50%)



-= Testing valid =-
Test set: Average loss: 0.3507,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.7643,                   Accuracy: 1490/2000.0 (74.50%)



-= Testing valid =-
Test set: Average loss: 0.2610,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.3366,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.2296,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2732,                   Accuracy: 1830/2000.0 (91.50%)



Epoch 10 train accuracy: 93.81%, valid accuracy 91.50%
-= Testing valid =-
Test set: Average loss: 0.1727,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.2456,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.1647,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1364,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1089,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1453,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1458,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1208,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1237,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1250,                   Accuracy: 1916/2000.0 (95.80%)



Epoch 20 train accuracy: 95.54%, valid accuracy 95.80%
-= Testing valid =-
Test set: Average loss: 0.1071,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1122,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1075,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1003,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 30 train accuracy: 96.44%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0926,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 40 train accuracy: 97.10%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0909,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 50 train accuracy: 97.18%, valid accuracy 97.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0992,                   Accuracy: 58272/60000 (97.12%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1084,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1053,                   Accuracy: 58089/60000 (96.82%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1062,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1065,                   Accuracy: 58105/60000 (96.84%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1064,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1030,                   Accuracy: 58140/60000 (96.90%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1015,                   Accuracy: 58177/60000 (96.96%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1015,                   Accuracy: 58198/60000 (97.00%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0992,                   Accuracy: 58272/60000 (97.12%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1084,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1053,                   Accuracy: 58089/60000 (96.82%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1062,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1065,                   Accuracy: 58105/60000 (96.84%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1064,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1030,                   Accuracy: 58140/60000 (96.90%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1015,                   Accuracy: 58177/60000 (96.96%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1015,                   Accuracy: 58198/60000 (97.00%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0992,                   Accuracy: 58272/60000 (97.12%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1084,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1053,                   Accuracy: 58089/60000 (96.82%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1062,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1065,                   Accuracy: 58105/60000 (96.84%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1064,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1030,                   Accuracy: 58140/60000 (96.90%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1015,                   Accuracy: 58177/60000 (96.96%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1015,                   Accuracy: 58198/60000 (97.00%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0992,                   Accuracy: 58272/60000 (97.12%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1084,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1053,                   Accuracy: 58089/60000 (96.82%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1062,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1065,                   Accuracy: 58105/60000 (96.84%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1064,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1030,                   Accuracy: 58140/60000 (96.90%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1015,                   Accuracy: 58177/60000 (96.96%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1015,                   Accuracy: 58198/60000 (97.00%)
{0: tensor(97.1200), 10: tensor(96.7750), 20: tensor(96.8150), 30: tensor(96.8333), 40: tensor(96.8417), 50: tensor(96.7800), 60: tensor(96.9000), 70: tensor(96.9617), 80: tensor(96.9967), 90: tensor(97.1200), 100: tensor(96.7750), 110: tensor(96.8150), 120: tensor(96.8333), 130: tensor(96.8417), 140: tensor(96.7800), 150: tensor(96.9000), 160: tensor(96.9617), 170: tensor(96.9967), 180: tensor(97.1200), 190: tensor(96.7750), 200: tensor(96.8150), 210: tensor(96.8333), 220: tensor(96.8417), 230: tensor(96.7800), 240: tensor(96.9000), 250: tensor(96.9617), 260: tensor(96.9967), 270: tensor(97.1200), 280: tensor(96.7750), 290: tensor(96.8150), 300: tensor(96.8333), 310: tensor(96.8417), 320: tensor(96.7800), 330: tensor(96.9000), 340: tensor(96.9617), 350: tensor(96.9967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=28, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.8444,                   Accuracy: 415/2000.0 (20.75%)



-= Testing valid =-
Test set: Average loss: 1.2408,                   Accuracy: 1160/2000.0 (58.00%)



-= Testing valid =-
Test set: Average loss: 1.3102,                   Accuracy: 1115/2000.0 (55.75%)



-= Testing valid =-
Test set: Average loss: 0.8489,                   Accuracy: 1363/2000.0 (68.15%)



-= Testing valid =-
Test set: Average loss: 0.4116,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.3685,                   Accuracy: 1777/2000.0 (88.85%)



-= Testing valid =-
Test set: Average loss: 0.4203,                   Accuracy: 1728/2000.0 (86.40%)



-= Testing valid =-
Test set: Average loss: 0.2962,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2336,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2827,                   Accuracy: 1840/2000.0 (92.00%)



Epoch 10 train accuracy: 93.44%, valid accuracy 92.00%
-= Testing valid =-
Test set: Average loss: 0.1645,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1610,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1462,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1475,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1390,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1207,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1283,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1234,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1499,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1271,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 20 train accuracy: 95.84%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.1143,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1101,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1216,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1199,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1109,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1108,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 30 train accuracy: 97.01%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0926,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 40 train accuracy: 97.20%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 50 train accuracy: 97.45%, valid accuracy 97.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1057,                   Accuracy: 58136/60000 (96.89%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1130,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1108,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1146,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1188,                   Accuracy: 57863/60000 (96.44%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1207,                   Accuracy: 57843/60000 (96.40%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1195,                   Accuracy: 57853/60000 (96.42%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1181,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1077,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1057,                   Accuracy: 58136/60000 (96.89%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1130,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1108,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1146,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1188,                   Accuracy: 57863/60000 (96.44%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1207,                   Accuracy: 57843/60000 (96.40%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1195,                   Accuracy: 57853/60000 (96.42%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1181,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1077,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1057,                   Accuracy: 58136/60000 (96.89%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1130,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1108,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1146,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1188,                   Accuracy: 57863/60000 (96.44%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1207,                   Accuracy: 57843/60000 (96.40%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1195,                   Accuracy: 57853/60000 (96.42%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1181,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1077,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1057,                   Accuracy: 58136/60000 (96.89%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1130,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1108,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1146,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1188,                   Accuracy: 57863/60000 (96.44%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1207,                   Accuracy: 57843/60000 (96.40%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1195,                   Accuracy: 57853/60000 (96.42%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1181,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1077,                   Accuracy: 58054/60000 (96.76%)
{0: tensor(96.8933), 10: tensor(96.6033), 20: tensor(96.7700), 30: tensor(96.6017), 40: tensor(96.4383), 50: tensor(96.4050), 60: tensor(96.4217), 70: tensor(96.4900), 80: tensor(96.7567), 90: tensor(96.8933), 100: tensor(96.6033), 110: tensor(96.7700), 120: tensor(96.6017), 130: tensor(96.4383), 140: tensor(96.4050), 150: tensor(96.4217), 160: tensor(96.4900), 170: tensor(96.7567), 180: tensor(96.8933), 190: tensor(96.6033), 200: tensor(96.7700), 210: tensor(96.6017), 220: tensor(96.4383), 230: tensor(96.4050), 240: tensor(96.4217), 250: tensor(96.4900), 260: tensor(96.7567), 270: tensor(96.8933), 280: tensor(96.6033), 290: tensor(96.7700), 300: tensor(96.6017), 310: tensor(96.4383), 320: tensor(96.4050), 330: tensor(96.4217), 340: tensor(96.4900), 350: tensor(96.7567)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=29, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9604,                   Accuracy: 405/2000.0 (20.25%)



-= Testing valid =-
Test set: Average loss: 1.5640,                   Accuracy: 826/2000.0 (41.30%)



-= Testing valid =-
Test set: Average loss: 1.4213,                   Accuracy: 978/2000.0 (48.90%)



-= Testing valid =-
Test set: Average loss: 0.8484,                   Accuracy: 1406/2000.0 (70.30%)



-= Testing valid =-
Test set: Average loss: 1.8969,                   Accuracy: 694/2000.0 (34.70%)



-= Testing valid =-
Test set: Average loss: 0.2611,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.4017,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 0.4911,                   Accuracy: 1724/2000.0 (86.20%)



-= Testing valid =-
Test set: Average loss: 0.4211,                   Accuracy: 1738/2000.0 (86.90%)



-= Testing valid =-
Test set: Average loss: 0.2552,                   Accuracy: 1841/2000.0 (92.05%)



Epoch 10 train accuracy: 93.31%, valid accuracy 92.05%
-= Testing valid =-
Test set: Average loss: 0.1412,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1436,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1811,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1204,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1314,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1461,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1096,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1085,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1267,                   Accuracy: 1918/2000.0 (95.90%)



Epoch 20 train accuracy: 96.16%, valid accuracy 95.90%
-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1092,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1140,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1223,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 30 train accuracy: 96.90%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 40 train accuracy: 97.24%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 50 train accuracy: 97.61%, valid accuracy 97.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1152,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1177,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1209,                   Accuracy: 57926/60000 (96.54%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1213,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1203,                   Accuracy: 57934/60000 (96.56%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1199,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1186,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1160,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1122,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1152,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1177,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1209,                   Accuracy: 57926/60000 (96.54%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1213,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1203,                   Accuracy: 57934/60000 (96.56%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1199,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1186,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1160,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1122,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1152,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1177,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1209,                   Accuracy: 57926/60000 (96.54%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1213,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1203,                   Accuracy: 57934/60000 (96.56%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1199,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1186,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1160,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1122,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1152,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1177,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1209,                   Accuracy: 57926/60000 (96.54%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1213,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1203,                   Accuracy: 57934/60000 (96.56%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1199,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1186,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1160,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1122,                   Accuracy: 58063/60000 (96.77%)
{0: tensor(96.7417), 10: tensor(96.6150), 20: tensor(96.5433), 30: tensor(96.5133), 40: tensor(96.5567), 50: tensor(96.5950), 60: tensor(96.5867), 70: tensor(96.6800), 80: tensor(96.7717), 90: tensor(96.7417), 100: tensor(96.6150), 110: tensor(96.5433), 120: tensor(96.5133), 130: tensor(96.5567), 140: tensor(96.5950), 150: tensor(96.5867), 160: tensor(96.6800), 170: tensor(96.7717), 180: tensor(96.7417), 190: tensor(96.6150), 200: tensor(96.5433), 210: tensor(96.5133), 220: tensor(96.5567), 230: tensor(96.5950), 240: tensor(96.5867), 250: tensor(96.6800), 260: tensor(96.7717), 270: tensor(96.7417), 280: tensor(96.6150), 290: tensor(96.5433), 300: tensor(96.5133), 310: tensor(96.5567), 320: tensor(96.5950), 330: tensor(96.5867), 340: tensor(96.6800), 350: tensor(96.7717)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=30, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5874,                   Accuracy: 494/2000.0 (24.70%)



-= Testing valid =-
Test set: Average loss: 0.9966,                   Accuracy: 1269/2000.0 (63.45%)



-= Testing valid =-
Test set: Average loss: 1.0820,                   Accuracy: 1206/2000.0 (60.30%)



-= Testing valid =-
Test set: Average loss: 0.5757,                   Accuracy: 1616/2000.0 (80.80%)



-= Testing valid =-
Test set: Average loss: 0.5521,                   Accuracy: 1670/2000.0 (83.50%)



-= Testing valid =-
Test set: Average loss: 0.2810,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.3695,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.2480,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.1723,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1945,                   Accuracy: 1887/2000.0 (94.35%)



Epoch 10 train accuracy: 93.41%, valid accuracy 94.35%
-= Testing valid =-
Test set: Average loss: 0.1389,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1381,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1145,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1089,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1792,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1503,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1141,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1188,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1127,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1127,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 20 train accuracy: 95.70%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0964,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1097,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 30 train accuracy: 96.68%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 40 train accuracy: 96.89%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0746,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 50 train accuracy: 97.12%, valid accuracy 97.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1081,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1198,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1117,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1169,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1181,                   Accuracy: 57839/60000 (96.40%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1178,                   Accuracy: 57865/60000 (96.44%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1163,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1164,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1122,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1081,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1198,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1117,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1169,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1181,                   Accuracy: 57839/60000 (96.40%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1178,                   Accuracy: 57865/60000 (96.44%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1163,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1164,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1122,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1081,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1198,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1117,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1169,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1181,                   Accuracy: 57839/60000 (96.40%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1178,                   Accuracy: 57865/60000 (96.44%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1163,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1164,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1122,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1081,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1198,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1117,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1169,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1181,                   Accuracy: 57839/60000 (96.40%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1178,                   Accuracy: 57865/60000 (96.44%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1163,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1164,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1122,                   Accuracy: 57953/60000 (96.59%)
{0: tensor(96.8367), 10: tensor(96.4167), 20: tensor(96.6967), 30: tensor(96.4100), 40: tensor(96.3983), 50: tensor(96.4417), 60: tensor(96.4167), 70: tensor(96.4167), 80: tensor(96.5883), 90: tensor(96.8367), 100: tensor(96.4167), 110: tensor(96.6967), 120: tensor(96.4100), 130: tensor(96.3983), 140: tensor(96.4417), 150: tensor(96.4167), 160: tensor(96.4167), 170: tensor(96.5883), 180: tensor(96.8367), 190: tensor(96.4167), 200: tensor(96.6967), 210: tensor(96.4100), 220: tensor(96.3983), 230: tensor(96.4417), 240: tensor(96.4167), 250: tensor(96.4167), 260: tensor(96.5883), 270: tensor(96.8367), 280: tensor(96.4167), 290: tensor(96.6967), 300: tensor(96.4100), 310: tensor(96.3983), 320: tensor(96.4417), 330: tensor(96.4167), 340: tensor(96.4167), 350: tensor(96.5883)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=31, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3029,                   Accuracy: 471/2000.0 (23.55%)



-= Testing valid =-
Test set: Average loss: 1.8802,                   Accuracy: 650/2000.0 (32.50%)



-= Testing valid =-
Test set: Average loss: 1.4941,                   Accuracy: 932/2000.0 (46.60%)



-= Testing valid =-
Test set: Average loss: 2.1694,                   Accuracy: 680/2000.0 (34.00%)



-= Testing valid =-
Test set: Average loss: 1.1982,                   Accuracy: 1144/2000.0 (57.20%)



-= Testing valid =-
Test set: Average loss: 0.3744,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.2139,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.2764,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.5601,                   Accuracy: 1621/2000.0 (81.05%)



-= Testing valid =-
Test set: Average loss: 0.1497,                   Accuracy: 1897/2000.0 (94.85%)



Epoch 10 train accuracy: 92.66%, valid accuracy 94.85%
-= Testing valid =-
Test set: Average loss: 0.1767,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1139,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1373,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1286,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.2445,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.1740,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1167,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1101,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 20 train accuracy: 95.54%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.0937,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 30 train accuracy: 96.41%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0734,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 40 train accuracy: 96.74%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0709,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 50 train accuracy: 97.15%, valid accuracy 97.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1060,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1195,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1177,                   Accuracy: 57874/60000 (96.46%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1212,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1203,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1204,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1167,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1133,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1075,                   Accuracy: 58061/60000 (96.77%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1060,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1195,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1177,                   Accuracy: 57874/60000 (96.46%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1212,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1203,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1204,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1167,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1133,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1075,                   Accuracy: 58061/60000 (96.77%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1060,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1195,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1177,                   Accuracy: 57874/60000 (96.46%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1212,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1203,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1204,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1167,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1133,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1075,                   Accuracy: 58061/60000 (96.77%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1060,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1195,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1177,                   Accuracy: 57874/60000 (96.46%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1212,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1203,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1204,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1167,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1133,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1075,                   Accuracy: 58061/60000 (96.77%)
{0: tensor(96.8800), 10: tensor(96.3567), 20: tensor(96.4567), 30: tensor(96.4350), 40: tensor(96.5317), 50: tensor(96.5617), 60: tensor(96.5683), 70: tensor(96.6517), 80: tensor(96.7683), 90: tensor(96.8800), 100: tensor(96.3567), 110: tensor(96.4567), 120: tensor(96.4350), 130: tensor(96.5317), 140: tensor(96.5617), 150: tensor(96.5683), 160: tensor(96.6517), 170: tensor(96.7683), 180: tensor(96.8800), 190: tensor(96.3567), 200: tensor(96.4567), 210: tensor(96.4350), 220: tensor(96.5317), 230: tensor(96.5617), 240: tensor(96.5683), 250: tensor(96.6517), 260: tensor(96.7683), 270: tensor(96.8800), 280: tensor(96.3567), 290: tensor(96.4567), 300: tensor(96.4350), 310: tensor(96.5317), 320: tensor(96.5617), 330: tensor(96.5683), 340: tensor(96.6517), 350: tensor(96.7683)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=32, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9996,                   Accuracy: 473/2000.0 (23.65%)



-= Testing valid =-
Test set: Average loss: 1.5213,                   Accuracy: 1026/2000.0 (51.30%)



-= Testing valid =-
Test set: Average loss: 1.4915,                   Accuracy: 933/2000.0 (46.65%)



-= Testing valid =-
Test set: Average loss: 0.5959,                   Accuracy: 1592/2000.0 (79.60%)



-= Testing valid =-
Test set: Average loss: 0.4897,                   Accuracy: 1682/2000.0 (84.10%)



-= Testing valid =-
Test set: Average loss: 0.3233,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.2677,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.2410,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2500,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2703,                   Accuracy: 1825/2000.0 (91.25%)



Epoch 10 train accuracy: 93.30%, valid accuracy 91.25%
-= Testing valid =-
Test set: Average loss: 0.1253,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1108,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1141,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1320,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1626,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1200,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1064,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1117,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1092,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 20 train accuracy: 95.97%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.1051,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1052,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1030,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 30 train accuracy: 96.66%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0704,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0698,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0707,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0715,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 40 train accuracy: 97.36%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0715,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0723,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 50 train accuracy: 97.43%, valid accuracy 98.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0965,                   Accuracy: 58290/60000 (97.15%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1062,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1068,                   Accuracy: 58110/60000 (96.85%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1113,                   Accuracy: 58028/60000 (96.71%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1152,                   Accuracy: 57959/60000 (96.60%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1160,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1113,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1055,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1006,                   Accuracy: 58199/60000 (97.00%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0965,                   Accuracy: 58290/60000 (97.15%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1062,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1068,                   Accuracy: 58110/60000 (96.85%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1113,                   Accuracy: 58028/60000 (96.71%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1152,                   Accuracy: 57959/60000 (96.60%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1160,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1113,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1055,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1006,                   Accuracy: 58199/60000 (97.00%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0965,                   Accuracy: 58290/60000 (97.15%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1062,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1068,                   Accuracy: 58110/60000 (96.85%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1113,                   Accuracy: 58028/60000 (96.71%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1152,                   Accuracy: 57959/60000 (96.60%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1160,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1113,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1055,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1006,                   Accuracy: 58199/60000 (97.00%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0965,                   Accuracy: 58290/60000 (97.15%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1062,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1068,                   Accuracy: 58110/60000 (96.85%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1113,                   Accuracy: 58028/60000 (96.71%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1152,                   Accuracy: 57959/60000 (96.60%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1160,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1113,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1055,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1006,                   Accuracy: 58199/60000 (97.00%)
{0: tensor(97.1500), 10: tensor(96.8283), 20: tensor(96.8500), 30: tensor(96.7133), 40: tensor(96.5983), 50: tensor(96.6467), 60: tensor(96.7383), 70: tensor(96.9417), 80: tensor(96.9983), 90: tensor(97.1500), 100: tensor(96.8283), 110: tensor(96.8500), 120: tensor(96.7133), 130: tensor(96.5983), 140: tensor(96.6467), 150: tensor(96.7383), 160: tensor(96.9417), 170: tensor(96.9983), 180: tensor(97.1500), 190: tensor(96.8283), 200: tensor(96.8500), 210: tensor(96.7133), 220: tensor(96.5983), 230: tensor(96.6467), 240: tensor(96.7383), 250: tensor(96.9417), 260: tensor(96.9983), 270: tensor(97.1500), 280: tensor(96.8283), 290: tensor(96.8500), 300: tensor(96.7133), 310: tensor(96.5983), 320: tensor(96.6467), 330: tensor(96.7383), 340: tensor(96.9417), 350: tensor(96.9983)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=33, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.2817,                   Accuracy: 274/2000.0 (13.70%)



-= Testing valid =-
Test set: Average loss: 2.8928,                   Accuracy: 279/2000.0 (13.95%)



-= Testing valid =-
Test set: Average loss: 0.9731,                   Accuracy: 1385/2000.0 (69.25%)



-= Testing valid =-
Test set: Average loss: 0.6405,                   Accuracy: 1589/2000.0 (79.45%)



-= Testing valid =-
Test set: Average loss: 0.3539,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.3665,                   Accuracy: 1751/2000.0 (87.55%)



-= Testing valid =-
Test set: Average loss: 0.2591,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.3839,                   Accuracy: 1733/2000.0 (86.65%)



-= Testing valid =-
Test set: Average loss: 0.3600,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.1893,                   Accuracy: 1878/2000.0 (93.90%)



Epoch 10 train accuracy: 93.30%, valid accuracy 93.90%
-= Testing valid =-
Test set: Average loss: 0.1641,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1289,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1445,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1003,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1200,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 20 train accuracy: 95.51%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0756,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0646,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 30 train accuracy: 96.25%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0704,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0644,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0657,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 40 train accuracy: 96.65%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0606,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0607,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0597,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0619,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 50 train accuracy: 96.91%, valid accuracy 98.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1153,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1237,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1227,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1243,                   Accuracy: 57825/60000 (96.38%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1223,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1209,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1198,                   Accuracy: 57918/60000 (96.53%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1198,                   Accuracy: 57930/60000 (96.55%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1198,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1153,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1237,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1227,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1243,                   Accuracy: 57825/60000 (96.38%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1223,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1209,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1198,                   Accuracy: 57918/60000 (96.53%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1198,                   Accuracy: 57930/60000 (96.55%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1198,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1153,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1237,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1227,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1243,                   Accuracy: 57825/60000 (96.38%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1223,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1209,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1198,                   Accuracy: 57918/60000 (96.53%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1198,                   Accuracy: 57930/60000 (96.55%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1198,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1153,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1237,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1227,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1243,                   Accuracy: 57825/60000 (96.38%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1223,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1209,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1198,                   Accuracy: 57918/60000 (96.53%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1198,                   Accuracy: 57930/60000 (96.55%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1198,                   Accuracy: 57941/60000 (96.57%)
{0: tensor(96.6600), 10: tensor(96.4017), 20: tensor(96.4017), 30: tensor(96.3750), 40: tensor(96.3650), 50: tensor(96.4733), 60: tensor(96.5300), 70: tensor(96.5500), 80: tensor(96.5683), 90: tensor(96.6600), 100: tensor(96.4017), 110: tensor(96.4017), 120: tensor(96.3750), 130: tensor(96.3650), 140: tensor(96.4733), 150: tensor(96.5300), 160: tensor(96.5500), 170: tensor(96.5683), 180: tensor(96.6600), 190: tensor(96.4017), 200: tensor(96.4017), 210: tensor(96.3750), 220: tensor(96.3650), 230: tensor(96.4733), 240: tensor(96.5300), 250: tensor(96.5500), 260: tensor(96.5683), 270: tensor(96.6600), 280: tensor(96.4017), 290: tensor(96.4017), 300: tensor(96.3750), 310: tensor(96.3650), 320: tensor(96.4733), 330: tensor(96.5300), 340: tensor(96.5500), 350: tensor(96.5683)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=34, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4959,                   Accuracy: 280/2000.0 (14.00%)



-= Testing valid =-
Test set: Average loss: 3.4098,                   Accuracy: 510/2000.0 (25.50%)



-= Testing valid =-
Test set: Average loss: 4.7571,                   Accuracy: 381/2000.0 (19.05%)



-= Testing valid =-
Test set: Average loss: 1.1737,                   Accuracy: 1234/2000.0 (61.70%)



-= Testing valid =-
Test set: Average loss: 0.8620,                   Accuracy: 1378/2000.0 (68.90%)



-= Testing valid =-
Test set: Average loss: 0.4340,                   Accuracy: 1748/2000.0 (87.40%)



-= Testing valid =-
Test set: Average loss: 0.5109,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.4186,                   Accuracy: 1740/2000.0 (87.00%)



-= Testing valid =-
Test set: Average loss: 0.2415,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2497,                   Accuracy: 1856/2000.0 (92.80%)



Epoch 10 train accuracy: 93.61%, valid accuracy 92.80%
-= Testing valid =-
Test set: Average loss: 0.2193,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1742,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.2118,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1594,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1705,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1570,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1704,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1376,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1374,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1376,                   Accuracy: 1919/2000.0 (95.95%)



Epoch 20 train accuracy: 95.81%, valid accuracy 95.95%
-= Testing valid =-
Test set: Average loss: 0.1374,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1338,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1299,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1255,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1201,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1224,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1313,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1171,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1266,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1202,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 30 train accuracy: 97.28%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.1176,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1124,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1220,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1112,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1113,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1106,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1123,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1123,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 40 train accuracy: 96.97%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1080,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1070,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1092,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 50 train accuracy: 97.31%, valid accuracy 97.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0983,                   Accuracy: 58253/60000 (97.09%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1076,                   Accuracy: 58034/60000 (96.72%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1046,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1085,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1121,                   Accuracy: 58034/60000 (96.72%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1141,                   Accuracy: 58022/60000 (96.70%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1102,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1059,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1004,                   Accuracy: 58190/60000 (96.98%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0983,                   Accuracy: 58253/60000 (97.09%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1076,                   Accuracy: 58034/60000 (96.72%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1046,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1085,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1121,                   Accuracy: 58034/60000 (96.72%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1141,                   Accuracy: 58022/60000 (96.70%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1102,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1059,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1004,                   Accuracy: 58190/60000 (96.98%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0983,                   Accuracy: 58253/60000 (97.09%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1076,                   Accuracy: 58034/60000 (96.72%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1046,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1085,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1121,                   Accuracy: 58034/60000 (96.72%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1141,                   Accuracy: 58022/60000 (96.70%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1102,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1059,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1004,                   Accuracy: 58190/60000 (96.98%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0983,                   Accuracy: 58253/60000 (97.09%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1076,                   Accuracy: 58034/60000 (96.72%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1046,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1085,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1121,                   Accuracy: 58034/60000 (96.72%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1141,                   Accuracy: 58022/60000 (96.70%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1102,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1059,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1004,                   Accuracy: 58190/60000 (96.98%)
{0: tensor(97.0883), 10: tensor(96.7233), 20: tensor(96.8100), 30: tensor(96.8017), 40: tensor(96.7233), 50: tensor(96.7033), 60: tensor(96.7567), 70: tensor(96.8450), 80: tensor(96.9833), 90: tensor(97.0883), 100: tensor(96.7233), 110: tensor(96.8100), 120: tensor(96.8017), 130: tensor(96.7233), 140: tensor(96.7033), 150: tensor(96.7567), 160: tensor(96.8450), 170: tensor(96.9833), 180: tensor(97.0883), 190: tensor(96.7233), 200: tensor(96.8100), 210: tensor(96.8017), 220: tensor(96.7233), 230: tensor(96.7033), 240: tensor(96.7567), 250: tensor(96.8450), 260: tensor(96.9833), 270: tensor(97.0883), 280: tensor(96.7233), 290: tensor(96.8100), 300: tensor(96.8017), 310: tensor(96.7233), 320: tensor(96.7033), 330: tensor(96.7567), 340: tensor(96.8450), 350: tensor(96.9833)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=35, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6551,                   Accuracy: 259/2000.0 (12.95%)



-= Testing valid =-
Test set: Average loss: 1.7657,                   Accuracy: 851/2000.0 (42.55%)



-= Testing valid =-
Test set: Average loss: 1.6592,                   Accuracy: 867/2000.0 (43.35%)



-= Testing valid =-
Test set: Average loss: 1.1291,                   Accuracy: 1262/2000.0 (63.10%)



-= Testing valid =-
Test set: Average loss: 0.8358,                   Accuracy: 1426/2000.0 (71.30%)



-= Testing valid =-
Test set: Average loss: 0.4490,                   Accuracy: 1725/2000.0 (86.25%)



-= Testing valid =-
Test set: Average loss: 0.4081,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.3172,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.3533,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.2284,                   Accuracy: 1857/2000.0 (92.85%)



Epoch 10 train accuracy: 93.35%, valid accuracy 92.85%
-= Testing valid =-
Test set: Average loss: 0.1619,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1769,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1602,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1705,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1482,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1513,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1342,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.2284,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.1630,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1364,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 20 train accuracy: 95.84%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.1161,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1206,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1203,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1207,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1301,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1074,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1143,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1134,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1183,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 30 train accuracy: 96.68%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1131,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1092,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1037,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 40 train accuracy: 97.14%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1012,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 50 train accuracy: 96.95%, valid accuracy 97.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1096,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1196,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1117,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1187,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1247,                   Accuracy: 57840/60000 (96.40%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1279,                   Accuracy: 57762/60000 (96.27%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1288,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1227,                   Accuracy: 57828/60000 (96.38%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1156,                   Accuracy: 58011/60000 (96.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1096,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1196,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1117,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1187,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1247,                   Accuracy: 57840/60000 (96.40%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1279,                   Accuracy: 57762/60000 (96.27%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1288,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1227,                   Accuracy: 57828/60000 (96.38%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1156,                   Accuracy: 58011/60000 (96.68%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1096,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1196,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1117,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1187,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1247,                   Accuracy: 57840/60000 (96.40%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1279,                   Accuracy: 57762/60000 (96.27%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1288,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1227,                   Accuracy: 57828/60000 (96.38%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1156,                   Accuracy: 58011/60000 (96.68%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1096,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1196,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1117,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1187,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1247,                   Accuracy: 57840/60000 (96.40%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1279,                   Accuracy: 57762/60000 (96.27%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1288,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1227,                   Accuracy: 57828/60000 (96.38%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1156,                   Accuracy: 58011/60000 (96.68%)
{0: tensor(96.8133), 10: tensor(96.5333), 20: tensor(96.8467), 30: tensor(96.5867), 40: tensor(96.4000), 50: tensor(96.2700), 60: tensor(96.2600), 70: tensor(96.3800), 80: tensor(96.6850), 90: tensor(96.8133), 100: tensor(96.5333), 110: tensor(96.8467), 120: tensor(96.5867), 130: tensor(96.4000), 140: tensor(96.2700), 150: tensor(96.2600), 160: tensor(96.3800), 170: tensor(96.6850), 180: tensor(96.8133), 190: tensor(96.5333), 200: tensor(96.8467), 210: tensor(96.5867), 220: tensor(96.4000), 230: tensor(96.2700), 240: tensor(96.2600), 250: tensor(96.3800), 260: tensor(96.6850), 270: tensor(96.8133), 280: tensor(96.5333), 290: tensor(96.8467), 300: tensor(96.5867), 310: tensor(96.4000), 320: tensor(96.2700), 330: tensor(96.2600), 340: tensor(96.3800), 350: tensor(96.6850)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=36, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.2136,                   Accuracy: 411/2000.0 (20.55%)



-= Testing valid =-
Test set: Average loss: 2.3683,                   Accuracy: 343/2000.0 (17.15%)



-= Testing valid =-
Test set: Average loss: 1.2697,                   Accuracy: 1131/2000.0 (56.55%)



-= Testing valid =-
Test set: Average loss: 0.8366,                   Accuracy: 1434/2000.0 (71.70%)



-= Testing valid =-
Test set: Average loss: 0.6500,                   Accuracy: 1585/2000.0 (79.25%)



-= Testing valid =-
Test set: Average loss: 0.3841,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.2500,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2854,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.1402,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.2582,                   Accuracy: 1827/2000.0 (91.35%)



Epoch 10 train accuracy: 93.07%, valid accuracy 91.35%
-= Testing valid =-
Test set: Average loss: 0.1821,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1915,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1785,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1578,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1409,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1435,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1527,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1219,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1053,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1362,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 20 train accuracy: 95.97%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.1678,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1181,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0986,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1140,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1046,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 30 train accuracy: 96.57%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1094,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1115,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0919,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 40 train accuracy: 97.04%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0986,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0926,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 50 train accuracy: 97.32%, valid accuracy 97.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1210,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1295,                   Accuracy: 57635/60000 (96.06%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1245,                   Accuracy: 57764/60000 (96.27%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1325,                   Accuracy: 57621/60000 (96.04%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1327,                   Accuracy: 57662/60000 (96.10%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1339,                   Accuracy: 57704/60000 (96.17%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1285,                   Accuracy: 57786/60000 (96.31%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1245,                   Accuracy: 57840/60000 (96.40%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1199,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1210,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1295,                   Accuracy: 57635/60000 (96.06%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1245,                   Accuracy: 57764/60000 (96.27%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1325,                   Accuracy: 57621/60000 (96.04%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1327,                   Accuracy: 57662/60000 (96.10%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1339,                   Accuracy: 57704/60000 (96.17%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1285,                   Accuracy: 57786/60000 (96.31%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1245,                   Accuracy: 57840/60000 (96.40%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1199,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1210,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1295,                   Accuracy: 57635/60000 (96.06%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1245,                   Accuracy: 57764/60000 (96.27%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1325,                   Accuracy: 57621/60000 (96.04%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1327,                   Accuracy: 57662/60000 (96.10%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1339,                   Accuracy: 57704/60000 (96.17%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1285,                   Accuracy: 57786/60000 (96.31%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1245,                   Accuracy: 57840/60000 (96.40%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1199,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1210,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1295,                   Accuracy: 57635/60000 (96.06%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1245,                   Accuracy: 57764/60000 (96.27%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1325,                   Accuracy: 57621/60000 (96.04%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1327,                   Accuracy: 57662/60000 (96.10%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1339,                   Accuracy: 57704/60000 (96.17%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1285,                   Accuracy: 57786/60000 (96.31%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1245,                   Accuracy: 57840/60000 (96.40%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1199,                   Accuracy: 57884/60000 (96.47%)
{0: tensor(96.3600), 10: tensor(96.0583), 20: tensor(96.2733), 30: tensor(96.0350), 40: tensor(96.1033), 50: tensor(96.1733), 60: tensor(96.3100), 70: tensor(96.4000), 80: tensor(96.4733), 90: tensor(96.3600), 100: tensor(96.0583), 110: tensor(96.2733), 120: tensor(96.0350), 130: tensor(96.1033), 140: tensor(96.1733), 150: tensor(96.3100), 160: tensor(96.4000), 170: tensor(96.4733), 180: tensor(96.3600), 190: tensor(96.0583), 200: tensor(96.2733), 210: tensor(96.0350), 220: tensor(96.1033), 230: tensor(96.1733), 240: tensor(96.3100), 250: tensor(96.4000), 260: tensor(96.4733), 270: tensor(96.3600), 280: tensor(96.0583), 290: tensor(96.2733), 300: tensor(96.0350), 310: tensor(96.1033), 320: tensor(96.1733), 330: tensor(96.3100), 340: tensor(96.4000), 350: tensor(96.4733)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=37, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7704,                   Accuracy: 706/2000.0 (35.30%)



-= Testing valid =-
Test set: Average loss: 4.6693,                   Accuracy: 254/2000.0 (12.70%)



-= Testing valid =-
Test set: Average loss: 1.1237,                   Accuracy: 1200/2000.0 (60.00%)



-= Testing valid =-
Test set: Average loss: 0.7295,                   Accuracy: 1491/2000.0 (74.55%)



-= Testing valid =-
Test set: Average loss: 0.5448,                   Accuracy: 1658/2000.0 (82.90%)



-= Testing valid =-
Test set: Average loss: 1.1724,                   Accuracy: 1263/2000.0 (63.15%)



-= Testing valid =-
Test set: Average loss: 0.2600,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2448,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.1467,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1372,                   Accuracy: 1915/2000.0 (95.75%)



Epoch 10 train accuracy: 93.72%, valid accuracy 95.75%
-= Testing valid =-
Test set: Average loss: 0.1478,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1332,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1105,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1440,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1137,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 20 train accuracy: 95.34%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0752,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0802,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 30 train accuracy: 96.45%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0687,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0710,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0650,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 40 train accuracy: 97.11%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0678,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0646,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0683,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0683,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0647,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0636,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 50 train accuracy: 97.34%, valid accuracy 97.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0979,                   Accuracy: 58246/60000 (97.08%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1028,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0980,                   Accuracy: 58211/60000 (97.02%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1021,                   Accuracy: 58192/60000 (96.99%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1070,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1131,                   Accuracy: 57981/60000 (96.64%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1135,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1101,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1060,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0979,                   Accuracy: 58246/60000 (97.08%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1028,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.0980,                   Accuracy: 58211/60000 (97.02%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1021,                   Accuracy: 58192/60000 (96.99%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1070,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1131,                   Accuracy: 57981/60000 (96.64%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1135,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1101,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1060,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0979,                   Accuracy: 58246/60000 (97.08%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1028,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.0980,                   Accuracy: 58211/60000 (97.02%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1021,                   Accuracy: 58192/60000 (96.99%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1070,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1131,                   Accuracy: 57981/60000 (96.64%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1135,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1101,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1060,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0979,                   Accuracy: 58246/60000 (97.08%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1028,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0980,                   Accuracy: 58211/60000 (97.02%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1021,                   Accuracy: 58192/60000 (96.99%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1070,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1131,                   Accuracy: 57981/60000 (96.64%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1135,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1101,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1060,                   Accuracy: 58090/60000 (96.82%)
{0: tensor(97.0767), 10: tensor(96.8283), 20: tensor(97.0183), 30: tensor(96.9867), 40: tensor(96.7600), 50: tensor(96.6350), 60: tensor(96.6067), 70: tensor(96.6683), 80: tensor(96.8167), 90: tensor(97.0767), 100: tensor(96.8283), 110: tensor(97.0183), 120: tensor(96.9867), 130: tensor(96.7600), 140: tensor(96.6350), 150: tensor(96.6067), 160: tensor(96.6683), 170: tensor(96.8167), 180: tensor(97.0767), 190: tensor(96.8283), 200: tensor(97.0183), 210: tensor(96.9867), 220: tensor(96.7600), 230: tensor(96.6350), 240: tensor(96.6067), 250: tensor(96.6683), 260: tensor(96.8167), 270: tensor(97.0767), 280: tensor(96.8283), 290: tensor(97.0183), 300: tensor(96.9867), 310: tensor(96.7600), 320: tensor(96.6350), 330: tensor(96.6067), 340: tensor(96.6683), 350: tensor(96.8167)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=38, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.6589,                   Accuracy: 272/2000.0 (13.60%)



-= Testing valid =-
Test set: Average loss: 3.7301,                   Accuracy: 298/2000.0 (14.90%)



-= Testing valid =-
Test set: Average loss: 1.3522,                   Accuracy: 1032/2000.0 (51.60%)



-= Testing valid =-
Test set: Average loss: 2.3203,                   Accuracy: 649/2000.0 (32.45%)



-= Testing valid =-
Test set: Average loss: 1.6289,                   Accuracy: 1133/2000.0 (56.65%)



-= Testing valid =-
Test set: Average loss: 0.4107,                   Accuracy: 1748/2000.0 (87.40%)



-= Testing valid =-
Test set: Average loss: 0.3540,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.4627,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.2563,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.1987,                   Accuracy: 1883/2000.0 (94.15%)



Epoch 10 train accuracy: 92.78%, valid accuracy 94.15%
-= Testing valid =-
Test set: Average loss: 0.1656,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1286,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1782,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1190,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1093,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1312,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1239,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1202,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1576,                   Accuracy: 1900/2000.0 (95.00%)



Epoch 20 train accuracy: 95.90%, valid accuracy 95.00%
-= Testing valid =-
Test set: Average loss: 0.1267,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1147,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1304,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 30 train accuracy: 96.36%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 40 train accuracy: 96.68%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0798,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 50 train accuracy: 97.30%, valid accuracy 97.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0960,                   Accuracy: 58273/60000 (97.12%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1065,                   Accuracy: 58084/60000 (96.81%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1031,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1033,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1064,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1109,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1086,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1072,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1068,                   Accuracy: 58083/60000 (96.81%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0960,                   Accuracy: 58273/60000 (97.12%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1065,                   Accuracy: 58084/60000 (96.81%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1031,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1033,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1064,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1109,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1086,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1072,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1068,                   Accuracy: 58083/60000 (96.81%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0960,                   Accuracy: 58273/60000 (97.12%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1065,                   Accuracy: 58084/60000 (96.81%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1031,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1033,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1064,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1109,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1086,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1072,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1068,                   Accuracy: 58083/60000 (96.81%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0960,                   Accuracy: 58273/60000 (97.12%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1065,                   Accuracy: 58084/60000 (96.81%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1031,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1033,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1064,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1109,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1086,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1072,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1068,                   Accuracy: 58083/60000 (96.81%)
{0: tensor(97.1217), 10: tensor(96.8067), 20: tensor(96.8533), 30: tensor(96.8383), 40: tensor(96.7967), 50: tensor(96.6533), 60: tensor(96.7117), 70: tensor(96.7967), 80: tensor(96.8050), 90: tensor(97.1217), 100: tensor(96.8067), 110: tensor(96.8533), 120: tensor(96.8383), 130: tensor(96.7967), 140: tensor(96.6533), 150: tensor(96.7117), 160: tensor(96.7967), 170: tensor(96.8050), 180: tensor(97.1217), 190: tensor(96.8067), 200: tensor(96.8533), 210: tensor(96.8383), 220: tensor(96.7967), 230: tensor(96.6533), 240: tensor(96.7117), 250: tensor(96.7967), 260: tensor(96.8050), 270: tensor(97.1217), 280: tensor(96.8067), 290: tensor(96.8533), 300: tensor(96.8383), 310: tensor(96.7967), 320: tensor(96.6533), 330: tensor(96.7117), 340: tensor(96.7967), 350: tensor(96.8050)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=39, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0510,                   Accuracy: 302/2000.0 (15.10%)



-= Testing valid =-
Test set: Average loss: 1.1835,                   Accuracy: 1233/2000.0 (61.65%)



-= Testing valid =-
Test set: Average loss: 1.5446,                   Accuracy: 964/2000.0 (48.20%)



-= Testing valid =-
Test set: Average loss: 1.3387,                   Accuracy: 1155/2000.0 (57.75%)



-= Testing valid =-
Test set: Average loss: 1.7198,                   Accuracy: 1267/2000.0 (63.35%)



-= Testing valid =-
Test set: Average loss: 0.3564,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.3001,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.3845,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.1939,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.2153,                   Accuracy: 1861/2000.0 (93.05%)



Epoch 10 train accuracy: 93.95%, valid accuracy 93.05%
-= Testing valid =-
Test set: Average loss: 0.1382,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1336,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1241,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1413,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1329,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1288,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1253,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1015,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1482,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1242,                   Accuracy: 1928/2000.0 (96.40%)



Epoch 20 train accuracy: 95.89%, valid accuracy 96.40%
-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1120,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1093,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1048,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1148,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 30 train accuracy: 96.88%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 40 train accuracy: 97.22%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0910,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0877,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 50 train accuracy: 97.65%, valid accuracy 97.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1065,                   Accuracy: 58176/60000 (96.96%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1150,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1121,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1160,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1152,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1153,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1121,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1085,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1068,                   Accuracy: 58141/60000 (96.90%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1065,                   Accuracy: 58176/60000 (96.96%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1150,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1121,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1160,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1152,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1153,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1121,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1085,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1068,                   Accuracy: 58141/60000 (96.90%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1065,                   Accuracy: 58176/60000 (96.96%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1150,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1121,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1160,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1152,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1153,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1121,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1085,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1068,                   Accuracy: 58141/60000 (96.90%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1065,                   Accuracy: 58176/60000 (96.96%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1150,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1121,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1160,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1152,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1153,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1121,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1085,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1068,                   Accuracy: 58141/60000 (96.90%)
{0: tensor(96.9600), 10: tensor(96.6417), 20: tensor(96.7967), 30: tensor(96.6483), 40: tensor(96.6533), 50: tensor(96.6883), 60: tensor(96.7317), 70: tensor(96.8483), 80: tensor(96.9017), 90: tensor(96.9600), 100: tensor(96.6417), 110: tensor(96.7967), 120: tensor(96.6483), 130: tensor(96.6533), 140: tensor(96.6883), 150: tensor(96.7317), 160: tensor(96.8483), 170: tensor(96.9017), 180: tensor(96.9600), 190: tensor(96.6417), 200: tensor(96.7967), 210: tensor(96.6483), 220: tensor(96.6533), 230: tensor(96.6883), 240: tensor(96.7317), 250: tensor(96.8483), 260: tensor(96.9017), 270: tensor(96.9600), 280: tensor(96.6417), 290: tensor(96.7967), 300: tensor(96.6483), 310: tensor(96.6533), 320: tensor(96.6883), 330: tensor(96.7317), 340: tensor(96.8483), 350: tensor(96.9017)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=40, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.3192,                   Accuracy: 422/2000.0 (21.10%)



-= Testing valid =-
Test set: Average loss: 1.9690,                   Accuracy: 627/2000.0 (31.35%)



-= Testing valid =-
Test set: Average loss: 1.0360,                   Accuracy: 1376/2000.0 (68.80%)



-= Testing valid =-
Test set: Average loss: 1.1652,                   Accuracy: 1243/2000.0 (62.15%)



-= Testing valid =-
Test set: Average loss: 0.3827,                   Accuracy: 1765/2000.0 (88.25%)



-= Testing valid =-
Test set: Average loss: 0.2582,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2230,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2502,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.1846,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.2632,                   Accuracy: 1830/2000.0 (91.50%)



Epoch 10 train accuracy: 93.00%, valid accuracy 91.50%
-= Testing valid =-
Test set: Average loss: 0.1340,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1093,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1242,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1069,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1193,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1042,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1079,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 20 train accuracy: 95.84%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0736,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 30 train accuracy: 96.70%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0719,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0683,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0677,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 40 train accuracy: 97.06%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0656,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0629,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0638,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0658,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0632,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 50 train accuracy: 97.28%, valid accuracy 98.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1025,                   Accuracy: 58182/60000 (96.97%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1070,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1030,                   Accuracy: 58186/60000 (96.98%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1044,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1065,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1102,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1105,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1077,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1060,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1025,                   Accuracy: 58182/60000 (96.97%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1070,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1030,                   Accuracy: 58186/60000 (96.98%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1044,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1065,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1102,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1105,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1077,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1060,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1025,                   Accuracy: 58182/60000 (96.97%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1070,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1030,                   Accuracy: 58186/60000 (96.98%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1044,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1065,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1102,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1105,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1077,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1060,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1025,                   Accuracy: 58182/60000 (96.97%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1070,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1030,                   Accuracy: 58186/60000 (96.98%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1044,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1065,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1102,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1105,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1077,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1060,                   Accuracy: 58072/60000 (96.79%)
{0: tensor(96.9700), 10: tensor(96.7517), 20: tensor(96.9767), 30: tensor(96.8767), 40: tensor(96.8283), 50: tensor(96.7700), 60: tensor(96.7417), 70: tensor(96.7633), 80: tensor(96.7867), 90: tensor(96.9700), 100: tensor(96.7517), 110: tensor(96.9767), 120: tensor(96.8767), 130: tensor(96.8283), 140: tensor(96.7700), 150: tensor(96.7417), 160: tensor(96.7633), 170: tensor(96.7867), 180: tensor(96.9700), 190: tensor(96.7517), 200: tensor(96.9767), 210: tensor(96.8767), 220: tensor(96.8283), 230: tensor(96.7700), 240: tensor(96.7417), 250: tensor(96.7633), 260: tensor(96.7867), 270: tensor(96.9700), 280: tensor(96.7517), 290: tensor(96.9767), 300: tensor(96.8767), 310: tensor(96.8283), 320: tensor(96.7700), 330: tensor(96.7417), 340: tensor(96.7633), 350: tensor(96.7867)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=11, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.3275,                   Accuracy: 225/2000.0 (11.25%)



-= Testing valid =-
Test set: Average loss: 1.7688,                   Accuracy: 825/2000.0 (41.25%)



-= Testing valid =-
Test set: Average loss: 1.2507,                   Accuracy: 1100/2000.0 (55.00%)



-= Testing valid =-
Test set: Average loss: 0.6785,                   Accuracy: 1477/2000.0 (73.85%)



-= Testing valid =-
Test set: Average loss: 0.4341,                   Accuracy: 1736/2000.0 (86.80%)



-= Testing valid =-
Test set: Average loss: 0.6484,                   Accuracy: 1584/2000.0 (79.20%)



-= Testing valid =-
Test set: Average loss: 0.4527,                   Accuracy: 1708/2000.0 (85.40%)



-= Testing valid =-
Test set: Average loss: 0.1696,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.2396,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2098,                   Accuracy: 1861/2000.0 (93.05%)



Epoch 10 train accuracy: 92.38%, valid accuracy 93.05%
-= Testing valid =-
Test set: Average loss: 0.1605,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1463,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1569,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1312,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1338,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1260,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1262,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 20 train accuracy: 95.20%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1162,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1119,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1308,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1164,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 30 train accuracy: 96.18%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.1111,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 40 train accuracy: 96.55%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0775,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 50 train accuracy: 96.89%, valid accuracy 97.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1203,                   Accuracy: 57865/60000 (96.44%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1328,                   Accuracy: 57526/60000 (95.88%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1304,                   Accuracy: 57612/60000 (96.02%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1321,                   Accuracy: 57616/60000 (96.03%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1355,                   Accuracy: 57569/60000 (95.95%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1356,                   Accuracy: 57562/60000 (95.94%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1331,                   Accuracy: 57648/60000 (96.08%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1271,                   Accuracy: 57736/60000 (96.23%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1291,                   Accuracy: 57656/60000 (96.09%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1240,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1370,                   Accuracy: 57477/60000 (95.79%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1377,                   Accuracy: 57455/60000 (95.76%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1375,                   Accuracy: 57489/60000 (95.82%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1404,                   Accuracy: 57463/60000 (95.77%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1406,                   Accuracy: 57472/60000 (95.79%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1406,                   Accuracy: 57477/60000 (95.79%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1309,                   Accuracy: 57640/60000 (96.07%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1374,                   Accuracy: 57503/60000 (95.84%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1286,                   Accuracy: 57665/60000 (96.11%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1426,                   Accuracy: 57299/60000 (95.50%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1395,                   Accuracy: 57371/60000 (95.62%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1422,                   Accuracy: 57373/60000 (95.62%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1425,                   Accuracy: 57383/60000 (95.64%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1424,                   Accuracy: 57430/60000 (95.72%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1390,                   Accuracy: 57515/60000 (95.86%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1265,                   Accuracy: 57722/60000 (96.20%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1310,                   Accuracy: 57631/60000 (96.05%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1249,                   Accuracy: 57776/60000 (96.29%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1376,                   Accuracy: 57432/60000 (95.72%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1323,                   Accuracy: 57529/60000 (95.88%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1353,                   Accuracy: 57530/60000 (95.88%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1361,                   Accuracy: 57519/60000 (95.86%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1361,                   Accuracy: 57546/60000 (95.91%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1301,                   Accuracy: 57706/60000 (96.18%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1230,                   Accuracy: 57812/60000 (96.35%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1231,                   Accuracy: 57803/60000 (96.34%)
{0: tensor(96.4417), 10: tensor(95.8767), 20: tensor(96.0200), 30: tensor(96.0267), 40: tensor(95.9483), 50: tensor(95.9367), 60: tensor(96.0800), 70: tensor(96.2267), 80: tensor(96.0933), 90: tensor(96.2600), 100: tensor(95.7950), 110: tensor(95.7583), 120: tensor(95.8150), 130: tensor(95.7717), 140: tensor(95.7867), 150: tensor(95.7950), 160: tensor(96.0667), 170: tensor(95.8383), 180: tensor(96.1083), 190: tensor(95.4983), 200: tensor(95.6183), 210: tensor(95.6217), 220: tensor(95.6383), 230: tensor(95.7167), 240: tensor(95.8583), 250: tensor(96.2033), 260: tensor(96.0517), 270: tensor(96.2933), 280: tensor(95.7200), 290: tensor(95.8817), 300: tensor(95.8833), 310: tensor(95.8650), 320: tensor(95.9100), 330: tensor(96.1767), 340: tensor(96.3533), 350: tensor(96.3383)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=12, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.1040,                   Accuracy: 238/2000.0 (11.90%)



-= Testing valid =-
Test set: Average loss: 1.7385,                   Accuracy: 799/2000.0 (39.95%)



-= Testing valid =-
Test set: Average loss: 1.2630,                   Accuracy: 1267/2000.0 (63.35%)



-= Testing valid =-
Test set: Average loss: 0.5644,                   Accuracy: 1656/2000.0 (82.80%)



-= Testing valid =-
Test set: Average loss: 0.5835,                   Accuracy: 1594/2000.0 (79.70%)



-= Testing valid =-
Test set: Average loss: 0.2704,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2381,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2196,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2204,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2088,                   Accuracy: 1867/2000.0 (93.35%)



Epoch 10 train accuracy: 92.55%, valid accuracy 93.35%
-= Testing valid =-
Test set: Average loss: 0.1632,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1519,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1779,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1369,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1363,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1337,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1240,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1485,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1224,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1662,                   Accuracy: 1897/2000.0 (94.85%)



Epoch 20 train accuracy: 95.04%, valid accuracy 94.85%
-= Testing valid =-
Test set: Average loss: 0.1057,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1112,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 30 train accuracy: 96.46%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0807,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 40 train accuracy: 96.61%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0798,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0715,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 50 train accuracy: 97.11%, valid accuracy 97.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1094,                   Accuracy: 58168/60000 (96.95%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1246,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1246,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1279,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1220,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1186,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1162,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1097,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1120,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1154,                   Accuracy: 58002/60000 (96.67%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1342,                   Accuracy: 57616/60000 (96.03%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1356,                   Accuracy: 57669/60000 (96.11%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1429,                   Accuracy: 57516/60000 (95.86%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1371,                   Accuracy: 57609/60000 (96.01%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1323,                   Accuracy: 57672/60000 (96.12%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1313,                   Accuracy: 57703/60000 (96.17%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1233,                   Accuracy: 57779/60000 (96.30%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1291,                   Accuracy: 57664/60000 (96.11%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1263,                   Accuracy: 57735/60000 (96.22%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1408,                   Accuracy: 57471/60000 (95.79%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1384,                   Accuracy: 57595/60000 (95.99%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1401,                   Accuracy: 57605/60000 (96.01%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1339,                   Accuracy: 57730/60000 (96.22%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1276,                   Accuracy: 57780/60000 (96.30%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1253,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1165,                   Accuracy: 57954/60000 (96.59%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1211,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1170,                   Accuracy: 57975/60000 (96.62%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1286,                   Accuracy: 57753/60000 (96.25%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1257,                   Accuracy: 57848/60000 (96.41%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1255,                   Accuracy: 57901/60000 (96.50%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1191,                   Accuracy: 57997/60000 (96.66%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1163,                   Accuracy: 58074/60000 (96.79%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1130,                   Accuracy: 58094/60000 (96.82%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1062,                   Accuracy: 58186/60000 (96.98%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1080,                   Accuracy: 58132/60000 (96.89%)
{0: tensor(96.9467), 10: tensor(96.4300), 20: tensor(96.5383), 30: tensor(96.4100), 40: tensor(96.5317), 50: tensor(96.6733), 60: tensor(96.7167), 70: tensor(96.8133), 80: tensor(96.7383), 90: tensor(96.6700), 100: tensor(96.0267), 110: tensor(96.1150), 120: tensor(95.8600), 130: tensor(96.0150), 140: tensor(96.1200), 150: tensor(96.1717), 160: tensor(96.2983), 170: tensor(96.1067), 180: tensor(96.2250), 190: tensor(95.7850), 200: tensor(95.9917), 210: tensor(96.0083), 220: tensor(96.2167), 230: tensor(96.3000), 240: tensor(96.4117), 250: tensor(96.5900), 260: tensor(96.4483), 270: tensor(96.6250), 280: tensor(96.2550), 290: tensor(96.4133), 300: tensor(96.5017), 310: tensor(96.6617), 320: tensor(96.7900), 330: tensor(96.8233), 340: tensor(96.9767), 350: tensor(96.8867)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=13, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1166,                   Accuracy: 402/2000.0 (20.10%)



-= Testing valid =-
Test set: Average loss: 2.6457,                   Accuracy: 407/2000.0 (20.35%)



-= Testing valid =-
Test set: Average loss: 0.8281,                   Accuracy: 1461/2000.0 (73.05%)



-= Testing valid =-
Test set: Average loss: 1.4354,                   Accuracy: 1115/2000.0 (55.75%)



-= Testing valid =-
Test set: Average loss: 0.8197,                   Accuracy: 1435/2000.0 (71.75%)



-= Testing valid =-
Test set: Average loss: 0.2428,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2614,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.1587,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.2225,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.2034,                   Accuracy: 1869/2000.0 (93.45%)



Epoch 10 train accuracy: 93.74%, valid accuracy 93.45%
-= Testing valid =-
Test set: Average loss: 0.1077,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1121,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1189,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1193,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1092,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 20 train accuracy: 95.85%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1074,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.0825,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 30 train accuracy: 96.50%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0723,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0802,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0718,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0877,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0736,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 40 train accuracy: 97.12%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 50 train accuracy: 97.47%, valid accuracy 97.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0875,                   Accuracy: 58414/60000 (97.36%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0934,                   Accuracy: 58321/60000 (97.20%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0888,                   Accuracy: 58363/60000 (97.27%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0908,                   Accuracy: 58342/60000 (97.24%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0954,                   Accuracy: 58282/60000 (97.14%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0995,                   Accuracy: 58242/60000 (97.07%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1034,                   Accuracy: 58160/60000 (96.93%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1028,                   Accuracy: 58145/60000 (96.91%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1012,                   Accuracy: 58151/60000 (96.92%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0907,                   Accuracy: 58329/60000 (97.21%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.0951,                   Accuracy: 58258/60000 (97.10%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.0896,                   Accuracy: 58338/60000 (97.23%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.0897,                   Accuracy: 58390/60000 (97.32%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.0951,                   Accuracy: 58270/60000 (97.12%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1009,                   Accuracy: 58185/60000 (96.97%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1038,                   Accuracy: 58099/60000 (96.83%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1072,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1076,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0961,                   Accuracy: 58221/60000 (97.04%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.0969,                   Accuracy: 58192/60000 (96.99%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.0908,                   Accuracy: 58312/60000 (97.19%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.0905,                   Accuracy: 58359/60000 (97.26%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.0942,                   Accuracy: 58302/60000 (97.17%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.0985,                   Accuracy: 58255/60000 (97.09%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1006,                   Accuracy: 58212/60000 (97.02%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1029,                   Accuracy: 58129/60000 (96.88%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1017,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0915,                   Accuracy: 58306/60000 (97.18%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.0946,                   Accuracy: 58264/60000 (97.11%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0893,                   Accuracy: 58357/60000 (97.26%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.0907,                   Accuracy: 58362/60000 (97.27%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.0943,                   Accuracy: 58294/60000 (97.16%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.0968,                   Accuracy: 58267/60000 (97.11%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0994,                   Accuracy: 58224/60000 (97.04%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0995,                   Accuracy: 58208/60000 (97.01%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0975,                   Accuracy: 58267/60000 (97.11%)
{0: tensor(97.3567), 10: tensor(97.2017), 20: tensor(97.2717), 30: tensor(97.2367), 40: tensor(97.1367), 50: tensor(97.0700), 60: tensor(96.9333), 70: tensor(96.9083), 80: tensor(96.9183), 90: tensor(97.2150), 100: tensor(97.0967), 110: tensor(97.2300), 120: tensor(97.3167), 130: tensor(97.1167), 140: tensor(96.9750), 150: tensor(96.8317), 160: tensor(96.7017), 170: tensor(96.6533), 180: tensor(97.0350), 190: tensor(96.9867), 200: tensor(97.1867), 210: tensor(97.2650), 220: tensor(97.1700), 230: tensor(97.0917), 240: tensor(97.0200), 250: tensor(96.8817), 260: tensor(96.9100), 270: tensor(97.1767), 280: tensor(97.1067), 290: tensor(97.2617), 300: tensor(97.2700), 310: tensor(97.1567), 320: tensor(97.1117), 330: tensor(97.0400), 340: tensor(97.0133), 350: tensor(97.1117)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=14, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2053,                   Accuracy: 512/2000.0 (25.60%)



-= Testing valid =-
Test set: Average loss: 2.0867,                   Accuracy: 569/2000.0 (28.45%)



-= Testing valid =-
Test set: Average loss: 2.3455,                   Accuracy: 547/2000.0 (27.35%)



-= Testing valid =-
Test set: Average loss: 0.5719,                   Accuracy: 1680/2000.0 (84.00%)



-= Testing valid =-
Test set: Average loss: 0.2439,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2789,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.1795,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.2076,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2032,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 10 train accuracy: 93.89%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1020,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1260,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1292,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1177,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1256,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1339,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1057,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1457,                   Accuracy: 1911/2000.0 (95.55%)



Epoch 20 train accuracy: 95.66%, valid accuracy 95.55%
-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0926,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 30 train accuracy: 96.79%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0882,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0622,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 40 train accuracy: 97.28%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0720,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 50 train accuracy: 97.25%, valid accuracy 97.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0834,                   Accuracy: 58546/60000 (97.58%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0964,                   Accuracy: 58297/60000 (97.16%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0959,                   Accuracy: 58274/60000 (97.12%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1031,                   Accuracy: 58186/60000 (96.98%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1056,                   Accuracy: 58145/60000 (96.91%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1074,                   Accuracy: 58127/60000 (96.88%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1037,                   Accuracy: 58184/60000 (96.97%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1004,                   Accuracy: 58210/60000 (97.02%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.0983,                   Accuracy: 58214/60000 (97.02%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0898,                   Accuracy: 58441/60000 (97.40%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1041,                   Accuracy: 58132/60000 (96.89%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1033,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1120,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1158,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1197,                   Accuracy: 57881/60000 (96.47%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1149,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1111,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1131,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0981,                   Accuracy: 58233/60000 (97.06%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1095,                   Accuracy: 58012/60000 (96.69%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1075,                   Accuracy: 58028/60000 (96.71%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1115,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1119,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1134,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1072,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1009,                   Accuracy: 58175/60000 (96.96%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1007,                   Accuracy: 58161/60000 (96.93%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0882,                   Accuracy: 58412/60000 (97.35%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.0971,                   Accuracy: 58286/60000 (97.14%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0963,                   Accuracy: 58262/60000 (97.10%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1006,                   Accuracy: 58225/60000 (97.04%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1009,                   Accuracy: 58226/60000 (97.04%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1022,                   Accuracy: 58214/60000 (97.02%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0978,                   Accuracy: 58302/60000 (97.17%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0934,                   Accuracy: 58341/60000 (97.24%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0915,                   Accuracy: 58341/60000 (97.24%)
{0: tensor(97.5767), 10: tensor(97.1617), 20: tensor(97.1233), 30: tensor(96.9767), 40: tensor(96.9083), 50: tensor(96.8783), 60: tensor(96.9733), 70: tensor(97.0167), 80: tensor(97.0233), 90: tensor(97.4017), 100: tensor(96.8867), 110: tensor(96.8367), 120: tensor(96.6417), 130: tensor(96.5067), 140: tensor(96.4683), 150: tensor(96.5450), 160: tensor(96.5883), 170: tensor(96.4533), 180: tensor(97.0550), 190: tensor(96.6867), 200: tensor(96.7133), 210: tensor(96.6467), 220: tensor(96.6467), 230: tensor(96.6517), 240: tensor(96.8133), 250: tensor(96.9583), 260: tensor(96.9350), 270: tensor(97.3533), 280: tensor(97.1433), 290: tensor(97.1033), 300: tensor(97.0417), 310: tensor(97.0433), 320: tensor(97.0233), 330: tensor(97.1700), 340: tensor(97.2350), 350: tensor(97.2350)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=15, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.6585,                   Accuracy: 269/2000.0 (13.45%)



-= Testing valid =-
Test set: Average loss: 1.5480,                   Accuracy: 927/2000.0 (46.35%)



-= Testing valid =-
Test set: Average loss: 0.9601,                   Accuracy: 1418/2000.0 (70.90%)



-= Testing valid =-
Test set: Average loss: 0.8729,                   Accuracy: 1391/2000.0 (69.55%)



-= Testing valid =-
Test set: Average loss: 0.3703,                   Accuracy: 1747/2000.0 (87.35%)



-= Testing valid =-
Test set: Average loss: 0.3109,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2864,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.1864,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1614,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1797,                   Accuracy: 1899/2000.0 (94.95%)



Epoch 10 train accuracy: 93.41%, valid accuracy 94.95%
-= Testing valid =-
Test set: Average loss: 0.1339,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1266,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1526,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1427,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1376,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1096,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1399,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1089,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1176,                   Accuracy: 1928/2000.0 (96.40%)



Epoch 20 train accuracy: 95.65%, valid accuracy 96.40%
-= Testing valid =-
Test set: Average loss: 0.1114,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1317,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1277,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0756,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 30 train accuracy: 96.38%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0718,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 40 train accuracy: 97.14%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 50 train accuracy: 97.10%, valid accuracy 97.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1033,                   Accuracy: 58225/60000 (97.04%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1112,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1093,                   Accuracy: 58095/60000 (96.82%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1124,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1112,                   Accuracy: 58077/60000 (96.79%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1093,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1080,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1021,                   Accuracy: 58224/60000 (97.04%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1070,                   Accuracy: 58096/60000 (96.83%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1058,                   Accuracy: 58157/60000 (96.93%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1151,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1136,                   Accuracy: 58012/60000 (96.69%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1183,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1176,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1160,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1144,                   Accuracy: 57900/60000 (96.50%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1080,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1135,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1081,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1165,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1119,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1154,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1137,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1117,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1104,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1045,                   Accuracy: 58167/60000 (96.94%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1083,                   Accuracy: 58091/60000 (96.82%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1042,                   Accuracy: 58190/60000 (96.98%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1112,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1076,                   Accuracy: 58143/60000 (96.90%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1099,                   Accuracy: 58117/60000 (96.86%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1083,                   Accuracy: 58133/60000 (96.89%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1066,                   Accuracy: 58187/60000 (96.98%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1057,                   Accuracy: 58162/60000 (96.94%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1002,                   Accuracy: 58273/60000 (97.12%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1045,                   Accuracy: 58191/60000 (96.99%)
{0: tensor(97.0417), 10: tensor(96.7867), 20: tensor(96.8250), 30: tensor(96.7867), 40: tensor(96.7950), 50: tensor(96.8133), 60: tensor(96.8217), 70: tensor(97.0400), 80: tensor(96.8267), 90: tensor(96.9283), 100: tensor(96.5683), 110: tensor(96.6867), 120: tensor(96.5133), 130: tensor(96.4767), 140: tensor(96.5750), 150: tensor(96.5000), 160: tensor(96.7533), 170: tensor(96.5683), 180: tensor(96.8133), 190: tensor(96.4817), 200: tensor(96.6400), 210: tensor(96.6117), 220: tensor(96.6583), 230: tensor(96.6750), 240: tensor(96.7333), 250: tensor(96.9450), 260: tensor(96.8183), 270: tensor(96.9833), 280: tensor(96.7383), 290: tensor(96.9050), 300: tensor(96.8617), 310: tensor(96.8883), 320: tensor(96.9783), 330: tensor(96.9367), 340: tensor(97.1217), 350: tensor(96.9850)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=16, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.8245,                   Accuracy: 225/2000.0 (11.25%)



-= Testing valid =-
Test set: Average loss: 1.4828,                   Accuracy: 914/2000.0 (45.70%)



-= Testing valid =-
Test set: Average loss: 3.4791,                   Accuracy: 351/2000.0 (17.55%)



-= Testing valid =-
Test set: Average loss: 2.3628,                   Accuracy: 776/2000.0 (38.80%)



-= Testing valid =-
Test set: Average loss: 0.4227,                   Accuracy: 1747/2000.0 (87.35%)



-= Testing valid =-
Test set: Average loss: 0.4715,                   Accuracy: 1687/2000.0 (84.35%)



-= Testing valid =-
Test set: Average loss: 0.2538,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.4071,                   Accuracy: 1738/2000.0 (86.90%)



-= Testing valid =-
Test set: Average loss: 0.3631,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.1559,                   Accuracy: 1907/2000.0 (95.35%)



Epoch 10 train accuracy: 93.31%, valid accuracy 95.35%
-= Testing valid =-
Test set: Average loss: 0.1729,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1848,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1280,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1581,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1399,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1194,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1696,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1491,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1386,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 20 train accuracy: 95.90%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.1224,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1079,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1164,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1215,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1091,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1021,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1166,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 30 train accuracy: 96.49%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1071,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1034,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1089,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 40 train accuracy: 96.70%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0947,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 50 train accuracy: 97.25%, valid accuracy 97.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1163,                   Accuracy: 57994/60000 (96.66%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1274,                   Accuracy: 57736/60000 (96.23%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1264,                   Accuracy: 57735/60000 (96.22%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1375,                   Accuracy: 57592/60000 (95.99%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1369,                   Accuracy: 57593/60000 (95.99%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1383,                   Accuracy: 57557/60000 (95.93%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1311,                   Accuracy: 57679/60000 (96.13%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1207,                   Accuracy: 57857/60000 (96.43%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1186,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1164,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1254,                   Accuracy: 57743/60000 (96.24%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1253,                   Accuracy: 57772/60000 (96.29%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1361,                   Accuracy: 57577/60000 (95.96%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1357,                   Accuracy: 57563/60000 (95.94%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1374,                   Accuracy: 57567/60000 (95.94%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1334,                   Accuracy: 57597/60000 (96.00%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1209,                   Accuracy: 57795/60000 (96.32%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1213,                   Accuracy: 57786/60000 (96.31%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1190,                   Accuracy: 57867/60000 (96.44%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1285,                   Accuracy: 57727/60000 (96.21%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1256,                   Accuracy: 57718/60000 (96.20%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1355,                   Accuracy: 57571/60000 (95.95%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1347,                   Accuracy: 57607/60000 (96.01%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1355,                   Accuracy: 57636/60000 (96.06%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1311,                   Accuracy: 57665/60000 (96.11%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1184,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1167,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1172,                   Accuracy: 57946/60000 (96.58%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1279,                   Accuracy: 57735/60000 (96.22%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1249,                   Accuracy: 57790/60000 (96.32%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1357,                   Accuracy: 57588/60000 (95.98%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1358,                   Accuracy: 57606/60000 (96.01%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1368,                   Accuracy: 57580/60000 (95.97%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1294,                   Accuracy: 57722/60000 (96.20%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1195,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1167,                   Accuracy: 57974/60000 (96.62%)
{0: tensor(96.6567), 10: tensor(96.2267), 20: tensor(96.2250), 30: tensor(95.9867), 40: tensor(95.9883), 50: tensor(95.9283), 60: tensor(96.1317), 70: tensor(96.4283), 80: tensor(96.5117), 90: tensor(96.6050), 100: tensor(96.2383), 110: tensor(96.2867), 120: tensor(95.9617), 130: tensor(95.9383), 140: tensor(95.9450), 150: tensor(95.9950), 160: tensor(96.3250), 170: tensor(96.3100), 180: tensor(96.4450), 190: tensor(96.2117), 200: tensor(96.1967), 210: tensor(95.9517), 220: tensor(96.0117), 230: tensor(96.0600), 240: tensor(96.1083), 250: tensor(96.4900), 260: tensor(96.5800), 270: tensor(96.5767), 280: tensor(96.2250), 290: tensor(96.3167), 300: tensor(95.9800), 310: tensor(96.0100), 320: tensor(95.9667), 330: tensor(96.2033), 340: tensor(96.5450), 350: tensor(96.6233)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=17, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5453,                   Accuracy: 331/2000.0 (16.55%)



-= Testing valid =-
Test set: Average loss: 1.3835,                   Accuracy: 1092/2000.0 (54.60%)



-= Testing valid =-
Test set: Average loss: 1.4811,                   Accuracy: 943/2000.0 (47.15%)



-= Testing valid =-
Test set: Average loss: 1.9058,                   Accuracy: 893/2000.0 (44.65%)



-= Testing valid =-
Test set: Average loss: 6.1673,                   Accuracy: 199/2000.0 (9.95%)



-= Testing valid =-
Test set: Average loss: 1.1912,                   Accuracy: 1210/2000.0 (60.50%)



-= Testing valid =-
Test set: Average loss: 0.7720,                   Accuracy: 1473/2000.0 (73.65%)



-= Testing valid =-
Test set: Average loss: 0.5801,                   Accuracy: 1658/2000.0 (82.90%)



-= Testing valid =-
Test set: Average loss: 0.2656,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2804,                   Accuracy: 1813/2000.0 (90.65%)



Epoch 10 train accuracy: 92.76%, valid accuracy 90.65%
-= Testing valid =-
Test set: Average loss: 0.3017,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2183,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2097,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.4462,                   Accuracy: 1689/2000.0 (84.45%)



-= Testing valid =-
Test set: Average loss: 0.1929,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.2278,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1924,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.1728,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1886,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.2059,                   Accuracy: 1880/2000.0 (94.00%)



Epoch 20 train accuracy: 95.05%, valid accuracy 94.00%
-= Testing valid =-
Test set: Average loss: 0.1661,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1601,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1873,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1346,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1308,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1408,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1294,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1304,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1183,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1230,                   Accuracy: 1919/2000.0 (95.95%)



Epoch 30 train accuracy: 96.10%, valid accuracy 95.95%
-= Testing valid =-
Test set: Average loss: 0.1417,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1474,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1154,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1167,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1329,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1800,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1085,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1250,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1213,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 40 train accuracy: 96.76%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.1160,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1189,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1130,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1162,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1263,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1165,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1348,                   Accuracy: 1912/2000.0 (95.60%)



Epoch 50 train accuracy: 96.71%, valid accuracy 95.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1306,                   Accuracy: 57682/60000 (96.14%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1415,                   Accuracy: 57434/60000 (95.72%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1389,                   Accuracy: 57529/60000 (95.88%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1382,                   Accuracy: 57501/60000 (95.83%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1347,                   Accuracy: 57604/60000 (96.01%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1306,                   Accuracy: 57730/60000 (96.22%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1246,                   Accuracy: 57855/60000 (96.43%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1190,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1278,                   Accuracy: 57807/60000 (96.35%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1170,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1279,                   Accuracy: 57789/60000 (96.32%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1239,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1218,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1201,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1188,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1155,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1104,                   Accuracy: 58118/60000 (96.86%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1206,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1143,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1311,                   Accuracy: 57725/60000 (96.21%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1239,                   Accuracy: 57867/60000 (96.44%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1254,                   Accuracy: 57849/60000 (96.42%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1251,                   Accuracy: 57849/60000 (96.42%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1268,                   Accuracy: 57798/60000 (96.33%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1249,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1208,                   Accuracy: 57896/60000 (96.49%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1331,                   Accuracy: 57651/60000 (96.08%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1255,                   Accuracy: 57806/60000 (96.34%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1431,                   Accuracy: 57451/60000 (95.75%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1381,                   Accuracy: 57514/60000 (95.86%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1419,                   Accuracy: 57448/60000 (95.75%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1407,                   Accuracy: 57553/60000 (95.92%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1406,                   Accuracy: 57500/60000 (95.83%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1368,                   Accuracy: 57576/60000 (95.96%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1339,                   Accuracy: 57664/60000 (96.11%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1423,                   Accuracy: 57503/60000 (95.84%)
{0: tensor(96.1367), 10: tensor(95.7233), 20: tensor(95.8817), 30: tensor(95.8350), 40: tensor(96.0067), 50: tensor(96.2167), 60: tensor(96.4250), 70: tensor(96.5883), 80: tensor(96.3450), 90: tensor(96.7300), 100: tensor(96.3150), 110: tensor(96.4617), 120: tensor(96.5333), 130: tensor(96.6200), 140: tensor(96.6017), 150: tensor(96.7283), 160: tensor(96.8633), 170: tensor(96.5183), 180: tensor(96.7550), 190: tensor(96.2083), 200: tensor(96.4450), 210: tensor(96.4150), 220: tensor(96.4150), 230: tensor(96.3300), 240: tensor(96.3817), 250: tensor(96.4933), 260: tensor(96.0850), 270: tensor(96.3433), 280: tensor(95.7517), 290: tensor(95.8567), 300: tensor(95.7467), 310: tensor(95.9217), 320: tensor(95.8333), 330: tensor(95.9600), 340: tensor(96.1067), 350: tensor(95.8383)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=18, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.3512,                   Accuracy: 265/2000.0 (13.25%)



-= Testing valid =-
Test set: Average loss: 1.4875,                   Accuracy: 901/2000.0 (45.05%)



-= Testing valid =-
Test set: Average loss: 1.0203,                   Accuracy: 1317/2000.0 (65.85%)



-= Testing valid =-
Test set: Average loss: 0.7808,                   Accuracy: 1459/2000.0 (72.95%)



-= Testing valid =-
Test set: Average loss: 0.4975,                   Accuracy: 1676/2000.0 (83.80%)



-= Testing valid =-
Test set: Average loss: 0.5293,                   Accuracy: 1631/2000.0 (81.55%)



-= Testing valid =-
Test set: Average loss: 0.3266,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2871,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.1503,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.2492,                   Accuracy: 1833/2000.0 (91.65%)



Epoch 10 train accuracy: 93.44%, valid accuracy 91.65%
-= Testing valid =-
Test set: Average loss: 0.1467,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1684,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1723,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1399,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1479,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1532,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1208,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1178,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1524,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1372,                   Accuracy: 1912/2000.0 (95.60%)



Epoch 20 train accuracy: 96.05%, valid accuracy 95.60%
-= Testing valid =-
Test set: Average loss: 0.1401,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1066,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1111,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1059,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 30 train accuracy: 97.14%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 40 train accuracy: 97.20%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0919,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 50 train accuracy: 97.24%, valid accuracy 97.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1063,                   Accuracy: 58171/60000 (96.95%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1103,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1082,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1142,                   Accuracy: 58011/60000 (96.68%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1134,                   Accuracy: 58061/60000 (96.77%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1140,                   Accuracy: 58057/60000 (96.76%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1136,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1089,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1130,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1098,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1135,                   Accuracy: 57997/60000 (96.66%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1098,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1149,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1153,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1165,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1143,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1094,                   Accuracy: 58083/60000 (96.81%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1125,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1090,                   Accuracy: 58094/60000 (96.82%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1127,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1069,                   Accuracy: 58095/60000 (96.82%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1095,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1097,                   Accuracy: 58117/60000 (96.86%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1119,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1089,                   Accuracy: 58132/60000 (96.89%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1045,                   Accuracy: 58217/60000 (97.03%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1063,                   Accuracy: 58110/60000 (96.85%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1052,                   Accuracy: 58181/60000 (96.97%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1094,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1044,                   Accuracy: 58140/60000 (96.90%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1102,                   Accuracy: 58101/60000 (96.83%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1092,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1111,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1102,                   Accuracy: 58091/60000 (96.82%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1049,                   Accuracy: 58140/60000 (96.90%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1083,                   Accuracy: 58091/60000 (96.82%)
{0: tensor(96.9517), 10: tensor(96.7717), 20: tensor(96.8283), 30: tensor(96.6850), 40: tensor(96.7683), 50: tensor(96.7617), 60: tensor(96.6883), 70: tensor(96.7750), 80: tensor(96.6217), 90: tensor(96.7833), 100: tensor(96.6617), 110: tensor(96.7417), 120: tensor(96.6483), 130: tensor(96.6483), 140: tensor(96.6600), 150: tensor(96.6717), 160: tensor(96.8050), 170: tensor(96.5833), 180: tensor(96.8233), 190: tensor(96.6450), 200: tensor(96.8250), 210: tensor(96.8100), 220: tensor(96.8617), 230: tensor(96.8100), 240: tensor(96.8867), 250: tensor(97.0283), 260: tensor(96.8500), 270: tensor(96.9683), 280: tensor(96.7383), 290: tensor(96.9000), 300: tensor(96.8350), 310: tensor(96.9100), 320: tensor(96.8533), 330: tensor(96.8183), 340: tensor(96.9000), 350: tensor(96.8183)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=19, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9284,                   Accuracy: 598/2000.0 (29.90%)



-= Testing valid =-
Test set: Average loss: 4.1365,                   Accuracy: 263/2000.0 (13.15%)



-= Testing valid =-
Test set: Average loss: 6.4467,                   Accuracy: 336/2000.0 (16.80%)



-= Testing valid =-
Test set: Average loss: 2.2007,                   Accuracy: 942/2000.0 (47.10%)



-= Testing valid =-
Test set: Average loss: 1.1114,                   Accuracy: 1354/2000.0 (67.70%)



-= Testing valid =-
Test set: Average loss: 0.3715,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.3078,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2307,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.1770,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.2428,                   Accuracy: 1848/2000.0 (92.40%)



Epoch 10 train accuracy: 93.47%, valid accuracy 92.40%
-= Testing valid =-
Test set: Average loss: 0.1627,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.2045,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1773,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1194,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1604,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1291,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1647,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1467,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1538,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1397,                   Accuracy: 1906/2000.0 (95.30%)



Epoch 20 train accuracy: 95.86%, valid accuracy 95.30%
-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1215,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1167,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1274,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1152,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1235,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1192,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1070,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0964,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 30 train accuracy: 96.81%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 40 train accuracy: 97.05%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 50 train accuracy: 97.41%, valid accuracy 97.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1016,                   Accuracy: 58197/60000 (97.00%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1113,                   Accuracy: 58087/60000 (96.81%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1073,                   Accuracy: 58131/60000 (96.89%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1110,                   Accuracy: 58095/60000 (96.82%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1121,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1130,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1113,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1058,                   Accuracy: 58129/60000 (96.88%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1099,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1035,                   Accuracy: 58167/60000 (96.94%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1105,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1087,                   Accuracy: 58096/60000 (96.83%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1136,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1147,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1161,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1150,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1102,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1148,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1084,                   Accuracy: 58073/60000 (96.79%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1129,                   Accuracy: 58034/60000 (96.72%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1107,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1136,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1144,                   Accuracy: 57982/60000 (96.64%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1142,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1114,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1076,                   Accuracy: 58095/60000 (96.82%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1107,                   Accuracy: 58019/60000 (96.70%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1061,                   Accuracy: 58133/60000 (96.89%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1134,                   Accuracy: 58035/60000 (96.72%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1086,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1109,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1118,                   Accuracy: 58082/60000 (96.80%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1113,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1081,                   Accuracy: 58122/60000 (96.87%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1039,                   Accuracy: 58156/60000 (96.93%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1063,                   Accuracy: 58110/60000 (96.85%)
{0: tensor(96.9950), 10: tensor(96.8117), 20: tensor(96.8850), 30: tensor(96.8250), 40: tensor(96.7567), 50: tensor(96.8083), 60: tensor(96.7417), 70: tensor(96.8817), 80: tensor(96.7050), 90: tensor(96.9450), 100: tensor(96.7517), 110: tensor(96.8267), 120: tensor(96.6433), 130: tensor(96.6633), 140: tensor(96.6133), 150: tensor(96.5683), 160: tensor(96.7800), 170: tensor(96.5317), 180: tensor(96.7883), 190: tensor(96.7233), 200: tensor(96.7383), 210: tensor(96.7567), 220: tensor(96.6367), 230: tensor(96.6067), 240: tensor(96.7167), 250: tensor(96.8250), 260: tensor(96.6983), 270: tensor(96.8883), 280: tensor(96.7250), 290: tensor(96.8367), 300: tensor(96.8450), 310: tensor(96.8033), 320: tensor(96.8133), 330: tensor(96.8700), 340: tensor(96.9267), 350: tensor(96.8500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=20, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7887,                   Accuracy: 671/2000.0 (33.55%)



-= Testing valid =-
Test set: Average loss: 1.6964,                   Accuracy: 710/2000.0 (35.50%)



-= Testing valid =-
Test set: Average loss: 0.9969,                   Accuracy: 1272/2000.0 (63.60%)



-= Testing valid =-
Test set: Average loss: 0.9300,                   Accuracy: 1388/2000.0 (69.40%)



-= Testing valid =-
Test set: Average loss: 0.4711,                   Accuracy: 1695/2000.0 (84.75%)



-= Testing valid =-
Test set: Average loss: 0.3266,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.2262,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.1798,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1720,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1952,                   Accuracy: 1885/2000.0 (94.25%)



Epoch 10 train accuracy: 94.21%, valid accuracy 94.25%
-= Testing valid =-
Test set: Average loss: 0.1676,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1256,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1477,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1661,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1236,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1555,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1445,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1208,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1104,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1115,                   Accuracy: 1928/2000.0 (96.40%)



Epoch 20 train accuracy: 96.36%, valid accuracy 96.40%
-= Testing valid =-
Test set: Average loss: 0.1286,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1033,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1088,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 30 train accuracy: 97.12%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 40 train accuracy: 97.26%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 50 train accuracy: 97.22%, valid accuracy 97.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1116,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1199,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1235,                   Accuracy: 57783/60000 (96.31%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1284,                   Accuracy: 57739/60000 (96.23%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1286,                   Accuracy: 57755/60000 (96.26%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1245,                   Accuracy: 57823/60000 (96.37%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1189,                   Accuracy: 57898/60000 (96.50%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1148,                   Accuracy: 57982/60000 (96.64%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1185,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1152,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1239,                   Accuracy: 57796/60000 (96.33%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1260,                   Accuracy: 57705/60000 (96.18%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1314,                   Accuracy: 57627/60000 (96.04%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1320,                   Accuracy: 57661/60000 (96.10%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1289,                   Accuracy: 57722/60000 (96.20%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1224,                   Accuracy: 57812/60000 (96.35%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1178,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1219,                   Accuracy: 57828/60000 (96.38%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1176,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1266,                   Accuracy: 57721/60000 (96.20%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1254,                   Accuracy: 57716/60000 (96.19%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1283,                   Accuracy: 57710/60000 (96.18%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1256,                   Accuracy: 57782/60000 (96.30%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1214,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1155,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1114,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1117,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1126,                   Accuracy: 58034/60000 (96.72%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1216,                   Accuracy: 57822/60000 (96.37%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1226,                   Accuracy: 57793/60000 (96.32%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1253,                   Accuracy: 57775/60000 (96.29%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1225,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1182,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1119,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1087,                   Accuracy: 58094/60000 (96.82%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1104,                   Accuracy: 58083/60000 (96.81%)
{0: tensor(96.7667), 10: tensor(96.4433), 20: tensor(96.3050), 30: tensor(96.2317), 40: tensor(96.2583), 50: tensor(96.3717), 60: tensor(96.4967), 70: tensor(96.6367), 80: tensor(96.5183), 90: tensor(96.6267), 100: tensor(96.3267), 110: tensor(96.1750), 120: tensor(96.0450), 130: tensor(96.1017), 140: tensor(96.2033), 150: tensor(96.3533), 160: tensor(96.5217), 170: tensor(96.3800), 180: tensor(96.5550), 190: tensor(96.2017), 200: tensor(96.1933), 210: tensor(96.1833), 220: tensor(96.3033), 230: tensor(96.4300), 240: tensor(96.6267), 250: tensor(96.7633), 260: tensor(96.7267), 270: tensor(96.7233), 280: tensor(96.3700), 290: tensor(96.3217), 300: tensor(96.2917), 310: tensor(96.4400), 320: tensor(96.5600), 330: tensor(96.7417), 340: tensor(96.8233), 350: tensor(96.8050)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=21, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.9413,                   Accuracy: 230/2000.0 (11.50%)



-= Testing valid =-
Test set: Average loss: 2.4735,                   Accuracy: 312/2000.0 (15.60%)



-= Testing valid =-
Test set: Average loss: 1.3841,                   Accuracy: 1069/2000.0 (53.45%)



-= Testing valid =-
Test set: Average loss: 0.8011,                   Accuracy: 1446/2000.0 (72.30%)



-= Testing valid =-
Test set: Average loss: 1.3511,                   Accuracy: 1029/2000.0 (51.45%)



-= Testing valid =-
Test set: Average loss: 0.5235,                   Accuracy: 1697/2000.0 (84.85%)



-= Testing valid =-
Test set: Average loss: 0.3896,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.3347,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.3688,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.2645,                   Accuracy: 1834/2000.0 (91.70%)



Epoch 10 train accuracy: 91.90%, valid accuracy 91.70%
-= Testing valid =-
Test set: Average loss: 0.2429,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2273,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.1472,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1668,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1251,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1542,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1714,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1195,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1480,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1401,                   Accuracy: 1913/2000.0 (95.65%)



Epoch 20 train accuracy: 95.35%, valid accuracy 95.65%
-= Testing valid =-
Test set: Average loss: 0.1637,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1250,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1197,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1182,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1280,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1069,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1210,                   Accuracy: 1922/2000.0 (96.10%)



Epoch 30 train accuracy: 95.97%, valid accuracy 96.10%
-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1036,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 40 train accuracy: 96.64%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 50 train accuracy: 96.79%, valid accuracy 97.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1132,                   Accuracy: 58033/60000 (96.72%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1145,                   Accuracy: 57926/60000 (96.54%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1099,                   Accuracy: 58067/60000 (96.78%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1161,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1167,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1223,                   Accuracy: 57842/60000 (96.40%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1291,                   Accuracy: 57713/60000 (96.19%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1229,                   Accuracy: 57790/60000 (96.32%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1256,                   Accuracy: 57713/60000 (96.19%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1169,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1200,                   Accuracy: 57796/60000 (96.33%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1130,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1163,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1195,                   Accuracy: 57900/60000 (96.50%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1255,                   Accuracy: 57750/60000 (96.25%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1311,                   Accuracy: 57639/60000 (96.07%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1277,                   Accuracy: 57726/60000 (96.21%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1327,                   Accuracy: 57569/60000 (95.95%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1183,                   Accuracy: 57892/60000 (96.49%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1180,                   Accuracy: 57815/60000 (96.36%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1098,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1117,                   Accuracy: 58031/60000 (96.72%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1144,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1190,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1249,                   Accuracy: 57753/60000 (96.25%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1190,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1225,                   Accuracy: 57787/60000 (96.31%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1120,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1114,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1060,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1119,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1136,                   Accuracy: 57993/60000 (96.65%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1187,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1257,                   Accuracy: 57753/60000 (96.25%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1179,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1199,                   Accuracy: 57847/60000 (96.41%)
{0: tensor(96.7217), 10: tensor(96.5433), 20: tensor(96.7783), 30: tensor(96.6233), 40: tensor(96.5800), 50: tensor(96.4033), 60: tensor(96.1883), 70: tensor(96.3167), 80: tensor(96.1883), 90: tensor(96.5333), 100: tensor(96.3267), 110: tensor(96.6267), 120: tensor(96.6233), 130: tensor(96.5000), 140: tensor(96.2500), 150: tensor(96.0650), 160: tensor(96.2100), 170: tensor(95.9483), 180: tensor(96.4867), 190: tensor(96.3583), 200: tensor(96.6900), 210: tensor(96.7183), 220: tensor(96.6150), 230: tensor(96.4600), 240: tensor(96.2550), 250: tensor(96.4183), 260: tensor(96.3117), 270: tensor(96.6733), 280: tensor(96.6267), 290: tensor(96.8767), 300: tensor(96.7633), 310: tensor(96.6550), 320: tensor(96.4900), 330: tensor(96.2550), 340: tensor(96.4617), 350: tensor(96.4117)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=22, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.4899,                   Accuracy: 411/2000.0 (20.55%)



-= Testing valid =-
Test set: Average loss: 3.8660,                   Accuracy: 305/2000.0 (15.25%)



-= Testing valid =-
Test set: Average loss: 0.9305,                   Accuracy: 1332/2000.0 (66.60%)



-= Testing valid =-
Test set: Average loss: 1.3901,                   Accuracy: 1009/2000.0 (50.45%)



-= Testing valid =-
Test set: Average loss: 0.7978,                   Accuracy: 1503/2000.0 (75.15%)



-= Testing valid =-
Test set: Average loss: 0.7362,                   Accuracy: 1536/2000.0 (76.80%)



-= Testing valid =-
Test set: Average loss: 0.4042,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.2494,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.3296,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2087,                   Accuracy: 1877/2000.0 (93.85%)



Epoch 10 train accuracy: 93.75%, valid accuracy 93.85%
-= Testing valid =-
Test set: Average loss: 0.1492,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1472,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1843,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1633,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1298,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1751,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1436,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1458,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1149,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 20 train accuracy: 96.15%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.1388,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1467,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1192,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1228,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1066,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1154,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1229,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1124,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1046,                   Accuracy: 1934/2000.0 (96.70%)



Epoch 30 train accuracy: 96.70%, valid accuracy 96.70%
-= Testing valid =-
Test set: Average loss: 0.1103,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0976,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1015,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 40 train accuracy: 97.10%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0919,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 50 train accuracy: 97.21%, valid accuracy 97.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1135,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1215,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1183,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1189,                   Accuracy: 57930/60000 (96.55%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1184,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1194,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1190,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1191,                   Accuracy: 57863/60000 (96.44%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1230,                   Accuracy: 57797/60000 (96.33%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1187,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1270,                   Accuracy: 57694/60000 (96.16%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1225,                   Accuracy: 57769/60000 (96.28%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1235,                   Accuracy: 57827/60000 (96.38%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1221,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1242,                   Accuracy: 57805/60000 (96.34%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1252,                   Accuracy: 57784/60000 (96.31%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1214,                   Accuracy: 57795/60000 (96.32%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1280,                   Accuracy: 57621/60000 (96.04%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1245,                   Accuracy: 57707/60000 (96.18%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1346,                   Accuracy: 57470/60000 (95.78%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1214,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1221,                   Accuracy: 57880/60000 (96.47%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1191,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1209,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1204,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1163,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1195,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1177,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1268,                   Accuracy: 57688/60000 (96.15%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1162,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1170,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1161,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1166,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1165,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1146,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1164,                   Accuracy: 57911/60000 (96.52%)
{0: tensor(96.6833), 10: tensor(96.3767), 20: tensor(96.4783), 30: tensor(96.5500), 40: tensor(96.5933), 50: tensor(96.5367), 60: tensor(96.5550), 70: tensor(96.4383), 80: tensor(96.3283), 90: tensor(96.4350), 100: tensor(96.1567), 110: tensor(96.2817), 120: tensor(96.3783), 130: tensor(96.4167), 140: tensor(96.3417), 150: tensor(96.3067), 160: tensor(96.3250), 170: tensor(96.0350), 180: tensor(96.1783), 190: tensor(95.7833), 200: tensor(96.3400), 210: tensor(96.4667), 220: tensor(96.5317), 230: tensor(96.4850), 240: tensor(96.4733), 250: tensor(96.5067), 260: tensor(96.4167), 270: tensor(96.4733), 280: tensor(96.1467), 290: tensor(96.5250), 300: tensor(96.6117), 310: tensor(96.6517), 320: tensor(96.6150), 330: tensor(96.6883), 340: tensor(96.6517), 350: tensor(96.5183)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=23, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5371,                   Accuracy: 187/2000.0 (9.35%)



-= Testing valid =-
Test set: Average loss: 1.9102,                   Accuracy: 599/2000.0 (29.95%)



-= Testing valid =-
Test set: Average loss: 0.9846,                   Accuracy: 1330/2000.0 (66.50%)



-= Testing valid =-
Test set: Average loss: 1.2560,                   Accuracy: 1175/2000.0 (58.75%)



-= Testing valid =-
Test set: Average loss: 1.4831,                   Accuracy: 987/2000.0 (49.35%)



-= Testing valid =-
Test set: Average loss: 0.4415,                   Accuracy: 1664/2000.0 (83.20%)



-= Testing valid =-
Test set: Average loss: 0.2876,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.5749,                   Accuracy: 1653/2000.0 (82.65%)



-= Testing valid =-
Test set: Average loss: 0.1700,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.6446,                   Accuracy: 1487/2000.0 (74.35%)



Epoch 10 train accuracy: 92.97%, valid accuracy 74.35%
-= Testing valid =-
Test set: Average loss: 0.1526,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1644,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1562,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1968,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1375,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.2367,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.1721,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1286,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1252,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.2006,                   Accuracy: 1887/2000.0 (94.35%)



Epoch 20 train accuracy: 95.55%, valid accuracy 94.35%
-= Testing valid =-
Test set: Average loss: 0.1456,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1275,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1265,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1288,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1297,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1066,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1361,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1097,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1134,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 30 train accuracy: 96.19%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1059,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1072,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1017,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 40 train accuracy: 96.91%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0937,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 50 train accuracy: 96.93%, valid accuracy 97.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1282,                   Accuracy: 57790/60000 (96.32%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1418,                   Accuracy: 57532/60000 (95.89%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1412,                   Accuracy: 57571/60000 (95.95%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1451,                   Accuracy: 57529/60000 (95.88%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1419,                   Accuracy: 57612/60000 (96.02%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1414,                   Accuracy: 57604/60000 (96.01%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1402,                   Accuracy: 57603/60000 (96.00%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1342,                   Accuracy: 57636/60000 (96.06%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1357,                   Accuracy: 57564/60000 (95.94%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1278,                   Accuracy: 57793/60000 (96.32%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1404,                   Accuracy: 57526/60000 (95.88%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1409,                   Accuracy: 57538/60000 (95.90%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1457,                   Accuracy: 57518/60000 (95.86%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1446,                   Accuracy: 57498/60000 (95.83%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1442,                   Accuracy: 57514/60000 (95.86%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1431,                   Accuracy: 57475/60000 (95.79%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1366,                   Accuracy: 57545/60000 (95.91%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1377,                   Accuracy: 57507/60000 (95.85%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1305,                   Accuracy: 57725/60000 (96.21%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1446,                   Accuracy: 57401/60000 (95.67%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1413,                   Accuracy: 57509/60000 (95.85%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1448,                   Accuracy: 57526/60000 (95.88%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1438,                   Accuracy: 57527/60000 (95.88%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1431,                   Accuracy: 57467/60000 (95.78%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1415,                   Accuracy: 57527/60000 (95.88%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1346,                   Accuracy: 57588/60000 (95.98%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1325,                   Accuracy: 57641/60000 (96.07%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1291,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1446,                   Accuracy: 57442/60000 (95.74%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1410,                   Accuracy: 57532/60000 (95.89%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1435,                   Accuracy: 57545/60000 (95.91%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1426,                   Accuracy: 57606/60000 (96.01%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1408,                   Accuracy: 57624/60000 (96.04%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1408,                   Accuracy: 57599/60000 (96.00%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1336,                   Accuracy: 57669/60000 (96.11%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1317,                   Accuracy: 57681/60000 (96.14%)
{0: tensor(96.3167), 10: tensor(95.8867), 20: tensor(95.9517), 30: tensor(95.8817), 40: tensor(96.0200), 50: tensor(96.0067), 60: tensor(96.0050), 70: tensor(96.0600), 80: tensor(95.9400), 90: tensor(96.3217), 100: tensor(95.8767), 110: tensor(95.8967), 120: tensor(95.8633), 130: tensor(95.8300), 140: tensor(95.8567), 150: tensor(95.7917), 160: tensor(95.9083), 170: tensor(95.8450), 180: tensor(96.2083), 190: tensor(95.6683), 200: tensor(95.8483), 210: tensor(95.8767), 220: tensor(95.8783), 230: tensor(95.7783), 240: tensor(95.8783), 250: tensor(95.9800), 260: tensor(96.0683), 270: tensor(96.2600), 280: tensor(95.7367), 290: tensor(95.8867), 300: tensor(95.9083), 310: tensor(96.0100), 320: tensor(96.0400), 330: tensor(95.9983), 340: tensor(96.1150), 350: tensor(96.1350)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=24, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.4833,                   Accuracy: 230/2000.0 (11.50%)



-= Testing valid =-
Test set: Average loss: 1.7363,                   Accuracy: 649/2000.0 (32.45%)



-= Testing valid =-
Test set: Average loss: 1.1219,                   Accuracy: 1328/2000.0 (66.40%)



-= Testing valid =-
Test set: Average loss: 0.5462,                   Accuracy: 1682/2000.0 (84.10%)



-= Testing valid =-
Test set: Average loss: 1.4792,                   Accuracy: 1157/2000.0 (57.85%)



-= Testing valid =-
Test set: Average loss: 0.3251,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.3696,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.2669,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.4070,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.1519,                   Accuracy: 1903/2000.0 (95.15%)



Epoch 10 train accuracy: 93.38%, valid accuracy 95.15%
-= Testing valid =-
Test set: Average loss: 0.1475,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1294,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1212,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1433,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1788,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1636,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1183,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1687,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1077,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 20 train accuracy: 95.81%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0986,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1050,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 30 train accuracy: 96.41%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0802,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 40 train accuracy: 96.82%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 50 train accuracy: 97.16%, valid accuracy 98.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1060,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1099,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1078,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1126,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1151,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1177,                   Accuracy: 57931/60000 (96.55%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1192,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1135,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1139,                   Accuracy: 57955/60000 (96.59%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1092,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1126,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1100,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1150,                   Accuracy: 57926/60000 (96.54%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1175,                   Accuracy: 57892/60000 (96.49%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1203,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1200,                   Accuracy: 57844/60000 (96.41%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1139,                   Accuracy: 57955/60000 (96.59%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1173,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1118,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1161,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1101,                   Accuracy: 57965/60000 (96.61%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1145,                   Accuracy: 57926/60000 (96.54%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1150,                   Accuracy: 57924/60000 (96.54%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1162,                   Accuracy: 57896/60000 (96.49%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1161,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1093,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1094,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1071,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1123,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1070,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1117,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1125,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1144,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1155,                   Accuracy: 57965/60000 (96.61%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1110,                   Accuracy: 58029/60000 (96.71%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1080,                   Accuracy: 58047/60000 (96.75%)
{0: tensor(96.7967), 10: tensor(96.7283), 20: tensor(96.6817), 30: tensor(96.6400), 40: tensor(96.5633), 50: tensor(96.5517), 60: tensor(96.5333), 70: tensor(96.6533), 80: tensor(96.5917), 90: tensor(96.7450), 100: tensor(96.5717), 110: tensor(96.6517), 120: tensor(96.5433), 130: tensor(96.4867), 140: tensor(96.4017), 150: tensor(96.4067), 160: tensor(96.5917), 170: tensor(96.4100), 180: tensor(96.5800), 190: tensor(96.4533), 200: tensor(96.6083), 210: tensor(96.5433), 220: tensor(96.5400), 230: tensor(96.4933), 240: tensor(96.5383), 250: tensor(96.7383), 260: tensor(96.6683), 270: tensor(96.7650), 280: tensor(96.6267), 290: tensor(96.7383), 300: tensor(96.6900), 310: tensor(96.6433), 320: tensor(96.6017), 330: tensor(96.6083), 340: tensor(96.7150), 350: tensor(96.7450)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=25, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9276,                   Accuracy: 499/2000.0 (24.95%)



-= Testing valid =-
Test set: Average loss: 1.8588,                   Accuracy: 665/2000.0 (33.25%)



-= Testing valid =-
Test set: Average loss: 1.1289,                   Accuracy: 1167/2000.0 (58.35%)



-= Testing valid =-
Test set: Average loss: 0.7434,                   Accuracy: 1531/2000.0 (76.55%)



-= Testing valid =-
Test set: Average loss: 0.5115,                   Accuracy: 1695/2000.0 (84.75%)



-= Testing valid =-
Test set: Average loss: 0.2996,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2091,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.9223,                   Accuracy: 1438/2000.0 (71.90%)



-= Testing valid =-
Test set: Average loss: 0.1605,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1865,                   Accuracy: 1877/2000.0 (93.85%)



Epoch 10 train accuracy: 92.95%, valid accuracy 93.85%
-= Testing valid =-
Test set: Average loss: 0.1763,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1242,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1340,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1238,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1411,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1303,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1468,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1268,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1178,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1030,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 20 train accuracy: 95.31%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.1323,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1130,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1100,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1082,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1082,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 30 train accuracy: 96.25%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0775,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 40 train accuracy: 96.71%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 50 train accuracy: 97.06%, valid accuracy 97.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1026,                   Accuracy: 58231/60000 (97.05%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1119,                   Accuracy: 58026/60000 (96.71%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1054,                   Accuracy: 58131/60000 (96.89%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1055,                   Accuracy: 58116/60000 (96.86%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1060,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1081,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1104,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1074,                   Accuracy: 58116/60000 (96.86%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1093,                   Accuracy: 58083/60000 (96.81%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1052,                   Accuracy: 58178/60000 (96.96%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1143,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1061,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1055,                   Accuracy: 58087/60000 (96.81%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1076,                   Accuracy: 58074/60000 (96.79%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1123,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1127,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1136,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1154,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1100,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1144,                   Accuracy: 57914/60000 (96.52%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1070,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1052,                   Accuracy: 58110/60000 (96.85%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1053,                   Accuracy: 58122/60000 (96.87%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1091,                   Accuracy: 58075/60000 (96.79%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1107,                   Accuracy: 58067/60000 (96.78%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1108,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1108,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1061,                   Accuracy: 58150/60000 (96.92%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1104,                   Accuracy: 58017/60000 (96.69%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1052,                   Accuracy: 58119/60000 (96.86%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1045,                   Accuracy: 58134/60000 (96.89%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1033,                   Accuracy: 58160/60000 (96.93%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1053,                   Accuracy: 58152/60000 (96.92%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1082,                   Accuracy: 58130/60000 (96.88%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1047,                   Accuracy: 58206/60000 (97.01%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1063,                   Accuracy: 58122/60000 (96.87%)
{0: tensor(97.0517), 10: tensor(96.7100), 20: tensor(96.8850), 30: tensor(96.8600), 40: tensor(96.8567), 50: tensor(96.8083), 60: tensor(96.7533), 70: tensor(96.8600), 80: tensor(96.8050), 90: tensor(96.9633), 100: tensor(96.5633), 110: tensor(96.8450), 120: tensor(96.8117), 130: tensor(96.7900), 140: tensor(96.6267), 150: tensor(96.6050), 160: tensor(96.6033), 170: tensor(96.5350), 180: tensor(96.7517), 190: tensor(96.5233), 200: tensor(96.7550), 210: tensor(96.8500), 220: tensor(96.8700), 230: tensor(96.7917), 240: tensor(96.7783), 250: tensor(96.7600), 260: tensor(96.7300), 270: tensor(96.9167), 280: tensor(96.6950), 290: tensor(96.8650), 300: tensor(96.8900), 310: tensor(96.9333), 320: tensor(96.9200), 330: tensor(96.8833), 340: tensor(97.0100), 350: tensor(96.8700)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=26, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6394,                   Accuracy: 209/2000.0 (10.45%)



-= Testing valid =-
Test set: Average loss: 1.7871,                   Accuracy: 685/2000.0 (34.25%)



-= Testing valid =-
Test set: Average loss: 1.3994,                   Accuracy: 1142/2000.0 (57.10%)



-= Testing valid =-
Test set: Average loss: 1.2745,                   Accuracy: 1058/2000.0 (52.90%)



-= Testing valid =-
Test set: Average loss: 0.4463,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.6389,                   Accuracy: 1594/2000.0 (79.70%)



-= Testing valid =-
Test set: Average loss: 0.4352,                   Accuracy: 1739/2000.0 (86.95%)



-= Testing valid =-
Test set: Average loss: 0.4888,                   Accuracy: 1707/2000.0 (85.35%)



-= Testing valid =-
Test set: Average loss: 0.2151,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.3031,                   Accuracy: 1818/2000.0 (90.90%)



Epoch 10 train accuracy: 92.46%, valid accuracy 90.90%
-= Testing valid =-
Test set: Average loss: 0.2055,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.1847,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1480,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1553,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1332,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1454,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1935,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1733,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1506,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1712,                   Accuracy: 1901/2000.0 (95.05%)



Epoch 20 train accuracy: 95.28%, valid accuracy 95.05%
-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1168,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1127,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1153,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1142,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1328,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1160,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1120,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1072,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1124,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 30 train accuracy: 96.65%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.1048,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1046,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1042,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0947,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 40 train accuracy: 97.15%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 50 train accuracy: 96.94%, valid accuracy 97.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1098,                   Accuracy: 58152/60000 (96.92%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1182,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1151,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1197,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1191,                   Accuracy: 57975/60000 (96.62%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1198,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1187,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1105,                   Accuracy: 58105/60000 (96.84%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1097,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1118,                   Accuracy: 58116/60000 (96.86%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1205,                   Accuracy: 57931/60000 (96.55%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1166,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1209,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1211,                   Accuracy: 57873/60000 (96.46%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1224,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1204,                   Accuracy: 57893/60000 (96.49%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1119,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1150,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1134,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1204,                   Accuracy: 57914/60000 (96.52%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1164,                   Accuracy: 57983/60000 (96.64%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1197,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1208,                   Accuracy: 57905/60000 (96.51%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1210,                   Accuracy: 57944/60000 (96.57%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1182,                   Accuracy: 57966/60000 (96.61%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1104,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1105,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1102,                   Accuracy: 58132/60000 (96.89%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1176,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1149,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1189,                   Accuracy: 57983/60000 (96.64%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1193,                   Accuracy: 57982/60000 (96.64%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1186,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1166,                   Accuracy: 58028/60000 (96.71%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1091,                   Accuracy: 58147/60000 (96.91%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1069,                   Accuracy: 58234/60000 (97.06%)
{0: tensor(96.9200), 10: tensor(96.6733), 20: tensor(96.7267), 30: tensor(96.6183), 40: tensor(96.6250), 50: tensor(96.5717), 60: tensor(96.6733), 70: tensor(96.8417), 80: tensor(96.8750), 90: tensor(96.8600), 100: tensor(96.5517), 110: tensor(96.5550), 120: tensor(96.5333), 130: tensor(96.4550), 140: tensor(96.4983), 150: tensor(96.4883), 160: tensor(96.7633), 170: tensor(96.5883), 180: tensor(96.7400), 190: tensor(96.5233), 200: tensor(96.6383), 210: tensor(96.5333), 220: tensor(96.5083), 230: tensor(96.5733), 240: tensor(96.6100), 250: tensor(96.8333), 260: tensor(96.8283), 270: tensor(96.8867), 280: tensor(96.6333), 290: tensor(96.6517), 300: tensor(96.6383), 310: tensor(96.6367), 320: tensor(96.6883), 330: tensor(96.7133), 340: tensor(96.9117), 350: tensor(97.0567)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=27, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6153,                   Accuracy: 309/2000.0 (15.45%)



-= Testing valid =-
Test set: Average loss: 0.9336,                   Accuracy: 1347/2000.0 (67.35%)



-= Testing valid =-
Test set: Average loss: 1.1282,                   Accuracy: 1172/2000.0 (58.60%)



-= Testing valid =-
Test set: Average loss: 0.3228,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2693,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.3638,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.2277,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.2020,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.1889,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.2499,                   Accuracy: 1841/2000.0 (92.05%)



Epoch 10 train accuracy: 94.04%, valid accuracy 92.05%
-= Testing valid =-
Test set: Average loss: 0.1303,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1679,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1409,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1493,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1159,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1151,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1130,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1340,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1067,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1122,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 20 train accuracy: 95.72%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1167,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1134,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1091,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1030,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 30 train accuracy: 96.80%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 40 train accuracy: 97.21%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0756,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 50 train accuracy: 97.53%, valid accuracy 97.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0979,                   Accuracy: 58289/60000 (97.15%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1063,                   Accuracy: 58138/60000 (96.90%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1031,                   Accuracy: 58167/60000 (96.94%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1051,                   Accuracy: 58143/60000 (96.90%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1073,                   Accuracy: 58104/60000 (96.84%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1099,                   Accuracy: 58084/60000 (96.81%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1111,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1081,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1090,                   Accuracy: 58073/60000 (96.79%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1049,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1152,                   Accuracy: 57958/60000 (96.60%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1100,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1133,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1155,                   Accuracy: 57918/60000 (96.53%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1188,                   Accuracy: 57859/60000 (96.43%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1193,                   Accuracy: 57831/60000 (96.39%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1152,                   Accuracy: 57949/60000 (96.58%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1183,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1107,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1139,                   Accuracy: 57949/60000 (96.58%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1119,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1127,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1104,                   Accuracy: 57990/60000 (96.65%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1119,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1107,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1055,                   Accuracy: 58130/60000 (96.88%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1063,                   Accuracy: 58089/60000 (96.82%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1005,                   Accuracy: 58215/60000 (97.03%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1036,                   Accuracy: 58180/60000 (96.97%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1033,                   Accuracy: 58167/60000 (96.94%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1044,                   Accuracy: 58144/60000 (96.91%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1041,                   Accuracy: 58164/60000 (96.94%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1045,                   Accuracy: 58173/60000 (96.96%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1047,                   Accuracy: 58154/60000 (96.92%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1015,                   Accuracy: 58248/60000 (97.08%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1015,                   Accuracy: 58236/60000 (97.06%)
{0: tensor(97.1483), 10: tensor(96.8967), 20: tensor(96.9450), 30: tensor(96.9050), 40: tensor(96.8400), 50: tensor(96.8067), 60: tensor(96.7433), 70: tensor(96.8483), 80: tensor(96.7883), 90: tensor(96.9100), 100: tensor(96.5967), 110: tensor(96.7633), 120: tensor(96.5783), 130: tensor(96.5300), 140: tensor(96.4317), 150: tensor(96.3850), 160: tensor(96.5817), 170: tensor(96.3833), 180: tensor(96.6600), 190: tensor(96.5817), 200: tensor(96.6150), 210: tensor(96.6183), 220: tensor(96.6500), 230: tensor(96.6667), 240: tensor(96.6883), 250: tensor(96.8833), 260: tensor(96.8150), 270: tensor(97.0250), 280: tensor(96.9667), 290: tensor(96.9450), 300: tensor(96.9067), 310: tensor(96.9400), 320: tensor(96.9550), 330: tensor(96.9233), 340: tensor(97.0800), 350: tensor(97.0600)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=28, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8721,                   Accuracy: 604/2000.0 (30.20%)



-= Testing valid =-
Test set: Average loss: 1.5698,                   Accuracy: 834/2000.0 (41.70%)



-= Testing valid =-
Test set: Average loss: 0.7868,                   Accuracy: 1505/2000.0 (75.25%)



-= Testing valid =-
Test set: Average loss: 0.4990,                   Accuracy: 1726/2000.0 (86.30%)



-= Testing valid =-
Test set: Average loss: 0.3705,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.7229,                   Accuracy: 1534/2000.0 (76.70%)



-= Testing valid =-
Test set: Average loss: 0.2721,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2526,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.2829,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2364,                   Accuracy: 1872/2000.0 (93.60%)



Epoch 10 train accuracy: 93.64%, valid accuracy 93.60%
-= Testing valid =-
Test set: Average loss: 0.1755,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1751,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1368,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1405,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1353,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1288,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1413,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1222,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1896,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1331,                   Accuracy: 1922/2000.0 (96.10%)



Epoch 20 train accuracy: 96.04%, valid accuracy 96.10%
-= Testing valid =-
Test set: Average loss: 0.1344,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1181,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1212,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1305,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1206,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1190,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1319,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1165,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1082,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 30 train accuracy: 96.18%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.1150,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1104,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1033,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 40 train accuracy: 97.12%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.1015,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0981,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 50 train accuracy: 97.18%, valid accuracy 97.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1012,                   Accuracy: 58252/60000 (97.09%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1130,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1068,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1111,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1164,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1231,                   Accuracy: 57852/60000 (96.42%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1249,                   Accuracy: 57833/60000 (96.39%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1185,                   Accuracy: 57946/60000 (96.58%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1164,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1061,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1168,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1104,                   Accuracy: 57978/60000 (96.63%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1121,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1175,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1246,                   Accuracy: 57833/60000 (96.39%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1265,                   Accuracy: 57780/60000 (96.30%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1218,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1220,                   Accuracy: 57735/60000 (96.22%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1095,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1206,                   Accuracy: 57845/60000 (96.41%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1112,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1127,                   Accuracy: 58011/60000 (96.68%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1165,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1228,                   Accuracy: 57862/60000 (96.44%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1241,                   Accuracy: 57862/60000 (96.44%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1174,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1140,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1035,                   Accuracy: 58207/60000 (97.01%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1143,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1058,                   Accuracy: 58129/60000 (96.88%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1095,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1142,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1202,                   Accuracy: 57918/60000 (96.53%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1214,                   Accuracy: 57880/60000 (96.47%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1143,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1104,                   Accuracy: 58018/60000 (96.70%)
{0: tensor(97.0867), 10: tensor(96.7083), 20: tensor(96.8100), 30: tensor(96.7017), 40: tensor(96.5617), 50: tensor(96.4200), 60: tensor(96.3883), 70: tensor(96.5767), 80: tensor(96.4717), 90: tensor(96.9217), 100: tensor(96.5183), 110: tensor(96.6300), 120: tensor(96.6883), 130: tensor(96.5383), 140: tensor(96.3883), 150: tensor(96.3000), 160: tensor(96.4467), 170: tensor(96.2250), 180: tensor(96.7467), 190: tensor(96.4083), 200: tensor(96.6600), 210: tensor(96.6850), 220: tensor(96.6033), 230: tensor(96.4367), 240: tensor(96.4367), 250: tensor(96.6400), 260: tensor(96.6217), 270: tensor(97.0117), 280: tensor(96.6217), 290: tensor(96.8817), 300: tensor(96.7867), 310: tensor(96.6633), 320: tensor(96.5300), 330: tensor(96.4667), 340: tensor(96.6667), 350: tensor(96.6967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=29, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8752,                   Accuracy: 603/2000.0 (30.15%)



-= Testing valid =-
Test set: Average loss: 1.5284,                   Accuracy: 911/2000.0 (45.55%)



-= Testing valid =-
Test set: Average loss: 0.8890,                   Accuracy: 1406/2000.0 (70.30%)



-= Testing valid =-
Test set: Average loss: 0.4856,                   Accuracy: 1735/2000.0 (86.75%)



-= Testing valid =-
Test set: Average loss: 0.3504,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.3628,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.1883,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.3935,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.4238,                   Accuracy: 1738/2000.0 (86.90%)



-= Testing valid =-
Test set: Average loss: 0.1479,                   Accuracy: 1910/2000.0 (95.50%)



Epoch 10 train accuracy: 92.84%, valid accuracy 95.50%
-= Testing valid =-
Test set: Average loss: 0.1877,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1526,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1552,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1268,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1307,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1512,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1268,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1447,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1316,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1346,                   Accuracy: 1917/2000.0 (95.85%)



Epoch 20 train accuracy: 96.26%, valid accuracy 95.85%
-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1212,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1070,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1277,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1017,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 30 train accuracy: 96.57%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 40 train accuracy: 97.34%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 50 train accuracy: 97.29%, valid accuracy 97.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0949,                   Accuracy: 58376/60000 (97.29%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1035,                   Accuracy: 58213/60000 (97.02%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1032,                   Accuracy: 58208/60000 (97.01%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1058,                   Accuracy: 58167/60000 (96.94%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1052,                   Accuracy: 58175/60000 (96.96%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1026,                   Accuracy: 58219/60000 (97.03%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1005,                   Accuracy: 58237/60000 (97.06%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0979,                   Accuracy: 58258/60000 (97.10%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1004,                   Accuracy: 58208/60000 (97.01%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0958,                   Accuracy: 58326/60000 (97.21%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1035,                   Accuracy: 58171/60000 (96.95%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1028,                   Accuracy: 58208/60000 (97.01%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1044,                   Accuracy: 58197/60000 (97.00%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1040,                   Accuracy: 58192/60000 (96.99%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1010,                   Accuracy: 58234/60000 (97.06%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1003,                   Accuracy: 58212/60000 (97.02%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.0969,                   Accuracy: 58328/60000 (97.21%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1007,                   Accuracy: 58211/60000 (97.02%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0940,                   Accuracy: 58363/60000 (97.27%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1018,                   Accuracy: 58216/60000 (97.03%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1008,                   Accuracy: 58255/60000 (97.09%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1020,                   Accuracy: 58228/60000 (97.05%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1011,                   Accuracy: 58226/60000 (97.04%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.0984,                   Accuracy: 58268/60000 (97.11%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.0972,                   Accuracy: 58294/60000 (97.16%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.0953,                   Accuracy: 58338/60000 (97.23%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.0961,                   Accuracy: 58330/60000 (97.22%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0931,                   Accuracy: 58409/60000 (97.35%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1021,                   Accuracy: 58225/60000 (97.04%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1004,                   Accuracy: 58247/60000 (97.08%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1026,                   Accuracy: 58233/60000 (97.06%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1022,                   Accuracy: 58237/60000 (97.06%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.0996,                   Accuracy: 58253/60000 (97.09%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0977,                   Accuracy: 58316/60000 (97.19%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0959,                   Accuracy: 58354/60000 (97.26%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0966,                   Accuracy: 58293/60000 (97.15%)
{0: tensor(97.2933), 10: tensor(97.0217), 20: tensor(97.0133), 30: tensor(96.9450), 40: tensor(96.9583), 50: tensor(97.0317), 60: tensor(97.0617), 70: tensor(97.0967), 80: tensor(97.0133), 90: tensor(97.2100), 100: tensor(96.9517), 110: tensor(97.0133), 120: tensor(96.9950), 130: tensor(96.9867), 140: tensor(97.0567), 150: tensor(97.0200), 160: tensor(97.2133), 170: tensor(97.0183), 180: tensor(97.2717), 190: tensor(97.0267), 200: tensor(97.0917), 210: tensor(97.0467), 220: tensor(97.0433), 230: tensor(97.1133), 240: tensor(97.1567), 250: tensor(97.2300), 260: tensor(97.2167), 270: tensor(97.3483), 280: tensor(97.0417), 290: tensor(97.0783), 300: tensor(97.0550), 310: tensor(97.0617), 320: tensor(97.0883), 330: tensor(97.1933), 340: tensor(97.2567), 350: tensor(97.1550)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=30, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.4438,                   Accuracy: 265/2000.0 (13.25%)



-= Testing valid =-
Test set: Average loss: 1.4927,                   Accuracy: 899/2000.0 (44.95%)



-= Testing valid =-
Test set: Average loss: 0.7576,                   Accuracy: 1577/2000.0 (78.85%)



-= Testing valid =-
Test set: Average loss: 1.5503,                   Accuracy: 1047/2000.0 (52.35%)



-= Testing valid =-
Test set: Average loss: 0.4173,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.7087,                   Accuracy: 1545/2000.0 (77.25%)



-= Testing valid =-
Test set: Average loss: 0.2817,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.3234,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2997,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.1800,                   Accuracy: 1889/2000.0 (94.45%)



Epoch 10 train accuracy: 92.53%, valid accuracy 94.45%
-= Testing valid =-
Test set: Average loss: 0.1495,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1375,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1361,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1153,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1765,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1209,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1358,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1036,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 20 train accuracy: 95.61%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1011,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 30 train accuracy: 96.40%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0639,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0723,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0711,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0712,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 40 train accuracy: 96.71%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0600,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0636,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0655,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0691,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0614,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0657,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 50 train accuracy: 97.11%, valid accuracy 97.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0959,                   Accuracy: 58330/60000 (97.22%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1096,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1074,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1108,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1134,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1158,                   Accuracy: 58012/60000 (96.69%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1137,                   Accuracy: 58029/60000 (96.71%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1136,                   Accuracy: 57994/60000 (96.66%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1149,                   Accuracy: 57979/60000 (96.63%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1017,                   Accuracy: 58217/60000 (97.03%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1137,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1106,                   Accuracy: 58012/60000 (96.69%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1171,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1187,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1197,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1178,                   Accuracy: 57924/60000 (96.54%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1150,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1183,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1056,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1156,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1100,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1128,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1138,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1139,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1113,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1081,                   Accuracy: 58138/60000 (96.90%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1091,                   Accuracy: 58101/60000 (96.83%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0984,                   Accuracy: 58272/60000 (97.12%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1112,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1062,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1059,                   Accuracy: 58117/60000 (96.86%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1094,                   Accuracy: 58092/60000 (96.82%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1105,                   Accuracy: 58119/60000 (96.86%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1075,                   Accuracy: 58145/60000 (96.91%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1071,                   Accuracy: 58145/60000 (96.91%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1069,                   Accuracy: 58124/60000 (96.87%)
{0: tensor(97.2167), 10: tensor(96.8167), 20: tensor(96.8467), 30: tensor(96.7517), 40: tensor(96.7417), 50: tensor(96.6867), 60: tensor(96.7150), 70: tensor(96.6567), 80: tensor(96.6317), 90: tensor(97.0283), 100: tensor(96.6400), 110: tensor(96.6867), 120: tensor(96.4733), 130: tensor(96.5283), 140: tensor(96.5133), 150: tensor(96.5400), 160: tensor(96.6183), 170: tensor(96.4633), 180: tensor(96.8533), 190: tensor(96.5367), 200: tensor(96.6767), 210: tensor(96.5383), 220: tensor(96.6683), 230: tensor(96.7550), 240: tensor(96.7400), 250: tensor(96.8967), 260: tensor(96.8350), 270: tensor(97.1200), 280: tensor(96.7333), 290: tensor(96.8533), 300: tensor(96.8617), 310: tensor(96.8200), 320: tensor(96.8650), 330: tensor(96.9083), 340: tensor(96.9083), 350: tensor(96.8733)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=31, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8342,                   Accuracy: 656/2000.0 (32.80%)



-= Testing valid =-
Test set: Average loss: 2.3703,                   Accuracy: 624/2000.0 (31.20%)



-= Testing valid =-
Test set: Average loss: 1.6747,                   Accuracy: 932/2000.0 (46.60%)



-= Testing valid =-
Test set: Average loss: 0.4546,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.4951,                   Accuracy: 1670/2000.0 (83.50%)



-= Testing valid =-
Test set: Average loss: 0.2280,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2835,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.2737,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.1796,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.2083,                   Accuracy: 1863/2000.0 (93.15%)



Epoch 10 train accuracy: 93.70%, valid accuracy 93.15%
-= Testing valid =-
Test set: Average loss: 0.1381,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1267,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1461,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1704,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1253,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1293,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1362,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 20 train accuracy: 95.61%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1030,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 30 train accuracy: 96.84%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.0790,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 40 train accuracy: 96.99%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 50 train accuracy: 97.26%, valid accuracy 97.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1019,                   Accuracy: 58221/60000 (97.04%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1058,                   Accuracy: 58145/60000 (96.91%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0984,                   Accuracy: 58228/60000 (97.05%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1044,                   Accuracy: 58169/60000 (96.95%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1048,                   Accuracy: 58176/60000 (96.96%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1112,                   Accuracy: 58092/60000 (96.82%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1163,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1121,                   Accuracy: 58057/60000 (96.76%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1123,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1091,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1132,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1070,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1103,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1110,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1174,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1217,                   Accuracy: 57857/60000 (96.43%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1178,                   Accuracy: 57965/60000 (96.61%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1178,                   Accuracy: 57870/60000 (96.45%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1119,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1131,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1076,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1086,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1076,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1124,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1149,                   Accuracy: 57997/60000 (96.66%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1098,                   Accuracy: 58083/60000 (96.81%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1114,                   Accuracy: 58002/60000 (96.67%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1041,                   Accuracy: 58182/60000 (96.97%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1061,                   Accuracy: 58148/60000 (96.91%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0991,                   Accuracy: 58257/60000 (97.10%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1030,                   Accuracy: 58200/60000 (97.00%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1022,                   Accuracy: 58240/60000 (97.07%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1067,                   Accuracy: 58171/60000 (96.95%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1110,                   Accuracy: 58098/60000 (96.83%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1054,                   Accuracy: 58186/60000 (96.98%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1071,                   Accuracy: 58111/60000 (96.85%)
{0: tensor(97.0350), 10: tensor(96.9083), 20: tensor(97.0467), 30: tensor(96.9483), 40: tensor(96.9600), 50: tensor(96.8200), 60: tensor(96.6233), 70: tensor(96.7617), 80: tensor(96.7050), 90: tensor(96.8217), 100: tensor(96.6800), 110: tensor(96.7667), 120: tensor(96.7517), 130: tensor(96.7583), 140: tensor(96.5700), 150: tensor(96.4283), 160: tensor(96.6083), 170: tensor(96.4500), 180: tensor(96.7050), 190: tensor(96.6650), 200: tensor(96.8167), 210: tensor(96.8100), 220: tensor(96.8750), 230: tensor(96.7567), 240: tensor(96.6617), 250: tensor(96.8050), 260: tensor(96.6700), 270: tensor(96.9700), 280: tensor(96.9133), 290: tensor(97.0950), 300: tensor(97.), 310: tensor(97.0667), 320: tensor(96.9517), 330: tensor(96.8300), 340: tensor(96.9767), 350: tensor(96.8517)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=32, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3515,                   Accuracy: 328/2000.0 (16.40%)



-= Testing valid =-
Test set: Average loss: 1.6107,                   Accuracy: 872/2000.0 (43.60%)



-= Testing valid =-
Test set: Average loss: 0.8446,                   Accuracy: 1459/2000.0 (72.95%)



-= Testing valid =-
Test set: Average loss: 0.8157,                   Accuracy: 1467/2000.0 (73.35%)



-= Testing valid =-
Test set: Average loss: 0.4319,                   Accuracy: 1682/2000.0 (84.10%)



-= Testing valid =-
Test set: Average loss: 0.3080,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2875,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2873,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.1871,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.2474,                   Accuracy: 1848/2000.0 (92.40%)



Epoch 10 train accuracy: 93.20%, valid accuracy 92.40%
-= Testing valid =-
Test set: Average loss: 0.1466,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1454,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1542,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1248,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1500,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1195,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1196,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1137,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1225,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1305,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 20 train accuracy: 95.76%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.1298,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1364,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1115,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 30 train accuracy: 96.70%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1153,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1059,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1010,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 40 train accuracy: 97.09%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0825,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 50 train accuracy: 97.10%, valid accuracy 97.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1156,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1189,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1134,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1192,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1187,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1198,                   Accuracy: 57940/60000 (96.57%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1199,                   Accuracy: 57954/60000 (96.59%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1126,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1182,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1173,                   Accuracy: 57994/60000 (96.66%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1209,                   Accuracy: 57880/60000 (96.47%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1159,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1206,                   Accuracy: 57852/60000 (96.42%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1200,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1213,                   Accuracy: 57882/60000 (96.47%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1213,                   Accuracy: 57900/60000 (96.50%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1109,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1187,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1145,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1193,                   Accuracy: 57879/60000 (96.46%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1140,                   Accuracy: 57993/60000 (96.65%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1171,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1146,                   Accuracy: 58002/60000 (96.67%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1160,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1157,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1081,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1137,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1112,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1160,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1105,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1151,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1138,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1159,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1159,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1107,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1151,                   Accuracy: 58024/60000 (96.71%)
{0: tensor(96.7433), 10: tensor(96.5850), 20: tensor(96.7383), 30: tensor(96.5633), 40: tensor(96.5283), 50: tensor(96.5667), 60: tensor(96.5900), 70: tensor(96.7167), 80: tensor(96.5117), 90: tensor(96.6567), 100: tensor(96.4667), 110: tensor(96.5833), 120: tensor(96.4200), 130: tensor(96.4483), 140: tensor(96.4700), 150: tensor(96.5000), 160: tensor(96.7267), 170: tensor(96.4767), 180: tensor(96.6483), 190: tensor(96.4650), 200: tensor(96.6550), 210: tensor(96.5867), 220: tensor(96.6700), 230: tensor(96.6750), 240: tensor(96.6933), 250: tensor(96.8533), 260: tensor(96.7600), 270: tensor(96.8667), 280: tensor(96.6417), 290: tensor(96.8450), 300: tensor(96.6733), 310: tensor(96.6750), 320: tensor(96.7283), 330: tensor(96.7433), 340: tensor(96.8100), 350: tensor(96.7067)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=33, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.4472,                   Accuracy: 447/2000.0 (22.35%)



-= Testing valid =-
Test set: Average loss: 2.6557,                   Accuracy: 392/2000.0 (19.60%)



-= Testing valid =-
Test set: Average loss: 3.7769,                   Accuracy: 417/2000.0 (20.85%)



-= Testing valid =-
Test set: Average loss: 0.8742,                   Accuracy: 1432/2000.0 (71.60%)



-= Testing valid =-
Test set: Average loss: 0.4112,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.3907,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.3645,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.2880,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.1382,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1494,                   Accuracy: 1899/2000.0 (94.95%)



Epoch 10 train accuracy: 93.32%, valid accuracy 94.95%
-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1046,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1180,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1088,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1280,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.1012,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 20 train accuracy: 95.69%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0736,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0630,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0599,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0589,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0600,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 30 train accuracy: 96.25%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0592,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0619,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0597,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0638,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 40 train accuracy: 96.80%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0595,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0534,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0578,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0608,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 50 train accuracy: 97.00%, valid accuracy 98.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1066,                   Accuracy: 58104/60000 (96.84%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1229,                   Accuracy: 57794/60000 (96.32%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1156,                   Accuracy: 57914/60000 (96.52%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1175,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1178,                   Accuracy: 57843/60000 (96.40%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1151,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1129,                   Accuracy: 57909/60000 (96.51%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1090,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1142,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1085,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1245,                   Accuracy: 57703/60000 (96.17%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1157,                   Accuracy: 57867/60000 (96.44%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1217,                   Accuracy: 57734/60000 (96.22%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1189,                   Accuracy: 57791/60000 (96.32%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1163,                   Accuracy: 57810/60000 (96.35%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1141,                   Accuracy: 57843/60000 (96.40%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1092,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1159,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1102,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1229,                   Accuracy: 57746/60000 (96.24%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1143,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1192,                   Accuracy: 57793/60000 (96.32%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1146,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1120,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1097,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1043,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1097,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1068,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1201,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1138,                   Accuracy: 57955/60000 (96.59%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1150,                   Accuracy: 57940/60000 (96.57%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1137,                   Accuracy: 57924/60000 (96.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1116,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1088,                   Accuracy: 58022/60000 (96.70%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1058,                   Accuracy: 58094/60000 (96.82%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1099,                   Accuracy: 58062/60000 (96.77%)
{0: tensor(96.8400), 10: tensor(96.3233), 20: tensor(96.5233), 30: tensor(96.4467), 40: tensor(96.4050), 50: tensor(96.4633), 60: tensor(96.5150), 70: tensor(96.7117), 80: tensor(96.5833), 90: tensor(96.7517), 100: tensor(96.1717), 110: tensor(96.4450), 120: tensor(96.2233), 130: tensor(96.3183), 140: tensor(96.3500), 150: tensor(96.4050), 160: tensor(96.5633), 170: tensor(96.4850), 180: tensor(96.6683), 190: tensor(96.2433), 200: tensor(96.4917), 210: tensor(96.3217), 220: tensor(96.4533), 230: tensor(96.5450), 240: tensor(96.6267), 250: tensor(96.8017), 260: tensor(96.7117), 270: tensor(96.8100), 280: tensor(96.4433), 290: tensor(96.5917), 300: tensor(96.5667), 310: tensor(96.5400), 320: tensor(96.6417), 330: tensor(96.7033), 340: tensor(96.8233), 350: tensor(96.7700)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=34, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6642,                   Accuracy: 306/2000.0 (15.30%)



-= Testing valid =-
Test set: Average loss: 2.2397,                   Accuracy: 483/2000.0 (24.15%)



-= Testing valid =-
Test set: Average loss: 1.7965,                   Accuracy: 693/2000.0 (34.65%)



-= Testing valid =-
Test set: Average loss: 1.5263,                   Accuracy: 936/2000.0 (46.80%)



-= Testing valid =-
Test set: Average loss: 0.7237,                   Accuracy: 1514/2000.0 (75.70%)



-= Testing valid =-
Test set: Average loss: 0.3420,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.9608,                   Accuracy: 1418/2000.0 (70.90%)



-= Testing valid =-
Test set: Average loss: 0.2731,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2573,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2908,                   Accuracy: 1811/2000.0 (90.55%)



Epoch 10 train accuracy: 92.47%, valid accuracy 90.55%
-= Testing valid =-
Test set: Average loss: 0.1518,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1489,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1530,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1644,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1510,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1526,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1441,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1556,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1509,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1505,                   Accuracy: 1912/2000.0 (95.60%)



Epoch 20 train accuracy: 95.14%, valid accuracy 95.60%
-= Testing valid =-
Test set: Average loss: 0.1130,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1128,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1128,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1234,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1132,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1135,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1530,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1145,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 30 train accuracy: 96.32%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1059,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 40 train accuracy: 96.89%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 50 train accuracy: 97.12%, valid accuracy 97.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0991,                   Accuracy: 58281/60000 (97.14%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1139,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1179,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1206,                   Accuracy: 57882/60000 (96.47%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1204,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1186,                   Accuracy: 57892/60000 (96.49%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1121,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1076,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1043,                   Accuracy: 58132/60000 (96.89%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1024,                   Accuracy: 58217/60000 (97.03%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1174,                   Accuracy: 57918/60000 (96.53%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1202,                   Accuracy: 57870/60000 (96.45%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1212,                   Accuracy: 57859/60000 (96.43%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1211,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1197,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1133,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1075,                   Accuracy: 58087/60000 (96.81%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1099,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1031,                   Accuracy: 58196/60000 (96.99%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1185,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1186,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1178,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1158,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1132,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1073,                   Accuracy: 58089/60000 (96.82%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1025,                   Accuracy: 58209/60000 (97.01%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1031,                   Accuracy: 58180/60000 (96.97%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0990,                   Accuracy: 58292/60000 (97.15%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1129,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1147,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1167,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1162,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1134,                   Accuracy: 58011/60000 (96.68%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1072,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1039,                   Accuracy: 58183/60000 (96.97%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1004,                   Accuracy: 58238/60000 (97.06%)
{0: tensor(97.1350), 10: tensor(96.6833), 20: tensor(96.5683), 30: tensor(96.4700), 40: tensor(96.4917), 50: tensor(96.4867), 60: tensor(96.6933), 70: tensor(96.8750), 80: tensor(96.8867), 90: tensor(97.0283), 100: tensor(96.5300), 110: tensor(96.4500), 120: tensor(96.4317), 130: tensor(96.4600), 140: tensor(96.4617), 150: tensor(96.6117), 160: tensor(96.8117), 170: tensor(96.7267), 180: tensor(96.9933), 190: tensor(96.4583), 200: tensor(96.5367), 210: tensor(96.5600), 220: tensor(96.5600), 230: tensor(96.7000), 240: tensor(96.8150), 250: tensor(97.0150), 260: tensor(96.9667), 270: tensor(97.1533), 280: tensor(96.7550), 290: tensor(96.6333), 300: tensor(96.6233), 310: tensor(96.5583), 320: tensor(96.6850), 330: tensor(96.8383), 340: tensor(96.9717), 350: tensor(97.0633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=35, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.5780,                   Accuracy: 221/2000.0 (11.05%)



-= Testing valid =-
Test set: Average loss: 1.7107,                   Accuracy: 708/2000.0 (35.40%)



-= Testing valid =-
Test set: Average loss: 1.7651,                   Accuracy: 758/2000.0 (37.90%)



-= Testing valid =-
Test set: Average loss: 0.8537,                   Accuracy: 1487/2000.0 (74.35%)



-= Testing valid =-
Test set: Average loss: 0.7532,                   Accuracy: 1455/2000.0 (72.75%)



-= Testing valid =-
Test set: Average loss: 0.3918,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.4131,                   Accuracy: 1752/2000.0 (87.60%)



-= Testing valid =-
Test set: Average loss: 0.3621,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.3376,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.2099,                   Accuracy: 1872/2000.0 (93.60%)



Epoch 10 train accuracy: 92.15%, valid accuracy 93.60%
-= Testing valid =-
Test set: Average loss: 0.2845,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.1704,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1681,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1644,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1983,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1477,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1810,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1364,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1618,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1622,                   Accuracy: 1908/2000.0 (95.40%)



Epoch 20 train accuracy: 95.29%, valid accuracy 95.40%
-= Testing valid =-
Test set: Average loss: 0.1293,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1168,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1312,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1230,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1381,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1536,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1400,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1419,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1384,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 30 train accuracy: 96.12%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.1271,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1075,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1239,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1149,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1126,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 40 train accuracy: 96.78%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1104,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1166,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1080,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1097,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1003,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1074,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 50 train accuracy: 97.05%, valid accuracy 97.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1225,                   Accuracy: 57931/60000 (96.55%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1375,                   Accuracy: 57659/60000 (96.10%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1309,                   Accuracy: 57789/60000 (96.32%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1370,                   Accuracy: 57653/60000 (96.09%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1349,                   Accuracy: 57727/60000 (96.21%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1352,                   Accuracy: 57722/60000 (96.20%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1306,                   Accuracy: 57788/60000 (96.31%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1234,                   Accuracy: 57949/60000 (96.58%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1281,                   Accuracy: 57801/60000 (96.33%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1194,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1319,                   Accuracy: 57755/60000 (96.26%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1273,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1322,                   Accuracy: 57748/60000 (96.25%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1326,                   Accuracy: 57778/60000 (96.30%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1343,                   Accuracy: 57698/60000 (96.16%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1329,                   Accuracy: 57736/60000 (96.23%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1260,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1327,                   Accuracy: 57702/60000 (96.17%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1253,                   Accuracy: 57901/60000 (96.50%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1393,                   Accuracy: 57564/60000 (95.94%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1305,                   Accuracy: 57798/60000 (96.33%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1333,                   Accuracy: 57715/60000 (96.19%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1329,                   Accuracy: 57741/60000 (96.24%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1341,                   Accuracy: 57702/60000 (96.17%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1330,                   Accuracy: 57702/60000 (96.17%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1263,                   Accuracy: 57825/60000 (96.38%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1325,                   Accuracy: 57722/60000 (96.20%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1274,                   Accuracy: 57836/60000 (96.39%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1438,                   Accuracy: 57496/60000 (95.83%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1339,                   Accuracy: 57741/60000 (96.24%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1381,                   Accuracy: 57638/60000 (96.06%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1356,                   Accuracy: 57687/60000 (96.14%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1350,                   Accuracy: 57695/60000 (96.16%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1321,                   Accuracy: 57742/60000 (96.24%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1244,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1292,                   Accuracy: 57796/60000 (96.33%)
{0: tensor(96.5517), 10: tensor(96.0983), 20: tensor(96.3150), 30: tensor(96.0883), 40: tensor(96.2117), 50: tensor(96.2033), 60: tensor(96.3133), 70: tensor(96.5817), 80: tensor(96.3350), 90: tensor(96.6667), 100: tensor(96.2583), 110: tensor(96.4350), 120: tensor(96.2467), 130: tensor(96.2967), 140: tensor(96.1633), 150: tensor(96.2267), 160: tensor(96.4117), 170: tensor(96.1700), 180: tensor(96.5017), 190: tensor(95.9400), 200: tensor(96.3300), 210: tensor(96.1917), 220: tensor(96.2350), 230: tensor(96.1700), 240: tensor(96.1700), 250: tensor(96.3750), 260: tensor(96.2033), 270: tensor(96.3933), 280: tensor(95.8267), 290: tensor(96.2350), 300: tensor(96.0633), 310: tensor(96.1450), 320: tensor(96.1583), 330: tensor(96.2367), 340: tensor(96.5317), 350: tensor(96.3267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=36, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.7168,                   Accuracy: 199/2000.0 (9.95%)



-= Testing valid =-
Test set: Average loss: 1.8281,                   Accuracy: 706/2000.0 (35.30%)



-= Testing valid =-
Test set: Average loss: 0.8566,                   Accuracy: 1367/2000.0 (68.35%)



-= Testing valid =-
Test set: Average loss: 0.9770,                   Accuracy: 1404/2000.0 (70.20%)



-= Testing valid =-
Test set: Average loss: 0.7099,                   Accuracy: 1521/2000.0 (76.05%)



-= Testing valid =-
Test set: Average loss: 0.6526,                   Accuracy: 1515/2000.0 (75.75%)



-= Testing valid =-
Test set: Average loss: 0.3769,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.2923,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.1775,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1963,                   Accuracy: 1881/2000.0 (94.05%)



Epoch 10 train accuracy: 93.11%, valid accuracy 94.05%
-= Testing valid =-
Test set: Average loss: 0.1306,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1346,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1593,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1225,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1182,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1147,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1276,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1156,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1196,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 20 train accuracy: 95.59%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1107,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1222,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1067,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 30 train accuracy: 96.43%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0964,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0919,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0882,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 40 train accuracy: 96.78%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 50 train accuracy: 97.31%, valid accuracy 97.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1144,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1258,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1201,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1231,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1198,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1169,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1161,                   Accuracy: 58026/60000 (96.71%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1142,                   Accuracy: 58035/60000 (96.72%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1180,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1221,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1347,                   Accuracy: 57599/60000 (96.00%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1276,                   Accuracy: 57711/60000 (96.18%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1313,                   Accuracy: 57689/60000 (96.15%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1278,                   Accuracy: 57774/60000 (96.29%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1244,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1217,                   Accuracy: 57902/60000 (96.50%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1180,                   Accuracy: 57977/60000 (96.63%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1232,                   Accuracy: 57865/60000 (96.44%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1229,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1311,                   Accuracy: 57688/60000 (96.15%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1253,                   Accuracy: 57770/60000 (96.28%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1269,                   Accuracy: 57799/60000 (96.33%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1226,                   Accuracy: 57881/60000 (96.47%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1188,                   Accuracy: 57949/60000 (96.58%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1145,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1109,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1132,                   Accuracy: 58080/60000 (96.80%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1141,                   Accuracy: 58057/60000 (96.76%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1224,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1174,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1202,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1157,                   Accuracy: 58002/60000 (96.67%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1133,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1109,                   Accuracy: 58142/60000 (96.90%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1091,                   Accuracy: 58158/60000 (96.93%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1107,                   Accuracy: 58138/60000 (96.90%)
{0: tensor(96.7600), 10: tensor(96.3400), 20: tensor(96.4617), 30: tensor(96.4467), 40: tensor(96.5783), 50: tensor(96.6683), 60: tensor(96.7100), 70: tensor(96.7250), 80: tensor(96.6067), 90: tensor(96.4750), 100: tensor(95.9983), 110: tensor(96.1850), 120: tensor(96.1483), 130: tensor(96.2900), 140: tensor(96.4117), 150: tensor(96.5033), 160: tensor(96.6283), 170: tensor(96.4417), 180: tensor(96.4400), 190: tensor(96.1467), 200: tensor(96.2833), 210: tensor(96.3317), 220: tensor(96.4683), 230: tensor(96.5817), 240: tensor(96.7700), 250: tensor(96.8450), 260: tensor(96.8000), 270: tensor(96.7617), 280: tensor(96.4167), 290: tensor(96.5833), 300: tensor(96.5700), 310: tensor(96.6700), 320: tensor(96.7850), 330: tensor(96.9033), 340: tensor(96.9300), 350: tensor(96.8967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=37, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.6627,                   Accuracy: 764/2000.0 (38.20%)



-= Testing valid =-
Test set: Average loss: 2.9650,                   Accuracy: 259/2000.0 (12.95%)



-= Testing valid =-
Test set: Average loss: 1.0000,                   Accuracy: 1318/2000.0 (65.90%)



-= Testing valid =-
Test set: Average loss: 0.5098,                   Accuracy: 1715/2000.0 (85.75%)



-= Testing valid =-
Test set: Average loss: 0.6176,                   Accuracy: 1619/2000.0 (80.95%)



-= Testing valid =-
Test set: Average loss: 0.3957,                   Accuracy: 1752/2000.0 (87.60%)



-= Testing valid =-
Test set: Average loss: 0.1942,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1960,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1828,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1528,                   Accuracy: 1905/2000.0 (95.25%)



Epoch 10 train accuracy: 93.15%, valid accuracy 95.25%
-= Testing valid =-
Test set: Average loss: 0.1349,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1518,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1192,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1058,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1195,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1558,                   Accuracy: 1908/2000.0 (95.40%)



Epoch 20 train accuracy: 95.65%, valid accuracy 95.40%
-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1012,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0935,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 30 train accuracy: 96.66%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 40 train accuracy: 97.01%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 50 train accuracy: 97.09%, valid accuracy 97.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1017,                   Accuracy: 58286/60000 (97.14%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1120,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1040,                   Accuracy: 58192/60000 (96.99%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1059,                   Accuracy: 58163/60000 (96.94%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1044,                   Accuracy: 58182/60000 (96.97%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1013,                   Accuracy: 58228/60000 (97.05%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1021,                   Accuracy: 58212/60000 (97.02%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1002,                   Accuracy: 58187/60000 (96.98%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1057,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1076,                   Accuracy: 58138/60000 (96.90%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1204,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1137,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1140,                   Accuracy: 57975/60000 (96.62%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1135,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1126,                   Accuracy: 57981/60000 (96.64%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1118,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1094,                   Accuracy: 57979/60000 (96.63%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1156,                   Accuracy: 57842/60000 (96.40%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1153,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1298,                   Accuracy: 57598/60000 (96.00%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1185,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1163,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1127,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1087,                   Accuracy: 58087/60000 (96.81%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1064,                   Accuracy: 58118/60000 (96.86%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1016,                   Accuracy: 58161/60000 (96.93%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1037,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1049,                   Accuracy: 58197/60000 (97.00%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1169,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1064,                   Accuracy: 58139/60000 (96.90%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1070,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1037,                   Accuracy: 58208/60000 (97.01%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.0996,                   Accuracy: 58301/60000 (97.17%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0989,                   Accuracy: 58293/60000 (97.15%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0959,                   Accuracy: 58289/60000 (97.15%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0989,                   Accuracy: 58231/60000 (97.05%)
{0: tensor(97.1433), 10: tensor(96.7467), 20: tensor(96.9867), 30: tensor(96.9383), 40: tensor(96.9700), 50: tensor(97.0467), 60: tensor(97.0200), 70: tensor(96.9783), 80: tensor(96.8283), 90: tensor(96.8967), 100: tensor(96.4717), 110: tensor(96.6517), 120: tensor(96.6250), 130: tensor(96.6467), 140: tensor(96.6350), 150: tensor(96.6133), 160: tensor(96.6317), 170: tensor(96.4033), 180: tensor(96.5683), 190: tensor(95.9967), 200: tensor(96.4767), 210: tensor(96.6017), 220: tensor(96.6433), 230: tensor(96.8117), 240: tensor(96.8633), 250: tensor(96.9350), 260: tensor(96.8450), 270: tensor(96.9950), 280: tensor(96.6133), 290: tensor(96.8983), 300: tensor(96.9500), 310: tensor(97.0133), 320: tensor(97.1683), 330: tensor(97.1550), 340: tensor(97.1483), 350: tensor(97.0517)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=38, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.9371,                   Accuracy: 242/2000.0 (12.10%)



-= Testing valid =-
Test set: Average loss: 1.3186,                   Accuracy: 1213/2000.0 (60.65%)



-= Testing valid =-
Test set: Average loss: 0.7516,                   Accuracy: 1573/2000.0 (78.65%)



-= Testing valid =-
Test set: Average loss: 0.5244,                   Accuracy: 1670/2000.0 (83.50%)



-= Testing valid =-
Test set: Average loss: 0.3415,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3396,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.1947,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1577,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.2249,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.1876,                   Accuracy: 1901/2000.0 (95.05%)



Epoch 10 train accuracy: 93.62%, valid accuracy 95.05%
-= Testing valid =-
Test set: Average loss: 0.1552,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1169,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1299,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1176,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1194,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1121,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1224,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1272,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1606,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1015,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 20 train accuracy: 95.95%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1091,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1331,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0981,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 30 train accuracy: 96.62%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 40 train accuracy: 97.12%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0711,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 50 train accuracy: 97.25%, valid accuracy 97.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1058,                   Accuracy: 58144/60000 (96.91%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1059,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1010,                   Accuracy: 58251/60000 (97.08%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1090,                   Accuracy: 58119/60000 (96.86%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1131,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1148,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1140,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1086,                   Accuracy: 58074/60000 (96.79%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1098,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1063,                   Accuracy: 58136/60000 (96.89%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1084,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1017,                   Accuracy: 58194/60000 (96.99%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1064,                   Accuracy: 58160/60000 (96.93%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1139,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1190,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1171,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1158,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1201,                   Accuracy: 57808/60000 (96.35%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1122,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1147,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1051,                   Accuracy: 58092/60000 (96.82%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1090,                   Accuracy: 58066/60000 (96.78%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1138,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1178,                   Accuracy: 57906/60000 (96.51%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1181,                   Accuracy: 57888/60000 (96.48%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1135,                   Accuracy: 57959/60000 (96.60%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1144,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1095,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1096,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1028,                   Accuracy: 58137/60000 (96.89%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1106,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1125,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1134,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1144,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1071,                   Accuracy: 58111/60000 (96.85%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1070,                   Accuracy: 58106/60000 (96.84%)
{0: tensor(96.9067), 10: tensor(96.8767), 20: tensor(97.0850), 30: tensor(96.8650), 40: tensor(96.7567), 50: tensor(96.6133), 60: tensor(96.6017), 70: tensor(96.7900), 80: tensor(96.7350), 90: tensor(96.8933), 100: tensor(96.8167), 110: tensor(96.9900), 120: tensor(96.9333), 130: tensor(96.7067), 140: tensor(96.4617), 150: tensor(96.4917), 160: tensor(96.5067), 170: tensor(96.3467), 180: tensor(96.6400), 190: tensor(96.4917), 200: tensor(96.8200), 210: tensor(96.7767), 220: tensor(96.6667), 230: tensor(96.5100), 240: tensor(96.4800), 250: tensor(96.5983), 260: tensor(96.5750), 270: tensor(96.7850), 280: tensor(96.6733), 290: tensor(96.8950), 300: tensor(96.7567), 310: tensor(96.7450), 320: tensor(96.7117), 330: tensor(96.6333), 340: tensor(96.8517), 350: tensor(96.8433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=39, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.8952,                   Accuracy: 259/2000.0 (12.95%)



-= Testing valid =-
Test set: Average loss: 1.4753,                   Accuracy: 969/2000.0 (48.45%)



-= Testing valid =-
Test set: Average loss: 0.8528,                   Accuracy: 1380/2000.0 (69.00%)



-= Testing valid =-
Test set: Average loss: 1.2419,                   Accuracy: 1267/2000.0 (63.35%)



-= Testing valid =-
Test set: Average loss: 0.7008,                   Accuracy: 1573/2000.0 (78.65%)



-= Testing valid =-
Test set: Average loss: 0.2195,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2113,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.3158,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2289,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.1635,                   Accuracy: 1904/2000.0 (95.20%)



Epoch 10 train accuracy: 93.14%, valid accuracy 95.20%
-= Testing valid =-
Test set: Average loss: 0.1574,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1756,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1807,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1557,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1345,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1147,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1143,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1084,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1430,                   Accuracy: 1915/2000.0 (95.75%)



Epoch 20 train accuracy: 95.97%, valid accuracy 95.75%
-= Testing valid =-
Test set: Average loss: 0.1161,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1114,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1061,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1145,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1251,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1190,                   Accuracy: 1934/2000.0 (96.70%)



Epoch 30 train accuracy: 96.76%, valid accuracy 96.70%
-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0976,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 40 train accuracy: 96.84%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0909,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0947,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0882,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 50 train accuracy: 97.45%, valid accuracy 97.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0964,                   Accuracy: 58331/60000 (97.22%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1065,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1066,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1109,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1145,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1143,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1126,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1093,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1114,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1043,                   Accuracy: 58119/60000 (96.86%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1157,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1173,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1218,                   Accuracy: 57765/60000 (96.28%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1252,                   Accuracy: 57739/60000 (96.23%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1280,                   Accuracy: 57665/60000 (96.11%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1261,                   Accuracy: 57713/60000 (96.19%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1235,                   Accuracy: 57711/60000 (96.18%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1288,                   Accuracy: 57610/60000 (96.02%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1170,                   Accuracy: 57837/60000 (96.39%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1247,                   Accuracy: 57660/60000 (96.10%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1205,                   Accuracy: 57752/60000 (96.25%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1216,                   Accuracy: 57761/60000 (96.27%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1201,                   Accuracy: 57842/60000 (96.40%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1195,                   Accuracy: 57871/60000 (96.45%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1159,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1105,                   Accuracy: 58031/60000 (96.72%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1109,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1023,                   Accuracy: 58195/60000 (96.99%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1093,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1062,                   Accuracy: 58076/60000 (96.79%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1092,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1099,                   Accuracy: 58104/60000 (96.84%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1093,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1071,                   Accuracy: 58152/60000 (96.92%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1024,                   Accuracy: 58217/60000 (97.03%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1011,                   Accuracy: 58208/60000 (97.01%)
{0: tensor(97.2183), 10: tensor(96.8667), 20: tensor(96.8683), 30: tensor(96.7517), 40: tensor(96.6817), 50: tensor(96.6667), 60: tensor(96.6633), 70: tensor(96.7467), 80: tensor(96.6883), 90: tensor(96.8650), 100: tensor(96.4983), 110: tensor(96.4300), 120: tensor(96.2750), 130: tensor(96.2317), 140: tensor(96.1083), 150: tensor(96.1883), 160: tensor(96.1850), 170: tensor(96.0167), 180: tensor(96.3950), 190: tensor(96.1000), 200: tensor(96.2533), 210: tensor(96.2683), 220: tensor(96.4033), 230: tensor(96.4517), 240: tensor(96.5483), 250: tensor(96.7183), 260: tensor(96.6750), 270: tensor(96.9917), 280: tensor(96.7450), 290: tensor(96.7933), 300: tensor(96.7867), 310: tensor(96.8400), 320: tensor(96.8533), 330: tensor(96.9200), 340: tensor(97.0283), 350: tensor(97.0133)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=40, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7909,                   Accuracy: 686/2000.0 (34.30%)



-= Testing valid =-
Test set: Average loss: 2.0253,                   Accuracy: 574/2000.0 (28.70%)



-= Testing valid =-
Test set: Average loss: 1.0740,                   Accuracy: 1249/2000.0 (62.45%)



-= Testing valid =-
Test set: Average loss: 0.8228,                   Accuracy: 1496/2000.0 (74.80%)



-= Testing valid =-
Test set: Average loss: 0.5035,                   Accuracy: 1649/2000.0 (82.45%)



-= Testing valid =-
Test set: Average loss: 0.6067,                   Accuracy: 1605/2000.0 (80.25%)



-= Testing valid =-
Test set: Average loss: 0.2591,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.1681,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.3772,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.1652,                   Accuracy: 1903/2000.0 (95.15%)



Epoch 10 train accuracy: 92.78%, valid accuracy 95.15%
-= Testing valid =-
Test set: Average loss: 0.1311,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1270,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1380,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1197,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1478,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 20 train accuracy: 95.55%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1173,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1109,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 30 train accuracy: 96.44%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0755,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0719,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0668,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 40 train accuracy: 96.54%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0686,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 50 train accuracy: 96.95%, valid accuracy 98.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1082,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1156,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1096,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1111,                   Accuracy: 57993/60000 (96.65%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1103,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1098,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1104,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1098,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1120,                   Accuracy: 57979/60000 (96.63%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1098,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1168,                   Accuracy: 57853/60000 (96.42%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1101,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1109,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1107,                   Accuracy: 57981/60000 (96.64%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1115,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1122,                   Accuracy: 57954/60000 (96.59%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1091,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1162,                   Accuracy: 57900/60000 (96.50%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1088,                   Accuracy: 58057/60000 (96.76%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1148,                   Accuracy: 57902/60000 (96.50%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1097,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1089,                   Accuracy: 58035/60000 (96.72%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1090,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1091,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1082,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1068,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1143,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1076,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1142,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1089,                   Accuracy: 58031/60000 (96.72%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1091,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1094,                   Accuracy: 58042/60000 (96.74%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1082,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1071,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1080,                   Accuracy: 58077/60000 (96.79%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1109,                   Accuracy: 57986/60000 (96.64%)
{0: tensor(96.7633), 10: tensor(96.4583), 20: tensor(96.6117), 30: tensor(96.6550), 40: tensor(96.6767), 50: tensor(96.6883), 60: tensor(96.6450), 70: tensor(96.7450), 80: tensor(96.6317), 90: tensor(96.7533), 100: tensor(96.4217), 110: tensor(96.6750), 120: tensor(96.6333), 130: tensor(96.6350), 140: tensor(96.6683), 150: tensor(96.5900), 160: tensor(96.7317), 170: tensor(96.5000), 180: tensor(96.7617), 190: tensor(96.5033), 200: tensor(96.6800), 210: tensor(96.7250), 220: tensor(96.7467), 230: tensor(96.7467), 240: tensor(96.7017), 250: tensor(96.7433), 260: tensor(96.5600), 270: tensor(96.7800), 280: tensor(96.5333), 290: tensor(96.7183), 300: tensor(96.7283), 310: tensor(96.7367), 320: tensor(96.7433), 330: tensor(96.7333), 340: tensor(96.7950), 350: tensor(96.6433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=11, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.9749,                   Accuracy: 328/2000.0 (16.40%)



-= Testing valid =-
Test set: Average loss: 1.4433,                   Accuracy: 1109/2000.0 (55.45%)



-= Testing valid =-
Test set: Average loss: 1.1661,                   Accuracy: 1169/2000.0 (58.45%)



-= Testing valid =-
Test set: Average loss: 0.6319,                   Accuracy: 1548/2000.0 (77.40%)



-= Testing valid =-
Test set: Average loss: 0.4447,                   Accuracy: 1736/2000.0 (86.80%)



-= Testing valid =-
Test set: Average loss: 0.3136,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.1784,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.2107,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.2082,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1522,                   Accuracy: 1904/2000.0 (95.20%)



Epoch 10 train accuracy: 93.49%, valid accuracy 95.20%
-= Testing valid =-
Test set: Average loss: 0.1778,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1569,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1186,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1756,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1254,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1182,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1243,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1168,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 20 train accuracy: 95.66%, valid accuracy 96.45%
-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0710,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 30 train accuracy: 96.65%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0742,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0720,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0691,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 40 train accuracy: 97.12%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0736,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0719,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0755,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 50 train accuracy: 97.32%, valid accuracy 97.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0992,                   Accuracy: 58275/60000 (97.12%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1091,                   Accuracy: 58099/60000 (96.83%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1098,                   Accuracy: 58073/60000 (96.79%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1187,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1240,                   Accuracy: 57775/60000 (96.29%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1248,                   Accuracy: 57784/60000 (96.31%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1195,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1103,                   Accuracy: 58019/60000 (96.70%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1121,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1079,                   Accuracy: 58094/60000 (96.82%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1170,                   Accuracy: 57925/60000 (96.54%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1200,                   Accuracy: 57842/60000 (96.40%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1300,                   Accuracy: 57646/60000 (96.08%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1357,                   Accuracy: 57514/60000 (95.86%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1362,                   Accuracy: 57543/60000 (95.90%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1326,                   Accuracy: 57568/60000 (95.95%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1193,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1184,                   Accuracy: 57882/60000 (96.47%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1137,                   Accuracy: 57934/60000 (96.56%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1220,                   Accuracy: 57781/60000 (96.30%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1177,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1281,                   Accuracy: 57726/60000 (96.21%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1274,                   Accuracy: 57705/60000 (96.18%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1262,                   Accuracy: 57735/60000 (96.22%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1209,                   Accuracy: 57801/60000 (96.33%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1076,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1043,                   Accuracy: 58149/60000 (96.92%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1018,                   Accuracy: 58198/60000 (97.00%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1112,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1070,                   Accuracy: 58144/60000 (96.91%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1166,                   Accuracy: 57982/60000 (96.64%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1171,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1168,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1111,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1022,                   Accuracy: 58183/60000 (96.97%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1012,                   Accuracy: 58215/60000 (97.03%)
{0: tensor(97.1250), 10: tensor(96.8317), 20: tensor(96.7883), 30: tensor(96.5633), 40: tensor(96.2917), 50: tensor(96.3067), 60: tensor(96.4350), 70: tensor(96.6983), 80: tensor(96.6833), 90: tensor(96.8233), 100: tensor(96.5417), 110: tensor(96.4033), 120: tensor(96.0767), 130: tensor(95.8567), 140: tensor(95.9050), 150: tensor(95.9467), 160: tensor(96.3833), 170: tensor(96.4700), 180: tensor(96.5567), 190: tensor(96.3017), 200: tensor(96.4817), 210: tensor(96.2100), 220: tensor(96.1750), 230: tensor(96.2250), 240: tensor(96.3350), 250: tensor(96.7433), 260: tensor(96.9150), 270: tensor(96.9967), 280: tensor(96.7417), 290: tensor(96.9067), 300: tensor(96.6367), 310: tensor(96.5450), 320: tensor(96.5700), 330: tensor(96.6800), 340: tensor(96.9717), 350: tensor(97.0250)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=12, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9985,                   Accuracy: 490/2000.0 (24.50%)



-= Testing valid =-
Test set: Average loss: 4.4156,                   Accuracy: 230/2000.0 (11.50%)



-= Testing valid =-
Test set: Average loss: 1.1921,                   Accuracy: 1182/2000.0 (59.10%)



-= Testing valid =-
Test set: Average loss: 0.9445,                   Accuracy: 1369/2000.0 (68.45%)



-= Testing valid =-
Test set: Average loss: 0.6951,                   Accuracy: 1518/2000.0 (75.90%)



-= Testing valid =-
Test set: Average loss: 0.2598,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2690,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.3640,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.2138,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2022,                   Accuracy: 1863/2000.0 (93.15%)



Epoch 10 train accuracy: 93.15%, valid accuracy 93.15%
-= Testing valid =-
Test set: Average loss: 0.1858,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1359,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1506,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1289,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1876,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1211,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1545,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1659,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1121,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1501,                   Accuracy: 1913/2000.0 (95.65%)



Epoch 20 train accuracy: 95.49%, valid accuracy 95.65%
-= Testing valid =-
Test set: Average loss: 0.1159,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1120,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1097,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1119,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 30 train accuracy: 96.72%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 40 train accuracy: 96.72%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 50 train accuracy: 96.81%, valid accuracy 97.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1108,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1299,                   Accuracy: 57737/60000 (96.23%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1278,                   Accuracy: 57817/60000 (96.36%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1254,                   Accuracy: 57856/60000 (96.43%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1196,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1158,                   Accuracy: 58007/60000 (96.68%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1124,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1139,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1227,                   Accuracy: 57798/60000 (96.33%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1179,                   Accuracy: 57934/60000 (96.56%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1392,                   Accuracy: 57519/60000 (95.86%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1365,                   Accuracy: 57623/60000 (96.04%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1372,                   Accuracy: 57593/60000 (95.99%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1297,                   Accuracy: 57733/60000 (96.22%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1244,                   Accuracy: 57812/60000 (96.35%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1244,                   Accuracy: 57751/60000 (96.25%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1183,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1301,                   Accuracy: 57594/60000 (95.99%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1227,                   Accuracy: 57792/60000 (96.32%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1422,                   Accuracy: 57369/60000 (95.61%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1330,                   Accuracy: 57672/60000 (96.12%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1322,                   Accuracy: 57643/60000 (96.07%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1232,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1177,                   Accuracy: 57931/60000 (96.55%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1142,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1102,                   Accuracy: 58057/60000 (96.76%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1188,                   Accuracy: 57865/60000 (96.44%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1123,                   Accuracy: 58061/60000 (96.77%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1301,                   Accuracy: 57677/60000 (96.13%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1246,                   Accuracy: 57862/60000 (96.44%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1216,                   Accuracy: 57946/60000 (96.58%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1151,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1115,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1067,                   Accuracy: 58182/60000 (96.97%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1086,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1140,                   Accuracy: 57970/60000 (96.62%)
{0: tensor(96.8750), 10: tensor(96.2283), 20: tensor(96.3617), 30: tensor(96.4267), 40: tensor(96.6167), 50: tensor(96.6783), 60: tensor(96.7517), 70: tensor(96.6883), 80: tensor(96.3300), 90: tensor(96.5567), 100: tensor(95.8650), 110: tensor(96.0383), 120: tensor(95.9883), 130: tensor(96.2217), 140: tensor(96.3533), 150: tensor(96.2517), 160: tensor(96.4433), 170: tensor(95.9900), 180: tensor(96.3200), 190: tensor(95.6150), 200: tensor(96.1200), 210: tensor(96.0717), 220: tensor(96.4583), 230: tensor(96.5517), 240: tensor(96.6683), 250: tensor(96.7617), 260: tensor(96.4417), 270: tensor(96.7683), 280: tensor(96.1283), 290: tensor(96.4367), 300: tensor(96.5767), 310: tensor(96.7833), 320: tensor(96.8667), 330: tensor(96.9700), 340: tensor(96.8533), 350: tensor(96.6167)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=13, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.9049,                   Accuracy: 315/2000.0 (15.75%)



-= Testing valid =-
Test set: Average loss: 6.6512,                   Accuracy: 257/2000.0 (12.85%)



-= Testing valid =-
Test set: Average loss: 1.7600,                   Accuracy: 604/2000.0 (30.20%)



-= Testing valid =-
Test set: Average loss: 0.8322,                   Accuracy: 1468/2000.0 (73.40%)



-= Testing valid =-
Test set: Average loss: 0.8263,                   Accuracy: 1424/2000.0 (71.20%)



-= Testing valid =-
Test set: Average loss: 0.5424,                   Accuracy: 1641/2000.0 (82.05%)



-= Testing valid =-
Test set: Average loss: 0.3613,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.3334,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.2767,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.3388,                   Accuracy: 1781/2000.0 (89.05%)



Epoch 10 train accuracy: 92.43%, valid accuracy 89.05%
-= Testing valid =-
Test set: Average loss: 0.1612,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1608,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1318,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1349,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1756,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1633,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1195,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1343,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1695,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1285,                   Accuracy: 1920/2000.0 (96.00%)



Epoch 20 train accuracy: 95.45%, valid accuracy 96.00%
-= Testing valid =-
Test set: Average loss: 0.1248,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1148,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1097,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1076,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1178,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1264,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1181,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 30 train accuracy: 96.38%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0910,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1021,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 40 train accuracy: 96.81%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 50 train accuracy: 96.90%, valid accuracy 97.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1109,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1156,                   Accuracy: 57944/60000 (96.57%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1136,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1194,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1188,                   Accuracy: 57882/60000 (96.47%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1176,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1190,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1117,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1134,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1150,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1205,                   Accuracy: 57834/60000 (96.39%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1178,                   Accuracy: 57881/60000 (96.47%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1241,                   Accuracy: 57761/60000 (96.27%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1231,                   Accuracy: 57792/60000 (96.32%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1228,                   Accuracy: 57763/60000 (96.27%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1250,                   Accuracy: 57693/60000 (96.15%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1184,                   Accuracy: 57857/60000 (96.43%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1177,                   Accuracy: 57860/60000 (96.43%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1189,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1213,                   Accuracy: 57774/60000 (96.29%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1179,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1230,                   Accuracy: 57767/60000 (96.28%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1199,                   Accuracy: 57849/60000 (96.42%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1192,                   Accuracy: 57854/60000 (96.42%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1208,                   Accuracy: 57803/60000 (96.34%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1143,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1132,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1132,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1142,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1133,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1185,                   Accuracy: 57901/60000 (96.50%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1156,                   Accuracy: 57928/60000 (96.55%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1149,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1158,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1097,                   Accuracy: 58089/60000 (96.82%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1103,                   Accuracy: 58047/60000 (96.75%)
{0: tensor(96.7700), 10: tensor(96.5733), 20: tensor(96.6200), 30: tensor(96.4583), 40: tensor(96.4700), 50: tensor(96.4533), 60: tensor(96.4850), 70: tensor(96.7533), 80: tensor(96.6650), 90: tensor(96.6450), 100: tensor(96.3900), 110: tensor(96.4683), 120: tensor(96.2683), 130: tensor(96.3200), 140: tensor(96.2717), 150: tensor(96.1550), 160: tensor(96.4283), 170: tensor(96.4333), 180: tensor(96.4183), 190: tensor(96.2900), 200: tensor(96.4483), 210: tensor(96.2783), 220: tensor(96.4150), 230: tensor(96.4233), 240: tensor(96.3383), 250: tensor(96.5350), 260: tensor(96.6533), 270: tensor(96.6400), 280: tensor(96.6150), 290: tensor(96.6133), 300: tensor(96.5017), 310: tensor(96.5467), 320: tensor(96.5367), 330: tensor(96.5717), 340: tensor(96.8150), 350: tensor(96.7450)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=14, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0432,                   Accuracy: 213/2000.0 (10.65%)



-= Testing valid =-
Test set: Average loss: 1.4159,                   Accuracy: 1006/2000.0 (50.30%)



-= Testing valid =-
Test set: Average loss: 2.0557,                   Accuracy: 583/2000.0 (29.15%)



-= Testing valid =-
Test set: Average loss: 1.2237,                   Accuracy: 1102/2000.0 (55.10%)



-= Testing valid =-
Test set: Average loss: 0.5800,                   Accuracy: 1582/2000.0 (79.10%)



-= Testing valid =-
Test set: Average loss: 0.3735,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.2184,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.1855,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1763,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2375,                   Accuracy: 1844/2000.0 (92.20%)



Epoch 10 train accuracy: 93.07%, valid accuracy 92.20%
-= Testing valid =-
Test set: Average loss: 0.1366,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1408,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1374,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1335,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1398,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1133,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1421,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1254,                   Accuracy: 1912/2000.0 (95.60%)



Epoch 20 train accuracy: 95.97%, valid accuracy 95.60%
-= Testing valid =-
Test set: Average loss: 0.1070,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0877,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1077,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0723,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 30 train accuracy: 96.99%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0596,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0691,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 40 train accuracy: 97.07%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0709,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0709,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 50 train accuracy: 97.40%, valid accuracy 98.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0927,                   Accuracy: 58413/60000 (97.36%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0985,                   Accuracy: 58284/60000 (97.14%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1013,                   Accuracy: 58239/60000 (97.07%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1085,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1140,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1181,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1186,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1093,                   Accuracy: 58113/60000 (96.86%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1048,                   Accuracy: 58164/60000 (96.94%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0990,                   Accuracy: 58255/60000 (97.09%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1079,                   Accuracy: 58079/60000 (96.80%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1101,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1168,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1225,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1285,                   Accuracy: 57705/60000 (96.18%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1306,                   Accuracy: 57641/60000 (96.07%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1239,                   Accuracy: 57764/60000 (96.27%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1184,                   Accuracy: 57848/60000 (96.41%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1117,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1167,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1140,                   Accuracy: 57896/60000 (96.49%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1174,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1207,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1219,                   Accuracy: 57837/60000 (96.39%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1210,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1132,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1069,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1003,                   Accuracy: 58218/60000 (97.03%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1024,                   Accuracy: 58242/60000 (97.07%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1032,                   Accuracy: 58169/60000 (96.95%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1082,                   Accuracy: 58118/60000 (96.86%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1128,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1136,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1139,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1041,                   Accuracy: 58217/60000 (97.03%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0985,                   Accuracy: 58296/60000 (97.16%)
{0: tensor(97.3550), 10: tensor(97.1400), 20: tensor(97.0650), 30: tensor(96.8683), 40: tensor(96.7000), 50: tensor(96.6183), 60: tensor(96.6183), 70: tensor(96.8550), 80: tensor(96.9400), 90: tensor(97.0917), 100: tensor(96.7983), 110: tensor(96.6817), 120: tensor(96.5800), 130: tensor(96.3567), 140: tensor(96.1750), 150: tensor(96.0683), 160: tensor(96.2733), 170: tensor(96.4133), 180: tensor(96.6167), 190: tensor(96.4350), 200: tensor(96.4933), 210: tensor(96.4583), 220: tensor(96.4467), 230: tensor(96.3950), 240: tensor(96.4633), 250: tensor(96.6650), 260: tensor(96.8917), 270: tensor(97.0300), 280: tensor(97.0700), 290: tensor(96.9483), 300: tensor(96.8633), 310: tensor(96.7850), 320: tensor(96.7333), 330: tensor(96.7583), 340: tensor(97.0283), 350: tensor(97.1600)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=15, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.7137,                   Accuracy: 363/2000.0 (18.15%)



-= Testing valid =-
Test set: Average loss: 1.6474,                   Accuracy: 841/2000.0 (42.05%)



-= Testing valid =-
Test set: Average loss: 0.6952,                   Accuracy: 1521/2000.0 (76.05%)



-= Testing valid =-
Test set: Average loss: 0.4002,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 0.7289,                   Accuracy: 1502/2000.0 (75.10%)



-= Testing valid =-
Test set: Average loss: 0.3908,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.2090,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.2599,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.2616,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.3022,                   Accuracy: 1814/2000.0 (90.70%)



Epoch 10 train accuracy: 94.16%, valid accuracy 90.70%
-= Testing valid =-
Test set: Average loss: 0.1688,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1468,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1270,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1477,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1274,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1310,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1206,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1190,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1195,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1152,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 20 train accuracy: 95.93%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.1017,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1104,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0910,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1096,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1166,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0775,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 30 train accuracy: 96.93%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.1021,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 40 train accuracy: 97.14%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 50 train accuracy: 97.21%, valid accuracy 97.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1085,                   Accuracy: 58080/60000 (96.80%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1182,                   Accuracy: 57873/60000 (96.46%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1195,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1222,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1175,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1144,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1117,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1096,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1102,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1102,                   Accuracy: 58064/60000 (96.77%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1207,                   Accuracy: 57828/60000 (96.38%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1207,                   Accuracy: 57860/60000 (96.43%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1259,                   Accuracy: 57806/60000 (96.34%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1198,                   Accuracy: 57918/60000 (96.53%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1177,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1174,                   Accuracy: 57924/60000 (96.54%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1129,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1135,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1152,                   Accuracy: 57930/60000 (96.55%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1250,                   Accuracy: 57734/60000 (96.22%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1227,                   Accuracy: 57842/60000 (96.40%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1270,                   Accuracy: 57757/60000 (96.26%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1196,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1169,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1147,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1094,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1101,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1110,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1206,                   Accuracy: 57842/60000 (96.40%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1196,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1230,                   Accuracy: 57882/60000 (96.47%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1170,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1141,                   Accuracy: 58061/60000 (96.77%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1106,                   Accuracy: 58105/60000 (96.84%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1082,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1087,                   Accuracy: 58073/60000 (96.79%)
{0: tensor(96.8000), 10: tensor(96.4550), 20: tensor(96.4817), 30: tensor(96.4583), 40: tensor(96.5850), 50: tensor(96.7317), 60: tensor(96.7433), 70: tensor(96.7867), 80: tensor(96.7500), 90: tensor(96.7733), 100: tensor(96.3800), 110: tensor(96.4333), 120: tensor(96.3433), 130: tensor(96.5300), 140: tensor(96.6583), 150: tensor(96.5400), 160: tensor(96.6650), 170: tensor(96.6067), 180: tensor(96.5500), 190: tensor(96.2233), 200: tensor(96.4033), 210: tensor(96.2617), 220: tensor(96.5283), 230: tensor(96.6583), 240: tensor(96.6750), 250: tensor(96.8133), 260: tensor(96.6717), 270: tensor(96.7650), 280: tensor(96.4033), 290: tensor(96.4917), 300: tensor(96.4700), 310: tensor(96.6233), 320: tensor(96.7683), 330: tensor(96.8417), 340: tensor(96.8683), 350: tensor(96.7883)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=16, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 6.1686,                   Accuracy: 225/2000.0 (11.25%)



-= Testing valid =-
Test set: Average loss: 4.5092,                   Accuracy: 204/2000.0 (10.20%)



-= Testing valid =-
Test set: Average loss: 1.4092,                   Accuracy: 1202/2000.0 (60.10%)



-= Testing valid =-
Test set: Average loss: 1.1258,                   Accuracy: 1295/2000.0 (64.75%)



-= Testing valid =-
Test set: Average loss: 0.4319,                   Accuracy: 1753/2000.0 (87.65%)



-= Testing valid =-
Test set: Average loss: 0.4500,                   Accuracy: 1720/2000.0 (86.00%)



-= Testing valid =-
Test set: Average loss: 0.2303,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.4009,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.1896,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.2637,                   Accuracy: 1831/2000.0 (91.55%)



Epoch 10 train accuracy: 93.30%, valid accuracy 91.55%
-= Testing valid =-
Test set: Average loss: 0.1505,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1469,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1562,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.2599,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.1419,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1199,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1030,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1381,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 20 train accuracy: 95.64%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 30 train accuracy: 96.62%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0658,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 40 train accuracy: 96.76%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0707,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0683,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0684,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 50 train accuracy: 97.22%, valid accuracy 98.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0967,                   Accuracy: 58252/60000 (97.09%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1029,                   Accuracy: 58140/60000 (96.90%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1010,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1052,                   Accuracy: 58116/60000 (96.86%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1089,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1117,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1104,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1082,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1063,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0983,                   Accuracy: 58227/60000 (97.04%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1057,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1006,                   Accuracy: 58163/60000 (96.94%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1041,                   Accuracy: 58138/60000 (96.90%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1077,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1109,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1108,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1071,                   Accuracy: 58087/60000 (96.81%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1066,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0988,                   Accuracy: 58208/60000 (97.01%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1051,                   Accuracy: 58080/60000 (96.80%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.0995,                   Accuracy: 58231/60000 (97.05%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1042,                   Accuracy: 58116/60000 (96.86%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1064,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1088,                   Accuracy: 58069/60000 (96.78%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1094,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1045,                   Accuracy: 58133/60000 (96.89%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1051,                   Accuracy: 58131/60000 (96.89%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0968,                   Accuracy: 58257/60000 (97.10%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1013,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0995,                   Accuracy: 58202/60000 (97.00%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1056,                   Accuracy: 58106/60000 (96.84%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1078,                   Accuracy: 58069/60000 (96.78%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1101,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1098,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1059,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1056,                   Accuracy: 58095/60000 (96.82%)
{0: tensor(97.0867), 10: tensor(96.9000), 20: tensor(96.8767), 30: tensor(96.8600), 40: tensor(96.7300), 50: tensor(96.6133), 60: tensor(96.6817), 70: tensor(96.7717), 80: tensor(96.8083), 90: tensor(97.0450), 100: tensor(96.7967), 110: tensor(96.9383), 120: tensor(96.8967), 130: tensor(96.7517), 140: tensor(96.7050), 150: tensor(96.6517), 160: tensor(96.8117), 170: tensor(96.8367), 180: tensor(97.0133), 190: tensor(96.8000), 200: tensor(97.0517), 210: tensor(96.8600), 220: tensor(96.8533), 230: tensor(96.7817), 240: tensor(96.7567), 250: tensor(96.8883), 260: tensor(96.8850), 270: tensor(97.0950), 280: tensor(96.9100), 290: tensor(97.0033), 300: tensor(96.8433), 310: tensor(96.7817), 320: tensor(96.7050), 330: tensor(96.7417), 340: tensor(96.8367), 350: tensor(96.8250)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=17, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.5795,                   Accuracy: 324/2000.0 (16.20%)



-= Testing valid =-
Test set: Average loss: 2.0630,                   Accuracy: 512/2000.0 (25.60%)



-= Testing valid =-
Test set: Average loss: 1.5904,                   Accuracy: 993/2000.0 (49.65%)



-= Testing valid =-
Test set: Average loss: 1.1327,                   Accuracy: 1273/2000.0 (63.65%)



-= Testing valid =-
Test set: Average loss: 0.6394,                   Accuracy: 1599/2000.0 (79.95%)



-= Testing valid =-
Test set: Average loss: 0.4435,                   Accuracy: 1694/2000.0 (84.70%)



-= Testing valid =-
Test set: Average loss: 0.3664,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.2481,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2176,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.1712,                   Accuracy: 1885/2000.0 (94.25%)



Epoch 10 train accuracy: 93.61%, valid accuracy 94.25%
-= Testing valid =-
Test set: Average loss: 0.1511,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1656,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1727,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1252,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1724,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1103,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1242,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1228,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1477,                   Accuracy: 1904/2000.0 (95.20%)



Epoch 20 train accuracy: 95.99%, valid accuracy 95.20%
-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1398,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1193,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1097,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1015,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 30 train accuracy: 96.64%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 40 train accuracy: 96.95%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 50 train accuracy: 97.01%, valid accuracy 97.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1002,                   Accuracy: 58215/60000 (97.03%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1079,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1080,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1129,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1140,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1154,                   Accuracy: 57954/60000 (96.59%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1150,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1100,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1107,                   Accuracy: 57990/60000 (96.65%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1028,                   Accuracy: 58104/60000 (96.84%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1137,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1099,                   Accuracy: 57958/60000 (96.60%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1107,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1123,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1140,                   Accuracy: 57924/60000 (96.54%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1135,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1112,                   Accuracy: 57954/60000 (96.59%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1105,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1034,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1144,                   Accuracy: 57860/60000 (96.43%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1075,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1076,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1086,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1090,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1092,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1048,                   Accuracy: 58129/60000 (96.88%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1056,                   Accuracy: 58082/60000 (96.80%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0998,                   Accuracy: 58217/60000 (97.03%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1075,                   Accuracy: 58028/60000 (96.71%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1046,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1093,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1091,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1103,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1095,                   Accuracy: 58099/60000 (96.83%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1044,                   Accuracy: 58156/60000 (96.93%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1057,                   Accuracy: 58119/60000 (96.86%)
{0: tensor(97.0250), 10: tensor(96.7650), 20: tensor(96.7400), 30: tensor(96.6000), 40: tensor(96.5700), 50: tensor(96.5900), 60: tensor(96.5350), 70: tensor(96.6817), 80: tensor(96.6500), 90: tensor(96.8400), 100: tensor(96.4583), 110: tensor(96.5967), 120: tensor(96.5800), 130: tensor(96.5183), 140: tensor(96.5400), 150: tensor(96.5800), 160: tensor(96.5900), 170: tensor(96.6517), 180: tensor(96.8483), 190: tensor(96.4333), 200: tensor(96.7083), 210: tensor(96.7333), 220: tensor(96.6650), 230: tensor(96.7267), 240: tensor(96.8017), 250: tensor(96.8817), 260: tensor(96.8033), 270: tensor(97.0283), 280: tensor(96.7133), 290: tensor(96.8683), 300: tensor(96.7333), 310: tensor(96.7417), 320: tensor(96.7350), 330: tensor(96.8317), 340: tensor(96.9267), 350: tensor(96.8650)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=18, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4184,                   Accuracy: 219/2000.0 (10.95%)



-= Testing valid =-
Test set: Average loss: 1.5074,                   Accuracy: 971/2000.0 (48.55%)



-= Testing valid =-
Test set: Average loss: 1.6666,                   Accuracy: 759/2000.0 (37.95%)



-= Testing valid =-
Test set: Average loss: 1.2029,                   Accuracy: 1141/2000.0 (57.05%)



-= Testing valid =-
Test set: Average loss: 0.7962,                   Accuracy: 1394/2000.0 (69.70%)



-= Testing valid =-
Test set: Average loss: 0.4415,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.2701,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.3222,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.4263,                   Accuracy: 1729/2000.0 (86.45%)



-= Testing valid =-
Test set: Average loss: 0.3028,                   Accuracy: 1815/2000.0 (90.75%)



Epoch 10 train accuracy: 92.62%, valid accuracy 90.75%
-= Testing valid =-
Test set: Average loss: 0.1693,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1654,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1692,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1663,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1344,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1221,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1747,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1584,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1374,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1128,                   Accuracy: 1928/2000.0 (96.40%)



Epoch 20 train accuracy: 95.14%, valid accuracy 96.40%
-= Testing valid =-
Test set: Average loss: 0.1238,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1154,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1057,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1175,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1037,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1173,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 30 train accuracy: 96.40%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.1053,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0877,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 40 train accuracy: 96.91%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 50 train accuracy: 96.95%, valid accuracy 97.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0972,                   Accuracy: 58288/60000 (97.15%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1074,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1040,                   Accuracy: 58163/60000 (96.94%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1045,                   Accuracy: 58167/60000 (96.94%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1054,                   Accuracy: 58148/60000 (96.91%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1069,                   Accuracy: 58133/60000 (96.89%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1069,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1078,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1133,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1022,                   Accuracy: 58167/60000 (96.94%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1147,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1091,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1095,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1112,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1148,                   Accuracy: 57954/60000 (96.59%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1140,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1132,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1212,                   Accuracy: 57750/60000 (96.25%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1075,                   Accuracy: 58057/60000 (96.76%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1189,                   Accuracy: 57840/60000 (96.40%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1123,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1136,                   Accuracy: 58012/60000 (96.69%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1130,                   Accuracy: 57993/60000 (96.65%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1136,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1138,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1087,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1164,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1017,                   Accuracy: 58215/60000 (97.03%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1100,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1059,                   Accuracy: 58148/60000 (96.91%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1084,                   Accuracy: 58136/60000 (96.89%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1074,                   Accuracy: 58159/60000 (96.93%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1068,                   Accuracy: 58144/60000 (96.91%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1067,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1043,                   Accuracy: 58136/60000 (96.89%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1091,                   Accuracy: 58020/60000 (96.70%)
{0: tensor(97.1467), 10: tensor(96.7533), 20: tensor(96.9383), 30: tensor(96.9450), 40: tensor(96.9133), 50: tensor(96.8883), 60: tensor(96.8567), 70: tensor(96.7350), 80: tensor(96.5483), 90: tensor(96.9450), 100: tensor(96.5117), 110: tensor(96.6967), 120: tensor(96.7700), 130: tensor(96.7067), 140: tensor(96.5900), 150: tensor(96.5833), 160: tensor(96.5383), 170: tensor(96.2500), 180: tensor(96.7617), 190: tensor(96.4000), 200: tensor(96.6417), 210: tensor(96.6867), 220: tensor(96.6550), 230: tensor(96.6800), 240: tensor(96.5783), 250: tensor(96.7050), 260: tensor(96.4483), 270: tensor(97.0250), 280: tensor(96.7267), 290: tensor(96.9133), 300: tensor(96.8933), 310: tensor(96.9317), 320: tensor(96.9067), 330: tensor(96.8533), 340: tensor(96.8933), 350: tensor(96.7000)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=19, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6540,                   Accuracy: 251/2000.0 (12.55%)



-= Testing valid =-
Test set: Average loss: 3.0873,                   Accuracy: 482/2000.0 (24.10%)



-= Testing valid =-
Test set: Average loss: 1.3905,                   Accuracy: 1081/2000.0 (54.05%)



-= Testing valid =-
Test set: Average loss: 1.2864,                   Accuracy: 1241/2000.0 (62.05%)



-= Testing valid =-
Test set: Average loss: 0.9973,                   Accuracy: 1287/2000.0 (64.35%)



-= Testing valid =-
Test set: Average loss: 0.2960,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.5181,                   Accuracy: 1687/2000.0 (84.35%)



-= Testing valid =-
Test set: Average loss: 0.2441,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.1634,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.2881,                   Accuracy: 1803/2000.0 (90.15%)



Epoch 10 train accuracy: 93.47%, valid accuracy 90.15%
-= Testing valid =-
Test set: Average loss: 0.1534,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1347,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1519,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1322,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1453,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1248,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1317,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1401,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1300,                   Accuracy: 1919/2000.0 (95.95%)



Epoch 20 train accuracy: 95.94%, valid accuracy 95.95%
-= Testing valid =-
Test set: Average loss: 0.1179,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0986,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 30 train accuracy: 96.68%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0802,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 40 train accuracy: 97.22%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 50 train accuracy: 97.22%, valid accuracy 97.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0978,                   Accuracy: 58341/60000 (97.24%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1066,                   Accuracy: 58171/60000 (96.95%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1038,                   Accuracy: 58184/60000 (96.97%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1058,                   Accuracy: 58142/60000 (96.90%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1119,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1144,                   Accuracy: 57975/60000 (96.62%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1155,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1126,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1133,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1029,                   Accuracy: 58212/60000 (97.02%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1121,                   Accuracy: 58031/60000 (96.72%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1097,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1130,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1203,                   Accuracy: 57794/60000 (96.32%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1249,                   Accuracy: 57749/60000 (96.25%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1258,                   Accuracy: 57708/60000 (96.18%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1235,                   Accuracy: 57734/60000 (96.22%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1228,                   Accuracy: 57809/60000 (96.35%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1109,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1198,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1133,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1181,                   Accuracy: 57881/60000 (96.47%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1208,                   Accuracy: 57792/60000 (96.32%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1228,                   Accuracy: 57776/60000 (96.29%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1216,                   Accuracy: 57812/60000 (96.35%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1157,                   Accuracy: 57905/60000 (96.51%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1139,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1030,                   Accuracy: 58233/60000 (97.06%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1109,                   Accuracy: 58067/60000 (96.78%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1050,                   Accuracy: 58132/60000 (96.89%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1089,                   Accuracy: 58089/60000 (96.82%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1113,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1122,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1125,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1079,                   Accuracy: 58077/60000 (96.79%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1073,                   Accuracy: 58114/60000 (96.86%)
{0: tensor(97.2350), 10: tensor(96.9517), 20: tensor(96.9733), 30: tensor(96.9033), 40: tensor(96.6800), 50: tensor(96.6250), 60: tensor(96.5950), 70: tensor(96.7350), 80: tensor(96.6750), 90: tensor(97.0200), 100: tensor(96.7183), 110: tensor(96.7967), 120: tensor(96.6533), 130: tensor(96.3233), 140: tensor(96.2483), 150: tensor(96.1800), 160: tensor(96.2233), 170: tensor(96.3483), 180: tensor(96.7500), 190: tensor(96.4850), 200: tensor(96.6000), 210: tensor(96.4683), 220: tensor(96.3200), 230: tensor(96.2933), 240: tensor(96.3533), 250: tensor(96.5083), 260: tensor(96.6467), 270: tensor(97.0550), 280: tensor(96.7783), 290: tensor(96.8867), 300: tensor(96.8150), 310: tensor(96.6717), 320: tensor(96.7333), 330: tensor(96.6917), 340: tensor(96.7950), 350: tensor(96.8567)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=20, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3879,                   Accuracy: 345/2000.0 (17.25%)



-= Testing valid =-
Test set: Average loss: 1.5817,                   Accuracy: 827/2000.0 (41.35%)



-= Testing valid =-
Test set: Average loss: 1.2731,                   Accuracy: 1166/2000.0 (58.30%)



-= Testing valid =-
Test set: Average loss: 0.6712,                   Accuracy: 1608/2000.0 (80.40%)



-= Testing valid =-
Test set: Average loss: 0.3657,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.2356,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2172,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.2471,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2192,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.2981,                   Accuracy: 1803/2000.0 (90.15%)



Epoch 10 train accuracy: 93.66%, valid accuracy 90.15%
-= Testing valid =-
Test set: Average loss: 0.1220,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1927,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1324,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1265,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1172,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1348,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1140,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1264,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1079,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1435,                   Accuracy: 1912/2000.0 (95.60%)



Epoch 20 train accuracy: 95.90%, valid accuracy 95.60%
-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1178,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0981,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1102,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1167,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1033,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 30 train accuracy: 96.76%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1033,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 40 train accuracy: 96.90%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 50 train accuracy: 97.24%, valid accuracy 97.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1038,                   Accuracy: 58234/60000 (97.06%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1126,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1145,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1174,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1176,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1180,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1166,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1137,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1135,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1116,                   Accuracy: 58075/60000 (96.79%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1220,                   Accuracy: 57774/60000 (96.29%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1240,                   Accuracy: 57802/60000 (96.34%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1282,                   Accuracy: 57724/60000 (96.21%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1273,                   Accuracy: 57752/60000 (96.25%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1285,                   Accuracy: 57727/60000 (96.21%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1274,                   Accuracy: 57679/60000 (96.13%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1219,                   Accuracy: 57822/60000 (96.37%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1194,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1174,                   Accuracy: 57905/60000 (96.51%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1284,                   Accuracy: 57613/60000 (96.02%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1253,                   Accuracy: 57741/60000 (96.24%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1273,                   Accuracy: 57750/60000 (96.25%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1238,                   Accuracy: 57792/60000 (96.32%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1226,                   Accuracy: 57845/60000 (96.41%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1205,                   Accuracy: 57879/60000 (96.46%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1135,                   Accuracy: 58057/60000 (96.76%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1115,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1067,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1153,                   Accuracy: 57944/60000 (96.57%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1158,                   Accuracy: 57979/60000 (96.63%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1166,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1150,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1144,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1122,                   Accuracy: 58075/60000 (96.79%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1084,                   Accuracy: 58159/60000 (96.93%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1087,                   Accuracy: 58132/60000 (96.89%)
{0: tensor(97.0567), 10: tensor(96.7050), 20: tensor(96.6817), 30: tensor(96.6333), 40: tensor(96.6683), 50: tensor(96.5867), 60: tensor(96.6133), 70: tensor(96.6750), 80: tensor(96.6900), 90: tensor(96.7917), 100: tensor(96.2900), 110: tensor(96.3367), 120: tensor(96.2067), 130: tensor(96.2533), 140: tensor(96.2117), 150: tensor(96.1317), 160: tensor(96.3700), 170: tensor(96.4350), 180: tensor(96.5083), 190: tensor(96.0217), 200: tensor(96.2350), 210: tensor(96.2500), 220: tensor(96.3200), 230: tensor(96.4083), 240: tensor(96.4650), 250: tensor(96.7617), 260: tensor(96.7833), 270: tensor(96.9100), 280: tensor(96.5733), 290: tensor(96.6317), 300: tensor(96.6583), 310: tensor(96.7450), 320: tensor(96.6900), 330: tensor(96.7917), 340: tensor(96.9317), 350: tensor(96.8867)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=21, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.4830,                   Accuracy: 234/2000.0 (11.70%)



-= Testing valid =-
Test set: Average loss: 1.6901,                   Accuracy: 770/2000.0 (38.50%)



-= Testing valid =-
Test set: Average loss: 1.0153,                   Accuracy: 1347/2000.0 (67.35%)



-= Testing valid =-
Test set: Average loss: 0.7400,                   Accuracy: 1518/2000.0 (75.90%)



-= Testing valid =-
Test set: Average loss: 0.3682,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.3986,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.2081,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.1666,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1650,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1801,                   Accuracy: 1866/2000.0 (93.30%)



Epoch 10 train accuracy: 93.05%, valid accuracy 93.30%
-= Testing valid =-
Test set: Average loss: 0.1763,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.1258,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1251,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1088,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1068,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1118,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1219,                   Accuracy: 1918/2000.0 (95.90%)



Epoch 20 train accuracy: 95.31%, valid accuracy 95.90%
-= Testing valid =-
Test set: Average loss: 0.0926,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 30 train accuracy: 96.47%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0712,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0734,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 40 train accuracy: 96.78%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0625,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0698,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0701,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0668,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 50 train accuracy: 97.05%, valid accuracy 97.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0981,                   Accuracy: 58240/60000 (97.07%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1021,                   Accuracy: 58176/60000 (96.96%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1028,                   Accuracy: 58147/60000 (96.91%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1067,                   Accuracy: 58079/60000 (96.80%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1073,                   Accuracy: 58101/60000 (96.83%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1105,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1117,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1080,                   Accuracy: 58111/60000 (96.85%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1075,                   Accuracy: 58074/60000 (96.79%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1012,                   Accuracy: 58177/60000 (96.96%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1077,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1045,                   Accuracy: 58110/60000 (96.85%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1066,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1076,                   Accuracy: 58084/60000 (96.81%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1111,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1119,                   Accuracy: 57955/60000 (96.59%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1089,                   Accuracy: 58064/60000 (96.77%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1072,                   Accuracy: 58079/60000 (96.80%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0998,                   Accuracy: 58211/60000 (97.02%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1065,                   Accuracy: 58064/60000 (96.77%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.0998,                   Accuracy: 58242/60000 (97.07%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1012,                   Accuracy: 58204/60000 (97.01%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1015,                   Accuracy: 58204/60000 (97.01%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1048,                   Accuracy: 58154/60000 (96.92%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1051,                   Accuracy: 58147/60000 (96.91%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1044,                   Accuracy: 58181/60000 (96.97%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1011,                   Accuracy: 58205/60000 (97.01%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0962,                   Accuracy: 58271/60000 (97.12%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1005,                   Accuracy: 58215/60000 (97.03%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0982,                   Accuracy: 58255/60000 (97.09%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1013,                   Accuracy: 58215/60000 (97.03%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1019,                   Accuracy: 58202/60000 (97.00%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1051,                   Accuracy: 58171/60000 (96.95%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1060,                   Accuracy: 58144/60000 (96.91%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1044,                   Accuracy: 58207/60000 (97.01%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1022,                   Accuracy: 58158/60000 (96.93%)
{0: tensor(97.0667), 10: tensor(96.9600), 20: tensor(96.9117), 30: tensor(96.7983), 40: tensor(96.8350), 50: tensor(96.7317), 60: tensor(96.6683), 70: tensor(96.8517), 80: tensor(96.7900), 90: tensor(96.9617), 100: tensor(96.7550), 110: tensor(96.8500), 120: tensor(96.8083), 130: tensor(96.8067), 140: tensor(96.6883), 150: tensor(96.5917), 160: tensor(96.7733), 170: tensor(96.7983), 180: tensor(97.0183), 190: tensor(96.7733), 200: tensor(97.0700), 210: tensor(97.0067), 220: tensor(97.0067), 230: tensor(96.9233), 240: tensor(96.9117), 250: tensor(96.9683), 260: tensor(97.0083), 270: tensor(97.1183), 280: tensor(97.0250), 290: tensor(97.0917), 300: tensor(97.0250), 310: tensor(97.0033), 320: tensor(96.9517), 330: tensor(96.9067), 340: tensor(97.0117), 350: tensor(96.9300)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=22, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8885,                   Accuracy: 507/2000.0 (25.35%)



-= Testing valid =-
Test set: Average loss: 1.7331,                   Accuracy: 816/2000.0 (40.80%)



-= Testing valid =-
Test set: Average loss: 1.6150,                   Accuracy: 855/2000.0 (42.75%)



-= Testing valid =-
Test set: Average loss: 0.9188,                   Accuracy: 1390/2000.0 (69.50%)



-= Testing valid =-
Test set: Average loss: 0.9623,                   Accuracy: 1404/2000.0 (70.20%)



-= Testing valid =-
Test set: Average loss: 0.5530,                   Accuracy: 1674/2000.0 (83.70%)



-= Testing valid =-
Test set: Average loss: 0.2752,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2494,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2159,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.3786,                   Accuracy: 1788/2000.0 (89.40%)



Epoch 10 train accuracy: 92.88%, valid accuracy 89.40%
-= Testing valid =-
Test set: Average loss: 0.1958,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1483,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1447,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1256,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1982,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1447,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1286,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1410,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1071,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1909/2000.0 (95.45%)



Epoch 20 train accuracy: 95.43%, valid accuracy 95.45%
-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1037,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0981,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 30 train accuracy: 96.40%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0802,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 40 train accuracy: 97.00%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0734,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 50 train accuracy: 96.91%, valid accuracy 97.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1172,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1363,                   Accuracy: 57653/60000 (96.09%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1316,                   Accuracy: 57720/60000 (96.20%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1308,                   Accuracy: 57732/60000 (96.22%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1314,                   Accuracy: 57736/60000 (96.23%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1291,                   Accuracy: 57823/60000 (96.37%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1257,                   Accuracy: 57863/60000 (96.44%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1263,                   Accuracy: 57832/60000 (96.39%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1314,                   Accuracy: 57782/60000 (96.30%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1194,                   Accuracy: 57940/60000 (96.57%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1397,                   Accuracy: 57599/60000 (96.00%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1307,                   Accuracy: 57732/60000 (96.22%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1322,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1326,                   Accuracy: 57680/60000 (96.13%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1320,                   Accuracy: 57743/60000 (96.24%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1290,                   Accuracy: 57770/60000 (96.28%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1257,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1323,                   Accuracy: 57730/60000 (96.22%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1193,                   Accuracy: 57903/60000 (96.50%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1339,                   Accuracy: 57656/60000 (96.09%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1286,                   Accuracy: 57746/60000 (96.24%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1301,                   Accuracy: 57720/60000 (96.20%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1262,                   Accuracy: 57800/60000 (96.33%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1259,                   Accuracy: 57821/60000 (96.37%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1206,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1198,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1284,                   Accuracy: 57775/60000 (96.29%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1155,                   Accuracy: 57983/60000 (96.64%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1299,                   Accuracy: 57783/60000 (96.31%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1290,                   Accuracy: 57747/60000 (96.25%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1294,                   Accuracy: 57745/60000 (96.24%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1270,                   Accuracy: 57805/60000 (96.34%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1258,                   Accuracy: 57839/60000 (96.40%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1201,                   Accuracy: 57949/60000 (96.58%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1224,                   Accuracy: 57888/60000 (96.48%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1296,                   Accuracy: 57809/60000 (96.35%)
{0: tensor(96.6183), 10: tensor(96.0883), 20: tensor(96.2000), 30: tensor(96.2200), 40: tensor(96.2267), 50: tensor(96.3717), 60: tensor(96.4383), 70: tensor(96.3867), 80: tensor(96.3033), 90: tensor(96.5667), 100: tensor(95.9983), 110: tensor(96.2200), 120: tensor(96.1417), 130: tensor(96.1333), 140: tensor(96.2383), 150: tensor(96.2833), 160: tensor(96.3833), 170: tensor(96.2167), 180: tensor(96.5050), 190: tensor(96.0933), 200: tensor(96.2433), 210: tensor(96.2000), 220: tensor(96.3333), 230: tensor(96.3683), 240: tensor(96.5483), 250: tensor(96.5217), 260: tensor(96.2917), 270: tensor(96.6383), 280: tensor(96.3050), 290: tensor(96.2450), 300: tensor(96.2417), 310: tensor(96.3417), 320: tensor(96.3983), 330: tensor(96.5817), 340: tensor(96.4800), 350: tensor(96.3483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=23, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.7951,                   Accuracy: 226/2000.0 (11.30%)



-= Testing valid =-
Test set: Average loss: 1.4706,                   Accuracy: 958/2000.0 (47.90%)



-= Testing valid =-
Test set: Average loss: 1.1247,                   Accuracy: 1198/2000.0 (59.90%)



-= Testing valid =-
Test set: Average loss: 1.2945,                   Accuracy: 1050/2000.0 (52.50%)



-= Testing valid =-
Test set: Average loss: 1.2025,                   Accuracy: 1160/2000.0 (58.00%)



-= Testing valid =-
Test set: Average loss: 0.5141,                   Accuracy: 1630/2000.0 (81.50%)



-= Testing valid =-
Test set: Average loss: 0.2774,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.4262,                   Accuracy: 1732/2000.0 (86.60%)



-= Testing valid =-
Test set: Average loss: 0.2008,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.2028,                   Accuracy: 1863/2000.0 (93.15%)



Epoch 10 train accuracy: 93.51%, valid accuracy 93.15%
-= Testing valid =-
Test set: Average loss: 0.1772,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1341,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1431,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1553,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1285,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1230,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1807,                   Accuracy: 1893/2000.0 (94.65%)



Epoch 20 train accuracy: 95.97%, valid accuracy 94.65%
-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1143,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1232,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 30 train accuracy: 96.65%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1030,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 40 train accuracy: 96.94%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0802,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 50 train accuracy: 97.25%, valid accuracy 97.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1064,                   Accuracy: 58110/60000 (96.85%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1190,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1190,                   Accuracy: 57902/60000 (96.50%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1271,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1288,                   Accuracy: 57834/60000 (96.39%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1271,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1246,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1174,                   Accuracy: 57918/60000 (96.53%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1148,                   Accuracy: 57926/60000 (96.54%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1106,                   Accuracy: 58012/60000 (96.69%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1254,                   Accuracy: 57715/60000 (96.19%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1250,                   Accuracy: 57746/60000 (96.24%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1345,                   Accuracy: 57643/60000 (96.07%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1369,                   Accuracy: 57643/60000 (96.07%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1378,                   Accuracy: 57586/60000 (95.98%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1374,                   Accuracy: 57515/60000 (95.86%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1290,                   Accuracy: 57631/60000 (96.05%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1232,                   Accuracy: 57733/60000 (96.22%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1215,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1357,                   Accuracy: 57446/60000 (95.74%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1322,                   Accuracy: 57598/60000 (96.00%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1389,                   Accuracy: 57543/60000 (95.90%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1385,                   Accuracy: 57577/60000 (95.96%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1359,                   Accuracy: 57613/60000 (96.02%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1337,                   Accuracy: 57616/60000 (96.03%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1228,                   Accuracy: 57799/60000 (96.33%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1168,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1126,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1238,                   Accuracy: 57747/60000 (96.25%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1236,                   Accuracy: 57815/60000 (96.36%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1306,                   Accuracy: 57695/60000 (96.16%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1301,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1262,                   Accuracy: 57836/60000 (96.39%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1245,                   Accuracy: 57831/60000 (96.39%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1148,                   Accuracy: 58002/60000 (96.67%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1121,                   Accuracy: 58031/60000 (96.72%)
{0: tensor(96.8500), 10: tensor(96.4633), 20: tensor(96.5033), 30: tensor(96.3600), 40: tensor(96.3900), 50: tensor(96.3400), 60: tensor(96.3833), 70: tensor(96.5300), 80: tensor(96.5433), 90: tensor(96.6867), 100: tensor(96.1917), 110: tensor(96.2433), 120: tensor(96.0717), 130: tensor(96.0717), 140: tensor(95.9767), 150: tensor(95.8583), 160: tensor(96.0517), 170: tensor(96.2217), 180: tensor(96.2600), 190: tensor(95.7433), 200: tensor(95.9967), 210: tensor(95.9050), 220: tensor(95.9617), 230: tensor(96.0217), 240: tensor(96.0267), 250: tensor(96.3317), 260: tensor(96.5067), 270: tensor(96.5933), 280: tensor(96.2450), 290: tensor(96.3583), 300: tensor(96.1583), 310: tensor(96.2600), 320: tensor(96.3933), 330: tensor(96.3850), 340: tensor(96.6700), 350: tensor(96.7183)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=24, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.3120,                   Accuracy: 239/2000.0 (11.95%)



-= Testing valid =-
Test set: Average loss: 2.9055,                   Accuracy: 422/2000.0 (21.10%)



-= Testing valid =-
Test set: Average loss: 1.2560,                   Accuracy: 1222/2000.0 (61.10%)



-= Testing valid =-
Test set: Average loss: 1.2784,                   Accuracy: 1178/2000.0 (58.90%)



-= Testing valid =-
Test set: Average loss: 1.2578,                   Accuracy: 1153/2000.0 (57.65%)



-= Testing valid =-
Test set: Average loss: 0.5153,                   Accuracy: 1654/2000.0 (82.70%)



-= Testing valid =-
Test set: Average loss: 0.5036,                   Accuracy: 1682/2000.0 (84.10%)



-= Testing valid =-
Test set: Average loss: 0.6492,                   Accuracy: 1548/2000.0 (77.40%)



-= Testing valid =-
Test set: Average loss: 0.2430,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2004,                   Accuracy: 1876/2000.0 (93.80%)



Epoch 10 train accuracy: 92.90%, valid accuracy 93.80%
-= Testing valid =-
Test set: Average loss: 0.2421,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.1455,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1674,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1346,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1222,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1847,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.1752,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1295,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1122,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 20 train accuracy: 95.30%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.1166,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1309,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1163,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1264,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.1074,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1216,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 30 train accuracy: 96.40%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1010,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 40 train accuracy: 96.93%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 50 train accuracy: 97.22%, valid accuracy 97.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1191,                   Accuracy: 57931/60000 (96.55%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1221,                   Accuracy: 57833/60000 (96.39%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1220,                   Accuracy: 57840/60000 (96.40%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1310,                   Accuracy: 57718/60000 (96.20%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1339,                   Accuracy: 57669/60000 (96.11%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1389,                   Accuracy: 57606/60000 (96.01%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1378,                   Accuracy: 57605/60000 (96.01%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1310,                   Accuracy: 57651/60000 (96.08%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1310,                   Accuracy: 57609/60000 (96.01%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1289,                   Accuracy: 57708/60000 (96.18%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1342,                   Accuracy: 57601/60000 (96.00%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1360,                   Accuracy: 57570/60000 (95.95%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1444,                   Accuracy: 57449/60000 (95.75%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1489,                   Accuracy: 57370/60000 (95.62%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1549,                   Accuracy: 57268/60000 (95.45%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1535,                   Accuracy: 57216/60000 (95.36%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1448,                   Accuracy: 57331/60000 (95.55%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1407,                   Accuracy: 57417/60000 (95.69%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1393,                   Accuracy: 57448/60000 (95.75%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1391,                   Accuracy: 57452/60000 (95.75%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1343,                   Accuracy: 57568/60000 (95.95%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1406,                   Accuracy: 57513/60000 (95.86%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1408,                   Accuracy: 57567/60000 (95.94%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1423,                   Accuracy: 57518/60000 (95.86%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1398,                   Accuracy: 57518/60000 (95.86%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1291,                   Accuracy: 57690/60000 (96.15%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1239,                   Accuracy: 57792/60000 (96.32%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1244,                   Accuracy: 57828/60000 (96.38%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1234,                   Accuracy: 57786/60000 (96.31%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1194,                   Accuracy: 57882/60000 (96.47%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1274,                   Accuracy: 57790/60000 (96.32%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1283,                   Accuracy: 57800/60000 (96.33%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1307,                   Accuracy: 57764/60000 (96.27%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1288,                   Accuracy: 57832/60000 (96.39%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1216,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1181,                   Accuracy: 57930/60000 (96.55%)
{0: tensor(96.5517), 10: tensor(96.3883), 20: tensor(96.4000), 30: tensor(96.1967), 40: tensor(96.1150), 50: tensor(96.0100), 60: tensor(96.0083), 70: tensor(96.0850), 80: tensor(96.0150), 90: tensor(96.1800), 100: tensor(96.0017), 110: tensor(95.9500), 120: tensor(95.7483), 130: tensor(95.6167), 140: tensor(95.4467), 150: tensor(95.3600), 160: tensor(95.5517), 170: tensor(95.6950), 180: tensor(95.7467), 190: tensor(95.7533), 200: tensor(95.9467), 210: tensor(95.8550), 220: tensor(95.9450), 230: tensor(95.8633), 240: tensor(95.8633), 250: tensor(96.1500), 260: tensor(96.3200), 270: tensor(96.3800), 280: tensor(96.3100), 290: tensor(96.4700), 300: tensor(96.3167), 310: tensor(96.3333), 320: tensor(96.2733), 330: tensor(96.3867), 340: tensor(96.4300), 350: tensor(96.5500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=25, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.4013,                   Accuracy: 349/2000.0 (17.45%)



-= Testing valid =-
Test set: Average loss: 1.8602,                   Accuracy: 577/2000.0 (28.85%)



-= Testing valid =-
Test set: Average loss: 0.9027,                   Accuracy: 1469/2000.0 (73.45%)



-= Testing valid =-
Test set: Average loss: 0.9311,                   Accuracy: 1373/2000.0 (68.65%)



-= Testing valid =-
Test set: Average loss: 0.3620,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.3215,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.3636,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.2547,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2259,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1983,                   Accuracy: 1882/2000.0 (94.10%)



Epoch 10 train accuracy: 92.51%, valid accuracy 94.10%
-= Testing valid =-
Test set: Average loss: 0.1583,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1645,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1766,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1270,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1312,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1483,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1352,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1339,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1259,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1253,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 20 train accuracy: 95.45%, valid accuracy 96.45%
-= Testing valid =-
Test set: Average loss: 0.1096,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1165,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1100,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1253,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1052,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1102,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1015,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 30 train accuracy: 96.19%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 40 train accuracy: 96.72%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 50 train accuracy: 96.96%, valid accuracy 97.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1002,                   Accuracy: 58214/60000 (97.02%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1130,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1069,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1092,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1100,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1076,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1051,                   Accuracy: 58118/60000 (96.86%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1048,                   Accuracy: 58129/60000 (96.88%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1092,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1039,                   Accuracy: 58162/60000 (96.94%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1190,                   Accuracy: 57824/60000 (96.37%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1133,                   Accuracy: 57910/60000 (96.52%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1181,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1195,                   Accuracy: 57791/60000 (96.32%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1173,                   Accuracy: 57837/60000 (96.39%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1168,                   Accuracy: 57848/60000 (96.41%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1120,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1175,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1103,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1242,                   Accuracy: 57682/60000 (96.14%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1148,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1183,                   Accuracy: 57834/60000 (96.39%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1172,                   Accuracy: 57838/60000 (96.40%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1135,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1121,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1069,                   Accuracy: 58084/60000 (96.81%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1121,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1041,                   Accuracy: 58115/60000 (96.86%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1159,                   Accuracy: 57859/60000 (96.43%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1090,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1093,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1083,                   Accuracy: 58076/60000 (96.79%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1059,                   Accuracy: 58101/60000 (96.83%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1030,                   Accuracy: 58149/60000 (96.92%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1020,                   Accuracy: 58190/60000 (96.98%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1057,                   Accuracy: 58127/60000 (96.88%)
{0: tensor(97.0233), 10: tensor(96.6017), 20: tensor(96.7850), 30: tensor(96.7017), 40: tensor(96.7067), 50: tensor(96.8167), 60: tensor(96.8633), 70: tensor(96.8817), 80: tensor(96.7583), 90: tensor(96.9367), 100: tensor(96.3733), 110: tensor(96.5167), 120: tensor(96.3567), 130: tensor(96.3183), 140: tensor(96.3950), 150: tensor(96.4133), 160: tensor(96.5883), 170: tensor(96.3767), 180: tensor(96.6167), 190: tensor(96.1367), 200: tensor(96.5067), 210: tensor(96.3900), 220: tensor(96.3967), 230: tensor(96.5317), 240: tensor(96.5700), 250: tensor(96.8067), 260: tensor(96.5867), 270: tensor(96.8583), 280: tensor(96.4317), 290: tensor(96.7117), 300: tensor(96.6900), 310: tensor(96.7933), 320: tensor(96.8350), 330: tensor(96.9150), 340: tensor(96.9833), 350: tensor(96.8783)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=26, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.1644,                   Accuracy: 209/2000.0 (10.45%)



-= Testing valid =-
Test set: Average loss: 2.0085,                   Accuracy: 564/2000.0 (28.20%)



-= Testing valid =-
Test set: Average loss: 2.1142,                   Accuracy: 623/2000.0 (31.15%)



-= Testing valid =-
Test set: Average loss: 2.9364,                   Accuracy: 404/2000.0 (20.20%)



-= Testing valid =-
Test set: Average loss: 0.9050,                   Accuracy: 1353/2000.0 (67.65%)



-= Testing valid =-
Test set: Average loss: 0.5138,                   Accuracy: 1652/2000.0 (82.60%)



-= Testing valid =-
Test set: Average loss: 0.5250,                   Accuracy: 1654/2000.0 (82.70%)



-= Testing valid =-
Test set: Average loss: 0.3993,                   Accuracy: 1732/2000.0 (86.60%)



-= Testing valid =-
Test set: Average loss: 0.4214,                   Accuracy: 1726/2000.0 (86.30%)



-= Testing valid =-
Test set: Average loss: 0.3715,                   Accuracy: 1785/2000.0 (89.25%)



Epoch 10 train accuracy: 93.29%, valid accuracy 89.25%
-= Testing valid =-
Test set: Average loss: 0.2663,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.1899,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1608,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.2245,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.2220,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1700,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1641,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1631,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1704,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.2025,                   Accuracy: 1865/2000.0 (93.25%)



Epoch 20 train accuracy: 96.25%, valid accuracy 93.25%
-= Testing valid =-
Test set: Average loss: 0.1532,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1490,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1382,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1434,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1294,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1115,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1611,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1246,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1334,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1295,                   Accuracy: 1920/2000.0 (96.00%)



Epoch 30 train accuracy: 96.82%, valid accuracy 96.00%
-= Testing valid =-
Test set: Average loss: 0.1350,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1251,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1414,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1200,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1195,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1191,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1297,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1168,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1331,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1189,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 40 train accuracy: 96.82%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.1239,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1298,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1171,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1220,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1148,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1141,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1134,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1091,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1136,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1107,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 50 train accuracy: 97.49%, valid accuracy 96.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1240,                   Accuracy: 57890/60000 (96.48%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1318,                   Accuracy: 57626/60000 (96.04%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1275,                   Accuracy: 57702/60000 (96.17%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1336,                   Accuracy: 57588/60000 (95.98%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1314,                   Accuracy: 57676/60000 (96.13%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1353,                   Accuracy: 57602/60000 (96.00%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1324,                   Accuracy: 57652/60000 (96.09%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1295,                   Accuracy: 57696/60000 (96.16%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1321,                   Accuracy: 57629/60000 (96.05%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1328,                   Accuracy: 57626/60000 (96.04%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1423,                   Accuracy: 57372/60000 (95.62%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1396,                   Accuracy: 57400/60000 (95.67%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1485,                   Accuracy: 57193/60000 (95.32%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1465,                   Accuracy: 57254/60000 (95.42%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1499,                   Accuracy: 57203/60000 (95.34%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1497,                   Accuracy: 57194/60000 (95.32%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1418,                   Accuracy: 57408/60000 (95.68%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1466,                   Accuracy: 57313/60000 (95.52%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1447,                   Accuracy: 57321/60000 (95.54%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1562,                   Accuracy: 57003/60000 (95.00%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1473,                   Accuracy: 57198/60000 (95.33%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1530,                   Accuracy: 57065/60000 (95.11%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1456,                   Accuracy: 57263/60000 (95.44%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1464,                   Accuracy: 57287/60000 (95.48%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1443,                   Accuracy: 57340/60000 (95.57%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1338,                   Accuracy: 57579/60000 (95.96%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1351,                   Accuracy: 57556/60000 (95.93%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1324,                   Accuracy: 57641/60000 (96.07%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1408,                   Accuracy: 57400/60000 (95.67%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1333,                   Accuracy: 57587/60000 (95.98%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1370,                   Accuracy: 57509/60000 (95.85%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1322,                   Accuracy: 57662/60000 (96.10%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1334,                   Accuracy: 57633/60000 (96.06%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1292,                   Accuracy: 57734/60000 (96.22%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1236,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1241,                   Accuracy: 57855/60000 (96.43%)
{0: tensor(96.4833), 10: tensor(96.0433), 20: tensor(96.1700), 30: tensor(95.9800), 40: tensor(96.1267), 50: tensor(96.0033), 60: tensor(96.0867), 70: tensor(96.1600), 80: tensor(96.0483), 90: tensor(96.0433), 100: tensor(95.6200), 110: tensor(95.6667), 120: tensor(95.3217), 130: tensor(95.4233), 140: tensor(95.3383), 150: tensor(95.3233), 160: tensor(95.6800), 170: tensor(95.5217), 180: tensor(95.5350), 190: tensor(95.0050), 200: tensor(95.3300), 210: tensor(95.1083), 220: tensor(95.4383), 230: tensor(95.4783), 240: tensor(95.5667), 250: tensor(95.9650), 260: tensor(95.9267), 270: tensor(96.0683), 280: tensor(95.6667), 290: tensor(95.9783), 300: tensor(95.8483), 310: tensor(96.1033), 320: tensor(96.0550), 330: tensor(96.2233), 340: tensor(96.3650), 350: tensor(96.4250)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=27, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.5347,                   Accuracy: 262/2000.0 (13.10%)



-= Testing valid =-
Test set: Average loss: 7.5037,                   Accuracy: 205/2000.0 (10.25%)



-= Testing valid =-
Test set: Average loss: 3.1649,                   Accuracy: 466/2000.0 (23.30%)



-= Testing valid =-
Test set: Average loss: 0.7664,                   Accuracy: 1498/2000.0 (74.90%)



-= Testing valid =-
Test set: Average loss: 0.7601,                   Accuracy: 1464/2000.0 (73.20%)



-= Testing valid =-
Test set: Average loss: 1.0491,                   Accuracy: 1300/2000.0 (65.00%)



-= Testing valid =-
Test set: Average loss: 0.2641,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.3080,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.2623,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.4728,                   Accuracy: 1723/2000.0 (86.15%)



Epoch 10 train accuracy: 92.96%, valid accuracy 86.15%
-= Testing valid =-
Test set: Average loss: 0.1735,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1814,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1783,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1430,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1358,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1999,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.1353,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1569,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1725,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1572,                   Accuracy: 1904/2000.0 (95.20%)



Epoch 20 train accuracy: 95.21%, valid accuracy 95.20%
-= Testing valid =-
Test set: Average loss: 0.1378,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1209,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1109,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1217,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1273,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1259,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1088,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 30 train accuracy: 96.78%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.0986,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1170,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1057,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0877,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 40 train accuracy: 96.95%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1021,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 50 train accuracy: 97.30%, valid accuracy 97.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1101,                   Accuracy: 58096/60000 (96.83%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1247,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1225,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1206,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1155,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1152,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1117,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1102,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1139,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1090,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1252,                   Accuracy: 57748/60000 (96.25%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1208,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1185,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1158,                   Accuracy: 57946/60000 (96.58%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1169,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1131,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1127,                   Accuracy: 57977/60000 (96.63%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1199,                   Accuracy: 57870/60000 (96.45%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1148,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1304,                   Accuracy: 57679/60000 (96.13%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1243,                   Accuracy: 57780/60000 (96.30%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1193,                   Accuracy: 57892/60000 (96.49%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1174,                   Accuracy: 57909/60000 (96.51%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1172,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1142,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1134,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1196,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1136,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1263,                   Accuracy: 57773/60000 (96.29%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1257,                   Accuracy: 57785/60000 (96.31%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1212,                   Accuracy: 57892/60000 (96.49%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1170,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1165,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1140,                   Accuracy: 58028/60000 (96.71%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1128,                   Accuracy: 57993/60000 (96.65%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1154,                   Accuracy: 57977/60000 (96.63%)
{0: tensor(96.8267), 10: tensor(96.3817), 20: tensor(96.4350), 30: tensor(96.5383), 40: tensor(96.7083), 50: tensor(96.7000), 60: tensor(96.7967), 70: tensor(96.7583), 80: tensor(96.6133), 90: tensor(96.8367), 100: tensor(96.2467), 110: tensor(96.4483), 120: tensor(96.4850), 130: tensor(96.5767), 140: tensor(96.6233), 150: tensor(96.7067), 160: tensor(96.6283), 170: tensor(96.4500), 180: tensor(96.5850), 190: tensor(96.1317), 200: tensor(96.3000), 210: tensor(96.4867), 220: tensor(96.5150), 230: tensor(96.5750), 240: tensor(96.6817), 250: tensor(96.5950), 260: tensor(96.4533), 270: tensor(96.6533), 280: tensor(96.2883), 290: tensor(96.3083), 300: tensor(96.4867), 310: tensor(96.6133), 320: tensor(96.6400), 330: tensor(96.7133), 340: tensor(96.6550), 350: tensor(96.6283)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=28, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5875,                   Accuracy: 252/2000.0 (12.60%)



-= Testing valid =-
Test set: Average loss: 1.7729,                   Accuracy: 677/2000.0 (33.85%)



-= Testing valid =-
Test set: Average loss: 0.7792,                   Accuracy: 1571/2000.0 (78.55%)



-= Testing valid =-
Test set: Average loss: 0.7162,                   Accuracy: 1599/2000.0 (79.95%)



-= Testing valid =-
Test set: Average loss: 0.4684,                   Accuracy: 1711/2000.0 (85.55%)



-= Testing valid =-
Test set: Average loss: 0.6085,                   Accuracy: 1599/2000.0 (79.95%)



-= Testing valid =-
Test set: Average loss: 0.3101,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.1907,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1799,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.2902,                   Accuracy: 1828/2000.0 (91.40%)



Epoch 10 train accuracy: 93.22%, valid accuracy 91.40%
-= Testing valid =-
Test set: Average loss: 0.1467,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1359,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1473,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1490,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1898,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1292,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1547,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1168,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1243,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1108,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 20 train accuracy: 96.11%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0877,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0937,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 30 train accuracy: 96.47%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 40 train accuracy: 97.21%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0825,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 50 train accuracy: 96.89%, valid accuracy 97.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1003,                   Accuracy: 58275/60000 (97.12%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1013,                   Accuracy: 58265/60000 (97.11%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0970,                   Accuracy: 58299/60000 (97.17%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1029,                   Accuracy: 58199/60000 (97.00%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1081,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1141,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1153,                   Accuracy: 57990/60000 (96.65%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1094,                   Accuracy: 58139/60000 (96.90%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1055,                   Accuracy: 58194/60000 (96.99%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1011,                   Accuracy: 58261/60000 (97.10%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1026,                   Accuracy: 58197/60000 (97.00%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.0979,                   Accuracy: 58279/60000 (97.13%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1042,                   Accuracy: 58205/60000 (97.01%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1086,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1143,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1189,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1106,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1077,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1066,                   Accuracy: 58168/60000 (96.95%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1088,                   Accuracy: 58080/60000 (96.80%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1007,                   Accuracy: 58239/60000 (97.07%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1074,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1092,                   Accuracy: 58073/60000 (96.79%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1126,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1156,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1085,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1059,                   Accuracy: 58199/60000 (97.00%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1049,                   Accuracy: 58190/60000 (96.98%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1069,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0997,                   Accuracy: 58262/60000 (97.10%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1059,                   Accuracy: 58160/60000 (96.93%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1088,                   Accuracy: 58083/60000 (96.81%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1121,                   Accuracy: 58079/60000 (96.80%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1123,                   Accuracy: 58091/60000 (96.82%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1073,                   Accuracy: 58172/60000 (96.95%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1033,                   Accuracy: 58238/60000 (97.06%)
{0: tensor(97.1250), 10: tensor(97.1083), 20: tensor(97.1650), 30: tensor(96.9983), 40: tensor(96.8450), 50: tensor(96.7267), 60: tensor(96.6500), 70: tensor(96.8983), 80: tensor(96.9900), 90: tensor(97.1017), 100: tensor(96.9950), 110: tensor(97.1317), 120: tensor(97.0083), 130: tensor(96.8133), 140: tensor(96.7433), 150: tensor(96.5800), 160: tensor(96.8167), 170: tensor(96.9500), 180: tensor(96.9467), 190: tensor(96.8000), 200: tensor(97.0650), 210: tensor(96.8917), 220: tensor(96.7883), 230: tensor(96.7750), 240: tensor(96.7083), 250: tensor(96.8750), 260: tensor(96.9983), 270: tensor(96.9833), 280: tensor(96.8367), 290: tensor(97.1033), 300: tensor(96.9333), 310: tensor(96.8050), 320: tensor(96.7983), 330: tensor(96.8183), 340: tensor(96.9533), 350: tensor(97.0633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=29, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.7445,                   Accuracy: 225/2000.0 (11.25%)



-= Testing valid =-
Test set: Average loss: 1.8438,                   Accuracy: 526/2000.0 (26.30%)



-= Testing valid =-
Test set: Average loss: 1.1174,                   Accuracy: 1163/2000.0 (58.15%)



-= Testing valid =-
Test set: Average loss: 1.1964,                   Accuracy: 1264/2000.0 (63.20%)



-= Testing valid =-
Test set: Average loss: 0.4443,                   Accuracy: 1744/2000.0 (87.20%)



-= Testing valid =-
Test set: Average loss: 0.2731,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.2391,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.3256,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.1700,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1857,                   Accuracy: 1884/2000.0 (94.20%)



Epoch 10 train accuracy: 93.79%, valid accuracy 94.20%
-= Testing valid =-
Test set: Average loss: 0.1595,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1238,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1232,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1202,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1411,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1190,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1456,                   Accuracy: 1913/2000.0 (95.65%)



Epoch 20 train accuracy: 96.10%, valid accuracy 95.65%
-= Testing valid =-
Test set: Average loss: 0.1277,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1222,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1093,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1050,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1042,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1121,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 30 train accuracy: 96.90%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 40 train accuracy: 97.34%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 50 train accuracy: 97.34%, valid accuracy 97.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0994,                   Accuracy: 58291/60000 (97.15%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1030,                   Accuracy: 58233/60000 (97.06%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1014,                   Accuracy: 58246/60000 (97.08%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1072,                   Accuracy: 58147/60000 (96.91%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1073,                   Accuracy: 58144/60000 (96.91%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1078,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1086,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1051,                   Accuracy: 58129/60000 (96.88%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1059,                   Accuracy: 58127/60000 (96.88%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1076,                   Accuracy: 58092/60000 (96.82%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1128,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1113,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1197,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1182,                   Accuracy: 57879/60000 (96.46%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1173,                   Accuracy: 57918/60000 (96.53%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1195,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1105,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1120,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1112,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1130,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1105,                   Accuracy: 58061/60000 (96.77%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1173,                   Accuracy: 57946/60000 (96.58%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1116,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1097,                   Accuracy: 58083/60000 (96.81%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1095,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1017,                   Accuracy: 58186/60000 (96.98%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1026,                   Accuracy: 58213/60000 (97.02%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1011,                   Accuracy: 58257/60000 (97.10%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1020,                   Accuracy: 58229/60000 (97.05%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1000,                   Accuracy: 58293/60000 (97.15%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1040,                   Accuracy: 58193/60000 (96.99%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1019,                   Accuracy: 58248/60000 (97.08%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1011,                   Accuracy: 58245/60000 (97.07%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1011,                   Accuracy: 58261/60000 (97.10%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0976,                   Accuracy: 58277/60000 (97.13%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0989,                   Accuracy: 58276/60000 (97.13%)
{0: tensor(97.1517), 10: tensor(97.0550), 20: tensor(97.0767), 30: tensor(96.9117), 40: tensor(96.9067), 50: tensor(96.8567), 60: tensor(96.8367), 70: tensor(96.8817), 80: tensor(96.8783), 90: tensor(96.8200), 100: tensor(96.6883), 110: tensor(96.6917), 120: tensor(96.4817), 130: tensor(96.4650), 140: tensor(96.5300), 150: tensor(96.4600), 160: tensor(96.6800), 170: tensor(96.6883), 180: tensor(96.7317), 190: tensor(96.6333), 200: tensor(96.7683), 210: tensor(96.5767), 220: tensor(96.7117), 230: tensor(96.8050), 240: tensor(96.7833), 250: tensor(96.9767), 260: tensor(97.0217), 270: tensor(97.0950), 280: tensor(97.0483), 290: tensor(97.1550), 300: tensor(96.9883), 310: tensor(97.0800), 320: tensor(97.0750), 330: tensor(97.1017), 340: tensor(97.1283), 350: tensor(97.1267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=30, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.0023,                   Accuracy: 193/2000.0 (9.65%)



-= Testing valid =-
Test set: Average loss: 1.3399,                   Accuracy: 1080/2000.0 (54.00%)



-= Testing valid =-
Test set: Average loss: 0.9528,                   Accuracy: 1396/2000.0 (69.80%)



-= Testing valid =-
Test set: Average loss: 1.1476,                   Accuracy: 1202/2000.0 (60.10%)



-= Testing valid =-
Test set: Average loss: 0.4025,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3634,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.2803,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.3855,                   Accuracy: 1745/2000.0 (87.25%)



-= Testing valid =-
Test set: Average loss: 0.3965,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.2506,                   Accuracy: 1845/2000.0 (92.25%)



Epoch 10 train accuracy: 92.88%, valid accuracy 92.25%
-= Testing valid =-
Test set: Average loss: 0.1999,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1783,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1369,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1608,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1326,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1539,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1378,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1457,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1262,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1450,                   Accuracy: 1914/2000.0 (95.70%)



Epoch 20 train accuracy: 95.16%, valid accuracy 95.70%
-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1034,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1058,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1191,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 30 train accuracy: 96.36%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0877,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 40 train accuracy: 96.71%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 50 train accuracy: 96.76%, valid accuracy 97.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1123,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1308,                   Accuracy: 57680/60000 (96.13%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1216,                   Accuracy: 57805/60000 (96.34%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1227,                   Accuracy: 57793/60000 (96.32%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1203,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1202,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1176,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1141,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1186,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1084,                   Accuracy: 58092/60000 (96.82%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1289,                   Accuracy: 57669/60000 (96.11%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1182,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1170,                   Accuracy: 57925/60000 (96.54%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1172,                   Accuracy: 57925/60000 (96.54%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1183,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1150,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1118,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1194,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1073,                   Accuracy: 58106/60000 (96.84%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1225,                   Accuracy: 57802/60000 (96.34%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1150,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1143,                   Accuracy: 57978/60000 (96.63%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1159,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1181,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1150,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1135,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1229,                   Accuracy: 57783/60000 (96.31%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1100,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1245,                   Accuracy: 57790/60000 (96.32%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1185,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1195,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1185,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1198,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1186,                   Accuracy: 57903/60000 (96.50%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1170,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1228,                   Accuracy: 57832/60000 (96.39%)
{0: tensor(96.7000), 10: tensor(96.1333), 20: tensor(96.3417), 30: tensor(96.3217), 40: tensor(96.4583), 50: tensor(96.4617), 60: tensor(96.4767), 70: tensor(96.6150), 80: tensor(96.5183), 90: tensor(96.8200), 100: tensor(96.1150), 110: tensor(96.4167), 120: tensor(96.5417), 130: tensor(96.5417), 140: tensor(96.4850), 150: tensor(96.6067), 160: tensor(96.6650), 170: tensor(96.4117), 180: tensor(96.8433), 190: tensor(96.3367), 200: tensor(96.5533), 210: tensor(96.6300), 220: tensor(96.5700), 230: tensor(96.4917), 240: tensor(96.6067), 250: tensor(96.6133), 260: tensor(96.3050), 270: tensor(96.7600), 280: tensor(96.3167), 290: tensor(96.4533), 300: tensor(96.4717), 310: tensor(96.5583), 320: tensor(96.5283), 330: tensor(96.5050), 340: tensor(96.5383), 350: tensor(96.3867)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=31, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.5936,                   Accuracy: 242/2000.0 (12.10%)



-= Testing valid =-
Test set: Average loss: 6.1882,                   Accuracy: 188/2000.0 (9.40%)



-= Testing valid =-
Test set: Average loss: 0.9756,                   Accuracy: 1297/2000.0 (64.85%)



-= Testing valid =-
Test set: Average loss: 1.0313,                   Accuracy: 1291/2000.0 (64.55%)



-= Testing valid =-
Test set: Average loss: 0.3850,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.4282,                   Accuracy: 1730/2000.0 (86.50%)



-= Testing valid =-
Test set: Average loss: 0.2868,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2416,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.1975,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1682,                   Accuracy: 1904/2000.0 (95.20%)



Epoch 10 train accuracy: 93.04%, valid accuracy 95.20%
-= Testing valid =-
Test set: Average loss: 0.1448,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1332,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1350,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1391,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1589,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1436,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1297,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1721,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1367,                   Accuracy: 1917/2000.0 (95.85%)



Epoch 20 train accuracy: 95.06%, valid accuracy 95.85%
-= Testing valid =-
Test set: Average loss: 0.1148,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1120,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0910,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0935,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1079,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1107,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 30 train accuracy: 96.61%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 40 train accuracy: 96.81%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 50 train accuracy: 96.78%, valid accuracy 97.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1087,                   Accuracy: 58131/60000 (96.89%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1200,                   Accuracy: 57863/60000 (96.44%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1146,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1156,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1171,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1175,                   Accuracy: 57966/60000 (96.61%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1162,                   Accuracy: 57982/60000 (96.64%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1145,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1211,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1112,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1264,                   Accuracy: 57714/60000 (96.19%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1186,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1205,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1227,                   Accuracy: 57825/60000 (96.38%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1247,                   Accuracy: 57783/60000 (96.31%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1272,                   Accuracy: 57724/60000 (96.21%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1258,                   Accuracy: 57755/60000 (96.26%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1318,                   Accuracy: 57636/60000 (96.06%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1200,                   Accuracy: 57870/60000 (96.45%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1345,                   Accuracy: 57554/60000 (95.92%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1233,                   Accuracy: 57800/60000 (96.33%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1250,                   Accuracy: 57787/60000 (96.31%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1224,                   Accuracy: 57823/60000 (96.37%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1232,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1233,                   Accuracy: 57808/60000 (96.35%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1220,                   Accuracy: 57832/60000 (96.39%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1265,                   Accuracy: 57757/60000 (96.26%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1147,                   Accuracy: 58011/60000 (96.68%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1246,                   Accuracy: 57769/60000 (96.28%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1189,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1198,                   Accuracy: 57939/60000 (96.57%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1176,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1171,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1148,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1132,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1183,                   Accuracy: 57933/60000 (96.56%)
{0: tensor(96.8850), 10: tensor(96.4383), 20: tensor(96.6000), 30: tensor(96.6967), 40: tensor(96.6217), 50: tensor(96.6100), 60: tensor(96.6367), 70: tensor(96.6067), 80: tensor(96.4533), 90: tensor(96.8017), 100: tensor(96.1900), 110: tensor(96.4850), 120: tensor(96.4533), 130: tensor(96.3750), 140: tensor(96.3050), 150: tensor(96.2067), 160: tensor(96.2583), 170: tensor(96.0600), 180: tensor(96.4500), 190: tensor(95.9233), 200: tensor(96.3333), 210: tensor(96.3117), 220: tensor(96.3717), 230: tensor(96.4100), 240: tensor(96.3467), 250: tensor(96.3867), 260: tensor(96.2617), 270: tensor(96.6850), 280: tensor(96.2817), 290: tensor(96.5067), 300: tensor(96.5650), 310: tensor(96.6483), 320: tensor(96.6433), 330: tensor(96.7000), 340: tensor(96.6967), 350: tensor(96.5550)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=32, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0540,                   Accuracy: 250/2000.0 (12.50%)



-= Testing valid =-
Test set: Average loss: 1.8747,                   Accuracy: 836/2000.0 (41.80%)



-= Testing valid =-
Test set: Average loss: 2.0653,                   Accuracy: 690/2000.0 (34.50%)



-= Testing valid =-
Test set: Average loss: 0.5478,                   Accuracy: 1724/2000.0 (86.20%)



-= Testing valid =-
Test set: Average loss: 0.7410,                   Accuracy: 1482/2000.0 (74.10%)



-= Testing valid =-
Test set: Average loss: 0.3953,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.3395,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.3397,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.2496,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2099,                   Accuracy: 1872/2000.0 (93.60%)



Epoch 10 train accuracy: 92.68%, valid accuracy 93.60%
-= Testing valid =-
Test set: Average loss: 0.1663,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1471,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1378,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1668,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1274,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1158,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1229,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1343,                   Accuracy: 1920/2000.0 (96.00%)



Epoch 20 train accuracy: 95.47%, valid accuracy 96.00%
-= Testing valid =-
Test set: Average loss: 0.1094,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1037,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1012,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1086,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 30 train accuracy: 96.51%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 40 train accuracy: 97.11%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0825,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 50 train accuracy: 97.25%, valid accuracy 98.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1082,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1084,                   Accuracy: 58119/60000 (96.86%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1027,                   Accuracy: 58250/60000 (97.08%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1039,                   Accuracy: 58240/60000 (97.07%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1067,                   Accuracy: 58168/60000 (96.95%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1113,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1158,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1126,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1152,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1105,                   Accuracy: 58033/60000 (96.72%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1116,                   Accuracy: 58012/60000 (96.69%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1050,                   Accuracy: 58210/60000 (97.02%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1081,                   Accuracy: 58164/60000 (96.94%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1099,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1154,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1203,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1167,                   Accuracy: 57873/60000 (96.46%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1163,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1107,                   Accuracy: 58032/60000 (96.72%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1124,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1050,                   Accuracy: 58185/60000 (96.97%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1067,                   Accuracy: 58183/60000 (96.97%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1080,                   Accuracy: 58161/60000 (96.93%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1118,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1159,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1119,                   Accuracy: 58026/60000 (96.71%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1119,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1068,                   Accuracy: 58138/60000 (96.90%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1079,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1022,                   Accuracy: 58293/60000 (97.15%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1032,                   Accuracy: 58273/60000 (97.12%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1061,                   Accuracy: 58195/60000 (96.99%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1092,                   Accuracy: 58117/60000 (96.86%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1134,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1096,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1128,                   Accuracy: 57992/60000 (96.65%)
{0: tensor(96.8750), 10: tensor(96.8650), 20: tensor(97.0833), 30: tensor(97.0667), 40: tensor(96.9467), 50: tensor(96.7700), 60: tensor(96.5783), 70: tensor(96.6267), 80: tensor(96.5383), 90: tensor(96.7217), 100: tensor(96.6867), 110: tensor(97.0167), 120: tensor(96.9400), 130: tensor(96.8450), 140: tensor(96.6400), 150: tensor(96.4300), 160: tensor(96.4550), 170: tensor(96.5133), 180: tensor(96.7200), 190: tensor(96.6967), 200: tensor(96.9750), 210: tensor(96.9717), 220: tensor(96.9350), 230: tensor(96.7600), 240: tensor(96.5883), 250: tensor(96.7100), 260: tensor(96.6933), 270: tensor(96.8967), 280: tensor(96.9100), 290: tensor(97.1550), 300: tensor(97.1217), 310: tensor(96.9917), 320: tensor(96.8617), 330: tensor(96.7000), 340: tensor(96.7567), 350: tensor(96.6533)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=33, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.9508,                   Accuracy: 239/2000.0 (11.95%)



-= Testing valid =-
Test set: Average loss: 1.8425,                   Accuracy: 910/2000.0 (45.50%)



-= Testing valid =-
Test set: Average loss: 1.5966,                   Accuracy: 1025/2000.0 (51.25%)



-= Testing valid =-
Test set: Average loss: 1.0813,                   Accuracy: 1197/2000.0 (59.85%)



-= Testing valid =-
Test set: Average loss: 0.2501,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.7277,                   Accuracy: 1490/2000.0 (74.50%)



-= Testing valid =-
Test set: Average loss: 0.2265,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.1625,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.3343,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.2255,                   Accuracy: 1856/2000.0 (92.80%)



Epoch 10 train accuracy: 93.74%, valid accuracy 92.80%
-= Testing valid =-
Test set: Average loss: 0.1418,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1217,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1625,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1108,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1543,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 20 train accuracy: 95.44%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0698,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.1246,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0736,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 30 train accuracy: 96.51%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0662,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0657,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0618,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0605,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0606,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0584,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0622,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 40 train accuracy: 97.10%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0582,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0567,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0580,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0579,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0605,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0590,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0617,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 50 train accuracy: 97.22%, valid accuracy 98.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1138,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1155,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1140,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1179,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1191,                   Accuracy: 57934/60000 (96.56%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1216,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1242,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1188,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1151,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1169,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1200,                   Accuracy: 57823/60000 (96.37%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1176,                   Accuracy: 57882/60000 (96.47%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1238,                   Accuracy: 57785/60000 (96.31%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1232,                   Accuracy: 57800/60000 (96.33%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1247,                   Accuracy: 57794/60000 (96.32%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1280,                   Accuracy: 57750/60000 (96.25%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1190,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1157,                   Accuracy: 57978/60000 (96.63%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1170,                   Accuracy: 57905/60000 (96.51%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1197,                   Accuracy: 57827/60000 (96.38%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1147,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1188,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1192,                   Accuracy: 57888/60000 (96.48%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1214,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1238,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1160,                   Accuracy: 57983/60000 (96.64%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1143,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1137,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1150,                   Accuracy: 57930/60000 (96.55%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1124,                   Accuracy: 58035/60000 (96.72%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1154,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1169,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1199,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1223,                   Accuracy: 57912/60000 (96.52%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1172,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1146,                   Accuracy: 58000/60000 (96.67%)
{0: tensor(96.6467), 10: tensor(96.5800), 20: tensor(96.6733), 30: tensor(96.5583), 40: tensor(96.5567), 50: tensor(96.4600), 60: tensor(96.4400), 70: tensor(96.5583), 80: tensor(96.6833), 90: tensor(96.5317), 100: tensor(96.3717), 110: tensor(96.4700), 120: tensor(96.3083), 130: tensor(96.3333), 140: tensor(96.3233), 150: tensor(96.2500), 160: tensor(96.5133), 170: tensor(96.6300), 180: tensor(96.5083), 190: tensor(96.3783), 200: tensor(96.5850), 210: tensor(96.4633), 220: tensor(96.4800), 230: tensor(96.4583), 240: tensor(96.4183), 250: tensor(96.6383), 260: tensor(96.6600), 270: tensor(96.6717), 280: tensor(96.5500), 290: tensor(96.7250), 300: tensor(96.7467), 310: tensor(96.6333), 320: tensor(96.5350), 330: tensor(96.5200), 340: tensor(96.6000), 350: tensor(96.6667)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=34, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6121,                   Accuracy: 357/2000.0 (17.85%)



-= Testing valid =-
Test set: Average loss: 1.8158,                   Accuracy: 593/2000.0 (29.65%)



-= Testing valid =-
Test set: Average loss: 1.7690,                   Accuracy: 845/2000.0 (42.25%)



-= Testing valid =-
Test set: Average loss: 1.6219,                   Accuracy: 993/2000.0 (49.65%)



-= Testing valid =-
Test set: Average loss: 1.1208,                   Accuracy: 1260/2000.0 (63.00%)



-= Testing valid =-
Test set: Average loss: 0.3514,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.2479,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.3920,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.2102,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2537,                   Accuracy: 1855/2000.0 (92.75%)



Epoch 10 train accuracy: 93.07%, valid accuracy 92.75%
-= Testing valid =-
Test set: Average loss: 0.2091,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1606,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1790,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1394,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1478,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1716,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1439,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1412,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1966,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1143,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 20 train accuracy: 95.71%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.1167,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1030,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1219,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1422,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1257,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1229,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1274,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1229,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 30 train accuracy: 96.84%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.1300,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1310,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1096,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1111,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1046,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1053,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1094,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 40 train accuracy: 97.01%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1066,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1104,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1103,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 50 train accuracy: 97.54%, valid accuracy 97.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0969,                   Accuracy: 58220/60000 (97.03%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1109,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1124,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1141,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1146,                   Accuracy: 57958/60000 (96.60%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1124,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1067,                   Accuracy: 58049/60000 (96.75%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1006,                   Accuracy: 58166/60000 (96.94%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1046,                   Accuracy: 58069/60000 (96.78%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0960,                   Accuracy: 58217/60000 (97.03%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1114,                   Accuracy: 57959/60000 (96.60%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1110,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1102,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1123,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1129,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1070,                   Accuracy: 58049/60000 (96.75%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1020,                   Accuracy: 58110/60000 (96.85%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1052,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0975,                   Accuracy: 58182/60000 (96.97%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1118,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1084,                   Accuracy: 58011/60000 (96.68%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1090,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1106,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1117,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1060,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1021,                   Accuracy: 58118/60000 (96.86%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1053,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0981,                   Accuracy: 58183/60000 (96.97%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1105,                   Accuracy: 57977/60000 (96.63%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1104,                   Accuracy: 57981/60000 (96.64%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1133,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1138,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1118,                   Accuracy: 58028/60000 (96.71%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1067,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1009,                   Accuracy: 58156/60000 (96.93%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1052,                   Accuracy: 58051/60000 (96.75%)
{0: tensor(97.0333), 10: tensor(96.6183), 20: tensor(96.5633), 30: tensor(96.5950), 40: tensor(96.5967), 50: tensor(96.6517), 60: tensor(96.7483), 70: tensor(96.9433), 80: tensor(96.7817), 90: tensor(97.0283), 100: tensor(96.5983), 110: tensor(96.6033), 120: tensor(96.7533), 130: tensor(96.6650), 140: tensor(96.6467), 150: tensor(96.7483), 160: tensor(96.8500), 170: tensor(96.7300), 180: tensor(96.9700), 190: tensor(96.5283), 200: tensor(96.6850), 210: tensor(96.7583), 220: tensor(96.6933), 230: tensor(96.6750), 240: tensor(96.7967), 250: tensor(96.8633), 260: tensor(96.7717), 270: tensor(96.9717), 280: tensor(96.6283), 290: tensor(96.6350), 300: tensor(96.6000), 310: tensor(96.6033), 320: tensor(96.7133), 330: tensor(96.7467), 340: tensor(96.9267), 350: tensor(96.7517)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=35, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.8699,                   Accuracy: 246/2000.0 (12.30%)



-= Testing valid =-
Test set: Average loss: 2.2323,                   Accuracy: 383/2000.0 (19.15%)



-= Testing valid =-
Test set: Average loss: 1.3712,                   Accuracy: 1051/2000.0 (52.55%)



-= Testing valid =-
Test set: Average loss: 1.5491,                   Accuracy: 879/2000.0 (43.95%)



-= Testing valid =-
Test set: Average loss: 2.2190,                   Accuracy: 716/2000.0 (35.80%)



-= Testing valid =-
Test set: Average loss: 1.2639,                   Accuracy: 1170/2000.0 (58.50%)



-= Testing valid =-
Test set: Average loss: 0.3322,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.5913,                   Accuracy: 1632/2000.0 (81.60%)



-= Testing valid =-
Test set: Average loss: 0.3192,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.1984,                   Accuracy: 1890/2000.0 (94.50%)



Epoch 10 train accuracy: 92.69%, valid accuracy 94.50%
-= Testing valid =-
Test set: Average loss: 0.2059,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1627,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1648,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1827,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1582,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1336,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1436,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.2223,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2196,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.1532,                   Accuracy: 1921/2000.0 (96.05%)



Epoch 20 train accuracy: 95.04%, valid accuracy 96.05%
-= Testing valid =-
Test set: Average loss: 0.1420,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1298,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1442,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1329,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1471,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1239,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1255,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1149,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1094,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 30 train accuracy: 96.05%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.1128,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1084,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1094,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 40 train accuracy: 96.71%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.1015,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0981,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1042,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 50 train accuracy: 97.09%, valid accuracy 97.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1148,                   Accuracy: 58074/60000 (96.79%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1209,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1183,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1200,                   Accuracy: 58007/60000 (96.68%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1191,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1191,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1199,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1166,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1197,                   Accuracy: 57979/60000 (96.63%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1178,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1232,                   Accuracy: 57930/60000 (96.55%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1216,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1274,                   Accuracy: 57862/60000 (96.44%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1251,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1242,                   Accuracy: 57840/60000 (96.40%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1279,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1219,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1215,                   Accuracy: 57946/60000 (96.58%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1205,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1239,                   Accuracy: 57855/60000 (96.43%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1223,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1259,                   Accuracy: 57859/60000 (96.43%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1233,                   Accuracy: 57881/60000 (96.47%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1215,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1235,                   Accuracy: 57880/60000 (96.47%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1172,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1171,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1158,                   Accuracy: 58074/60000 (96.79%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1199,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1181,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1185,                   Accuracy: 58031/60000 (96.72%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1184,                   Accuracy: 57990/60000 (96.65%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1179,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1179,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1143,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1174,                   Accuracy: 58003/60000 (96.67%)
{0: tensor(96.7900), 10: tensor(96.5750), 20: tensor(96.7167), 30: tensor(96.6783), 40: tensor(96.6467), 50: tensor(96.6150), 60: tensor(96.6400), 70: tensor(96.7650), 80: tensor(96.6317), 90: tensor(96.6900), 100: tensor(96.5500), 110: tensor(96.6517), 120: tensor(96.4367), 130: tensor(96.4100), 140: tensor(96.4000), 150: tensor(96.3650), 160: tensor(96.5600), 170: tensor(96.5767), 180: tensor(96.6200), 190: tensor(96.4250), 200: tensor(96.5717), 210: tensor(96.4317), 220: tensor(96.4683), 230: tensor(96.5283), 240: tensor(96.4667), 250: tensor(96.7167), 260: tensor(96.7000), 270: tensor(96.7900), 280: tensor(96.5867), 290: tensor(96.7283), 300: tensor(96.7183), 310: tensor(96.6500), 320: tensor(96.6767), 330: tensor(96.7333), 340: tensor(96.8100), 350: tensor(96.6717)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=36, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 10.1186,                   Accuracy: 199/2000.0 (9.95%)



-= Testing valid =-
Test set: Average loss: 2.6488,                   Accuracy: 417/2000.0 (20.85%)



-= Testing valid =-
Test set: Average loss: 2.5452,                   Accuracy: 845/2000.0 (42.25%)



-= Testing valid =-
Test set: Average loss: 0.5929,                   Accuracy: 1634/2000.0 (81.70%)



-= Testing valid =-
Test set: Average loss: 1.4930,                   Accuracy: 1108/2000.0 (55.40%)



-= Testing valid =-
Test set: Average loss: 0.7872,                   Accuracy: 1544/2000.0 (77.20%)



-= Testing valid =-
Test set: Average loss: 0.4345,                   Accuracy: 1702/2000.0 (85.10%)



-= Testing valid =-
Test set: Average loss: 0.2118,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.1981,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.3821,                   Accuracy: 1727/2000.0 (86.35%)



Epoch 10 train accuracy: 93.50%, valid accuracy 86.35%
-= Testing valid =-
Test set: Average loss: 0.1798,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1964,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1496,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1234,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.2531,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.1442,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1259,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1201,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1739,                   Accuracy: 1890/2000.0 (94.50%)



Epoch 20 train accuracy: 95.84%, valid accuracy 94.50%
-= Testing valid =-
Test set: Average loss: 0.1206,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1140,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1097,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 30 train accuracy: 96.62%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 40 train accuracy: 96.84%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0752,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 50 train accuracy: 97.24%, valid accuracy 97.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1023,                   Accuracy: 58193/60000 (96.99%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1122,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1135,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1219,                   Accuracy: 57860/60000 (96.43%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1244,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1251,                   Accuracy: 57777/60000 (96.29%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1212,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1130,                   Accuracy: 57997/60000 (96.66%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1115,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1053,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1171,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1162,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1231,                   Accuracy: 57797/60000 (96.33%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1257,                   Accuracy: 57768/60000 (96.28%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1267,                   Accuracy: 57706/60000 (96.18%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1223,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1162,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1139,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1079,                   Accuracy: 58064/60000 (96.77%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1167,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1156,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1222,                   Accuracy: 57834/60000 (96.39%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1238,                   Accuracy: 57801/60000 (96.33%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1221,                   Accuracy: 57852/60000 (96.42%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1181,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1114,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1112,                   Accuracy: 58019/60000 (96.70%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1038,                   Accuracy: 58192/60000 (96.99%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1117,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1138,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1215,                   Accuracy: 57879/60000 (96.46%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1227,                   Accuracy: 57860/60000 (96.43%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1220,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1171,                   Accuracy: 57959/60000 (96.60%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1092,                   Accuracy: 58084/60000 (96.81%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1086,                   Accuracy: 58109/60000 (96.85%)
{0: tensor(96.9883), 10: tensor(96.7050), 20: tensor(96.6717), 30: tensor(96.4333), 40: tensor(96.3400), 50: tensor(96.2950), 60: tensor(96.3817), 70: tensor(96.6617), 80: tensor(96.6967), 90: tensor(96.9217), 100: tensor(96.4783), 110: tensor(96.5800), 120: tensor(96.3283), 130: tensor(96.2800), 140: tensor(96.1767), 150: tensor(96.3400), 160: tensor(96.5117), 170: tensor(96.5317), 180: tensor(96.7733), 190: tensor(96.4767), 200: tensor(96.5800), 210: tensor(96.3900), 220: tensor(96.3350), 230: tensor(96.4200), 240: tensor(96.4633), 250: tensor(96.6833), 260: tensor(96.6983), 270: tensor(96.9867), 280: tensor(96.6917), 290: tensor(96.7317), 300: tensor(96.4650), 310: tensor(96.4333), 320: tensor(96.4750), 330: tensor(96.5983), 340: tensor(96.8067), 350: tensor(96.8483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=37, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1011,                   Accuracy: 593/2000.0 (29.65%)



-= Testing valid =-
Test set: Average loss: 1.8953,                   Accuracy: 727/2000.0 (36.35%)



-= Testing valid =-
Test set: Average loss: 1.9876,                   Accuracy: 728/2000.0 (36.40%)



-= Testing valid =-
Test set: Average loss: 0.8370,                   Accuracy: 1473/2000.0 (73.65%)



-= Testing valid =-
Test set: Average loss: 0.3516,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.2869,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2567,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.1850,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.5277,                   Accuracy: 1641/2000.0 (82.05%)



-= Testing valid =-
Test set: Average loss: 0.1472,                   Accuracy: 1911/2000.0 (95.55%)



Epoch 10 train accuracy: 93.05%, valid accuracy 95.55%
-= Testing valid =-
Test set: Average loss: 0.1525,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1414,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1544,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1506,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1139,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1069,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1015,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 20 train accuracy: 95.69%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 30 train accuracy: 96.69%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0775,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 40 train accuracy: 96.94%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0720,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0641,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0630,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 50 train accuracy: 97.38%, valid accuracy 97.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1001,                   Accuracy: 58262/60000 (97.10%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1043,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1045,                   Accuracy: 58117/60000 (96.86%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1103,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1118,                   Accuracy: 57978/60000 (96.63%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1121,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1106,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1054,                   Accuracy: 58157/60000 (96.93%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1073,                   Accuracy: 58129/60000 (96.88%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1048,                   Accuracy: 58195/60000 (96.99%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1086,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1085,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1173,                   Accuracy: 57831/60000 (96.39%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1187,                   Accuracy: 57852/60000 (96.42%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1202,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1200,                   Accuracy: 57854/60000 (96.42%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1139,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1157,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1114,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1131,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1114,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1183,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1174,                   Accuracy: 57832/60000 (96.39%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1178,                   Accuracy: 57905/60000 (96.51%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1158,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1096,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1102,                   Accuracy: 58049/60000 (96.75%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1045,                   Accuracy: 58169/60000 (96.95%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1069,                   Accuracy: 58091/60000 (96.82%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1057,                   Accuracy: 58061/60000 (96.77%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1107,                   Accuracy: 57990/60000 (96.65%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1107,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1106,                   Accuracy: 58064/60000 (96.77%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1084,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1027,                   Accuracy: 58208/60000 (97.01%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1039,                   Accuracy: 58178/60000 (96.96%)
{0: tensor(97.1033), 10: tensor(96.8717), 20: tensor(96.8617), 30: tensor(96.6067), 40: tensor(96.6300), 50: tensor(96.6533), 60: tensor(96.7567), 70: tensor(96.9283), 80: tensor(96.8817), 90: tensor(96.9917), 100: tensor(96.7867), 110: tensor(96.6967), 120: tensor(96.3850), 130: tensor(96.4200), 140: tensor(96.4017), 150: tensor(96.4233), 160: tensor(96.5750), 170: tensor(96.5333), 180: tensor(96.7000), 190: tensor(96.5617), 200: tensor(96.5850), 210: tensor(96.3400), 220: tensor(96.3867), 230: tensor(96.5083), 240: tensor(96.6050), 250: tensor(96.7633), 260: tensor(96.7483), 270: tensor(96.9483), 280: tensor(96.8183), 290: tensor(96.7683), 300: tensor(96.6500), 310: tensor(96.6533), 320: tensor(96.7733), 330: tensor(96.8750), 340: tensor(97.0133), 350: tensor(96.9633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=38, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.8637,                   Accuracy: 266/2000.0 (13.30%)



-= Testing valid =-
Test set: Average loss: 1.5089,                   Accuracy: 886/2000.0 (44.30%)



-= Testing valid =-
Test set: Average loss: 1.0836,                   Accuracy: 1165/2000.0 (58.25%)



-= Testing valid =-
Test set: Average loss: 0.5910,                   Accuracy: 1654/2000.0 (82.70%)



-= Testing valid =-
Test set: Average loss: 0.3411,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.3222,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.2877,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2357,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.2246,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1407,                   Accuracy: 1912/2000.0 (95.60%)



Epoch 10 train accuracy: 93.29%, valid accuracy 95.60%
-= Testing valid =-
Test set: Average loss: 0.1443,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1392,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1076,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1142,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.2082,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.1325,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1152,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1113,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1110,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 20 train accuracy: 95.84%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 30 train accuracy: 96.95%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0691,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 40 train accuracy: 97.10%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0746,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0678,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0691,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 50 train accuracy: 97.11%, valid accuracy 97.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1030,                   Accuracy: 58172/60000 (96.95%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1114,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1094,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1099,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1088,                   Accuracy: 58098/60000 (96.83%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1073,                   Accuracy: 58106/60000 (96.84%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1060,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1055,                   Accuracy: 58144/60000 (96.91%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1108,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1050,                   Accuracy: 58149/60000 (96.92%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1138,                   Accuracy: 57949/60000 (96.58%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1102,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1108,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1078,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1064,                   Accuracy: 58105/60000 (96.84%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1059,                   Accuracy: 58105/60000 (96.84%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1037,                   Accuracy: 58154/60000 (96.92%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1086,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1050,                   Accuracy: 58119/60000 (96.86%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1146,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1082,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1077,                   Accuracy: 58116/60000 (96.86%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1041,                   Accuracy: 58147/60000 (96.91%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1026,                   Accuracy: 58200/60000 (97.00%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1026,                   Accuracy: 58183/60000 (96.97%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1007,                   Accuracy: 58237/60000 (97.06%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1056,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1023,                   Accuracy: 58183/60000 (96.97%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1112,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1071,                   Accuracy: 58082/60000 (96.80%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1065,                   Accuracy: 58158/60000 (96.93%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1055,                   Accuracy: 58160/60000 (96.93%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1040,                   Accuracy: 58167/60000 (96.94%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1027,                   Accuracy: 58206/60000 (97.01%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1026,                   Accuracy: 58197/60000 (97.00%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1078,                   Accuracy: 58080/60000 (96.80%)
{0: tensor(96.9533), 10: tensor(96.6767), 20: tensor(96.7417), 30: tensor(96.8167), 40: tensor(96.8300), 50: tensor(96.8433), 60: tensor(96.8717), 70: tensor(96.9067), 80: tensor(96.6933), 90: tensor(96.9150), 100: tensor(96.5817), 110: tensor(96.7283), 120: tensor(96.7550), 130: tensor(96.7800), 140: tensor(96.8417), 150: tensor(96.8417), 160: tensor(96.9233), 170: tensor(96.7533), 180: tensor(96.8650), 190: tensor(96.5367), 200: tensor(96.8083), 210: tensor(96.8600), 220: tensor(96.9117), 230: tensor(97.), 240: tensor(96.9717), 250: tensor(97.0617), 260: tensor(96.8767), 270: tensor(96.9717), 280: tensor(96.6767), 290: tensor(96.8033), 300: tensor(96.9300), 310: tensor(96.9333), 320: tensor(96.9450), 330: tensor(97.0100), 340: tensor(96.9950), 350: tensor(96.8000)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=39, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.7968,                   Accuracy: 259/2000.0 (12.95%)



-= Testing valid =-
Test set: Average loss: 3.3819,                   Accuracy: 210/2000.0 (10.50%)



-= Testing valid =-
Test set: Average loss: 1.0744,                   Accuracy: 1310/2000.0 (65.50%)



-= Testing valid =-
Test set: Average loss: 2.5351,                   Accuracy: 754/2000.0 (37.70%)



-= Testing valid =-
Test set: Average loss: 0.6297,                   Accuracy: 1606/2000.0 (80.30%)



-= Testing valid =-
Test set: Average loss: 0.3816,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.3603,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.3420,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.3151,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.1692,                   Accuracy: 1894/2000.0 (94.70%)



Epoch 10 train accuracy: 93.28%, valid accuracy 94.70%
-= Testing valid =-
Test set: Average loss: 0.1818,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1659,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1528,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1298,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1739,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1431,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1564,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1955,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1671,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1582,                   Accuracy: 1899/2000.0 (94.95%)



Epoch 20 train accuracy: 95.60%, valid accuracy 94.95%
-= Testing valid =-
Test set: Average loss: 0.1324,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1356,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1398,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1153,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1621,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1213,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1214,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1157,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1136,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1053,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 30 train accuracy: 96.59%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.1170,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1105,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1042,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1033,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1037,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 40 train accuracy: 96.97%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1149,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 50 train accuracy: 97.05%, valid accuracy 97.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1129,                   Accuracy: 58064/60000 (96.77%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1119,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1072,                   Accuracy: 58144/60000 (96.91%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1115,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1157,                   Accuracy: 57978/60000 (96.63%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1193,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1214,                   Accuracy: 57871/60000 (96.45%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1185,                   Accuracy: 57940/60000 (96.57%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1164,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1145,                   Accuracy: 58028/60000 (96.71%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1112,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1066,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1125,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1149,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1181,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1246,                   Accuracy: 57798/60000 (96.33%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1171,                   Accuracy: 57916/60000 (96.53%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1164,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1131,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1116,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1050,                   Accuracy: 58171/60000 (96.95%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1125,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1126,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1152,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1200,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1146,                   Accuracy: 58002/60000 (96.67%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1120,                   Accuracy: 58076/60000 (96.79%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1099,                   Accuracy: 58124/60000 (96.87%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1107,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1048,                   Accuracy: 58157/60000 (96.93%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1116,                   Accuracy: 58034/60000 (96.72%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1136,                   Accuracy: 58022/60000 (96.70%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1165,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1187,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1164,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1129,                   Accuracy: 58048/60000 (96.75%)
{0: tensor(96.7733), 10: tensor(96.7800), 20: tensor(96.9067), 30: tensor(96.7633), 40: tensor(96.6300), 50: tensor(96.4917), 60: tensor(96.4517), 70: tensor(96.5667), 80: tensor(96.7267), 90: tensor(96.7133), 100: tensor(96.7400), 110: tensor(96.8717), 120: tensor(96.7017), 130: tensor(96.6167), 140: tensor(96.5317), 150: tensor(96.3300), 160: tensor(96.5267), 170: tensor(96.6917), 180: tensor(96.7283), 190: tensor(96.6933), 200: tensor(96.9517), 210: tensor(96.6267), 220: tensor(96.7067), 230: tensor(96.6433), 240: tensor(96.5283), 250: tensor(96.6700), 260: tensor(96.7933), 270: tensor(96.8733), 280: tensor(96.7417), 290: tensor(96.9283), 300: tensor(96.7233), 310: tensor(96.7033), 320: tensor(96.5583), 330: tensor(96.5367), 340: tensor(96.6333), 350: tensor(96.7467)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=40, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7844,                   Accuracy: 644/2000.0 (32.20%)



-= Testing valid =-
Test set: Average loss: 1.3546,                   Accuracy: 1141/2000.0 (57.05%)



-= Testing valid =-
Test set: Average loss: 1.7614,                   Accuracy: 875/2000.0 (43.75%)



-= Testing valid =-
Test set: Average loss: 0.3708,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.2552,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2676,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.3327,                   Accuracy: 1756/2000.0 (87.80%)



-= Testing valid =-
Test set: Average loss: 0.1718,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1975,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.2458,                   Accuracy: 1852/2000.0 (92.60%)



Epoch 10 train accuracy: 93.62%, valid accuracy 92.60%
-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1096,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1159,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1033,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1214,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1303,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 20 train accuracy: 95.84%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0736,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0608,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 30 train accuracy: 96.84%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0595,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0567,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0619,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0594,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0594,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0555,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 40 train accuracy: 97.22%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0559,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0585,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0579,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0558,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 50 train accuracy: 97.40%, valid accuracy 98.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0899,                   Accuracy: 58397/60000 (97.33%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0932,                   Accuracy: 58361/60000 (97.27%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0967,                   Accuracy: 58248/60000 (97.08%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1018,                   Accuracy: 58192/60000 (96.99%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1036,                   Accuracy: 58157/60000 (96.93%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1057,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1031,                   Accuracy: 58137/60000 (96.89%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0981,                   Accuracy: 58258/60000 (97.10%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.0973,                   Accuracy: 58220/60000 (97.03%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0959,                   Accuracy: 58267/60000 (97.11%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.0976,                   Accuracy: 58248/60000 (97.08%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1050,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1135,                   Accuracy: 57912/60000 (96.52%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1150,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1176,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1185,                   Accuracy: 57832/60000 (96.39%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1080,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1073,                   Accuracy: 57994/60000 (96.66%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1063,                   Accuracy: 58028/60000 (96.71%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1126,                   Accuracy: 57910/60000 (96.52%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1103,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1151,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1133,                   Accuracy: 57896/60000 (96.49%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1125,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1100,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1010,                   Accuracy: 58190/60000 (96.98%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.0965,                   Accuracy: 58262/60000 (97.10%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0962,                   Accuracy: 58276/60000 (97.13%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1029,                   Accuracy: 58168/60000 (96.95%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0984,                   Accuracy: 58255/60000 (97.09%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1013,                   Accuracy: 58202/60000 (97.00%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1020,                   Accuracy: 58160/60000 (96.93%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1019,                   Accuracy: 58186/60000 (96.98%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0982,                   Accuracy: 58248/60000 (97.08%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0936,                   Accuracy: 58335/60000 (97.22%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0904,                   Accuracy: 58355/60000 (97.26%)
{0: tensor(97.3283), 10: tensor(97.2683), 20: tensor(97.0800), 30: tensor(96.9867), 40: tensor(96.9283), 50: tensor(96.8483), 60: tensor(96.8950), 70: tensor(97.0967), 80: tensor(97.0333), 90: tensor(97.1117), 100: tensor(97.0800), 110: tensor(96.7717), 120: tensor(96.5200), 130: tensor(96.5367), 140: tensor(96.4300), 150: tensor(96.3867), 160: tensor(96.6733), 170: tensor(96.6567), 180: tensor(96.7133), 190: tensor(96.5167), 200: tensor(96.6033), 210: tensor(96.4750), 220: tensor(96.4933), 230: tensor(96.6000), 240: tensor(96.6917), 250: tensor(96.9833), 260: tensor(97.1033), 270: tensor(97.1267), 280: tensor(96.9467), 290: tensor(97.0917), 300: tensor(97.0033), 310: tensor(96.9333), 320: tensor(96.9767), 330: tensor(97.0800), 340: tensor(97.2250), 350: tensor(97.2583)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=11, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3742,                   Accuracy: 460/2000.0 (23.00%)



-= Testing valid =-
Test set: Average loss: 3.0695,                   Accuracy: 370/2000.0 (18.50%)



-= Testing valid =-
Test set: Average loss: 1.6204,                   Accuracy: 791/2000.0 (39.55%)



-= Testing valid =-
Test set: Average loss: 1.6906,                   Accuracy: 755/2000.0 (37.75%)



-= Testing valid =-
Test set: Average loss: 1.5102,                   Accuracy: 970/2000.0 (48.50%)



-= Testing valid =-
Test set: Average loss: 1.5122,                   Accuracy: 914/2000.0 (45.70%)



-= Testing valid =-
Test set: Average loss: 2.2378,                   Accuracy: 754/2000.0 (37.70%)



-= Testing valid =-
Test set: Average loss: 1.2729,                   Accuracy: 1210/2000.0 (60.50%)



-= Testing valid =-
Test set: Average loss: 0.9401,                   Accuracy: 1394/2000.0 (69.70%)



-= Testing valid =-
Test set: Average loss: 0.9167,                   Accuracy: 1380/2000.0 (69.00%)



Epoch 10 train accuracy: 74.85%, valid accuracy 69.00%
-= Testing valid =-
Test set: Average loss: 0.8535,                   Accuracy: 1451/2000.0 (72.55%)



-= Testing valid =-
Test set: Average loss: 0.8054,                   Accuracy: 1410/2000.0 (70.50%)



-= Testing valid =-
Test set: Average loss: 0.5893,                   Accuracy: 1626/2000.0 (81.30%)



-= Testing valid =-
Test set: Average loss: 0.5016,                   Accuracy: 1680/2000.0 (84.00%)



-= Testing valid =-
Test set: Average loss: 0.4913,                   Accuracy: 1683/2000.0 (84.15%)



-= Testing valid =-
Test set: Average loss: 0.5209,                   Accuracy: 1657/2000.0 (82.85%)



-= Testing valid =-
Test set: Average loss: 0.4800,                   Accuracy: 1664/2000.0 (83.20%)



-= Testing valid =-
Test set: Average loss: 0.5041,                   Accuracy: 1658/2000.0 (82.90%)



-= Testing valid =-
Test set: Average loss: 0.5969,                   Accuracy: 1576/2000.0 (78.80%)



-= Testing valid =-
Test set: Average loss: 0.6767,                   Accuracy: 1531/2000.0 (76.55%)



Epoch 20 train accuracy: 86.74%, valid accuracy 76.55%
-= Testing valid =-
Test set: Average loss: 0.4159,                   Accuracy: 1738/2000.0 (86.90%)



-= Testing valid =-
Test set: Average loss: 0.3850,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 0.3136,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.2779,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.3993,                   Accuracy: 1733/2000.0 (86.65%)



-= Testing valid =-
Test set: Average loss: 0.4071,                   Accuracy: 1729/2000.0 (86.45%)



-= Testing valid =-
Test set: Average loss: 0.3440,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.3160,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.3445,                   Accuracy: 1756/2000.0 (87.80%)



-= Testing valid =-
Test set: Average loss: 0.3235,                   Accuracy: 1797/2000.0 (89.85%)



Epoch 30 train accuracy: 89.05%, valid accuracy 89.85%
-= Testing valid =-
Test set: Average loss: 0.3157,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.2706,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2806,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2904,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.3140,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.2983,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2908,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.3219,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.3107,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.3738,                   Accuracy: 1742/2000.0 (87.10%)



Epoch 40 train accuracy: 90.30%, valid accuracy 87.10%
-= Testing valid =-
Test set: Average loss: 0.2822,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.2929,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.2664,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2601,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2908,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2848,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.2725,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2960,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2824,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.2687,                   Accuracy: 1826/2000.0 (91.30%)



Epoch 50 train accuracy: 90.81%, valid accuracy 91.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2858,                   Accuracy: 54947/60000 (91.58%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2824,                   Accuracy: 54998/60000 (91.66%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2915,                   Accuracy: 54777/60000 (91.29%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2949,                   Accuracy: 54669/60000 (91.11%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3005,                   Accuracy: 54579/60000 (90.96%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3129,                   Accuracy: 54368/60000 (90.61%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3247,                   Accuracy: 54119/60000 (90.20%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3394,                   Accuracy: 53835/60000 (89.72%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3435,                   Accuracy: 53729/60000 (89.55%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3660,                   Accuracy: 53363/60000 (88.94%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3897,                   Accuracy: 52790/60000 (87.98%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.4125,                   Accuracy: 52113/60000 (86.86%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4135,                   Accuracy: 51792/60000 (86.32%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4216,                   Accuracy: 51615/60000 (86.03%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.4284,                   Accuracy: 51280/60000 (85.47%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4228,                   Accuracy: 51306/60000 (85.51%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4152,                   Accuracy: 51546/60000 (85.91%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3931,                   Accuracy: 52092/60000 (86.82%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3886,                   Accuracy: 52265/60000 (87.11%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3878,                   Accuracy: 52289/60000 (87.15%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3899,                   Accuracy: 52137/60000 (86.89%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3891,                   Accuracy: 52118/60000 (86.86%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3914,                   Accuracy: 52014/60000 (86.69%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3973,                   Accuracy: 51843/60000 (86.40%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3969,                   Accuracy: 51882/60000 (86.47%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3849,                   Accuracy: 52351/60000 (87.25%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3633,                   Accuracy: 52945/60000 (88.24%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3644,                   Accuracy: 52983/60000 (88.31%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3415,                   Accuracy: 53637/60000 (89.39%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3339,                   Accuracy: 53835/60000 (89.72%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3303,                   Accuracy: 53936/60000 (89.89%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3189,                   Accuracy: 54257/60000 (90.43%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3093,                   Accuracy: 54515/60000 (90.86%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3071,                   Accuracy: 54540/60000 (90.90%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2966,                   Accuracy: 54810/60000 (91.35%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2788,                   Accuracy: 55086/60000 (91.81%)
{0: tensor(91.5783), 10: tensor(91.6633), 20: tensor(91.2950), 30: tensor(91.1150), 40: tensor(90.9650), 50: tensor(90.6133), 60: tensor(90.1983), 70: tensor(89.7250), 80: tensor(89.5483), 90: tensor(88.9383), 100: tensor(87.9833), 110: tensor(86.8550), 120: tensor(86.3200), 130: tensor(86.0250), 140: tensor(85.4667), 150: tensor(85.5100), 160: tensor(85.9100), 170: tensor(86.8200), 180: tensor(87.1083), 190: tensor(87.1483), 200: tensor(86.8950), 210: tensor(86.8633), 220: tensor(86.6900), 230: tensor(86.4050), 240: tensor(86.4700), 250: tensor(87.2517), 260: tensor(88.2417), 270: tensor(88.3050), 280: tensor(89.3950), 290: tensor(89.7250), 300: tensor(89.8933), 310: tensor(90.4283), 320: tensor(90.8583), 330: tensor(90.9000), 340: tensor(91.3500), 350: tensor(91.8100)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=12, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.0595,                   Accuracy: 230/2000.0 (11.50%)



-= Testing valid =-
Test set: Average loss: 1.9619,                   Accuracy: 624/2000.0 (31.20%)



-= Testing valid =-
Test set: Average loss: 2.8044,                   Accuracy: 543/2000.0 (27.15%)



-= Testing valid =-
Test set: Average loss: 2.3680,                   Accuracy: 649/2000.0 (32.45%)



-= Testing valid =-
Test set: Average loss: 1.9659,                   Accuracy: 687/2000.0 (34.35%)



-= Testing valid =-
Test set: Average loss: 0.9370,                   Accuracy: 1395/2000.0 (69.75%)



-= Testing valid =-
Test set: Average loss: 1.5702,                   Accuracy: 1021/2000.0 (51.05%)



-= Testing valid =-
Test set: Average loss: 1.1219,                   Accuracy: 1152/2000.0 (57.60%)



-= Testing valid =-
Test set: Average loss: 0.9546,                   Accuracy: 1330/2000.0 (66.50%)



-= Testing valid =-
Test set: Average loss: 0.7596,                   Accuracy: 1516/2000.0 (75.80%)



Epoch 10 train accuracy: 71.85%, valid accuracy 75.80%
-= Testing valid =-
Test set: Average loss: 0.8611,                   Accuracy: 1373/2000.0 (68.65%)



-= Testing valid =-
Test set: Average loss: 0.6683,                   Accuracy: 1543/2000.0 (77.15%)



-= Testing valid =-
Test set: Average loss: 0.5936,                   Accuracy: 1626/2000.0 (81.30%)



-= Testing valid =-
Test set: Average loss: 0.5066,                   Accuracy: 1679/2000.0 (83.95%)



-= Testing valid =-
Test set: Average loss: 0.6930,                   Accuracy: 1482/2000.0 (74.10%)



-= Testing valid =-
Test set: Average loss: 0.4899,                   Accuracy: 1682/2000.0 (84.10%)



-= Testing valid =-
Test set: Average loss: 0.4214,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.7477,                   Accuracy: 1477/2000.0 (73.85%)



-= Testing valid =-
Test set: Average loss: 0.4782,                   Accuracy: 1702/2000.0 (85.10%)



-= Testing valid =-
Test set: Average loss: 0.5416,                   Accuracy: 1636/2000.0 (81.80%)



Epoch 20 train accuracy: 84.75%, valid accuracy 81.80%
-= Testing valid =-
Test set: Average loss: 0.3379,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.3047,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2774,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2778,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.2904,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.3618,                   Accuracy: 1756/2000.0 (87.80%)



-= Testing valid =-
Test set: Average loss: 0.3333,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.2456,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.2724,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.3436,                   Accuracy: 1787/2000.0 (89.35%)



Epoch 30 train accuracy: 87.84%, valid accuracy 89.35%
-= Testing valid =-
Test set: Average loss: 0.2521,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2946,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.3316,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.2840,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.3095,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.3106,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.3047,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.3124,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.2553,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2636,                   Accuracy: 1837/2000.0 (91.85%)



Epoch 40 train accuracy: 89.79%, valid accuracy 91.85%
-= Testing valid =-
Test set: Average loss: 0.2981,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2748,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2898,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.3208,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.2761,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2612,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2844,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.2784,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2597,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2905,                   Accuracy: 1822/2000.0 (91.10%)



Epoch 50 train accuracy: 89.76%, valid accuracy 91.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2703,                   Accuracy: 55297/60000 (92.16%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2865,                   Accuracy: 54928/60000 (91.55%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2866,                   Accuracy: 55076/60000 (91.79%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2911,                   Accuracy: 55000/60000 (91.67%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2908,                   Accuracy: 55012/60000 (91.69%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2942,                   Accuracy: 54969/60000 (91.61%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3005,                   Accuracy: 54732/60000 (91.22%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3030,                   Accuracy: 54621/60000 (91.04%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3092,                   Accuracy: 54385/60000 (90.64%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3285,                   Accuracy: 53890/60000 (89.82%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3639,                   Accuracy: 53122/60000 (88.54%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3842,                   Accuracy: 52750/60000 (87.92%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4140,                   Accuracy: 52092/60000 (86.82%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4309,                   Accuracy: 51723/60000 (86.21%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.4480,                   Accuracy: 51310/60000 (85.52%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4547,                   Accuracy: 51123/60000 (85.21%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4562,                   Accuracy: 51128/60000 (85.21%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.4534,                   Accuracy: 51230/60000 (85.38%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.4489,                   Accuracy: 51216/60000 (85.36%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.4538,                   Accuracy: 51144/60000 (85.24%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.4442,                   Accuracy: 51345/60000 (85.57%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4541,                   Accuracy: 51041/60000 (85.07%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4486,                   Accuracy: 51133/60000 (85.22%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4382,                   Accuracy: 51529/60000 (85.88%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4178,                   Accuracy: 51934/60000 (86.56%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3997,                   Accuracy: 52393/60000 (87.32%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3821,                   Accuracy: 52607/60000 (87.68%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3574,                   Accuracy: 53314/60000 (88.86%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3584,                   Accuracy: 53284/60000 (88.81%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3359,                   Accuracy: 53792/60000 (89.65%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3208,                   Accuracy: 54116/60000 (90.19%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3007,                   Accuracy: 54505/60000 (90.84%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2854,                   Accuracy: 54877/60000 (91.46%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2732,                   Accuracy: 55076/60000 (91.79%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2717,                   Accuracy: 55171/60000 (91.95%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2799,                   Accuracy: 55081/60000 (91.80%)
{0: tensor(92.1617), 10: tensor(91.5467), 20: tensor(91.7933), 30: tensor(91.6667), 40: tensor(91.6867), 50: tensor(91.6150), 60: tensor(91.2200), 70: tensor(91.0350), 80: tensor(90.6417), 90: tensor(89.8167), 100: tensor(88.5367), 110: tensor(87.9167), 120: tensor(86.8200), 130: tensor(86.2050), 140: tensor(85.5167), 150: tensor(85.2050), 160: tensor(85.2133), 170: tensor(85.3833), 180: tensor(85.3600), 190: tensor(85.2400), 200: tensor(85.5750), 210: tensor(85.0683), 220: tensor(85.2217), 230: tensor(85.8817), 240: tensor(86.5567), 250: tensor(87.3217), 260: tensor(87.6783), 270: tensor(88.8567), 280: tensor(88.8067), 290: tensor(89.6533), 300: tensor(90.1933), 310: tensor(90.8417), 320: tensor(91.4617), 330: tensor(91.7933), 340: tensor(91.9517), 350: tensor(91.8017)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=13, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.8791,                   Accuracy: 329/2000.0 (16.45%)



-= Testing valid =-
Test set: Average loss: 2.5813,                   Accuracy: 381/2000.0 (19.05%)



-= Testing valid =-
Test set: Average loss: 2.0224,                   Accuracy: 565/2000.0 (28.25%)



-= Testing valid =-
Test set: Average loss: 2.7028,                   Accuracy: 546/2000.0 (27.30%)



-= Testing valid =-
Test set: Average loss: 1.0942,                   Accuracy: 1315/2000.0 (65.75%)



-= Testing valid =-
Test set: Average loss: 1.6939,                   Accuracy: 770/2000.0 (38.50%)



-= Testing valid =-
Test set: Average loss: 1.1656,                   Accuracy: 1185/2000.0 (59.25%)



-= Testing valid =-
Test set: Average loss: 0.8818,                   Accuracy: 1425/2000.0 (71.25%)



-= Testing valid =-
Test set: Average loss: 0.7512,                   Accuracy: 1515/2000.0 (75.75%)



-= Testing valid =-
Test set: Average loss: 1.1471,                   Accuracy: 1260/2000.0 (63.00%)



Epoch 10 train accuracy: 74.49%, valid accuracy 63.00%
-= Testing valid =-
Test set: Average loss: 0.7336,                   Accuracy: 1489/2000.0 (74.45%)



-= Testing valid =-
Test set: Average loss: 0.6472,                   Accuracy: 1553/2000.0 (77.65%)



-= Testing valid =-
Test set: Average loss: 0.7516,                   Accuracy: 1479/2000.0 (73.95%)



-= Testing valid =-
Test set: Average loss: 0.7147,                   Accuracy: 1507/2000.0 (75.35%)



-= Testing valid =-
Test set: Average loss: 0.7023,                   Accuracy: 1517/2000.0 (75.85%)



-= Testing valid =-
Test set: Average loss: 0.6108,                   Accuracy: 1552/2000.0 (77.60%)



-= Testing valid =-
Test set: Average loss: 0.9446,                   Accuracy: 1310/2000.0 (65.50%)



-= Testing valid =-
Test set: Average loss: 0.5031,                   Accuracy: 1699/2000.0 (84.95%)



-= Testing valid =-
Test set: Average loss: 0.5999,                   Accuracy: 1573/2000.0 (78.65%)



-= Testing valid =-
Test set: Average loss: 0.3600,                   Accuracy: 1784/2000.0 (89.20%)



Epoch 20 train accuracy: 86.78%, valid accuracy 89.20%
-= Testing valid =-
Test set: Average loss: 0.4203,                   Accuracy: 1717/2000.0 (85.85%)



-= Testing valid =-
Test set: Average loss: 0.3613,                   Accuracy: 1765/2000.0 (88.25%)



-= Testing valid =-
Test set: Average loss: 0.4758,                   Accuracy: 1673/2000.0 (83.65%)



-= Testing valid =-
Test set: Average loss: 0.2947,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.3539,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.3323,                   Accuracy: 1765/2000.0 (88.25%)



-= Testing valid =-
Test set: Average loss: 0.3117,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.4194,                   Accuracy: 1736/2000.0 (86.80%)



-= Testing valid =-
Test set: Average loss: 0.2741,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.3055,                   Accuracy: 1795/2000.0 (89.75%)



Epoch 30 train accuracy: 89.82%, valid accuracy 89.75%
-= Testing valid =-
Test set: Average loss: 0.2479,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.4153,                   Accuracy: 1730/2000.0 (86.50%)



-= Testing valid =-
Test set: Average loss: 0.3038,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.3206,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.3034,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.3046,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2777,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.3402,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.2842,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2718,                   Accuracy: 1831/2000.0 (91.55%)



Epoch 40 train accuracy: 90.75%, valid accuracy 91.55%
-= Testing valid =-
Test set: Average loss: 0.2714,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.3067,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.2407,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2500,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2744,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.3118,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2579,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2717,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2768,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2819,                   Accuracy: 1827/2000.0 (91.35%)



Epoch 50 train accuracy: 91.12%, valid accuracy 91.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2551,                   Accuracy: 55525/60000 (92.54%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2569,                   Accuracy: 55459/60000 (92.43%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2784,                   Accuracy: 55040/60000 (91.73%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2950,                   Accuracy: 54757/60000 (91.26%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3104,                   Accuracy: 54398/60000 (90.66%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3192,                   Accuracy: 54187/60000 (90.31%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3287,                   Accuracy: 53928/60000 (89.88%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3320,                   Accuracy: 53924/60000 (89.87%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3240,                   Accuracy: 54028/60000 (90.05%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3306,                   Accuracy: 53945/60000 (89.91%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3374,                   Accuracy: 53672/60000 (89.45%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3563,                   Accuracy: 53252/60000 (88.75%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3760,                   Accuracy: 52745/60000 (87.91%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3806,                   Accuracy: 52584/60000 (87.64%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3746,                   Accuracy: 52706/60000 (87.84%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3599,                   Accuracy: 52948/60000 (88.25%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3464,                   Accuracy: 53262/60000 (88.77%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3148,                   Accuracy: 53923/60000 (89.87%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3095,                   Accuracy: 53970/60000 (89.95%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3084,                   Accuracy: 53965/60000 (89.94%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2966,                   Accuracy: 54317/60000 (90.53%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.2974,                   Accuracy: 54363/60000 (90.61%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.2979,                   Accuracy: 54359/60000 (90.60%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.2964,                   Accuracy: 54381/60000 (90.64%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.2974,                   Accuracy: 54522/60000 (90.87%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2969,                   Accuracy: 54466/60000 (90.78%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2976,                   Accuracy: 54353/60000 (90.59%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2967,                   Accuracy: 54475/60000 (90.79%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2968,                   Accuracy: 54432/60000 (90.72%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3063,                   Accuracy: 54368/60000 (90.61%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3139,                   Accuracy: 54305/60000 (90.51%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3086,                   Accuracy: 54392/60000 (90.65%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2983,                   Accuracy: 54673/60000 (91.12%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2862,                   Accuracy: 54858/60000 (91.43%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2744,                   Accuracy: 55141/60000 (91.90%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2602,                   Accuracy: 55340/60000 (92.23%)
{0: tensor(92.5417), 10: tensor(92.4317), 20: tensor(91.7333), 30: tensor(91.2617), 40: tensor(90.6633), 50: tensor(90.3117), 60: tensor(89.8800), 70: tensor(89.8733), 80: tensor(90.0467), 90: tensor(89.9083), 100: tensor(89.4533), 110: tensor(88.7533), 120: tensor(87.9083), 130: tensor(87.6400), 140: tensor(87.8433), 150: tensor(88.2467), 160: tensor(88.7700), 170: tensor(89.8717), 180: tensor(89.9500), 190: tensor(89.9417), 200: tensor(90.5283), 210: tensor(90.6050), 220: tensor(90.5983), 230: tensor(90.6350), 240: tensor(90.8700), 250: tensor(90.7767), 260: tensor(90.5883), 270: tensor(90.7917), 280: tensor(90.7200), 290: tensor(90.6133), 300: tensor(90.5083), 310: tensor(90.6533), 320: tensor(91.1217), 330: tensor(91.4300), 340: tensor(91.9017), 350: tensor(92.2333)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=14, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.4734,                   Accuracy: 288/2000.0 (14.40%)



-= Testing valid =-
Test set: Average loss: 2.7368,                   Accuracy: 485/2000.0 (24.25%)



-= Testing valid =-
Test set: Average loss: 1.4530,                   Accuracy: 957/2000.0 (47.85%)



-= Testing valid =-
Test set: Average loss: 2.6048,                   Accuracy: 420/2000.0 (21.00%)



-= Testing valid =-
Test set: Average loss: 2.6453,                   Accuracy: 572/2000.0 (28.60%)



-= Testing valid =-
Test set: Average loss: 1.8310,                   Accuracy: 871/2000.0 (43.55%)



-= Testing valid =-
Test set: Average loss: 1.7883,                   Accuracy: 895/2000.0 (44.75%)



-= Testing valid =-
Test set: Average loss: 1.1236,                   Accuracy: 1182/2000.0 (59.10%)



-= Testing valid =-
Test set: Average loss: 1.1561,                   Accuracy: 1165/2000.0 (58.25%)



-= Testing valid =-
Test set: Average loss: 1.0165,                   Accuracy: 1342/2000.0 (67.10%)



Epoch 10 train accuracy: 70.36%, valid accuracy 67.10%
-= Testing valid =-
Test set: Average loss: 1.0284,                   Accuracy: 1300/2000.0 (65.00%)



-= Testing valid =-
Test set: Average loss: 0.9299,                   Accuracy: 1352/2000.0 (67.60%)



-= Testing valid =-
Test set: Average loss: 0.7055,                   Accuracy: 1524/2000.0 (76.20%)



-= Testing valid =-
Test set: Average loss: 0.6837,                   Accuracy: 1511/2000.0 (75.55%)



-= Testing valid =-
Test set: Average loss: 0.5708,                   Accuracy: 1621/2000.0 (81.05%)



-= Testing valid =-
Test set: Average loss: 0.5199,                   Accuracy: 1686/2000.0 (84.30%)



-= Testing valid =-
Test set: Average loss: 0.4986,                   Accuracy: 1698/2000.0 (84.90%)



-= Testing valid =-
Test set: Average loss: 0.4699,                   Accuracy: 1681/2000.0 (84.05%)



-= Testing valid =-
Test set: Average loss: 0.3482,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.3679,                   Accuracy: 1778/2000.0 (88.90%)



Epoch 20 train accuracy: 84.54%, valid accuracy 88.90%
-= Testing valid =-
Test set: Average loss: 0.4370,                   Accuracy: 1715/2000.0 (85.75%)



-= Testing valid =-
Test set: Average loss: 0.3840,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.3654,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.4382,                   Accuracy: 1717/2000.0 (85.85%)



-= Testing valid =-
Test set: Average loss: 0.5030,                   Accuracy: 1666/2000.0 (83.30%)



-= Testing valid =-
Test set: Average loss: 0.3696,                   Accuracy: 1768/2000.0 (88.40%)



-= Testing valid =-
Test set: Average loss: 0.3443,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.2957,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.4223,                   Accuracy: 1728/2000.0 (86.40%)



-= Testing valid =-
Test set: Average loss: 0.4754,                   Accuracy: 1677/2000.0 (83.85%)



Epoch 30 train accuracy: 88.05%, valid accuracy 83.85%
-= Testing valid =-
Test set: Average loss: 0.3295,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.3818,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.3210,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3687,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.3719,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3457,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.4227,                   Accuracy: 1715/2000.0 (85.75%)



-= Testing valid =-
Test set: Average loss: 0.3557,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.3086,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.3039,                   Accuracy: 1819/2000.0 (90.95%)



Epoch 40 train accuracy: 89.45%, valid accuracy 90.95%
-= Testing valid =-
Test set: Average loss: 0.2848,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.3182,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3136,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.3236,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.2981,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.3446,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.3307,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.3350,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.2967,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.3534,                   Accuracy: 1782/2000.0 (89.10%)



Epoch 50 train accuracy: 89.99%, valid accuracy 89.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3012,                   Accuracy: 54691/60000 (91.15%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2952,                   Accuracy: 54710/60000 (91.18%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3150,                   Accuracy: 54334/60000 (90.56%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3269,                   Accuracy: 54046/60000 (90.08%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3297,                   Accuracy: 54035/60000 (90.06%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3281,                   Accuracy: 54063/60000 (90.11%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3253,                   Accuracy: 54084/60000 (90.14%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3189,                   Accuracy: 54277/60000 (90.46%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3007,                   Accuracy: 54593/60000 (90.99%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3090,                   Accuracy: 54476/60000 (90.79%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3167,                   Accuracy: 54270/60000 (90.45%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3476,                   Accuracy: 53713/60000 (89.52%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3623,                   Accuracy: 53317/60000 (88.86%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3748,                   Accuracy: 52994/60000 (88.32%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3849,                   Accuracy: 52691/60000 (87.82%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3823,                   Accuracy: 52686/60000 (87.81%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3861,                   Accuracy: 52498/60000 (87.50%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3577,                   Accuracy: 52946/60000 (88.24%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3539,                   Accuracy: 53082/60000 (88.47%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3366,                   Accuracy: 53380/60000 (88.97%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3605,                   Accuracy: 52927/60000 (88.21%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3650,                   Accuracy: 52847/60000 (88.08%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3749,                   Accuracy: 52728/60000 (87.88%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3810,                   Accuracy: 52669/60000 (87.78%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3822,                   Accuracy: 52704/60000 (87.84%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3823,                   Accuracy: 52699/60000 (87.83%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3673,                   Accuracy: 52944/60000 (88.24%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3647,                   Accuracy: 52961/60000 (88.27%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3615,                   Accuracy: 53043/60000 (88.40%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3725,                   Accuracy: 52942/60000 (88.24%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3727,                   Accuracy: 52887/60000 (88.14%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3612,                   Accuracy: 53274/60000 (88.79%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3532,                   Accuracy: 53571/60000 (89.29%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3389,                   Accuracy: 53864/60000 (89.77%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3266,                   Accuracy: 54291/60000 (90.49%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2967,                   Accuracy: 54710/60000 (91.18%)
{0: tensor(91.1517), 10: tensor(91.1833), 20: tensor(90.5567), 30: tensor(90.0767), 40: tensor(90.0583), 50: tensor(90.1050), 60: tensor(90.1400), 70: tensor(90.4617), 80: tensor(90.9883), 90: tensor(90.7933), 100: tensor(90.4500), 110: tensor(89.5217), 120: tensor(88.8617), 130: tensor(88.3233), 140: tensor(87.8183), 150: tensor(87.8100), 160: tensor(87.4967), 170: tensor(88.2433), 180: tensor(88.4700), 190: tensor(88.9667), 200: tensor(88.2117), 210: tensor(88.0783), 220: tensor(87.8800), 230: tensor(87.7817), 240: tensor(87.8400), 250: tensor(87.8317), 260: tensor(88.2400), 270: tensor(88.2683), 280: tensor(88.4050), 290: tensor(88.2367), 300: tensor(88.1450), 310: tensor(88.7900), 320: tensor(89.2850), 330: tensor(89.7733), 340: tensor(90.4850), 350: tensor(91.1833)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=15, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.3997,                   Accuracy: 217/2000.0 (10.85%)



-= Testing valid =-
Test set: Average loss: 3.4642,                   Accuracy: 243/2000.0 (12.15%)



-= Testing valid =-
Test set: Average loss: 2.1739,                   Accuracy: 560/2000.0 (28.00%)



-= Testing valid =-
Test set: Average loss: 1.5024,                   Accuracy: 872/2000.0 (43.60%)



-= Testing valid =-
Test set: Average loss: 1.2334,                   Accuracy: 1166/2000.0 (58.30%)



-= Testing valid =-
Test set: Average loss: 1.1630,                   Accuracy: 1204/2000.0 (60.20%)



-= Testing valid =-
Test set: Average loss: 1.4384,                   Accuracy: 989/2000.0 (49.45%)



-= Testing valid =-
Test set: Average loss: 1.1147,                   Accuracy: 1262/2000.0 (63.10%)



-= Testing valid =-
Test set: Average loss: 0.7360,                   Accuracy: 1543/2000.0 (77.15%)



-= Testing valid =-
Test set: Average loss: 0.6604,                   Accuracy: 1570/2000.0 (78.50%)



Epoch 10 train accuracy: 69.82%, valid accuracy 78.50%
-= Testing valid =-
Test set: Average loss: 0.5727,                   Accuracy: 1668/2000.0 (83.40%)



-= Testing valid =-
Test set: Average loss: 0.4949,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.6871,                   Accuracy: 1550/2000.0 (77.50%)



-= Testing valid =-
Test set: Average loss: 0.4821,                   Accuracy: 1708/2000.0 (85.40%)



-= Testing valid =-
Test set: Average loss: 0.6935,                   Accuracy: 1546/2000.0 (77.30%)



-= Testing valid =-
Test set: Average loss: 0.4448,                   Accuracy: 1720/2000.0 (86.00%)



-= Testing valid =-
Test set: Average loss: 0.3977,                   Accuracy: 1748/2000.0 (87.40%)



-= Testing valid =-
Test set: Average loss: 0.4386,                   Accuracy: 1731/2000.0 (86.55%)



-= Testing valid =-
Test set: Average loss: 0.4087,                   Accuracy: 1739/2000.0 (86.95%)



-= Testing valid =-
Test set: Average loss: 0.3609,                   Accuracy: 1775/2000.0 (88.75%)



Epoch 20 train accuracy: 85.64%, valid accuracy 88.75%
-= Testing valid =-
Test set: Average loss: 0.3803,                   Accuracy: 1736/2000.0 (86.80%)



-= Testing valid =-
Test set: Average loss: 0.2652,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.3598,                   Accuracy: 1765/2000.0 (88.25%)



-= Testing valid =-
Test set: Average loss: 0.2811,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2950,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.3306,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.2836,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2992,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.3020,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2922,                   Accuracy: 1820/2000.0 (91.00%)



Epoch 30 train accuracy: 87.95%, valid accuracy 91.00%
-= Testing valid =-
Test set: Average loss: 0.2943,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.2735,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.2323,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2784,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2440,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2472,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2276,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2526,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2864,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2809,                   Accuracy: 1821/2000.0 (91.05%)



Epoch 40 train accuracy: 89.89%, valid accuracy 91.05%
-= Testing valid =-
Test set: Average loss: 0.2853,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2569,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2934,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.2863,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.2580,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2591,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2612,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2379,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.2649,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2619,                   Accuracy: 1828/2000.0 (91.40%)



Epoch 50 train accuracy: 90.45%, valid accuracy 91.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2699,                   Accuracy: 54923/60000 (91.54%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2897,                   Accuracy: 54543/60000 (90.90%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2849,                   Accuracy: 54673/60000 (91.12%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2892,                   Accuracy: 54508/60000 (90.85%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2938,                   Accuracy: 54365/60000 (90.61%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2991,                   Accuracy: 54214/60000 (90.36%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2989,                   Accuracy: 54299/60000 (90.50%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3088,                   Accuracy: 54272/60000 (90.45%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2979,                   Accuracy: 54398/60000 (90.66%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3013,                   Accuracy: 54412/60000 (90.69%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3201,                   Accuracy: 53919/60000 (89.86%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3306,                   Accuracy: 53772/60000 (89.62%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3362,                   Accuracy: 53568/60000 (89.28%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3485,                   Accuracy: 53299/60000 (88.83%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3457,                   Accuracy: 53317/60000 (88.86%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3395,                   Accuracy: 53368/60000 (88.95%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3454,                   Accuracy: 53248/60000 (88.75%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3359,                   Accuracy: 53417/60000 (89.03%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3234,                   Accuracy: 53754/60000 (89.59%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3357,                   Accuracy: 53543/60000 (89.24%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3362,                   Accuracy: 53550/60000 (89.25%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3379,                   Accuracy: 53480/60000 (89.13%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3357,                   Accuracy: 53572/60000 (89.29%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3330,                   Accuracy: 53649/60000 (89.42%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3268,                   Accuracy: 53631/60000 (89.39%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3263,                   Accuracy: 53693/60000 (89.49%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3100,                   Accuracy: 53995/60000 (89.99%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2933,                   Accuracy: 54373/60000 (90.62%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2847,                   Accuracy: 54590/60000 (90.98%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2790,                   Accuracy: 54698/60000 (91.16%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2780,                   Accuracy: 54679/60000 (91.13%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2793,                   Accuracy: 54679/60000 (91.13%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2722,                   Accuracy: 54875/60000 (91.46%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2654,                   Accuracy: 55032/60000 (91.72%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2678,                   Accuracy: 55061/60000 (91.77%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2736,                   Accuracy: 54907/60000 (91.51%)
{0: tensor(91.5383), 10: tensor(90.9050), 20: tensor(91.1217), 30: tensor(90.8467), 40: tensor(90.6083), 50: tensor(90.3567), 60: tensor(90.4983), 70: tensor(90.4533), 80: tensor(90.6633), 90: tensor(90.6867), 100: tensor(89.8650), 110: tensor(89.6200), 120: tensor(89.2800), 130: tensor(88.8317), 140: tensor(88.8617), 150: tensor(88.9467), 160: tensor(88.7467), 170: tensor(89.0283), 180: tensor(89.5900), 190: tensor(89.2383), 200: tensor(89.2500), 210: tensor(89.1333), 220: tensor(89.2867), 230: tensor(89.4150), 240: tensor(89.3850), 250: tensor(89.4883), 260: tensor(89.9917), 270: tensor(90.6217), 280: tensor(90.9833), 290: tensor(91.1633), 300: tensor(91.1317), 310: tensor(91.1317), 320: tensor(91.4583), 330: tensor(91.7200), 340: tensor(91.7683), 350: tensor(91.5117)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=16, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8016,                   Accuracy: 494/2000.0 (24.70%)



-= Testing valid =-
Test set: Average loss: 1.8104,                   Accuracy: 738/2000.0 (36.90%)



-= Testing valid =-
Test set: Average loss: 2.0965,                   Accuracy: 623/2000.0 (31.15%)



-= Testing valid =-
Test set: Average loss: 1.3780,                   Accuracy: 1007/2000.0 (50.35%)



-= Testing valid =-
Test set: Average loss: 2.3400,                   Accuracy: 594/2000.0 (29.70%)



-= Testing valid =-
Test set: Average loss: 2.3556,                   Accuracy: 595/2000.0 (29.75%)



-= Testing valid =-
Test set: Average loss: 1.0926,                   Accuracy: 1244/2000.0 (62.20%)



-= Testing valid =-
Test set: Average loss: 1.6358,                   Accuracy: 771/2000.0 (38.55%)



-= Testing valid =-
Test set: Average loss: 1.5602,                   Accuracy: 965/2000.0 (48.25%)



-= Testing valid =-
Test set: Average loss: 1.1218,                   Accuracy: 1191/2000.0 (59.55%)



Epoch 10 train accuracy: 73.31%, valid accuracy 59.55%
-= Testing valid =-
Test set: Average loss: 0.7139,                   Accuracy: 1555/2000.0 (77.75%)



-= Testing valid =-
Test set: Average loss: 0.7517,                   Accuracy: 1494/2000.0 (74.70%)



-= Testing valid =-
Test set: Average loss: 0.5116,                   Accuracy: 1672/2000.0 (83.60%)



-= Testing valid =-
Test set: Average loss: 0.5376,                   Accuracy: 1660/2000.0 (83.00%)



-= Testing valid =-
Test set: Average loss: 0.7196,                   Accuracy: 1477/2000.0 (73.85%)



-= Testing valid =-
Test set: Average loss: 0.5392,                   Accuracy: 1647/2000.0 (82.35%)



-= Testing valid =-
Test set: Average loss: 0.3055,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.4982,                   Accuracy: 1683/2000.0 (84.15%)



-= Testing valid =-
Test set: Average loss: 0.6533,                   Accuracy: 1559/2000.0 (77.95%)



-= Testing valid =-
Test set: Average loss: 0.4163,                   Accuracy: 1725/2000.0 (86.25%)



Epoch 20 train accuracy: 86.43%, valid accuracy 86.25%
-= Testing valid =-
Test set: Average loss: 0.4166,                   Accuracy: 1725/2000.0 (86.25%)



-= Testing valid =-
Test set: Average loss: 0.4197,                   Accuracy: 1732/2000.0 (86.60%)



-= Testing valid =-
Test set: Average loss: 0.3715,                   Accuracy: 1752/2000.0 (87.60%)



-= Testing valid =-
Test set: Average loss: 0.4010,                   Accuracy: 1756/2000.0 (87.80%)



-= Testing valid =-
Test set: Average loss: 0.3186,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.4369,                   Accuracy: 1731/2000.0 (86.55%)



-= Testing valid =-
Test set: Average loss: 0.3385,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.3280,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.4073,                   Accuracy: 1719/2000.0 (85.95%)



-= Testing valid =-
Test set: Average loss: 0.4249,                   Accuracy: 1725/2000.0 (86.25%)



Epoch 30 train accuracy: 89.56%, valid accuracy 86.25%
-= Testing valid =-
Test set: Average loss: 0.3575,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.2947,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.3303,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.3163,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3115,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.3846,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.3294,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.3076,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.4091,                   Accuracy: 1723/2000.0 (86.15%)



-= Testing valid =-
Test set: Average loss: 0.3062,                   Accuracy: 1816/2000.0 (90.80%)



Epoch 40 train accuracy: 90.31%, valid accuracy 90.80%
-= Testing valid =-
Test set: Average loss: 0.2579,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.3139,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.3248,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.3318,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.2918,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3256,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.3160,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.3531,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.3106,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.3272,                   Accuracy: 1795/2000.0 (89.75%)



Epoch 50 train accuracy: 91.04%, valid accuracy 89.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2854,                   Accuracy: 55028/60000 (91.71%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2871,                   Accuracy: 54840/60000 (91.40%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2929,                   Accuracy: 54767/60000 (91.28%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3067,                   Accuracy: 54458/60000 (90.76%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3092,                   Accuracy: 54396/60000 (90.66%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3136,                   Accuracy: 54348/60000 (90.58%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3048,                   Accuracy: 54485/60000 (90.81%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2969,                   Accuracy: 54567/60000 (90.94%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2801,                   Accuracy: 54869/60000 (91.45%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2988,                   Accuracy: 54605/60000 (91.01%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3136,                   Accuracy: 54129/60000 (90.21%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3440,                   Accuracy: 53682/60000 (89.47%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3674,                   Accuracy: 53207/60000 (88.68%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3825,                   Accuracy: 52887/60000 (88.14%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3884,                   Accuracy: 52732/60000 (87.89%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3918,                   Accuracy: 52727/60000 (87.88%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3890,                   Accuracy: 52535/60000 (87.56%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3776,                   Accuracy: 52741/60000 (87.90%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3828,                   Accuracy: 52715/60000 (87.86%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3953,                   Accuracy: 52405/60000 (87.34%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3805,                   Accuracy: 52667/60000 (87.78%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3683,                   Accuracy: 52997/60000 (88.33%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3582,                   Accuracy: 53261/60000 (88.77%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3475,                   Accuracy: 53489/60000 (89.15%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3304,                   Accuracy: 53863/60000 (89.77%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3248,                   Accuracy: 54042/60000 (90.07%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2993,                   Accuracy: 54505/60000 (90.84%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2948,                   Accuracy: 54667/60000 (91.11%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2862,                   Accuracy: 54792/60000 (91.32%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2934,                   Accuracy: 54814/60000 (91.36%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2890,                   Accuracy: 54921/60000 (91.54%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2893,                   Accuracy: 54960/60000 (91.60%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2881,                   Accuracy: 54978/60000 (91.63%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2811,                   Accuracy: 55173/60000 (91.96%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2851,                   Accuracy: 55092/60000 (91.82%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2690,                   Accuracy: 55343/60000 (92.24%)
{0: tensor(91.7133), 10: tensor(91.4000), 20: tensor(91.2783), 30: tensor(90.7633), 40: tensor(90.6600), 50: tensor(90.5800), 60: tensor(90.8083), 70: tensor(90.9450), 80: tensor(91.4483), 90: tensor(91.0083), 100: tensor(90.2150), 110: tensor(89.4700), 120: tensor(88.6783), 130: tensor(88.1450), 140: tensor(87.8867), 150: tensor(87.8783), 160: tensor(87.5583), 170: tensor(87.9017), 180: tensor(87.8583), 190: tensor(87.3417), 200: tensor(87.7783), 210: tensor(88.3283), 220: tensor(88.7683), 230: tensor(89.1483), 240: tensor(89.7717), 250: tensor(90.0700), 260: tensor(90.8417), 270: tensor(91.1117), 280: tensor(91.3200), 290: tensor(91.3567), 300: tensor(91.5350), 310: tensor(91.6000), 320: tensor(91.6300), 330: tensor(91.9550), 340: tensor(91.8200), 350: tensor(92.2383)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=17, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1887,                   Accuracy: 440/2000.0 (22.00%)



-= Testing valid =-
Test set: Average loss: 1.9008,                   Accuracy: 556/2000.0 (27.80%)



-= Testing valid =-
Test set: Average loss: 1.5478,                   Accuracy: 862/2000.0 (43.10%)



-= Testing valid =-
Test set: Average loss: 1.6523,                   Accuracy: 693/2000.0 (34.65%)



-= Testing valid =-
Test set: Average loss: 1.6552,                   Accuracy: 832/2000.0 (41.60%)



-= Testing valid =-
Test set: Average loss: 1.2195,                   Accuracy: 1159/2000.0 (57.95%)



-= Testing valid =-
Test set: Average loss: 1.3916,                   Accuracy: 1080/2000.0 (54.00%)



-= Testing valid =-
Test set: Average loss: 1.0094,                   Accuracy: 1345/2000.0 (67.25%)



-= Testing valid =-
Test set: Average loss: 0.8652,                   Accuracy: 1422/2000.0 (71.10%)



-= Testing valid =-
Test set: Average loss: 0.7456,                   Accuracy: 1537/2000.0 (76.85%)



Epoch 10 train accuracy: 72.93%, valid accuracy 76.85%
-= Testing valid =-
Test set: Average loss: 0.6878,                   Accuracy: 1585/2000.0 (79.25%)



-= Testing valid =-
Test set: Average loss: 0.6299,                   Accuracy: 1607/2000.0 (80.35%)



-= Testing valid =-
Test set: Average loss: 0.3625,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.5930,                   Accuracy: 1631/2000.0 (81.55%)



-= Testing valid =-
Test set: Average loss: 0.5939,                   Accuracy: 1605/2000.0 (80.25%)



-= Testing valid =-
Test set: Average loss: 0.5563,                   Accuracy: 1642/2000.0 (82.10%)



-= Testing valid =-
Test set: Average loss: 0.3706,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3891,                   Accuracy: 1744/2000.0 (87.20%)



-= Testing valid =-
Test set: Average loss: 0.3103,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.3060,                   Accuracy: 1804/2000.0 (90.20%)



Epoch 20 train accuracy: 86.11%, valid accuracy 90.20%
-= Testing valid =-
Test set: Average loss: 0.2904,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2887,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2946,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.2484,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.2922,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2530,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2713,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2491,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2670,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.3246,                   Accuracy: 1796/2000.0 (89.80%)



Epoch 30 train accuracy: 89.79%, valid accuracy 89.80%
-= Testing valid =-
Test set: Average loss: 0.2692,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2759,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2614,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.2687,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2146,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.2469,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2651,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2169,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.2470,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2428,                   Accuracy: 1846/2000.0 (92.30%)



Epoch 40 train accuracy: 90.65%, valid accuracy 92.30%
-= Testing valid =-
Test set: Average loss: 0.2552,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2312,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.2648,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.2337,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2246,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2443,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2499,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2544,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2388,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2357,                   Accuracy: 1836/2000.0 (91.80%)



Epoch 50 train accuracy: 90.99%, valid accuracy 91.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2558,                   Accuracy: 55523/60000 (92.54%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2671,                   Accuracy: 55275/60000 (92.12%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2729,                   Accuracy: 55174/60000 (91.96%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2822,                   Accuracy: 55000/60000 (91.67%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2887,                   Accuracy: 54835/60000 (91.39%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2920,                   Accuracy: 54743/60000 (91.24%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2966,                   Accuracy: 54640/60000 (91.07%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3000,                   Accuracy: 54590/60000 (90.98%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2857,                   Accuracy: 54781/60000 (91.30%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2995,                   Accuracy: 54582/60000 (90.97%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3122,                   Accuracy: 54265/60000 (90.44%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3231,                   Accuracy: 53977/60000 (89.96%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3398,                   Accuracy: 53527/60000 (89.21%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3431,                   Accuracy: 53445/60000 (89.07%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3435,                   Accuracy: 53402/60000 (89.00%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3473,                   Accuracy: 53282/60000 (88.80%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3387,                   Accuracy: 53399/60000 (89.00%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3286,                   Accuracy: 53583/60000 (89.31%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3385,                   Accuracy: 53438/60000 (89.06%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3531,                   Accuracy: 53174/60000 (88.62%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3700,                   Accuracy: 52879/60000 (88.13%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3741,                   Accuracy: 52805/60000 (88.01%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3683,                   Accuracy: 52846/60000 (88.08%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3537,                   Accuracy: 53245/60000 (88.74%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3407,                   Accuracy: 53531/60000 (89.22%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3395,                   Accuracy: 53645/60000 (89.41%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3202,                   Accuracy: 53830/60000 (89.72%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3076,                   Accuracy: 54264/60000 (90.44%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2982,                   Accuracy: 54516/60000 (90.86%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3023,                   Accuracy: 54354/60000 (90.59%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2908,                   Accuracy: 54743/60000 (91.24%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2840,                   Accuracy: 54861/60000 (91.43%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2721,                   Accuracy: 55241/60000 (92.07%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2643,                   Accuracy: 55362/60000 (92.27%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2644,                   Accuracy: 55367/60000 (92.28%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2521,                   Accuracy: 55536/60000 (92.56%)
{0: tensor(92.5383), 10: tensor(92.1250), 20: tensor(91.9567), 30: tensor(91.6667), 40: tensor(91.3917), 50: tensor(91.2383), 60: tensor(91.0667), 70: tensor(90.9833), 80: tensor(91.3017), 90: tensor(90.9700), 100: tensor(90.4417), 110: tensor(89.9617), 120: tensor(89.2117), 130: tensor(89.0750), 140: tensor(89.0033), 150: tensor(88.8033), 160: tensor(88.9983), 170: tensor(89.3050), 180: tensor(89.0633), 190: tensor(88.6233), 200: tensor(88.1317), 210: tensor(88.0083), 220: tensor(88.0767), 230: tensor(88.7417), 240: tensor(89.2183), 250: tensor(89.4083), 260: tensor(89.7167), 270: tensor(90.4400), 280: tensor(90.8600), 290: tensor(90.5900), 300: tensor(91.2383), 310: tensor(91.4350), 320: tensor(92.0683), 330: tensor(92.2700), 340: tensor(92.2783), 350: tensor(92.5600)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=18, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.5697,                   Accuracy: 367/2000.0 (18.35%)



-= Testing valid =-
Test set: Average loss: 2.8036,                   Accuracy: 365/2000.0 (18.25%)



-= Testing valid =-
Test set: Average loss: 4.5823,                   Accuracy: 272/2000.0 (13.60%)



-= Testing valid =-
Test set: Average loss: 1.2413,                   Accuracy: 1122/2000.0 (56.10%)



-= Testing valid =-
Test set: Average loss: 1.2916,                   Accuracy: 1018/2000.0 (50.90%)



-= Testing valid =-
Test set: Average loss: 1.0009,                   Accuracy: 1310/2000.0 (65.50%)



-= Testing valid =-
Test set: Average loss: 1.2535,                   Accuracy: 1057/2000.0 (52.85%)



-= Testing valid =-
Test set: Average loss: 1.0979,                   Accuracy: 1186/2000.0 (59.30%)



-= Testing valid =-
Test set: Average loss: 1.1863,                   Accuracy: 1242/2000.0 (62.10%)



-= Testing valid =-
Test set: Average loss: 0.9619,                   Accuracy: 1311/2000.0 (65.55%)



Epoch 10 train accuracy: 75.49%, valid accuracy 65.55%
-= Testing valid =-
Test set: Average loss: 0.6147,                   Accuracy: 1600/2000.0 (80.00%)



-= Testing valid =-
Test set: Average loss: 0.4388,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.3081,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.4318,                   Accuracy: 1729/2000.0 (86.45%)



-= Testing valid =-
Test set: Average loss: 0.3241,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.4624,                   Accuracy: 1677/2000.0 (83.85%)



-= Testing valid =-
Test set: Average loss: 0.4750,                   Accuracy: 1670/2000.0 (83.50%)



-= Testing valid =-
Test set: Average loss: 0.3574,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.3446,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.4304,                   Accuracy: 1688/2000.0 (84.40%)



Epoch 20 train accuracy: 87.01%, valid accuracy 84.40%
-= Testing valid =-
Test set: Average loss: 0.3576,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.3701,                   Accuracy: 1748/2000.0 (87.40%)



-= Testing valid =-
Test set: Average loss: 0.2892,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.3094,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.2480,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.2418,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2719,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.3370,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.3797,                   Accuracy: 1733/2000.0 (86.65%)



-= Testing valid =-
Test set: Average loss: 0.2698,                   Accuracy: 1825/2000.0 (91.25%)



Epoch 30 train accuracy: 88.88%, valid accuracy 91.25%
-= Testing valid =-
Test set: Average loss: 0.2984,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.1813,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2408,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2763,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2396,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2190,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2338,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2199,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.1981,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.1980,                   Accuracy: 1871/2000.0 (93.55%)



Epoch 40 train accuracy: 89.95%, valid accuracy 93.55%
-= Testing valid =-
Test set: Average loss: 0.2201,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.1937,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1968,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.2122,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2002,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.2154,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.1983,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.2050,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.1894,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.2068,                   Accuracy: 1869/2000.0 (93.45%)



Epoch 50 train accuracy: 90.53%, valid accuracy 93.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2401,                   Accuracy: 55622/60000 (92.70%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2511,                   Accuracy: 55377/60000 (92.29%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2607,                   Accuracy: 55184/60000 (91.97%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2713,                   Accuracy: 54984/60000 (91.64%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2764,                   Accuracy: 54855/60000 (91.43%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2783,                   Accuracy: 54886/60000 (91.48%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2798,                   Accuracy: 54904/60000 (91.51%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2655,                   Accuracy: 55153/60000 (91.92%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2525,                   Accuracy: 55398/60000 (92.33%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2530,                   Accuracy: 55429/60000 (92.38%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2513,                   Accuracy: 55441/60000 (92.40%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2472,                   Accuracy: 55542/60000 (92.57%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.2506,                   Accuracy: 55424/60000 (92.37%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.2522,                   Accuracy: 55366/60000 (92.28%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.2508,                   Accuracy: 55316/60000 (92.19%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.2478,                   Accuracy: 55272/60000 (92.12%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2497,                   Accuracy: 55214/60000 (92.02%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.2498,                   Accuracy: 55161/60000 (91.93%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.2580,                   Accuracy: 55179/60000 (91.96%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.2723,                   Accuracy: 54772/60000 (91.29%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2804,                   Accuracy: 54668/60000 (91.11%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.2864,                   Accuracy: 54610/60000 (91.02%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.2968,                   Accuracy: 54290/60000 (90.48%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3057,                   Accuracy: 54086/60000 (90.14%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3184,                   Accuracy: 53751/60000 (89.58%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3253,                   Accuracy: 53497/60000 (89.16%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3249,                   Accuracy: 53482/60000 (89.14%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3228,                   Accuracy: 53500/60000 (89.17%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3121,                   Accuracy: 53868/60000 (89.78%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3074,                   Accuracy: 53882/60000 (89.80%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2860,                   Accuracy: 54458/60000 (90.76%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2695,                   Accuracy: 54791/60000 (91.32%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2550,                   Accuracy: 55199/60000 (92.00%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2413,                   Accuracy: 55496/60000 (92.49%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2380,                   Accuracy: 55552/60000 (92.59%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2344,                   Accuracy: 55585/60000 (92.64%)
{0: tensor(92.7033), 10: tensor(92.2950), 20: tensor(91.9733), 30: tensor(91.6400), 40: tensor(91.4250), 50: tensor(91.4767), 60: tensor(91.5067), 70: tensor(91.9217), 80: tensor(92.3300), 90: tensor(92.3817), 100: tensor(92.4017), 110: tensor(92.5700), 120: tensor(92.3733), 130: tensor(92.2767), 140: tensor(92.1933), 150: tensor(92.1200), 160: tensor(92.0233), 170: tensor(91.9350), 180: tensor(91.9650), 190: tensor(91.2867), 200: tensor(91.1133), 210: tensor(91.0167), 220: tensor(90.4833), 230: tensor(90.1433), 240: tensor(89.5850), 250: tensor(89.1617), 260: tensor(89.1367), 270: tensor(89.1667), 280: tensor(89.7800), 290: tensor(89.8033), 300: tensor(90.7633), 310: tensor(91.3183), 320: tensor(91.9983), 330: tensor(92.4933), 340: tensor(92.5867), 350: tensor(92.6417)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=19, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.8420,                   Accuracy: 252/2000.0 (12.60%)



-= Testing valid =-
Test set: Average loss: 2.4770,                   Accuracy: 356/2000.0 (17.80%)



-= Testing valid =-
Test set: Average loss: 1.8619,                   Accuracy: 684/2000.0 (34.20%)



-= Testing valid =-
Test set: Average loss: 1.4109,                   Accuracy: 967/2000.0 (48.35%)



-= Testing valid =-
Test set: Average loss: 2.4279,                   Accuracy: 595/2000.0 (29.75%)



-= Testing valid =-
Test set: Average loss: 1.7077,                   Accuracy: 911/2000.0 (45.55%)



-= Testing valid =-
Test set: Average loss: 1.0456,                   Accuracy: 1288/2000.0 (64.40%)



-= Testing valid =-
Test set: Average loss: 1.5761,                   Accuracy: 848/2000.0 (42.40%)



-= Testing valid =-
Test set: Average loss: 1.4669,                   Accuracy: 1055/2000.0 (52.75%)



-= Testing valid =-
Test set: Average loss: 1.2524,                   Accuracy: 1161/2000.0 (58.05%)



Epoch 10 train accuracy: 72.53%, valid accuracy 58.05%
-= Testing valid =-
Test set: Average loss: 1.4054,                   Accuracy: 1027/2000.0 (51.35%)



-= Testing valid =-
Test set: Average loss: 0.9789,                   Accuracy: 1351/2000.0 (67.55%)



-= Testing valid =-
Test set: Average loss: 1.0108,                   Accuracy: 1320/2000.0 (66.00%)



-= Testing valid =-
Test set: Average loss: 1.0487,                   Accuracy: 1295/2000.0 (64.75%)



-= Testing valid =-
Test set: Average loss: 0.7514,                   Accuracy: 1468/2000.0 (73.40%)



-= Testing valid =-
Test set: Average loss: 0.6153,                   Accuracy: 1596/2000.0 (79.80%)



-= Testing valid =-
Test set: Average loss: 0.8483,                   Accuracy: 1427/2000.0 (71.35%)



-= Testing valid =-
Test set: Average loss: 0.5688,                   Accuracy: 1608/2000.0 (80.40%)



-= Testing valid =-
Test set: Average loss: 0.5287,                   Accuracy: 1628/2000.0 (81.40%)



-= Testing valid =-
Test set: Average loss: 0.4324,                   Accuracy: 1717/2000.0 (85.85%)



Epoch 20 train accuracy: 85.85%, valid accuracy 85.85%
-= Testing valid =-
Test set: Average loss: 0.4801,                   Accuracy: 1675/2000.0 (83.75%)



-= Testing valid =-
Test set: Average loss: 0.4541,                   Accuracy: 1687/2000.0 (84.35%)



-= Testing valid =-
Test set: Average loss: 0.5626,                   Accuracy: 1617/2000.0 (80.85%)



-= Testing valid =-
Test set: Average loss: 0.5242,                   Accuracy: 1662/2000.0 (83.10%)



-= Testing valid =-
Test set: Average loss: 0.3970,                   Accuracy: 1753/2000.0 (87.65%)



-= Testing valid =-
Test set: Average loss: 0.5748,                   Accuracy: 1602/2000.0 (80.10%)



-= Testing valid =-
Test set: Average loss: 0.5123,                   Accuracy: 1664/2000.0 (83.20%)



-= Testing valid =-
Test set: Average loss: 0.3641,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.4021,                   Accuracy: 1733/2000.0 (86.65%)



-= Testing valid =-
Test set: Average loss: 0.3513,                   Accuracy: 1773/2000.0 (88.65%)



Epoch 30 train accuracy: 88.79%, valid accuracy 88.65%
-= Testing valid =-
Test set: Average loss: 0.3570,                   Accuracy: 1756/2000.0 (87.80%)



-= Testing valid =-
Test set: Average loss: 0.3555,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.4048,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.3500,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.4289,                   Accuracy: 1708/2000.0 (85.40%)



-= Testing valid =-
Test set: Average loss: 0.4491,                   Accuracy: 1695/2000.0 (84.75%)



-= Testing valid =-
Test set: Average loss: 0.4429,                   Accuracy: 1699/2000.0 (84.95%)



-= Testing valid =-
Test set: Average loss: 0.3833,                   Accuracy: 1745/2000.0 (87.25%)



-= Testing valid =-
Test set: Average loss: 0.3335,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.4012,                   Accuracy: 1737/2000.0 (86.85%)



Epoch 40 train accuracy: 89.65%, valid accuracy 86.85%
-= Testing valid =-
Test set: Average loss: 0.3488,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 0.3677,                   Accuracy: 1755/2000.0 (87.75%)



-= Testing valid =-
Test set: Average loss: 0.3415,                   Accuracy: 1780/2000.0 (89.00%)



-= Testing valid =-
Test set: Average loss: 0.2883,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3418,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3454,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.3460,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3365,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.3348,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.3145,                   Accuracy: 1780/2000.0 (89.00%)



Epoch 50 train accuracy: 90.65%, valid accuracy 89.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3304,                   Accuracy: 53864/60000 (89.77%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3308,                   Accuracy: 53672/60000 (89.45%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3445,                   Accuracy: 53525/60000 (89.21%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3535,                   Accuracy: 53264/60000 (88.77%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3587,                   Accuracy: 53171/60000 (88.62%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3656,                   Accuracy: 53071/60000 (88.45%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3656,                   Accuracy: 53080/60000 (88.47%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3604,                   Accuracy: 53198/60000 (88.66%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3428,                   Accuracy: 53421/60000 (89.04%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3525,                   Accuracy: 53136/60000 (88.56%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3676,                   Accuracy: 52608/60000 (87.68%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3683,                   Accuracy: 52731/60000 (87.89%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3798,                   Accuracy: 52583/60000 (87.64%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3890,                   Accuracy: 52434/60000 (87.39%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3983,                   Accuracy: 52184/60000 (86.97%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4005,                   Accuracy: 52224/60000 (87.04%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4095,                   Accuracy: 52035/60000 (86.72%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.4001,                   Accuracy: 52174/60000 (86.96%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.4029,                   Accuracy: 52071/60000 (86.79%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.4200,                   Accuracy: 51601/60000 (86.00%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.4514,                   Accuracy: 51101/60000 (85.17%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4809,                   Accuracy: 50602/60000 (84.34%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4882,                   Accuracy: 50354/60000 (83.92%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4988,                   Accuracy: 50286/60000 (83.81%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4979,                   Accuracy: 50409/60000 (84.01%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.4813,                   Accuracy: 50875/60000 (84.79%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.4508,                   Accuracy: 51360/60000 (85.60%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4417,                   Accuracy: 51528/60000 (85.88%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4248,                   Accuracy: 51666/60000 (86.11%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.4319,                   Accuracy: 51607/60000 (86.01%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.4351,                   Accuracy: 51495/60000 (85.82%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.4177,                   Accuracy: 51927/60000 (86.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3998,                   Accuracy: 52397/60000 (87.33%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3854,                   Accuracy: 52748/60000 (87.91%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3705,                   Accuracy: 52988/60000 (88.31%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3302,                   Accuracy: 53875/60000 (89.79%)
{0: tensor(89.7733), 10: tensor(89.4533), 20: tensor(89.2083), 30: tensor(88.7733), 40: tensor(88.6183), 50: tensor(88.4517), 60: tensor(88.4667), 70: tensor(88.6633), 80: tensor(89.0350), 90: tensor(88.5600), 100: tensor(87.6800), 110: tensor(87.8850), 120: tensor(87.6383), 130: tensor(87.3900), 140: tensor(86.9733), 150: tensor(87.0400), 160: tensor(86.7250), 170: tensor(86.9567), 180: tensor(86.7850), 190: tensor(86.0017), 200: tensor(85.1683), 210: tensor(84.3367), 220: tensor(83.9233), 230: tensor(83.8100), 240: tensor(84.0150), 250: tensor(84.7917), 260: tensor(85.6000), 270: tensor(85.8800), 280: tensor(86.1100), 290: tensor(86.0117), 300: tensor(85.8250), 310: tensor(86.5450), 320: tensor(87.3283), 330: tensor(87.9133), 340: tensor(88.3133), 350: tensor(89.7917)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=20, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.3354,                   Accuracy: 237/2000.0 (11.85%)



-= Testing valid =-
Test set: Average loss: 2.8201,                   Accuracy: 298/2000.0 (14.90%)



-= Testing valid =-
Test set: Average loss: 1.6098,                   Accuracy: 862/2000.0 (43.10%)



-= Testing valid =-
Test set: Average loss: 2.3768,                   Accuracy: 533/2000.0 (26.65%)



-= Testing valid =-
Test set: Average loss: 1.2464,                   Accuracy: 1169/2000.0 (58.45%)



-= Testing valid =-
Test set: Average loss: 1.5900,                   Accuracy: 898/2000.0 (44.90%)



-= Testing valid =-
Test set: Average loss: 1.2767,                   Accuracy: 1098/2000.0 (54.90%)



-= Testing valid =-
Test set: Average loss: 1.7248,                   Accuracy: 932/2000.0 (46.60%)



-= Testing valid =-
Test set: Average loss: 1.5363,                   Accuracy: 1130/2000.0 (56.50%)



-= Testing valid =-
Test set: Average loss: 1.2132,                   Accuracy: 1136/2000.0 (56.80%)



Epoch 10 train accuracy: 72.15%, valid accuracy 56.80%
-= Testing valid =-
Test set: Average loss: 0.9650,                   Accuracy: 1277/2000.0 (63.85%)



-= Testing valid =-
Test set: Average loss: 0.9512,                   Accuracy: 1324/2000.0 (66.20%)



-= Testing valid =-
Test set: Average loss: 0.8422,                   Accuracy: 1427/2000.0 (71.35%)



-= Testing valid =-
Test set: Average loss: 0.8994,                   Accuracy: 1364/2000.0 (68.20%)



-= Testing valid =-
Test set: Average loss: 0.7133,                   Accuracy: 1504/2000.0 (75.20%)



-= Testing valid =-
Test set: Average loss: 0.6181,                   Accuracy: 1539/2000.0 (76.95%)



-= Testing valid =-
Test set: Average loss: 0.5668,                   Accuracy: 1614/2000.0 (80.70%)



-= Testing valid =-
Test set: Average loss: 0.6691,                   Accuracy: 1515/2000.0 (75.75%)



-= Testing valid =-
Test set: Average loss: 0.5519,                   Accuracy: 1630/2000.0 (81.50%)



-= Testing valid =-
Test set: Average loss: 0.4622,                   Accuracy: 1696/2000.0 (84.80%)



Epoch 20 train accuracy: 85.62%, valid accuracy 84.80%
-= Testing valid =-
Test set: Average loss: 0.5598,                   Accuracy: 1629/2000.0 (81.45%)



-= Testing valid =-
Test set: Average loss: 0.4077,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.4630,                   Accuracy: 1695/2000.0 (84.75%)



-= Testing valid =-
Test set: Average loss: 0.4016,                   Accuracy: 1740/2000.0 (87.00%)



-= Testing valid =-
Test set: Average loss: 0.3964,                   Accuracy: 1740/2000.0 (87.00%)



-= Testing valid =-
Test set: Average loss: 0.3146,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.3550,                   Accuracy: 1759/2000.0 (87.95%)



-= Testing valid =-
Test set: Average loss: 0.4498,                   Accuracy: 1717/2000.0 (85.85%)



-= Testing valid =-
Test set: Average loss: 0.3797,                   Accuracy: 1747/2000.0 (87.35%)



-= Testing valid =-
Test set: Average loss: 0.3527,                   Accuracy: 1765/2000.0 (88.25%)



Epoch 30 train accuracy: 90.06%, valid accuracy 88.25%
-= Testing valid =-
Test set: Average loss: 0.2895,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2936,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.3176,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.3059,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.3980,                   Accuracy: 1739/2000.0 (86.95%)



-= Testing valid =-
Test set: Average loss: 0.3300,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.3010,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.3594,                   Accuracy: 1768/2000.0 (88.40%)



-= Testing valid =-
Test set: Average loss: 0.3356,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.2824,                   Accuracy: 1824/2000.0 (91.20%)



Epoch 40 train accuracy: 90.46%, valid accuracy 91.20%
-= Testing valid =-
Test set: Average loss: 0.3317,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.3447,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.3474,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.3444,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.3342,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.2952,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.2987,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3122,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.3298,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.3024,                   Accuracy: 1812/2000.0 (90.60%)



Epoch 50 train accuracy: 91.31%, valid accuracy 90.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3172,                   Accuracy: 53910/60000 (89.85%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3270,                   Accuracy: 53588/60000 (89.31%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3310,                   Accuracy: 53667/60000 (89.44%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3365,                   Accuracy: 53635/60000 (89.39%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3368,                   Accuracy: 53578/60000 (89.30%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3376,                   Accuracy: 53604/60000 (89.34%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3483,                   Accuracy: 53421/60000 (89.04%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3567,                   Accuracy: 53336/60000 (88.89%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3420,                   Accuracy: 53611/60000 (89.35%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3489,                   Accuracy: 53510/60000 (89.18%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3600,                   Accuracy: 53137/60000 (88.56%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3823,                   Accuracy: 52681/60000 (87.80%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3756,                   Accuracy: 52879/60000 (88.13%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3612,                   Accuracy: 53137/60000 (88.56%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3491,                   Accuracy: 53382/60000 (88.97%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3411,                   Accuracy: 53524/60000 (89.21%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3366,                   Accuracy: 53690/60000 (89.48%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3191,                   Accuracy: 54055/60000 (90.09%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3184,                   Accuracy: 54046/60000 (90.08%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3424,                   Accuracy: 53432/60000 (89.05%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3642,                   Accuracy: 53079/60000 (88.46%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3814,                   Accuracy: 52748/60000 (87.91%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3971,                   Accuracy: 52326/60000 (87.21%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4216,                   Accuracy: 51850/60000 (86.42%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4311,                   Accuracy: 51718/60000 (86.20%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.4470,                   Accuracy: 51395/60000 (85.66%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.4250,                   Accuracy: 51679/60000 (86.13%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4367,                   Accuracy: 51489/60000 (85.82%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4518,                   Accuracy: 51145/60000 (85.24%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.4539,                   Accuracy: 51111/60000 (85.18%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.4491,                   Accuracy: 51192/60000 (85.32%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.4281,                   Accuracy: 51560/60000 (85.93%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.4058,                   Accuracy: 52000/60000 (86.67%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3883,                   Accuracy: 52349/60000 (87.25%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3684,                   Accuracy: 52721/60000 (87.87%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3329,                   Accuracy: 53384/60000 (88.97%)
{0: tensor(89.8500), 10: tensor(89.3133), 20: tensor(89.4450), 30: tensor(89.3917), 40: tensor(89.2967), 50: tensor(89.3400), 60: tensor(89.0350), 70: tensor(88.8933), 80: tensor(89.3517), 90: tensor(89.1833), 100: tensor(88.5617), 110: tensor(87.8017), 120: tensor(88.1317), 130: tensor(88.5617), 140: tensor(88.9700), 150: tensor(89.2067), 160: tensor(89.4833), 170: tensor(90.0917), 180: tensor(90.0767), 190: tensor(89.0533), 200: tensor(88.4650), 210: tensor(87.9133), 220: tensor(87.2100), 230: tensor(86.4167), 240: tensor(86.1967), 250: tensor(85.6583), 260: tensor(86.1317), 270: tensor(85.8150), 280: tensor(85.2417), 290: tensor(85.1850), 300: tensor(85.3200), 310: tensor(85.9333), 320: tensor(86.6667), 330: tensor(87.2483), 340: tensor(87.8683), 350: tensor(88.9733)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=21, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6163,                   Accuracy: 321/2000.0 (16.05%)



-= Testing valid =-
Test set: Average loss: 4.0256,                   Accuracy: 287/2000.0 (14.35%)



-= Testing valid =-
Test set: Average loss: 1.7072,                   Accuracy: 824/2000.0 (41.20%)



-= Testing valid =-
Test set: Average loss: 1.7016,                   Accuracy: 791/2000.0 (39.55%)



-= Testing valid =-
Test set: Average loss: 1.9424,                   Accuracy: 681/2000.0 (34.05%)



-= Testing valid =-
Test set: Average loss: 1.8234,                   Accuracy: 644/2000.0 (32.20%)



-= Testing valid =-
Test set: Average loss: 2.1396,                   Accuracy: 564/2000.0 (28.20%)



-= Testing valid =-
Test set: Average loss: 1.5690,                   Accuracy: 931/2000.0 (46.55%)



-= Testing valid =-
Test set: Average loss: 1.8497,                   Accuracy: 906/2000.0 (45.30%)



-= Testing valid =-
Test set: Average loss: 1.7167,                   Accuracy: 864/2000.0 (43.20%)



Epoch 10 train accuracy: 69.69%, valid accuracy 43.20%
-= Testing valid =-
Test set: Average loss: 1.2670,                   Accuracy: 1183/2000.0 (59.15%)



-= Testing valid =-
Test set: Average loss: 0.7407,                   Accuracy: 1448/2000.0 (72.40%)



-= Testing valid =-
Test set: Average loss: 1.0548,                   Accuracy: 1212/2000.0 (60.60%)



-= Testing valid =-
Test set: Average loss: 0.5149,                   Accuracy: 1670/2000.0 (83.50%)



-= Testing valid =-
Test set: Average loss: 0.8640,                   Accuracy: 1312/2000.0 (65.60%)



-= Testing valid =-
Test set: Average loss: 1.0534,                   Accuracy: 1296/2000.0 (64.80%)



-= Testing valid =-
Test set: Average loss: 0.4669,                   Accuracy: 1688/2000.0 (84.40%)



-= Testing valid =-
Test set: Average loss: 0.6705,                   Accuracy: 1461/2000.0 (73.05%)



-= Testing valid =-
Test set: Average loss: 0.5855,                   Accuracy: 1614/2000.0 (80.70%)



-= Testing valid =-
Test set: Average loss: 0.5983,                   Accuracy: 1607/2000.0 (80.35%)



Epoch 20 train accuracy: 85.72%, valid accuracy 80.35%
-= Testing valid =-
Test set: Average loss: 0.5450,                   Accuracy: 1635/2000.0 (81.75%)



-= Testing valid =-
Test set: Average loss: 0.5014,                   Accuracy: 1652/2000.0 (82.60%)



-= Testing valid =-
Test set: Average loss: 0.4223,                   Accuracy: 1731/2000.0 (86.55%)



-= Testing valid =-
Test set: Average loss: 0.5901,                   Accuracy: 1630/2000.0 (81.50%)



-= Testing valid =-
Test set: Average loss: 0.4760,                   Accuracy: 1688/2000.0 (84.40%)



-= Testing valid =-
Test set: Average loss: 0.5015,                   Accuracy: 1685/2000.0 (84.25%)



-= Testing valid =-
Test set: Average loss: 0.3928,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.4524,                   Accuracy: 1704/2000.0 (85.20%)



-= Testing valid =-
Test set: Average loss: 0.3873,                   Accuracy: 1738/2000.0 (86.90%)



-= Testing valid =-
Test set: Average loss: 0.4437,                   Accuracy: 1699/2000.0 (84.95%)



Epoch 30 train accuracy: 89.09%, valid accuracy 84.95%
-= Testing valid =-
Test set: Average loss: 0.3463,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.3690,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.4036,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.4844,                   Accuracy: 1699/2000.0 (84.95%)



-= Testing valid =-
Test set: Average loss: 0.4978,                   Accuracy: 1675/2000.0 (83.75%)



-= Testing valid =-
Test set: Average loss: 0.4375,                   Accuracy: 1717/2000.0 (85.85%)



-= Testing valid =-
Test set: Average loss: 0.4598,                   Accuracy: 1717/2000.0 (85.85%)



-= Testing valid =-
Test set: Average loss: 0.4102,                   Accuracy: 1739/2000.0 (86.95%)



-= Testing valid =-
Test set: Average loss: 0.4044,                   Accuracy: 1742/2000.0 (87.10%)



-= Testing valid =-
Test set: Average loss: 0.4349,                   Accuracy: 1718/2000.0 (85.90%)



Epoch 40 train accuracy: 90.40%, valid accuracy 85.90%
-= Testing valid =-
Test set: Average loss: 0.4268,                   Accuracy: 1724/2000.0 (86.20%)



-= Testing valid =-
Test set: Average loss: 0.4043,                   Accuracy: 1744/2000.0 (87.20%)



-= Testing valid =-
Test set: Average loss: 0.3949,                   Accuracy: 1742/2000.0 (87.10%)



-= Testing valid =-
Test set: Average loss: 0.4778,                   Accuracy: 1693/2000.0 (84.65%)



-= Testing valid =-
Test set: Average loss: 0.4386,                   Accuracy: 1719/2000.0 (85.95%)



-= Testing valid =-
Test set: Average loss: 0.4048,                   Accuracy: 1745/2000.0 (87.25%)



-= Testing valid =-
Test set: Average loss: 0.4336,                   Accuracy: 1730/2000.0 (86.50%)



-= Testing valid =-
Test set: Average loss: 0.3938,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.3953,                   Accuracy: 1742/2000.0 (87.10%)



-= Testing valid =-
Test set: Average loss: 0.3805,                   Accuracy: 1756/2000.0 (87.80%)



Epoch 50 train accuracy: 90.68%, valid accuracy 87.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3770,                   Accuracy: 53094/60000 (88.49%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3867,                   Accuracy: 52694/60000 (87.82%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.4076,                   Accuracy: 52250/60000 (87.08%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4244,                   Accuracy: 51633/60000 (86.06%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.4328,                   Accuracy: 51295/60000 (85.49%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.4351,                   Accuracy: 51149/60000 (85.25%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.4349,                   Accuracy: 51222/60000 (85.37%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.4210,                   Accuracy: 51562/60000 (85.94%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4058,                   Accuracy: 51932/60000 (86.55%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4222,                   Accuracy: 51714/60000 (86.19%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.4243,                   Accuracy: 51661/60000 (86.10%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.4619,                   Accuracy: 50853/60000 (84.75%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4713,                   Accuracy: 50645/60000 (84.41%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4570,                   Accuracy: 50983/60000 (84.97%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.4392,                   Accuracy: 51451/60000 (85.75%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4312,                   Accuracy: 51591/60000 (85.99%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4178,                   Accuracy: 52022/60000 (86.70%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3823,                   Accuracy: 52838/60000 (88.06%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3760,                   Accuracy: 53125/60000 (88.54%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3739,                   Accuracy: 53156/60000 (88.59%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3828,                   Accuracy: 53143/60000 (88.57%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3839,                   Accuracy: 53139/60000 (88.57%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3788,                   Accuracy: 53161/60000 (88.60%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3706,                   Accuracy: 53316/60000 (88.86%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3687,                   Accuracy: 53292/60000 (88.82%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3593,                   Accuracy: 53474/60000 (89.12%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3343,                   Accuracy: 54000/60000 (90.00%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3416,                   Accuracy: 53880/60000 (89.80%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3458,                   Accuracy: 53708/60000 (89.51%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3631,                   Accuracy: 53531/60000 (89.22%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3743,                   Accuracy: 53256/60000 (88.76%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3766,                   Accuracy: 53177/60000 (88.63%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3807,                   Accuracy: 52995/60000 (88.32%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3791,                   Accuracy: 53133/60000 (88.56%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3770,                   Accuracy: 53071/60000 (88.45%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3651,                   Accuracy: 53398/60000 (89.00%)
{0: tensor(88.4900), 10: tensor(87.8233), 20: tensor(87.0833), 30: tensor(86.0550), 40: tensor(85.4917), 50: tensor(85.2483), 60: tensor(85.3700), 70: tensor(85.9367), 80: tensor(86.5533), 90: tensor(86.1900), 100: tensor(86.1017), 110: tensor(84.7550), 120: tensor(84.4083), 130: tensor(84.9717), 140: tensor(85.7517), 150: tensor(85.9850), 160: tensor(86.7033), 170: tensor(88.0633), 180: tensor(88.5417), 190: tensor(88.5933), 200: tensor(88.5717), 210: tensor(88.5650), 220: tensor(88.6017), 230: tensor(88.8600), 240: tensor(88.8200), 250: tensor(89.1233), 260: tensor(90.), 270: tensor(89.8000), 280: tensor(89.5133), 290: tensor(89.2183), 300: tensor(88.7600), 310: tensor(88.6283), 320: tensor(88.3250), 330: tensor(88.5550), 340: tensor(88.4517), 350: tensor(88.9967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=22, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 7.7015,                   Accuracy: 232/2000.0 (11.60%)



-= Testing valid =-
Test set: Average loss: 2.7475,                   Accuracy: 408/2000.0 (20.40%)



-= Testing valid =-
Test set: Average loss: 5.0879,                   Accuracy: 241/2000.0 (12.05%)



-= Testing valid =-
Test set: Average loss: 1.5047,                   Accuracy: 991/2000.0 (49.55%)



-= Testing valid =-
Test set: Average loss: 1.7398,                   Accuracy: 754/2000.0 (37.70%)



-= Testing valid =-
Test set: Average loss: 1.8685,                   Accuracy: 730/2000.0 (36.50%)



-= Testing valid =-
Test set: Average loss: 1.2781,                   Accuracy: 1073/2000.0 (53.65%)



-= Testing valid =-
Test set: Average loss: 1.0944,                   Accuracy: 1266/2000.0 (63.30%)



-= Testing valid =-
Test set: Average loss: 1.1781,                   Accuracy: 1143/2000.0 (57.15%)



-= Testing valid =-
Test set: Average loss: 1.5531,                   Accuracy: 1023/2000.0 (51.15%)



Epoch 10 train accuracy: 74.21%, valid accuracy 51.15%
-= Testing valid =-
Test set: Average loss: 0.6996,                   Accuracy: 1601/2000.0 (80.05%)



-= Testing valid =-
Test set: Average loss: 0.8325,                   Accuracy: 1399/2000.0 (69.95%)



-= Testing valid =-
Test set: Average loss: 0.9622,                   Accuracy: 1359/2000.0 (67.95%)



-= Testing valid =-
Test set: Average loss: 0.6430,                   Accuracy: 1578/2000.0 (78.90%)



-= Testing valid =-
Test set: Average loss: 0.6964,                   Accuracy: 1490/2000.0 (74.50%)



-= Testing valid =-
Test set: Average loss: 0.7778,                   Accuracy: 1498/2000.0 (74.90%)



-= Testing valid =-
Test set: Average loss: 0.7153,                   Accuracy: 1509/2000.0 (75.45%)



-= Testing valid =-
Test set: Average loss: 0.4427,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.6860,                   Accuracy: 1570/2000.0 (78.50%)



-= Testing valid =-
Test set: Average loss: 0.5744,                   Accuracy: 1620/2000.0 (81.00%)



Epoch 20 train accuracy: 84.82%, valid accuracy 81.00%
-= Testing valid =-
Test set: Average loss: 0.4308,                   Accuracy: 1751/2000.0 (87.55%)



-= Testing valid =-
Test set: Average loss: 0.4718,                   Accuracy: 1697/2000.0 (84.85%)



-= Testing valid =-
Test set: Average loss: 0.4313,                   Accuracy: 1747/2000.0 (87.35%)



-= Testing valid =-
Test set: Average loss: 0.4176,                   Accuracy: 1747/2000.0 (87.35%)



-= Testing valid =-
Test set: Average loss: 0.3596,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.5841,                   Accuracy: 1623/2000.0 (81.15%)



-= Testing valid =-
Test set: Average loss: 0.4546,                   Accuracy: 1716/2000.0 (85.80%)



-= Testing valid =-
Test set: Average loss: 0.4574,                   Accuracy: 1717/2000.0 (85.85%)



-= Testing valid =-
Test set: Average loss: 0.4337,                   Accuracy: 1738/2000.0 (86.90%)



-= Testing valid =-
Test set: Average loss: 0.4360,                   Accuracy: 1730/2000.0 (86.50%)



Epoch 30 train accuracy: 88.14%, valid accuracy 86.50%
-= Testing valid =-
Test set: Average loss: 0.3520,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.4228,                   Accuracy: 1735/2000.0 (86.75%)



-= Testing valid =-
Test set: Average loss: 0.4338,                   Accuracy: 1729/2000.0 (86.45%)



-= Testing valid =-
Test set: Average loss: 0.3890,                   Accuracy: 1748/2000.0 (87.40%)



-= Testing valid =-
Test set: Average loss: 0.3896,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.4109,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.4450,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.3981,                   Accuracy: 1760/2000.0 (88.00%)



-= Testing valid =-
Test set: Average loss: 0.3860,                   Accuracy: 1753/2000.0 (87.65%)



-= Testing valid =-
Test set: Average loss: 0.3265,                   Accuracy: 1807/2000.0 (90.35%)



Epoch 40 train accuracy: 89.49%, valid accuracy 90.35%
-= Testing valid =-
Test set: Average loss: 0.3728,                   Accuracy: 1768/2000.0 (88.40%)



-= Testing valid =-
Test set: Average loss: 0.3600,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.4178,                   Accuracy: 1739/2000.0 (86.95%)



-= Testing valid =-
Test set: Average loss: 0.3590,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.3582,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.3434,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.4008,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.3810,                   Accuracy: 1759/2000.0 (87.95%)



-= Testing valid =-
Test set: Average loss: 0.3828,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.3512,                   Accuracy: 1790/2000.0 (89.50%)



Epoch 50 train accuracy: 90.04%, valid accuracy 89.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3370,                   Accuracy: 53791/60000 (89.65%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3296,                   Accuracy: 53995/60000 (89.99%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3459,                   Accuracy: 53629/60000 (89.38%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3730,                   Accuracy: 53032/60000 (88.39%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3747,                   Accuracy: 53008/60000 (88.35%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3765,                   Accuracy: 52944/60000 (88.24%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3789,                   Accuracy: 52823/60000 (88.04%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3663,                   Accuracy: 53148/60000 (88.58%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3503,                   Accuracy: 53467/60000 (89.11%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3631,                   Accuracy: 53262/60000 (88.77%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3461,                   Accuracy: 53608/60000 (89.35%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3474,                   Accuracy: 53648/60000 (89.41%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3602,                   Accuracy: 53352/60000 (88.92%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3579,                   Accuracy: 53338/60000 (88.90%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3534,                   Accuracy: 53497/60000 (89.16%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3484,                   Accuracy: 53606/60000 (89.34%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3324,                   Accuracy: 53894/60000 (89.82%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3138,                   Accuracy: 54184/60000 (90.31%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3234,                   Accuracy: 54000/60000 (90.00%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3242,                   Accuracy: 53950/60000 (89.92%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3312,                   Accuracy: 53812/60000 (89.69%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3503,                   Accuracy: 53382/60000 (88.97%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3568,                   Accuracy: 53178/60000 (88.63%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3580,                   Accuracy: 53184/60000 (88.64%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3640,                   Accuracy: 52894/60000 (88.16%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3540,                   Accuracy: 53123/60000 (88.54%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3453,                   Accuracy: 53262/60000 (88.77%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3539,                   Accuracy: 53132/60000 (88.55%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3436,                   Accuracy: 53433/60000 (89.06%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3510,                   Accuracy: 53269/60000 (88.78%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3550,                   Accuracy: 53202/60000 (88.67%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3603,                   Accuracy: 53123/60000 (88.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3554,                   Accuracy: 53241/60000 (88.74%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3550,                   Accuracy: 53247/60000 (88.75%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3519,                   Accuracy: 53411/60000 (89.02%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3251,                   Accuracy: 53922/60000 (89.87%)
{0: tensor(89.6517), 10: tensor(89.9917), 20: tensor(89.3817), 30: tensor(88.3867), 40: tensor(88.3467), 50: tensor(88.2400), 60: tensor(88.0383), 70: tensor(88.5800), 80: tensor(89.1117), 90: tensor(88.7700), 100: tensor(89.3467), 110: tensor(89.4133), 120: tensor(88.9200), 130: tensor(88.8967), 140: tensor(89.1617), 150: tensor(89.3433), 160: tensor(89.8233), 170: tensor(90.3067), 180: tensor(90.), 190: tensor(89.9167), 200: tensor(89.6867), 210: tensor(88.9700), 220: tensor(88.6300), 230: tensor(88.6400), 240: tensor(88.1567), 250: tensor(88.5383), 260: tensor(88.7700), 270: tensor(88.5533), 280: tensor(89.0550), 290: tensor(88.7817), 300: tensor(88.6700), 310: tensor(88.5383), 320: tensor(88.7350), 330: tensor(88.7450), 340: tensor(89.0183), 350: tensor(89.8700)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=23, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 8.5131,                   Accuracy: 216/2000.0 (10.80%)



-= Testing valid =-
Test set: Average loss: 2.4919,                   Accuracy: 402/2000.0 (20.10%)



-= Testing valid =-
Test set: Average loss: 2.1415,                   Accuracy: 547/2000.0 (27.35%)



-= Testing valid =-
Test set: Average loss: 3.0654,                   Accuracy: 401/2000.0 (20.05%)



-= Testing valid =-
Test set: Average loss: 3.3514,                   Accuracy: 405/2000.0 (20.25%)



-= Testing valid =-
Test set: Average loss: 1.9620,                   Accuracy: 707/2000.0 (35.35%)



-= Testing valid =-
Test set: Average loss: 1.3678,                   Accuracy: 1002/2000.0 (50.10%)



-= Testing valid =-
Test set: Average loss: 0.8072,                   Accuracy: 1487/2000.0 (74.35%)



-= Testing valid =-
Test set: Average loss: 1.5048,                   Accuracy: 1175/2000.0 (58.75%)



-= Testing valid =-
Test set: Average loss: 1.1186,                   Accuracy: 1192/2000.0 (59.60%)



Epoch 10 train accuracy: 71.05%, valid accuracy 59.60%
-= Testing valid =-
Test set: Average loss: 0.5758,                   Accuracy: 1654/2000.0 (82.70%)



-= Testing valid =-
Test set: Average loss: 0.6386,                   Accuracy: 1621/2000.0 (81.05%)



-= Testing valid =-
Test set: Average loss: 0.7954,                   Accuracy: 1449/2000.0 (72.45%)



-= Testing valid =-
Test set: Average loss: 0.6121,                   Accuracy: 1596/2000.0 (79.80%)



-= Testing valid =-
Test set: Average loss: 0.3622,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.4276,                   Accuracy: 1717/2000.0 (85.85%)



-= Testing valid =-
Test set: Average loss: 0.4245,                   Accuracy: 1716/2000.0 (85.80%)



-= Testing valid =-
Test set: Average loss: 0.5508,                   Accuracy: 1607/2000.0 (80.35%)



-= Testing valid =-
Test set: Average loss: 0.4540,                   Accuracy: 1723/2000.0 (86.15%)



-= Testing valid =-
Test set: Average loss: 0.3260,                   Accuracy: 1773/2000.0 (88.65%)



Epoch 20 train accuracy: 85.24%, valid accuracy 88.65%
-= Testing valid =-
Test set: Average loss: 0.5152,                   Accuracy: 1618/2000.0 (80.90%)



-= Testing valid =-
Test set: Average loss: 0.4115,                   Accuracy: 1720/2000.0 (86.00%)



-= Testing valid =-
Test set: Average loss: 0.3872,                   Accuracy: 1736/2000.0 (86.80%)



-= Testing valid =-
Test set: Average loss: 0.3255,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.3620,                   Accuracy: 1752/2000.0 (87.60%)



-= Testing valid =-
Test set: Average loss: 0.3351,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.3270,                   Accuracy: 1780/2000.0 (89.00%)



-= Testing valid =-
Test set: Average loss: 0.2522,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2875,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.3323,                   Accuracy: 1794/2000.0 (89.70%)



Epoch 30 train accuracy: 89.04%, valid accuracy 89.70%
-= Testing valid =-
Test set: Average loss: 0.3301,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.2738,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.3073,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.2347,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.3062,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.2798,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2818,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.2690,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.2914,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.2562,                   Accuracy: 1822/2000.0 (91.10%)



Epoch 40 train accuracy: 90.14%, valid accuracy 91.10%
-= Testing valid =-
Test set: Average loss: 0.2935,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2672,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2621,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.2583,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2339,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.2383,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2503,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2313,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2497,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2575,                   Accuracy: 1812/2000.0 (90.60%)



Epoch 50 train accuracy: 90.70%, valid accuracy 90.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2802,                   Accuracy: 54983/60000 (91.64%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2941,                   Accuracy: 54649/60000 (91.08%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3035,                   Accuracy: 54512/60000 (90.85%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3127,                   Accuracy: 54324/60000 (90.54%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3141,                   Accuracy: 54255/60000 (90.43%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3113,                   Accuracy: 54258/60000 (90.43%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3055,                   Accuracy: 54340/60000 (90.57%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2966,                   Accuracy: 54505/60000 (90.84%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2765,                   Accuracy: 54926/60000 (91.54%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2744,                   Accuracy: 54988/60000 (91.65%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2857,                   Accuracy: 54671/60000 (91.12%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2985,                   Accuracy: 54550/60000 (90.92%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3188,                   Accuracy: 54179/60000 (90.30%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3343,                   Accuracy: 53760/60000 (89.60%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3399,                   Accuracy: 53576/60000 (89.29%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3393,                   Accuracy: 53636/60000 (89.39%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3567,                   Accuracy: 53268/60000 (88.78%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3434,                   Accuracy: 53488/60000 (89.15%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3513,                   Accuracy: 53325/60000 (88.88%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3793,                   Accuracy: 52615/60000 (87.69%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3826,                   Accuracy: 52567/60000 (87.61%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3928,                   Accuracy: 52352/60000 (87.25%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3913,                   Accuracy: 52377/60000 (87.29%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3914,                   Accuracy: 52341/60000 (87.24%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3888,                   Accuracy: 52363/60000 (87.27%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3906,                   Accuracy: 52268/60000 (87.11%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3691,                   Accuracy: 52777/60000 (87.96%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3702,                   Accuracy: 52756/60000 (87.93%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3701,                   Accuracy: 52827/60000 (88.04%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3706,                   Accuracy: 52838/60000 (88.06%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3646,                   Accuracy: 52999/60000 (88.33%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3503,                   Accuracy: 53258/60000 (88.76%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3327,                   Accuracy: 53609/60000 (89.35%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3132,                   Accuracy: 54105/60000 (90.18%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3077,                   Accuracy: 54302/60000 (90.50%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2944,                   Accuracy: 54530/60000 (90.88%)
{0: tensor(91.6383), 10: tensor(91.0817), 20: tensor(90.8533), 30: tensor(90.5400), 40: tensor(90.4250), 50: tensor(90.4300), 60: tensor(90.5667), 70: tensor(90.8417), 80: tensor(91.5433), 90: tensor(91.6467), 100: tensor(91.1183), 110: tensor(90.9167), 120: tensor(90.2983), 130: tensor(89.6000), 140: tensor(89.2933), 150: tensor(89.3933), 160: tensor(88.7800), 170: tensor(89.1467), 180: tensor(88.8750), 190: tensor(87.6917), 200: tensor(87.6117), 210: tensor(87.2533), 220: tensor(87.2950), 230: tensor(87.2350), 240: tensor(87.2717), 250: tensor(87.1133), 260: tensor(87.9617), 270: tensor(87.9267), 280: tensor(88.0450), 290: tensor(88.0633), 300: tensor(88.3317), 310: tensor(88.7633), 320: tensor(89.3483), 330: tensor(90.1750), 340: tensor(90.5033), 350: tensor(90.8833)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=24, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.3706,                   Accuracy: 262/2000.0 (13.10%)



-= Testing valid =-
Test set: Average loss: 2.1214,                   Accuracy: 678/2000.0 (33.90%)



-= Testing valid =-
Test set: Average loss: 2.9138,                   Accuracy: 365/2000.0 (18.25%)



-= Testing valid =-
Test set: Average loss: 1.2186,                   Accuracy: 1170/2000.0 (58.50%)



-= Testing valid =-
Test set: Average loss: 2.1201,                   Accuracy: 572/2000.0 (28.60%)



-= Testing valid =-
Test set: Average loss: 1.4332,                   Accuracy: 899/2000.0 (44.95%)



-= Testing valid =-
Test set: Average loss: 2.8568,                   Accuracy: 567/2000.0 (28.35%)



-= Testing valid =-
Test set: Average loss: 1.0097,                   Accuracy: 1265/2000.0 (63.25%)



-= Testing valid =-
Test set: Average loss: 1.1196,                   Accuracy: 1216/2000.0 (60.80%)



-= Testing valid =-
Test set: Average loss: 0.9178,                   Accuracy: 1391/2000.0 (69.55%)



Epoch 10 train accuracy: 70.82%, valid accuracy 69.55%
-= Testing valid =-
Test set: Average loss: 0.9246,                   Accuracy: 1378/2000.0 (68.90%)



-= Testing valid =-
Test set: Average loss: 0.7644,                   Accuracy: 1506/2000.0 (75.30%)



-= Testing valid =-
Test set: Average loss: 0.8471,                   Accuracy: 1384/2000.0 (69.20%)



-= Testing valid =-
Test set: Average loss: 0.7413,                   Accuracy: 1514/2000.0 (75.70%)



-= Testing valid =-
Test set: Average loss: 0.6453,                   Accuracy: 1576/2000.0 (78.80%)



-= Testing valid =-
Test set: Average loss: 0.4332,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.7815,                   Accuracy: 1443/2000.0 (72.15%)



-= Testing valid =-
Test set: Average loss: 0.6853,                   Accuracy: 1527/2000.0 (76.35%)



-= Testing valid =-
Test set: Average loss: 0.6552,                   Accuracy: 1560/2000.0 (78.00%)



-= Testing valid =-
Test set: Average loss: 0.3975,                   Accuracy: 1738/2000.0 (86.90%)



Epoch 20 train accuracy: 84.91%, valid accuracy 86.90%
-= Testing valid =-
Test set: Average loss: 0.3777,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.3526,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.4602,                   Accuracy: 1691/2000.0 (84.55%)



-= Testing valid =-
Test set: Average loss: 0.4160,                   Accuracy: 1722/2000.0 (86.10%)



-= Testing valid =-
Test set: Average loss: 0.3491,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.2766,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.3055,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.2856,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.2642,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.3312,                   Accuracy: 1780/2000.0 (89.00%)



Epoch 30 train accuracy: 89.50%, valid accuracy 89.00%
-= Testing valid =-
Test set: Average loss: 0.2921,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.2886,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.2803,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.2873,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.2936,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.3056,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.2969,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.2473,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.3019,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.2929,                   Accuracy: 1795/2000.0 (89.75%)



Epoch 40 train accuracy: 90.22%, valid accuracy 89.75%
-= Testing valid =-
Test set: Average loss: 0.2276,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2966,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.3098,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.2955,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.2423,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2843,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.2704,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.2507,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2849,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.2435,                   Accuracy: 1837/2000.0 (91.85%)



Epoch 50 train accuracy: 91.56%, valid accuracy 91.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2439,                   Accuracy: 55655/60000 (92.76%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2631,                   Accuracy: 55183/60000 (91.97%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2695,                   Accuracy: 54988/60000 (91.65%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2761,                   Accuracy: 54888/60000 (91.48%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2829,                   Accuracy: 54739/60000 (91.23%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2896,                   Accuracy: 54704/60000 (91.17%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3032,                   Accuracy: 54340/60000 (90.57%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3065,                   Accuracy: 54217/60000 (90.36%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3135,                   Accuracy: 53987/60000 (89.98%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3078,                   Accuracy: 54120/60000 (90.20%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3092,                   Accuracy: 54097/60000 (90.16%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3072,                   Accuracy: 54063/60000 (90.11%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3166,                   Accuracy: 53833/60000 (89.72%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3158,                   Accuracy: 53785/60000 (89.64%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3181,                   Accuracy: 53748/60000 (89.58%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3185,                   Accuracy: 53693/60000 (89.49%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3153,                   Accuracy: 53806/60000 (89.68%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3075,                   Accuracy: 53930/60000 (89.88%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3034,                   Accuracy: 54192/60000 (90.32%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3366,                   Accuracy: 53588/60000 (89.31%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3244,                   Accuracy: 53850/60000 (89.75%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3281,                   Accuracy: 53850/60000 (89.75%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3303,                   Accuracy: 53785/60000 (89.64%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3189,                   Accuracy: 54101/60000 (90.17%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.2988,                   Accuracy: 54474/60000 (90.79%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2853,                   Accuracy: 54845/60000 (91.41%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2640,                   Accuracy: 55285/60000 (92.14%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2495,                   Accuracy: 55608/60000 (92.68%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2464,                   Accuracy: 55663/60000 (92.77%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2424,                   Accuracy: 55706/60000 (92.84%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2392,                   Accuracy: 55817/60000 (93.03%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2342,                   Accuracy: 55855/60000 (93.09%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2291,                   Accuracy: 55961/60000 (93.27%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2294,                   Accuracy: 55901/60000 (93.17%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2362,                   Accuracy: 55763/60000 (92.94%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2402,                   Accuracy: 55668/60000 (92.78%)
{0: tensor(92.7583), 10: tensor(91.9717), 20: tensor(91.6467), 30: tensor(91.4800), 40: tensor(91.2317), 50: tensor(91.1733), 60: tensor(90.5667), 70: tensor(90.3617), 80: tensor(89.9783), 90: tensor(90.2000), 100: tensor(90.1617), 110: tensor(90.1050), 120: tensor(89.7217), 130: tensor(89.6417), 140: tensor(89.5800), 150: tensor(89.4883), 160: tensor(89.6767), 170: tensor(89.8833), 180: tensor(90.3200), 190: tensor(89.3133), 200: tensor(89.7500), 210: tensor(89.7500), 220: tensor(89.6417), 230: tensor(90.1683), 240: tensor(90.7900), 250: tensor(91.4083), 260: tensor(92.1417), 270: tensor(92.6800), 280: tensor(92.7717), 290: tensor(92.8433), 300: tensor(93.0283), 310: tensor(93.0917), 320: tensor(93.2683), 330: tensor(93.1683), 340: tensor(92.9383), 350: tensor(92.7800)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=25, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2605,                   Accuracy: 442/2000.0 (22.10%)



-= Testing valid =-
Test set: Average loss: 2.1882,                   Accuracy: 521/2000.0 (26.05%)



-= Testing valid =-
Test set: Average loss: 2.8536,                   Accuracy: 559/2000.0 (27.95%)



-= Testing valid =-
Test set: Average loss: 1.8543,                   Accuracy: 736/2000.0 (36.80%)



-= Testing valid =-
Test set: Average loss: 1.9216,                   Accuracy: 801/2000.0 (40.05%)



-= Testing valid =-
Test set: Average loss: 0.9780,                   Accuracy: 1289/2000.0 (64.45%)



-= Testing valid =-
Test set: Average loss: 2.1392,                   Accuracy: 843/2000.0 (42.15%)



-= Testing valid =-
Test set: Average loss: 0.8779,                   Accuracy: 1442/2000.0 (72.10%)



-= Testing valid =-
Test set: Average loss: 0.9161,                   Accuracy: 1295/2000.0 (64.75%)



-= Testing valid =-
Test set: Average loss: 1.1027,                   Accuracy: 1234/2000.0 (61.70%)



Epoch 10 train accuracy: 71.72%, valid accuracy 61.70%
-= Testing valid =-
Test set: Average loss: 0.8021,                   Accuracy: 1465/2000.0 (73.25%)



-= Testing valid =-
Test set: Average loss: 0.6253,                   Accuracy: 1632/2000.0 (81.60%)



-= Testing valid =-
Test set: Average loss: 0.7917,                   Accuracy: 1457/2000.0 (72.85%)



-= Testing valid =-
Test set: Average loss: 0.6777,                   Accuracy: 1548/2000.0 (77.40%)



-= Testing valid =-
Test set: Average loss: 0.4914,                   Accuracy: 1706/2000.0 (85.30%)



-= Testing valid =-
Test set: Average loss: 0.4454,                   Accuracy: 1712/2000.0 (85.60%)



-= Testing valid =-
Test set: Average loss: 0.3875,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 0.3858,                   Accuracy: 1755/2000.0 (87.75%)



-= Testing valid =-
Test set: Average loss: 0.3249,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.4499,                   Accuracy: 1703/2000.0 (85.15%)



Epoch 20 train accuracy: 85.66%, valid accuracy 85.15%
-= Testing valid =-
Test set: Average loss: 0.3684,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.3857,                   Accuracy: 1747/2000.0 (87.35%)



-= Testing valid =-
Test set: Average loss: 0.2859,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.2403,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.3040,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.2654,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.3116,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.2735,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2757,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2074,                   Accuracy: 1892/2000.0 (94.60%)



Epoch 30 train accuracy: 88.91%, valid accuracy 94.60%
-= Testing valid =-
Test set: Average loss: 0.2493,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2520,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2517,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2473,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2247,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.1956,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.2143,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.2162,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2196,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.2159,                   Accuracy: 1869/2000.0 (93.45%)



Epoch 40 train accuracy: 90.25%, valid accuracy 93.45%
-= Testing valid =-
Test set: Average loss: 0.2485,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2355,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.2562,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2161,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.2215,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.2486,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2107,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.2060,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.2112,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.1826,                   Accuracy: 1886/2000.0 (94.30%)



Epoch 50 train accuracy: 90.71%, valid accuracy 94.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2506,                   Accuracy: 55762/60000 (92.94%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2630,                   Accuracy: 55469/60000 (92.45%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2758,                   Accuracy: 55186/60000 (91.98%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2949,                   Accuracy: 54801/60000 (91.33%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3023,                   Accuracy: 54635/60000 (91.06%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3113,                   Accuracy: 54532/60000 (90.89%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3130,                   Accuracy: 54354/60000 (90.59%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3112,                   Accuracy: 54356/60000 (90.59%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3171,                   Accuracy: 54129/60000 (90.21%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3308,                   Accuracy: 53747/60000 (89.58%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3567,                   Accuracy: 53148/60000 (88.58%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3644,                   Accuracy: 52847/60000 (88.08%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3869,                   Accuracy: 52343/60000 (87.24%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3862,                   Accuracy: 52262/60000 (87.10%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3973,                   Accuracy: 51897/60000 (86.50%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4076,                   Accuracy: 51560/60000 (85.93%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4149,                   Accuracy: 51475/60000 (85.79%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.4227,                   Accuracy: 51410/60000 (85.68%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.4249,                   Accuracy: 51299/60000 (85.50%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.4366,                   Accuracy: 51263/60000 (85.44%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.4348,                   Accuracy: 51329/60000 (85.55%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4281,                   Accuracy: 51535/60000 (85.89%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4126,                   Accuracy: 51920/60000 (86.53%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3978,                   Accuracy: 52341/60000 (87.24%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3774,                   Accuracy: 52745/60000 (87.91%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3519,                   Accuracy: 53307/60000 (88.85%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3268,                   Accuracy: 53864/60000 (89.77%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3121,                   Accuracy: 54307/60000 (90.51%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3051,                   Accuracy: 54478/60000 (90.80%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2911,                   Accuracy: 54907/60000 (91.51%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2861,                   Accuracy: 55035/60000 (91.72%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2783,                   Accuracy: 55238/60000 (92.06%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2718,                   Accuracy: 55440/60000 (92.40%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2655,                   Accuracy: 55570/60000 (92.62%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2576,                   Accuracy: 55733/60000 (92.89%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2523,                   Accuracy: 55702/60000 (92.84%)
{0: tensor(92.9367), 10: tensor(92.4483), 20: tensor(91.9767), 30: tensor(91.3350), 40: tensor(91.0583), 50: tensor(90.8867), 60: tensor(90.5900), 70: tensor(90.5933), 80: tensor(90.2150), 90: tensor(89.5783), 100: tensor(88.5800), 110: tensor(88.0783), 120: tensor(87.2383), 130: tensor(87.1033), 140: tensor(86.4950), 150: tensor(85.9333), 160: tensor(85.7917), 170: tensor(85.6833), 180: tensor(85.4983), 190: tensor(85.4383), 200: tensor(85.5483), 210: tensor(85.8917), 220: tensor(86.5333), 230: tensor(87.2350), 240: tensor(87.9083), 250: tensor(88.8450), 260: tensor(89.7733), 270: tensor(90.5117), 280: tensor(90.7967), 290: tensor(91.5117), 300: tensor(91.7250), 310: tensor(92.0633), 320: tensor(92.4000), 330: tensor(92.6167), 340: tensor(92.8883), 350: tensor(92.8367)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=26, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.7444,                   Accuracy: 220/2000.0 (11.00%)



-= Testing valid =-
Test set: Average loss: 3.5289,                   Accuracy: 259/2000.0 (12.95%)



-= Testing valid =-
Test set: Average loss: 1.4386,                   Accuracy: 949/2000.0 (47.45%)



-= Testing valid =-
Test set: Average loss: 1.6431,                   Accuracy: 782/2000.0 (39.10%)



-= Testing valid =-
Test set: Average loss: 1.2639,                   Accuracy: 1072/2000.0 (53.60%)



-= Testing valid =-
Test set: Average loss: 0.8009,                   Accuracy: 1464/2000.0 (73.20%)



-= Testing valid =-
Test set: Average loss: 1.1404,                   Accuracy: 1165/2000.0 (58.25%)



-= Testing valid =-
Test set: Average loss: 0.9460,                   Accuracy: 1408/2000.0 (70.40%)



-= Testing valid =-
Test set: Average loss: 0.7400,                   Accuracy: 1549/2000.0 (77.45%)



-= Testing valid =-
Test set: Average loss: 0.9255,                   Accuracy: 1383/2000.0 (69.15%)



Epoch 10 train accuracy: 76.65%, valid accuracy 69.15%
-= Testing valid =-
Test set: Average loss: 0.6830,                   Accuracy: 1559/2000.0 (77.95%)



-= Testing valid =-
Test set: Average loss: 0.4623,                   Accuracy: 1719/2000.0 (85.95%)



-= Testing valid =-
Test set: Average loss: 0.4908,                   Accuracy: 1686/2000.0 (84.30%)



-= Testing valid =-
Test set: Average loss: 0.5327,                   Accuracy: 1658/2000.0 (82.90%)



-= Testing valid =-
Test set: Average loss: 0.5046,                   Accuracy: 1687/2000.0 (84.35%)



-= Testing valid =-
Test set: Average loss: 0.3202,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.5178,                   Accuracy: 1653/2000.0 (82.65%)



-= Testing valid =-
Test set: Average loss: 0.3623,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.3387,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.2984,                   Accuracy: 1811/2000.0 (90.55%)



Epoch 20 train accuracy: 86.97%, valid accuracy 90.55%
-= Testing valid =-
Test set: Average loss: 0.3274,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.3690,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.3762,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.4068,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.3381,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.3271,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.2904,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.3302,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.3811,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.3084,                   Accuracy: 1818/2000.0 (90.90%)



Epoch 30 train accuracy: 89.76%, valid accuracy 90.90%
-= Testing valid =-
Test set: Average loss: 0.2840,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.3102,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3142,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.3224,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2728,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.3393,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.2952,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2915,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.2520,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2781,                   Accuracy: 1820/2000.0 (91.00%)



Epoch 40 train accuracy: 90.45%, valid accuracy 91.00%
-= Testing valid =-
Test set: Average loss: 0.2854,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2849,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2623,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2973,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2926,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.2902,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.3020,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2925,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.3035,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.2648,                   Accuracy: 1830/2000.0 (91.50%)



Epoch 50 train accuracy: 91.10%, valid accuracy 91.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2543,                   Accuracy: 55415/60000 (92.36%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2566,                   Accuracy: 55332/60000 (92.22%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2646,                   Accuracy: 55169/60000 (91.95%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2698,                   Accuracy: 55131/60000 (91.89%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2742,                   Accuracy: 55153/60000 (91.92%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2737,                   Accuracy: 55136/60000 (91.89%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2741,                   Accuracy: 55144/60000 (91.91%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2769,                   Accuracy: 55067/60000 (91.78%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2724,                   Accuracy: 55035/60000 (91.72%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2836,                   Accuracy: 54842/60000 (91.40%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2971,                   Accuracy: 54536/60000 (90.89%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3160,                   Accuracy: 54242/60000 (90.40%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3310,                   Accuracy: 54055/60000 (90.09%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3367,                   Accuracy: 53947/60000 (89.91%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3386,                   Accuracy: 53863/60000 (89.77%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3383,                   Accuracy: 53697/60000 (89.50%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3345,                   Accuracy: 53712/60000 (89.52%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3168,                   Accuracy: 54034/60000 (90.06%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3221,                   Accuracy: 53897/60000 (89.83%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3220,                   Accuracy: 53888/60000 (89.81%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3366,                   Accuracy: 53535/60000 (89.22%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3441,                   Accuracy: 53489/60000 (89.15%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3363,                   Accuracy: 53744/60000 (89.57%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3239,                   Accuracy: 53961/60000 (89.93%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3144,                   Accuracy: 54207/60000 (90.35%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3038,                   Accuracy: 54497/60000 (90.83%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2905,                   Accuracy: 54709/60000 (91.18%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2871,                   Accuracy: 54847/60000 (91.41%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2834,                   Accuracy: 54831/60000 (91.39%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2949,                   Accuracy: 54734/60000 (91.22%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2944,                   Accuracy: 54811/60000 (91.35%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2916,                   Accuracy: 54918/60000 (91.53%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2797,                   Accuracy: 55108/60000 (91.85%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2719,                   Accuracy: 55203/60000 (92.00%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2685,                   Accuracy: 55249/60000 (92.08%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2482,                   Accuracy: 55546/60000 (92.58%)
{0: tensor(92.3583), 10: tensor(92.2200), 20: tensor(91.9483), 30: tensor(91.8850), 40: tensor(91.9217), 50: tensor(91.8933), 60: tensor(91.9067), 70: tensor(91.7783), 80: tensor(91.7250), 90: tensor(91.4033), 100: tensor(90.8933), 110: tensor(90.4033), 120: tensor(90.0917), 130: tensor(89.9117), 140: tensor(89.7717), 150: tensor(89.4950), 160: tensor(89.5200), 170: tensor(90.0567), 180: tensor(89.8283), 190: tensor(89.8133), 200: tensor(89.2250), 210: tensor(89.1483), 220: tensor(89.5733), 230: tensor(89.9350), 240: tensor(90.3450), 250: tensor(90.8283), 260: tensor(91.1817), 270: tensor(91.4117), 280: tensor(91.3850), 290: tensor(91.2233), 300: tensor(91.3517), 310: tensor(91.5300), 320: tensor(91.8467), 330: tensor(92.0050), 340: tensor(92.0817), 350: tensor(92.5767)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=27, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0757,                   Accuracy: 512/2000.0 (25.60%)



-= Testing valid =-
Test set: Average loss: 2.3859,                   Accuracy: 360/2000.0 (18.00%)



-= Testing valid =-
Test set: Average loss: 1.5157,                   Accuracy: 872/2000.0 (43.60%)



-= Testing valid =-
Test set: Average loss: 3.3000,                   Accuracy: 365/2000.0 (18.25%)



-= Testing valid =-
Test set: Average loss: 1.3264,                   Accuracy: 1174/2000.0 (58.70%)



-= Testing valid =-
Test set: Average loss: 1.7325,                   Accuracy: 812/2000.0 (40.60%)



-= Testing valid =-
Test set: Average loss: 2.3160,                   Accuracy: 614/2000.0 (30.70%)



-= Testing valid =-
Test set: Average loss: 0.9349,                   Accuracy: 1413/2000.0 (70.65%)



-= Testing valid =-
Test set: Average loss: 1.2251,                   Accuracy: 1156/2000.0 (57.80%)



-= Testing valid =-
Test set: Average loss: 1.3806,                   Accuracy: 1197/2000.0 (59.85%)



Epoch 10 train accuracy: 71.22%, valid accuracy 59.85%
-= Testing valid =-
Test set: Average loss: 0.7540,                   Accuracy: 1537/2000.0 (76.85%)



-= Testing valid =-
Test set: Average loss: 0.8924,                   Accuracy: 1442/2000.0 (72.10%)



-= Testing valid =-
Test set: Average loss: 0.6836,                   Accuracy: 1602/2000.0 (80.10%)



-= Testing valid =-
Test set: Average loss: 0.6749,                   Accuracy: 1552/2000.0 (77.60%)



-= Testing valid =-
Test set: Average loss: 0.6181,                   Accuracy: 1590/2000.0 (79.50%)



-= Testing valid =-
Test set: Average loss: 0.6810,                   Accuracy: 1568/2000.0 (78.40%)



-= Testing valid =-
Test set: Average loss: 0.6856,                   Accuracy: 1539/2000.0 (76.95%)



-= Testing valid =-
Test set: Average loss: 0.5306,                   Accuracy: 1672/2000.0 (83.60%)



-= Testing valid =-
Test set: Average loss: 0.4401,                   Accuracy: 1712/2000.0 (85.60%)



-= Testing valid =-
Test set: Average loss: 0.4129,                   Accuracy: 1773/2000.0 (88.65%)



Epoch 20 train accuracy: 85.81%, valid accuracy 88.65%
-= Testing valid =-
Test set: Average loss: 0.2511,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.3005,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.3400,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.2790,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2763,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.3339,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.3575,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.2581,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.3261,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.2459,                   Accuracy: 1859/2000.0 (92.95%)



Epoch 30 train accuracy: 89.64%, valid accuracy 92.95%
-= Testing valid =-
Test set: Average loss: 0.3107,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.2604,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.2799,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2869,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.2370,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.3101,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.2750,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2442,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.2764,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2805,                   Accuracy: 1825/2000.0 (91.25%)



Epoch 40 train accuracy: 90.30%, valid accuracy 91.25%
-= Testing valid =-
Test set: Average loss: 0.2401,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2679,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2749,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.2655,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2511,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2542,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.2670,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2695,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2705,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2767,                   Accuracy: 1830/2000.0 (91.50%)



Epoch 50 train accuracy: 91.12%, valid accuracy 91.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2627,                   Accuracy: 55231/60000 (92.05%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2787,                   Accuracy: 54809/60000 (91.35%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2847,                   Accuracy: 54723/60000 (91.21%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2970,                   Accuracy: 54479/60000 (90.80%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3074,                   Accuracy: 54269/60000 (90.45%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3155,                   Accuracy: 54056/60000 (90.09%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3225,                   Accuracy: 53878/60000 (89.80%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3226,                   Accuracy: 53870/60000 (89.78%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3230,                   Accuracy: 53874/60000 (89.79%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3273,                   Accuracy: 53805/60000 (89.68%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3511,                   Accuracy: 53360/60000 (88.93%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3719,                   Accuracy: 52912/60000 (88.19%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3889,                   Accuracy: 52426/60000 (87.38%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3910,                   Accuracy: 52475/60000 (87.46%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3819,                   Accuracy: 52622/60000 (87.70%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3728,                   Accuracy: 52803/60000 (88.00%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3620,                   Accuracy: 52974/60000 (88.29%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3463,                   Accuracy: 53149/60000 (88.58%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3416,                   Accuracy: 53245/60000 (88.74%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3386,                   Accuracy: 53295/60000 (88.82%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3240,                   Accuracy: 53665/60000 (89.44%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3205,                   Accuracy: 53784/60000 (89.64%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3220,                   Accuracy: 53894/60000 (89.82%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3212,                   Accuracy: 53929/60000 (89.88%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3174,                   Accuracy: 53969/60000 (89.95%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3136,                   Accuracy: 54075/60000 (90.12%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2997,                   Accuracy: 54284/60000 (90.47%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2924,                   Accuracy: 54587/60000 (90.98%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3027,                   Accuracy: 54309/60000 (90.51%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3007,                   Accuracy: 54575/60000 (90.96%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2960,                   Accuracy: 54666/60000 (91.11%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2906,                   Accuracy: 54813/60000 (91.36%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2852,                   Accuracy: 54960/60000 (91.60%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2790,                   Accuracy: 55004/60000 (91.67%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2736,                   Accuracy: 55069/60000 (91.78%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2697,                   Accuracy: 55056/60000 (91.76%)
{0: tensor(92.0517), 10: tensor(91.3483), 20: tensor(91.2050), 30: tensor(90.7983), 40: tensor(90.4483), 50: tensor(90.0933), 60: tensor(89.7967), 70: tensor(89.7833), 80: tensor(89.7900), 90: tensor(89.6750), 100: tensor(88.9333), 110: tensor(88.1867), 120: tensor(87.3767), 130: tensor(87.4583), 140: tensor(87.7033), 150: tensor(88.0050), 160: tensor(88.2900), 170: tensor(88.5817), 180: tensor(88.7417), 190: tensor(88.8250), 200: tensor(89.4417), 210: tensor(89.6400), 220: tensor(89.8233), 230: tensor(89.8817), 240: tensor(89.9483), 250: tensor(90.1250), 260: tensor(90.4733), 270: tensor(90.9783), 280: tensor(90.5150), 290: tensor(90.9583), 300: tensor(91.1100), 310: tensor(91.3550), 320: tensor(91.6000), 330: tensor(91.6733), 340: tensor(91.7817), 350: tensor(91.7600)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=28, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 8.1806,                   Accuracy: 249/2000.0 (12.45%)



-= Testing valid =-
Test set: Average loss: 5.7228,                   Accuracy: 253/2000.0 (12.65%)



-= Testing valid =-
Test set: Average loss: 2.9618,                   Accuracy: 311/2000.0 (15.55%)



-= Testing valid =-
Test set: Average loss: 1.7867,                   Accuracy: 752/2000.0 (37.60%)



-= Testing valid =-
Test set: Average loss: 2.6523,                   Accuracy: 468/2000.0 (23.40%)



-= Testing valid =-
Test set: Average loss: 2.0890,                   Accuracy: 637/2000.0 (31.85%)



-= Testing valid =-
Test set: Average loss: 1.1319,                   Accuracy: 1223/2000.0 (61.15%)



-= Testing valid =-
Test set: Average loss: 1.4049,                   Accuracy: 984/2000.0 (49.20%)



-= Testing valid =-
Test set: Average loss: 1.4651,                   Accuracy: 925/2000.0 (46.25%)



-= Testing valid =-
Test set: Average loss: 1.3062,                   Accuracy: 1009/2000.0 (50.45%)



Epoch 10 train accuracy: 67.90%, valid accuracy 50.45%
-= Testing valid =-
Test set: Average loss: 0.8891,                   Accuracy: 1398/2000.0 (69.90%)



-= Testing valid =-
Test set: Average loss: 0.8105,                   Accuracy: 1469/2000.0 (73.45%)



-= Testing valid =-
Test set: Average loss: 0.7108,                   Accuracy: 1534/2000.0 (76.70%)



-= Testing valid =-
Test set: Average loss: 0.7739,                   Accuracy: 1503/2000.0 (75.15%)



-= Testing valid =-
Test set: Average loss: 0.9225,                   Accuracy: 1408/2000.0 (70.40%)



-= Testing valid =-
Test set: Average loss: 0.9110,                   Accuracy: 1369/2000.0 (68.45%)



-= Testing valid =-
Test set: Average loss: 0.6381,                   Accuracy: 1577/2000.0 (78.85%)



-= Testing valid =-
Test set: Average loss: 0.6303,                   Accuracy: 1597/2000.0 (79.85%)



-= Testing valid =-
Test set: Average loss: 0.5480,                   Accuracy: 1674/2000.0 (83.70%)



-= Testing valid =-
Test set: Average loss: 0.4145,                   Accuracy: 1765/2000.0 (88.25%)



Epoch 20 train accuracy: 81.71%, valid accuracy 88.25%
-= Testing valid =-
Test set: Average loss: 0.4311,                   Accuracy: 1745/2000.0 (87.25%)



-= Testing valid =-
Test set: Average loss: 0.5094,                   Accuracy: 1677/2000.0 (83.85%)



-= Testing valid =-
Test set: Average loss: 0.3990,                   Accuracy: 1764/2000.0 (88.20%)



-= Testing valid =-
Test set: Average loss: 0.3969,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.4738,                   Accuracy: 1694/2000.0 (84.70%)



-= Testing valid =-
Test set: Average loss: 0.4882,                   Accuracy: 1652/2000.0 (82.60%)



-= Testing valid =-
Test set: Average loss: 0.4398,                   Accuracy: 1726/2000.0 (86.30%)



-= Testing valid =-
Test set: Average loss: 0.4496,                   Accuracy: 1698/2000.0 (84.90%)



-= Testing valid =-
Test set: Average loss: 0.4540,                   Accuracy: 1700/2000.0 (85.00%)



-= Testing valid =-
Test set: Average loss: 0.4218,                   Accuracy: 1740/2000.0 (87.00%)



Epoch 30 train accuracy: 86.50%, valid accuracy 87.00%
-= Testing valid =-
Test set: Average loss: 0.3634,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.3554,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.3258,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.3404,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.3430,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.3465,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3470,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 0.4171,                   Accuracy: 1718/2000.0 (85.90%)



-= Testing valid =-
Test set: Average loss: 0.3234,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.3204,                   Accuracy: 1796/2000.0 (89.80%)



Epoch 40 train accuracy: 87.54%, valid accuracy 89.80%
-= Testing valid =-
Test set: Average loss: 0.3649,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.3155,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.3342,                   Accuracy: 1777/2000.0 (88.85%)



-= Testing valid =-
Test set: Average loss: 0.2942,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.3049,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.2738,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.3167,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.2993,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.3222,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.2898,                   Accuracy: 1822/2000.0 (91.10%)



Epoch 50 train accuracy: 88.45%, valid accuracy 91.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3305,                   Accuracy: 54121/60000 (90.20%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3603,                   Accuracy: 53481/60000 (89.14%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3587,                   Accuracy: 53506/60000 (89.18%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3749,                   Accuracy: 53143/60000 (88.57%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3791,                   Accuracy: 53007/60000 (88.35%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3748,                   Accuracy: 53125/60000 (88.54%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3826,                   Accuracy: 53038/60000 (88.40%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3646,                   Accuracy: 53366/60000 (88.94%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3495,                   Accuracy: 53502/60000 (89.17%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3371,                   Accuracy: 53772/60000 (89.62%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3580,                   Accuracy: 53336/60000 (88.89%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3523,                   Accuracy: 53501/60000 (89.17%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3628,                   Accuracy: 53324/60000 (88.87%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3570,                   Accuracy: 53396/60000 (88.99%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3518,                   Accuracy: 53430/60000 (89.05%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3572,                   Accuracy: 53347/60000 (88.91%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3534,                   Accuracy: 53384/60000 (88.97%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3526,                   Accuracy: 53249/60000 (88.75%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3511,                   Accuracy: 53246/60000 (88.74%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3707,                   Accuracy: 52930/60000 (88.22%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3717,                   Accuracy: 52810/60000 (88.02%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3823,                   Accuracy: 52633/60000 (87.72%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3866,                   Accuracy: 52586/60000 (87.64%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3818,                   Accuracy: 52784/60000 (87.97%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3875,                   Accuracy: 52706/60000 (87.84%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3703,                   Accuracy: 53118/60000 (88.53%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3452,                   Accuracy: 53535/60000 (89.22%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3378,                   Accuracy: 53805/60000 (89.68%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3407,                   Accuracy: 53842/60000 (89.74%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3359,                   Accuracy: 53843/60000 (89.74%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3453,                   Accuracy: 53723/60000 (89.54%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3417,                   Accuracy: 53809/60000 (89.68%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3345,                   Accuracy: 53914/60000 (89.86%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3417,                   Accuracy: 53897/60000 (89.83%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3413,                   Accuracy: 53866/60000 (89.78%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3308,                   Accuracy: 54076/60000 (90.13%)
{0: tensor(90.2017), 10: tensor(89.1350), 20: tensor(89.1767), 30: tensor(88.5717), 40: tensor(88.3450), 50: tensor(88.5417), 60: tensor(88.3967), 70: tensor(88.9433), 80: tensor(89.1700), 90: tensor(89.6200), 100: tensor(88.8933), 110: tensor(89.1683), 120: tensor(88.8733), 130: tensor(88.9933), 140: tensor(89.0500), 150: tensor(88.9117), 160: tensor(88.9733), 170: tensor(88.7483), 180: tensor(88.7433), 190: tensor(88.2167), 200: tensor(88.0167), 210: tensor(87.7217), 220: tensor(87.6433), 230: tensor(87.9733), 240: tensor(87.8433), 250: tensor(88.5300), 260: tensor(89.2250), 270: tensor(89.6750), 280: tensor(89.7367), 290: tensor(89.7383), 300: tensor(89.5383), 310: tensor(89.6817), 320: tensor(89.8567), 330: tensor(89.8283), 340: tensor(89.7767), 350: tensor(90.1267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=29, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.8035,                   Accuracy: 215/2000.0 (10.75%)



-= Testing valid =-
Test set: Average loss: 2.1870,                   Accuracy: 496/2000.0 (24.80%)



-= Testing valid =-
Test set: Average loss: 1.7415,                   Accuracy: 830/2000.0 (41.50%)



-= Testing valid =-
Test set: Average loss: 1.2938,                   Accuracy: 1141/2000.0 (57.05%)



-= Testing valid =-
Test set: Average loss: 1.1142,                   Accuracy: 1197/2000.0 (59.85%)



-= Testing valid =-
Test set: Average loss: 1.1699,                   Accuracy: 1236/2000.0 (61.80%)



-= Testing valid =-
Test set: Average loss: 0.7323,                   Accuracy: 1512/2000.0 (75.60%)



-= Testing valid =-
Test set: Average loss: 1.0041,                   Accuracy: 1334/2000.0 (66.70%)



-= Testing valid =-
Test set: Average loss: 0.6551,                   Accuracy: 1593/2000.0 (79.65%)



-= Testing valid =-
Test set: Average loss: 1.0564,                   Accuracy: 1359/2000.0 (67.95%)



Epoch 10 train accuracy: 76.86%, valid accuracy 67.95%
-= Testing valid =-
Test set: Average loss: 0.7653,                   Accuracy: 1482/2000.0 (74.10%)



-= Testing valid =-
Test set: Average loss: 0.6057,                   Accuracy: 1534/2000.0 (76.70%)



-= Testing valid =-
Test set: Average loss: 0.3935,                   Accuracy: 1755/2000.0 (87.75%)



-= Testing valid =-
Test set: Average loss: 0.3715,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.3007,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.4580,                   Accuracy: 1707/2000.0 (85.35%)



-= Testing valid =-
Test set: Average loss: 0.5272,                   Accuracy: 1656/2000.0 (82.80%)



-= Testing valid =-
Test set: Average loss: 0.3200,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.3745,                   Accuracy: 1759/2000.0 (87.95%)



-= Testing valid =-
Test set: Average loss: 0.2957,                   Accuracy: 1812/2000.0 (90.60%)



Epoch 20 train accuracy: 86.80%, valid accuracy 90.60%
-= Testing valid =-
Test set: Average loss: 0.3285,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.2850,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.2571,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2952,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.2833,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.2168,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.3073,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2917,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.2818,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.3556,                   Accuracy: 1783/2000.0 (89.15%)



Epoch 30 train accuracy: 89.56%, valid accuracy 89.15%
-= Testing valid =-
Test set: Average loss: 0.2757,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2393,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.2583,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2310,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.2286,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.2221,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2221,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.1891,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.2461,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2073,                   Accuracy: 1867/2000.0 (93.35%)



Epoch 40 train accuracy: 90.59%, valid accuracy 93.35%
-= Testing valid =-
Test set: Average loss: 0.2008,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.2300,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.2421,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2546,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2417,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2346,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2162,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2589,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2527,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2178,                   Accuracy: 1862/2000.0 (93.10%)



Epoch 50 train accuracy: 90.56%, valid accuracy 93.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2328,                   Accuracy: 56016/60000 (93.36%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2423,                   Accuracy: 55793/60000 (92.99%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2489,                   Accuracy: 55724/60000 (92.87%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2594,                   Accuracy: 55445/60000 (92.41%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2627,                   Accuracy: 55388/60000 (92.31%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2620,                   Accuracy: 55384/60000 (92.31%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2602,                   Accuracy: 55368/60000 (92.28%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2555,                   Accuracy: 55428/60000 (92.38%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2508,                   Accuracy: 55464/60000 (92.44%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2500,                   Accuracy: 55468/60000 (92.45%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2723,                   Accuracy: 54960/60000 (91.60%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2937,                   Accuracy: 54487/60000 (90.81%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3156,                   Accuracy: 53869/60000 (89.78%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3353,                   Accuracy: 53413/60000 (89.02%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3548,                   Accuracy: 52930/60000 (88.22%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3705,                   Accuracy: 52390/60000 (87.32%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3809,                   Accuracy: 52144/60000 (86.91%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3852,                   Accuracy: 51926/60000 (86.54%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3788,                   Accuracy: 52200/60000 (87.00%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3964,                   Accuracy: 51963/60000 (86.61%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3856,                   Accuracy: 52303/60000 (87.17%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3846,                   Accuracy: 52410/60000 (87.35%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3801,                   Accuracy: 52494/60000 (87.49%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3746,                   Accuracy: 52644/60000 (87.74%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3586,                   Accuracy: 52953/60000 (88.25%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3447,                   Accuracy: 53333/60000 (88.89%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3268,                   Accuracy: 53655/60000 (89.43%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3119,                   Accuracy: 54015/60000 (90.03%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3128,                   Accuracy: 54108/60000 (90.18%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3032,                   Accuracy: 54233/60000 (90.39%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2951,                   Accuracy: 54495/60000 (90.82%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2844,                   Accuracy: 54759/60000 (91.26%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2741,                   Accuracy: 55036/60000 (91.73%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2628,                   Accuracy: 55280/60000 (92.13%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2480,                   Accuracy: 55660/60000 (92.77%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2341,                   Accuracy: 55858/60000 (93.10%)
{0: tensor(93.3600), 10: tensor(92.9883), 20: tensor(92.8733), 30: tensor(92.4083), 40: tensor(92.3133), 50: tensor(92.3067), 60: tensor(92.2800), 70: tensor(92.3800), 80: tensor(92.4400), 90: tensor(92.4467), 100: tensor(91.6000), 110: tensor(90.8117), 120: tensor(89.7817), 130: tensor(89.0217), 140: tensor(88.2167), 150: tensor(87.3167), 160: tensor(86.9067), 170: tensor(86.5433), 180: tensor(87.), 190: tensor(86.6050), 200: tensor(87.1717), 210: tensor(87.3500), 220: tensor(87.4900), 230: tensor(87.7400), 240: tensor(88.2550), 250: tensor(88.8883), 260: tensor(89.4250), 270: tensor(90.0250), 280: tensor(90.1800), 290: tensor(90.3883), 300: tensor(90.8250), 310: tensor(91.2650), 320: tensor(91.7267), 330: tensor(92.1333), 340: tensor(92.7667), 350: tensor(93.0967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=30, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 6.9329,                   Accuracy: 218/2000.0 (10.90%)



-= Testing valid =-
Test set: Average loss: 2.4994,                   Accuracy: 428/2000.0 (21.40%)



-= Testing valid =-
Test set: Average loss: 1.5020,                   Accuracy: 954/2000.0 (47.70%)



-= Testing valid =-
Test set: Average loss: 2.7582,                   Accuracy: 561/2000.0 (28.05%)



-= Testing valid =-
Test set: Average loss: 1.2705,                   Accuracy: 1043/2000.0 (52.15%)



-= Testing valid =-
Test set: Average loss: 1.5061,                   Accuracy: 1015/2000.0 (50.75%)



-= Testing valid =-
Test set: Average loss: 2.3009,                   Accuracy: 814/2000.0 (40.70%)



-= Testing valid =-
Test set: Average loss: 0.9753,                   Accuracy: 1281/2000.0 (64.05%)



-= Testing valid =-
Test set: Average loss: 1.1654,                   Accuracy: 1225/2000.0 (61.25%)



-= Testing valid =-
Test set: Average loss: 0.6236,                   Accuracy: 1625/2000.0 (81.25%)



Epoch 10 train accuracy: 75.43%, valid accuracy 81.25%
-= Testing valid =-
Test set: Average loss: 0.8405,                   Accuracy: 1383/2000.0 (69.15%)



-= Testing valid =-
Test set: Average loss: 0.5338,                   Accuracy: 1644/2000.0 (82.20%)



-= Testing valid =-
Test set: Average loss: 0.7951,                   Accuracy: 1405/2000.0 (70.25%)



-= Testing valid =-
Test set: Average loss: 0.4690,                   Accuracy: 1704/2000.0 (85.20%)



-= Testing valid =-
Test set: Average loss: 0.4366,                   Accuracy: 1723/2000.0 (86.15%)



-= Testing valid =-
Test set: Average loss: 0.3387,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.4414,                   Accuracy: 1721/2000.0 (86.05%)



-= Testing valid =-
Test set: Average loss: 0.4831,                   Accuracy: 1688/2000.0 (84.40%)



-= Testing valid =-
Test set: Average loss: 0.3224,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.3297,                   Accuracy: 1776/2000.0 (88.80%)



Epoch 20 train accuracy: 86.01%, valid accuracy 88.80%
-= Testing valid =-
Test set: Average loss: 0.4214,                   Accuracy: 1702/2000.0 (85.10%)



-= Testing valid =-
Test set: Average loss: 0.3011,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.3296,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.2674,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2884,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.3022,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.3137,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3031,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.2656,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.3794,                   Accuracy: 1748/2000.0 (87.40%)



Epoch 30 train accuracy: 88.68%, valid accuracy 87.40%
-= Testing valid =-
Test set: Average loss: 0.2470,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.2975,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.2827,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2765,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2515,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2932,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.3000,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.2992,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2499,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2596,                   Accuracy: 1835/2000.0 (91.75%)



Epoch 40 train accuracy: 90.36%, valid accuracy 91.75%
-= Testing valid =-
Test set: Average loss: 0.2402,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.2417,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2456,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2663,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2500,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2419,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2647,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2341,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.2016,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.2347,                   Accuracy: 1860/2000.0 (93.00%)



Epoch 50 train accuracy: 91.05%, valid accuracy 93.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2438,                   Accuracy: 55713/60000 (92.86%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2380,                   Accuracy: 55757/60000 (92.93%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2420,                   Accuracy: 55785/60000 (92.97%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2520,                   Accuracy: 55619/60000 (92.70%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2557,                   Accuracy: 55571/60000 (92.62%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2607,                   Accuracy: 55506/60000 (92.51%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2650,                   Accuracy: 55353/60000 (92.25%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2603,                   Accuracy: 55289/60000 (92.15%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2502,                   Accuracy: 55527/60000 (92.54%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2551,                   Accuracy: 55402/60000 (92.34%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2679,                   Accuracy: 55120/60000 (91.87%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2849,                   Accuracy: 54806/60000 (91.34%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.2993,                   Accuracy: 54551/60000 (90.92%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3005,                   Accuracy: 54510/60000 (90.85%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3033,                   Accuracy: 54418/60000 (90.70%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3030,                   Accuracy: 54354/60000 (90.59%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2963,                   Accuracy: 54404/60000 (90.67%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3015,                   Accuracy: 54072/60000 (90.12%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3094,                   Accuracy: 53923/60000 (89.87%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3298,                   Accuracy: 53388/60000 (88.98%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3432,                   Accuracy: 52964/60000 (88.27%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3525,                   Accuracy: 52804/60000 (88.01%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3538,                   Accuracy: 52905/60000 (88.18%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3520,                   Accuracy: 52943/60000 (88.24%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3433,                   Accuracy: 53233/60000 (88.72%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3268,                   Accuracy: 53652/60000 (89.42%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3055,                   Accuracy: 54151/60000 (90.25%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2924,                   Accuracy: 54548/60000 (90.91%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2884,                   Accuracy: 54640/60000 (91.07%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2961,                   Accuracy: 54451/60000 (90.75%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3028,                   Accuracy: 54314/60000 (90.52%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3044,                   Accuracy: 54272/60000 (90.45%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2982,                   Accuracy: 54521/60000 (90.87%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2900,                   Accuracy: 54714/60000 (91.19%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2706,                   Accuracy: 55096/60000 (91.83%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2476,                   Accuracy: 55581/60000 (92.64%)
{0: tensor(92.8550), 10: tensor(92.9283), 20: tensor(92.9750), 30: tensor(92.6983), 40: tensor(92.6183), 50: tensor(92.5100), 60: tensor(92.2550), 70: tensor(92.1483), 80: tensor(92.5450), 90: tensor(92.3367), 100: tensor(91.8667), 110: tensor(91.3433), 120: tensor(90.9183), 130: tensor(90.8500), 140: tensor(90.6967), 150: tensor(90.5900), 160: tensor(90.6733), 170: tensor(90.1200), 180: tensor(89.8717), 190: tensor(88.9800), 200: tensor(88.2733), 210: tensor(88.0067), 220: tensor(88.1750), 230: tensor(88.2383), 240: tensor(88.7217), 250: tensor(89.4200), 260: tensor(90.2517), 270: tensor(90.9133), 280: tensor(91.0667), 290: tensor(90.7517), 300: tensor(90.5233), 310: tensor(90.4533), 320: tensor(90.8683), 330: tensor(91.1900), 340: tensor(91.8267), 350: tensor(92.6350)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=31, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0927,                   Accuracy: 490/2000.0 (24.50%)



-= Testing valid =-
Test set: Average loss: 3.2569,                   Accuracy: 356/2000.0 (17.80%)



-= Testing valid =-
Test set: Average loss: 1.9601,                   Accuracy: 557/2000.0 (27.85%)



-= Testing valid =-
Test set: Average loss: 1.7873,                   Accuracy: 817/2000.0 (40.85%)



-= Testing valid =-
Test set: Average loss: 1.8767,                   Accuracy: 658/2000.0 (32.90%)



-= Testing valid =-
Test set: Average loss: 1.3849,                   Accuracy: 1046/2000.0 (52.30%)



-= Testing valid =-
Test set: Average loss: 1.6975,                   Accuracy: 710/2000.0 (35.50%)



-= Testing valid =-
Test set: Average loss: 1.2374,                   Accuracy: 1125/2000.0 (56.25%)



-= Testing valid =-
Test set: Average loss: 1.4530,                   Accuracy: 1008/2000.0 (50.40%)



-= Testing valid =-
Test set: Average loss: 1.7581,                   Accuracy: 825/2000.0 (41.25%)



Epoch 10 train accuracy: 72.86%, valid accuracy 41.25%
-= Testing valid =-
Test set: Average loss: 0.7027,                   Accuracy: 1559/2000.0 (77.95%)



-= Testing valid =-
Test set: Average loss: 0.7243,                   Accuracy: 1503/2000.0 (75.15%)



-= Testing valid =-
Test set: Average loss: 0.8009,                   Accuracy: 1411/2000.0 (70.55%)



-= Testing valid =-
Test set: Average loss: 1.0259,                   Accuracy: 1228/2000.0 (61.40%)



-= Testing valid =-
Test set: Average loss: 0.6318,                   Accuracy: 1569/2000.0 (78.45%)



-= Testing valid =-
Test set: Average loss: 0.5546,                   Accuracy: 1653/2000.0 (82.65%)



-= Testing valid =-
Test set: Average loss: 0.4718,                   Accuracy: 1681/2000.0 (84.05%)



-= Testing valid =-
Test set: Average loss: 0.3793,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.6598,                   Accuracy: 1572/2000.0 (78.60%)



-= Testing valid =-
Test set: Average loss: 0.4094,                   Accuracy: 1756/2000.0 (87.80%)



Epoch 20 train accuracy: 85.16%, valid accuracy 87.80%
-= Testing valid =-
Test set: Average loss: 0.3457,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.3203,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.4170,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.3307,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.3944,                   Accuracy: 1764/2000.0 (88.20%)



-= Testing valid =-
Test set: Average loss: 0.2955,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.3104,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2876,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2781,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2579,                   Accuracy: 1849/2000.0 (92.45%)



Epoch 30 train accuracy: 88.39%, valid accuracy 92.45%
-= Testing valid =-
Test set: Average loss: 0.2760,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.3021,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2728,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.3304,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.2757,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2930,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2743,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2857,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2782,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.3307,                   Accuracy: 1802/2000.0 (90.10%)



Epoch 40 train accuracy: 89.64%, valid accuracy 90.10%
-= Testing valid =-
Test set: Average loss: 0.2720,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2844,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.3413,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.3280,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.3020,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.2994,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2799,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.3246,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.2708,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2880,                   Accuracy: 1826/2000.0 (91.30%)



Epoch 50 train accuracy: 90.18%, valid accuracy 91.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2937,                   Accuracy: 54952/60000 (91.59%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3018,                   Accuracy: 54722/60000 (91.20%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3083,                   Accuracy: 54655/60000 (91.09%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3182,                   Accuracy: 54424/60000 (90.71%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3111,                   Accuracy: 54560/60000 (90.93%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3120,                   Accuracy: 54525/60000 (90.88%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3150,                   Accuracy: 54483/60000 (90.81%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3212,                   Accuracy: 54165/60000 (90.28%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3288,                   Accuracy: 53823/60000 (89.71%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3526,                   Accuracy: 53415/60000 (89.03%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3883,                   Accuracy: 52603/60000 (87.67%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.4081,                   Accuracy: 52207/60000 (87.01%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4523,                   Accuracy: 51288/60000 (85.48%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4604,                   Accuracy: 51014/60000 (85.02%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.4653,                   Accuracy: 50849/60000 (84.75%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4769,                   Accuracy: 50559/60000 (84.26%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4578,                   Accuracy: 51020/60000 (85.03%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.4325,                   Accuracy: 51557/60000 (85.93%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.4211,                   Accuracy: 51943/60000 (86.57%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.4014,                   Accuracy: 52502/60000 (87.50%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3777,                   Accuracy: 52883/60000 (88.14%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3623,                   Accuracy: 53337/60000 (88.89%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3439,                   Accuracy: 53581/60000 (89.30%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3306,                   Accuracy: 53880/60000 (89.80%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3205,                   Accuracy: 54085/60000 (90.14%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3086,                   Accuracy: 54364/60000 (90.61%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2953,                   Accuracy: 54618/60000 (91.03%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2945,                   Accuracy: 54687/60000 (91.14%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2971,                   Accuracy: 54641/60000 (91.07%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2975,                   Accuracy: 54630/60000 (91.05%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3212,                   Accuracy: 54223/60000 (90.37%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3181,                   Accuracy: 54338/60000 (90.56%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3186,                   Accuracy: 54388/60000 (90.65%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3177,                   Accuracy: 54439/60000 (90.73%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3003,                   Accuracy: 54802/60000 (91.34%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2923,                   Accuracy: 54839/60000 (91.40%)
{0: tensor(91.5867), 10: tensor(91.2033), 20: tensor(91.0917), 30: tensor(90.7067), 40: tensor(90.9333), 50: tensor(90.8750), 60: tensor(90.8050), 70: tensor(90.2750), 80: tensor(89.7050), 90: tensor(89.0250), 100: tensor(87.6717), 110: tensor(87.0117), 120: tensor(85.4800), 130: tensor(85.0233), 140: tensor(84.7483), 150: tensor(84.2650), 160: tensor(85.0333), 170: tensor(85.9283), 180: tensor(86.5717), 190: tensor(87.5033), 200: tensor(88.1383), 210: tensor(88.8950), 220: tensor(89.3017), 230: tensor(89.8000), 240: tensor(90.1417), 250: tensor(90.6067), 260: tensor(91.0300), 270: tensor(91.1450), 280: tensor(91.0683), 290: tensor(91.0500), 300: tensor(90.3717), 310: tensor(90.5633), 320: tensor(90.6467), 330: tensor(90.7317), 340: tensor(91.3367), 350: tensor(91.3983)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=32, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.8085,                   Accuracy: 304/2000.0 (15.20%)



-= Testing valid =-
Test set: Average loss: 1.7534,                   Accuracy: 703/2000.0 (35.15%)



-= Testing valid =-
Test set: Average loss: 1.7748,                   Accuracy: 688/2000.0 (34.40%)



-= Testing valid =-
Test set: Average loss: 1.5821,                   Accuracy: 845/2000.0 (42.25%)



-= Testing valid =-
Test set: Average loss: 1.2145,                   Accuracy: 1120/2000.0 (56.00%)



-= Testing valid =-
Test set: Average loss: 1.4476,                   Accuracy: 889/2000.0 (44.45%)



-= Testing valid =-
Test set: Average loss: 1.1765,                   Accuracy: 1156/2000.0 (57.80%)



-= Testing valid =-
Test set: Average loss: 1.7960,                   Accuracy: 793/2000.0 (39.65%)



-= Testing valid =-
Test set: Average loss: 0.9751,                   Accuracy: 1337/2000.0 (66.85%)



-= Testing valid =-
Test set: Average loss: 0.8668,                   Accuracy: 1385/2000.0 (69.25%)



Epoch 10 train accuracy: 69.12%, valid accuracy 69.25%
-= Testing valid =-
Test set: Average loss: 1.2119,                   Accuracy: 1149/2000.0 (57.45%)



-= Testing valid =-
Test set: Average loss: 1.0887,                   Accuracy: 1159/2000.0 (57.95%)



-= Testing valid =-
Test set: Average loss: 1.1430,                   Accuracy: 1141/2000.0 (57.05%)



-= Testing valid =-
Test set: Average loss: 0.7573,                   Accuracy: 1399/2000.0 (69.95%)



-= Testing valid =-
Test set: Average loss: 0.7122,                   Accuracy: 1421/2000.0 (71.05%)



-= Testing valid =-
Test set: Average loss: 0.7986,                   Accuracy: 1382/2000.0 (69.10%)



-= Testing valid =-
Test set: Average loss: 0.8222,                   Accuracy: 1409/2000.0 (70.45%)



-= Testing valid =-
Test set: Average loss: 0.4939,                   Accuracy: 1684/2000.0 (84.20%)



-= Testing valid =-
Test set: Average loss: 0.5053,                   Accuracy: 1679/2000.0 (83.95%)



-= Testing valid =-
Test set: Average loss: 0.5016,                   Accuracy: 1673/2000.0 (83.65%)



Epoch 20 train accuracy: 85.89%, valid accuracy 83.65%
-= Testing valid =-
Test set: Average loss: 0.4307,                   Accuracy: 1732/2000.0 (86.60%)



-= Testing valid =-
Test set: Average loss: 0.3502,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.5167,                   Accuracy: 1683/2000.0 (84.15%)



-= Testing valid =-
Test set: Average loss: 0.4188,                   Accuracy: 1739/2000.0 (86.95%)



-= Testing valid =-
Test set: Average loss: 0.3968,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.5038,                   Accuracy: 1631/2000.0 (81.55%)



-= Testing valid =-
Test set: Average loss: 0.4378,                   Accuracy: 1720/2000.0 (86.00%)



-= Testing valid =-
Test set: Average loss: 0.3351,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.3772,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.5042,                   Accuracy: 1667/2000.0 (83.35%)



Epoch 30 train accuracy: 88.49%, valid accuracy 83.35%
-= Testing valid =-
Test set: Average loss: 0.3853,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.2995,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.4048,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.3611,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.3171,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.3677,                   Accuracy: 1759/2000.0 (87.95%)



-= Testing valid =-
Test set: Average loss: 0.3900,                   Accuracy: 1744/2000.0 (87.20%)



-= Testing valid =-
Test set: Average loss: 0.3557,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.3256,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.3447,                   Accuracy: 1776/2000.0 (88.80%)



Epoch 40 train accuracy: 90.04%, valid accuracy 88.80%
-= Testing valid =-
Test set: Average loss: 0.3386,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.2933,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.3415,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.3016,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.3107,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.3254,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.3307,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.3214,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2967,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.3249,                   Accuracy: 1801/2000.0 (90.05%)



Epoch 50 train accuracy: 90.60%, valid accuracy 90.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3657,                   Accuracy: 53364/60000 (88.94%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3681,                   Accuracy: 53337/60000 (88.89%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3681,                   Accuracy: 53384/60000 (88.97%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3693,                   Accuracy: 53447/60000 (89.08%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3588,                   Accuracy: 53515/60000 (89.19%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3471,                   Accuracy: 53864/60000 (89.77%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3390,                   Accuracy: 54034/60000 (90.06%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3355,                   Accuracy: 54078/60000 (90.13%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3334,                   Accuracy: 54008/60000 (90.01%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3502,                   Accuracy: 53856/60000 (89.76%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3733,                   Accuracy: 53464/60000 (89.11%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.4040,                   Accuracy: 52815/60000 (88.03%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4210,                   Accuracy: 52481/60000 (87.47%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4093,                   Accuracy: 52669/60000 (87.78%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3943,                   Accuracy: 53021/60000 (88.37%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3775,                   Accuracy: 53377/60000 (88.96%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3547,                   Accuracy: 53893/60000 (89.82%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3354,                   Accuracy: 54099/60000 (90.17%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3231,                   Accuracy: 54401/60000 (90.67%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3450,                   Accuracy: 53989/60000 (89.98%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3625,                   Accuracy: 53650/60000 (89.42%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3878,                   Accuracy: 53063/60000 (88.44%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3896,                   Accuracy: 52870/60000 (88.12%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3898,                   Accuracy: 52885/60000 (88.14%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3898,                   Accuracy: 52749/60000 (87.92%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3752,                   Accuracy: 53065/60000 (88.44%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3640,                   Accuracy: 53229/60000 (88.71%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3844,                   Accuracy: 52870/60000 (88.12%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4059,                   Accuracy: 52648/60000 (87.75%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.4321,                   Accuracy: 52175/60000 (86.96%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.4497,                   Accuracy: 51828/60000 (86.38%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.4494,                   Accuracy: 51696/60000 (86.16%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.4382,                   Accuracy: 52032/60000 (86.72%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4307,                   Accuracy: 52112/60000 (86.85%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.4131,                   Accuracy: 52432/60000 (87.39%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3780,                   Accuracy: 53059/60000 (88.43%)
{0: tensor(88.9400), 10: tensor(88.8950), 20: tensor(88.9733), 30: tensor(89.0783), 40: tensor(89.1917), 50: tensor(89.7733), 60: tensor(90.0567), 70: tensor(90.1300), 80: tensor(90.0133), 90: tensor(89.7600), 100: tensor(89.1067), 110: tensor(88.0250), 120: tensor(87.4683), 130: tensor(87.7817), 140: tensor(88.3683), 150: tensor(88.9617), 160: tensor(89.8217), 170: tensor(90.1650), 180: tensor(90.6683), 190: tensor(89.9817), 200: tensor(89.4167), 210: tensor(88.4383), 220: tensor(88.1167), 230: tensor(88.1417), 240: tensor(87.9150), 250: tensor(88.4417), 260: tensor(88.7150), 270: tensor(88.1167), 280: tensor(87.7467), 290: tensor(86.9583), 300: tensor(86.3800), 310: tensor(86.1600), 320: tensor(86.7200), 330: tensor(86.8533), 340: tensor(87.3867), 350: tensor(88.4317)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=33, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 14.3822,                   Accuracy: 225/2000.0 (11.25%)



-= Testing valid =-
Test set: Average loss: 1.7530,                   Accuracy: 690/2000.0 (34.50%)



-= Testing valid =-
Test set: Average loss: 1.6650,                   Accuracy: 735/2000.0 (36.75%)



-= Testing valid =-
Test set: Average loss: 1.4365,                   Accuracy: 930/2000.0 (46.50%)



-= Testing valid =-
Test set: Average loss: 1.6433,                   Accuracy: 829/2000.0 (41.45%)



-= Testing valid =-
Test set: Average loss: 1.3541,                   Accuracy: 996/2000.0 (49.80%)



-= Testing valid =-
Test set: Average loss: 1.6585,                   Accuracy: 908/2000.0 (45.40%)



-= Testing valid =-
Test set: Average loss: 1.1399,                   Accuracy: 1212/2000.0 (60.60%)



-= Testing valid =-
Test set: Average loss: 1.0719,                   Accuracy: 1255/2000.0 (62.75%)



-= Testing valid =-
Test set: Average loss: 0.7760,                   Accuracy: 1474/2000.0 (73.70%)



Epoch 10 train accuracy: 69.96%, valid accuracy 73.70%
-= Testing valid =-
Test set: Average loss: 0.8196,                   Accuracy: 1475/2000.0 (73.75%)



-= Testing valid =-
Test set: Average loss: 0.6849,                   Accuracy: 1597/2000.0 (79.85%)



-= Testing valid =-
Test set: Average loss: 0.7258,                   Accuracy: 1547/2000.0 (77.35%)



-= Testing valid =-
Test set: Average loss: 0.7806,                   Accuracy: 1455/2000.0 (72.75%)



-= Testing valid =-
Test set: Average loss: 1.4711,                   Accuracy: 1067/2000.0 (53.35%)



-= Testing valid =-
Test set: Average loss: 0.7756,                   Accuracy: 1461/2000.0 (73.05%)



-= Testing valid =-
Test set: Average loss: 0.7339,                   Accuracy: 1472/2000.0 (73.60%)



-= Testing valid =-
Test set: Average loss: 0.5281,                   Accuracy: 1642/2000.0 (82.10%)



-= Testing valid =-
Test set: Average loss: 0.5635,                   Accuracy: 1643/2000.0 (82.15%)



-= Testing valid =-
Test set: Average loss: 0.4940,                   Accuracy: 1629/2000.0 (81.45%)



Epoch 20 train accuracy: 85.21%, valid accuracy 81.45%
-= Testing valid =-
Test set: Average loss: 0.3687,                   Accuracy: 1764/2000.0 (88.20%)



-= Testing valid =-
Test set: Average loss: 0.3818,                   Accuracy: 1752/2000.0 (87.60%)



-= Testing valid =-
Test set: Average loss: 0.4019,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.3389,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.3549,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.3437,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.3091,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.2889,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.3466,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.3560,                   Accuracy: 1769/2000.0 (88.45%)



Epoch 30 train accuracy: 87.71%, valid accuracy 88.45%
-= Testing valid =-
Test set: Average loss: 0.2941,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.2851,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2960,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.3280,                   Accuracy: 1777/2000.0 (88.85%)



-= Testing valid =-
Test set: Average loss: 0.4513,                   Accuracy: 1669/2000.0 (83.45%)



-= Testing valid =-
Test set: Average loss: 0.2932,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.2602,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2739,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2641,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.3617,                   Accuracy: 1750/2000.0 (87.50%)



Epoch 40 train accuracy: 89.54%, valid accuracy 87.50%
-= Testing valid =-
Test set: Average loss: 0.2699,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2682,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2636,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2450,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2687,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2548,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2630,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2916,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2568,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2509,                   Accuracy: 1837/2000.0 (91.85%)



Epoch 50 train accuracy: 90.14%, valid accuracy 91.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3097,                   Accuracy: 54174/60000 (90.29%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3158,                   Accuracy: 54065/60000 (90.11%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3025,                   Accuracy: 54343/60000 (90.57%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3060,                   Accuracy: 54312/60000 (90.52%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3070,                   Accuracy: 54344/60000 (90.57%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3060,                   Accuracy: 54346/60000 (90.58%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3067,                   Accuracy: 54406/60000 (90.68%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3039,                   Accuracy: 54360/60000 (90.60%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2805,                   Accuracy: 54797/60000 (91.33%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2745,                   Accuracy: 55030/60000 (91.72%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2723,                   Accuracy: 55086/60000 (91.81%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2806,                   Accuracy: 54965/60000 (91.61%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.2845,                   Accuracy: 54916/60000 (91.53%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.2886,                   Accuracy: 54862/60000 (91.44%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.2926,                   Accuracy: 54761/60000 (91.27%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3004,                   Accuracy: 54599/60000 (91.00%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3026,                   Accuracy: 54525/60000 (90.88%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.2968,                   Accuracy: 54510/60000 (90.85%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.2976,                   Accuracy: 54508/60000 (90.85%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.2996,                   Accuracy: 54438/60000 (90.73%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3075,                   Accuracy: 54310/60000 (90.52%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3073,                   Accuracy: 54272/60000 (90.45%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3118,                   Accuracy: 54142/60000 (90.24%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3121,                   Accuracy: 54125/60000 (90.21%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3164,                   Accuracy: 54054/60000 (90.09%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3150,                   Accuracy: 54112/60000 (90.19%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3060,                   Accuracy: 54247/60000 (90.41%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3201,                   Accuracy: 53984/60000 (89.97%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3249,                   Accuracy: 53771/60000 (89.62%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3388,                   Accuracy: 53517/60000 (89.19%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3466,                   Accuracy: 53316/60000 (88.86%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3490,                   Accuracy: 53220/60000 (88.70%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3439,                   Accuracy: 53348/60000 (88.91%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3388,                   Accuracy: 53485/60000 (89.14%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3308,                   Accuracy: 53664/60000 (89.44%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3112,                   Accuracy: 54022/60000 (90.04%)
{0: tensor(90.2900), 10: tensor(90.1083), 20: tensor(90.5717), 30: tensor(90.5200), 40: tensor(90.5733), 50: tensor(90.5767), 60: tensor(90.6767), 70: tensor(90.6000), 80: tensor(91.3283), 90: tensor(91.7167), 100: tensor(91.8100), 110: tensor(91.6083), 120: tensor(91.5267), 130: tensor(91.4367), 140: tensor(91.2683), 150: tensor(90.9983), 160: tensor(90.8750), 170: tensor(90.8500), 180: tensor(90.8467), 190: tensor(90.7300), 200: tensor(90.5167), 210: tensor(90.4533), 220: tensor(90.2367), 230: tensor(90.2083), 240: tensor(90.0900), 250: tensor(90.1867), 260: tensor(90.4117), 270: tensor(89.9733), 280: tensor(89.6183), 290: tensor(89.1950), 300: tensor(88.8600), 310: tensor(88.7000), 320: tensor(88.9133), 330: tensor(89.1417), 340: tensor(89.4400), 350: tensor(90.0367)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=34, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5987,                   Accuracy: 399/2000.0 (19.95%)



-= Testing valid =-
Test set: Average loss: 3.3332,                   Accuracy: 320/2000.0 (16.00%)



-= Testing valid =-
Test set: Average loss: 2.2955,                   Accuracy: 523/2000.0 (26.15%)



-= Testing valid =-
Test set: Average loss: 1.6960,                   Accuracy: 737/2000.0 (36.85%)



-= Testing valid =-
Test set: Average loss: 1.3290,                   Accuracy: 1042/2000.0 (52.10%)



-= Testing valid =-
Test set: Average loss: 3.2063,                   Accuracy: 320/2000.0 (16.00%)



-= Testing valid =-
Test set: Average loss: 1.5774,                   Accuracy: 896/2000.0 (44.80%)



-= Testing valid =-
Test set: Average loss: 1.2099,                   Accuracy: 1097/2000.0 (54.85%)



-= Testing valid =-
Test set: Average loss: 0.9924,                   Accuracy: 1336/2000.0 (66.80%)



-= Testing valid =-
Test set: Average loss: 1.4654,                   Accuracy: 974/2000.0 (48.70%)



Epoch 10 train accuracy: 66.70%, valid accuracy 48.70%
-= Testing valid =-
Test set: Average loss: 1.1358,                   Accuracy: 1180/2000.0 (59.00%)



-= Testing valid =-
Test set: Average loss: 1.2974,                   Accuracy: 1054/2000.0 (52.70%)



-= Testing valid =-
Test set: Average loss: 0.8587,                   Accuracy: 1415/2000.0 (70.75%)



-= Testing valid =-
Test set: Average loss: 1.1315,                   Accuracy: 1181/2000.0 (59.05%)



-= Testing valid =-
Test set: Average loss: 0.8592,                   Accuracy: 1384/2000.0 (69.20%)



-= Testing valid =-
Test set: Average loss: 0.6778,                   Accuracy: 1557/2000.0 (77.85%)



-= Testing valid =-
Test set: Average loss: 1.1975,                   Accuracy: 1094/2000.0 (54.70%)



-= Testing valid =-
Test set: Average loss: 0.5646,                   Accuracy: 1605/2000.0 (80.25%)



-= Testing valid =-
Test set: Average loss: 0.5448,                   Accuracy: 1625/2000.0 (81.25%)



-= Testing valid =-
Test set: Average loss: 0.6730,                   Accuracy: 1449/2000.0 (72.45%)



Epoch 20 train accuracy: 84.88%, valid accuracy 72.45%
-= Testing valid =-
Test set: Average loss: 0.5364,                   Accuracy: 1616/2000.0 (80.80%)



-= Testing valid =-
Test set: Average loss: 0.3339,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.3398,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.3855,                   Accuracy: 1735/2000.0 (86.75%)



-= Testing valid =-
Test set: Average loss: 0.3967,                   Accuracy: 1730/2000.0 (86.50%)



-= Testing valid =-
Test set: Average loss: 0.3333,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.4328,                   Accuracy: 1708/2000.0 (85.40%)



-= Testing valid =-
Test set: Average loss: 0.3860,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.3625,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.3485,                   Accuracy: 1760/2000.0 (88.00%)



Epoch 30 train accuracy: 88.45%, valid accuracy 88.00%
-= Testing valid =-
Test set: Average loss: 0.2786,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.3054,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.3074,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.2612,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.3304,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.2513,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2917,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.2560,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2389,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.2667,                   Accuracy: 1833/2000.0 (91.65%)



Epoch 40 train accuracy: 89.64%, valid accuracy 91.65%
-= Testing valid =-
Test set: Average loss: 0.2622,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2642,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2616,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2515,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2556,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2659,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2198,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2654,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.3011,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.2697,                   Accuracy: 1822/2000.0 (91.10%)



Epoch 50 train accuracy: 90.41%, valid accuracy 91.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2516,                   Accuracy: 55523/60000 (92.54%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2718,                   Accuracy: 55139/60000 (91.90%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2782,                   Accuracy: 55099/60000 (91.83%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2905,                   Accuracy: 54909/60000 (91.51%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2955,                   Accuracy: 54832/60000 (91.39%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3027,                   Accuracy: 54807/60000 (91.35%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3088,                   Accuracy: 54642/60000 (91.07%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3128,                   Accuracy: 54629/60000 (91.05%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3073,                   Accuracy: 54555/60000 (90.93%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3091,                   Accuracy: 54579/60000 (90.96%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3146,                   Accuracy: 54387/60000 (90.64%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3152,                   Accuracy: 54430/60000 (90.72%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3196,                   Accuracy: 54344/60000 (90.57%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3183,                   Accuracy: 54313/60000 (90.52%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3239,                   Accuracy: 54205/60000 (90.34%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3200,                   Accuracy: 54182/60000 (90.30%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3193,                   Accuracy: 54047/60000 (90.08%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3243,                   Accuracy: 53783/60000 (89.64%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3139,                   Accuracy: 54018/60000 (90.03%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3458,                   Accuracy: 53407/60000 (89.01%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3603,                   Accuracy: 53237/60000 (88.73%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3700,                   Accuracy: 53099/60000 (88.50%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3711,                   Accuracy: 53046/60000 (88.41%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3700,                   Accuracy: 53070/60000 (88.45%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3639,                   Accuracy: 53289/60000 (88.82%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3559,                   Accuracy: 53337/60000 (88.89%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3316,                   Accuracy: 53798/60000 (89.66%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3178,                   Accuracy: 54010/60000 (90.02%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3145,                   Accuracy: 54102/60000 (90.17%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3147,                   Accuracy: 54184/60000 (90.31%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3091,                   Accuracy: 54344/60000 (90.57%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3029,                   Accuracy: 54399/60000 (90.67%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2923,                   Accuracy: 54664/60000 (91.11%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2809,                   Accuracy: 54910/60000 (91.52%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2753,                   Accuracy: 55086/60000 (91.81%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2567,                   Accuracy: 55388/60000 (92.31%)
{0: tensor(92.5383), 10: tensor(91.8983), 20: tensor(91.8317), 30: tensor(91.5150), 40: tensor(91.3867), 50: tensor(91.3450), 60: tensor(91.0700), 70: tensor(91.0483), 80: tensor(90.9250), 90: tensor(90.9650), 100: tensor(90.6450), 110: tensor(90.7167), 120: tensor(90.5733), 130: tensor(90.5217), 140: tensor(90.3417), 150: tensor(90.3033), 160: tensor(90.0783), 170: tensor(89.6383), 180: tensor(90.0300), 190: tensor(89.0117), 200: tensor(88.7283), 210: tensor(88.4983), 220: tensor(88.4100), 230: tensor(88.4500), 240: tensor(88.8150), 250: tensor(88.8950), 260: tensor(89.6633), 270: tensor(90.0167), 280: tensor(90.1700), 290: tensor(90.3067), 300: tensor(90.5733), 310: tensor(90.6650), 320: tensor(91.1067), 330: tensor(91.5167), 340: tensor(91.8100), 350: tensor(92.3133)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=35, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 8.2828,                   Accuracy: 206/2000.0 (10.30%)



-= Testing valid =-
Test set: Average loss: 2.9695,                   Accuracy: 355/2000.0 (17.75%)



-= Testing valid =-
Test set: Average loss: 1.9251,                   Accuracy: 651/2000.0 (32.55%)



-= Testing valid =-
Test set: Average loss: 1.6308,                   Accuracy: 774/2000.0 (38.70%)



-= Testing valid =-
Test set: Average loss: 1.4472,                   Accuracy: 968/2000.0 (48.40%)



-= Testing valid =-
Test set: Average loss: 1.5575,                   Accuracy: 889/2000.0 (44.45%)



-= Testing valid =-
Test set: Average loss: 1.5450,                   Accuracy: 840/2000.0 (42.00%)



-= Testing valid =-
Test set: Average loss: 0.8823,                   Accuracy: 1426/2000.0 (71.30%)



-= Testing valid =-
Test set: Average loss: 0.8294,                   Accuracy: 1423/2000.0 (71.15%)



-= Testing valid =-
Test set: Average loss: 0.8758,                   Accuracy: 1409/2000.0 (70.45%)



Epoch 10 train accuracy: 71.93%, valid accuracy 70.45%
-= Testing valid =-
Test set: Average loss: 1.2778,                   Accuracy: 1113/2000.0 (55.65%)



-= Testing valid =-
Test set: Average loss: 0.9245,                   Accuracy: 1325/2000.0 (66.25%)



-= Testing valid =-
Test set: Average loss: 0.5969,                   Accuracy: 1631/2000.0 (81.55%)



-= Testing valid =-
Test set: Average loss: 0.5326,                   Accuracy: 1604/2000.0 (80.20%)



-= Testing valid =-
Test set: Average loss: 0.5851,                   Accuracy: 1632/2000.0 (81.60%)



-= Testing valid =-
Test set: Average loss: 0.4796,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.7878,                   Accuracy: 1416/2000.0 (70.80%)



-= Testing valid =-
Test set: Average loss: 0.6629,                   Accuracy: 1573/2000.0 (78.65%)



-= Testing valid =-
Test set: Average loss: 0.4418,                   Accuracy: 1726/2000.0 (86.30%)



-= Testing valid =-
Test set: Average loss: 0.3600,                   Accuracy: 1798/2000.0 (89.90%)



Epoch 20 train accuracy: 87.01%, valid accuracy 89.90%
-= Testing valid =-
Test set: Average loss: 0.2981,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.3580,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.3609,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.3697,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.4600,                   Accuracy: 1714/2000.0 (85.70%)



-= Testing valid =-
Test set: Average loss: 0.3417,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.3172,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.3455,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.3048,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.3336,                   Accuracy: 1818/2000.0 (90.90%)



Epoch 30 train accuracy: 89.04%, valid accuracy 90.90%
-= Testing valid =-
Test set: Average loss: 0.2781,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.3023,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.3122,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.3263,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.3074,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.4078,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.3610,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.2958,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2990,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2907,                   Accuracy: 1839/2000.0 (91.95%)



Epoch 40 train accuracy: 90.66%, valid accuracy 91.95%
-= Testing valid =-
Test set: Average loss: 0.2771,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.3204,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2717,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2640,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2865,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2996,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2906,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.3262,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.2996,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2704,                   Accuracy: 1847/2000.0 (92.35%)



Epoch 50 train accuracy: 91.22%, valid accuracy 92.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2989,                   Accuracy: 54774/60000 (91.29%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2876,                   Accuracy: 54885/60000 (91.47%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3058,                   Accuracy: 54585/60000 (90.97%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3157,                   Accuracy: 54333/60000 (90.56%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3206,                   Accuracy: 54156/60000 (90.26%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3195,                   Accuracy: 54160/60000 (90.27%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3190,                   Accuracy: 54107/60000 (90.18%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3122,                   Accuracy: 54211/60000 (90.35%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2890,                   Accuracy: 54581/60000 (90.97%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2891,                   Accuracy: 54656/60000 (91.09%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2960,                   Accuracy: 54470/60000 (90.78%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3309,                   Accuracy: 53861/60000 (89.77%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3543,                   Accuracy: 53408/60000 (89.01%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3621,                   Accuracy: 53252/60000 (88.75%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3645,                   Accuracy: 53182/60000 (88.64%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3638,                   Accuracy: 53272/60000 (88.79%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3538,                   Accuracy: 53349/60000 (88.92%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3354,                   Accuracy: 53684/60000 (89.47%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3432,                   Accuracy: 53625/60000 (89.38%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3503,                   Accuracy: 53418/60000 (89.03%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3667,                   Accuracy: 53110/60000 (88.52%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3862,                   Accuracy: 52795/60000 (87.99%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3827,                   Accuracy: 52891/60000 (88.15%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3818,                   Accuracy: 52923/60000 (88.21%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3747,                   Accuracy: 53083/60000 (88.47%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3484,                   Accuracy: 53641/60000 (89.40%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3295,                   Accuracy: 53849/60000 (89.75%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3306,                   Accuracy: 53879/60000 (89.80%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3205,                   Accuracy: 54081/60000 (90.14%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3278,                   Accuracy: 54086/60000 (90.14%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3589,                   Accuracy: 53510/60000 (89.18%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3668,                   Accuracy: 53327/60000 (88.88%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3724,                   Accuracy: 53182/60000 (88.64%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3690,                   Accuracy: 53323/60000 (88.87%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3430,                   Accuracy: 53793/60000 (89.65%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3108,                   Accuracy: 54449/60000 (90.75%)
{0: tensor(91.2900), 10: tensor(91.4750), 20: tensor(90.9750), 30: tensor(90.5550), 40: tensor(90.2600), 50: tensor(90.2667), 60: tensor(90.1783), 70: tensor(90.3517), 80: tensor(90.9683), 90: tensor(91.0933), 100: tensor(90.7833), 110: tensor(89.7683), 120: tensor(89.0133), 130: tensor(88.7533), 140: tensor(88.6367), 150: tensor(88.7867), 160: tensor(88.9150), 170: tensor(89.4733), 180: tensor(89.3750), 190: tensor(89.0300), 200: tensor(88.5167), 210: tensor(87.9917), 220: tensor(88.1517), 230: tensor(88.2050), 240: tensor(88.4717), 250: tensor(89.4017), 260: tensor(89.7483), 270: tensor(89.7983), 280: tensor(90.1350), 290: tensor(90.1433), 300: tensor(89.1833), 310: tensor(88.8783), 320: tensor(88.6367), 330: tensor(88.8717), 340: tensor(89.6550), 350: tensor(90.7483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=36, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.1788,                   Accuracy: 236/2000.0 (11.80%)



-= Testing valid =-
Test set: Average loss: 2.2559,                   Accuracy: 534/2000.0 (26.70%)



-= Testing valid =-
Test set: Average loss: 2.6054,                   Accuracy: 537/2000.0 (26.85%)



-= Testing valid =-
Test set: Average loss: 1.3489,                   Accuracy: 1059/2000.0 (52.95%)



-= Testing valid =-
Test set: Average loss: 1.0152,                   Accuracy: 1296/2000.0 (64.80%)



-= Testing valid =-
Test set: Average loss: 1.0566,                   Accuracy: 1255/2000.0 (62.75%)



-= Testing valid =-
Test set: Average loss: 1.2645,                   Accuracy: 1103/2000.0 (55.15%)



-= Testing valid =-
Test set: Average loss: 1.0202,                   Accuracy: 1278/2000.0 (63.90%)



-= Testing valid =-
Test set: Average loss: 0.9218,                   Accuracy: 1349/2000.0 (67.45%)



-= Testing valid =-
Test set: Average loss: 1.4159,                   Accuracy: 1059/2000.0 (52.95%)



Epoch 10 train accuracy: 72.79%, valid accuracy 52.95%
-= Testing valid =-
Test set: Average loss: 0.8377,                   Accuracy: 1413/2000.0 (70.65%)



-= Testing valid =-
Test set: Average loss: 1.1776,                   Accuracy: 1204/2000.0 (60.20%)



-= Testing valid =-
Test set: Average loss: 0.9265,                   Accuracy: 1304/2000.0 (65.20%)



-= Testing valid =-
Test set: Average loss: 0.5813,                   Accuracy: 1602/2000.0 (80.10%)



-= Testing valid =-
Test set: Average loss: 0.5615,                   Accuracy: 1591/2000.0 (79.55%)



-= Testing valid =-
Test set: Average loss: 0.7279,                   Accuracy: 1485/2000.0 (74.25%)



-= Testing valid =-
Test set: Average loss: 0.7246,                   Accuracy: 1510/2000.0 (75.50%)



-= Testing valid =-
Test set: Average loss: 0.4573,                   Accuracy: 1715/2000.0 (85.75%)



-= Testing valid =-
Test set: Average loss: 0.4229,                   Accuracy: 1744/2000.0 (87.20%)



-= Testing valid =-
Test set: Average loss: 0.6279,                   Accuracy: 1566/2000.0 (78.30%)



Epoch 20 train accuracy: 86.96%, valid accuracy 78.30%
-= Testing valid =-
Test set: Average loss: 0.5246,                   Accuracy: 1648/2000.0 (82.40%)



-= Testing valid =-
Test set: Average loss: 0.5570,                   Accuracy: 1618/2000.0 (80.90%)



-= Testing valid =-
Test set: Average loss: 0.4253,                   Accuracy: 1745/2000.0 (87.25%)



-= Testing valid =-
Test set: Average loss: 0.4462,                   Accuracy: 1714/2000.0 (85.70%)



-= Testing valid =-
Test set: Average loss: 0.4877,                   Accuracy: 1687/2000.0 (84.35%)



-= Testing valid =-
Test set: Average loss: 0.5695,                   Accuracy: 1619/2000.0 (80.95%)



-= Testing valid =-
Test set: Average loss: 0.3564,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.3357,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.3988,                   Accuracy: 1764/2000.0 (88.20%)



-= Testing valid =-
Test set: Average loss: 0.2466,                   Accuracy: 1866/2000.0 (93.30%)



Epoch 30 train accuracy: 88.75%, valid accuracy 93.30%
-= Testing valid =-
Test set: Average loss: 0.4048,                   Accuracy: 1755/2000.0 (87.75%)



-= Testing valid =-
Test set: Average loss: 0.3768,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.3503,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.3579,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3019,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.3526,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.2913,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2445,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.3419,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.2702,                   Accuracy: 1842/2000.0 (92.10%)



Epoch 40 train accuracy: 89.97%, valid accuracy 92.10%
-= Testing valid =-
Test set: Average loss: 0.2449,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2628,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2867,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2536,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2848,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2348,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2894,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2701,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2502,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2600,                   Accuracy: 1848/2000.0 (92.40%)



Epoch 50 train accuracy: 90.62%, valid accuracy 92.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3293,                   Accuracy: 54221/60000 (90.37%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3340,                   Accuracy: 54123/60000 (90.21%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3384,                   Accuracy: 54076/60000 (90.13%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3456,                   Accuracy: 53794/60000 (89.66%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3489,                   Accuracy: 53602/60000 (89.34%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3641,                   Accuracy: 53165/60000 (88.61%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3801,                   Accuracy: 52733/60000 (87.89%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3934,                   Accuracy: 52329/60000 (87.21%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4039,                   Accuracy: 52134/60000 (86.89%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4146,                   Accuracy: 51761/60000 (86.27%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.4477,                   Accuracy: 51081/60000 (85.14%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.4808,                   Accuracy: 50182/60000 (83.64%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5082,                   Accuracy: 49510/60000 (82.52%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.5392,                   Accuracy: 48862/60000 (81.44%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.5535,                   Accuracy: 48529/60000 (80.88%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5544,                   Accuracy: 48519/60000 (80.86%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.5403,                   Accuracy: 48839/60000 (81.40%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.5120,                   Accuracy: 49596/60000 (82.66%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.5011,                   Accuracy: 49809/60000 (83.01%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.4731,                   Accuracy: 50535/60000 (84.22%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.4579,                   Accuracy: 50799/60000 (84.67%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4467,                   Accuracy: 51021/60000 (85.04%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4156,                   Accuracy: 51828/60000 (86.38%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3878,                   Accuracy: 52600/60000 (87.67%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3594,                   Accuracy: 53343/60000 (88.90%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3287,                   Accuracy: 54008/60000 (90.01%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3042,                   Accuracy: 54583/60000 (90.97%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2815,                   Accuracy: 55058/60000 (91.76%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2805,                   Accuracy: 55223/60000 (92.04%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2757,                   Accuracy: 55379/60000 (92.30%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2879,                   Accuracy: 55109/60000 (91.85%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2901,                   Accuracy: 55082/60000 (91.80%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2987,                   Accuracy: 54903/60000 (91.50%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3122,                   Accuracy: 54692/60000 (91.15%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3131,                   Accuracy: 54622/60000 (91.04%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3192,                   Accuracy: 54370/60000 (90.62%)
{0: tensor(90.3683), 10: tensor(90.2050), 20: tensor(90.1267), 30: tensor(89.6567), 40: tensor(89.3367), 50: tensor(88.6083), 60: tensor(87.8883), 70: tensor(87.2150), 80: tensor(86.8900), 90: tensor(86.2683), 100: tensor(85.1350), 110: tensor(83.6367), 120: tensor(82.5167), 130: tensor(81.4367), 140: tensor(80.8817), 150: tensor(80.8650), 160: tensor(81.3983), 170: tensor(82.6600), 180: tensor(83.0150), 190: tensor(84.2250), 200: tensor(84.6650), 210: tensor(85.0350), 220: tensor(86.3800), 230: tensor(87.6667), 240: tensor(88.9050), 250: tensor(90.0133), 260: tensor(90.9717), 270: tensor(91.7633), 280: tensor(92.0383), 290: tensor(92.2983), 300: tensor(91.8483), 310: tensor(91.8033), 320: tensor(91.5050), 330: tensor(91.1533), 340: tensor(91.0367), 350: tensor(90.6167)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=37, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5576,                   Accuracy: 430/2000.0 (21.50%)



-= Testing valid =-
Test set: Average loss: 1.6031,                   Accuracy: 819/2000.0 (40.95%)



-= Testing valid =-
Test set: Average loss: 2.7882,                   Accuracy: 510/2000.0 (25.50%)



-= Testing valid =-
Test set: Average loss: 1.6093,                   Accuracy: 903/2000.0 (45.15%)



-= Testing valid =-
Test set: Average loss: 1.7059,                   Accuracy: 918/2000.0 (45.90%)



-= Testing valid =-
Test set: Average loss: 1.0112,                   Accuracy: 1311/2000.0 (65.55%)



-= Testing valid =-
Test set: Average loss: 1.1369,                   Accuracy: 1211/2000.0 (60.55%)



-= Testing valid =-
Test set: Average loss: 0.6504,                   Accuracy: 1623/2000.0 (81.15%)



-= Testing valid =-
Test set: Average loss: 0.6835,                   Accuracy: 1582/2000.0 (79.10%)



-= Testing valid =-
Test set: Average loss: 1.1821,                   Accuracy: 1252/2000.0 (62.60%)



Epoch 10 train accuracy: 77.97%, valid accuracy 62.60%
-= Testing valid =-
Test set: Average loss: 0.6677,                   Accuracy: 1531/2000.0 (76.55%)



-= Testing valid =-
Test set: Average loss: 0.6137,                   Accuracy: 1566/2000.0 (78.30%)



-= Testing valid =-
Test set: Average loss: 0.5864,                   Accuracy: 1653/2000.0 (82.65%)



-= Testing valid =-
Test set: Average loss: 0.3831,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.4481,                   Accuracy: 1735/2000.0 (86.75%)



-= Testing valid =-
Test set: Average loss: 0.5511,                   Accuracy: 1597/2000.0 (79.85%)



-= Testing valid =-
Test set: Average loss: 0.3664,                   Accuracy: 1751/2000.0 (87.55%)



-= Testing valid =-
Test set: Average loss: 0.5954,                   Accuracy: 1608/2000.0 (80.40%)



-= Testing valid =-
Test set: Average loss: 0.4055,                   Accuracy: 1712/2000.0 (85.60%)



-= Testing valid =-
Test set: Average loss: 0.4474,                   Accuracy: 1725/2000.0 (86.25%)



Epoch 20 train accuracy: 86.14%, valid accuracy 86.25%
-= Testing valid =-
Test set: Average loss: 0.3848,                   Accuracy: 1749/2000.0 (87.45%)



-= Testing valid =-
Test set: Average loss: 0.3234,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.3448,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3494,                   Accuracy: 1777/2000.0 (88.85%)



-= Testing valid =-
Test set: Average loss: 0.3863,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 0.3264,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.3306,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.3636,                   Accuracy: 1755/2000.0 (87.75%)



-= Testing valid =-
Test set: Average loss: 0.3760,                   Accuracy: 1760/2000.0 (88.00%)



-= Testing valid =-
Test set: Average loss: 0.3085,                   Accuracy: 1814/2000.0 (90.70%)



Epoch 30 train accuracy: 88.86%, valid accuracy 90.70%
-= Testing valid =-
Test set: Average loss: 0.2863,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.2910,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.3220,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.2845,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.3018,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2645,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2597,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2441,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2769,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.3191,                   Accuracy: 1801/2000.0 (90.05%)



Epoch 40 train accuracy: 89.93%, valid accuracy 90.05%
-= Testing valid =-
Test set: Average loss: 0.2870,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2621,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.2675,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2591,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2626,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2642,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2362,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2577,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2757,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2557,                   Accuracy: 1838/2000.0 (91.90%)



Epoch 50 train accuracy: 90.65%, valid accuracy 91.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2636,                   Accuracy: 55175/60000 (91.96%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2609,                   Accuracy: 55292/60000 (92.15%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2662,                   Accuracy: 55177/60000 (91.96%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2697,                   Accuracy: 55229/60000 (92.05%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2721,                   Accuracy: 55142/60000 (91.90%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2758,                   Accuracy: 55087/60000 (91.81%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2790,                   Accuracy: 55000/60000 (91.67%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2808,                   Accuracy: 55007/60000 (91.68%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2722,                   Accuracy: 55129/60000 (91.88%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2832,                   Accuracy: 54992/60000 (91.65%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2994,                   Accuracy: 54712/60000 (91.19%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3083,                   Accuracy: 54435/60000 (90.72%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3190,                   Accuracy: 54208/60000 (90.35%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3167,                   Accuracy: 54164/60000 (90.27%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3078,                   Accuracy: 54341/60000 (90.57%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3043,                   Accuracy: 54347/60000 (90.58%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2939,                   Accuracy: 54624/60000 (91.04%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.2809,                   Accuracy: 54781/60000 (91.30%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.2895,                   Accuracy: 54626/60000 (91.04%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.2910,                   Accuracy: 54625/60000 (91.04%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3001,                   Accuracy: 54468/60000 (90.78%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3050,                   Accuracy: 54403/60000 (90.67%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3077,                   Accuracy: 54371/60000 (90.62%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3100,                   Accuracy: 54407/60000 (90.68%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3105,                   Accuracy: 54440/60000 (90.73%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3115,                   Accuracy: 54420/60000 (90.70%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3006,                   Accuracy: 54483/60000 (90.81%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3098,                   Accuracy: 54354/60000 (90.59%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3069,                   Accuracy: 54525/60000 (90.88%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3082,                   Accuracy: 54463/60000 (90.77%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3097,                   Accuracy: 54515/60000 (90.86%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3009,                   Accuracy: 54676/60000 (91.13%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2952,                   Accuracy: 54719/60000 (91.20%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2894,                   Accuracy: 54784/60000 (91.31%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2833,                   Accuracy: 54833/60000 (91.39%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2619,                   Accuracy: 55173/60000 (91.96%)
{0: tensor(91.9583), 10: tensor(92.1533), 20: tensor(91.9617), 30: tensor(92.0483), 40: tensor(91.9033), 50: tensor(91.8117), 60: tensor(91.6667), 70: tensor(91.6783), 80: tensor(91.8817), 90: tensor(91.6533), 100: tensor(91.1867), 110: tensor(90.7250), 120: tensor(90.3467), 130: tensor(90.2733), 140: tensor(90.5683), 150: tensor(90.5783), 160: tensor(91.0400), 170: tensor(91.3017), 180: tensor(91.0433), 190: tensor(91.0417), 200: tensor(90.7800), 210: tensor(90.6717), 220: tensor(90.6183), 230: tensor(90.6783), 240: tensor(90.7333), 250: tensor(90.7000), 260: tensor(90.8050), 270: tensor(90.5900), 280: tensor(90.8750), 290: tensor(90.7717), 300: tensor(90.8583), 310: tensor(91.1267), 320: tensor(91.1983), 330: tensor(91.3067), 340: tensor(91.3883), 350: tensor(91.9550)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=38, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7881,                   Accuracy: 735/2000.0 (36.75%)



-= Testing valid =-
Test set: Average loss: 1.9510,                   Accuracy: 592/2000.0 (29.60%)



-= Testing valid =-
Test set: Average loss: 1.4776,                   Accuracy: 922/2000.0 (46.10%)



-= Testing valid =-
Test set: Average loss: 1.2050,                   Accuracy: 1157/2000.0 (57.85%)



-= Testing valid =-
Test set: Average loss: 1.6302,                   Accuracy: 1011/2000.0 (50.55%)



-= Testing valid =-
Test set: Average loss: 0.8283,                   Accuracy: 1486/2000.0 (74.30%)



-= Testing valid =-
Test set: Average loss: 1.1935,                   Accuracy: 1083/2000.0 (54.15%)



-= Testing valid =-
Test set: Average loss: 0.9308,                   Accuracy: 1275/2000.0 (63.75%)



-= Testing valid =-
Test set: Average loss: 0.8944,                   Accuracy: 1440/2000.0 (72.00%)



-= Testing valid =-
Test set: Average loss: 0.7247,                   Accuracy: 1509/2000.0 (75.45%)



Epoch 10 train accuracy: 76.62%, valid accuracy 75.45%
-= Testing valid =-
Test set: Average loss: 0.6066,                   Accuracy: 1566/2000.0 (78.30%)



-= Testing valid =-
Test set: Average loss: 0.8418,                   Accuracy: 1434/2000.0 (71.70%)



-= Testing valid =-
Test set: Average loss: 0.4613,                   Accuracy: 1711/2000.0 (85.55%)



-= Testing valid =-
Test set: Average loss: 0.3947,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.4854,                   Accuracy: 1691/2000.0 (84.55%)



-= Testing valid =-
Test set: Average loss: 0.5125,                   Accuracy: 1634/2000.0 (81.70%)



-= Testing valid =-
Test set: Average loss: 0.5657,                   Accuracy: 1602/2000.0 (80.10%)



-= Testing valid =-
Test set: Average loss: 0.3958,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.2091,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.5622,                   Accuracy: 1587/2000.0 (79.35%)



Epoch 20 train accuracy: 87.15%, valid accuracy 79.35%
-= Testing valid =-
Test set: Average loss: 0.3169,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2867,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.4859,                   Accuracy: 1676/2000.0 (83.80%)



-= Testing valid =-
Test set: Average loss: 0.3630,                   Accuracy: 1755/2000.0 (87.75%)



-= Testing valid =-
Test set: Average loss: 0.3099,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.3733,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.2606,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.4319,                   Accuracy: 1695/2000.0 (84.75%)



-= Testing valid =-
Test set: Average loss: 0.2855,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2278,                   Accuracy: 1857/2000.0 (92.85%)



Epoch 30 train accuracy: 89.56%, valid accuracy 92.85%
-= Testing valid =-
Test set: Average loss: 0.3497,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.2297,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2310,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2400,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2946,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.2492,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2187,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.3453,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.2818,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2592,                   Accuracy: 1833/2000.0 (91.65%)



Epoch 40 train accuracy: 90.28%, valid accuracy 91.65%
-= Testing valid =-
Test set: Average loss: 0.2292,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.2044,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.2106,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.2029,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.2248,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.2117,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.2007,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.2670,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2301,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2390,                   Accuracy: 1844/2000.0 (92.20%)



Epoch 50 train accuracy: 91.00%, valid accuracy 92.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2636,                   Accuracy: 55141/60000 (91.90%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2547,                   Accuracy: 55385/60000 (92.31%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2638,                   Accuracy: 55284/60000 (92.14%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2799,                   Accuracy: 54977/60000 (91.63%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2872,                   Accuracy: 54760/60000 (91.27%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2898,                   Accuracy: 54771/60000 (91.29%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2914,                   Accuracy: 54648/60000 (91.08%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2807,                   Accuracy: 54907/60000 (91.51%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2678,                   Accuracy: 55177/60000 (91.96%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2714,                   Accuracy: 55151/60000 (91.92%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2864,                   Accuracy: 54707/60000 (91.18%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2980,                   Accuracy: 54635/60000 (91.06%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3283,                   Accuracy: 54050/60000 (90.08%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3495,                   Accuracy: 53445/60000 (89.07%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3681,                   Accuracy: 53096/60000 (88.49%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3842,                   Accuracy: 52745/60000 (87.91%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3726,                   Accuracy: 52931/60000 (88.22%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3651,                   Accuracy: 53107/60000 (88.51%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3809,                   Accuracy: 52780/60000 (87.97%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.4018,                   Accuracy: 52262/60000 (87.10%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.4239,                   Accuracy: 51883/60000 (86.47%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4438,                   Accuracy: 51474/60000 (85.79%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4421,                   Accuracy: 51372/60000 (85.62%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4309,                   Accuracy: 51515/60000 (85.86%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4171,                   Accuracy: 51721/60000 (86.20%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3910,                   Accuracy: 52299/60000 (87.17%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3504,                   Accuracy: 53023/60000 (88.37%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3378,                   Accuracy: 53341/60000 (88.90%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3255,                   Accuracy: 53519/60000 (89.20%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3300,                   Accuracy: 53503/60000 (89.17%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3228,                   Accuracy: 53681/60000 (89.47%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3190,                   Accuracy: 53850/60000 (89.75%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3133,                   Accuracy: 53920/60000 (89.87%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3075,                   Accuracy: 54102/60000 (90.17%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2891,                   Accuracy: 54536/60000 (90.89%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2701,                   Accuracy: 54896/60000 (91.49%)
{0: tensor(91.9017), 10: tensor(92.3083), 20: tensor(92.1400), 30: tensor(91.6283), 40: tensor(91.2667), 50: tensor(91.2850), 60: tensor(91.0800), 70: tensor(91.5117), 80: tensor(91.9617), 90: tensor(91.9183), 100: tensor(91.1783), 110: tensor(91.0583), 120: tensor(90.0833), 130: tensor(89.0750), 140: tensor(88.4933), 150: tensor(87.9083), 160: tensor(88.2183), 170: tensor(88.5117), 180: tensor(87.9667), 190: tensor(87.1033), 200: tensor(86.4717), 210: tensor(85.7900), 220: tensor(85.6200), 230: tensor(85.8583), 240: tensor(86.2017), 250: tensor(87.1650), 260: tensor(88.3717), 270: tensor(88.9017), 280: tensor(89.1983), 290: tensor(89.1717), 300: tensor(89.4683), 310: tensor(89.7500), 320: tensor(89.8667), 330: tensor(90.1700), 340: tensor(90.8933), 350: tensor(91.4933)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=39, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5409,                   Accuracy: 272/2000.0 (13.60%)



-= Testing valid =-
Test set: Average loss: 2.3249,                   Accuracy: 407/2000.0 (20.35%)



-= Testing valid =-
Test set: Average loss: 1.6088,                   Accuracy: 790/2000.0 (39.50%)



-= Testing valid =-
Test set: Average loss: 1.3694,                   Accuracy: 1032/2000.0 (51.60%)



-= Testing valid =-
Test set: Average loss: 1.9081,                   Accuracy: 695/2000.0 (34.75%)



-= Testing valid =-
Test set: Average loss: 1.3919,                   Accuracy: 1010/2000.0 (50.50%)



-= Testing valid =-
Test set: Average loss: 1.0174,                   Accuracy: 1335/2000.0 (66.75%)



-= Testing valid =-
Test set: Average loss: 1.0096,                   Accuracy: 1262/2000.0 (63.10%)



-= Testing valid =-
Test set: Average loss: 0.6742,                   Accuracy: 1636/2000.0 (81.80%)



-= Testing valid =-
Test set: Average loss: 0.8465,                   Accuracy: 1428/2000.0 (71.40%)



Epoch 10 train accuracy: 72.22%, valid accuracy 71.40%
-= Testing valid =-
Test set: Average loss: 0.6692,                   Accuracy: 1597/2000.0 (79.85%)



-= Testing valid =-
Test set: Average loss: 0.5998,                   Accuracy: 1656/2000.0 (82.80%)



-= Testing valid =-
Test set: Average loss: 0.5614,                   Accuracy: 1684/2000.0 (84.20%)



-= Testing valid =-
Test set: Average loss: 0.5033,                   Accuracy: 1688/2000.0 (84.40%)



-= Testing valid =-
Test set: Average loss: 0.5105,                   Accuracy: 1713/2000.0 (85.65%)



-= Testing valid =-
Test set: Average loss: 0.5095,                   Accuracy: 1674/2000.0 (83.70%)



-= Testing valid =-
Test set: Average loss: 0.4614,                   Accuracy: 1699/2000.0 (84.95%)



-= Testing valid =-
Test set: Average loss: 0.7033,                   Accuracy: 1464/2000.0 (73.20%)



-= Testing valid =-
Test set: Average loss: 0.4147,                   Accuracy: 1733/2000.0 (86.65%)



-= Testing valid =-
Test set: Average loss: 0.4398,                   Accuracy: 1709/2000.0 (85.45%)



Epoch 20 train accuracy: 86.35%, valid accuracy 85.45%
-= Testing valid =-
Test set: Average loss: 0.3297,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.3611,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.3348,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.3476,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.2486,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.3578,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.2809,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.3243,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.2893,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.3461,                   Accuracy: 1767/2000.0 (88.35%)



Epoch 30 train accuracy: 89.29%, valid accuracy 88.35%
-= Testing valid =-
Test set: Average loss: 0.2719,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2977,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.2820,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.3626,                   Accuracy: 1748/2000.0 (87.40%)



-= Testing valid =-
Test set: Average loss: 0.3038,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.2372,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2250,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2708,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2812,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.3233,                   Accuracy: 1776/2000.0 (88.80%)



Epoch 40 train accuracy: 90.34%, valid accuracy 88.80%
-= Testing valid =-
Test set: Average loss: 0.2785,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2528,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2646,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2847,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2395,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2396,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2873,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2558,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2798,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2822,                   Accuracy: 1806/2000.0 (90.30%)



Epoch 50 train accuracy: 91.11%, valid accuracy 90.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2551,                   Accuracy: 55379/60000 (92.30%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2688,                   Accuracy: 55109/60000 (91.85%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2564,                   Accuracy: 55463/60000 (92.44%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2640,                   Accuracy: 55345/60000 (92.24%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2777,                   Accuracy: 55020/60000 (91.70%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2896,                   Accuracy: 54798/60000 (91.33%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2997,                   Accuracy: 54630/60000 (91.05%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2993,                   Accuracy: 54539/60000 (90.90%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2952,                   Accuracy: 54555/60000 (90.93%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2839,                   Accuracy: 54687/60000 (91.14%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3004,                   Accuracy: 54336/60000 (90.56%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2896,                   Accuracy: 54504/60000 (90.84%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.2923,                   Accuracy: 54449/60000 (90.75%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.2911,                   Accuracy: 54507/60000 (90.85%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3004,                   Accuracy: 54172/60000 (90.29%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3031,                   Accuracy: 54080/60000 (90.13%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3091,                   Accuracy: 53901/60000 (89.83%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3223,                   Accuracy: 53649/60000 (89.42%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3124,                   Accuracy: 53719/60000 (89.53%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3557,                   Accuracy: 52841/60000 (88.07%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3510,                   Accuracy: 52866/60000 (88.11%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3704,                   Accuracy: 52604/60000 (87.67%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3793,                   Accuracy: 52446/60000 (87.41%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3798,                   Accuracy: 52431/60000 (87.39%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3823,                   Accuracy: 52328/60000 (87.21%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3697,                   Accuracy: 52706/60000 (87.84%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3752,                   Accuracy: 52673/60000 (87.79%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3432,                   Accuracy: 53286/60000 (88.81%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3513,                   Accuracy: 53304/60000 (88.84%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3217,                   Accuracy: 53932/60000 (89.89%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3134,                   Accuracy: 54157/60000 (90.26%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3026,                   Accuracy: 54289/60000 (90.48%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2856,                   Accuracy: 54730/60000 (91.22%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2774,                   Accuracy: 54987/60000 (91.64%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2661,                   Accuracy: 55155/60000 (91.93%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2721,                   Accuracy: 54989/60000 (91.65%)
{0: tensor(92.2983), 10: tensor(91.8483), 20: tensor(92.4383), 30: tensor(92.2417), 40: tensor(91.7000), 50: tensor(91.3300), 60: tensor(91.0500), 70: tensor(90.8983), 80: tensor(90.9250), 90: tensor(91.1450), 100: tensor(90.5600), 110: tensor(90.8400), 120: tensor(90.7483), 130: tensor(90.8450), 140: tensor(90.2867), 150: tensor(90.1333), 160: tensor(89.8350), 170: tensor(89.4150), 180: tensor(89.5317), 190: tensor(88.0683), 200: tensor(88.1100), 210: tensor(87.6733), 220: tensor(87.4100), 230: tensor(87.3850), 240: tensor(87.2133), 250: tensor(87.8433), 260: tensor(87.7883), 270: tensor(88.8100), 280: tensor(88.8400), 290: tensor(89.8867), 300: tensor(90.2617), 310: tensor(90.4817), 320: tensor(91.2167), 330: tensor(91.6450), 340: tensor(91.9250), 350: tensor(91.6483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=40, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.9531,                   Accuracy: 334/2000.0 (16.70%)



-= Testing valid =-
Test set: Average loss: 2.2157,                   Accuracy: 515/2000.0 (25.75%)



-= Testing valid =-
Test set: Average loss: 3.4574,                   Accuracy: 306/2000.0 (15.30%)



-= Testing valid =-
Test set: Average loss: 1.6296,                   Accuracy: 801/2000.0 (40.05%)



-= Testing valid =-
Test set: Average loss: 1.9095,                   Accuracy: 637/2000.0 (31.85%)



-= Testing valid =-
Test set: Average loss: 1.2167,                   Accuracy: 1184/2000.0 (59.20%)



-= Testing valid =-
Test set: Average loss: 2.2960,                   Accuracy: 647/2000.0 (32.35%)



-= Testing valid =-
Test set: Average loss: 1.1823,                   Accuracy: 1208/2000.0 (60.40%)



-= Testing valid =-
Test set: Average loss: 0.8556,                   Accuracy: 1437/2000.0 (71.85%)



-= Testing valid =-
Test set: Average loss: 0.9704,                   Accuracy: 1333/2000.0 (66.65%)



Epoch 10 train accuracy: 66.45%, valid accuracy 66.65%
-= Testing valid =-
Test set: Average loss: 0.6937,                   Accuracy: 1583/2000.0 (79.15%)



-= Testing valid =-
Test set: Average loss: 0.7817,                   Accuracy: 1491/2000.0 (74.55%)



-= Testing valid =-
Test set: Average loss: 0.6000,                   Accuracy: 1628/2000.0 (81.40%)



-= Testing valid =-
Test set: Average loss: 0.6014,                   Accuracy: 1608/2000.0 (80.40%)



-= Testing valid =-
Test set: Average loss: 0.5524,                   Accuracy: 1656/2000.0 (82.80%)



-= Testing valid =-
Test set: Average loss: 0.5095,                   Accuracy: 1672/2000.0 (83.60%)



-= Testing valid =-
Test set: Average loss: 0.3307,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.5938,                   Accuracy: 1558/2000.0 (77.90%)



-= Testing valid =-
Test set: Average loss: 0.4956,                   Accuracy: 1672/2000.0 (83.60%)



-= Testing valid =-
Test set: Average loss: 0.4193,                   Accuracy: 1739/2000.0 (86.95%)



Epoch 20 train accuracy: 83.74%, valid accuracy 86.95%
-= Testing valid =-
Test set: Average loss: 0.2751,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.3038,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2779,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.3152,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.2492,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2820,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.3099,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2848,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2995,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.3012,                   Accuracy: 1805/2000.0 (90.25%)



Epoch 30 train accuracy: 87.95%, valid accuracy 90.25%
-= Testing valid =-
Test set: Average loss: 0.2924,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2706,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2804,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.3220,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.2562,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.2416,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2766,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2458,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2487,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2898,                   Accuracy: 1816/2000.0 (90.80%)



Epoch 40 train accuracy: 89.40%, valid accuracy 90.80%
-= Testing valid =-
Test set: Average loss: 0.2220,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.2583,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2478,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2430,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2834,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.2664,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2477,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2464,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2225,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.2421,                   Accuracy: 1849/2000.0 (92.45%)



Epoch 50 train accuracy: 89.84%, valid accuracy 92.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2831,                   Accuracy: 54939/60000 (91.57%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2870,                   Accuracy: 54725/60000 (91.21%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2982,                   Accuracy: 54631/60000 (91.05%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3063,                   Accuracy: 54479/60000 (90.80%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3192,                   Accuracy: 54209/60000 (90.35%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3262,                   Accuracy: 53995/60000 (89.99%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3229,                   Accuracy: 53940/60000 (89.90%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3189,                   Accuracy: 53956/60000 (89.93%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3088,                   Accuracy: 54072/60000 (90.12%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3288,                   Accuracy: 53736/60000 (89.56%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3515,                   Accuracy: 53135/60000 (88.56%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3805,                   Accuracy: 52550/60000 (87.58%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3944,                   Accuracy: 52361/60000 (87.27%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4057,                   Accuracy: 52169/60000 (86.95%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.4117,                   Accuracy: 51991/60000 (86.65%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4027,                   Accuracy: 52281/60000 (87.14%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3923,                   Accuracy: 52491/60000 (87.49%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3578,                   Accuracy: 53154/60000 (88.59%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3455,                   Accuracy: 53441/60000 (89.07%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3408,                   Accuracy: 53404/60000 (89.01%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3521,                   Accuracy: 53317/60000 (88.86%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3514,                   Accuracy: 53401/60000 (89.00%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3456,                   Accuracy: 53496/60000 (89.16%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3302,                   Accuracy: 53784/60000 (89.64%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3098,                   Accuracy: 54237/60000 (90.39%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2898,                   Accuracy: 54630/60000 (91.05%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2693,                   Accuracy: 55000/60000 (91.67%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2620,                   Accuracy: 55187/60000 (91.98%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2589,                   Accuracy: 55339/60000 (92.23%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2797,                   Accuracy: 55025/60000 (91.71%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2951,                   Accuracy: 54780/60000 (91.30%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3098,                   Accuracy: 54469/60000 (90.78%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3131,                   Accuracy: 54443/60000 (90.74%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3078,                   Accuracy: 54479/60000 (90.80%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3063,                   Accuracy: 54584/60000 (90.97%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2803,                   Accuracy: 54928/60000 (91.55%)
{0: tensor(91.5650), 10: tensor(91.2083), 20: tensor(91.0517), 30: tensor(90.7983), 40: tensor(90.3483), 50: tensor(89.9917), 60: tensor(89.9000), 70: tensor(89.9267), 80: tensor(90.1200), 90: tensor(89.5600), 100: tensor(88.5583), 110: tensor(87.5833), 120: tensor(87.2683), 130: tensor(86.9483), 140: tensor(86.6517), 150: tensor(87.1350), 160: tensor(87.4850), 170: tensor(88.5900), 180: tensor(89.0683), 190: tensor(89.0067), 200: tensor(88.8617), 210: tensor(89.0017), 220: tensor(89.1600), 230: tensor(89.6400), 240: tensor(90.3950), 250: tensor(91.0500), 260: tensor(91.6667), 270: tensor(91.9783), 280: tensor(92.2317), 290: tensor(91.7083), 300: tensor(91.3000), 310: tensor(90.7817), 320: tensor(90.7383), 330: tensor(90.7983), 340: tensor(90.9733), 350: tensor(91.5467)}
