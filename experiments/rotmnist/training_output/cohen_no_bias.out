Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=1, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4995,                   Accuracy: 255/2000.0 (12.75%)



-= Testing valid =-
Test set: Average loss: 2.0335,                   Accuracy: 468/2000.0 (23.40%)



-= Testing valid =-
Test set: Average loss: 0.5506,                   Accuracy: 1602/2000.0 (80.10%)



-= Testing valid =-
Test set: Average loss: 0.2481,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2271,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.1544,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1562,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.2366,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.1893,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1084,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 10 train accuracy: 96.18%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0926,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 20 train accuracy: 98.20%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0607,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0646,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0650,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0633,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 30 train accuracy: 98.59%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0597,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0601,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0594,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 40 train accuracy: 98.97%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0563,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 50 train accuracy: 99.16%, valid accuracy 98.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0738,                   Accuracy: 58735/60000 (97.89%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1290,                   Accuracy: 57824/60000 (96.37%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2650,                   Accuracy: 55486/60000 (92.48%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6232,                   Accuracy: 49567/60000 (82.61%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9413,                   Accuracy: 44007/60000 (73.35%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9870,                   Accuracy: 42680/60000 (71.13%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6332,                   Accuracy: 48296/60000 (80.49%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2925,                   Accuracy: 54566/60000 (90.94%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1185,                   Accuracy: 57862/60000 (96.44%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0738,                   Accuracy: 58735/60000 (97.89%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1290,                   Accuracy: 57824/60000 (96.37%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2650,                   Accuracy: 55486/60000 (92.48%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6232,                   Accuracy: 49567/60000 (82.61%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9413,                   Accuracy: 44007/60000 (73.35%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9870,                   Accuracy: 42680/60000 (71.13%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6332,                   Accuracy: 48296/60000 (80.49%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2925,                   Accuracy: 54566/60000 (90.94%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1185,                   Accuracy: 57862/60000 (96.44%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0738,                   Accuracy: 58735/60000 (97.89%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1290,                   Accuracy: 57824/60000 (96.37%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2650,                   Accuracy: 55486/60000 (92.48%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6232,                   Accuracy: 49567/60000 (82.61%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9413,                   Accuracy: 44007/60000 (73.35%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9870,                   Accuracy: 42680/60000 (71.13%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6332,                   Accuracy: 48296/60000 (80.49%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2925,                   Accuracy: 54566/60000 (90.94%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1185,                   Accuracy: 57862/60000 (96.44%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0738,                   Accuracy: 58735/60000 (97.89%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1290,                   Accuracy: 57824/60000 (96.37%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2650,                   Accuracy: 55486/60000 (92.48%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6232,                   Accuracy: 49567/60000 (82.61%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9413,                   Accuracy: 44007/60000 (73.35%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9870,                   Accuracy: 42680/60000 (71.13%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6332,                   Accuracy: 48296/60000 (80.49%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2925,                   Accuracy: 54566/60000 (90.94%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1185,                   Accuracy: 57862/60000 (96.44%)
{0: tensor(97.8917), 10: tensor(96.3733), 20: tensor(92.4767), 30: tensor(82.6117), 40: tensor(73.3450), 50: tensor(71.1333), 60: tensor(80.4933), 70: tensor(90.9433), 80: tensor(96.4367), 90: tensor(97.8917), 100: tensor(96.3733), 110: tensor(92.4767), 120: tensor(82.6117), 130: tensor(73.3450), 140: tensor(71.1333), 150: tensor(80.4933), 160: tensor(90.9433), 170: tensor(96.4367), 180: tensor(97.8917), 190: tensor(96.3733), 200: tensor(92.4767), 210: tensor(82.6117), 220: tensor(73.3450), 230: tensor(71.1333), 240: tensor(80.4933), 250: tensor(90.9433), 260: tensor(96.4367), 270: tensor(97.8917), 280: tensor(96.3733), 290: tensor(92.4767), 300: tensor(82.6117), 310: tensor(73.3450), 320: tensor(71.1333), 330: tensor(80.4933), 340: tensor(90.9433), 350: tensor(96.4367)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=2, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.7515,                   Accuracy: 236/2000.0 (11.80%)



-= Testing valid =-
Test set: Average loss: 1.1890,                   Accuracy: 1155/2000.0 (57.75%)



-= Testing valid =-
Test set: Average loss: 0.7658,                   Accuracy: 1491/2000.0 (74.55%)



-= Testing valid =-
Test set: Average loss: 0.4450,                   Accuracy: 1723/2000.0 (86.15%)



-= Testing valid =-
Test set: Average loss: 0.4688,                   Accuracy: 1720/2000.0 (86.00%)



-= Testing valid =-
Test set: Average loss: 0.2542,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.5772,                   Accuracy: 1644/2000.0 (82.20%)



-= Testing valid =-
Test set: Average loss: 0.1529,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1372,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1131,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 10 train accuracy: 96.45%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1160,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1107,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1082,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 20 train accuracy: 97.57%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0738,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0723,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0656,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 30 train accuracy: 98.43%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0645,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0659,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 40 train accuracy: 98.90%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0630,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0638,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0650,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0615,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0620,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0638,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 50 train accuracy: 99.06%, valid accuracy 97.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0791,                   Accuracy: 58631/60000 (97.72%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1285,                   Accuracy: 57758/60000 (96.26%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2636,                   Accuracy: 55428/60000 (92.38%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6117,                   Accuracy: 49862/60000 (83.10%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9516,                   Accuracy: 44707/60000 (74.51%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0215,                   Accuracy: 43368/60000 (72.28%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6807,                   Accuracy: 48144/60000 (80.24%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3412,                   Accuracy: 53856/60000 (89.76%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1438,                   Accuracy: 57375/60000 (95.62%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0791,                   Accuracy: 58631/60000 (97.72%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1285,                   Accuracy: 57758/60000 (96.26%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2636,                   Accuracy: 55428/60000 (92.38%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6117,                   Accuracy: 49862/60000 (83.10%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9516,                   Accuracy: 44707/60000 (74.51%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0215,                   Accuracy: 43368/60000 (72.28%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6807,                   Accuracy: 48144/60000 (80.24%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3412,                   Accuracy: 53856/60000 (89.76%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1438,                   Accuracy: 57375/60000 (95.62%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0791,                   Accuracy: 58631/60000 (97.72%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1285,                   Accuracy: 57758/60000 (96.26%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2636,                   Accuracy: 55428/60000 (92.38%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6117,                   Accuracy: 49862/60000 (83.10%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9516,                   Accuracy: 44707/60000 (74.51%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0215,                   Accuracy: 43368/60000 (72.28%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6807,                   Accuracy: 48144/60000 (80.24%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3412,                   Accuracy: 53856/60000 (89.76%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1438,                   Accuracy: 57375/60000 (95.62%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0791,                   Accuracy: 58631/60000 (97.72%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1285,                   Accuracy: 57758/60000 (96.26%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2636,                   Accuracy: 55428/60000 (92.38%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6117,                   Accuracy: 49862/60000 (83.10%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9516,                   Accuracy: 44707/60000 (74.51%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0215,                   Accuracy: 43368/60000 (72.28%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6807,                   Accuracy: 48144/60000 (80.24%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3412,                   Accuracy: 53856/60000 (89.76%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1438,                   Accuracy: 57375/60000 (95.62%)
{0: tensor(97.7183), 10: tensor(96.2633), 20: tensor(92.3800), 30: tensor(83.1033), 40: tensor(74.5117), 50: tensor(72.2800), 60: tensor(80.2400), 70: tensor(89.7600), 80: tensor(95.6250), 90: tensor(97.7183), 100: tensor(96.2633), 110: tensor(92.3800), 120: tensor(83.1033), 130: tensor(74.5117), 140: tensor(72.2800), 150: tensor(80.2400), 160: tensor(89.7600), 170: tensor(95.6250), 180: tensor(97.7183), 190: tensor(96.2633), 200: tensor(92.3800), 210: tensor(83.1033), 220: tensor(74.5117), 230: tensor(72.2800), 240: tensor(80.2400), 250: tensor(89.7600), 260: tensor(95.6250), 270: tensor(97.7183), 280: tensor(96.2633), 290: tensor(92.3800), 300: tensor(83.1033), 310: tensor(74.5117), 320: tensor(72.2800), 330: tensor(80.2400), 340: tensor(89.7600), 350: tensor(95.6250)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=3, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.9663,                   Accuracy: 312/2000.0 (15.60%)



-= Testing valid =-
Test set: Average loss: 1.4844,                   Accuracy: 945/2000.0 (47.25%)



-= Testing valid =-
Test set: Average loss: 1.0486,                   Accuracy: 1213/2000.0 (60.65%)



-= Testing valid =-
Test set: Average loss: 1.0595,                   Accuracy: 1317/2000.0 (65.85%)



-= Testing valid =-
Test set: Average loss: 0.4221,                   Accuracy: 1725/2000.0 (86.25%)



-= Testing valid =-
Test set: Average loss: 0.2667,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.4405,                   Accuracy: 1711/2000.0 (85.55%)



-= Testing valid =-
Test set: Average loss: 0.1871,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.6053,                   Accuracy: 1609/2000.0 (80.45%)



-= Testing valid =-
Test set: Average loss: 0.1645,                   Accuracy: 1897/2000.0 (94.85%)



Epoch 10 train accuracy: 95.61%, valid accuracy 94.85%
-= Testing valid =-
Test set: Average loss: 0.1241,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1075,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1595,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1190,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1243,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 20 train accuracy: 97.69%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 30 train accuracy: 98.46%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 40 train accuracy: 98.74%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0756,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 50 train accuracy: 99.05%, valid accuracy 97.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0877,                   Accuracy: 58464/60000 (97.44%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1402,                   Accuracy: 57424/60000 (95.71%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2935,                   Accuracy: 54502/60000 (90.84%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5578,                   Accuracy: 49854/60000 (83.09%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8941,                   Accuracy: 44477/60000 (74.13%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9184,                   Accuracy: 44001/60000 (73.33%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5763,                   Accuracy: 49807/60000 (83.01%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2720,                   Accuracy: 55040/60000 (91.73%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1166,                   Accuracy: 57910/60000 (96.52%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0877,                   Accuracy: 58464/60000 (97.44%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1402,                   Accuracy: 57424/60000 (95.71%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2935,                   Accuracy: 54502/60000 (90.84%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5578,                   Accuracy: 49854/60000 (83.09%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8941,                   Accuracy: 44477/60000 (74.13%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9184,                   Accuracy: 44001/60000 (73.33%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5763,                   Accuracy: 49807/60000 (83.01%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2720,                   Accuracy: 55040/60000 (91.73%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1166,                   Accuracy: 57910/60000 (96.52%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0877,                   Accuracy: 58464/60000 (97.44%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1402,                   Accuracy: 57424/60000 (95.71%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2935,                   Accuracy: 54502/60000 (90.84%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5578,                   Accuracy: 49854/60000 (83.09%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8941,                   Accuracy: 44477/60000 (74.13%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9184,                   Accuracy: 44001/60000 (73.33%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5763,                   Accuracy: 49807/60000 (83.01%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2720,                   Accuracy: 55040/60000 (91.73%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1166,                   Accuracy: 57910/60000 (96.52%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0877,                   Accuracy: 58464/60000 (97.44%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1402,                   Accuracy: 57424/60000 (95.71%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2935,                   Accuracy: 54502/60000 (90.84%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5578,                   Accuracy: 49854/60000 (83.09%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8941,                   Accuracy: 44477/60000 (74.13%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9184,                   Accuracy: 44001/60000 (73.33%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5763,                   Accuracy: 49807/60000 (83.01%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2720,                   Accuracy: 55040/60000 (91.73%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1166,                   Accuracy: 57910/60000 (96.52%)
{0: tensor(97.4400), 10: tensor(95.7067), 20: tensor(90.8367), 30: tensor(83.0900), 40: tensor(74.1283), 50: tensor(73.3350), 60: tensor(83.0117), 70: tensor(91.7333), 80: tensor(96.5167), 90: tensor(97.4400), 100: tensor(95.7067), 110: tensor(90.8367), 120: tensor(83.0900), 130: tensor(74.1283), 140: tensor(73.3350), 150: tensor(83.0117), 160: tensor(91.7333), 170: tensor(96.5167), 180: tensor(97.4400), 190: tensor(95.7067), 200: tensor(90.8367), 210: tensor(83.0900), 220: tensor(74.1283), 230: tensor(73.3350), 240: tensor(83.0117), 250: tensor(91.7333), 260: tensor(96.5167), 270: tensor(97.4400), 280: tensor(95.7067), 290: tensor(90.8367), 300: tensor(83.0900), 310: tensor(74.1283), 320: tensor(73.3350), 330: tensor(83.0117), 340: tensor(91.7333), 350: tensor(96.5167)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=4, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.9006,                   Accuracy: 423/2000.0 (21.15%)



-= Testing valid =-
Test set: Average loss: 4.1190,                   Accuracy: 255/2000.0 (12.75%)



-= Testing valid =-
Test set: Average loss: 0.5434,                   Accuracy: 1648/2000.0 (82.40%)



-= Testing valid =-
Test set: Average loss: 0.7819,                   Accuracy: 1527/2000.0 (76.35%)



-= Testing valid =-
Test set: Average loss: 0.7239,                   Accuracy: 1492/2000.0 (74.60%)



-= Testing valid =-
Test set: Average loss: 0.3485,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.1529,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.2027,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1466,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1917/2000.0 (95.85%)



Epoch 10 train accuracy: 96.04%, valid accuracy 95.85%
-= Testing valid =-
Test set: Average loss: 0.1150,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1080,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1111,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1112,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1222,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1199,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0719,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1099,                   Accuracy: 1934/2000.0 (96.70%)



Epoch 20 train accuracy: 98.04%, valid accuracy 96.70%
-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0718,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0937,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0721,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 30 train accuracy: 98.39%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0674,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0708,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 40 train accuracy: 98.89%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0686,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0686,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0709,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 50 train accuracy: 99.16%, valid accuracy 97.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0803,                   Accuracy: 58600/60000 (97.67%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1282,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2819,                   Accuracy: 55052/60000 (91.75%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6068,                   Accuracy: 49591/60000 (82.65%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9620,                   Accuracy: 43935/60000 (73.22%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0379,                   Accuracy: 42758/60000 (71.26%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6797,                   Accuracy: 48342/60000 (80.57%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3205,                   Accuracy: 54287/60000 (90.48%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1250,                   Accuracy: 57809/60000 (96.35%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0803,                   Accuracy: 58600/60000 (97.67%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1282,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2819,                   Accuracy: 55052/60000 (91.75%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6068,                   Accuracy: 49591/60000 (82.65%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9620,                   Accuracy: 43935/60000 (73.22%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0379,                   Accuracy: 42758/60000 (71.26%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6797,                   Accuracy: 48342/60000 (80.57%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3205,                   Accuracy: 54287/60000 (90.48%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1250,                   Accuracy: 57809/60000 (96.35%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0803,                   Accuracy: 58600/60000 (97.67%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1282,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2819,                   Accuracy: 55052/60000 (91.75%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6068,                   Accuracy: 49591/60000 (82.65%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9620,                   Accuracy: 43935/60000 (73.22%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0379,                   Accuracy: 42758/60000 (71.26%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6797,                   Accuracy: 48342/60000 (80.57%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3205,                   Accuracy: 54287/60000 (90.48%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1250,                   Accuracy: 57809/60000 (96.35%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0803,                   Accuracy: 58600/60000 (97.67%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1282,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2819,                   Accuracy: 55052/60000 (91.75%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6068,                   Accuracy: 49591/60000 (82.65%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9620,                   Accuracy: 43935/60000 (73.22%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0379,                   Accuracy: 42758/60000 (71.26%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6797,                   Accuracy: 48342/60000 (80.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3205,                   Accuracy: 54287/60000 (90.48%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1250,                   Accuracy: 57809/60000 (96.35%)
{0: tensor(97.6667), 10: tensor(96.1417), 20: tensor(91.7533), 30: tensor(82.6517), 40: tensor(73.2250), 50: tensor(71.2633), 60: tensor(80.5700), 70: tensor(90.4783), 80: tensor(96.3483), 90: tensor(97.6667), 100: tensor(96.1417), 110: tensor(91.7533), 120: tensor(82.6517), 130: tensor(73.2250), 140: tensor(71.2633), 150: tensor(80.5700), 160: tensor(90.4783), 170: tensor(96.3483), 180: tensor(97.6667), 190: tensor(96.1417), 200: tensor(91.7533), 210: tensor(82.6517), 220: tensor(73.2250), 230: tensor(71.2633), 240: tensor(80.5700), 250: tensor(90.4783), 260: tensor(96.3483), 270: tensor(97.6667), 280: tensor(96.1417), 290: tensor(91.7533), 300: tensor(82.6517), 310: tensor(73.2250), 320: tensor(71.2633), 330: tensor(80.5700), 340: tensor(90.4783), 350: tensor(96.3483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=5, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.7833,                   Accuracy: 253/2000.0 (12.65%)



-= Testing valid =-
Test set: Average loss: 1.3794,                   Accuracy: 980/2000.0 (49.00%)



-= Testing valid =-
Test set: Average loss: 1.4368,                   Accuracy: 907/2000.0 (45.35%)



-= Testing valid =-
Test set: Average loss: 0.5761,                   Accuracy: 1656/2000.0 (82.80%)



-= Testing valid =-
Test set: Average loss: 0.2470,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.2882,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.4696,                   Accuracy: 1691/2000.0 (84.55%)



-= Testing valid =-
Test set: Average loss: 0.3036,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.1608,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1552,                   Accuracy: 1913/2000.0 (95.65%)



Epoch 10 train accuracy: 95.99%, valid accuracy 95.65%
-= Testing valid =-
Test set: Average loss: 0.1309,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1168,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1083,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1330,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1154,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1135,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 20 train accuracy: 97.61%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0825,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 30 train accuracy: 98.51%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0687,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0632,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0628,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0719,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 40 train accuracy: 98.69%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0708,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0664,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0674,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0629,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 50 train accuracy: 99.00%, valid accuracy 98.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0902,                   Accuracy: 58395/60000 (97.32%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1318,                   Accuracy: 57634/60000 (96.06%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2361,                   Accuracy: 55827/60000 (93.04%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5015,                   Accuracy: 50998/60000 (85.00%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7668,                   Accuracy: 46354/60000 (77.26%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.8002,                   Accuracy: 45667/60000 (76.11%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5595,                   Accuracy: 49639/60000 (82.73%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2783,                   Accuracy: 54884/60000 (91.47%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1318,                   Accuracy: 57624/60000 (96.04%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0902,                   Accuracy: 58395/60000 (97.32%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1318,                   Accuracy: 57634/60000 (96.06%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2361,                   Accuracy: 55827/60000 (93.04%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5015,                   Accuracy: 50998/60000 (85.00%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7668,                   Accuracy: 46354/60000 (77.26%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8002,                   Accuracy: 45667/60000 (76.11%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5595,                   Accuracy: 49639/60000 (82.73%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2783,                   Accuracy: 54884/60000 (91.47%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1318,                   Accuracy: 57624/60000 (96.04%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0902,                   Accuracy: 58395/60000 (97.32%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1318,                   Accuracy: 57634/60000 (96.06%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2361,                   Accuracy: 55827/60000 (93.04%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5015,                   Accuracy: 50998/60000 (85.00%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.7668,                   Accuracy: 46354/60000 (77.26%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.8002,                   Accuracy: 45667/60000 (76.11%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5595,                   Accuracy: 49639/60000 (82.73%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2783,                   Accuracy: 54884/60000 (91.47%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1318,                   Accuracy: 57624/60000 (96.04%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0902,                   Accuracy: 58395/60000 (97.32%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1318,                   Accuracy: 57634/60000 (96.06%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2361,                   Accuracy: 55827/60000 (93.04%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5015,                   Accuracy: 50998/60000 (85.00%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7668,                   Accuracy: 46354/60000 (77.26%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8002,                   Accuracy: 45667/60000 (76.11%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5595,                   Accuracy: 49639/60000 (82.73%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2783,                   Accuracy: 54884/60000 (91.47%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1318,                   Accuracy: 57624/60000 (96.04%)
{0: tensor(97.3250), 10: tensor(96.0567), 20: tensor(93.0450), 30: tensor(84.9967), 40: tensor(77.2567), 50: tensor(76.1117), 60: tensor(82.7317), 70: tensor(91.4733), 80: tensor(96.0400), 90: tensor(97.3250), 100: tensor(96.0567), 110: tensor(93.0450), 120: tensor(84.9967), 130: tensor(77.2567), 140: tensor(76.1117), 150: tensor(82.7317), 160: tensor(91.4733), 170: tensor(96.0400), 180: tensor(97.3250), 190: tensor(96.0567), 200: tensor(93.0450), 210: tensor(84.9967), 220: tensor(77.2567), 230: tensor(76.1117), 240: tensor(82.7317), 250: tensor(91.4733), 260: tensor(96.0400), 270: tensor(97.3250), 280: tensor(96.0567), 290: tensor(93.0450), 300: tensor(84.9967), 310: tensor(77.2567), 320: tensor(76.1117), 330: tensor(82.7317), 340: tensor(91.4733), 350: tensor(96.0400)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=6, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1801,                   Accuracy: 513/2000.0 (25.65%)



-= Testing valid =-
Test set: Average loss: 1.4986,                   Accuracy: 836/2000.0 (41.80%)



-= Testing valid =-
Test set: Average loss: 0.8391,                   Accuracy: 1426/2000.0 (71.30%)



-= Testing valid =-
Test set: Average loss: 0.5564,                   Accuracy: 1670/2000.0 (83.50%)



-= Testing valid =-
Test set: Average loss: 0.7326,                   Accuracy: 1479/2000.0 (73.95%)



-= Testing valid =-
Test set: Average loss: 0.1862,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1678,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1682,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.4627,                   Accuracy: 1700/2000.0 (85.00%)



-= Testing valid =-
Test set: Average loss: 0.2272,                   Accuracy: 1854/2000.0 (92.70%)



Epoch 10 train accuracy: 95.95%, valid accuracy 92.70%
-= Testing valid =-
Test set: Average loss: 0.1327,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1362,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0807,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0719,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 20 train accuracy: 97.46%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0825,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0654,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0686,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0596,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 30 train accuracy: 98.10%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0594,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0575,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 40 train accuracy: 98.57%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0590,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0555,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0550,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0598,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 50 train accuracy: 98.64%, valid accuracy 98.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0886,                   Accuracy: 58424/60000 (97.37%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1320,                   Accuracy: 57684/60000 (96.14%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2568,                   Accuracy: 55279/60000 (92.13%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6331,                   Accuracy: 48568/60000 (80.95%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9417,                   Accuracy: 43991/60000 (73.32%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9244,                   Accuracy: 44175/60000 (73.62%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5662,                   Accuracy: 49794/60000 (82.99%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2645,                   Accuracy: 55217/60000 (92.03%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1235,                   Accuracy: 57807/60000 (96.35%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0886,                   Accuracy: 58424/60000 (97.37%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1320,                   Accuracy: 57684/60000 (96.14%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2568,                   Accuracy: 55279/60000 (92.13%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6331,                   Accuracy: 48568/60000 (80.95%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9417,                   Accuracy: 43991/60000 (73.32%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9244,                   Accuracy: 44175/60000 (73.62%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5662,                   Accuracy: 49794/60000 (82.99%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2645,                   Accuracy: 55217/60000 (92.03%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1235,                   Accuracy: 57807/60000 (96.35%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0886,                   Accuracy: 58424/60000 (97.37%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1320,                   Accuracy: 57684/60000 (96.14%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2568,                   Accuracy: 55279/60000 (92.13%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.6331,                   Accuracy: 48568/60000 (80.95%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9417,                   Accuracy: 43991/60000 (73.32%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9244,                   Accuracy: 44175/60000 (73.62%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5662,                   Accuracy: 49794/60000 (82.99%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2645,                   Accuracy: 55217/60000 (92.03%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1235,                   Accuracy: 57807/60000 (96.35%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0886,                   Accuracy: 58424/60000 (97.37%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1320,                   Accuracy: 57684/60000 (96.14%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2568,                   Accuracy: 55279/60000 (92.13%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6331,                   Accuracy: 48568/60000 (80.95%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9417,                   Accuracy: 43991/60000 (73.32%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9244,                   Accuracy: 44175/60000 (73.62%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5662,                   Accuracy: 49794/60000 (82.99%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2645,                   Accuracy: 55217/60000 (92.03%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1235,                   Accuracy: 57807/60000 (96.35%)
{0: tensor(97.3733), 10: tensor(96.1400), 20: tensor(92.1317), 30: tensor(80.9467), 40: tensor(73.3183), 50: tensor(73.6250), 60: tensor(82.9900), 70: tensor(92.0283), 80: tensor(96.3450), 90: tensor(97.3733), 100: tensor(96.1400), 110: tensor(92.1317), 120: tensor(80.9467), 130: tensor(73.3183), 140: tensor(73.6250), 150: tensor(82.9900), 160: tensor(92.0283), 170: tensor(96.3450), 180: tensor(97.3733), 190: tensor(96.1400), 200: tensor(92.1317), 210: tensor(80.9467), 220: tensor(73.3183), 230: tensor(73.6250), 240: tensor(82.9900), 250: tensor(92.0283), 260: tensor(96.3450), 270: tensor(97.3733), 280: tensor(96.1400), 290: tensor(92.1317), 300: tensor(80.9467), 310: tensor(73.3183), 320: tensor(73.6250), 330: tensor(82.9900), 340: tensor(92.0283), 350: tensor(96.3450)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=7, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4282,                   Accuracy: 419/2000.0 (20.95%)



-= Testing valid =-
Test set: Average loss: 1.3006,                   Accuracy: 1125/2000.0 (56.25%)



-= Testing valid =-
Test set: Average loss: 0.9675,                   Accuracy: 1303/2000.0 (65.15%)



-= Testing valid =-
Test set: Average loss: 0.2916,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.3820,                   Accuracy: 1737/2000.0 (86.85%)



-= Testing valid =-
Test set: Average loss: 0.2197,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2400,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.1495,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1540,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1330,                   Accuracy: 1914/2000.0 (95.70%)



Epoch 10 train accuracy: 96.03%, valid accuracy 95.70%
-= Testing valid =-
Test set: Average loss: 0.1196,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1168,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 20 train accuracy: 97.70%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0650,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0738,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0593,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0585,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 30 train accuracy: 98.47%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0662,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0674,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0641,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0736,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0630,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0655,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0625,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 40 train accuracy: 98.84%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0657,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0636,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0664,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0656,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0630,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0622,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 50 train accuracy: 98.94%, valid accuracy 97.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0835,                   Accuracy: 58521/60000 (97.54%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1531,                   Accuracy: 57362/60000 (95.60%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3855,                   Accuracy: 53591/60000 (89.32%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7078,                   Accuracy: 47953/60000 (79.92%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.1436,                   Accuracy: 40994/60000 (68.32%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2534,                   Accuracy: 39165/60000 (65.28%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8485,                   Accuracy: 45217/60000 (75.36%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.4211,                   Accuracy: 52566/60000 (87.61%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1480,                   Accuracy: 57350/60000 (95.58%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0835,                   Accuracy: 58521/60000 (97.54%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1531,                   Accuracy: 57362/60000 (95.60%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3855,                   Accuracy: 53591/60000 (89.32%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.7078,                   Accuracy: 47953/60000 (79.92%)
-= Testing Rotation 130 =-
Test set: Average loss: 1.1436,                   Accuracy: 40994/60000 (68.32%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.2534,                   Accuracy: 39165/60000 (65.28%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.8485,                   Accuracy: 45217/60000 (75.36%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4211,                   Accuracy: 52566/60000 (87.61%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1480,                   Accuracy: 57350/60000 (95.58%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0835,                   Accuracy: 58521/60000 (97.54%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1531,                   Accuracy: 57362/60000 (95.60%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3855,                   Accuracy: 53591/60000 (89.32%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.7078,                   Accuracy: 47953/60000 (79.92%)
-= Testing Rotation 220 =-
Test set: Average loss: 1.1436,                   Accuracy: 40994/60000 (68.32%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.2534,                   Accuracy: 39165/60000 (65.28%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.8485,                   Accuracy: 45217/60000 (75.36%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.4211,                   Accuracy: 52566/60000 (87.61%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1480,                   Accuracy: 57350/60000 (95.58%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0835,                   Accuracy: 58521/60000 (97.54%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1531,                   Accuracy: 57362/60000 (95.60%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3855,                   Accuracy: 53591/60000 (89.32%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.7078,                   Accuracy: 47953/60000 (79.92%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1436,                   Accuracy: 40994/60000 (68.32%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2534,                   Accuracy: 39165/60000 (65.28%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8485,                   Accuracy: 45217/60000 (75.36%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.4211,                   Accuracy: 52566/60000 (87.61%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1480,                   Accuracy: 57350/60000 (95.58%)
{0: tensor(97.5350), 10: tensor(95.6033), 20: tensor(89.3183), 30: tensor(79.9217), 40: tensor(68.3233), 50: tensor(65.2750), 60: tensor(75.3617), 70: tensor(87.6100), 80: tensor(95.5833), 90: tensor(97.5350), 100: tensor(95.6033), 110: tensor(89.3183), 120: tensor(79.9217), 130: tensor(68.3233), 140: tensor(65.2750), 150: tensor(75.3617), 160: tensor(87.6100), 170: tensor(95.5833), 180: tensor(97.5350), 190: tensor(95.6033), 200: tensor(89.3183), 210: tensor(79.9217), 220: tensor(68.3233), 230: tensor(65.2750), 240: tensor(75.3617), 250: tensor(87.6100), 260: tensor(95.5833), 270: tensor(97.5350), 280: tensor(95.6033), 290: tensor(89.3183), 300: tensor(79.9217), 310: tensor(68.3233), 320: tensor(65.2750), 330: tensor(75.3617), 340: tensor(87.6100), 350: tensor(95.5833)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=8, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3535,                   Accuracy: 324/2000.0 (16.20%)



-= Testing valid =-
Test set: Average loss: 2.7426,                   Accuracy: 399/2000.0 (19.95%)



-= Testing valid =-
Test set: Average loss: 1.0327,                   Accuracy: 1330/2000.0 (66.50%)



-= Testing valid =-
Test set: Average loss: 0.4162,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.6759,                   Accuracy: 1576/2000.0 (78.80%)



-= Testing valid =-
Test set: Average loss: 0.4497,                   Accuracy: 1732/2000.0 (86.60%)



-= Testing valid =-
Test set: Average loss: 0.2228,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.1718,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.3430,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.1920,                   Accuracy: 1872/2000.0 (93.60%)



Epoch 10 train accuracy: 94.76%, valid accuracy 93.60%
-= Testing valid =-
Test set: Average loss: 0.1036,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1401,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1216,                   Accuracy: 1928/2000.0 (96.40%)



Epoch 20 train accuracy: 97.55%, valid accuracy 96.40%
-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0683,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0622,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0686,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 30 train accuracy: 98.21%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0698,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0685,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0590,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0607,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 40 train accuracy: 98.85%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0570,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0580,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0602,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 50 train accuracy: 98.96%, valid accuracy 98.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0882,                   Accuracy: 58429/60000 (97.38%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1403,                   Accuracy: 57481/60000 (95.80%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2677,                   Accuracy: 55161/60000 (91.93%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5772,                   Accuracy: 49625/60000 (82.71%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9263,                   Accuracy: 43522/60000 (72.54%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0442,                   Accuracy: 41550/60000 (69.25%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7326,                   Accuracy: 46758/60000 (77.93%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3476,                   Accuracy: 53785/60000 (89.64%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1371,                   Accuracy: 57521/60000 (95.87%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0882,                   Accuracy: 58429/60000 (97.38%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1403,                   Accuracy: 57481/60000 (95.80%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2677,                   Accuracy: 55161/60000 (91.93%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5772,                   Accuracy: 49625/60000 (82.71%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.9263,                   Accuracy: 43522/60000 (72.54%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0442,                   Accuracy: 41550/60000 (69.25%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7326,                   Accuracy: 46758/60000 (77.93%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3476,                   Accuracy: 53785/60000 (89.64%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1371,                   Accuracy: 57521/60000 (95.87%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0882,                   Accuracy: 58429/60000 (97.38%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1403,                   Accuracy: 57481/60000 (95.80%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2677,                   Accuracy: 55161/60000 (91.93%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5772,                   Accuracy: 49625/60000 (82.71%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.9263,                   Accuracy: 43522/60000 (72.54%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0442,                   Accuracy: 41550/60000 (69.25%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.7326,                   Accuracy: 46758/60000 (77.93%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3476,                   Accuracy: 53785/60000 (89.64%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1371,                   Accuracy: 57521/60000 (95.87%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0882,                   Accuracy: 58429/60000 (97.38%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1403,                   Accuracy: 57481/60000 (95.80%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2677,                   Accuracy: 55161/60000 (91.93%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5772,                   Accuracy: 49625/60000 (82.71%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.9263,                   Accuracy: 43522/60000 (72.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0442,                   Accuracy: 41550/60000 (69.25%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7326,                   Accuracy: 46758/60000 (77.93%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3476,                   Accuracy: 53785/60000 (89.64%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1371,                   Accuracy: 57521/60000 (95.87%)
{0: tensor(97.3817), 10: tensor(95.8017), 20: tensor(91.9350), 30: tensor(82.7083), 40: tensor(72.5367), 50: tensor(69.2500), 60: tensor(77.9300), 70: tensor(89.6417), 80: tensor(95.8683), 90: tensor(97.3817), 100: tensor(95.8017), 110: tensor(91.9350), 120: tensor(82.7083), 130: tensor(72.5367), 140: tensor(69.2500), 150: tensor(77.9300), 160: tensor(89.6417), 170: tensor(95.8683), 180: tensor(97.3817), 190: tensor(95.8017), 200: tensor(91.9350), 210: tensor(82.7083), 220: tensor(72.5367), 230: tensor(69.2500), 240: tensor(77.9300), 250: tensor(89.6417), 260: tensor(95.8683), 270: tensor(97.3817), 280: tensor(95.8017), 290: tensor(91.9350), 300: tensor(82.7083), 310: tensor(72.5367), 320: tensor(69.2500), 330: tensor(77.9300), 340: tensor(89.6417), 350: tensor(95.8683)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=9, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.7823,                   Accuracy: 371/2000.0 (18.55%)



-= Testing valid =-
Test set: Average loss: 2.5564,                   Accuracy: 369/2000.0 (18.45%)



-= Testing valid =-
Test set: Average loss: 1.2132,                   Accuracy: 1142/2000.0 (57.10%)



-= Testing valid =-
Test set: Average loss: 0.8389,                   Accuracy: 1360/2000.0 (68.00%)



-= Testing valid =-
Test set: Average loss: 0.7111,                   Accuracy: 1530/2000.0 (76.50%)



-= Testing valid =-
Test set: Average loss: 0.3145,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.1813,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.2494,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.2582,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.1418,                   Accuracy: 1922/2000.0 (96.10%)



Epoch 10 train accuracy: 95.99%, valid accuracy 96.10%
-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.1083,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1282,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0640,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 20 train accuracy: 97.94%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0532,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 30 train accuracy: 98.51%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0445,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 40 train accuracy: 98.88%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 50 train accuracy: 99.16%, valid accuracy 98.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0817,                   Accuracy: 58500/60000 (97.50%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1348,                   Accuracy: 57532/60000 (95.89%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3045,                   Accuracy: 54512/60000 (90.85%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7389,                   Accuracy: 47137/60000 (78.56%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.0324,                   Accuracy: 42575/60000 (70.96%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0080,                   Accuracy: 43108/60000 (71.85%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6425,                   Accuracy: 48902/60000 (81.50%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2874,                   Accuracy: 54800/60000 (91.33%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1167,                   Accuracy: 57818/60000 (96.36%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0817,                   Accuracy: 58500/60000 (97.50%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1348,                   Accuracy: 57532/60000 (95.89%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3045,                   Accuracy: 54512/60000 (90.85%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.7389,                   Accuracy: 47137/60000 (78.56%)
-= Testing Rotation 130 =-
Test set: Average loss: 1.0324,                   Accuracy: 42575/60000 (70.96%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0080,                   Accuracy: 43108/60000 (71.85%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6425,                   Accuracy: 48902/60000 (81.50%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2874,                   Accuracy: 54800/60000 (91.33%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1167,                   Accuracy: 57818/60000 (96.36%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0817,                   Accuracy: 58500/60000 (97.50%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1348,                   Accuracy: 57532/60000 (95.89%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3045,                   Accuracy: 54512/60000 (90.85%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.7389,                   Accuracy: 47137/60000 (78.56%)
-= Testing Rotation 220 =-
Test set: Average loss: 1.0324,                   Accuracy: 42575/60000 (70.96%)
-= Testing Rotation 230 =-
Test set: Average loss: 1.0080,                   Accuracy: 43108/60000 (71.85%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6425,                   Accuracy: 48902/60000 (81.50%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2874,                   Accuracy: 54800/60000 (91.33%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1167,                   Accuracy: 57818/60000 (96.36%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0817,                   Accuracy: 58500/60000 (97.50%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1348,                   Accuracy: 57532/60000 (95.89%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3045,                   Accuracy: 54512/60000 (90.85%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.7389,                   Accuracy: 47137/60000 (78.56%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0324,                   Accuracy: 42575/60000 (70.96%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0080,                   Accuracy: 43108/60000 (71.85%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6425,                   Accuracy: 48902/60000 (81.50%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2874,                   Accuracy: 54800/60000 (91.33%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1167,                   Accuracy: 57818/60000 (96.36%)
{0: tensor(97.5000), 10: tensor(95.8867), 20: tensor(90.8533), 30: tensor(78.5617), 40: tensor(70.9583), 50: tensor(71.8467), 60: tensor(81.5033), 70: tensor(91.3333), 80: tensor(96.3633), 90: tensor(97.5000), 100: tensor(95.8867), 110: tensor(90.8533), 120: tensor(78.5617), 130: tensor(70.9583), 140: tensor(71.8467), 150: tensor(81.5033), 160: tensor(91.3333), 170: tensor(96.3633), 180: tensor(97.5000), 190: tensor(95.8867), 200: tensor(90.8533), 210: tensor(78.5617), 220: tensor(70.9583), 230: tensor(71.8467), 240: tensor(81.5033), 250: tensor(91.3333), 260: tensor(96.3633), 270: tensor(97.5000), 280: tensor(95.8867), 290: tensor(90.8533), 300: tensor(78.5617), 310: tensor(70.9583), 320: tensor(71.8467), 330: tensor(81.5033), 340: tensor(91.3333), 350: tensor(96.3633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=10, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8800,                   Accuracy: 609/2000.0 (30.45%)



-= Testing valid =-
Test set: Average loss: 2.3134,                   Accuracy: 581/2000.0 (29.05%)



-= Testing valid =-
Test set: Average loss: 1.0413,                   Accuracy: 1404/2000.0 (70.20%)



-= Testing valid =-
Test set: Average loss: 1.1067,                   Accuracy: 1223/2000.0 (61.15%)



-= Testing valid =-
Test set: Average loss: 0.3851,                   Accuracy: 1760/2000.0 (88.00%)



-= Testing valid =-
Test set: Average loss: 0.3175,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.2946,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.3831,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.1689,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1693,                   Accuracy: 1892/2000.0 (94.60%)



Epoch 10 train accuracy: 95.89%, valid accuracy 94.60%
-= Testing valid =-
Test set: Average loss: 0.1215,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1342,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1487,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1417,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1173,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 20 train accuracy: 97.79%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0807,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0659,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 30 train accuracy: 98.51%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0590,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0590,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0668,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0602,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 40 train accuracy: 98.62%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0555,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0512,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0540,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0556,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0546,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 50 train accuracy: 98.89%, valid accuracy 98.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0748,                   Accuracy: 58669/60000 (97.78%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1193,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2404,                   Accuracy: 55638/60000 (92.73%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5433,                   Accuracy: 50402/60000 (84.00%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8655,                   Accuracy: 45022/60000 (75.04%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9816,                   Accuracy: 43378/60000 (72.30%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.6603,                   Accuracy: 48479/60000 (80.80%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3020,                   Accuracy: 54483/60000 (90.81%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1118,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0748,                   Accuracy: 58669/60000 (97.78%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1193,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2404,                   Accuracy: 55638/60000 (92.73%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5433,                   Accuracy: 50402/60000 (84.00%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8655,                   Accuracy: 45022/60000 (75.04%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9816,                   Accuracy: 43378/60000 (72.30%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6603,                   Accuracy: 48479/60000 (80.80%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3020,                   Accuracy: 54483/60000 (90.81%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1118,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0748,                   Accuracy: 58669/60000 (97.78%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1193,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2404,                   Accuracy: 55638/60000 (92.73%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5433,                   Accuracy: 50402/60000 (84.00%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.8655,                   Accuracy: 45022/60000 (75.04%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.9816,                   Accuracy: 43378/60000 (72.30%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6603,                   Accuracy: 48479/60000 (80.80%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3020,                   Accuracy: 54483/60000 (90.81%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1118,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0748,                   Accuracy: 58669/60000 (97.78%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1193,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2404,                   Accuracy: 55638/60000 (92.73%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5433,                   Accuracy: 50402/60000 (84.00%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8655,                   Accuracy: 45022/60000 (75.04%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9816,                   Accuracy: 43378/60000 (72.30%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6603,                   Accuracy: 48479/60000 (80.80%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3020,                   Accuracy: 54483/60000 (90.81%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1118,                   Accuracy: 57941/60000 (96.57%)
{0: tensor(97.7817), 10: tensor(96.3817), 20: tensor(92.7300), 30: tensor(84.0033), 40: tensor(75.0367), 50: tensor(72.2967), 60: tensor(80.7983), 70: tensor(90.8050), 80: tensor(96.5683), 90: tensor(97.7817), 100: tensor(96.3817), 110: tensor(92.7300), 120: tensor(84.0033), 130: tensor(75.0367), 140: tensor(72.2967), 150: tensor(80.7983), 160: tensor(90.8050), 170: tensor(96.5683), 180: tensor(97.7817), 190: tensor(96.3817), 200: tensor(92.7300), 210: tensor(84.0033), 220: tensor(75.0367), 230: tensor(72.2967), 240: tensor(80.7983), 250: tensor(90.8050), 260: tensor(96.5683), 270: tensor(97.7817), 280: tensor(96.3817), 290: tensor(92.7300), 300: tensor(84.0033), 310: tensor(75.0367), 320: tensor(72.2967), 330: tensor(80.7983), 340: tensor(90.8050), 350: tensor(96.5683)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=1, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7538,                   Accuracy: 718/2000.0 (35.90%)



-= Testing valid =-
Test set: Average loss: 2.3508,                   Accuracy: 566/2000.0 (28.30%)



-= Testing valid =-
Test set: Average loss: 0.4921,                   Accuracy: 1718/2000.0 (85.90%)



-= Testing valid =-
Test set: Average loss: 0.2321,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1423,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1160,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1311,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 10 train accuracy: 98.55%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0561,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0471,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0566,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0514,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0608,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 20 train accuracy: 99.28%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0465,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0454,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0453,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 30 train accuracy: 99.71%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 40 train accuracy: 99.64%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.81%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0464,                   Accuracy: 59229/60000 (98.71%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0781,                   Accuracy: 58700/60000 (97.83%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1796,                   Accuracy: 57014/60000 (95.02%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4486,                   Accuracy: 52717/60000 (87.86%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7967,                   Accuracy: 46772/60000 (77.95%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9607,                   Accuracy: 43140/60000 (71.90%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9087,                   Accuracy: 43154/60000 (71.92%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7525,                   Accuracy: 45225/60000 (75.38%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6655,                   Accuracy: 46289/60000 (77.15%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7066,                   Accuracy: 46288/60000 (77.15%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9882,                   Accuracy: 42466/60000 (70.78%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6161,                   Accuracy: 36098/60000 (60.16%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5661,                   Accuracy: 27884/60000 (46.47%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.3465,                   Accuracy: 23435/60000 (39.06%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.6826,                   Accuracy: 23340/60000 (38.90%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.6368,                   Accuracy: 24909/60000 (41.51%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4003,                   Accuracy: 27794/60000 (46.32%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.4265,                   Accuracy: 30010/60000 (50.02%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.4893,                   Accuracy: 30730/60000 (51.22%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.5182,                   Accuracy: 30083/60000 (50.14%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.8226,                   Accuracy: 27582/60000 (45.97%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.1576,                   Accuracy: 24587/60000 (40.98%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.9817,                   Accuracy: 23578/60000 (39.30%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2561,                   Accuracy: 26302/60000 (43.84%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.1942,                   Accuracy: 33415/60000 (55.69%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2706,                   Accuracy: 42403/60000 (70.67%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6444,                   Accuracy: 49722/60000 (82.87%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4327,                   Accuracy: 52646/60000 (87.74%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5228,                   Accuracy: 50585/60000 (84.31%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7071,                   Accuracy: 47281/60000 (78.80%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0510,                   Accuracy: 42005/60000 (70.01%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2030,                   Accuracy: 39864/60000 (66.44%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0921,                   Accuracy: 42529/60000 (70.88%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6551,                   Accuracy: 49022/60000 (81.70%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2590,                   Accuracy: 55475/60000 (92.46%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0824,                   Accuracy: 58584/60000 (97.64%)
{0: tensor(98.7150), 10: tensor(97.8333), 20: tensor(95.0233), 30: tensor(87.8617), 40: tensor(77.9533), 50: tensor(71.9000), 60: tensor(71.9233), 70: tensor(75.3750), 80: tensor(77.1483), 90: tensor(77.1467), 100: tensor(70.7767), 110: tensor(60.1633), 120: tensor(46.4733), 130: tensor(39.0583), 140: tensor(38.9000), 150: tensor(41.5150), 160: tensor(46.3233), 170: tensor(50.0167), 180: tensor(51.2167), 190: tensor(50.1383), 200: tensor(45.9700), 210: tensor(40.9783), 220: tensor(39.2967), 230: tensor(43.8367), 240: tensor(55.6917), 250: tensor(70.6717), 260: tensor(82.8700), 270: tensor(87.7433), 280: tensor(84.3083), 290: tensor(78.8017), 300: tensor(70.0083), 310: tensor(66.4400), 320: tensor(70.8817), 330: tensor(81.7033), 340: tensor(92.4583), 350: tensor(97.6400)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=2, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9644,                   Accuracy: 559/2000.0 (27.95%)



-= Testing valid =-
Test set: Average loss: 2.2535,                   Accuracy: 708/2000.0 (35.40%)



-= Testing valid =-
Test set: Average loss: 1.0306,                   Accuracy: 1257/2000.0 (62.85%)



-= Testing valid =-
Test set: Average loss: 0.3388,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.3077,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.1514,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1457,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1344,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1826,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1919/2000.0 (95.95%)



Epoch 10 train accuracy: 98.22%, valid accuracy 95.95%
-= Testing valid =-
Test set: Average loss: 0.0549,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0601,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0585,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0443,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0459,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 20 train accuracy: 99.29%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 30 train accuracy: 99.53%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0318,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.71%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.71%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0490,                   Accuracy: 59158/60000 (98.60%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0883,                   Accuracy: 58491/60000 (97.49%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2066,                   Accuracy: 56502/60000 (94.17%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4911,                   Accuracy: 52172/60000 (86.95%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8969,                   Accuracy: 44939/60000 (74.90%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1942,                   Accuracy: 39672/60000 (66.12%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0693,                   Accuracy: 40624/60000 (67.71%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7837,                   Accuracy: 45281/60000 (75.47%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5995,                   Accuracy: 48468/60000 (80.78%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4863,                   Accuracy: 50504/60000 (84.17%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9168,                   Accuracy: 44058/60000 (73.43%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.7478,                   Accuracy: 34563/60000 (57.60%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.7132,                   Accuracy: 27457/60000 (45.76%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.4980,                   Accuracy: 23182/60000 (38.64%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.8496,                   Accuracy: 21881/60000 (36.47%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.7637,                   Accuracy: 24949/60000 (41.58%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4882,                   Accuracy: 28904/60000 (48.17%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5532,                   Accuracy: 31203/60000 (52.01%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.5172,                   Accuracy: 32285/60000 (53.81%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.6076,                   Accuracy: 30178/60000 (50.30%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.9588,                   Accuracy: 27094/60000 (45.16%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.2867,                   Accuracy: 23396/60000 (38.99%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.9249,                   Accuracy: 21821/60000 (36.37%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2420,                   Accuracy: 23468/60000 (39.11%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2051,                   Accuracy: 29673/60000 (49.46%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2055,                   Accuracy: 39396/60000 (65.66%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7109,                   Accuracy: 46241/60000 (77.07%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4879,                   Accuracy: 49398/60000 (82.33%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7997,                   Accuracy: 45375/60000 (75.62%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0695,                   Accuracy: 41979/60000 (69.96%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.4798,                   Accuracy: 37251/60000 (62.08%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.5898,                   Accuracy: 35949/60000 (59.92%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.5028,                   Accuracy: 38434/60000 (64.06%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8264,                   Accuracy: 47416/60000 (79.03%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2596,                   Accuracy: 55380/60000 (92.30%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0935,                   Accuracy: 58374/60000 (97.29%)
{0: tensor(98.5967), 10: tensor(97.4850), 20: tensor(94.1700), 30: tensor(86.9533), 40: tensor(74.8983), 50: tensor(66.1200), 60: tensor(67.7067), 70: tensor(75.4683), 80: tensor(80.7800), 90: tensor(84.1733), 100: tensor(73.4300), 110: tensor(57.6050), 120: tensor(45.7617), 130: tensor(38.6367), 140: tensor(36.4683), 150: tensor(41.5817), 160: tensor(48.1733), 170: tensor(52.0050), 180: tensor(53.8083), 190: tensor(50.2967), 200: tensor(45.1567), 210: tensor(38.9933), 220: tensor(36.3683), 230: tensor(39.1133), 240: tensor(49.4550), 250: tensor(65.6600), 260: tensor(77.0683), 270: tensor(82.3300), 280: tensor(75.6250), 290: tensor(69.9650), 300: tensor(62.0850), 310: tensor(59.9150), 320: tensor(64.0567), 330: tensor(79.0267), 340: tensor(92.3000), 350: tensor(97.2900)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=3, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.6943,                   Accuracy: 275/2000.0 (13.75%)



-= Testing valid =-
Test set: Average loss: 1.3639,                   Accuracy: 997/2000.0 (49.85%)



-= Testing valid =-
Test set: Average loss: 0.6039,                   Accuracy: 1618/2000.0 (80.90%)



-= Testing valid =-
Test set: Average loss: 0.4040,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.1745,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1404,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1245,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0947,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 10 train accuracy: 98.29%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0488,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 20 train accuracy: 99.19%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0494,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0515,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0568,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 30 train accuracy: 99.56%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0429,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0380,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 40 train accuracy: 99.60%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 50 train accuracy: 99.74%, valid accuracy 98.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0541,                   Accuracy: 59088/60000 (98.48%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0804,                   Accuracy: 58688/60000 (97.81%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1786,                   Accuracy: 57090/60000 (95.15%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4450,                   Accuracy: 52644/60000 (87.74%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9294,                   Accuracy: 44836/60000 (74.73%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2326,                   Accuracy: 39501/60000 (65.83%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1935,                   Accuracy: 39055/60000 (65.09%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9298,                   Accuracy: 42336/60000 (70.56%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7794,                   Accuracy: 44188/60000 (73.65%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6979,                   Accuracy: 45453/60000 (75.75%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9638,                   Accuracy: 40932/60000 (68.22%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5544,                   Accuracy: 34687/60000 (57.81%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2656,                   Accuracy: 28460/60000 (47.43%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.0093,                   Accuracy: 24962/60000 (41.60%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.4842,                   Accuracy: 24255/60000 (40.42%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8173,                   Accuracy: 25592/60000 (42.65%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.0436,                   Accuracy: 28972/60000 (48.29%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.2604,                   Accuracy: 30795/60000 (51.33%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.2987,                   Accuracy: 31317/60000 (52.19%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.4250,                   Accuracy: 31046/60000 (51.74%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.5550,                   Accuracy: 28923/60000 (48.21%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.6896,                   Accuracy: 25779/60000 (42.97%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.6475,                   Accuracy: 23484/60000 (39.14%)
-= Testing Rotation 230 =-
Test set: Average loss: 4.0506,                   Accuracy: 24107/60000 (40.18%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.9775,                   Accuracy: 28772/60000 (47.95%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.7664,                   Accuracy: 36690/60000 (61.15%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9703,                   Accuracy: 43658/60000 (72.76%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5589,                   Accuracy: 49978/60000 (83.30%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6604,                   Accuracy: 47381/60000 (78.97%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8824,                   Accuracy: 43602/60000 (72.67%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1478,                   Accuracy: 39478/60000 (65.80%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3324,                   Accuracy: 37826/60000 (63.04%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1395,                   Accuracy: 41281/60000 (68.80%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6589,                   Accuracy: 48559/60000 (80.93%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2381,                   Accuracy: 55661/60000 (92.77%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0824,                   Accuracy: 58469/60000 (97.45%)
{0: tensor(98.4800), 10: tensor(97.8133), 20: tensor(95.1500), 30: tensor(87.7400), 40: tensor(74.7267), 50: tensor(65.8350), 60: tensor(65.0917), 70: tensor(70.5600), 80: tensor(73.6467), 90: tensor(75.7550), 100: tensor(68.2200), 110: tensor(57.8117), 120: tensor(47.4333), 130: tensor(41.6033), 140: tensor(40.4250), 150: tensor(42.6533), 160: tensor(48.2867), 170: tensor(51.3250), 180: tensor(52.1950), 190: tensor(51.7433), 200: tensor(48.2050), 210: tensor(42.9650), 220: tensor(39.1400), 230: tensor(40.1783), 240: tensor(47.9533), 250: tensor(61.1500), 260: tensor(72.7633), 270: tensor(83.2967), 280: tensor(78.9683), 290: tensor(72.6700), 300: tensor(65.7967), 310: tensor(63.0433), 320: tensor(68.8017), 330: tensor(80.9317), 340: tensor(92.7683), 350: tensor(97.4483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=4, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0328,                   Accuracy: 488/2000.0 (24.40%)



-= Testing valid =-
Test set: Average loss: 1.1674,                   Accuracy: 1060/2000.0 (53.00%)



-= Testing valid =-
Test set: Average loss: 2.1933,                   Accuracy: 639/2000.0 (31.95%)



-= Testing valid =-
Test set: Average loss: 0.5790,                   Accuracy: 1646/2000.0 (82.30%)



-= Testing valid =-
Test set: Average loss: 0.4553,                   Accuracy: 1742/2000.0 (87.10%)



-= Testing valid =-
Test set: Average loss: 0.2913,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.1477,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 10 train accuracy: 98.09%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0575,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0637,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0569,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 20 train accuracy: 98.91%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0610,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0453,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 30 train accuracy: 99.45%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0428,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 40 train accuracy: 99.66%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0439,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 50 train accuracy: 99.72%, valid accuracy 98.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0469,                   Accuracy: 59158/60000 (98.60%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0727,                   Accuracy: 58678/60000 (97.80%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1622,                   Accuracy: 57195/60000 (95.32%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4161,                   Accuracy: 53074/60000 (88.46%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8447,                   Accuracy: 45890/60000 (76.48%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1567,                   Accuracy: 40433/60000 (67.39%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1044,                   Accuracy: 40605/60000 (67.68%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9720,                   Accuracy: 42407/60000 (70.68%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8823,                   Accuracy: 43498/60000 (72.50%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.9071,                   Accuracy: 43252/60000 (72.09%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.3002,                   Accuracy: 36979/60000 (61.63%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.8896,                   Accuracy: 31466/60000 (52.44%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.7117,                   Accuracy: 25432/60000 (42.39%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.4639,                   Accuracy: 22194/60000 (36.99%)
-= Testing Rotation 140 =-
Test set: Average loss: 4.0743,                   Accuracy: 21560/60000 (35.93%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.4577,                   Accuracy: 23229/60000 (38.72%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.7935,                   Accuracy: 25615/60000 (42.69%)
-= Testing Rotation 170 =-
Test set: Average loss: 5.0439,                   Accuracy: 27023/60000 (45.04%)
-= Testing Rotation 180 =-
Test set: Average loss: 5.1755,                   Accuracy: 28266/60000 (47.11%)
-= Testing Rotation 190 =-
Test set: Average loss: 5.2116,                   Accuracy: 27466/60000 (45.78%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.3279,                   Accuracy: 25860/60000 (43.10%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.3839,                   Accuracy: 23238/60000 (38.73%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.9653,                   Accuracy: 22075/60000 (36.79%)
-= Testing Rotation 230 =-
Test set: Average loss: 4.1421,                   Accuracy: 24098/60000 (40.16%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.9980,                   Accuracy: 29018/60000 (48.36%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.9006,                   Accuracy: 35470/60000 (59.12%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.1766,                   Accuracy: 39965/60000 (66.61%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7973,                   Accuracy: 44784/60000 (74.64%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.0688,                   Accuracy: 40670/60000 (67.78%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.1450,                   Accuracy: 39775/60000 (66.29%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3606,                   Accuracy: 38178/60000 (63.63%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4179,                   Accuracy: 38507/60000 (64.18%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1673,                   Accuracy: 42236/60000 (70.39%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6304,                   Accuracy: 49711/60000 (82.85%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2196,                   Accuracy: 56057/60000 (93.43%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0873,                   Accuracy: 58433/60000 (97.39%)
{0: tensor(98.5967), 10: tensor(97.7967), 20: tensor(95.3250), 30: tensor(88.4567), 40: tensor(76.4833), 50: tensor(67.3883), 60: tensor(67.6750), 70: tensor(70.6783), 80: tensor(72.4967), 90: tensor(72.0867), 100: tensor(61.6317), 110: tensor(52.4433), 120: tensor(42.3867), 130: tensor(36.9900), 140: tensor(35.9333), 150: tensor(38.7150), 160: tensor(42.6917), 170: tensor(45.0383), 180: tensor(47.1100), 190: tensor(45.7767), 200: tensor(43.1000), 210: tensor(38.7300), 220: tensor(36.7917), 230: tensor(40.1633), 240: tensor(48.3633), 250: tensor(59.1167), 260: tensor(66.6083), 270: tensor(74.6400), 280: tensor(67.7833), 290: tensor(66.2917), 300: tensor(63.6300), 310: tensor(64.1783), 320: tensor(70.3933), 330: tensor(82.8517), 340: tensor(93.4283), 350: tensor(97.3883)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=5, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7819,                   Accuracy: 696/2000.0 (34.80%)



-= Testing valid =-
Test set: Average loss: 1.2078,                   Accuracy: 1252/2000.0 (62.60%)



-= Testing valid =-
Test set: Average loss: 0.4830,                   Accuracy: 1717/2000.0 (85.85%)



-= Testing valid =-
Test set: Average loss: 0.2080,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.5791,                   Accuracy: 1626/2000.0 (81.30%)



-= Testing valid =-
Test set: Average loss: 0.3514,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.1110,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1145,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 10 train accuracy: 98.28%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0586,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0567,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0559,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0504,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 20 train accuracy: 99.20%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0536,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0525,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 30 train accuracy: 99.54%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0376,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 40 train accuracy: 99.56%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 50 train accuracy: 99.79%, valid accuracy 98.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0474,                   Accuracy: 59167/60000 (98.61%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0726,                   Accuracy: 58719/60000 (97.86%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1545,                   Accuracy: 57358/60000 (95.60%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3431,                   Accuracy: 54113/60000 (90.19%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.6197,                   Accuracy: 49032/60000 (81.72%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.7433,                   Accuracy: 46469/60000 (77.45%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.7003,                   Accuracy: 47089/60000 (78.48%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.5400,                   Accuracy: 50044/60000 (83.41%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4330,                   Accuracy: 51728/60000 (86.21%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4323,                   Accuracy: 51506/60000 (85.84%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6941,                   Accuracy: 47174/60000 (78.62%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2446,                   Accuracy: 40193/60000 (66.99%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.1416,                   Accuracy: 30871/60000 (51.45%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.8936,                   Accuracy: 25472/60000 (42.45%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.2204,                   Accuracy: 24784/60000 (41.31%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.2383,                   Accuracy: 26132/60000 (43.55%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.1143,                   Accuracy: 28710/60000 (47.85%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.1727,                   Accuracy: 30302/60000 (50.50%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.3252,                   Accuracy: 30207/60000 (50.35%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.5394,                   Accuracy: 29834/60000 (49.72%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7824,                   Accuracy: 27715/60000 (46.19%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9290,                   Accuracy: 24895/60000 (41.49%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6287,                   Accuracy: 24310/60000 (40.52%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8957,                   Accuracy: 27213/60000 (45.35%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0321,                   Accuracy: 33141/60000 (55.24%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2757,                   Accuracy: 40282/60000 (67.14%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8032,                   Accuracy: 45705/60000 (76.18%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5593,                   Accuracy: 49601/60000 (82.67%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6902,                   Accuracy: 46887/60000 (78.14%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9259,                   Accuracy: 43160/60000 (71.93%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2002,                   Accuracy: 39176/60000 (65.29%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3136,                   Accuracy: 37815/60000 (63.03%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1029,                   Accuracy: 41693/60000 (69.49%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6255,                   Accuracy: 49223/60000 (82.04%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2417,                   Accuracy: 55669/60000 (92.78%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0817,                   Accuracy: 58537/60000 (97.56%)
{0: tensor(98.6117), 10: tensor(97.8650), 20: tensor(95.5967), 30: tensor(90.1883), 40: tensor(81.7200), 50: tensor(77.4483), 60: tensor(78.4817), 70: tensor(83.4067), 80: tensor(86.2133), 90: tensor(85.8433), 100: tensor(78.6233), 110: tensor(66.9883), 120: tensor(51.4517), 130: tensor(42.4533), 140: tensor(41.3067), 150: tensor(43.5533), 160: tensor(47.8500), 170: tensor(50.5033), 180: tensor(50.3450), 190: tensor(49.7233), 200: tensor(46.1917), 210: tensor(41.4917), 220: tensor(40.5167), 230: tensor(45.3550), 240: tensor(55.2350), 250: tensor(67.1367), 260: tensor(76.1750), 270: tensor(82.6683), 280: tensor(78.1450), 290: tensor(71.9333), 300: tensor(65.2933), 310: tensor(63.0250), 320: tensor(69.4883), 330: tensor(82.0383), 340: tensor(92.7817), 350: tensor(97.5617)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=6, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9510,                   Accuracy: 493/2000.0 (24.65%)



-= Testing valid =-
Test set: Average loss: 1.1183,                   Accuracy: 1243/2000.0 (62.15%)



-= Testing valid =-
Test set: Average loss: 0.7847,                   Accuracy: 1410/2000.0 (70.50%)



-= Testing valid =-
Test set: Average loss: 0.3811,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 0.2929,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.3894,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.1775,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1233,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1457,                   Accuracy: 1914/2000.0 (95.70%)



Epoch 10 train accuracy: 97.99%, valid accuracy 95.70%
-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0577,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0593,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0746,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0469,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0656,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 20 train accuracy: 99.10%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0387,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0451,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 30 train accuracy: 99.53%, valid accuracy 99.30%
-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0251,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 40 train accuracy: 99.65%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0264,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.84%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0461,                   Accuracy: 59223/60000 (98.71%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0873,                   Accuracy: 58495/60000 (97.49%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1689,                   Accuracy: 57054/60000 (95.09%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4602,                   Accuracy: 52406/60000 (87.34%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8309,                   Accuracy: 46440/60000 (77.40%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0809,                   Accuracy: 42551/60000 (70.92%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9540,                   Accuracy: 44047/60000 (73.41%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6904,                   Accuracy: 47106/60000 (78.51%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6262,                   Accuracy: 48216/60000 (80.36%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7330,                   Accuracy: 46981/60000 (78.30%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.1898,                   Accuracy: 41637/60000 (69.39%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.9204,                   Accuracy: 36066/60000 (60.11%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.9303,                   Accuracy: 30069/60000 (50.12%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.5346,                   Accuracy: 26350/60000 (43.92%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.8169,                   Accuracy: 25182/60000 (41.97%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8603,                   Accuracy: 26162/60000 (43.60%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.5152,                   Accuracy: 29530/60000 (49.22%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.8838,                   Accuracy: 29546/60000 (49.24%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.0055,                   Accuracy: 30108/60000 (50.18%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.8013,                   Accuracy: 30172/60000 (50.29%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.9103,                   Accuracy: 28302/60000 (47.17%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.1185,                   Accuracy: 24737/60000 (41.23%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7481,                   Accuracy: 23147/60000 (38.58%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.0601,                   Accuracy: 24764/60000 (41.27%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0811,                   Accuracy: 30776/60000 (51.29%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.2988,                   Accuracy: 37428/60000 (62.38%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9608,                   Accuracy: 41626/60000 (69.38%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6282,                   Accuracy: 47436/60000 (79.06%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7664,                   Accuracy: 44906/60000 (74.84%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0522,                   Accuracy: 41245/60000 (68.74%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.4189,                   Accuracy: 38095/60000 (63.49%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.5281,                   Accuracy: 37460/60000 (62.43%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3499,                   Accuracy: 41360/60000 (68.93%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7537,                   Accuracy: 48785/60000 (81.31%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2678,                   Accuracy: 55350/60000 (92.25%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0998,                   Accuracy: 58231/60000 (97.05%)
{0: tensor(98.7050), 10: tensor(97.4917), 20: tensor(95.0900), 30: tensor(87.3433), 40: tensor(77.4000), 50: tensor(70.9183), 60: tensor(73.4117), 70: tensor(78.5100), 80: tensor(80.3600), 90: tensor(78.3017), 100: tensor(69.3950), 110: tensor(60.1100), 120: tensor(50.1150), 130: tensor(43.9167), 140: tensor(41.9700), 150: tensor(43.6033), 160: tensor(49.2167), 170: tensor(49.2433), 180: tensor(50.1800), 190: tensor(50.2867), 200: tensor(47.1700), 210: tensor(41.2283), 220: tensor(38.5783), 230: tensor(41.2733), 240: tensor(51.2933), 250: tensor(62.3800), 260: tensor(69.3767), 270: tensor(79.0600), 280: tensor(74.8433), 290: tensor(68.7417), 300: tensor(63.4917), 310: tensor(62.4333), 320: tensor(68.9333), 330: tensor(81.3083), 340: tensor(92.2500), 350: tensor(97.0517)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=7, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5562,                   Accuracy: 418/2000.0 (20.90%)



-= Testing valid =-
Test set: Average loss: 1.3959,                   Accuracy: 956/2000.0 (47.80%)



-= Testing valid =-
Test set: Average loss: 0.8841,                   Accuracy: 1417/2000.0 (70.85%)



-= Testing valid =-
Test set: Average loss: 0.2639,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2911,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.1294,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1888,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1242,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 10 train accuracy: 98.15%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0427,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 20 train accuracy: 99.24%, valid accuracy 99.15%
-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0213,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 30 train accuracy: 99.31%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0200,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0220,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0193,                   Accuracy: 1988/2000.0 (99.40%)



Epoch 40 train accuracy: 99.62%, valid accuracy 99.40%
-= Testing valid =-
Test set: Average loss: 0.0193,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0183,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0184,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0212,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0205,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0177,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0177,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0202,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.68%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0518,                   Accuracy: 59107/60000 (98.51%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0776,                   Accuracy: 58703/60000 (97.84%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1745,                   Accuracy: 57026/60000 (95.04%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4484,                   Accuracy: 52514/60000 (87.52%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8561,                   Accuracy: 46034/60000 (76.72%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1169,                   Accuracy: 41755/60000 (69.59%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9871,                   Accuracy: 43557/60000 (72.60%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7122,                   Accuracy: 47492/60000 (79.15%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5351,                   Accuracy: 49979/60000 (83.30%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4246,                   Accuracy: 51683/60000 (86.14%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6862,                   Accuracy: 47395/60000 (78.99%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2567,                   Accuracy: 39595/60000 (65.99%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2849,                   Accuracy: 29440/60000 (49.07%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.0760,                   Accuracy: 23991/60000 (39.99%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.5027,                   Accuracy: 23502/60000 (39.17%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.6122,                   Accuracy: 25823/60000 (43.04%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4670,                   Accuracy: 29888/60000 (49.81%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5551,                   Accuracy: 31918/60000 (53.20%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.4754,                   Accuracy: 32105/60000 (53.51%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.5616,                   Accuracy: 31004/60000 (51.67%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7024,                   Accuracy: 28671/60000 (47.78%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.9354,                   Accuracy: 24867/60000 (41.44%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.8064,                   Accuracy: 22750/60000 (37.92%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2214,                   Accuracy: 24558/60000 (40.93%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2119,                   Accuracy: 30559/60000 (50.93%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1729,                   Accuracy: 40419/60000 (67.36%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5960,                   Accuracy: 48333/60000 (80.56%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3291,                   Accuracy: 53293/60000 (88.82%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4681,                   Accuracy: 50623/60000 (84.37%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7028,                   Accuracy: 46998/60000 (78.33%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1883,                   Accuracy: 40825/60000 (68.04%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3985,                   Accuracy: 37836/60000 (63.06%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3067,                   Accuracy: 40084/60000 (66.81%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8117,                   Accuracy: 47250/60000 (78.75%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2874,                   Accuracy: 55059/60000 (91.76%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0960,                   Accuracy: 58313/60000 (97.19%)
{0: tensor(98.5117), 10: tensor(97.8383), 20: tensor(95.0433), 30: tensor(87.5233), 40: tensor(76.7233), 50: tensor(69.5917), 60: tensor(72.5950), 70: tensor(79.1533), 80: tensor(83.2983), 90: tensor(86.1383), 100: tensor(78.9917), 110: tensor(65.9917), 120: tensor(49.0667), 130: tensor(39.9850), 140: tensor(39.1700), 150: tensor(43.0383), 160: tensor(49.8133), 170: tensor(53.1967), 180: tensor(53.5083), 190: tensor(51.6733), 200: tensor(47.7850), 210: tensor(41.4450), 220: tensor(37.9167), 230: tensor(40.9300), 240: tensor(50.9317), 250: tensor(67.3650), 260: tensor(80.5550), 270: tensor(88.8217), 280: tensor(84.3717), 290: tensor(78.3300), 300: tensor(68.0417), 310: tensor(63.0600), 320: tensor(66.8067), 330: tensor(78.7500), 340: tensor(91.7650), 350: tensor(97.1883)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=8, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1265,                   Accuracy: 469/2000.0 (23.45%)



-= Testing valid =-
Test set: Average loss: 1.1134,                   Accuracy: 1290/2000.0 (64.50%)



-= Testing valid =-
Test set: Average loss: 1.0097,                   Accuracy: 1320/2000.0 (66.00%)



-= Testing valid =-
Test set: Average loss: 0.2901,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.1690,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1385,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0608,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 10 train accuracy: 98.19%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0565,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0510,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0435,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 20 train accuracy: 99.05%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0368,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0251,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.43%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 40 train accuracy: 99.54%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.72%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0476,                   Accuracy: 59153/60000 (98.59%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0762,                   Accuracy: 58686/60000 (97.81%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1915,                   Accuracy: 56684/60000 (94.47%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5181,                   Accuracy: 51140/60000 (85.23%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9775,                   Accuracy: 43696/60000 (72.83%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2447,                   Accuracy: 39374/60000 (65.62%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1424,                   Accuracy: 40112/60000 (66.85%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8402,                   Accuracy: 44621/60000 (74.37%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6295,                   Accuracy: 47983/60000 (79.97%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6214,                   Accuracy: 48566/60000 (80.94%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9298,                   Accuracy: 44651/60000 (74.42%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.4717,                   Accuracy: 38140/60000 (63.57%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.3448,                   Accuracy: 29305/60000 (48.84%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.0281,                   Accuracy: 24072/60000 (40.12%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.4529,                   Accuracy: 22489/60000 (37.48%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.5156,                   Accuracy: 23696/60000 (39.49%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.3661,                   Accuracy: 26258/60000 (43.76%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.3192,                   Accuracy: 28107/60000 (46.85%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.2749,                   Accuracy: 29410/60000 (49.02%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.2935,                   Accuracy: 28361/60000 (47.27%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.4085,                   Accuracy: 26279/60000 (43.80%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.6107,                   Accuracy: 23177/60000 (38.63%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.5692,                   Accuracy: 21704/60000 (36.17%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2059,                   Accuracy: 23344/60000 (38.91%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.4942,                   Accuracy: 28260/60000 (47.10%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.6468,                   Accuracy: 35858/60000 (59.76%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.0435,                   Accuracy: 41799/60000 (69.67%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.7196,                   Accuracy: 46106/60000 (76.84%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7126,                   Accuracy: 45430/60000 (75.72%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8871,                   Accuracy: 42442/60000 (70.74%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1941,                   Accuracy: 38333/60000 (63.89%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3280,                   Accuracy: 37094/60000 (61.82%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1918,                   Accuracy: 40484/60000 (67.47%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7031,                   Accuracy: 48280/60000 (80.47%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2463,                   Accuracy: 55700/60000 (92.83%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0882,                   Accuracy: 58418/60000 (97.36%)
{0: tensor(98.5883), 10: tensor(97.8100), 20: tensor(94.4733), 30: tensor(85.2333), 40: tensor(72.8267), 50: tensor(65.6233), 60: tensor(66.8533), 70: tensor(74.3683), 80: tensor(79.9717), 90: tensor(80.9433), 100: tensor(74.4183), 110: tensor(63.5667), 120: tensor(48.8417), 130: tensor(40.1200), 140: tensor(37.4817), 150: tensor(39.4933), 160: tensor(43.7633), 170: tensor(46.8450), 180: tensor(49.0167), 190: tensor(47.2683), 200: tensor(43.7983), 210: tensor(38.6283), 220: tensor(36.1733), 230: tensor(38.9067), 240: tensor(47.1000), 250: tensor(59.7633), 260: tensor(69.6650), 270: tensor(76.8433), 280: tensor(75.7167), 290: tensor(70.7367), 300: tensor(63.8883), 310: tensor(61.8233), 320: tensor(67.4733), 330: tensor(80.4667), 340: tensor(92.8333), 350: tensor(97.3633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=9, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6220,                   Accuracy: 508/2000.0 (25.40%)



-= Testing valid =-
Test set: Average loss: 2.4400,                   Accuracy: 490/2000.0 (24.50%)



-= Testing valid =-
Test set: Average loss: 0.9106,                   Accuracy: 1415/2000.0 (70.75%)



-= Testing valid =-
Test set: Average loss: 0.2364,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.5818,                   Accuracy: 1601/2000.0 (80.05%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1046,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1353,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 10 train accuracy: 98.07%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0447,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 20 train accuracy: 99.11%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0208,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 30 train accuracy: 99.32%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0217,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0247,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0204,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0213,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0231,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0214,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0201,                   Accuracy: 1988/2000.0 (99.40%)



Epoch 40 train accuracy: 99.66%, valid accuracy 99.40%
-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0198,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0203,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0217,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0217,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0201,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0223,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1986/2000.0 (99.30%)



Epoch 50 train accuracy: 99.64%, valid accuracy 99.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0467,                   Accuracy: 59161/60000 (98.60%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0767,                   Accuracy: 58622/60000 (97.70%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1662,                   Accuracy: 57133/60000 (95.22%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4040,                   Accuracy: 53020/60000 (88.37%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8077,                   Accuracy: 45975/60000 (76.62%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0703,                   Accuracy: 41066/60000 (68.44%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0377,                   Accuracy: 40819/60000 (68.03%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7844,                   Accuracy: 44384/60000 (73.97%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6108,                   Accuracy: 47223/60000 (78.71%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6157,                   Accuracy: 46878/60000 (78.13%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9117,                   Accuracy: 43037/60000 (71.73%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6239,                   Accuracy: 35375/60000 (58.96%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.5885,                   Accuracy: 28012/60000 (46.69%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.2514,                   Accuracy: 25039/60000 (41.73%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.5647,                   Accuracy: 24690/60000 (41.15%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.5683,                   Accuracy: 26300/60000 (43.83%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4836,                   Accuracy: 29108/60000 (48.51%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5194,                   Accuracy: 30893/60000 (51.49%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.5677,                   Accuracy: 30808/60000 (51.35%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4878,                   Accuracy: 30651/60000 (51.08%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.6141,                   Accuracy: 28917/60000 (48.19%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7622,                   Accuracy: 26558/60000 (44.26%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.5093,                   Accuracy: 25327/60000 (42.21%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9112,                   Accuracy: 27233/60000 (45.39%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0180,                   Accuracy: 32858/60000 (54.76%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0950,                   Accuracy: 42231/60000 (70.39%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6283,                   Accuracy: 48239/60000 (80.40%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4194,                   Accuracy: 51607/60000 (86.01%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5674,                   Accuracy: 49131/60000 (81.89%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8063,                   Accuracy: 45355/60000 (75.59%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2216,                   Accuracy: 40194/60000 (66.99%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.2857,                   Accuracy: 39195/60000 (65.32%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.0653,                   Accuracy: 42625/60000 (71.04%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5924,                   Accuracy: 49707/60000 (82.85%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2027,                   Accuracy: 56176/60000 (93.63%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0790,                   Accuracy: 58510/60000 (97.52%)
{0: tensor(98.6017), 10: tensor(97.7033), 20: tensor(95.2217), 30: tensor(88.3667), 40: tensor(76.6250), 50: tensor(68.4433), 60: tensor(68.0317), 70: tensor(73.9733), 80: tensor(78.7050), 90: tensor(78.1300), 100: tensor(71.7283), 110: tensor(58.9583), 120: tensor(46.6867), 130: tensor(41.7317), 140: tensor(41.1500), 150: tensor(43.8333), 160: tensor(48.5133), 170: tensor(51.4883), 180: tensor(51.3467), 190: tensor(51.0850), 200: tensor(48.1950), 210: tensor(44.2633), 220: tensor(42.2117), 230: tensor(45.3883), 240: tensor(54.7633), 250: tensor(70.3850), 260: tensor(80.3983), 270: tensor(86.0117), 280: tensor(81.8850), 290: tensor(75.5917), 300: tensor(66.9900), 310: tensor(65.3250), 320: tensor(71.0417), 330: tensor(82.8450), 340: tensor(93.6267), 350: tensor(97.5167)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=10, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6396,                   Accuracy: 255/2000.0 (12.75%)



-= Testing valid =-
Test set: Average loss: 1.0096,                   Accuracy: 1351/2000.0 (67.55%)



-= Testing valid =-
Test set: Average loss: 2.2045,                   Accuracy: 647/2000.0 (32.35%)



-= Testing valid =-
Test set: Average loss: 0.2874,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.1639,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1530,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1597,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1249,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1711,                   Accuracy: 1904/2000.0 (95.20%)



Epoch 10 train accuracy: 98.53%, valid accuracy 95.20%
-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0591,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0608,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0595,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0477,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0411,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 20 train accuracy: 99.07%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0345,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0412,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 30 train accuracy: 99.34%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0301,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0294,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 40 train accuracy: 99.59%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0305,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.72%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0465,                   Accuracy: 59205/60000 (98.68%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0800,                   Accuracy: 58555/60000 (97.59%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1615,                   Accuracy: 57236/60000 (95.39%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4300,                   Accuracy: 52886/60000 (88.14%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8607,                   Accuracy: 45856/60000 (76.43%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2058,                   Accuracy: 40075/60000 (66.79%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1937,                   Accuracy: 39355/60000 (65.59%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8900,                   Accuracy: 43459/60000 (72.43%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.7840,                   Accuracy: 43969/60000 (73.28%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.7295,                   Accuracy: 44448/60000 (74.08%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.0961,                   Accuracy: 38780/60000 (64.63%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6811,                   Accuracy: 33779/60000 (56.30%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.6184,                   Accuracy: 28332/60000 (47.22%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.4440,                   Accuracy: 25826/60000 (43.04%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.9480,                   Accuracy: 25297/60000 (42.16%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.0708,                   Accuracy: 25747/60000 (42.91%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.8290,                   Accuracy: 27828/60000 (46.38%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.9163,                   Accuracy: 29172/60000 (48.62%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.9644,                   Accuracy: 29923/60000 (49.87%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.8669,                   Accuracy: 29884/60000 (49.81%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.9877,                   Accuracy: 27984/60000 (46.64%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.3052,                   Accuracy: 25769/60000 (42.95%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.1779,                   Accuracy: 23906/60000 (39.84%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.5727,                   Accuracy: 24984/60000 (41.64%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.5364,                   Accuracy: 30159/60000 (50.26%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3912,                   Accuracy: 39082/60000 (65.14%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7535,                   Accuracy: 46138/60000 (76.90%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4908,                   Accuracy: 50806/60000 (84.68%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6512,                   Accuracy: 47829/60000 (79.71%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8453,                   Accuracy: 45428/60000 (75.71%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2094,                   Accuracy: 41011/60000 (68.35%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3813,                   Accuracy: 38846/60000 (64.74%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2593,                   Accuracy: 41733/60000 (69.56%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6679,                   Accuracy: 49464/60000 (82.44%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2120,                   Accuracy: 56187/60000 (93.64%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0771,                   Accuracy: 58598/60000 (97.66%)
{0: tensor(98.6750), 10: tensor(97.5917), 20: tensor(95.3933), 30: tensor(88.1433), 40: tensor(76.4267), 50: tensor(66.7917), 60: tensor(65.5917), 70: tensor(72.4317), 80: tensor(73.2817), 90: tensor(74.0800), 100: tensor(64.6333), 110: tensor(56.2983), 120: tensor(47.2200), 130: tensor(43.0433), 140: tensor(42.1617), 150: tensor(42.9117), 160: tensor(46.3800), 170: tensor(48.6200), 180: tensor(49.8717), 190: tensor(49.8067), 200: tensor(46.6400), 210: tensor(42.9483), 220: tensor(39.8433), 230: tensor(41.6400), 240: tensor(50.2650), 250: tensor(65.1367), 260: tensor(76.8967), 270: tensor(84.6767), 280: tensor(79.7150), 290: tensor(75.7133), 300: tensor(68.3517), 310: tensor(64.7433), 320: tensor(69.5550), 330: tensor(82.4400), 340: tensor(93.6450), 350: tensor(97.6633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=1, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1815,                   Accuracy: 286/2000.0 (14.30%)



-= Testing valid =-
Test set: Average loss: 1.3189,                   Accuracy: 924/2000.0 (46.20%)



-= Testing valid =-
Test set: Average loss: 0.6592,                   Accuracy: 1631/2000.0 (81.55%)



-= Testing valid =-
Test set: Average loss: 0.4014,                   Accuracy: 1733/2000.0 (86.65%)



-= Testing valid =-
Test set: Average loss: 0.1418,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.2296,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.1670,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.2319,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2658,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.1232,                   Accuracy: 1923/2000.0 (96.15%)



Epoch 10 train accuracy: 97.96%, valid accuracy 96.15%
-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.1181,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0579,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0583,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0513,                   Accuracy: 1971/2000.0 (98.55%)



Epoch 20 train accuracy: 99.15%, valid accuracy 98.55%
-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0481,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0436,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0453,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1973/2000.0 (98.65%)



Epoch 30 train accuracy: 99.47%, valid accuracy 98.65%
-= Testing valid =-
Test set: Average loss: 0.0441,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0492,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0417,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.66%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0414,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0424,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.78%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0568,                   Accuracy: 58977/60000 (98.29%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1017,                   Accuracy: 58185/60000 (96.97%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2388,                   Accuracy: 55659/60000 (92.76%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5670,                   Accuracy: 49779/60000 (82.96%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9835,                   Accuracy: 43231/60000 (72.05%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0916,                   Accuracy: 41041/60000 (68.40%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8967,                   Accuracy: 43540/60000 (72.57%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6626,                   Accuracy: 47115/60000 (78.53%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5300,                   Accuracy: 48882/60000 (81.47%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5108,                   Accuracy: 49571/60000 (82.62%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7841,                   Accuracy: 45186/60000 (75.31%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.3781,                   Accuracy: 37619/60000 (62.70%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2887,                   Accuracy: 28636/60000 (47.73%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.9333,                   Accuracy: 24638/60000 (41.06%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.1922,                   Accuracy: 24416/60000 (40.69%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.1245,                   Accuracy: 26471/60000 (44.12%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.0517,                   Accuracy: 29366/60000 (48.94%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.1632,                   Accuracy: 30495/60000 (50.83%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.2458,                   Accuracy: 30379/60000 (50.63%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4452,                   Accuracy: 29062/60000 (48.44%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.6953,                   Accuracy: 27237/60000 (45.40%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.8176,                   Accuracy: 24707/60000 (41.18%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.4892,                   Accuracy: 25200/60000 (42.00%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7963,                   Accuracy: 27997/60000 (46.66%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.8938,                   Accuracy: 34022/60000 (56.70%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.1682,                   Accuracy: 41140/60000 (68.57%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7028,                   Accuracy: 46698/60000 (77.83%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5044,                   Accuracy: 49673/60000 (82.79%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5973,                   Accuracy: 48099/60000 (80.17%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9066,                   Accuracy: 42877/60000 (71.46%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2528,                   Accuracy: 37846/60000 (63.08%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3761,                   Accuracy: 36775/60000 (61.29%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1532,                   Accuracy: 41151/60000 (68.58%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6639,                   Accuracy: 48649/60000 (81.08%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2404,                   Accuracy: 55562/60000 (92.60%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0855,                   Accuracy: 58425/60000 (97.38%)
{0: tensor(98.2950), 10: tensor(96.9750), 20: tensor(92.7650), 30: tensor(82.9650), 40: tensor(72.0517), 50: tensor(68.4017), 60: tensor(72.5667), 70: tensor(78.5250), 80: tensor(81.4700), 90: tensor(82.6183), 100: tensor(75.3100), 110: tensor(62.6983), 120: tensor(47.7267), 130: tensor(41.0633), 140: tensor(40.6933), 150: tensor(44.1183), 160: tensor(48.9433), 170: tensor(50.8250), 180: tensor(50.6317), 190: tensor(48.4367), 200: tensor(45.3950), 210: tensor(41.1783), 220: tensor(42.), 230: tensor(46.6617), 240: tensor(56.7033), 250: tensor(68.5667), 260: tensor(77.8300), 270: tensor(82.7883), 280: tensor(80.1650), 290: tensor(71.4617), 300: tensor(63.0767), 310: tensor(61.2917), 320: tensor(68.5850), 330: tensor(81.0817), 340: tensor(92.6033), 350: tensor(97.3750)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=2, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4025,                   Accuracy: 240/2000.0 (12.00%)



-= Testing valid =-
Test set: Average loss: 2.6065,                   Accuracy: 330/2000.0 (16.50%)



-= Testing valid =-
Test set: Average loss: 0.7394,                   Accuracy: 1635/2000.0 (81.75%)



-= Testing valid =-
Test set: Average loss: 0.3924,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2267,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.1784,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1426,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1431,                   Accuracy: 1905/2000.0 (95.25%)



Epoch 10 train accuracy: 98.06%, valid accuracy 95.25%
-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0448,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0428,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0369,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0348,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 20 train accuracy: 99.04%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 30 train accuracy: 99.49%, valid accuracy 98.95%
-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0232,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0239,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0222,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0221,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 40 train accuracy: 99.64%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0205,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0225,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0233,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0218,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0218,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0206,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0191,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 50 train accuracy: 99.80%, valid accuracy 99.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0423,                   Accuracy: 59264/60000 (98.77%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0720,                   Accuracy: 58739/60000 (97.90%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1501,                   Accuracy: 57393/60000 (95.65%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3950,                   Accuracy: 53055/60000 (88.43%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7245,                   Accuracy: 47241/60000 (78.74%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9368,                   Accuracy: 43340/60000 (72.23%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9582,                   Accuracy: 42419/60000 (70.70%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.9084,                   Accuracy: 42543/60000 (70.90%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.9728,                   Accuracy: 41271/60000 (68.79%)
-= Testing Rotation 90 =-
Test set: Average loss: 1.1895,                   Accuracy: 39380/60000 (65.63%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.6350,                   Accuracy: 35752/60000 (59.59%)
-= Testing Rotation 110 =-
Test set: Average loss: 2.2251,                   Accuracy: 30343/60000 (50.57%)
-= Testing Rotation 120 =-
Test set: Average loss: 3.0127,                   Accuracy: 25980/60000 (43.30%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.5595,                   Accuracy: 22081/60000 (36.80%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.8464,                   Accuracy: 21607/60000 (36.01%)
-= Testing Rotation 150 =-
Test set: Average loss: 4.0482,                   Accuracy: 23631/60000 (39.38%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.1409,                   Accuracy: 26583/60000 (44.31%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.4317,                   Accuracy: 28328/60000 (47.21%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.9019,                   Accuracy: 27595/60000 (45.99%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.6882,                   Accuracy: 27135/60000 (45.22%)
-= Testing Rotation 200 =-
Test set: Average loss: 4.7210,                   Accuracy: 25260/60000 (42.10%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.9317,                   Accuracy: 22528/60000 (37.55%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.4983,                   Accuracy: 21607/60000 (36.01%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.7189,                   Accuracy: 23902/60000 (39.84%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.6146,                   Accuracy: 30104/60000 (50.17%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.5239,                   Accuracy: 38719/60000 (64.53%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8605,                   Accuracy: 45824/60000 (76.37%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5742,                   Accuracy: 50077/60000 (83.46%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6987,                   Accuracy: 46695/60000 (77.82%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9115,                   Accuracy: 42523/60000 (70.87%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2334,                   Accuracy: 38328/60000 (63.88%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3445,                   Accuracy: 36665/60000 (61.11%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1678,                   Accuracy: 40441/60000 (67.40%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6569,                   Accuracy: 48604/60000 (81.01%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2144,                   Accuracy: 55958/60000 (93.26%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0668,                   Accuracy: 58745/60000 (97.91%)
{0: tensor(98.7733), 10: tensor(97.8983), 20: tensor(95.6550), 30: tensor(88.4250), 40: tensor(78.7350), 50: tensor(72.2333), 60: tensor(70.6983), 70: tensor(70.9050), 80: tensor(68.7850), 90: tensor(65.6333), 100: tensor(59.5867), 110: tensor(50.5717), 120: tensor(43.3000), 130: tensor(36.8017), 140: tensor(36.0117), 150: tensor(39.3850), 160: tensor(44.3050), 170: tensor(47.2133), 180: tensor(45.9917), 190: tensor(45.2250), 200: tensor(42.1000), 210: tensor(37.5467), 220: tensor(36.0117), 230: tensor(39.8367), 240: tensor(50.1733), 250: tensor(64.5317), 260: tensor(76.3733), 270: tensor(83.4617), 280: tensor(77.8250), 290: tensor(70.8717), 300: tensor(63.8800), 310: tensor(61.1083), 320: tensor(67.4017), 330: tensor(81.0067), 340: tensor(93.2633), 350: tensor(97.9083)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=3, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.3450,                   Accuracy: 182/2000.0 (9.10%)



-= Testing valid =-
Test set: Average loss: 1.6595,                   Accuracy: 802/2000.0 (40.10%)



-= Testing valid =-
Test set: Average loss: 0.8349,                   Accuracy: 1427/2000.0 (71.35%)



-= Testing valid =-
Test set: Average loss: 0.3924,                   Accuracy: 1755/2000.0 (87.75%)



-= Testing valid =-
Test set: Average loss: 0.3605,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.4672,                   Accuracy: 1716/2000.0 (85.80%)



-= Testing valid =-
Test set: Average loss: 0.2521,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.4667,                   Accuracy: 1634/2000.0 (81.70%)



-= Testing valid =-
Test set: Average loss: 0.5506,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.1104,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 10 train accuracy: 97.72%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.2178,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.1201,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1284,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1202,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1584,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.0719,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.1716,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.0545,                   Accuracy: 1966/2000.0 (98.30%)



Epoch 20 train accuracy: 99.01%, valid accuracy 98.30%
-= Testing valid =-
Test set: Average loss: 0.1531,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.1387,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0624,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0585,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 30 train accuracy: 99.50%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0516,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0457,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0650,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0486,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0450,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 40 train accuracy: 99.62%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0420,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0506,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0444,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 50 train accuracy: 99.60%, valid accuracy 98.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0564,                   Accuracy: 59033/60000 (98.39%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0898,                   Accuracy: 58462/60000 (97.44%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2048,                   Accuracy: 56547/60000 (94.25%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5143,                   Accuracy: 51527/60000 (85.88%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9727,                   Accuracy: 44372/60000 (73.95%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.1863,                   Accuracy: 40831/60000 (68.05%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9649,                   Accuracy: 43398/60000 (72.33%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.5913,                   Accuracy: 48918/60000 (81.53%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4115,                   Accuracy: 51743/60000 (86.24%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3419,                   Accuracy: 53177/60000 (88.63%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.5062,                   Accuracy: 49964/60000 (83.27%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.9161,                   Accuracy: 43001/60000 (71.67%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.6138,                   Accuracy: 33874/60000 (56.46%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.3293,                   Accuracy: 26812/60000 (44.69%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.6655,                   Accuracy: 24155/60000 (40.26%)
-= Testing Rotation 150 =-
Test set: Average loss: 2.5147,                   Accuracy: 26463/60000 (44.10%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.2775,                   Accuracy: 32103/60000 (53.51%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.2326,                   Accuracy: 34811/60000 (58.02%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.1891,                   Accuracy: 35550/60000 (59.25%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.3977,                   Accuracy: 33771/60000 (56.28%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.6728,                   Accuracy: 30517/60000 (50.86%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.0208,                   Accuracy: 26399/60000 (44.00%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.0455,                   Accuracy: 25067/60000 (41.78%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.5915,                   Accuracy: 28041/60000 (46.74%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.6590,                   Accuracy: 36137/60000 (60.23%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.7918,                   Accuracy: 46903/60000 (78.17%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.4066,                   Accuracy: 52550/60000 (87.58%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3043,                   Accuracy: 54055/60000 (90.09%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3650,                   Accuracy: 52805/60000 (88.01%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.5602,                   Accuracy: 49121/60000 (81.87%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.8832,                   Accuracy: 43744/60000 (72.91%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0824,                   Accuracy: 40782/60000 (67.97%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.9887,                   Accuracy: 42534/60000 (70.89%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5547,                   Accuracy: 49925/60000 (83.21%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2013,                   Accuracy: 56311/60000 (93.85%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0863,                   Accuracy: 58462/60000 (97.44%)
{0: tensor(98.3883), 10: tensor(97.4367), 20: tensor(94.2450), 30: tensor(85.8783), 40: tensor(73.9533), 50: tensor(68.0517), 60: tensor(72.3300), 70: tensor(81.5300), 80: tensor(86.2383), 90: tensor(88.6283), 100: tensor(83.2733), 110: tensor(71.6683), 120: tensor(56.4567), 130: tensor(44.6867), 140: tensor(40.2583), 150: tensor(44.1050), 160: tensor(53.5050), 170: tensor(58.0183), 180: tensor(59.2500), 190: tensor(56.2850), 200: tensor(50.8617), 210: tensor(43.9983), 220: tensor(41.7783), 230: tensor(46.7350), 240: tensor(60.2283), 250: tensor(78.1717), 260: tensor(87.5833), 270: tensor(90.0917), 280: tensor(88.0083), 290: tensor(81.8683), 300: tensor(72.9067), 310: tensor(67.9700), 320: tensor(70.8900), 330: tensor(83.2083), 340: tensor(93.8517), 350: tensor(97.4367)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=4, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0107,                   Accuracy: 512/2000.0 (25.60%)



-= Testing valid =-
Test set: Average loss: 3.3167,                   Accuracy: 263/2000.0 (13.15%)



-= Testing valid =-
Test set: Average loss: 1.2444,                   Accuracy: 1120/2000.0 (56.00%)



-= Testing valid =-
Test set: Average loss: 1.6067,                   Accuracy: 899/2000.0 (44.95%)



-= Testing valid =-
Test set: Average loss: 0.1754,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.3150,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.7065,                   Accuracy: 1558/2000.0 (77.90%)



-= Testing valid =-
Test set: Average loss: 0.2608,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.1437,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.2763,                   Accuracy: 1827/2000.0 (91.35%)



Epoch 10 train accuracy: 98.09%, valid accuracy 91.35%
-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1444,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1452,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1229,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1353,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1134,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1954,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 20 train accuracy: 99.12%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1181,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0986,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0752,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 30 train accuracy: 99.45%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0909,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0756,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 40 train accuracy: 99.55%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0802,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0698,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 50 train accuracy: 99.70%, valid accuracy 97.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0853,                   Accuracy: 58471/60000 (97.45%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1261,                   Accuracy: 57774/60000 (96.29%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2215,                   Accuracy: 55998/60000 (93.33%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5135,                   Accuracy: 50015/60000 (83.36%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8527,                   Accuracy: 43397/60000 (72.33%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0664,                   Accuracy: 39180/60000 (65.30%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0578,                   Accuracy: 39211/60000 (65.35%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8552,                   Accuracy: 42491/60000 (70.82%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8654,                   Accuracy: 42565/60000 (70.94%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.9285,                   Accuracy: 42118/60000 (70.20%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.2797,                   Accuracy: 35824/60000 (59.71%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5860,                   Accuracy: 32098/60000 (53.50%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.1404,                   Accuracy: 28353/60000 (47.26%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.6657,                   Accuracy: 25431/60000 (42.38%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.0525,                   Accuracy: 25179/60000 (41.97%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.2544,                   Accuracy: 27188/60000 (45.31%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.4381,                   Accuracy: 29471/60000 (49.12%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.4442,                   Accuracy: 30402/60000 (50.67%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.2722,                   Accuracy: 31151/60000 (51.92%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4808,                   Accuracy: 30397/60000 (50.66%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.4795,                   Accuracy: 28932/60000 (48.22%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4015,                   Accuracy: 26172/60000 (43.62%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.2276,                   Accuracy: 24517/60000 (40.86%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7432,                   Accuracy: 25798/60000 (43.00%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.0038,                   Accuracy: 30615/60000 (51.03%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3452,                   Accuracy: 36999/60000 (61.67%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9014,                   Accuracy: 42623/60000 (71.04%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6070,                   Accuracy: 48095/60000 (80.16%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.7072,                   Accuracy: 45251/60000 (75.42%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8016,                   Accuracy: 43601/60000 (72.67%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0115,                   Accuracy: 40434/60000 (67.39%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.0652,                   Accuracy: 39338/60000 (65.56%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.8923,                   Accuracy: 43018/60000 (71.70%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.5356,                   Accuracy: 49966/60000 (83.28%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1941,                   Accuracy: 56299/60000 (93.83%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1031,                   Accuracy: 58129/60000 (96.88%)
{0: tensor(97.4517), 10: tensor(96.2900), 20: tensor(93.3300), 30: tensor(83.3583), 40: tensor(72.3283), 50: tensor(65.3000), 60: tensor(65.3517), 70: tensor(70.8183), 80: tensor(70.9417), 90: tensor(70.1967), 100: tensor(59.7067), 110: tensor(53.4967), 120: tensor(47.2550), 130: tensor(42.3850), 140: tensor(41.9650), 150: tensor(45.3133), 160: tensor(49.1183), 170: tensor(50.6700), 180: tensor(51.9183), 190: tensor(50.6617), 200: tensor(48.2200), 210: tensor(43.6200), 220: tensor(40.8617), 230: tensor(42.9967), 240: tensor(51.0250), 250: tensor(61.6650), 260: tensor(71.0383), 270: tensor(80.1583), 280: tensor(75.4183), 290: tensor(72.6683), 300: tensor(67.3900), 310: tensor(65.5633), 320: tensor(71.6967), 330: tensor(83.2767), 340: tensor(93.8317), 350: tensor(96.8817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=5, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7741,                   Accuracy: 738/2000.0 (36.90%)



-= Testing valid =-
Test set: Average loss: 0.8161,                   Accuracy: 1595/2000.0 (79.75%)



-= Testing valid =-
Test set: Average loss: 0.8157,                   Accuracy: 1467/2000.0 (73.35%)



-= Testing valid =-
Test set: Average loss: 0.2456,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.2120,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1255,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1415,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1407,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1968/2000.0 (98.40%)



Epoch 10 train accuracy: 98.16%, valid accuracy 98.40%
-= Testing valid =-
Test set: Average loss: 0.0616,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0551,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0544,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.1109,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0632,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0542,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 20 train accuracy: 99.18%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0464,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0478,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.45%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0416,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 40 train accuracy: 99.80%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0357,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 50 train accuracy: 99.70%, valid accuracy 98.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0497,                   Accuracy: 59117/60000 (98.53%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0847,                   Accuracy: 58598/60000 (97.66%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1581,                   Accuracy: 57355/60000 (95.59%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3664,                   Accuracy: 53712/60000 (89.52%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7219,                   Accuracy: 47652/60000 (79.42%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9718,                   Accuracy: 43039/60000 (71.73%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9065,                   Accuracy: 43663/60000 (72.77%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6645,                   Accuracy: 47357/60000 (78.93%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4725,                   Accuracy: 50733/60000 (84.56%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3939,                   Accuracy: 52453/60000 (87.42%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6576,                   Accuracy: 47780/60000 (79.63%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2061,                   Accuracy: 40744/60000 (67.91%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0941,                   Accuracy: 31789/60000 (52.98%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.9676,                   Accuracy: 25509/60000 (42.51%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.4718,                   Accuracy: 23790/60000 (39.65%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4797,                   Accuracy: 25324/60000 (42.21%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.3506,                   Accuracy: 27984/60000 (46.64%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.1639,                   Accuracy: 29859/60000 (49.76%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.0690,                   Accuracy: 31967/60000 (53.28%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.2824,                   Accuracy: 30372/60000 (50.62%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.5239,                   Accuracy: 28584/60000 (47.64%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.8024,                   Accuracy: 26308/60000 (43.85%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7887,                   Accuracy: 24632/60000 (41.05%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2861,                   Accuracy: 26141/60000 (43.57%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3221,                   Accuracy: 31790/60000 (52.98%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3881,                   Accuracy: 39549/60000 (65.92%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.7707,                   Accuracy: 46587/60000 (77.64%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4090,                   Accuracy: 52320/60000 (87.20%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5408,                   Accuracy: 49894/60000 (83.16%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7310,                   Accuracy: 46188/60000 (76.98%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0407,                   Accuracy: 40864/60000 (68.11%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3171,                   Accuracy: 37119/60000 (61.87%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2450,                   Accuracy: 39544/60000 (65.91%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7524,                   Accuracy: 47459/60000 (79.10%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2800,                   Accuracy: 54960/60000 (91.60%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0948,                   Accuracy: 58267/60000 (97.11%)
{0: tensor(98.5283), 10: tensor(97.6633), 20: tensor(95.5917), 30: tensor(89.5200), 40: tensor(79.4200), 50: tensor(71.7317), 60: tensor(72.7717), 70: tensor(78.9283), 80: tensor(84.5550), 90: tensor(87.4217), 100: tensor(79.6333), 110: tensor(67.9067), 120: tensor(52.9817), 130: tensor(42.5150), 140: tensor(39.6500), 150: tensor(42.2067), 160: tensor(46.6400), 170: tensor(49.7650), 180: tensor(53.2783), 190: tensor(50.6200), 200: tensor(47.6400), 210: tensor(43.8467), 220: tensor(41.0533), 230: tensor(43.5683), 240: tensor(52.9833), 250: tensor(65.9150), 260: tensor(77.6450), 270: tensor(87.2000), 280: tensor(83.1567), 290: tensor(76.9800), 300: tensor(68.1067), 310: tensor(61.8650), 320: tensor(65.9067), 330: tensor(79.0983), 340: tensor(91.6000), 350: tensor(97.1117)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=6, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9744,                   Accuracy: 571/2000.0 (28.55%)



-= Testing valid =-
Test set: Average loss: 1.5102,                   Accuracy: 918/2000.0 (45.90%)



-= Testing valid =-
Test set: Average loss: 0.7932,                   Accuracy: 1410/2000.0 (70.50%)



-= Testing valid =-
Test set: Average loss: 0.4971,                   Accuracy: 1610/2000.0 (80.50%)



-= Testing valid =-
Test set: Average loss: 0.3004,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.1519,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1235,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0538,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 10 train accuracy: 98.22%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0619,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0537,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0489,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0664,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0503,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0588,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 20 train accuracy: 99.10%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0389,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0361,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.40%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.55%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0290,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.81%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0458,                   Accuracy: 59169/60000 (98.61%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0744,                   Accuracy: 58680/60000 (97.80%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1683,                   Accuracy: 57069/60000 (95.11%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4193,                   Accuracy: 53045/60000 (88.41%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.7464,                   Accuracy: 47602/60000 (79.34%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.9507,                   Accuracy: 44234/60000 (73.72%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.8612,                   Accuracy: 45480/60000 (75.80%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.5985,                   Accuracy: 49454/60000 (82.42%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4384,                   Accuracy: 52022/60000 (86.70%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3874,                   Accuracy: 53135/60000 (88.56%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.5806,                   Accuracy: 49872/60000 (83.12%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.0734,                   Accuracy: 43181/60000 (71.97%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.9152,                   Accuracy: 33019/60000 (55.03%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.6800,                   Accuracy: 26751/60000 (44.58%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.1919,                   Accuracy: 23491/60000 (39.15%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.3728,                   Accuracy: 25193/60000 (41.99%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.3099,                   Accuracy: 28840/60000 (48.07%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.2539,                   Accuracy: 30944/60000 (51.57%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.2132,                   Accuracy: 31464/60000 (52.44%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.2545,                   Accuracy: 30713/60000 (51.19%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.4425,                   Accuracy: 28657/60000 (47.76%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7404,                   Accuracy: 25611/60000 (42.69%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6018,                   Accuracy: 24207/60000 (40.35%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.0924,                   Accuracy: 25403/60000 (42.34%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2025,                   Accuracy: 30273/60000 (50.46%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3652,                   Accuracy: 37672/60000 (62.79%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8300,                   Accuracy: 44394/60000 (73.99%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5919,                   Accuracy: 48094/60000 (80.16%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6580,                   Accuracy: 47563/60000 (79.27%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9086,                   Accuracy: 43702/60000 (72.84%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1950,                   Accuracy: 39220/60000 (65.37%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.3399,                   Accuracy: 38346/60000 (63.91%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.2359,                   Accuracy: 40955/60000 (68.26%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.7350,                   Accuracy: 48309/60000 (80.51%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2518,                   Accuracy: 55515/60000 (92.53%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0808,                   Accuracy: 58520/60000 (97.53%)
{0: tensor(98.6150), 10: tensor(97.8000), 20: tensor(95.1150), 30: tensor(88.4083), 40: tensor(79.3367), 50: tensor(73.7233), 60: tensor(75.8000), 70: tensor(82.4233), 80: tensor(86.7033), 90: tensor(88.5583), 100: tensor(83.1200), 110: tensor(71.9683), 120: tensor(55.0317), 130: tensor(44.5850), 140: tensor(39.1517), 150: tensor(41.9883), 160: tensor(48.0667), 170: tensor(51.5733), 180: tensor(52.4400), 190: tensor(51.1883), 200: tensor(47.7617), 210: tensor(42.6850), 220: tensor(40.3450), 230: tensor(42.3383), 240: tensor(50.4550), 250: tensor(62.7867), 260: tensor(73.9900), 270: tensor(80.1567), 280: tensor(79.2717), 290: tensor(72.8367), 300: tensor(65.3667), 310: tensor(63.9100), 320: tensor(68.2583), 330: tensor(80.5150), 340: tensor(92.5250), 350: tensor(97.5333)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=7, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.2142,                   Accuracy: 243/2000.0 (12.15%)



-= Testing valid =-
Test set: Average loss: 1.5504,                   Accuracy: 855/2000.0 (42.75%)



-= Testing valid =-
Test set: Average loss: 0.4585,                   Accuracy: 1724/2000.0 (86.20%)



-= Testing valid =-
Test set: Average loss: 0.3523,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.2375,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.6764,                   Accuracy: 1666/2000.0 (83.30%)



-= Testing valid =-
Test set: Average loss: 0.1663,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.2886,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.0585,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.1750,                   Accuracy: 1866/2000.0 (93.30%)



Epoch 10 train accuracy: 98.11%, valid accuracy 93.30%
-= Testing valid =-
Test set: Average loss: 0.1816,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0409,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0644,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 20 train accuracy: 99.21%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0408,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0378,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0400,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0445,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0289,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.50%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0312,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0347,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0276,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.74%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.70%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0526,                   Accuracy: 59116/60000 (98.53%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0900,                   Accuracy: 58538/60000 (97.56%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2003,                   Accuracy: 56653/60000 (94.42%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4873,                   Accuracy: 51952/60000 (86.59%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.8537,                   Accuracy: 45568/60000 (75.95%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.0734,                   Accuracy: 41405/60000 (69.01%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.9363,                   Accuracy: 42723/60000 (71.21%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.6196,                   Accuracy: 48316/60000 (80.53%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4380,                   Accuracy: 51408/60000 (85.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4049,                   Accuracy: 51653/60000 (86.09%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6976,                   Accuracy: 46491/60000 (77.49%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2246,                   Accuracy: 40299/60000 (67.17%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.0934,                   Accuracy: 32027/60000 (53.38%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.9835,                   Accuracy: 26839/60000 (44.73%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.3624,                   Accuracy: 25713/60000 (42.85%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.2225,                   Accuracy: 27581/60000 (45.97%)
-= Testing Rotation 160 =-
Test set: Average loss: 2.9181,                   Accuracy: 31045/60000 (51.74%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.8559,                   Accuracy: 32749/60000 (54.58%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.9720,                   Accuracy: 33397/60000 (55.66%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.0341,                   Accuracy: 32509/60000 (54.18%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.1079,                   Accuracy: 30635/60000 (51.06%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.2652,                   Accuracy: 27194/60000 (45.32%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.2088,                   Accuracy: 25152/60000 (41.92%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7411,                   Accuracy: 26662/60000 (44.44%)
-= Testing Rotation 240 =-
Test set: Average loss: 1.8522,                   Accuracy: 33239/60000 (55.40%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.0885,                   Accuracy: 41844/60000 (69.74%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5759,                   Accuracy: 49229/60000 (82.05%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3575,                   Accuracy: 53256/60000 (88.76%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4094,                   Accuracy: 52470/60000 (87.45%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.5955,                   Accuracy: 49152/60000 (81.92%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0177,                   Accuracy: 43522/60000 (72.54%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.1797,                   Accuracy: 41150/60000 (68.58%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.1355,                   Accuracy: 42911/60000 (71.52%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6534,                   Accuracy: 49431/60000 (82.39%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2167,                   Accuracy: 55944/60000 (93.24%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0794,                   Accuracy: 58537/60000 (97.56%)
{0: tensor(98.5267), 10: tensor(97.5633), 20: tensor(94.4217), 30: tensor(86.5867), 40: tensor(75.9467), 50: tensor(69.0083), 60: tensor(71.2050), 70: tensor(80.5267), 80: tensor(85.6800), 90: tensor(86.0883), 100: tensor(77.4850), 110: tensor(67.1650), 120: tensor(53.3783), 130: tensor(44.7317), 140: tensor(42.8550), 150: tensor(45.9683), 160: tensor(51.7417), 170: tensor(54.5817), 180: tensor(55.6617), 190: tensor(54.1817), 200: tensor(51.0583), 210: tensor(45.3233), 220: tensor(41.9200), 230: tensor(44.4367), 240: tensor(55.3983), 250: tensor(69.7400), 260: tensor(82.0483), 270: tensor(88.7600), 280: tensor(87.4500), 290: tensor(81.9200), 300: tensor(72.5367), 310: tensor(68.5833), 320: tensor(71.5183), 330: tensor(82.3850), 340: tensor(93.2400), 350: tensor(97.5617)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=8, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4677,                   Accuracy: 435/2000.0 (21.75%)



-= Testing valid =-
Test set: Average loss: 2.5240,                   Accuracy: 535/2000.0 (26.75%)



-= Testing valid =-
Test set: Average loss: 0.7882,                   Accuracy: 1492/2000.0 (74.60%)



-= Testing valid =-
Test set: Average loss: 0.2210,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.3122,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.2409,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.6058,                   Accuracy: 1735/2000.0 (86.75%)



-= Testing valid =-
Test set: Average loss: 0.2128,                   Accuracy: 1885/2000.0 (94.25%)



Epoch 10 train accuracy: 98.31%, valid accuracy 94.25%
-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0548,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0628,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0541,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 20 train accuracy: 99.10%, valid accuracy 98.70%
-= Testing valid =-
Test set: Average loss: 0.0275,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0334,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0304,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 30 train accuracy: 99.59%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0207,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0218,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0220,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0226,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0212,                   Accuracy: 1988/2000.0 (99.40%)



Epoch 40 train accuracy: 99.60%, valid accuracy 99.40%
-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0221,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0227,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0206,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0221,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0219,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0219,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 50 train accuracy: 99.69%, valid accuracy 99.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0515,                   Accuracy: 59094/60000 (98.49%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0774,                   Accuracy: 58679/60000 (97.80%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1737,                   Accuracy: 56980/60000 (94.97%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4706,                   Accuracy: 51757/60000 (86.26%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9898,                   Accuracy: 42565/60000 (70.94%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.3326,                   Accuracy: 36586/60000 (60.98%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.3168,                   Accuracy: 35680/60000 (59.47%)
-= Testing Rotation 70 =-
Test set: Average loss: 1.0614,                   Accuracy: 39726/60000 (66.21%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.8502,                   Accuracy: 43336/60000 (72.23%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.8571,                   Accuracy: 43105/60000 (71.84%)
-= Testing Rotation 100 =-
Test set: Average loss: 1.2985,                   Accuracy: 37884/60000 (63.14%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.9878,                   Accuracy: 31501/60000 (52.50%)
-= Testing Rotation 120 =-
Test set: Average loss: 3.0385,                   Accuracy: 23391/60000 (38.99%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.6589,                   Accuracy: 19572/60000 (32.62%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.9291,                   Accuracy: 19211/60000 (32.02%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8858,                   Accuracy: 21720/60000 (36.20%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.6235,                   Accuracy: 25050/60000 (41.75%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.6413,                   Accuracy: 26545/60000 (44.24%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.6887,                   Accuracy: 27072/60000 (45.12%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.6860,                   Accuracy: 26242/60000 (43.74%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.7866,                   Accuracy: 24457/60000 (40.76%)
-= Testing Rotation 210 =-
Test set: Average loss: 4.1113,                   Accuracy: 22011/60000 (36.69%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.9454,                   Accuracy: 20369/60000 (33.95%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.3734,                   Accuracy: 22053/60000 (36.76%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3851,                   Accuracy: 27383/60000 (45.64%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.4049,                   Accuracy: 36503/60000 (60.84%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.8596,                   Accuracy: 43353/60000 (72.25%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5217,                   Accuracy: 49680/60000 (82.80%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6908,                   Accuracy: 46391/60000 (77.32%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0314,                   Accuracy: 41494/60000 (69.16%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.6060,                   Accuracy: 34006/60000 (56.68%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.8302,                   Accuracy: 30842/60000 (51.40%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.6684,                   Accuracy: 33994/60000 (56.66%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.0363,                   Accuracy: 43207/60000 (72.01%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3749,                   Accuracy: 53359/60000 (88.93%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1118,                   Accuracy: 58010/60000 (96.68%)
{0: tensor(98.4900), 10: tensor(97.7983), 20: tensor(94.9667), 30: tensor(86.2617), 40: tensor(70.9417), 50: tensor(60.9767), 60: tensor(59.4667), 70: tensor(66.2100), 80: tensor(72.2267), 90: tensor(71.8417), 100: tensor(63.1400), 110: tensor(52.5017), 120: tensor(38.9850), 130: tensor(32.6200), 140: tensor(32.0183), 150: tensor(36.2000), 160: tensor(41.7500), 170: tensor(44.2417), 180: tensor(45.1200), 190: tensor(43.7367), 200: tensor(40.7617), 210: tensor(36.6850), 220: tensor(33.9483), 230: tensor(36.7550), 240: tensor(45.6383), 250: tensor(60.8383), 260: tensor(72.2550), 270: tensor(82.8000), 280: tensor(77.3183), 290: tensor(69.1567), 300: tensor(56.6767), 310: tensor(51.4033), 320: tensor(56.6567), 330: tensor(72.0117), 340: tensor(88.9317), 350: tensor(96.6833)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=9, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2900,                   Accuracy: 519/2000.0 (25.95%)



-= Testing valid =-
Test set: Average loss: 1.4858,                   Accuracy: 865/2000.0 (43.25%)



-= Testing valid =-
Test set: Average loss: 0.9034,                   Accuracy: 1426/2000.0 (71.30%)



-= Testing valid =-
Test set: Average loss: 0.2472,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2695,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.4922,                   Accuracy: 1699/2000.0 (84.95%)



-= Testing valid =-
Test set: Average loss: 0.1969,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.6303,                   Accuracy: 1622/2000.0 (81.10%)



-= Testing valid =-
Test set: Average loss: 0.1099,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 10 train accuracy: 97.66%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0668,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0454,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0458,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0520,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0660,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0580,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0473,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0802,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 20 train accuracy: 98.93%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0375,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0374,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0398,                   Accuracy: 1975/2000.0 (98.75%)



Epoch 30 train accuracy: 99.31%, valid accuracy 98.75%
-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0366,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0349,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.56%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 50 train accuracy: 99.53%, valid accuracy 99.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0590,                   Accuracy: 58958/60000 (98.26%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1179,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2453,                   Accuracy: 55947/60000 (93.25%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5529,                   Accuracy: 51209/60000 (85.35%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9780,                   Accuracy: 44562/60000 (74.27%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2468,                   Accuracy: 39950/60000 (66.58%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.1573,                   Accuracy: 40414/60000 (67.36%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.8938,                   Accuracy: 43567/60000 (72.61%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.6982,                   Accuracy: 46711/60000 (77.85%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6074,                   Accuracy: 48461/60000 (80.77%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9621,                   Accuracy: 43132/60000 (71.89%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5084,                   Accuracy: 36244/60000 (60.41%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2649,                   Accuracy: 28066/60000 (46.78%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.1185,                   Accuracy: 22340/60000 (37.23%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.5920,                   Accuracy: 20436/60000 (34.06%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.6332,                   Accuracy: 21576/60000 (35.96%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.6537,                   Accuracy: 23986/60000 (39.98%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.5617,                   Accuracy: 26494/60000 (44.16%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.4079,                   Accuracy: 29182/60000 (48.64%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.7984,                   Accuracy: 27577/60000 (45.96%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.8316,                   Accuracy: 26530/60000 (44.22%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.8874,                   Accuracy: 24629/60000 (41.05%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.7598,                   Accuracy: 23821/60000 (39.70%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1799,                   Accuracy: 26387/60000 (43.98%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.3064,                   Accuracy: 32166/60000 (53.61%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.5225,                   Accuracy: 38936/60000 (64.89%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.9545,                   Accuracy: 44579/60000 (74.30%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.5359,                   Accuracy: 50586/60000 (84.31%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.6512,                   Accuracy: 48693/60000 (81.15%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8760,                   Accuracy: 44748/60000 (74.58%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1294,                   Accuracy: 40613/60000 (67.69%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.4363,                   Accuracy: 36601/60000 (61.00%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.3107,                   Accuracy: 39450/60000 (65.75%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8391,                   Accuracy: 46792/60000 (77.99%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3292,                   Accuracy: 54417/60000 (90.69%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1146,                   Accuracy: 57863/60000 (96.44%)
{0: tensor(98.2633), 10: tensor(96.6183), 20: tensor(93.2450), 30: tensor(85.3483), 40: tensor(74.2700), 50: tensor(66.5833), 60: tensor(67.3567), 70: tensor(72.6117), 80: tensor(77.8517), 90: tensor(80.7683), 100: tensor(71.8867), 110: tensor(60.4067), 120: tensor(46.7767), 130: tensor(37.2333), 140: tensor(34.0600), 150: tensor(35.9600), 160: tensor(39.9767), 170: tensor(44.1567), 180: tensor(48.6367), 190: tensor(45.9617), 200: tensor(44.2167), 210: tensor(41.0483), 220: tensor(39.7017), 230: tensor(43.9783), 240: tensor(53.6100), 250: tensor(64.8933), 260: tensor(74.2983), 270: tensor(84.3100), 280: tensor(81.1550), 290: tensor(74.5800), 300: tensor(67.6883), 310: tensor(61.0017), 320: tensor(65.7500), 330: tensor(77.9867), 340: tensor(90.6950), 350: tensor(96.4383)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=10, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0192,                   Accuracy: 533/2000.0 (26.65%)



-= Testing valid =-
Test set: Average loss: 1.0737,                   Accuracy: 1229/2000.0 (61.45%)



-= Testing valid =-
Test set: Average loss: 1.5799,                   Accuracy: 1024/2000.0 (51.20%)



-= Testing valid =-
Test set: Average loss: 0.2485,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.8609,                   Accuracy: 1608/2000.0 (80.40%)



-= Testing valid =-
Test set: Average loss: 0.2291,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1654,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1290,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1115,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 10 train accuracy: 98.07%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0463,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0645,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.1042,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0507,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0587,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0568,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 20 train accuracy: 99.15%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0492,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0401,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0539,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0475,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 30 train accuracy: 99.55%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0403,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0405,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0428,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0423,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0391,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0364,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 40 train accuracy: 99.62%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0404,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0377,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0327,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0358,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0390,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 50 train accuracy: 99.78%, valid accuracy 99.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0493,                   Accuracy: 59155/60000 (98.59%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0787,                   Accuracy: 58630/60000 (97.72%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1903,                   Accuracy: 56828/60000 (94.71%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4721,                   Accuracy: 51959/60000 (86.60%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.9133,                   Accuracy: 44161/60000 (73.60%)
-= Testing Rotation 50 =-
Test set: Average loss: 1.2006,                   Accuracy: 39237/60000 (65.39%)
-= Testing Rotation 60 =-
Test set: Average loss: 1.0421,                   Accuracy: 41692/60000 (69.49%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.7505,                   Accuracy: 46535/60000 (77.56%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5353,                   Accuracy: 49753/60000 (82.92%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5570,                   Accuracy: 48516/60000 (80.86%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9430,                   Accuracy: 42002/60000 (70.00%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.6384,                   Accuracy: 33532/60000 (55.89%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.6854,                   Accuracy: 24239/60000 (40.40%)
-= Testing Rotation 130 =-
Test set: Average loss: 3.4365,                   Accuracy: 20256/60000 (33.76%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.7866,                   Accuracy: 20043/60000 (33.40%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.5963,                   Accuracy: 23250/60000 (38.75%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.2740,                   Accuracy: 28114/60000 (46.86%)
-= Testing Rotation 170 =-
Test set: Average loss: 3.1775,                   Accuracy: 31632/60000 (52.72%)
-= Testing Rotation 180 =-
Test set: Average loss: 3.4161,                   Accuracy: 32455/60000 (54.09%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.4023,                   Accuracy: 32010/60000 (53.35%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.4891,                   Accuracy: 30188/60000 (50.31%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.7631,                   Accuracy: 26349/60000 (43.92%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6905,                   Accuracy: 23906/60000 (39.84%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2015,                   Accuracy: 25306/60000 (42.18%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2436,                   Accuracy: 31985/60000 (53.31%)
-= Testing Rotation 250 =-
Test set: Average loss: 1.3257,                   Accuracy: 40617/60000 (67.69%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6929,                   Accuracy: 48341/60000 (80.57%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4384,                   Accuracy: 52100/60000 (86.83%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5091,                   Accuracy: 50434/60000 (84.06%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8331,                   Accuracy: 45201/60000 (75.33%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.3382,                   Accuracy: 39009/60000 (65.01%)
-= Testing Rotation 310 =-
Test set: Average loss: 1.5059,                   Accuracy: 36449/60000 (60.75%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.4977,                   Accuracy: 37945/60000 (63.24%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8529,                   Accuracy: 46544/60000 (77.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2904,                   Accuracy: 54824/60000 (91.37%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0870,                   Accuracy: 58444/60000 (97.41%)
{0: tensor(98.5917), 10: tensor(97.7167), 20: tensor(94.7133), 30: tensor(86.5983), 40: tensor(73.6017), 50: tensor(65.3950), 60: tensor(69.4867), 70: tensor(77.5583), 80: tensor(82.9217), 90: tensor(80.8600), 100: tensor(70.0033), 110: tensor(55.8867), 120: tensor(40.3983), 130: tensor(33.7600), 140: tensor(33.4050), 150: tensor(38.7500), 160: tensor(46.8567), 170: tensor(52.7200), 180: tensor(54.0917), 190: tensor(53.3500), 200: tensor(50.3133), 210: tensor(43.9150), 220: tensor(39.8433), 230: tensor(42.1767), 240: tensor(53.3083), 250: tensor(67.6950), 260: tensor(80.5683), 270: tensor(86.8333), 280: tensor(84.0567), 290: tensor(75.3350), 300: tensor(65.0150), 310: tensor(60.7483), 320: tensor(63.2417), 330: tensor(77.5733), 340: tensor(91.3733), 350: tensor(97.4067)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=1, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0361,                   Accuracy: 556/2000.0 (27.80%)



-= Testing valid =-
Test set: Average loss: 0.4251,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.2083,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.2316,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1853,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1151,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.2410,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.1119,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.0720,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 10 train accuracy: 97.93%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0571,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0531,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0642,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0483,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0388,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 20 train accuracy: 98.82%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0517,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0352,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0381,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0476,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 30 train accuracy: 99.20%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0337,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0262,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0362,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0269,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 40 train accuracy: 99.44%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0285,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0271,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0296,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0317,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0244,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 50 train accuracy: 99.55%, valid accuracy 99.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0547,                   Accuracy: 59115/60000 (98.53%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0962,                   Accuracy: 58469/60000 (97.45%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2397,                   Accuracy: 56253/60000 (93.75%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6884,                   Accuracy: 49121/60000 (81.87%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.5574,                   Accuracy: 38170/60000 (63.62%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.7137,                   Accuracy: 27579/60000 (45.97%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.9159,                   Accuracy: 18642/60000 (31.07%)
-= Testing Rotation 70 =-
Test set: Average loss: 5.0370,                   Accuracy: 13215/60000 (22.02%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.8415,                   Accuracy: 9895/60000 (16.49%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.2881,                   Accuracy: 9368/60000 (15.61%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.5619,                   Accuracy: 9348/60000 (15.58%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.8715,                   Accuracy: 9831/60000 (16.39%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.9071,                   Accuracy: 11484/60000 (19.14%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.6826,                   Accuracy: 14474/60000 (24.12%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.3191,                   Accuracy: 18194/60000 (30.32%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.2420,                   Accuracy: 22016/60000 (36.69%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.5525,                   Accuracy: 24976/60000 (41.63%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.9641,                   Accuracy: 26234/60000 (43.72%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.3047,                   Accuracy: 25923/60000 (43.21%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.2234,                   Accuracy: 25939/60000 (43.23%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.1934,                   Accuracy: 24430/60000 (40.72%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.8089,                   Accuracy: 21826/60000 (36.38%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.5699,                   Accuracy: 19186/60000 (31.98%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.5988,                   Accuracy: 16692/60000 (27.82%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.6480,                   Accuracy: 14040/60000 (23.40%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.8684,                   Accuracy: 12105/60000 (20.17%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.8497,                   Accuracy: 10669/60000 (17.78%)
-= Testing Rotation 270 =-
Test set: Average loss: 7.0384,                   Accuracy: 9156/60000 (15.26%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.9027,                   Accuracy: 8774/60000 (14.62%)
-= Testing Rotation 290 =-
Test set: Average loss: 6.6293,                   Accuracy: 8830/60000 (14.72%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.8994,                   Accuracy: 10965/60000 (18.27%)
-= Testing Rotation 310 =-
Test set: Average loss: 4.5501,                   Accuracy: 18414/60000 (30.69%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.8199,                   Accuracy: 30415/60000 (50.69%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.2466,                   Accuracy: 44402/60000 (74.00%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3485,                   Accuracy: 54608/60000 (91.01%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0958,                   Accuracy: 58398/60000 (97.33%)
{0: tensor(98.5250), 10: tensor(97.4483), 20: tensor(93.7550), 30: tensor(81.8683), 40: tensor(63.6167), 50: tensor(45.9650), 60: tensor(31.0700), 70: tensor(22.0250), 80: tensor(16.4917), 90: tensor(15.6133), 100: tensor(15.5800), 110: tensor(16.3850), 120: tensor(19.1400), 130: tensor(24.1233), 140: tensor(30.3233), 150: tensor(36.6933), 160: tensor(41.6267), 170: tensor(43.7233), 180: tensor(43.2050), 190: tensor(43.2317), 200: tensor(40.7167), 210: tensor(36.3767), 220: tensor(31.9767), 230: tensor(27.8200), 240: tensor(23.4000), 250: tensor(20.1750), 260: tensor(17.7817), 270: tensor(15.2600), 280: tensor(14.6233), 290: tensor(14.7167), 300: tensor(18.2750), 310: tensor(30.6900), 320: tensor(50.6917), 330: tensor(74.0033), 340: tensor(91.0133), 350: tensor(97.3300)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=2, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.2955,                   Accuracy: 1108/2000.0 (55.40%)



-= Testing valid =-
Test set: Average loss: 0.6853,                   Accuracy: 1563/2000.0 (78.15%)



-= Testing valid =-
Test set: Average loss: 0.3072,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.1241,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1900,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1742,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0877,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 10 train accuracy: 97.68%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0644,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0496,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0474,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0399,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0492,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0528,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 20 train accuracy: 98.96%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0385,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0455,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0487,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0479,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0413,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0410,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 30 train accuracy: 99.45%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0382,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0365,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0356,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 40 train accuracy: 99.64%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0277,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 50 train accuracy: 99.69%, valid accuracy 98.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0481,                   Accuracy: 59177/60000 (98.63%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0769,                   Accuracy: 58692/60000 (97.82%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1914,                   Accuracy: 56900/60000 (94.83%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5697,                   Accuracy: 50917/60000 (84.86%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.3502,                   Accuracy: 41418/60000 (69.03%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.3948,                   Accuracy: 31867/60000 (53.11%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.6875,                   Accuracy: 22725/60000 (37.88%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.6584,                   Accuracy: 17052/60000 (28.42%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.2791,                   Accuracy: 13593/60000 (22.66%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.8346,                   Accuracy: 12023/60000 (20.04%)
-= Testing Rotation 100 =-
Test set: Average loss: 6.1714,                   Accuracy: 10488/60000 (17.48%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.2613,                   Accuracy: 10458/60000 (17.43%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.2422,                   Accuracy: 11537/60000 (19.23%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.2368,                   Accuracy: 14762/60000 (24.60%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.0275,                   Accuracy: 18424/60000 (30.71%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.8155,                   Accuracy: 21893/60000 (36.49%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.0200,                   Accuracy: 24992/60000 (41.65%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.4056,                   Accuracy: 26403/60000 (44.01%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.0780,                   Accuracy: 26467/60000 (44.11%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.9435,                   Accuracy: 26551/60000 (44.25%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.9425,                   Accuracy: 25078/60000 (41.80%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.8579,                   Accuracy: 22372/60000 (37.29%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.7532,                   Accuracy: 20168/60000 (33.61%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.7474,                   Accuracy: 18006/60000 (30.01%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.7771,                   Accuracy: 15876/60000 (26.46%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.8006,                   Accuracy: 13330/60000 (22.22%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.6463,                   Accuracy: 11886/60000 (19.81%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.6942,                   Accuracy: 9687/60000 (16.15%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.4905,                   Accuracy: 8499/60000 (14.16%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.7928,                   Accuracy: 8665/60000 (14.44%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.8444,                   Accuracy: 12105/60000 (20.17%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.5435,                   Accuracy: 20090/60000 (33.48%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.0702,                   Accuracy: 32473/60000 (54.12%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8962,                   Accuracy: 45900/60000 (76.50%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2610,                   Accuracy: 55256/60000 (92.09%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0755,                   Accuracy: 58654/60000 (97.76%)
{0: tensor(98.6283), 10: tensor(97.8200), 20: tensor(94.8333), 30: tensor(84.8617), 40: tensor(69.0300), 50: tensor(53.1117), 60: tensor(37.8750), 70: tensor(28.4200), 80: tensor(22.6550), 90: tensor(20.0383), 100: tensor(17.4800), 110: tensor(17.4300), 120: tensor(19.2283), 130: tensor(24.6033), 140: tensor(30.7067), 150: tensor(36.4883), 160: tensor(41.6533), 170: tensor(44.0050), 180: tensor(44.1117), 190: tensor(44.2517), 200: tensor(41.7967), 210: tensor(37.2867), 220: tensor(33.6133), 230: tensor(30.0100), 240: tensor(26.4600), 250: tensor(22.2167), 260: tensor(19.8100), 270: tensor(16.1450), 280: tensor(14.1650), 290: tensor(14.4417), 300: tensor(20.1750), 310: tensor(33.4833), 320: tensor(54.1217), 330: tensor(76.5000), 340: tensor(92.0933), 350: tensor(97.7567)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=3, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0898,                   Accuracy: 326/2000.0 (16.30%)



-= Testing valid =-
Test set: Average loss: 0.5749,                   Accuracy: 1606/2000.0 (80.30%)



-= Testing valid =-
Test set: Average loss: 0.2511,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.5377,                   Accuracy: 1683/2000.0 (84.15%)



-= Testing valid =-
Test set: Average loss: 0.2929,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2401,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.1596,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1893,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1200,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 10 train accuracy: 97.97%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1355,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.0695,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0553,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0657,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0521,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1061,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1180,                   Accuracy: 1923/2000.0 (96.15%)



Epoch 20 train accuracy: 98.96%, valid accuracy 96.15%
-= Testing valid =-
Test set: Average loss: 0.0419,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0518,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0480,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0499,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0535,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0468,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0467,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0535,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 30 train accuracy: 99.22%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0505,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0438,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0492,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0466,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0490,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0461,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0574,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0432,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0456,                   Accuracy: 1963/2000.0 (98.15%)



Epoch 40 train accuracy: 99.47%, valid accuracy 98.15%
-= Testing valid =-
Test set: Average loss: 0.0484,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0462,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0470,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0446,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0407,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0526,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0431,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0502,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 50 train accuracy: 99.61%, valid accuracy 98.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0626,                   Accuracy: 58954/60000 (98.26%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0964,                   Accuracy: 58379/60000 (97.30%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2320,                   Accuracy: 56187/60000 (93.64%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6675,                   Accuracy: 49514/60000 (82.52%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4458,                   Accuracy: 39581/60000 (65.97%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.5569,                   Accuracy: 28932/60000 (48.22%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.7765,                   Accuracy: 20688/60000 (34.48%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.5215,                   Accuracy: 15319/60000 (25.53%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.1193,                   Accuracy: 11789/60000 (19.65%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.7710,                   Accuracy: 10435/60000 (17.39%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.9106,                   Accuracy: 10113/60000 (16.85%)
-= Testing Rotation 110 =-
Test set: Average loss: 6.2795,                   Accuracy: 10109/60000 (16.85%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.5726,                   Accuracy: 11611/60000 (19.35%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.4195,                   Accuracy: 14876/60000 (24.79%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.4081,                   Accuracy: 19191/60000 (31.99%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.5363,                   Accuracy: 23171/60000 (38.62%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.6801,                   Accuracy: 26076/60000 (43.46%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.8336,                   Accuracy: 27731/60000 (46.22%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.2651,                   Accuracy: 27731/60000 (46.22%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.9056,                   Accuracy: 27602/60000 (46.00%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.9111,                   Accuracy: 25584/60000 (42.64%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.9407,                   Accuracy: 22048/60000 (36.75%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.7976,                   Accuracy: 18933/60000 (31.56%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.8659,                   Accuracy: 16403/60000 (27.34%)
-= Testing Rotation 240 =-
Test set: Average loss: 7.0139,                   Accuracy: 13971/60000 (23.28%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.9461,                   Accuracy: 12371/60000 (20.62%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.8711,                   Accuracy: 11027/60000 (18.38%)
-= Testing Rotation 270 =-
Test set: Average loss: 7.0399,                   Accuracy: 9664/60000 (16.11%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.6814,                   Accuracy: 9009/60000 (15.02%)
-= Testing Rotation 290 =-
Test set: Average loss: 6.2118,                   Accuracy: 9376/60000 (15.63%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.4305,                   Accuracy: 11837/60000 (19.73%)
-= Testing Rotation 310 =-
Test set: Average loss: 4.0551,                   Accuracy: 19371/60000 (32.28%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.3440,                   Accuracy: 32450/60000 (54.08%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.0175,                   Accuracy: 46192/60000 (76.99%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3149,                   Accuracy: 54966/60000 (91.61%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0879,                   Accuracy: 58489/60000 (97.48%)
{0: tensor(98.2567), 10: tensor(97.2983), 20: tensor(93.6450), 30: tensor(82.5233), 40: tensor(65.9683), 50: tensor(48.2200), 60: tensor(34.4800), 70: tensor(25.5317), 80: tensor(19.6483), 90: tensor(17.3917), 100: tensor(16.8550), 110: tensor(16.8483), 120: tensor(19.3517), 130: tensor(24.7933), 140: tensor(31.9850), 150: tensor(38.6183), 160: tensor(43.4600), 170: tensor(46.2183), 180: tensor(46.2183), 190: tensor(46.0033), 200: tensor(42.6400), 210: tensor(36.7467), 220: tensor(31.5550), 230: tensor(27.3383), 240: tensor(23.2850), 250: tensor(20.6183), 260: tensor(18.3783), 270: tensor(16.1067), 280: tensor(15.0150), 290: tensor(15.6267), 300: tensor(19.7283), 310: tensor(32.2850), 320: tensor(54.0833), 330: tensor(76.9867), 340: tensor(91.6100), 350: tensor(97.4817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=4, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.6526,                   Accuracy: 758/2000.0 (37.90%)



-= Testing valid =-
Test set: Average loss: 0.3574,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.1813,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.3217,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1190,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1805,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 10 train accuracy: 98.30%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0371,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0440,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0321,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0340,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0256,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 20 train accuracy: 98.94%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0392,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0252,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0207,                   Accuracy: 1985/2000.0 (99.25%)



Epoch 30 train accuracy: 99.39%, valid accuracy 99.25%
-= Testing valid =-
Test set: Average loss: 0.0200,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0187,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0188,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0204,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0202,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0203,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0194,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0189,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0212,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 40 train accuracy: 99.57%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0188,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0200,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0180,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0188,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0178,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0174,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0182,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0184,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0164,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0174,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 50 train accuracy: 99.56%, valid accuracy 99.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0453,                   Accuracy: 59194/60000 (98.66%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0860,                   Accuracy: 58543/60000 (97.57%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2153,                   Accuracy: 56533/60000 (94.22%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5915,                   Accuracy: 51044/60000 (85.07%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4375,                   Accuracy: 40625/60000 (67.71%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.5709,                   Accuracy: 29255/60000 (48.76%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.7221,                   Accuracy: 19230/60000 (32.05%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.5049,                   Accuracy: 13168/60000 (21.95%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.8481,                   Accuracy: 10494/60000 (17.49%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.2954,                   Accuracy: 9886/60000 (16.48%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.3408,                   Accuracy: 10297/60000 (17.16%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.7269,                   Accuracy: 10385/60000 (17.31%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.9255,                   Accuracy: 11379/60000 (18.97%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.9056,                   Accuracy: 14217/60000 (23.69%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.9053,                   Accuracy: 18156/60000 (30.26%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.9206,                   Accuracy: 21864/60000 (36.44%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.2691,                   Accuracy: 24421/60000 (40.70%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.7191,                   Accuracy: 26103/60000 (43.51%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.1689,                   Accuracy: 26398/60000 (44.00%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.0426,                   Accuracy: 26204/60000 (43.67%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.1814,                   Accuracy: 24111/60000 (40.19%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.9142,                   Accuracy: 21195/60000 (35.33%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.7957,                   Accuracy: 18160/60000 (30.27%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.7917,                   Accuracy: 16239/60000 (27.07%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.6392,                   Accuracy: 14389/60000 (23.98%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.4173,                   Accuracy: 12797/60000 (21.33%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.0793,                   Accuracy: 12126/60000 (20.21%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.9807,                   Accuracy: 10483/60000 (17.47%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.5238,                   Accuracy: 9796/60000 (16.33%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.1873,                   Accuracy: 9465/60000 (15.77%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.5072,                   Accuracy: 12269/60000 (20.45%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.4282,                   Accuracy: 20326/60000 (33.88%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1003,                   Accuracy: 32745/60000 (54.58%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9111,                   Accuracy: 46200/60000 (77.00%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2647,                   Accuracy: 55320/60000 (92.20%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0825,                   Accuracy: 58510/60000 (97.52%)
{0: tensor(98.6567), 10: tensor(97.5717), 20: tensor(94.2217), 30: tensor(85.0733), 40: tensor(67.7083), 50: tensor(48.7583), 60: tensor(32.0500), 70: tensor(21.9467), 80: tensor(17.4900), 90: tensor(16.4767), 100: tensor(17.1617), 110: tensor(17.3083), 120: tensor(18.9650), 130: tensor(23.6950), 140: tensor(30.2600), 150: tensor(36.4400), 160: tensor(40.7017), 170: tensor(43.5050), 180: tensor(43.9967), 190: tensor(43.6733), 200: tensor(40.1850), 210: tensor(35.3250), 220: tensor(30.2667), 230: tensor(27.0650), 240: tensor(23.9817), 250: tensor(21.3283), 260: tensor(20.2100), 270: tensor(17.4717), 280: tensor(16.3267), 290: tensor(15.7750), 300: tensor(20.4483), 310: tensor(33.8767), 320: tensor(54.5750), 330: tensor(77.), 340: tensor(92.2000), 350: tensor(97.5167)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=5, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7079,                   Accuracy: 683/2000.0 (34.15%)



-= Testing valid =-
Test set: Average loss: 0.2758,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2879,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.1424,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.2959,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.1465,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1417,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1252,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.0686,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0452,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 10 train accuracy: 97.91%, valid accuracy 98.35%
-= Testing valid =-
Test set: Average loss: 0.0573,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0273,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0338,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0372,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 20 train accuracy: 98.94%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0223,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0221,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0187,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0245,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0243,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0249,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 30 train accuracy: 99.32%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0208,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0168,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0180,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0259,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0205,                   Accuracy: 1987/2000.0 (99.35%)



Epoch 40 train accuracy: 99.61%, valid accuracy 99.35%
-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0201,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0229,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0212,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0201,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0181,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0206,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1983/2000.0 (99.15%)



Epoch 50 train accuracy: 99.66%, valid accuracy 99.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0518,                   Accuracy: 59122/60000 (98.54%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0819,                   Accuracy: 58612/60000 (97.69%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1764,                   Accuracy: 57110/60000 (95.18%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4787,                   Accuracy: 52226/60000 (87.04%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.1387,                   Accuracy: 42469/60000 (70.78%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.0445,                   Accuracy: 31660/60000 (52.77%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.1633,                   Accuracy: 21483/60000 (35.81%)
-= Testing Rotation 70 =-
Test set: Average loss: 3.9938,                   Accuracy: 14965/60000 (24.94%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.5722,                   Accuracy: 11780/60000 (19.63%)
-= Testing Rotation 90 =-
Test set: Average loss: 4.9828,                   Accuracy: 12028/60000 (20.05%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.3415,                   Accuracy: 11999/60000 (20.00%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.8783,                   Accuracy: 12769/60000 (21.28%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.3111,                   Accuracy: 14500/60000 (24.17%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.5406,                   Accuracy: 17260/60000 (28.77%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.4270,                   Accuracy: 20286/60000 (33.81%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.0987,                   Accuracy: 23273/60000 (38.79%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.0646,                   Accuracy: 25565/60000 (42.61%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.1568,                   Accuracy: 26490/60000 (44.15%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.6567,                   Accuracy: 26363/60000 (43.94%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.5509,                   Accuracy: 26607/60000 (44.35%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.5870,                   Accuracy: 25609/60000 (42.68%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.6015,                   Accuracy: 22455/60000 (37.42%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.3930,                   Accuracy: 19012/60000 (31.69%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.1802,                   Accuracy: 16638/60000 (27.73%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.9683,                   Accuracy: 14596/60000 (24.33%)
-= Testing Rotation 250 =-
Test set: Average loss: 5.7628,                   Accuracy: 12819/60000 (21.36%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.5289,                   Accuracy: 11827/60000 (19.71%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.3801,                   Accuracy: 12201/60000 (20.33%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.2803,                   Accuracy: 10939/60000 (18.23%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.0291,                   Accuracy: 11618/60000 (19.36%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.4375,                   Accuracy: 14383/60000 (23.97%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.4029,                   Accuracy: 21756/60000 (36.26%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.0413,                   Accuracy: 33605/60000 (56.01%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9134,                   Accuracy: 46576/60000 (77.63%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2931,                   Accuracy: 55102/60000 (91.84%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0924,                   Accuracy: 58362/60000 (97.27%)
{0: tensor(98.5367), 10: tensor(97.6867), 20: tensor(95.1833), 30: tensor(87.0433), 40: tensor(70.7817), 50: tensor(52.7667), 60: tensor(35.8050), 70: tensor(24.9417), 80: tensor(19.6333), 90: tensor(20.0467), 100: tensor(19.9983), 110: tensor(21.2817), 120: tensor(24.1667), 130: tensor(28.7667), 140: tensor(33.8100), 150: tensor(38.7883), 160: tensor(42.6083), 170: tensor(44.1500), 180: tensor(43.9383), 190: tensor(44.3450), 200: tensor(42.6817), 210: tensor(37.4250), 220: tensor(31.6867), 230: tensor(27.7300), 240: tensor(24.3267), 250: tensor(21.3650), 260: tensor(19.7117), 270: tensor(20.3350), 280: tensor(18.2317), 290: tensor(19.3633), 300: tensor(23.9717), 310: tensor(36.2600), 320: tensor(56.0083), 330: tensor(77.6267), 340: tensor(91.8367), 350: tensor(97.2700)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=6, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0802,                   Accuracy: 758/2000.0 (37.90%)



-= Testing valid =-
Test set: Average loss: 0.2304,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.2572,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.3343,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.2296,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.3476,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0450,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 10 train accuracy: 97.99%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0678,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0598,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0562,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0576,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0680,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0343,                   Accuracy: 1976/2000.0 (98.80%)



Epoch 20 train accuracy: 99.01%, valid accuracy 98.80%
-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0279,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0437,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0421,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0422,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0246,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0198,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0166,                   Accuracy: 1990/2000.0 (99.50%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1988/2000.0 (99.40%)



Epoch 30 train accuracy: 99.40%, valid accuracy 99.40%
-= Testing valid =-
Test set: Average loss: 0.0397,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0207,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0254,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0333,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0213,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0199,                   Accuracy: 1991/2000.0 (99.55%)



-= Testing valid =-
Test set: Average loss: 0.0236,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.53%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0200,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0241,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0267,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0220,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0306,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0190,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0248,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 50 train accuracy: 99.62%, valid accuracy 99.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0564,                   Accuracy: 59059/60000 (98.43%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0896,                   Accuracy: 58520/60000 (97.53%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2207,                   Accuracy: 56459/60000 (94.10%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7224,                   Accuracy: 49060/60000 (81.77%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4607,                   Accuracy: 39810/60000 (66.35%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.4817,                   Accuracy: 29505/60000 (49.17%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.7010,                   Accuracy: 19576/60000 (32.63%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.4296,                   Accuracy: 13727/60000 (22.88%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.9280,                   Accuracy: 10500/60000 (17.50%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.2614,                   Accuracy: 9656/60000 (16.09%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.2859,                   Accuracy: 10160/60000 (16.93%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.3833,                   Accuracy: 11730/60000 (19.55%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.4287,                   Accuracy: 13584/60000 (22.64%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.5093,                   Accuracy: 16235/60000 (27.06%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.5445,                   Accuracy: 19643/60000 (32.74%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.6470,                   Accuracy: 23525/60000 (39.21%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.0741,                   Accuracy: 25857/60000 (43.10%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.4461,                   Accuracy: 26951/60000 (44.92%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.9363,                   Accuracy: 26915/60000 (44.86%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.7448,                   Accuracy: 27056/60000 (45.09%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.7154,                   Accuracy: 24975/60000 (41.62%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.6447,                   Accuracy: 21675/60000 (36.12%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.5279,                   Accuracy: 19692/60000 (32.82%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.5639,                   Accuracy: 17122/60000 (28.54%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.6664,                   Accuracy: 14243/60000 (23.74%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.6363,                   Accuracy: 12496/60000 (20.83%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.5686,                   Accuracy: 9942/60000 (16.57%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.4081,                   Accuracy: 9385/60000 (15.64%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.9842,                   Accuracy: 9866/60000 (16.44%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.4144,                   Accuracy: 11298/60000 (18.83%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.4268,                   Accuracy: 15044/60000 (25.07%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.0994,                   Accuracy: 23512/60000 (39.19%)
-= Testing Rotation 320 =-
Test set: Average loss: 1.7126,                   Accuracy: 36087/60000 (60.15%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.6746,                   Accuracy: 48829/60000 (81.38%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2077,                   Accuracy: 56276/60000 (93.79%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0759,                   Accuracy: 58649/60000 (97.75%)
{0: tensor(98.4317), 10: tensor(97.5333), 20: tensor(94.0983), 30: tensor(81.7667), 40: tensor(66.3500), 50: tensor(49.1750), 60: tensor(32.6267), 70: tensor(22.8783), 80: tensor(17.5000), 90: tensor(16.0933), 100: tensor(16.9333), 110: tensor(19.5500), 120: tensor(22.6400), 130: tensor(27.0583), 140: tensor(32.7383), 150: tensor(39.2083), 160: tensor(43.0950), 170: tensor(44.9183), 180: tensor(44.8583), 190: tensor(45.0933), 200: tensor(41.6250), 210: tensor(36.1250), 220: tensor(32.8200), 230: tensor(28.5367), 240: tensor(23.7383), 250: tensor(20.8267), 260: tensor(16.5700), 270: tensor(15.6417), 280: tensor(16.4433), 290: tensor(18.8300), 300: tensor(25.0733), 310: tensor(39.1867), 320: tensor(60.1450), 330: tensor(81.3817), 340: tensor(93.7933), 350: tensor(97.7483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=7, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.4342,                   Accuracy: 885/2000.0 (44.25%)



-= Testing valid =-
Test set: Average loss: 0.2360,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.1438,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1762,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1928,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1076,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1771,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.0543,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1970/2000.0 (98.50%)



Epoch 10 train accuracy: 98.18%, valid accuracy 98.50%
-= Testing valid =-
Test set: Average loss: 0.0482,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0386,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0460,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0415,                   Accuracy: 1973/2000.0 (98.65%)



-= Testing valid =-
Test set: Average loss: 0.0449,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0598,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0402,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0620,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0313,                   Accuracy: 1978/2000.0 (98.90%)



Epoch 20 train accuracy: 98.71%, valid accuracy 98.90%
-= Testing valid =-
Test set: Average loss: 0.0326,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0309,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0396,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0308,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0370,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1984/2000.0 (99.20%)



Epoch 30 train accuracy: 99.19%, valid accuracy 99.20%
-= Testing valid =-
Test set: Average loss: 0.0242,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0330,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0282,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0283,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0324,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0265,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.50%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0237,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0211,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0272,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0266,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0261,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0215,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0315,                   Accuracy: 1979/2000.0 (98.95%)



Epoch 50 train accuracy: 99.69%, valid accuracy 98.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0605,                   Accuracy: 59022/60000 (98.37%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0967,                   Accuracy: 58349/60000 (97.25%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2579,                   Accuracy: 55922/60000 (93.20%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.7705,                   Accuracy: 48387/60000 (80.64%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.7398,                   Accuracy: 37066/60000 (61.78%)
-= Testing Rotation 50 =-
Test set: Average loss: 3.0524,                   Accuracy: 25974/60000 (43.29%)
-= Testing Rotation 60 =-
Test set: Average loss: 4.4352,                   Accuracy: 17616/60000 (29.36%)
-= Testing Rotation 70 =-
Test set: Average loss: 5.3211,                   Accuracy: 12793/60000 (21.32%)
-= Testing Rotation 80 =-
Test set: Average loss: 5.8365,                   Accuracy: 10856/60000 (18.09%)
-= Testing Rotation 90 =-
Test set: Average loss: 6.1150,                   Accuracy: 10178/60000 (16.96%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.8927,                   Accuracy: 11703/60000 (19.50%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.8665,                   Accuracy: 11567/60000 (19.28%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.9884,                   Accuracy: 11710/60000 (19.52%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.9021,                   Accuracy: 14443/60000 (24.07%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.7997,                   Accuracy: 18367/60000 (30.61%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.9116,                   Accuracy: 22054/60000 (36.76%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.2802,                   Accuracy: 24707/60000 (41.18%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.8517,                   Accuracy: 26168/60000 (43.61%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.4137,                   Accuracy: 25768/60000 (42.95%)
-= Testing Rotation 190 =-
Test set: Average loss: 7.1201,                   Accuracy: 25903/60000 (43.17%)
-= Testing Rotation 200 =-
Test set: Average loss: 7.0114,                   Accuracy: 24020/60000 (40.03%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.8898,                   Accuracy: 21085/60000 (35.14%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.7196,                   Accuracy: 18550/60000 (30.92%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.6421,                   Accuracy: 15809/60000 (26.35%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.7527,                   Accuracy: 13497/60000 (22.50%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.7835,                   Accuracy: 11786/60000 (19.64%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.5605,                   Accuracy: 10944/60000 (18.24%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.3675,                   Accuracy: 9816/60000 (16.36%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.9215,                   Accuracy: 9811/60000 (16.35%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.3115,                   Accuracy: 10574/60000 (17.62%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.6440,                   Accuracy: 12679/60000 (21.13%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.5238,                   Accuracy: 19767/60000 (32.94%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1138,                   Accuracy: 32496/60000 (54.16%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.8866,                   Accuracy: 46545/60000 (77.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2579,                   Accuracy: 55631/60000 (92.72%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0815,                   Accuracy: 58611/60000 (97.68%)
{0: tensor(98.3700), 10: tensor(97.2483), 20: tensor(93.2033), 30: tensor(80.6450), 40: tensor(61.7767), 50: tensor(43.2900), 60: tensor(29.3600), 70: tensor(21.3217), 80: tensor(18.0933), 90: tensor(16.9633), 100: tensor(19.5050), 110: tensor(19.2783), 120: tensor(19.5167), 130: tensor(24.0717), 140: tensor(30.6117), 150: tensor(36.7567), 160: tensor(41.1783), 170: tensor(43.6133), 180: tensor(42.9467), 190: tensor(43.1717), 200: tensor(40.0333), 210: tensor(35.1417), 220: tensor(30.9167), 230: tensor(26.3483), 240: tensor(22.4950), 250: tensor(19.6433), 260: tensor(18.2400), 270: tensor(16.3600), 280: tensor(16.3517), 290: tensor(17.6233), 300: tensor(21.1317), 310: tensor(32.9450), 320: tensor(54.1600), 330: tensor(77.5750), 340: tensor(92.7183), 350: tensor(97.6850)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=8, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.3341,                   Accuracy: 1075/2000.0 (53.75%)



-= Testing valid =-
Test set: Average loss: 0.4026,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.2270,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.1119,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1517,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1354,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1780,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1478,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 10 train accuracy: 97.95%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.0500,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0524,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0418,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0508,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.1085,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0493,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0434,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0442,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 20 train accuracy: 98.95%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0359,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0353,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0393,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0307,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0339,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0325,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0328,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0496,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 30 train accuracy: 99.43%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0314,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0335,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0270,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0281,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0292,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0323,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1980/2000.0 (99.00%)



Epoch 40 train accuracy: 99.45%, valid accuracy 99.00%
-= Testing valid =-
Test set: Average loss: 0.0288,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0293,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0300,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0274,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0291,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 50 train accuracy: 99.62%, valid accuracy 99.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0438,                   Accuracy: 59268/60000 (98.78%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0754,                   Accuracy: 58726/60000 (97.88%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1960,                   Accuracy: 56707/60000 (94.51%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.6482,                   Accuracy: 49810/60000 (83.02%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.4596,                   Accuracy: 39509/60000 (65.85%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.5344,                   Accuracy: 29197/60000 (48.66%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.7063,                   Accuracy: 20137/60000 (33.56%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.3018,                   Accuracy: 15503/60000 (25.84%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.7818,                   Accuracy: 12132/60000 (20.22%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.1964,                   Accuracy: 10570/60000 (17.62%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.4305,                   Accuracy: 10278/60000 (17.13%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.7916,                   Accuracy: 9963/60000 (16.60%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.9996,                   Accuracy: 11279/60000 (18.80%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.8937,                   Accuracy: 14117/60000 (23.53%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.6982,                   Accuracy: 17338/60000 (28.90%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.6541,                   Accuracy: 21229/60000 (35.38%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.8860,                   Accuracy: 24431/60000 (40.72%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.2662,                   Accuracy: 25540/60000 (42.57%)
-= Testing Rotation 180 =-
Test set: Average loss: 6.9773,                   Accuracy: 25497/60000 (42.49%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.7354,                   Accuracy: 25347/60000 (42.24%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.5030,                   Accuracy: 24397/60000 (40.66%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.2977,                   Accuracy: 22327/60000 (37.21%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.0101,                   Accuracy: 20244/60000 (33.74%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.9899,                   Accuracy: 17767/60000 (29.61%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.1762,                   Accuracy: 15240/60000 (25.40%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.2060,                   Accuracy: 13241/60000 (22.07%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.1887,                   Accuracy: 11802/60000 (19.67%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.3486,                   Accuracy: 10500/60000 (17.50%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.1956,                   Accuracy: 9571/60000 (15.95%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.8024,                   Accuracy: 9424/60000 (15.71%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.0438,                   Accuracy: 12510/60000 (20.85%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.7515,                   Accuracy: 20112/60000 (33.52%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.2195,                   Accuracy: 32242/60000 (53.74%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9080,                   Accuracy: 46497/60000 (77.50%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2621,                   Accuracy: 55614/60000 (92.69%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0808,                   Accuracy: 58620/60000 (97.70%)
{0: tensor(98.7800), 10: tensor(97.8767), 20: tensor(94.5117), 30: tensor(83.0167), 40: tensor(65.8483), 50: tensor(48.6617), 60: tensor(33.5617), 70: tensor(25.8383), 80: tensor(20.2200), 90: tensor(17.6167), 100: tensor(17.1300), 110: tensor(16.6050), 120: tensor(18.7983), 130: tensor(23.5283), 140: tensor(28.8967), 150: tensor(35.3817), 160: tensor(40.7183), 170: tensor(42.5667), 180: tensor(42.4950), 190: tensor(42.2450), 200: tensor(40.6617), 210: tensor(37.2117), 220: tensor(33.7400), 230: tensor(29.6117), 240: tensor(25.4000), 250: tensor(22.0683), 260: tensor(19.6700), 270: tensor(17.5000), 280: tensor(15.9517), 290: tensor(15.7067), 300: tensor(20.8500), 310: tensor(33.5200), 320: tensor(53.7367), 330: tensor(77.4950), 340: tensor(92.6900), 350: tensor(97.7000)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=9, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.6624,                   Accuracy: 658/2000.0 (32.90%)



-= Testing valid =-
Test set: Average loss: 0.5770,                   Accuracy: 1661/2000.0 (83.05%)



-= Testing valid =-
Test set: Average loss: 0.1554,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1036,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1602,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.3114,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.0564,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.2984,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0648,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 10 train accuracy: 97.76%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0433,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0278,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0336,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0491,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0406,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0344,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0342,                   Accuracy: 1977/2000.0 (98.85%)



Epoch 20 train accuracy: 99.01%, valid accuracy 98.85%
-= Testing valid =-
Test set: Average loss: 0.0320,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0355,                   Accuracy: 1978/2000.0 (98.90%)



-= Testing valid =-
Test set: Average loss: 0.0316,                   Accuracy: 1979/2000.0 (98.95%)



-= Testing valid =-
Test set: Average loss: 0.0263,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0287,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1977/2000.0 (98.85%)



-= Testing valid =-
Test set: Average loss: 0.0280,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0286,                   Accuracy: 1982/2000.0 (99.10%)



-= Testing valid =-
Test set: Average loss: 0.0319,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0209,                   Accuracy: 1982/2000.0 (99.10%)



Epoch 30 train accuracy: 99.22%, valid accuracy 99.10%
-= Testing valid =-
Test set: Average loss: 0.0238,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0212,                   Accuracy: 1984/2000.0 (99.20%)



-= Testing valid =-
Test set: Average loss: 0.0228,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0258,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0204,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0257,                   Accuracy: 1980/2000.0 (99.00%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1983/2000.0 (99.15%)



-= Testing valid =-
Test set: Average loss: 0.0250,                   Accuracy: 1981/2000.0 (99.05%)



-= Testing valid =-
Test set: Average loss: 0.0234,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0235,                   Accuracy: 1981/2000.0 (99.05%)



Epoch 40 train accuracy: 99.47%, valid accuracy 99.05%
-= Testing valid =-
Test set: Average loss: 0.0216,                   Accuracy: 1986/2000.0 (99.30%)



-= Testing valid =-
Test set: Average loss: 0.0224,                   Accuracy: 1988/2000.0 (99.40%)



-= Testing valid =-
Test set: Average loss: 0.0210,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0208,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0208,                   Accuracy: 1985/2000.0 (99.25%)



-= Testing valid =-
Test set: Average loss: 0.0206,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0206,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0200,                   Accuracy: 1987/2000.0 (99.35%)



-= Testing valid =-
Test set: Average loss: 0.0192,                   Accuracy: 1989/2000.0 (99.45%)



-= Testing valid =-
Test set: Average loss: 0.0186,                   Accuracy: 1988/2000.0 (99.40%)



Epoch 50 train accuracy: 99.66%, valid accuracy 99.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0501,                   Accuracy: 59130/60000 (98.55%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0762,                   Accuracy: 58717/60000 (97.86%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1776,                   Accuracy: 57111/60000 (95.18%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5450,                   Accuracy: 51289/60000 (85.48%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.2850,                   Accuracy: 41518/60000 (69.20%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.2645,                   Accuracy: 31243/60000 (52.07%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.3544,                   Accuracy: 21532/60000 (35.89%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.1577,                   Accuracy: 15067/60000 (25.11%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.7687,                   Accuracy: 11258/60000 (18.76%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.1758,                   Accuracy: 10481/60000 (17.47%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.4636,                   Accuracy: 9843/60000 (16.41%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.9279,                   Accuracy: 10487/60000 (17.48%)
-= Testing Rotation 120 =-
Test set: Average loss: 6.4411,                   Accuracy: 12564/60000 (20.94%)
-= Testing Rotation 130 =-
Test set: Average loss: 6.7487,                   Accuracy: 15835/60000 (26.39%)
-= Testing Rotation 140 =-
Test set: Average loss: 6.8178,                   Accuracy: 19204/60000 (32.01%)
-= Testing Rotation 150 =-
Test set: Average loss: 6.7119,                   Accuracy: 22521/60000 (37.53%)
-= Testing Rotation 160 =-
Test set: Average loss: 6.7414,                   Accuracy: 25192/60000 (41.99%)
-= Testing Rotation 170 =-
Test set: Average loss: 6.9465,                   Accuracy: 26888/60000 (44.81%)
-= Testing Rotation 180 =-
Test set: Average loss: 7.2789,                   Accuracy: 26894/60000 (44.82%)
-= Testing Rotation 190 =-
Test set: Average loss: 6.8098,                   Accuracy: 26866/60000 (44.78%)
-= Testing Rotation 200 =-
Test set: Average loss: 6.5725,                   Accuracy: 25398/60000 (42.33%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.3948,                   Accuracy: 22176/60000 (36.96%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.2143,                   Accuracy: 18249/60000 (30.42%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.3277,                   Accuracy: 15240/60000 (25.40%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.5045,                   Accuracy: 12825/60000 (21.38%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.5531,                   Accuracy: 11748/60000 (19.58%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.5932,                   Accuracy: 11432/60000 (19.05%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.5012,                   Accuracy: 11779/60000 (19.63%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.9885,                   Accuracy: 11252/60000 (18.75%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.5629,                   Accuracy: 11044/60000 (18.41%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.7672,                   Accuracy: 14328/60000 (23.88%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.6742,                   Accuracy: 23001/60000 (38.33%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.3413,                   Accuracy: 34243/60000 (57.07%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.0846,                   Accuracy: 46261/60000 (77.10%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3165,                   Accuracy: 55109/60000 (91.85%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0851,                   Accuracy: 58543/60000 (97.57%)
{0: tensor(98.5500), 10: tensor(97.8617), 20: tensor(95.1850), 30: tensor(85.4817), 40: tensor(69.1967), 50: tensor(52.0717), 60: tensor(35.8867), 70: tensor(25.1117), 80: tensor(18.7633), 90: tensor(17.4683), 100: tensor(16.4050), 110: tensor(17.4783), 120: tensor(20.9400), 130: tensor(26.3917), 140: tensor(32.0067), 150: tensor(37.5350), 160: tensor(41.9867), 170: tensor(44.8133), 180: tensor(44.8233), 190: tensor(44.7767), 200: tensor(42.3300), 210: tensor(36.9600), 220: tensor(30.4150), 230: tensor(25.4000), 240: tensor(21.3750), 250: tensor(19.5800), 260: tensor(19.0533), 270: tensor(19.6317), 280: tensor(18.7533), 290: tensor(18.4067), 300: tensor(23.8800), 310: tensor(38.3350), 320: tensor(57.0717), 330: tensor(77.1017), 340: tensor(91.8483), 350: tensor(97.5717)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=False, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=10, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.4410,                   Accuracy: 804/2000.0 (40.20%)



-= Testing valid =-
Test set: Average loss: 0.5629,                   Accuracy: 1644/2000.0 (82.20%)



-= Testing valid =-
Test set: Average loss: 0.2721,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.3129,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.1312,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1704,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.0720,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.1521,                   Accuracy: 1903/2000.0 (95.15%)



Epoch 10 train accuracy: 98.14%, valid accuracy 95.15%
-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0426,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0425,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0520,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0612,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0579,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0554,                   Accuracy: 1965/2000.0 (98.25%)



Epoch 20 train accuracy: 98.85%, valid accuracy 98.25%
-= Testing valid =-
Test set: Average loss: 0.0367,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0395,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0428,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0383,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0379,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0303,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0394,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0430,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0509,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 30 train accuracy: 99.38%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0384,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0373,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0354,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0350,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0332,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1972/2000.0 (98.60%)



-= Testing valid =-
Test set: Average loss: 0.0311,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0360,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0351,                   Accuracy: 1972/2000.0 (98.60%)



Epoch 40 train accuracy: 99.65%, valid accuracy 98.60%
-= Testing valid =-
Test set: Average loss: 0.0298,                   Accuracy: 1975/2000.0 (98.75%)



-= Testing valid =-
Test set: Average loss: 0.0322,                   Accuracy: 1976/2000.0 (98.80%)



-= Testing valid =-
Test set: Average loss: 0.0329,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0295,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0331,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0299,                   Accuracy: 1974/2000.0 (98.70%)



-= Testing valid =-
Test set: Average loss: 0.0284,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0310,                   Accuracy: 1970/2000.0 (98.50%)



-= Testing valid =-
Test set: Average loss: 0.0302,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0297,                   Accuracy: 1974/2000.0 (98.70%)



Epoch 50 train accuracy: 99.75%, valid accuracy 98.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0599,                   Accuracy: 58940/60000 (98.23%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1308,                   Accuracy: 57724/60000 (96.21%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2660,                   Accuracy: 55617/60000 (92.69%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.5686,                   Accuracy: 50758/60000 (84.60%)
-= Testing Rotation 40 =-
Test set: Average loss: 1.2844,                   Accuracy: 40812/60000 (68.02%)
-= Testing Rotation 50 =-
Test set: Average loss: 2.2465,                   Accuracy: 30227/60000 (50.38%)
-= Testing Rotation 60 =-
Test set: Average loss: 3.4532,                   Accuracy: 20563/60000 (34.27%)
-= Testing Rotation 70 =-
Test set: Average loss: 4.3148,                   Accuracy: 14706/60000 (24.51%)
-= Testing Rotation 80 =-
Test set: Average loss: 4.9490,                   Accuracy: 11662/60000 (19.44%)
-= Testing Rotation 90 =-
Test set: Average loss: 5.6009,                   Accuracy: 10899/60000 (18.17%)
-= Testing Rotation 100 =-
Test set: Average loss: 5.5512,                   Accuracy: 11117/60000 (18.53%)
-= Testing Rotation 110 =-
Test set: Average loss: 5.6390,                   Accuracy: 11221/60000 (18.70%)
-= Testing Rotation 120 =-
Test set: Average loss: 5.7510,                   Accuracy: 11796/60000 (19.66%)
-= Testing Rotation 130 =-
Test set: Average loss: 5.5123,                   Accuracy: 14815/60000 (24.69%)
-= Testing Rotation 140 =-
Test set: Average loss: 5.1553,                   Accuracy: 18895/60000 (31.49%)
-= Testing Rotation 150 =-
Test set: Average loss: 5.0171,                   Accuracy: 23592/60000 (39.32%)
-= Testing Rotation 160 =-
Test set: Average loss: 5.2527,                   Accuracy: 26032/60000 (43.39%)
-= Testing Rotation 170 =-
Test set: Average loss: 5.6328,                   Accuracy: 27702/60000 (46.17%)
-= Testing Rotation 180 =-
Test set: Average loss: 5.9653,                   Accuracy: 28006/60000 (46.68%)
-= Testing Rotation 190 =-
Test set: Average loss: 5.9842,                   Accuracy: 26801/60000 (44.67%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.8836,                   Accuracy: 25267/60000 (42.11%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.6646,                   Accuracy: 22543/60000 (37.57%)
-= Testing Rotation 220 =-
Test set: Average loss: 5.6992,                   Accuracy: 19982/60000 (33.30%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.7969,                   Accuracy: 17762/60000 (29.60%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.1125,                   Accuracy: 15188/60000 (25.31%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.3791,                   Accuracy: 12945/60000 (21.58%)
-= Testing Rotation 260 =-
Test set: Average loss: 6.3843,                   Accuracy: 11760/60000 (19.60%)
-= Testing Rotation 270 =-
Test set: Average loss: 6.7905,                   Accuracy: 9621/60000 (16.03%)
-= Testing Rotation 280 =-
Test set: Average loss: 6.2898,                   Accuracy: 9290/60000 (15.48%)
-= Testing Rotation 290 =-
Test set: Average loss: 5.7227,                   Accuracy: 9422/60000 (15.70%)
-= Testing Rotation 300 =-
Test set: Average loss: 5.0335,                   Accuracy: 11686/60000 (19.48%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.7939,                   Accuracy: 18450/60000 (30.75%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.2566,                   Accuracy: 30036/60000 (50.06%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.9748,                   Accuracy: 44247/60000 (73.75%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3493,                   Accuracy: 53886/60000 (89.81%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1293,                   Accuracy: 57798/60000 (96.33%)
{0: tensor(98.2333), 10: tensor(96.2067), 20: tensor(92.6950), 30: tensor(84.5967), 40: tensor(68.0200), 50: tensor(50.3783), 60: tensor(34.2717), 70: tensor(24.5100), 80: tensor(19.4367), 90: tensor(18.1650), 100: tensor(18.5283), 110: tensor(18.7017), 120: tensor(19.6600), 130: tensor(24.6917), 140: tensor(31.4917), 150: tensor(39.3200), 160: tensor(43.3867), 170: tensor(46.1700), 180: tensor(46.6767), 190: tensor(44.6683), 200: tensor(42.1117), 210: tensor(37.5717), 220: tensor(33.3033), 230: tensor(29.6033), 240: tensor(25.3133), 250: tensor(21.5750), 260: tensor(19.6000), 270: tensor(16.0350), 280: tensor(15.4833), 290: tensor(15.7033), 300: tensor(19.4767), 310: tensor(30.7500), 320: tensor(50.0600), 330: tensor(73.7450), 340: tensor(89.8100), 350: tensor(96.3300)}
