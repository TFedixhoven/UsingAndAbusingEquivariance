Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=1, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.1432,                   Accuracy: 225/2000.0 (11.25%)



-= Testing valid =-
Test set: Average loss: 2.4335,                   Accuracy: 299/2000.0 (14.95%)



-= Testing valid =-
Test set: Average loss: 1.2430,                   Accuracy: 1142/2000.0 (57.10%)



-= Testing valid =-
Test set: Average loss: 0.7032,                   Accuracy: 1556/2000.0 (77.80%)



-= Testing valid =-
Test set: Average loss: 0.4186,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.3017,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.8175,                   Accuracy: 1451/2000.0 (72.55%)



-= Testing valid =-
Test set: Average loss: 0.3339,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.4818,                   Accuracy: 1669/2000.0 (83.45%)



-= Testing valid =-
Test set: Average loss: 0.2658,                   Accuracy: 1840/2000.0 (92.00%)



Epoch 10 train accuracy: 93.34%, valid accuracy 92.00%
-= Testing valid =-
Test set: Average loss: 0.2265,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2468,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.1847,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.2004,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.2097,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.1763,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1901,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1708,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1510,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1837,                   Accuracy: 1885/2000.0 (94.25%)



Epoch 20 train accuracy: 96.38%, valid accuracy 94.25%
-= Testing valid =-
Test set: Average loss: 0.1335,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1377,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1319,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1339,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1338,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1637,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1488,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1304,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1289,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1328,                   Accuracy: 1917/2000.0 (95.85%)



Epoch 30 train accuracy: 96.41%, valid accuracy 95.85%
-= Testing valid =-
Test set: Average loss: 0.1215,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1243,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1285,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1281,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1380,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1322,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1228,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1163,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1222,                   Accuracy: 1922/2000.0 (96.10%)



Epoch 40 train accuracy: 97.12%, valid accuracy 96.10%
-= Testing valid =-
Test set: Average loss: 0.1181,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1147,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1059,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1046,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1094,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1093,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 50 train accuracy: 97.15%, valid accuracy 96.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1282,                   Accuracy: 57785/60000 (96.31%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1331,                   Accuracy: 57616/60000 (96.03%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1085,                   Accuracy: 58074/60000 (96.79%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0960,                   Accuracy: 58290/60000 (97.15%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0886,                   Accuracy: 58441/60000 (97.40%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0888,                   Accuracy: 58385/60000 (97.31%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0943,                   Accuracy: 58304/60000 (97.17%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1055,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1244,                   Accuracy: 57769/60000 (96.28%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1282,                   Accuracy: 57785/60000 (96.31%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1331,                   Accuracy: 57616/60000 (96.03%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1085,                   Accuracy: 58074/60000 (96.79%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.0960,                   Accuracy: 58290/60000 (97.15%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.0886,                   Accuracy: 58441/60000 (97.40%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.0888,                   Accuracy: 58385/60000 (97.31%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.0943,                   Accuracy: 58304/60000 (97.17%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1055,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1244,                   Accuracy: 57769/60000 (96.28%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1282,                   Accuracy: 57785/60000 (96.31%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1331,                   Accuracy: 57616/60000 (96.03%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1085,                   Accuracy: 58074/60000 (96.79%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.0960,                   Accuracy: 58290/60000 (97.15%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.0886,                   Accuracy: 58441/60000 (97.40%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.0888,                   Accuracy: 58385/60000 (97.31%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.0943,                   Accuracy: 58304/60000 (97.17%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1055,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1244,                   Accuracy: 57769/60000 (96.28%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1282,                   Accuracy: 57785/60000 (96.31%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1331,                   Accuracy: 57616/60000 (96.03%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1085,                   Accuracy: 58074/60000 (96.79%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.0960,                   Accuracy: 58290/60000 (97.15%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.0886,                   Accuracy: 58441/60000 (97.40%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.0888,                   Accuracy: 58385/60000 (97.31%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0943,                   Accuracy: 58304/60000 (97.17%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1055,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1244,                   Accuracy: 57769/60000 (96.28%)
{0: tensor(96.3083), 10: tensor(96.0267), 20: tensor(96.7900), 30: tensor(97.1500), 40: tensor(97.4017), 50: tensor(97.3083), 60: tensor(97.1733), 70: tensor(96.9100), 80: tensor(96.2817), 90: tensor(96.3083), 100: tensor(96.0267), 110: tensor(96.7900), 120: tensor(97.1500), 130: tensor(97.4017), 140: tensor(97.3083), 150: tensor(97.1733), 160: tensor(96.9100), 170: tensor(96.2817), 180: tensor(96.3083), 190: tensor(96.0267), 200: tensor(96.7900), 210: tensor(97.1500), 220: tensor(97.4017), 230: tensor(97.3083), 240: tensor(97.1733), 250: tensor(96.9100), 260: tensor(96.2817), 270: tensor(96.3083), 280: tensor(96.0267), 290: tensor(96.7900), 300: tensor(97.1500), 310: tensor(97.4017), 320: tensor(97.3083), 330: tensor(97.1733), 340: tensor(96.9100), 350: tensor(96.2817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=2, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9091,                   Accuracy: 562/2000.0 (28.10%)



-= Testing valid =-
Test set: Average loss: 1.7688,                   Accuracy: 690/2000.0 (34.50%)



-= Testing valid =-
Test set: Average loss: 1.1487,                   Accuracy: 1172/2000.0 (58.60%)



-= Testing valid =-
Test set: Average loss: 0.9929,                   Accuracy: 1393/2000.0 (69.65%)



-= Testing valid =-
Test set: Average loss: 0.4516,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.2771,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2314,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2668,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.2431,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2500,                   Accuracy: 1831/2000.0 (91.55%)



Epoch 10 train accuracy: 94.18%, valid accuracy 91.55%
-= Testing valid =-
Test set: Average loss: 0.1775,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1758,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1868,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1627,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.2354,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.1663,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1891,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1708,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1870,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1690,                   Accuracy: 1905/2000.0 (95.25%)



Epoch 20 train accuracy: 96.29%, valid accuracy 95.25%
-= Testing valid =-
Test set: Average loss: 0.1544,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1497,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1566,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1432,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1639,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1399,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1604,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1490,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1447,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1317,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 30 train accuracy: 96.95%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.1359,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1288,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1314,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1351,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1451,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1329,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1596,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1224,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1322,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1261,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 40 train accuracy: 97.38%, valid accuracy 96.45%
-= Testing valid =-
Test set: Average loss: 0.1232,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1223,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1295,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1253,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1299,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1260,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1272,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1345,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1277,                   Accuracy: 1930/2000.0 (96.50%)



Epoch 50 train accuracy: 97.45%, valid accuracy 96.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1342,                   Accuracy: 57555/60000 (95.93%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1346,                   Accuracy: 57516/60000 (95.86%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1082,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0950,                   Accuracy: 58260/60000 (97.10%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0888,                   Accuracy: 58453/60000 (97.42%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0911,                   Accuracy: 58369/60000 (97.28%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0983,                   Accuracy: 58244/60000 (97.07%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1128,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1330,                   Accuracy: 57579/60000 (95.96%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1342,                   Accuracy: 57555/60000 (95.93%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1346,                   Accuracy: 57516/60000 (95.86%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1082,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.0950,                   Accuracy: 58260/60000 (97.10%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.0888,                   Accuracy: 58453/60000 (97.42%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.0911,                   Accuracy: 58369/60000 (97.28%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.0983,                   Accuracy: 58244/60000 (97.07%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1128,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1330,                   Accuracy: 57579/60000 (95.96%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1342,                   Accuracy: 57555/60000 (95.93%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1346,                   Accuracy: 57516/60000 (95.86%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1082,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.0950,                   Accuracy: 58260/60000 (97.10%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.0888,                   Accuracy: 58453/60000 (97.42%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.0911,                   Accuracy: 58369/60000 (97.28%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.0983,                   Accuracy: 58244/60000 (97.07%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1128,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1330,                   Accuracy: 57579/60000 (95.96%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1342,                   Accuracy: 57555/60000 (95.93%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1346,                   Accuracy: 57516/60000 (95.86%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1082,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.0950,                   Accuracy: 58260/60000 (97.10%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.0888,                   Accuracy: 58453/60000 (97.42%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.0911,                   Accuracy: 58369/60000 (97.28%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0983,                   Accuracy: 58244/60000 (97.07%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1128,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1330,                   Accuracy: 57579/60000 (95.96%)
{0: tensor(95.9250), 10: tensor(95.8600), 20: tensor(96.7550), 30: tensor(97.1000), 40: tensor(97.4217), 50: tensor(97.2817), 60: tensor(97.0733), 70: tensor(96.6433), 80: tensor(95.9650), 90: tensor(95.9250), 100: tensor(95.8600), 110: tensor(96.7550), 120: tensor(97.1000), 130: tensor(97.4217), 140: tensor(97.2817), 150: tensor(97.0733), 160: tensor(96.6433), 170: tensor(95.9650), 180: tensor(95.9250), 190: tensor(95.8600), 200: tensor(96.7550), 210: tensor(97.1000), 220: tensor(97.4217), 230: tensor(97.2817), 240: tensor(97.0733), 250: tensor(96.6433), 260: tensor(95.9650), 270: tensor(95.9250), 280: tensor(95.8600), 290: tensor(96.7550), 300: tensor(97.1000), 310: tensor(97.4217), 320: tensor(97.2817), 330: tensor(97.0733), 340: tensor(96.6433), 350: tensor(95.9650)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=3, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8683,                   Accuracy: 500/2000.0 (25.00%)



-= Testing valid =-
Test set: Average loss: 1.5801,                   Accuracy: 899/2000.0 (44.95%)



-= Testing valid =-
Test set: Average loss: 1.2918,                   Accuracy: 1060/2000.0 (53.00%)



-= Testing valid =-
Test set: Average loss: 0.9734,                   Accuracy: 1304/2000.0 (65.20%)



-= Testing valid =-
Test set: Average loss: 0.7864,                   Accuracy: 1484/2000.0 (74.20%)



-= Testing valid =-
Test set: Average loss: 0.8742,                   Accuracy: 1468/2000.0 (73.40%)



-= Testing valid =-
Test set: Average loss: 0.3468,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.3665,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.4294,                   Accuracy: 1708/2000.0 (85.40%)



-= Testing valid =-
Test set: Average loss: 0.3819,                   Accuracy: 1749/2000.0 (87.45%)



Epoch 10 train accuracy: 93.09%, valid accuracy 87.45%
-= Testing valid =-
Test set: Average loss: 0.2273,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.1949,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1773,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1890,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1835,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1651,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1779,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1531,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1927,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1548,                   Accuracy: 1901/2000.0 (95.05%)



Epoch 20 train accuracy: 96.10%, valid accuracy 95.05%
-= Testing valid =-
Test set: Average loss: 0.1539,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1546,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1563,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1637,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1439,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1440,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1339,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1520,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1330,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1340,                   Accuracy: 1919/2000.0 (95.95%)



Epoch 30 train accuracy: 96.59%, valid accuracy 95.95%
-= Testing valid =-
Test set: Average loss: 0.1346,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1284,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1230,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1233,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1271,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1207,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1191,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1308,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1252,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1206,                   Accuracy: 1921/2000.0 (96.05%)



Epoch 40 train accuracy: 97.35%, valid accuracy 96.05%
-= Testing valid =-
Test set: Average loss: 0.1246,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1132,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1190,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1270,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1212,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1126,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1247,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1202,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1146,                   Accuracy: 1921/2000.0 (96.05%)



Epoch 50 train accuracy: 97.38%, valid accuracy 96.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1323,                   Accuracy: 57688/60000 (96.15%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1310,                   Accuracy: 57701/60000 (96.17%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1134,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1020,                   Accuracy: 58160/60000 (96.93%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0959,                   Accuracy: 58332/60000 (97.22%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0976,                   Accuracy: 58273/60000 (97.12%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1055,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1187,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1333,                   Accuracy: 57630/60000 (96.05%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1323,                   Accuracy: 57688/60000 (96.15%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1310,                   Accuracy: 57701/60000 (96.17%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1134,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1020,                   Accuracy: 58160/60000 (96.93%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.0959,                   Accuracy: 58332/60000 (97.22%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.0976,                   Accuracy: 58273/60000 (97.12%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1055,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1187,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1333,                   Accuracy: 57630/60000 (96.05%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1323,                   Accuracy: 57688/60000 (96.15%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1310,                   Accuracy: 57701/60000 (96.17%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1134,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1020,                   Accuracy: 58160/60000 (96.93%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.0959,                   Accuracy: 58332/60000 (97.22%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.0976,                   Accuracy: 58273/60000 (97.12%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1055,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1187,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1333,                   Accuracy: 57630/60000 (96.05%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1323,                   Accuracy: 57688/60000 (96.15%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1310,                   Accuracy: 57701/60000 (96.17%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1134,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1020,                   Accuracy: 58160/60000 (96.93%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.0959,                   Accuracy: 58332/60000 (97.22%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.0976,                   Accuracy: 58273/60000 (97.12%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1055,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1187,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1333,                   Accuracy: 57630/60000 (96.05%)
{0: tensor(96.1467), 10: tensor(96.1683), 20: tensor(96.6233), 30: tensor(96.9333), 40: tensor(97.2200), 50: tensor(97.1217), 60: tensor(96.8767), 70: tensor(96.5850), 80: tensor(96.0500), 90: tensor(96.1467), 100: tensor(96.1683), 110: tensor(96.6233), 120: tensor(96.9333), 130: tensor(97.2200), 140: tensor(97.1217), 150: tensor(96.8767), 160: tensor(96.5850), 170: tensor(96.0500), 180: tensor(96.1467), 190: tensor(96.1683), 200: tensor(96.6233), 210: tensor(96.9333), 220: tensor(97.2200), 230: tensor(97.1217), 240: tensor(96.8767), 250: tensor(96.5850), 260: tensor(96.0500), 270: tensor(96.1467), 280: tensor(96.1683), 290: tensor(96.6233), 300: tensor(96.9333), 310: tensor(97.2200), 320: tensor(97.1217), 330: tensor(96.8767), 340: tensor(96.5850), 350: tensor(96.0500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=4, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3617,                   Accuracy: 328/2000.0 (16.40%)



-= Testing valid =-
Test set: Average loss: 1.8108,                   Accuracy: 836/2000.0 (41.80%)



-= Testing valid =-
Test set: Average loss: 1.5649,                   Accuracy: 837/2000.0 (41.85%)



-= Testing valid =-
Test set: Average loss: 1.9329,                   Accuracy: 803/2000.0 (40.15%)



-= Testing valid =-
Test set: Average loss: 0.6307,                   Accuracy: 1634/2000.0 (81.70%)



-= Testing valid =-
Test set: Average loss: 0.6284,                   Accuracy: 1614/2000.0 (80.70%)



-= Testing valid =-
Test set: Average loss: 0.5386,                   Accuracy: 1646/2000.0 (82.30%)



-= Testing valid =-
Test set: Average loss: 0.2689,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.4385,                   Accuracy: 1706/2000.0 (85.30%)



-= Testing valid =-
Test set: Average loss: 0.5124,                   Accuracy: 1621/2000.0 (81.05%)



Epoch 10 train accuracy: 92.96%, valid accuracy 81.05%
-= Testing valid =-
Test set: Average loss: 0.1845,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.2114,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.2228,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1826,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1455,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1395,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1481,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1712,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1821,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1961,                   Accuracy: 1878/2000.0 (93.90%)



Epoch 20 train accuracy: 95.85%, valid accuracy 93.90%
-= Testing valid =-
Test set: Average loss: 0.1403,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1324,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1302,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1276,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1511,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1217,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1401,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1294,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1211,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1270,                   Accuracy: 1920/2000.0 (96.00%)



Epoch 30 train accuracy: 96.82%, valid accuracy 96.00%
-= Testing valid =-
Test set: Average loss: 0.1193,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1163,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1187,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1178,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1160,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1117,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1098,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1266,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1280,                   Accuracy: 1922/2000.0 (96.10%)



Epoch 40 train accuracy: 97.20%, valid accuracy 96.10%
-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1115,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1091,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0976,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 50 train accuracy: 97.35%, valid accuracy 97.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1283,                   Accuracy: 57703/60000 (96.17%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1311,                   Accuracy: 57589/60000 (95.98%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1059,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0908,                   Accuracy: 58370/60000 (97.28%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0839,                   Accuracy: 58521/60000 (97.54%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0877,                   Accuracy: 58416/60000 (97.36%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0978,                   Accuracy: 58253/60000 (97.09%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1149,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1369,                   Accuracy: 57483/60000 (95.81%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1283,                   Accuracy: 57703/60000 (96.17%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1311,                   Accuracy: 57589/60000 (95.98%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1059,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.0908,                   Accuracy: 58370/60000 (97.28%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.0839,                   Accuracy: 58521/60000 (97.54%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.0877,                   Accuracy: 58416/60000 (97.36%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.0978,                   Accuracy: 58253/60000 (97.09%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1149,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1369,                   Accuracy: 57483/60000 (95.81%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1283,                   Accuracy: 57703/60000 (96.17%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1311,                   Accuracy: 57589/60000 (95.98%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1059,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.0908,                   Accuracy: 58370/60000 (97.28%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.0839,                   Accuracy: 58521/60000 (97.54%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.0877,                   Accuracy: 58416/60000 (97.36%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.0978,                   Accuracy: 58253/60000 (97.09%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1149,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1369,                   Accuracy: 57483/60000 (95.81%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1283,                   Accuracy: 57703/60000 (96.17%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1311,                   Accuracy: 57589/60000 (95.98%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1059,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.0908,                   Accuracy: 58370/60000 (97.28%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.0839,                   Accuracy: 58521/60000 (97.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.0877,                   Accuracy: 58416/60000 (97.36%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0978,                   Accuracy: 58253/60000 (97.09%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1149,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1369,                   Accuracy: 57483/60000 (95.81%)
{0: tensor(96.1717), 10: tensor(95.9817), 20: tensor(96.7967), 30: tensor(97.2833), 40: tensor(97.5350), 50: tensor(97.3600), 60: tensor(97.0883), 70: tensor(96.5717), 80: tensor(95.8050), 90: tensor(96.1717), 100: tensor(95.9817), 110: tensor(96.7967), 120: tensor(97.2833), 130: tensor(97.5350), 140: tensor(97.3600), 150: tensor(97.0883), 160: tensor(96.5717), 170: tensor(95.8050), 180: tensor(96.1717), 190: tensor(95.9817), 200: tensor(96.7967), 210: tensor(97.2833), 220: tensor(97.5350), 230: tensor(97.3600), 240: tensor(97.0883), 250: tensor(96.5717), 260: tensor(95.8050), 270: tensor(96.1717), 280: tensor(95.9817), 290: tensor(96.7967), 300: tensor(97.2833), 310: tensor(97.5350), 320: tensor(97.3600), 330: tensor(97.0883), 340: tensor(96.5717), 350: tensor(95.8050)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=5, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5972,                   Accuracy: 268/2000.0 (13.40%)



-= Testing valid =-
Test set: Average loss: 3.0507,                   Accuracy: 333/2000.0 (16.65%)



-= Testing valid =-
Test set: Average loss: 0.9512,                   Accuracy: 1332/2000.0 (66.60%)



-= Testing valid =-
Test set: Average loss: 0.6515,                   Accuracy: 1574/2000.0 (78.70%)



-= Testing valid =-
Test set: Average loss: 0.6748,                   Accuracy: 1561/2000.0 (78.05%)



-= Testing valid =-
Test set: Average loss: 0.3807,                   Accuracy: 1764/2000.0 (88.20%)



-= Testing valid =-
Test set: Average loss: 0.2824,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.3386,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.3169,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2705,                   Accuracy: 1819/2000.0 (90.95%)



Epoch 10 train accuracy: 94.12%, valid accuracy 90.95%
-= Testing valid =-
Test set: Average loss: 0.3455,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.2775,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.3750,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.2797,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2092,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1903,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.2051,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.2509,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2190,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.1860,                   Accuracy: 1883/2000.0 (94.15%)



Epoch 20 train accuracy: 96.31%, valid accuracy 94.15%
-= Testing valid =-
Test set: Average loss: 0.1963,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1536,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1954,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1784,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1918,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1794,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1614,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1517,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1403,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1573,                   Accuracy: 1908/2000.0 (95.40%)



Epoch 30 train accuracy: 97.18%, valid accuracy 95.40%
-= Testing valid =-
Test set: Average loss: 0.1503,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1466,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1536,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1727,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1561,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1603,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1523,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1570,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1729,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1526,                   Accuracy: 1914/2000.0 (95.70%)



Epoch 40 train accuracy: 97.15%, valid accuracy 95.70%
-= Testing valid =-
Test set: Average loss: 0.1511,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1535,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1516,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1505,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1405,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1494,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1560,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1492,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1435,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1487,                   Accuracy: 1916/2000.0 (95.80%)



Epoch 50 train accuracy: 97.74%, valid accuracy 95.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1338,                   Accuracy: 57629/60000 (96.05%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1381,                   Accuracy: 57551/60000 (95.92%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1101,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0978,                   Accuracy: 58235/60000 (97.06%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0908,                   Accuracy: 58359/60000 (97.26%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0916,                   Accuracy: 58345/60000 (97.24%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0985,                   Accuracy: 58194/60000 (96.99%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1112,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1327,                   Accuracy: 57548/60000 (95.91%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1338,                   Accuracy: 57629/60000 (96.05%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1381,                   Accuracy: 57551/60000 (95.92%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1101,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.0978,                   Accuracy: 58235/60000 (97.06%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.0908,                   Accuracy: 58359/60000 (97.26%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.0916,                   Accuracy: 58345/60000 (97.24%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.0985,                   Accuracy: 58194/60000 (96.99%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1112,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1327,                   Accuracy: 57548/60000 (95.91%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1338,                   Accuracy: 57629/60000 (96.05%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1381,                   Accuracy: 57551/60000 (95.92%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1101,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.0978,                   Accuracy: 58235/60000 (97.06%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.0908,                   Accuracy: 58359/60000 (97.26%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.0916,                   Accuracy: 58345/60000 (97.24%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.0985,                   Accuracy: 58194/60000 (96.99%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1112,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1327,                   Accuracy: 57548/60000 (95.91%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1338,                   Accuracy: 57629/60000 (96.05%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1381,                   Accuracy: 57551/60000 (95.92%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1101,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.0978,                   Accuracy: 58235/60000 (97.06%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.0908,                   Accuracy: 58359/60000 (97.26%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.0916,                   Accuracy: 58345/60000 (97.24%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0985,                   Accuracy: 58194/60000 (96.99%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1112,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1327,                   Accuracy: 57548/60000 (95.91%)
{0: tensor(96.0483), 10: tensor(95.9183), 20: tensor(96.7067), 30: tensor(97.0583), 40: tensor(97.2650), 50: tensor(97.2417), 60: tensor(96.9900), 70: tensor(96.6483), 80: tensor(95.9133), 90: tensor(96.0483), 100: tensor(95.9183), 110: tensor(96.7067), 120: tensor(97.0583), 130: tensor(97.2650), 140: tensor(97.2417), 150: tensor(96.9900), 160: tensor(96.6483), 170: tensor(95.9133), 180: tensor(96.0483), 190: tensor(95.9183), 200: tensor(96.7067), 210: tensor(97.0583), 220: tensor(97.2650), 230: tensor(97.2417), 240: tensor(96.9900), 250: tensor(96.6483), 260: tensor(95.9133), 270: tensor(96.0483), 280: tensor(95.9183), 290: tensor(96.7067), 300: tensor(97.0583), 310: tensor(97.2650), 320: tensor(97.2417), 330: tensor(96.9900), 340: tensor(96.6483), 350: tensor(95.9133)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=6, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2109,                   Accuracy: 470/2000.0 (23.50%)



-= Testing valid =-
Test set: Average loss: 1.5469,                   Accuracy: 816/2000.0 (40.80%)



-= Testing valid =-
Test set: Average loss: 1.2876,                   Accuracy: 1090/2000.0 (54.50%)



-= Testing valid =-
Test set: Average loss: 1.9034,                   Accuracy: 840/2000.0 (42.00%)



-= Testing valid =-
Test set: Average loss: 1.3612,                   Accuracy: 1087/2000.0 (54.35%)



-= Testing valid =-
Test set: Average loss: 0.3659,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.3236,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.4608,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.3211,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.3713,                   Accuracy: 1757/2000.0 (87.85%)



Epoch 10 train accuracy: 93.76%, valid accuracy 87.85%
-= Testing valid =-
Test set: Average loss: 0.2012,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1838,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.2174,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.2128,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.1779,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.2166,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.2064,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1826,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1930,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2096,                   Accuracy: 1883/2000.0 (94.15%)



Epoch 20 train accuracy: 95.74%, valid accuracy 94.15%
-= Testing valid =-
Test set: Average loss: 0.1516,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1456,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1594,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1431,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1588,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1383,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1350,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1318,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1359,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1398,                   Accuracy: 1919/2000.0 (95.95%)



Epoch 30 train accuracy: 96.97%, valid accuracy 95.95%
-= Testing valid =-
Test set: Average loss: 0.1373,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1353,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1329,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1361,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1322,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1343,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1244,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1268,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1288,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1248,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 40 train accuracy: 97.03%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.1245,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1241,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1234,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1254,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1257,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1234,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1217,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1204,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 50 train accuracy: 97.36%, valid accuracy 96.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1338,                   Accuracy: 57581/60000 (95.97%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1385,                   Accuracy: 57512/60000 (95.85%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1078,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0892,                   Accuracy: 58367/60000 (97.28%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0822,                   Accuracy: 58530/60000 (97.55%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0857,                   Accuracy: 58466/60000 (97.44%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0970,                   Accuracy: 58262/60000 (97.10%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1122,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1359,                   Accuracy: 57516/60000 (95.86%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1338,                   Accuracy: 57581/60000 (95.97%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1385,                   Accuracy: 57512/60000 (95.85%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1078,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.0892,                   Accuracy: 58367/60000 (97.28%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.0822,                   Accuracy: 58530/60000 (97.55%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.0857,                   Accuracy: 58466/60000 (97.44%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.0970,                   Accuracy: 58262/60000 (97.10%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1122,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1359,                   Accuracy: 57516/60000 (95.86%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1338,                   Accuracy: 57581/60000 (95.97%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1385,                   Accuracy: 57512/60000 (95.85%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1078,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.0892,                   Accuracy: 58367/60000 (97.28%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.0822,                   Accuracy: 58530/60000 (97.55%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.0857,                   Accuracy: 58466/60000 (97.44%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.0970,                   Accuracy: 58262/60000 (97.10%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1122,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1359,                   Accuracy: 57516/60000 (95.86%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1338,                   Accuracy: 57581/60000 (95.97%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1385,                   Accuracy: 57512/60000 (95.85%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1078,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.0892,                   Accuracy: 58367/60000 (97.28%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.0822,                   Accuracy: 58530/60000 (97.55%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.0857,                   Accuracy: 58466/60000 (97.44%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0970,                   Accuracy: 58262/60000 (97.10%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1122,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1359,                   Accuracy: 57516/60000 (95.86%)
{0: tensor(95.9683), 10: tensor(95.8533), 20: tensor(96.7667), 30: tensor(97.2783), 40: tensor(97.5500), 50: tensor(97.4433), 60: tensor(97.1033), 70: tensor(96.6217), 80: tensor(95.8600), 90: tensor(95.9683), 100: tensor(95.8533), 110: tensor(96.7667), 120: tensor(97.2783), 130: tensor(97.5500), 140: tensor(97.4433), 150: tensor(97.1033), 160: tensor(96.6217), 170: tensor(95.8600), 180: tensor(95.9683), 190: tensor(95.8533), 200: tensor(96.7667), 210: tensor(97.2783), 220: tensor(97.5500), 230: tensor(97.4433), 240: tensor(97.1033), 250: tensor(96.6217), 260: tensor(95.8600), 270: tensor(95.9683), 280: tensor(95.8533), 290: tensor(96.7667), 300: tensor(97.2783), 310: tensor(97.5500), 320: tensor(97.4433), 330: tensor(97.1033), 340: tensor(96.6217), 350: tensor(95.8600)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=7, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 9.6747,                   Accuracy: 212/2000.0 (10.60%)



-= Testing valid =-
Test set: Average loss: 2.4683,                   Accuracy: 396/2000.0 (19.80%)



-= Testing valid =-
Test set: Average loss: 2.4684,                   Accuracy: 552/2000.0 (27.60%)



-= Testing valid =-
Test set: Average loss: 0.8244,                   Accuracy: 1429/2000.0 (71.45%)



-= Testing valid =-
Test set: Average loss: 0.4341,                   Accuracy: 1759/2000.0 (87.95%)



-= Testing valid =-
Test set: Average loss: 0.4962,                   Accuracy: 1670/2000.0 (83.50%)



-= Testing valid =-
Test set: Average loss: 0.2851,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.4937,                   Accuracy: 1668/2000.0 (83.40%)



-= Testing valid =-
Test set: Average loss: 0.2360,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2778,                   Accuracy: 1825/2000.0 (91.25%)



Epoch 10 train accuracy: 93.88%, valid accuracy 91.25%
-= Testing valid =-
Test set: Average loss: 0.2036,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.2092,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.1788,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1956,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.1785,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.2753,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.1547,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.2265,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.1617,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1852,                   Accuracy: 1883/2000.0 (94.15%)



Epoch 20 train accuracy: 96.16%, valid accuracy 94.15%
-= Testing valid =-
Test set: Average loss: 0.1842,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1544,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1579,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1416,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1607,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1404,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1295,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1380,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1806,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1401,                   Accuracy: 1911/2000.0 (95.55%)



Epoch 30 train accuracy: 96.94%, valid accuracy 95.55%
-= Testing valid =-
Test set: Average loss: 0.1373,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1189,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1215,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1201,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1200,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1142,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1256,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1048,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1167,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1184,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 40 train accuracy: 97.56%, valid accuracy 96.45%
-= Testing valid =-
Test set: Average loss: 0.1139,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1158,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1107,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1117,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1134,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1103,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1086,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1085,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1067,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 50 train accuracy: 97.57%, valid accuracy 96.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1334,                   Accuracy: 57665/60000 (96.11%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1303,                   Accuracy: 57708/60000 (96.18%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1088,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0925,                   Accuracy: 58388/60000 (97.31%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0858,                   Accuracy: 58494/60000 (97.49%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0882,                   Accuracy: 58425/60000 (97.38%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0981,                   Accuracy: 58250/60000 (97.08%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1151,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1311,                   Accuracy: 57637/60000 (96.06%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1334,                   Accuracy: 57665/60000 (96.11%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1303,                   Accuracy: 57708/60000 (96.18%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1088,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.0925,                   Accuracy: 58388/60000 (97.31%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.0858,                   Accuracy: 58494/60000 (97.49%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.0882,                   Accuracy: 58425/60000 (97.38%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.0981,                   Accuracy: 58250/60000 (97.08%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1151,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1311,                   Accuracy: 57637/60000 (96.06%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1334,                   Accuracy: 57665/60000 (96.11%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1303,                   Accuracy: 57708/60000 (96.18%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1088,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.0925,                   Accuracy: 58388/60000 (97.31%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.0858,                   Accuracy: 58494/60000 (97.49%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.0882,                   Accuracy: 58425/60000 (97.38%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.0981,                   Accuracy: 58250/60000 (97.08%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1151,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1311,                   Accuracy: 57637/60000 (96.06%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1334,                   Accuracy: 57665/60000 (96.11%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1303,                   Accuracy: 57708/60000 (96.18%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1088,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.0925,                   Accuracy: 58388/60000 (97.31%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.0858,                   Accuracy: 58494/60000 (97.49%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.0882,                   Accuracy: 58425/60000 (97.38%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0981,                   Accuracy: 58250/60000 (97.08%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1151,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1311,                   Accuracy: 57637/60000 (96.06%)
{0: tensor(96.1083), 10: tensor(96.1800), 20: tensor(96.8283), 30: tensor(97.3133), 40: tensor(97.4900), 50: tensor(97.3750), 60: tensor(97.0833), 70: tensor(96.5850), 80: tensor(96.0617), 90: tensor(96.1083), 100: tensor(96.1800), 110: tensor(96.8283), 120: tensor(97.3133), 130: tensor(97.4900), 140: tensor(97.3750), 150: tensor(97.0833), 160: tensor(96.5850), 170: tensor(96.0617), 180: tensor(96.1083), 190: tensor(96.1800), 200: tensor(96.8283), 210: tensor(97.3133), 220: tensor(97.4900), 230: tensor(97.3750), 240: tensor(97.0833), 250: tensor(96.5850), 260: tensor(96.0617), 270: tensor(96.1083), 280: tensor(96.1800), 290: tensor(96.8283), 300: tensor(97.3133), 310: tensor(97.4900), 320: tensor(97.3750), 330: tensor(97.0833), 340: tensor(96.5850), 350: tensor(96.0617)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=8, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7456,                   Accuracy: 788/2000.0 (39.40%)



-= Testing valid =-
Test set: Average loss: 2.1589,                   Accuracy: 651/2000.0 (32.55%)



-= Testing valid =-
Test set: Average loss: 1.6153,                   Accuracy: 888/2000.0 (44.40%)



-= Testing valid =-
Test set: Average loss: 2.1272,                   Accuracy: 664/2000.0 (33.20%)



-= Testing valid =-
Test set: Average loss: 1.5890,                   Accuracy: 1036/2000.0 (51.80%)



-= Testing valid =-
Test set: Average loss: 0.3573,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.4279,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.3925,                   Accuracy: 1700/2000.0 (85.00%)



-= Testing valid =-
Test set: Average loss: 0.3734,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.2441,                   Accuracy: 1847/2000.0 (92.35%)



Epoch 10 train accuracy: 93.35%, valid accuracy 92.35%
-= Testing valid =-
Test set: Average loss: 0.2054,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.1944,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1867,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1808,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1653,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.2023,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1459,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1705,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1815,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1706,                   Accuracy: 1896/2000.0 (94.80%)



Epoch 20 train accuracy: 95.16%, valid accuracy 94.80%
-= Testing valid =-
Test set: Average loss: 0.1489,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1337,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1356,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1175,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1358,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1338,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1473,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1340,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1506,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1419,                   Accuracy: 1909/2000.0 (95.45%)



Epoch 30 train accuracy: 96.54%, valid accuracy 95.45%
-= Testing valid =-
Test set: Average loss: 0.1280,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1265,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1397,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1328,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1191,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1297,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1202,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1334,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1149,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1222,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 40 train accuracy: 96.93%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.1239,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1182,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1230,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1253,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1148,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1197,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1149,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1140,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1175,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 50 train accuracy: 97.01%, valid accuracy 96.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1379,                   Accuracy: 57528/60000 (95.88%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1377,                   Accuracy: 57443/60000 (95.74%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1190,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1107,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1058,                   Accuracy: 58152/60000 (96.92%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1051,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1117,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1245,                   Accuracy: 57773/60000 (96.29%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1369,                   Accuracy: 57544/60000 (95.91%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1379,                   Accuracy: 57528/60000 (95.88%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1377,                   Accuracy: 57443/60000 (95.74%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1190,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1107,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1058,                   Accuracy: 58152/60000 (96.92%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1051,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1117,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1245,                   Accuracy: 57773/60000 (96.29%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1369,                   Accuracy: 57544/60000 (95.91%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1379,                   Accuracy: 57528/60000 (95.88%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1377,                   Accuracy: 57443/60000 (95.74%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1190,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1107,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1058,                   Accuracy: 58152/60000 (96.92%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1051,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1117,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1245,                   Accuracy: 57773/60000 (96.29%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1369,                   Accuracy: 57544/60000 (95.91%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1379,                   Accuracy: 57528/60000 (95.88%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1377,                   Accuracy: 57443/60000 (95.74%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1190,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1107,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1058,                   Accuracy: 58152/60000 (96.92%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1051,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1117,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1245,                   Accuracy: 57773/60000 (96.29%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1369,                   Accuracy: 57544/60000 (95.91%)
{0: tensor(95.8800), 10: tensor(95.7383), 20: tensor(96.4117), 30: tensor(96.7350), 40: tensor(96.9200), 50: tensor(96.8683), 60: tensor(96.7050), 70: tensor(96.2883), 80: tensor(95.9067), 90: tensor(95.8800), 100: tensor(95.7383), 110: tensor(96.4117), 120: tensor(96.7350), 130: tensor(96.9200), 140: tensor(96.8683), 150: tensor(96.7050), 160: tensor(96.2883), 170: tensor(95.9067), 180: tensor(95.8800), 190: tensor(95.7383), 200: tensor(96.4117), 210: tensor(96.7350), 220: tensor(96.9200), 230: tensor(96.8683), 240: tensor(96.7050), 250: tensor(96.2883), 260: tensor(95.9067), 270: tensor(95.8800), 280: tensor(95.7383), 290: tensor(96.4117), 300: tensor(96.7350), 310: tensor(96.9200), 320: tensor(96.8683), 330: tensor(96.7050), 340: tensor(96.2883), 350: tensor(95.9067)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=9, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1764,                   Accuracy: 298/2000.0 (14.90%)



-= Testing valid =-
Test set: Average loss: 2.3279,                   Accuracy: 402/2000.0 (20.10%)



-= Testing valid =-
Test set: Average loss: 1.5958,                   Accuracy: 884/2000.0 (44.20%)



-= Testing valid =-
Test set: Average loss: 1.7962,                   Accuracy: 753/2000.0 (37.65%)



-= Testing valid =-
Test set: Average loss: 1.8175,                   Accuracy: 919/2000.0 (45.95%)



-= Testing valid =-
Test set: Average loss: 0.6200,                   Accuracy: 1532/2000.0 (76.60%)



-= Testing valid =-
Test set: Average loss: 1.0578,                   Accuracy: 1375/2000.0 (68.75%)



-= Testing valid =-
Test set: Average loss: 0.3223,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.4571,                   Accuracy: 1696/2000.0 (84.80%)



-= Testing valid =-
Test set: Average loss: 0.3156,                   Accuracy: 1791/2000.0 (89.55%)



Epoch 10 train accuracy: 93.35%, valid accuracy 89.55%
-= Testing valid =-
Test set: Average loss: 0.2961,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.2854,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.2120,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.3325,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.2276,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.2178,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.1926,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2090,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2446,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2175,                   Accuracy: 1862/2000.0 (93.10%)



Epoch 20 train accuracy: 95.91%, valid accuracy 93.10%
-= Testing valid =-
Test set: Average loss: 0.2071,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.2106,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.1737,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1602,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1789,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1311,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1744,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2102,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.1754,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1803,                   Accuracy: 1880/2000.0 (94.00%)



Epoch 30 train accuracy: 96.30%, valid accuracy 94.00%
-= Testing valid =-
Test set: Average loss: 0.1695,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1857,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.1448,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1483,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1583,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.2004,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.1436,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1477,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1697,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1429,                   Accuracy: 1909/2000.0 (95.45%)



Epoch 40 train accuracy: 96.79%, valid accuracy 95.45%
-= Testing valid =-
Test set: Average loss: 0.1426,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1520,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1683,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1479,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1594,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1543,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1378,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1664,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1556,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1478,                   Accuracy: 1900/2000.0 (95.00%)



Epoch 50 train accuracy: 97.00%, valid accuracy 95.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1656,                   Accuracy: 56837/60000 (94.73%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1791,                   Accuracy: 56547/60000 (94.25%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1426,                   Accuracy: 57339/60000 (95.57%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1322,                   Accuracy: 57506/60000 (95.84%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1309,                   Accuracy: 57495/60000 (95.82%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1318,                   Accuracy: 57521/60000 (95.87%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1391,                   Accuracy: 57328/60000 (95.55%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1547,                   Accuracy: 57001/60000 (95.00%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1788,                   Accuracy: 56551/60000 (94.25%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1656,                   Accuracy: 56837/60000 (94.73%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1791,                   Accuracy: 56547/60000 (94.25%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1426,                   Accuracy: 57339/60000 (95.57%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1322,                   Accuracy: 57506/60000 (95.84%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1309,                   Accuracy: 57495/60000 (95.82%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1318,                   Accuracy: 57521/60000 (95.87%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1391,                   Accuracy: 57328/60000 (95.55%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1547,                   Accuracy: 57001/60000 (95.00%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1788,                   Accuracy: 56551/60000 (94.25%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1656,                   Accuracy: 56837/60000 (94.73%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1791,                   Accuracy: 56547/60000 (94.25%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1426,                   Accuracy: 57339/60000 (95.57%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1322,                   Accuracy: 57506/60000 (95.84%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1309,                   Accuracy: 57495/60000 (95.82%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1318,                   Accuracy: 57521/60000 (95.87%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1391,                   Accuracy: 57328/60000 (95.55%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1547,                   Accuracy: 57001/60000 (95.00%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1788,                   Accuracy: 56551/60000 (94.25%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1656,                   Accuracy: 56837/60000 (94.73%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1791,                   Accuracy: 56547/60000 (94.25%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1426,                   Accuracy: 57339/60000 (95.57%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1322,                   Accuracy: 57506/60000 (95.84%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1309,                   Accuracy: 57495/60000 (95.82%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1318,                   Accuracy: 57521/60000 (95.87%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1391,                   Accuracy: 57328/60000 (95.55%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1547,                   Accuracy: 57001/60000 (95.00%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1788,                   Accuracy: 56551/60000 (94.25%)
{0: tensor(94.7283), 10: tensor(94.2450), 20: tensor(95.5650), 30: tensor(95.8433), 40: tensor(95.8250), 50: tensor(95.8683), 60: tensor(95.5467), 70: tensor(95.0017), 80: tensor(94.2517), 90: tensor(94.7283), 100: tensor(94.2450), 110: tensor(95.5650), 120: tensor(95.8433), 130: tensor(95.8250), 140: tensor(95.8683), 150: tensor(95.5467), 160: tensor(95.0017), 170: tensor(94.2517), 180: tensor(94.7283), 190: tensor(94.2450), 200: tensor(95.5650), 210: tensor(95.8433), 220: tensor(95.8250), 230: tensor(95.8683), 240: tensor(95.5467), 250: tensor(95.0017), 260: tensor(94.2517), 270: tensor(94.7283), 280: tensor(94.2450), 290: tensor(95.5650), 300: tensor(95.8433), 310: tensor(95.8250), 320: tensor(95.8683), 330: tensor(95.5467), 340: tensor(95.0017), 350: tensor(94.2517)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=10, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 8.4754,                   Accuracy: 254/2000.0 (12.70%)



-= Testing valid =-
Test set: Average loss: 2.1419,                   Accuracy: 649/2000.0 (32.45%)



-= Testing valid =-
Test set: Average loss: 2.3775,                   Accuracy: 531/2000.0 (26.55%)



-= Testing valid =-
Test set: Average loss: 1.2593,                   Accuracy: 1100/2000.0 (55.00%)



-= Testing valid =-
Test set: Average loss: 0.6928,                   Accuracy: 1531/2000.0 (76.55%)



-= Testing valid =-
Test set: Average loss: 0.5227,                   Accuracy: 1650/2000.0 (82.50%)



-= Testing valid =-
Test set: Average loss: 0.3782,                   Accuracy: 1740/2000.0 (87.00%)



-= Testing valid =-
Test set: Average loss: 0.3300,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.3230,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.3119,                   Accuracy: 1800/2000.0 (90.00%)



Epoch 10 train accuracy: 93.10%, valid accuracy 90.00%
-= Testing valid =-
Test set: Average loss: 0.2350,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.2583,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.1593,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.2502,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2059,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1520,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1549,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.2030,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1818,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.1536,                   Accuracy: 1905/2000.0 (95.25%)



Epoch 20 train accuracy: 95.38%, valid accuracy 95.25%
-= Testing valid =-
Test set: Average loss: 0.1465,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1631,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1295,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1386,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1481,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1457,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1398,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1393,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1395,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 30 train accuracy: 96.79%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.1272,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1301,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1263,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1285,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1246,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1092,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1188,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1162,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1180,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1305,                   Accuracy: 1914/2000.0 (95.70%)



Epoch 40 train accuracy: 96.72%, valid accuracy 95.70%
-= Testing valid =-
Test set: Average loss: 0.1200,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1130,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1275,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1146,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1089,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1117,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1107,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1152,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1156,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 50 train accuracy: 97.24%, valid accuracy 96.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1591,                   Accuracy: 57167/60000 (95.28%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1625,                   Accuracy: 56994/60000 (94.99%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1320,                   Accuracy: 57604/60000 (96.01%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1134,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1054,                   Accuracy: 58116/60000 (96.86%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1073,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1203,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1376,                   Accuracy: 57575/60000 (95.96%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1548,                   Accuracy: 57198/60000 (95.33%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1591,                   Accuracy: 57167/60000 (95.28%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1625,                   Accuracy: 56994/60000 (94.99%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1320,                   Accuracy: 57604/60000 (96.01%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1134,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1054,                   Accuracy: 58116/60000 (96.86%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1073,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1203,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1376,                   Accuracy: 57575/60000 (95.96%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1548,                   Accuracy: 57198/60000 (95.33%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1591,                   Accuracy: 57167/60000 (95.28%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1625,                   Accuracy: 56994/60000 (94.99%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1320,                   Accuracy: 57604/60000 (96.01%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1134,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1054,                   Accuracy: 58116/60000 (96.86%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1073,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1203,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1376,                   Accuracy: 57575/60000 (95.96%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1548,                   Accuracy: 57198/60000 (95.33%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1591,                   Accuracy: 57167/60000 (95.28%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1625,                   Accuracy: 56994/60000 (94.99%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1320,                   Accuracy: 57604/60000 (96.01%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1134,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1054,                   Accuracy: 58116/60000 (96.86%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1073,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1203,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1376,                   Accuracy: 57575/60000 (95.96%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1548,                   Accuracy: 57198/60000 (95.33%)
{0: tensor(95.2783), 10: tensor(94.9900), 20: tensor(96.0067), 30: tensor(96.5750), 40: tensor(96.8600), 50: tensor(96.8450), 60: tensor(96.4600), 70: tensor(95.9583), 80: tensor(95.3300), 90: tensor(95.2783), 100: tensor(94.9900), 110: tensor(96.0067), 120: tensor(96.5750), 130: tensor(96.8600), 140: tensor(96.8450), 150: tensor(96.4600), 160: tensor(95.9583), 170: tensor(95.3300), 180: tensor(95.2783), 190: tensor(94.9900), 200: tensor(96.0067), 210: tensor(96.5750), 220: tensor(96.8600), 230: tensor(96.8450), 240: tensor(96.4600), 250: tensor(95.9583), 260: tensor(95.3300), 270: tensor(95.2783), 280: tensor(94.9900), 290: tensor(96.0067), 300: tensor(96.5750), 310: tensor(96.8600), 320: tensor(96.8450), 330: tensor(96.4600), 340: tensor(95.9583), 350: tensor(95.3300)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=1, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6707,                   Accuracy: 225/2000.0 (11.25%)



-= Testing valid =-
Test set: Average loss: 2.1559,                   Accuracy: 518/2000.0 (25.90%)



-= Testing valid =-
Test set: Average loss: 0.7986,                   Accuracy: 1576/2000.0 (78.80%)



-= Testing valid =-
Test set: Average loss: 0.5738,                   Accuracy: 1615/2000.0 (80.75%)



-= Testing valid =-
Test set: Average loss: 0.3444,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.2761,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.3096,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.3130,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3304,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.2150,                   Accuracy: 1876/2000.0 (93.80%)



Epoch 10 train accuracy: 96.26%, valid accuracy 93.80%
-= Testing valid =-
Test set: Average loss: 0.1619,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.2398,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.1800,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.2346,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1730,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1211,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1501,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.2026,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.1353,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1601,                   Accuracy: 1901/2000.0 (95.05%)



Epoch 20 train accuracy: 97.78%, valid accuracy 95.05%
-= Testing valid =-
Test set: Average loss: 0.1318,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1106,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1276,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1241,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1137,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1242,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1143,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1106,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 30 train accuracy: 97.62%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0947,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1030,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 40 train accuracy: 98.21%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0937,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1010,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 50 train accuracy: 98.47%, valid accuracy 97.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0933,                   Accuracy: 58343/60000 (97.24%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0857,                   Accuracy: 58476/60000 (97.46%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0720,                   Accuracy: 58732/60000 (97.89%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0631,                   Accuracy: 58842/60000 (98.07%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0577,                   Accuracy: 58958/60000 (98.26%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0584,                   Accuracy: 58959/60000 (98.26%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0634,                   Accuracy: 58868/60000 (98.11%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0749,                   Accuracy: 58668/60000 (97.78%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.0970,                   Accuracy: 58283/60000 (97.14%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1300,                   Accuracy: 57840/60000 (96.40%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1819,                   Accuracy: 56854/60000 (94.76%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2661,                   Accuracy: 55277/60000 (92.13%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3830,                   Accuracy: 53148/60000 (88.58%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.5879,                   Accuracy: 49580/60000 (82.63%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8344,                   Accuracy: 45483/60000 (75.81%)
-= Testing Rotation 150 =-
Test set: Average loss: 1.1263,                   Accuracy: 41540/60000 (69.23%)
-= Testing Rotation 160 =-
Test set: Average loss: 1.4832,                   Accuracy: 38515/60000 (64.19%)
-= Testing Rotation 170 =-
Test set: Average loss: 1.7215,                   Accuracy: 37176/60000 (61.96%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.0214,                   Accuracy: 36080/60000 (60.13%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.3716,                   Accuracy: 34629/60000 (57.72%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.6514,                   Accuracy: 33664/60000 (56.11%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.9227,                   Accuracy: 32681/60000 (54.47%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.0627,                   Accuracy: 32884/60000 (54.81%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.1740,                   Accuracy: 32397/60000 (53.99%)
-= Testing Rotation 240 =-
Test set: Average loss: 3.1845,                   Accuracy: 31860/60000 (53.10%)
-= Testing Rotation 250 =-
Test set: Average loss: 3.0830,                   Accuracy: 31753/60000 (52.92%)
-= Testing Rotation 260 =-
Test set: Average loss: 2.7285,                   Accuracy: 32254/60000 (53.76%)
-= Testing Rotation 270 =-
Test set: Average loss: 2.3626,                   Accuracy: 33214/60000 (55.36%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.8054,                   Accuracy: 36766/60000 (61.28%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.2292,                   Accuracy: 41874/60000 (69.79%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.7931,                   Accuracy: 46739/60000 (77.90%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.5066,                   Accuracy: 51024/60000 (85.04%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3430,                   Accuracy: 53870/60000 (89.78%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2271,                   Accuracy: 55871/60000 (93.12%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1558,                   Accuracy: 57143/60000 (95.24%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1181,                   Accuracy: 57908/60000 (96.51%)
{0: tensor(97.2383), 10: tensor(97.4600), 20: tensor(97.8867), 30: tensor(98.0700), 40: tensor(98.2633), 50: tensor(98.2650), 60: tensor(98.1133), 70: tensor(97.7800), 80: tensor(97.1383), 90: tensor(96.4000), 100: tensor(94.7567), 110: tensor(92.1283), 120: tensor(88.5800), 130: tensor(82.6333), 140: tensor(75.8050), 150: tensor(69.2333), 160: tensor(64.1917), 170: tensor(61.9600), 180: tensor(60.1333), 190: tensor(57.7150), 200: tensor(56.1067), 210: tensor(54.4683), 220: tensor(54.8067), 230: tensor(53.9950), 240: tensor(53.1000), 250: tensor(52.9217), 260: tensor(53.7567), 270: tensor(55.3567), 280: tensor(61.2767), 290: tensor(69.7900), 300: tensor(77.8983), 310: tensor(85.0400), 320: tensor(89.7833), 330: tensor(93.1183), 340: tensor(95.2383), 350: tensor(96.5133)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=2, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2742,                   Accuracy: 398/2000.0 (19.90%)



-= Testing valid =-
Test set: Average loss: 1.7771,                   Accuracy: 633/2000.0 (31.65%)



-= Testing valid =-
Test set: Average loss: 1.1061,                   Accuracy: 1091/2000.0 (54.55%)



-= Testing valid =-
Test set: Average loss: 0.8709,                   Accuracy: 1446/2000.0 (72.30%)



-= Testing valid =-
Test set: Average loss: 0.3569,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.6904,                   Accuracy: 1556/2000.0 (77.80%)



-= Testing valid =-
Test set: Average loss: 0.6381,                   Accuracy: 1588/2000.0 (79.40%)



-= Testing valid =-
Test set: Average loss: 0.6295,                   Accuracy: 1585/2000.0 (79.25%)



-= Testing valid =-
Test set: Average loss: 0.9004,                   Accuracy: 1446/2000.0 (72.30%)



-= Testing valid =-
Test set: Average loss: 0.6171,                   Accuracy: 1584/2000.0 (79.20%)



Epoch 10 train accuracy: 95.90%, valid accuracy 79.20%
-= Testing valid =-
Test set: Average loss: 0.3445,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.2235,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.2632,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2045,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.2230,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.1497,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1556,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.3215,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.1612,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1754,                   Accuracy: 1888/2000.0 (94.40%)



Epoch 20 train accuracy: 97.89%, valid accuracy 94.40%
-= Testing valid =-
Test set: Average loss: 0.3438,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.1826,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1132,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1449,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1590,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1658,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1114,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1305,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1779,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1287,                   Accuracy: 1917/2000.0 (95.85%)



Epoch 30 train accuracy: 97.96%, valid accuracy 95.85%
-= Testing valid =-
Test set: Average loss: 0.1251,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1253,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1225,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1129,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1332,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1308,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1098,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1230,                   Accuracy: 1922/2000.0 (96.10%)



Epoch 40 train accuracy: 98.35%, valid accuracy 96.10%
-= Testing valid =-
Test set: Average loss: 0.1375,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1011,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 50 train accuracy: 98.34%, valid accuracy 96.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1132,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0987,                   Accuracy: 58237/60000 (97.06%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0840,                   Accuracy: 58481/60000 (97.47%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0721,                   Accuracy: 58693/60000 (97.82%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0660,                   Accuracy: 58799/60000 (98.00%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0637,                   Accuracy: 58838/60000 (98.06%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0693,                   Accuracy: 58755/60000 (97.93%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0792,                   Accuracy: 58569/60000 (97.61%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1037,                   Accuracy: 58161/60000 (96.93%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1500,                   Accuracy: 57413/60000 (95.69%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2408,                   Accuracy: 55844/60000 (93.07%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3885,                   Accuracy: 53192/60000 (88.65%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5706,                   Accuracy: 49732/60000 (82.89%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.8034,                   Accuracy: 45285/60000 (75.47%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0441,                   Accuracy: 41156/60000 (68.59%)
-= Testing Rotation 150 =-
Test set: Average loss: 1.3309,                   Accuracy: 37737/60000 (62.90%)
-= Testing Rotation 160 =-
Test set: Average loss: 1.6482,                   Accuracy: 35866/60000 (59.78%)
-= Testing Rotation 170 =-
Test set: Average loss: 1.8711,                   Accuracy: 35005/60000 (58.34%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.4521,                   Accuracy: 32308/60000 (53.85%)
-= Testing Rotation 190 =-
Test set: Average loss: 3.0863,                   Accuracy: 30894/60000 (51.49%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.6991,                   Accuracy: 29830/60000 (49.72%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.8889,                   Accuracy: 30156/60000 (50.26%)
-= Testing Rotation 220 =-
Test set: Average loss: 4.0225,                   Accuracy: 30651/60000 (51.08%)
-= Testing Rotation 230 =-
Test set: Average loss: 4.0015,                   Accuracy: 30952/60000 (51.59%)
-= Testing Rotation 240 =-
Test set: Average loss: 3.9152,                   Accuracy: 30749/60000 (51.25%)
-= Testing Rotation 250 =-
Test set: Average loss: 3.6575,                   Accuracy: 30614/60000 (51.02%)
-= Testing Rotation 260 =-
Test set: Average loss: 3.0365,                   Accuracy: 31410/60000 (52.35%)
-= Testing Rotation 270 =-
Test set: Average loss: 2.6804,                   Accuracy: 31886/60000 (53.14%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.9463,                   Accuracy: 34706/60000 (57.84%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.3853,                   Accuracy: 39633/60000 (66.06%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.8767,                   Accuracy: 45290/60000 (75.48%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.5363,                   Accuracy: 50528/60000 (84.21%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3501,                   Accuracy: 53764/60000 (89.61%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2423,                   Accuracy: 55766/60000 (92.94%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1684,                   Accuracy: 57026/60000 (95.04%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1440,                   Accuracy: 57420/60000 (95.70%)
{0: tensor(96.7333), 10: tensor(97.0617), 20: tensor(97.4683), 30: tensor(97.8217), 40: tensor(97.9983), 50: tensor(98.0633), 60: tensor(97.9250), 70: tensor(97.6150), 80: tensor(96.9350), 90: tensor(95.6883), 100: tensor(93.0733), 110: tensor(88.6533), 120: tensor(82.8867), 130: tensor(75.4750), 140: tensor(68.5933), 150: tensor(62.8950), 160: tensor(59.7767), 170: tensor(58.3417), 180: tensor(53.8467), 190: tensor(51.4900), 200: tensor(49.7167), 210: tensor(50.2600), 220: tensor(51.0850), 230: tensor(51.5867), 240: tensor(51.2483), 250: tensor(51.0233), 260: tensor(52.3500), 270: tensor(53.1433), 280: tensor(57.8433), 290: tensor(66.0550), 300: tensor(75.4833), 310: tensor(84.2133), 320: tensor(89.6067), 330: tensor(92.9433), 340: tensor(95.0433), 350: tensor(95.7000)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=3, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2691,                   Accuracy: 409/2000.0 (20.45%)



-= Testing valid =-
Test set: Average loss: 3.8134,                   Accuracy: 182/2000.0 (9.10%)



-= Testing valid =-
Test set: Average loss: 1.1806,                   Accuracy: 1139/2000.0 (56.95%)



-= Testing valid =-
Test set: Average loss: 0.8833,                   Accuracy: 1438/2000.0 (71.90%)



-= Testing valid =-
Test set: Average loss: 0.7312,                   Accuracy: 1501/2000.0 (75.05%)



-= Testing valid =-
Test set: Average loss: 0.4545,                   Accuracy: 1747/2000.0 (87.35%)



-= Testing valid =-
Test set: Average loss: 0.4935,                   Accuracy: 1718/2000.0 (85.90%)



-= Testing valid =-
Test set: Average loss: 0.3420,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.4028,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.2890,                   Accuracy: 1835/2000.0 (91.75%)



Epoch 10 train accuracy: 95.75%, valid accuracy 91.75%
-= Testing valid =-
Test set: Average loss: 0.1521,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.2098,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.2044,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1896,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1529,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1377,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1280,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1931,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1959,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1833,                   Accuracy: 1891/2000.0 (94.55%)



Epoch 20 train accuracy: 97.65%, valid accuracy 94.55%
-= Testing valid =-
Test set: Average loss: 0.1292,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1610,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1436,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1557,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1281,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1155,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1200,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1143,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1127,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1302,                   Accuracy: 1922/2000.0 (96.10%)



Epoch 30 train accuracy: 98.04%, valid accuracy 96.10%
-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1086,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1093,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1048,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 40 train accuracy: 98.62%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 50 train accuracy: 98.60%, valid accuracy 97.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1005,                   Accuracy: 58163/60000 (96.94%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0931,                   Accuracy: 58384/60000 (97.31%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0741,                   Accuracy: 58643/60000 (97.74%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0663,                   Accuracy: 58762/60000 (97.94%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0639,                   Accuracy: 58825/60000 (98.04%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0666,                   Accuracy: 58827/60000 (98.04%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0737,                   Accuracy: 58699/60000 (97.83%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0905,                   Accuracy: 58412/60000 (97.35%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1155,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1419,                   Accuracy: 57620/60000 (96.03%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1927,                   Accuracy: 56711/60000 (94.52%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2408,                   Accuracy: 55685/60000 (92.81%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3186,                   Accuracy: 53870/60000 (89.78%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4182,                   Accuracy: 51503/60000 (85.84%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.5345,                   Accuracy: 48716/60000 (81.19%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6809,                   Accuracy: 45938/60000 (76.56%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.8861,                   Accuracy: 43129/60000 (71.88%)
-= Testing Rotation 170 =-
Test set: Average loss: 1.1163,                   Accuracy: 40834/60000 (68.06%)
-= Testing Rotation 180 =-
Test set: Average loss: 1.4235,                   Accuracy: 38066/60000 (63.44%)
-= Testing Rotation 190 =-
Test set: Average loss: 1.7886,                   Accuracy: 35051/60000 (58.42%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.1178,                   Accuracy: 32874/60000 (54.79%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.3758,                   Accuracy: 31577/60000 (52.63%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.5335,                   Accuracy: 30819/60000 (51.37%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.6042,                   Accuracy: 30484/60000 (50.81%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.5662,                   Accuracy: 30550/60000 (50.92%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.4684,                   Accuracy: 30704/60000 (51.17%)
-= Testing Rotation 260 =-
Test set: Average loss: 2.1189,                   Accuracy: 32346/60000 (53.91%)
-= Testing Rotation 270 =-
Test set: Average loss: 1.7521,                   Accuracy: 35232/60000 (58.72%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.3836,                   Accuracy: 38406/60000 (64.01%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9698,                   Accuracy: 42807/60000 (71.35%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6440,                   Accuracy: 47430/60000 (79.05%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.4540,                   Accuracy: 51050/60000 (85.08%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3284,                   Accuracy: 53642/60000 (89.40%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2300,                   Accuracy: 55564/60000 (92.61%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1669,                   Accuracy: 56877/60000 (94.79%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1342,                   Accuracy: 57559/60000 (95.93%)
{0: tensor(96.9383), 10: tensor(97.3067), 20: tensor(97.7383), 30: tensor(97.9367), 40: tensor(98.0417), 50: tensor(98.0450), 60: tensor(97.8317), 70: tensor(97.3533), 80: tensor(96.6067), 90: tensor(96.0333), 100: tensor(94.5183), 110: tensor(92.8083), 120: tensor(89.7833), 130: tensor(85.8383), 140: tensor(81.1933), 150: tensor(76.5633), 160: tensor(71.8817), 170: tensor(68.0567), 180: tensor(63.4433), 190: tensor(58.4183), 200: tensor(54.7900), 210: tensor(52.6283), 220: tensor(51.3650), 230: tensor(50.8067), 240: tensor(50.9167), 250: tensor(51.1733), 260: tensor(53.9100), 270: tensor(58.7200), 280: tensor(64.0100), 290: tensor(71.3450), 300: tensor(79.0500), 310: tensor(85.0833), 320: tensor(89.4033), 330: tensor(92.6067), 340: tensor(94.7950), 350: tensor(95.9317)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=4, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.8605,                   Accuracy: 409/2000.0 (20.45%)



-= Testing valid =-
Test set: Average loss: 1.4142,                   Accuracy: 1036/2000.0 (51.80%)



-= Testing valid =-
Test set: Average loss: 0.7701,                   Accuracy: 1568/2000.0 (78.40%)



-= Testing valid =-
Test set: Average loss: 0.6279,                   Accuracy: 1626/2000.0 (81.30%)



-= Testing valid =-
Test set: Average loss: 0.3944,                   Accuracy: 1760/2000.0 (88.00%)



-= Testing valid =-
Test set: Average loss: 0.6523,                   Accuracy: 1490/2000.0 (74.50%)



-= Testing valid =-
Test set: Average loss: 0.7485,                   Accuracy: 1500/2000.0 (75.00%)



-= Testing valid =-
Test set: Average loss: 0.2444,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.3363,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.2756,                   Accuracy: 1827/2000.0 (91.35%)



Epoch 10 train accuracy: 96.03%, valid accuracy 91.35%
-= Testing valid =-
Test set: Average loss: 0.2105,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.1960,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1789,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1351,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.3507,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.1348,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1746,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1204,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1164,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 20 train accuracy: 97.34%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.1652,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1255,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1207,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1282,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1161,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1050,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1064,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1167,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1374,                   Accuracy: 1917/2000.0 (95.85%)



Epoch 30 train accuracy: 98.29%, valid accuracy 95.85%
-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1333,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1079,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1015,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1134,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 40 train accuracy: 98.66%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1079,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 50 train accuracy: 98.29%, valid accuracy 97.15%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1080,                   Accuracy: 58073/60000 (96.79%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0918,                   Accuracy: 58333/60000 (97.22%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0745,                   Accuracy: 58658/60000 (97.76%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0677,                   Accuracy: 58792/60000 (97.99%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0636,                   Accuracy: 58884/60000 (98.14%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0645,                   Accuracy: 58838/60000 (98.06%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0695,                   Accuracy: 58768/60000 (97.95%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0809,                   Accuracy: 58563/60000 (97.61%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1045,                   Accuracy: 58151/60000 (96.92%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1397,                   Accuracy: 57601/60000 (96.00%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2011,                   Accuracy: 56388/60000 (93.98%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2900,                   Accuracy: 54824/60000 (91.37%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4319,                   Accuracy: 52120/60000 (86.87%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.6307,                   Accuracy: 48409/60000 (80.68%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9166,                   Accuracy: 44134/60000 (73.56%)
-= Testing Rotation 150 =-
Test set: Average loss: 1.2438,                   Accuracy: 40683/60000 (67.81%)
-= Testing Rotation 160 =-
Test set: Average loss: 1.5576,                   Accuracy: 38079/60000 (63.47%)
-= Testing Rotation 170 =-
Test set: Average loss: 1.8160,                   Accuracy: 36049/60000 (60.08%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.1474,                   Accuracy: 34350/60000 (57.25%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.3699,                   Accuracy: 33242/60000 (55.40%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.5999,                   Accuracy: 32329/60000 (53.88%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.7786,                   Accuracy: 32307/60000 (53.85%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.9405,                   Accuracy: 32086/60000 (53.48%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9855,                   Accuracy: 32025/60000 (53.38%)
-= Testing Rotation 240 =-
Test set: Average loss: 3.0006,                   Accuracy: 31560/60000 (52.60%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.8275,                   Accuracy: 31836/60000 (53.06%)
-= Testing Rotation 260 =-
Test set: Average loss: 2.5060,                   Accuracy: 32547/60000 (54.24%)
-= Testing Rotation 270 =-
Test set: Average loss: 2.1070,                   Accuracy: 34705/60000 (57.84%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.5880,                   Accuracy: 38431/60000 (64.05%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0944,                   Accuracy: 43304/60000 (72.17%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6865,                   Accuracy: 47813/60000 (79.69%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.4176,                   Accuracy: 52094/60000 (86.82%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3075,                   Accuracy: 54230/60000 (90.38%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2442,                   Accuracy: 55491/60000 (92.49%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1807,                   Accuracy: 56651/60000 (94.42%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1410,                   Accuracy: 57444/60000 (95.74%)
{0: tensor(96.7883), 10: tensor(97.2217), 20: tensor(97.7633), 30: tensor(97.9867), 40: tensor(98.1400), 50: tensor(98.0633), 60: tensor(97.9467), 70: tensor(97.6050), 80: tensor(96.9183), 90: tensor(96.0017), 100: tensor(93.9800), 110: tensor(91.3733), 120: tensor(86.8667), 130: tensor(80.6817), 140: tensor(73.5567), 150: tensor(67.8050), 160: tensor(63.4650), 170: tensor(60.0817), 180: tensor(57.2500), 190: tensor(55.4033), 200: tensor(53.8817), 210: tensor(53.8450), 220: tensor(53.4767), 230: tensor(53.3750), 240: tensor(52.6000), 250: tensor(53.0600), 260: tensor(54.2450), 270: tensor(57.8417), 280: tensor(64.0517), 290: tensor(72.1733), 300: tensor(79.6883), 310: tensor(86.8233), 320: tensor(90.3833), 330: tensor(92.4850), 340: tensor(94.4183), 350: tensor(95.7400)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=5, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9993,                   Accuracy: 640/2000.0 (32.00%)



-= Testing valid =-
Test set: Average loss: 2.7274,                   Accuracy: 365/2000.0 (18.25%)



-= Testing valid =-
Test set: Average loss: 1.5248,                   Accuracy: 962/2000.0 (48.10%)



-= Testing valid =-
Test set: Average loss: 0.3975,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.5438,                   Accuracy: 1634/2000.0 (81.70%)



-= Testing valid =-
Test set: Average loss: 0.3240,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.4063,                   Accuracy: 1732/2000.0 (86.60%)



-= Testing valid =-
Test set: Average loss: 0.2600,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.4247,                   Accuracy: 1745/2000.0 (87.25%)



-= Testing valid =-
Test set: Average loss: 0.1672,                   Accuracy: 1901/2000.0 (95.05%)



Epoch 10 train accuracy: 96.36%, valid accuracy 95.05%
-= Testing valid =-
Test set: Average loss: 0.1656,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1776,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1991,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1729,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1487,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1304,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1332,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1711,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1327,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1686,                   Accuracy: 1897/2000.0 (94.85%)



Epoch 20 train accuracy: 97.41%, valid accuracy 94.85%
-= Testing valid =-
Test set: Average loss: 0.1172,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1179,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1263,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1355,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1303,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1321,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1160,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1159,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1168,                   Accuracy: 1921/2000.0 (96.05%)



Epoch 30 train accuracy: 98.03%, valid accuracy 96.05%
-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1275,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1339,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1096,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1493,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1187,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1353,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1212,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1255,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1431,                   Accuracy: 1909/2000.0 (95.45%)



Epoch 40 train accuracy: 98.34%, valid accuracy 95.45%
-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1218,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1324,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1206,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1171,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1270,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1260,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1152,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1137,                   Accuracy: 1920/2000.0 (96.00%)



Epoch 50 train accuracy: 98.57%, valid accuracy 96.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1146,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1008,                   Accuracy: 58182/60000 (96.97%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0794,                   Accuracy: 58566/60000 (97.61%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0707,                   Accuracy: 58718/60000 (97.86%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0677,                   Accuracy: 58766/60000 (97.94%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0688,                   Accuracy: 58799/60000 (98.00%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0756,                   Accuracy: 58655/60000 (97.76%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0904,                   Accuracy: 58371/60000 (97.29%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1141,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1298,                   Accuracy: 57787/60000 (96.31%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1734,                   Accuracy: 57005/60000 (95.01%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2004,                   Accuracy: 56498/60000 (94.16%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.2748,                   Accuracy: 54913/60000 (91.52%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4030,                   Accuracy: 52380/60000 (87.30%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.6177,                   Accuracy: 48219/60000 (80.36%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.9201,                   Accuracy: 43343/60000 (72.24%)
-= Testing Rotation 160 =-
Test set: Average loss: 1.3360,                   Accuracy: 39519/60000 (65.86%)
-= Testing Rotation 170 =-
Test set: Average loss: 1.7413,                   Accuracy: 36404/60000 (60.67%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.0234,                   Accuracy: 34323/60000 (57.21%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.2846,                   Accuracy: 32781/60000 (54.63%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.4572,                   Accuracy: 31903/60000 (53.17%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.6069,                   Accuracy: 31413/60000 (52.35%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.6436,                   Accuracy: 31422/60000 (52.37%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.6469,                   Accuracy: 31253/60000 (52.09%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.5742,                   Accuracy: 31243/60000 (52.07%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.3676,                   Accuracy: 32136/60000 (53.56%)
-= Testing Rotation 260 =-
Test set: Average loss: 2.1498,                   Accuracy: 33284/60000 (55.47%)
-= Testing Rotation 270 =-
Test set: Average loss: 1.8589,                   Accuracy: 34213/60000 (57.02%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.6520,                   Accuracy: 35256/60000 (58.76%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.2732,                   Accuracy: 38916/60000 (64.86%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.9423,                   Accuracy: 42681/60000 (71.14%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.6563,                   Accuracy: 47187/60000 (78.64%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.4710,                   Accuracy: 50788/60000 (84.65%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3164,                   Accuracy: 54030/60000 (90.05%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2185,                   Accuracy: 55944/60000 (93.24%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1561,                   Accuracy: 57145/60000 (95.24%)
{0: tensor(96.5067), 10: tensor(96.9700), 20: tensor(97.6100), 30: tensor(97.8633), 40: tensor(97.9433), 50: tensor(97.9983), 60: tensor(97.7583), 70: tensor(97.2850), 80: tensor(96.6717), 90: tensor(96.3117), 100: tensor(95.0083), 110: tensor(94.1633), 120: tensor(91.5217), 130: tensor(87.3000), 140: tensor(80.3650), 150: tensor(72.2383), 160: tensor(65.8650), 170: tensor(60.6733), 180: tensor(57.2050), 190: tensor(54.6350), 200: tensor(53.1717), 210: tensor(52.3550), 220: tensor(52.3700), 230: tensor(52.0883), 240: tensor(52.0717), 250: tensor(53.5600), 260: tensor(55.4733), 270: tensor(57.0217), 280: tensor(58.7600), 290: tensor(64.8600), 300: tensor(71.1350), 310: tensor(78.6450), 320: tensor(84.6467), 330: tensor(90.0500), 340: tensor(93.2400), 350: tensor(95.2417)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=6, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.8720,                   Accuracy: 303/2000.0 (15.15%)



-= Testing valid =-
Test set: Average loss: 1.7140,                   Accuracy: 789/2000.0 (39.45%)



-= Testing valid =-
Test set: Average loss: 1.5018,                   Accuracy: 888/2000.0 (44.40%)



-= Testing valid =-
Test set: Average loss: 1.4524,                   Accuracy: 1017/2000.0 (50.85%)



-= Testing valid =-
Test set: Average loss: 1.5530,                   Accuracy: 1163/2000.0 (58.15%)



-= Testing valid =-
Test set: Average loss: 0.9163,                   Accuracy: 1438/2000.0 (71.90%)



-= Testing valid =-
Test set: Average loss: 0.9074,                   Accuracy: 1412/2000.0 (70.60%)



-= Testing valid =-
Test set: Average loss: 0.2946,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.3029,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2609,                   Accuracy: 1831/2000.0 (91.55%)



Epoch 10 train accuracy: 95.86%, valid accuracy 91.55%
-= Testing valid =-
Test set: Average loss: 0.2067,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2403,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.4189,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.2550,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.2863,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.1991,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.2192,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.2724,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.1580,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1639,                   Accuracy: 1893/2000.0 (94.65%)



Epoch 20 train accuracy: 97.30%, valid accuracy 94.65%
-= Testing valid =-
Test set: Average loss: 0.1664,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1349,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1619,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1905,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.1569,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1356,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1491,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1569,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1290,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1688,                   Accuracy: 1893/2000.0 (94.65%)



Epoch 30 train accuracy: 98.11%, valid accuracy 94.65%
-= Testing valid =-
Test set: Average loss: 0.1199,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1071,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1363,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1053,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1130,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1918/2000.0 (95.90%)



Epoch 40 train accuracy: 98.16%, valid accuracy 95.90%
-= Testing valid =-
Test set: Average loss: 0.1152,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1228,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1302,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1216,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1317,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1196,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1183,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1092,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 50 train accuracy: 98.36%, valid accuracy 97.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1142,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0927,                   Accuracy: 58312/60000 (97.19%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0694,                   Accuracy: 58729/60000 (97.88%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0594,                   Accuracy: 58924/60000 (98.21%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0562,                   Accuracy: 58978/60000 (98.30%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0576,                   Accuracy: 58958/60000 (98.26%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0646,                   Accuracy: 58837/60000 (98.06%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0777,                   Accuracy: 58584/60000 (97.64%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1054,                   Accuracy: 58096/60000 (96.83%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1306,                   Accuracy: 57731/60000 (96.22%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1809,                   Accuracy: 56904/60000 (94.84%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2660,                   Accuracy: 55256/60000 (92.09%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4095,                   Accuracy: 52654/60000 (87.76%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.6470,                   Accuracy: 48684/60000 (81.14%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.9668,                   Accuracy: 43833/60000 (73.06%)
-= Testing Rotation 150 =-
Test set: Average loss: 1.3357,                   Accuracy: 39678/60000 (66.13%)
-= Testing Rotation 160 =-
Test set: Average loss: 1.7412,                   Accuracy: 37247/60000 (62.08%)
-= Testing Rotation 170 =-
Test set: Average loss: 2.1784,                   Accuracy: 34888/60000 (58.15%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.5545,                   Accuracy: 32971/60000 (54.95%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.8611,                   Accuracy: 32333/60000 (53.89%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.1287,                   Accuracy: 31865/60000 (53.11%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.3264,                   Accuracy: 31846/60000 (53.08%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.4258,                   Accuracy: 31888/60000 (53.15%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.4978,                   Accuracy: 31789/60000 (52.98%)
-= Testing Rotation 240 =-
Test set: Average loss: 3.5106,                   Accuracy: 31563/60000 (52.60%)
-= Testing Rotation 250 =-
Test set: Average loss: 3.4223,                   Accuracy: 31889/60000 (53.15%)
-= Testing Rotation 260 =-
Test set: Average loss: 3.0994,                   Accuracy: 32294/60000 (53.82%)
-= Testing Rotation 270 =-
Test set: Average loss: 2.6366,                   Accuracy: 33084/60000 (55.14%)
-= Testing Rotation 280 =-
Test set: Average loss: 2.0919,                   Accuracy: 34705/60000 (57.84%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.5282,                   Accuracy: 38187/60000 (63.65%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.0021,                   Accuracy: 42848/60000 (71.41%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.6679,                   Accuracy: 47585/60000 (79.31%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.4268,                   Accuracy: 51754/60000 (86.26%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2857,                   Accuracy: 54535/60000 (90.89%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2144,                   Accuracy: 56009/60000 (93.35%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1679,                   Accuracy: 56916/60000 (94.86%)
{0: tensor(96.6600), 10: tensor(97.1867), 20: tensor(97.8817), 30: tensor(98.2067), 40: tensor(98.2967), 50: tensor(98.2633), 60: tensor(98.0617), 70: tensor(97.6400), 80: tensor(96.8267), 90: tensor(96.2183), 100: tensor(94.8400), 110: tensor(92.0933), 120: tensor(87.7567), 130: tensor(81.1400), 140: tensor(73.0550), 150: tensor(66.1300), 160: tensor(62.0783), 170: tensor(58.1467), 180: tensor(54.9517), 190: tensor(53.8883), 200: tensor(53.1083), 210: tensor(53.0767), 220: tensor(53.1467), 230: tensor(52.9817), 240: tensor(52.6050), 250: tensor(53.1483), 260: tensor(53.8233), 270: tensor(55.1400), 280: tensor(57.8417), 290: tensor(63.6450), 300: tensor(71.4133), 310: tensor(79.3083), 320: tensor(86.2567), 330: tensor(90.8917), 340: tensor(93.3483), 350: tensor(94.8600)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=7, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0997,                   Accuracy: 191/2000.0 (9.55%)



-= Testing valid =-
Test set: Average loss: 1.2715,                   Accuracy: 1105/2000.0 (55.25%)



-= Testing valid =-
Test set: Average loss: 2.8023,                   Accuracy: 679/2000.0 (33.95%)



-= Testing valid =-
Test set: Average loss: 1.0190,                   Accuracy: 1327/2000.0 (66.35%)



-= Testing valid =-
Test set: Average loss: 0.4122,                   Accuracy: 1704/2000.0 (85.20%)



-= Testing valid =-
Test set: Average loss: 0.4437,                   Accuracy: 1736/2000.0 (86.80%)



-= Testing valid =-
Test set: Average loss: 0.3847,                   Accuracy: 1744/2000.0 (87.20%)



-= Testing valid =-
Test set: Average loss: 0.2053,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1328,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.2803,                   Accuracy: 1820/2000.0 (91.00%)



Epoch 10 train accuracy: 95.61%, valid accuracy 91.00%
-= Testing valid =-
Test set: Average loss: 0.2106,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1625,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1516,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.2119,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1786,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1184,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1978,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1388,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1640,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1212,                   Accuracy: 1923/2000.0 (96.15%)



Epoch 20 train accuracy: 97.60%, valid accuracy 96.15%
-= Testing valid =-
Test set: Average loss: 0.1127,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1052,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 30 train accuracy: 98.12%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0746,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 40 train accuracy: 98.51%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0746,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 50 train accuracy: 98.59%, valid accuracy 98.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0933,                   Accuracy: 58329/60000 (97.21%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0874,                   Accuracy: 58436/60000 (97.39%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0697,                   Accuracy: 58742/60000 (97.90%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0602,                   Accuracy: 58910/60000 (98.18%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0594,                   Accuracy: 58911/60000 (98.18%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0627,                   Accuracy: 58888/60000 (98.15%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0692,                   Accuracy: 58755/60000 (97.93%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0860,                   Accuracy: 58480/60000 (97.47%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1162,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1360,                   Accuracy: 57700/60000 (96.17%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2024,                   Accuracy: 56502/60000 (94.17%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2543,                   Accuracy: 55434/60000 (92.39%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3465,                   Accuracy: 53426/60000 (89.04%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4726,                   Accuracy: 50777/60000 (84.63%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.6226,                   Accuracy: 47932/60000 (79.89%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.8334,                   Accuracy: 44707/60000 (74.51%)
-= Testing Rotation 160 =-
Test set: Average loss: 1.0451,                   Accuracy: 42300/60000 (70.50%)
-= Testing Rotation 170 =-
Test set: Average loss: 1.3045,                   Accuracy: 40108/60000 (66.85%)
-= Testing Rotation 180 =-
Test set: Average loss: 1.6926,                   Accuracy: 37050/60000 (61.75%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.0392,                   Accuracy: 35160/60000 (58.60%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.3922,                   Accuracy: 33551/60000 (55.92%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.6848,                   Accuracy: 32488/60000 (54.15%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.7739,                   Accuracy: 32261/60000 (53.77%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7402,                   Accuracy: 32163/60000 (53.60%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.6076,                   Accuracy: 32640/60000 (54.40%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.2636,                   Accuracy: 34108/60000 (56.85%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.8184,                   Accuracy: 36947/60000 (61.58%)
-= Testing Rotation 270 =-
Test set: Average loss: 1.4112,                   Accuracy: 39810/60000 (66.35%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.0002,                   Accuracy: 43307/60000 (72.18%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7014,                   Accuracy: 47350/60000 (78.92%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5052,                   Accuracy: 50349/60000 (83.92%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3807,                   Accuracy: 52478/60000 (87.46%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3018,                   Accuracy: 54124/60000 (90.21%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2209,                   Accuracy: 55844/60000 (93.07%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1680,                   Accuracy: 56892/60000 (94.82%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1415,                   Accuracy: 57447/60000 (95.75%)
{0: tensor(97.2150), 10: tensor(97.3933), 20: tensor(97.9033), 30: tensor(98.1833), 40: tensor(98.1850), 50: tensor(98.1467), 60: tensor(97.9250), 70: tensor(97.4667), 80: tensor(96.6050), 90: tensor(96.1667), 100: tensor(94.1700), 110: tensor(92.3900), 120: tensor(89.0433), 130: tensor(84.6283), 140: tensor(79.8867), 150: tensor(74.5117), 160: tensor(70.5000), 170: tensor(66.8467), 180: tensor(61.7500), 190: tensor(58.6000), 200: tensor(55.9183), 210: tensor(54.1467), 220: tensor(53.7683), 230: tensor(53.6050), 240: tensor(54.4000), 250: tensor(56.8467), 260: tensor(61.5783), 270: tensor(66.3500), 280: tensor(72.1783), 290: tensor(78.9167), 300: tensor(83.9150), 310: tensor(87.4633), 320: tensor(90.2067), 330: tensor(93.0733), 340: tensor(94.8200), 350: tensor(95.7450)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=8, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1068,                   Accuracy: 467/2000.0 (23.35%)



-= Testing valid =-
Test set: Average loss: 1.6445,                   Accuracy: 724/2000.0 (36.20%)



-= Testing valid =-
Test set: Average loss: 3.0749,                   Accuracy: 481/2000.0 (24.05%)



-= Testing valid =-
Test set: Average loss: 1.3098,                   Accuracy: 1051/2000.0 (52.55%)



-= Testing valid =-
Test set: Average loss: 0.7985,                   Accuracy: 1488/2000.0 (74.40%)



-= Testing valid =-
Test set: Average loss: 0.6387,                   Accuracy: 1572/2000.0 (78.60%)



-= Testing valid =-
Test set: Average loss: 0.7084,                   Accuracy: 1545/2000.0 (77.25%)



-= Testing valid =-
Test set: Average loss: 0.3723,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.5046,                   Accuracy: 1676/2000.0 (83.80%)



-= Testing valid =-
Test set: Average loss: 0.2357,                   Accuracy: 1855/2000.0 (92.75%)



Epoch 10 train accuracy: 96.07%, valid accuracy 92.75%
-= Testing valid =-
Test set: Average loss: 0.2602,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.2246,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.1579,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1541,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1877,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1287,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1534,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1915,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1605,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.2051,                   Accuracy: 1882/2000.0 (94.10%)



Epoch 20 train accuracy: 97.56%, valid accuracy 94.10%
-= Testing valid =-
Test set: Average loss: 0.2089,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2453,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.1267,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1498,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.2005,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1555,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1561,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.2296,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2053,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.1994,                   Accuracy: 1881/2000.0 (94.05%)



Epoch 30 train accuracy: 98.22%, valid accuracy 94.05%
-= Testing valid =-
Test set: Average loss: 0.1256,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1458,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1416,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1537,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1679,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1815,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1522,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1538,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1995,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.1955,                   Accuracy: 1872/2000.0 (93.60%)



Epoch 40 train accuracy: 98.25%, valid accuracy 93.60%
-= Testing valid =-
Test set: Average loss: 0.1546,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1920,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1375,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1468,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1460,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1320,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1438,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1257,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1284,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1471,                   Accuracy: 1922/2000.0 (96.10%)



Epoch 50 train accuracy: 98.44%, valid accuracy 96.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1464,                   Accuracy: 57514/60000 (95.86%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1214,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0947,                   Accuracy: 58299/60000 (97.17%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0876,                   Accuracy: 58456/60000 (97.43%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0834,                   Accuracy: 58583/60000 (97.64%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0871,                   Accuracy: 58530/60000 (97.55%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0947,                   Accuracy: 58393/60000 (97.32%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1088,                   Accuracy: 58159/60000 (96.93%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1403,                   Accuracy: 57584/60000 (95.97%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1744,                   Accuracy: 57086/60000 (95.14%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2163,                   Accuracy: 56360/60000 (93.93%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2463,                   Accuracy: 55719/60000 (92.86%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3170,                   Accuracy: 54162/60000 (90.27%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3977,                   Accuracy: 52433/60000 (87.39%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.5096,                   Accuracy: 50058/60000 (83.43%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.6823,                   Accuracy: 46990/60000 (78.32%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.8410,                   Accuracy: 44443/60000 (74.07%)
-= Testing Rotation 170 =-
Test set: Average loss: 1.1131,                   Accuracy: 40600/60000 (67.67%)
-= Testing Rotation 180 =-
Test set: Average loss: 1.3051,                   Accuracy: 38508/60000 (64.18%)
-= Testing Rotation 190 =-
Test set: Average loss: 1.6679,                   Accuracy: 35440/60000 (59.07%)
-= Testing Rotation 200 =-
Test set: Average loss: 1.9023,                   Accuracy: 34321/60000 (57.20%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.1111,                   Accuracy: 33286/60000 (55.48%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.2255,                   Accuracy: 32832/60000 (54.72%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.2783,                   Accuracy: 32401/60000 (54.00%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.2480,                   Accuracy: 32162/60000 (53.60%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.1183,                   Accuracy: 31871/60000 (53.12%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.8457,                   Accuracy: 33060/60000 (55.10%)
-= Testing Rotation 270 =-
Test set: Average loss: 1.3547,                   Accuracy: 37779/60000 (62.97%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.1360,                   Accuracy: 39837/60000 (66.39%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.7431,                   Accuracy: 46161/60000 (76.93%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5196,                   Accuracy: 50119/60000 (83.53%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.4125,                   Accuracy: 52067/60000 (86.78%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3537,                   Accuracy: 53204/60000 (88.67%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2959,                   Accuracy: 54355/60000 (90.59%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2538,                   Accuracy: 55143/60000 (91.90%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1894,                   Accuracy: 56695/60000 (94.49%)
{0: tensor(95.8567), 10: tensor(96.5250), 20: tensor(97.1650), 30: tensor(97.4267), 40: tensor(97.6383), 50: tensor(97.5500), 60: tensor(97.3217), 70: tensor(96.9317), 80: tensor(95.9733), 90: tensor(95.1433), 100: tensor(93.9333), 110: tensor(92.8650), 120: tensor(90.2700), 130: tensor(87.3883), 140: tensor(83.4300), 150: tensor(78.3167), 160: tensor(74.0717), 170: tensor(67.6667), 180: tensor(64.1800), 190: tensor(59.0667), 200: tensor(57.2017), 210: tensor(55.4767), 220: tensor(54.7200), 230: tensor(54.0017), 240: tensor(53.6033), 250: tensor(53.1183), 260: tensor(55.1000), 270: tensor(62.9650), 280: tensor(66.3950), 290: tensor(76.9350), 300: tensor(83.5317), 310: tensor(86.7783), 320: tensor(88.6733), 330: tensor(90.5917), 340: tensor(91.9050), 350: tensor(94.4917)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=9, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5204,                   Accuracy: 387/2000.0 (19.35%)



-= Testing valid =-
Test set: Average loss: 1.8445,                   Accuracy: 561/2000.0 (28.05%)



-= Testing valid =-
Test set: Average loss: 1.6258,                   Accuracy: 766/2000.0 (38.30%)



-= Testing valid =-
Test set: Average loss: 0.8897,                   Accuracy: 1370/2000.0 (68.50%)



-= Testing valid =-
Test set: Average loss: 0.4648,                   Accuracy: 1695/2000.0 (84.75%)



-= Testing valid =-
Test set: Average loss: 0.3460,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.2719,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2472,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.2826,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.2209,                   Accuracy: 1867/2000.0 (93.35%)



Epoch 10 train accuracy: 96.07%, valid accuracy 93.35%
-= Testing valid =-
Test set: Average loss: 0.2425,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.1362,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1884,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1827,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1600,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1364,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1840,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1291,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1301,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1980,                   Accuracy: 1869/2000.0 (93.45%)



Epoch 20 train accuracy: 97.93%, valid accuracy 93.45%
-= Testing valid =-
Test set: Average loss: 0.1514,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1189,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1346,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1709,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1370,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1218,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1206,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1167,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1119,                   Accuracy: 1934/2000.0 (96.70%)



Epoch 30 train accuracy: 98.12%, valid accuracy 96.70%
-= Testing valid =-
Test set: Average loss: 0.1012,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 40 train accuracy: 98.16%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 50 train accuracy: 98.45%, valid accuracy 97.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1153,                   Accuracy: 57965/60000 (96.61%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1106,                   Accuracy: 58092/60000 (96.82%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0832,                   Accuracy: 58509/60000 (97.51%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0723,                   Accuracy: 58712/60000 (97.85%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0719,                   Accuracy: 58680/60000 (97.80%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0755,                   Accuracy: 58646/60000 (97.74%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0827,                   Accuracy: 58518/60000 (97.53%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0994,                   Accuracy: 58184/60000 (96.97%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1355,                   Accuracy: 57591/60000 (95.99%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1416,                   Accuracy: 57568/60000 (95.95%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2056,                   Accuracy: 56399/60000 (94.00%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2364,                   Accuracy: 55728/60000 (92.88%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.2977,                   Accuracy: 54405/60000 (90.68%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4190,                   Accuracy: 51922/60000 (86.54%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.5780,                   Accuracy: 49144/60000 (81.91%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7986,                   Accuracy: 45990/60000 (76.65%)
-= Testing Rotation 160 =-
Test set: Average loss: 1.1671,                   Accuracy: 42042/60000 (70.07%)
-= Testing Rotation 170 =-
Test set: Average loss: 1.5874,                   Accuracy: 38501/60000 (64.17%)
-= Testing Rotation 180 =-
Test set: Average loss: 1.9492,                   Accuracy: 35715/60000 (59.53%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.3661,                   Accuracy: 33344/60000 (55.57%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.6513,                   Accuracy: 31375/60000 (52.29%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.8309,                   Accuracy: 31480/60000 (52.47%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.8991,                   Accuracy: 31840/60000 (53.07%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8894,                   Accuracy: 32023/60000 (53.37%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.7948,                   Accuracy: 32317/60000 (53.86%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.6256,                   Accuracy: 32434/60000 (54.06%)
-= Testing Rotation 260 =-
Test set: Average loss: 2.2833,                   Accuracy: 33513/60000 (55.85%)
-= Testing Rotation 270 =-
Test set: Average loss: 2.0137,                   Accuracy: 34386/60000 (57.31%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.6745,                   Accuracy: 36885/60000 (61.47%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.2019,                   Accuracy: 41684/60000 (69.47%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.8270,                   Accuracy: 46051/60000 (76.75%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.5528,                   Accuracy: 50008/60000 (83.35%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3868,                   Accuracy: 52990/60000 (88.32%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2710,                   Accuracy: 55175/60000 (91.96%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1933,                   Accuracy: 56523/60000 (94.21%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1628,                   Accuracy: 57079/60000 (95.13%)
{0: tensor(96.6083), 10: tensor(96.8200), 20: tensor(97.5150), 30: tensor(97.8533), 40: tensor(97.8000), 50: tensor(97.7433), 60: tensor(97.5300), 70: tensor(96.9733), 80: tensor(95.9850), 90: tensor(95.9467), 100: tensor(93.9983), 110: tensor(92.8800), 120: tensor(90.6750), 130: tensor(86.5367), 140: tensor(81.9067), 150: tensor(76.6500), 160: tensor(70.0700), 170: tensor(64.1683), 180: tensor(59.5250), 190: tensor(55.5733), 200: tensor(52.2917), 210: tensor(52.4667), 220: tensor(53.0667), 230: tensor(53.3717), 240: tensor(53.8617), 250: tensor(54.0567), 260: tensor(55.8550), 270: tensor(57.3100), 280: tensor(61.4750), 290: tensor(69.4733), 300: tensor(76.7517), 310: tensor(83.3467), 320: tensor(88.3167), 330: tensor(91.9583), 340: tensor(94.2050), 350: tensor(95.1317)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=10, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.7360,                   Accuracy: 256/2000.0 (12.80%)



-= Testing valid =-
Test set: Average loss: 3.6618,                   Accuracy: 340/2000.0 (17.00%)



-= Testing valid =-
Test set: Average loss: 1.2533,                   Accuracy: 1095/2000.0 (54.75%)



-= Testing valid =-
Test set: Average loss: 1.5424,                   Accuracy: 1022/2000.0 (51.10%)



-= Testing valid =-
Test set: Average loss: 0.8969,                   Accuracy: 1383/2000.0 (69.15%)



-= Testing valid =-
Test set: Average loss: 0.4180,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.7389,                   Accuracy: 1554/2000.0 (77.70%)



-= Testing valid =-
Test set: Average loss: 0.3250,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.2125,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.3514,                   Accuracy: 1788/2000.0 (89.40%)



Epoch 10 train accuracy: 95.62%, valid accuracy 89.40%
-= Testing valid =-
Test set: Average loss: 0.2371,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1890,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.3526,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.2111,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.2644,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.1562,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1761,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.3072,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.1367,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1556,                   Accuracy: 1905/2000.0 (95.25%)



Epoch 20 train accuracy: 96.79%, valid accuracy 95.25%
-= Testing valid =-
Test set: Average loss: 0.1619,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1076,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1318,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1483,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1071,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1273,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 30 train accuracy: 97.96%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 40 train accuracy: 98.26%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0798,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 50 train accuracy: 98.62%, valid accuracy 97.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1206,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1028,                   Accuracy: 58211/60000 (97.02%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0833,                   Accuracy: 58547/60000 (97.58%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0763,                   Accuracy: 58652/60000 (97.75%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0739,                   Accuracy: 58672/60000 (97.79%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0777,                   Accuracy: 58630/60000 (97.72%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0885,                   Accuracy: 58475/60000 (97.46%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1035,                   Accuracy: 58216/60000 (97.03%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1323,                   Accuracy: 57743/60000 (96.24%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1700,                   Accuracy: 57206/60000 (95.34%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2189,                   Accuracy: 56214/60000 (93.69%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2777,                   Accuracy: 54945/60000 (91.57%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3689,                   Accuracy: 52928/60000 (88.21%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.5040,                   Accuracy: 49813/60000 (83.02%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.6655,                   Accuracy: 46488/60000 (77.48%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.9091,                   Accuracy: 42523/60000 (70.87%)
-= Testing Rotation 160 =-
Test set: Average loss: 1.2253,                   Accuracy: 39213/60000 (65.36%)
-= Testing Rotation 170 =-
Test set: Average loss: 1.5607,                   Accuracy: 37221/60000 (62.03%)
-= Testing Rotation 180 =-
Test set: Average loss: 1.9115,                   Accuracy: 35000/60000 (58.33%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.1662,                   Accuracy: 34269/60000 (57.12%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.4978,                   Accuracy: 32662/60000 (54.44%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.7264,                   Accuracy: 32099/60000 (53.50%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.7458,                   Accuracy: 32488/60000 (54.15%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.7877,                   Accuracy: 32736/60000 (54.56%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.8065,                   Accuracy: 32851/60000 (54.75%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.6620,                   Accuracy: 33698/60000 (56.16%)
-= Testing Rotation 260 =-
Test set: Average loss: 2.3827,                   Accuracy: 34100/60000 (56.83%)
-= Testing Rotation 270 =-
Test set: Average loss: 2.0096,                   Accuracy: 35211/60000 (58.69%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.5236,                   Accuracy: 38237/60000 (63.73%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.0807,                   Accuracy: 42149/60000 (70.25%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.7435,                   Accuracy: 46403/60000 (77.34%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.4832,                   Accuracy: 50885/60000 (84.81%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3443,                   Accuracy: 53618/60000 (89.36%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2521,                   Accuracy: 55557/60000 (92.60%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1923,                   Accuracy: 56626/60000 (94.38%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1497,                   Accuracy: 57429/60000 (95.71%)
{0: tensor(96.6117), 10: tensor(97.0183), 20: tensor(97.5783), 30: tensor(97.7533), 40: tensor(97.7867), 50: tensor(97.7167), 60: tensor(97.4583), 70: tensor(97.0267), 80: tensor(96.2383), 90: tensor(95.3433), 100: tensor(93.6900), 110: tensor(91.5750), 120: tensor(88.2133), 130: tensor(83.0217), 140: tensor(77.4800), 150: tensor(70.8717), 160: tensor(65.3550), 170: tensor(62.0350), 180: tensor(58.3333), 190: tensor(57.1150), 200: tensor(54.4367), 210: tensor(53.4983), 220: tensor(54.1467), 230: tensor(54.5600), 240: tensor(54.7517), 250: tensor(56.1633), 260: tensor(56.8333), 270: tensor(58.6850), 280: tensor(63.7283), 290: tensor(70.2483), 300: tensor(77.3383), 310: tensor(84.8083), 320: tensor(89.3633), 330: tensor(92.5950), 340: tensor(94.3767), 350: tensor(95.7150)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=1, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8414,                   Accuracy: 648/2000.0 (32.40%)



-= Testing valid =-
Test set: Average loss: 2.1520,                   Accuracy: 320/2000.0 (16.00%)



-= Testing valid =-
Test set: Average loss: 0.8585,                   Accuracy: 1457/2000.0 (72.85%)



-= Testing valid =-
Test set: Average loss: 0.8184,                   Accuracy: 1378/2000.0 (68.90%)



-= Testing valid =-
Test set: Average loss: 2.0843,                   Accuracy: 884/2000.0 (44.20%)



-= Testing valid =-
Test set: Average loss: 0.2827,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.5527,                   Accuracy: 1638/2000.0 (81.90%)



-= Testing valid =-
Test set: Average loss: 0.2737,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.1906,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.4923,                   Accuracy: 1646/2000.0 (82.30%)



Epoch 10 train accuracy: 96.54%, valid accuracy 82.30%
-= Testing valid =-
Test set: Average loss: 0.2619,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2575,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.1398,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1630,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1662,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1536,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1552,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1717,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1577,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1299,                   Accuracy: 1928/2000.0 (96.40%)



Epoch 20 train accuracy: 97.88%, valid accuracy 96.40%
-= Testing valid =-
Test set: Average loss: 0.1069,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1701,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1033,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1259,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1427,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1164,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1251,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 30 train accuracy: 98.09%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1067,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1203,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 40 train accuracy: 98.32%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.1034,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1052,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 50 train accuracy: 98.60%, valid accuracy 97.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1045,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0889,                   Accuracy: 58392/60000 (97.32%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0744,                   Accuracy: 58692/60000 (97.82%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0679,                   Accuracy: 58812/60000 (98.02%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0651,                   Accuracy: 58854/60000 (98.09%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0664,                   Accuracy: 58841/60000 (98.07%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0726,                   Accuracy: 58737/60000 (97.89%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0845,                   Accuracy: 58536/60000 (97.56%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1042,                   Accuracy: 58253/60000 (97.09%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1296,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1686,                   Accuracy: 57180/60000 (95.30%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2271,                   Accuracy: 56047/60000 (93.41%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3282,                   Accuracy: 54054/60000 (90.09%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4475,                   Accuracy: 51489/60000 (85.82%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.6209,                   Accuracy: 47768/60000 (79.61%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.8365,                   Accuracy: 44165/60000 (73.61%)
-= Testing Rotation 160 =-
Test set: Average loss: 1.1080,                   Accuracy: 40899/60000 (68.17%)
-= Testing Rotation 170 =-
Test set: Average loss: 1.4014,                   Accuracy: 38806/60000 (64.68%)
-= Testing Rotation 180 =-
Test set: Average loss: 1.9637,                   Accuracy: 35094/60000 (58.49%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.2277,                   Accuracy: 34040/60000 (56.73%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.6073,                   Accuracy: 32877/60000 (54.79%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.9213,                   Accuracy: 31984/60000 (53.31%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.0144,                   Accuracy: 31803/60000 (53.01%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.0175,                   Accuracy: 31616/60000 (52.69%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.9139,                   Accuracy: 31660/60000 (52.77%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.7409,                   Accuracy: 31921/60000 (53.20%)
-= Testing Rotation 260 =-
Test set: Average loss: 2.4178,                   Accuracy: 32366/60000 (53.94%)
-= Testing Rotation 270 =-
Test set: Average loss: 2.0920,                   Accuracy: 33646/60000 (56.08%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.5850,                   Accuracy: 36987/60000 (61.65%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.1631,                   Accuracy: 41199/60000 (68.67%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.7464,                   Accuracy: 46350/60000 (77.25%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.4986,                   Accuracy: 50551/60000 (84.25%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3545,                   Accuracy: 53471/60000 (89.12%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2597,                   Accuracy: 55110/60000 (91.85%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1918,                   Accuracy: 56464/60000 (94.11%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1447,                   Accuracy: 57314/60000 (95.52%)
{0: tensor(96.8367), 10: tensor(97.3200), 20: tensor(97.8200), 30: tensor(98.0200), 40: tensor(98.0900), 50: tensor(98.0683), 60: tensor(97.8950), 70: tensor(97.5600), 80: tensor(97.0883), 90: tensor(96.3600), 100: tensor(95.3000), 110: tensor(93.4117), 120: tensor(90.0900), 130: tensor(85.8150), 140: tensor(79.6133), 150: tensor(73.6083), 160: tensor(68.1650), 170: tensor(64.6767), 180: tensor(58.4900), 190: tensor(56.7333), 200: tensor(54.7950), 210: tensor(53.3067), 220: tensor(53.0050), 230: tensor(52.6933), 240: tensor(52.7667), 250: tensor(53.2017), 260: tensor(53.9433), 270: tensor(56.0767), 280: tensor(61.6450), 290: tensor(68.6650), 300: tensor(77.2500), 310: tensor(84.2517), 320: tensor(89.1183), 330: tensor(91.8500), 340: tensor(94.1067), 350: tensor(95.5233)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=2, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4818,                   Accuracy: 251/2000.0 (12.55%)



-= Testing valid =-
Test set: Average loss: 1.7437,                   Accuracy: 727/2000.0 (36.35%)



-= Testing valid =-
Test set: Average loss: 1.0342,                   Accuracy: 1300/2000.0 (65.00%)



-= Testing valid =-
Test set: Average loss: 0.6300,                   Accuracy: 1628/2000.0 (81.40%)



-= Testing valid =-
Test set: Average loss: 0.3335,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.6925,                   Accuracy: 1511/2000.0 (75.55%)



-= Testing valid =-
Test set: Average loss: 0.9114,                   Accuracy: 1398/2000.0 (69.90%)



-= Testing valid =-
Test set: Average loss: 0.3010,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.6449,                   Accuracy: 1582/2000.0 (79.10%)



-= Testing valid =-
Test set: Average loss: 0.1887,                   Accuracy: 1905/2000.0 (95.25%)



Epoch 10 train accuracy: 96.01%, valid accuracy 95.25%
-= Testing valid =-
Test set: Average loss: 0.1441,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1528,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1970,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1485,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.2186,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1291,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.3170,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.1645,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1764,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1878,                   Accuracy: 1883/2000.0 (94.15%)



Epoch 20 train accuracy: 97.94%, valid accuracy 94.15%
-= Testing valid =-
Test set: Average loss: 0.1609,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1130,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1333,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1305,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1489,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1292,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1259,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 30 train accuracy: 98.14%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.1198,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1188,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1069,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1148,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1164,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1071,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1175,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1415,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1210,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1176,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 40 train accuracy: 98.40%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.1212,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1051,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0909,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1071,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 50 train accuracy: 98.66%, valid accuracy 97.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1055,                   Accuracy: 58138/60000 (96.90%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0885,                   Accuracy: 58400/60000 (97.33%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0691,                   Accuracy: 58732/60000 (97.89%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0610,                   Accuracy: 58884/60000 (98.14%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0567,                   Accuracy: 58978/60000 (98.30%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0596,                   Accuracy: 58916/60000 (98.19%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0694,                   Accuracy: 58754/60000 (97.92%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0839,                   Accuracy: 58458/60000 (97.43%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1133,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1390,                   Accuracy: 57565/60000 (95.94%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2037,                   Accuracy: 56371/60000 (93.95%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2758,                   Accuracy: 54970/60000 (91.62%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3935,                   Accuracy: 52293/60000 (87.15%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.5471,                   Accuracy: 48895/60000 (81.49%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.7100,                   Accuracy: 46116/60000 (76.86%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.9119,                   Accuracy: 43264/60000 (72.11%)
-= Testing Rotation 160 =-
Test set: Average loss: 1.1856,                   Accuracy: 40408/60000 (67.35%)
-= Testing Rotation 170 =-
Test set: Average loss: 1.4935,                   Accuracy: 37634/60000 (62.72%)
-= Testing Rotation 180 =-
Test set: Average loss: 1.9608,                   Accuracy: 34014/60000 (56.69%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.4801,                   Accuracy: 31904/60000 (53.17%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.9311,                   Accuracy: 31426/60000 (52.38%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.2771,                   Accuracy: 31740/60000 (52.90%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.3907,                   Accuracy: 31909/60000 (53.18%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.4301,                   Accuracy: 31613/60000 (52.69%)
-= Testing Rotation 240 =-
Test set: Average loss: 3.4011,                   Accuracy: 30879/60000 (51.47%)
-= Testing Rotation 250 =-
Test set: Average loss: 3.1388,                   Accuracy: 30954/60000 (51.59%)
-= Testing Rotation 260 =-
Test set: Average loss: 2.6106,                   Accuracy: 32470/60000 (54.12%)
-= Testing Rotation 270 =-
Test set: Average loss: 2.0860,                   Accuracy: 34240/60000 (57.07%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.3753,                   Accuracy: 39405/60000 (65.68%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.8888,                   Accuracy: 44445/60000 (74.07%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5480,                   Accuracy: 49519/60000 (82.53%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.4000,                   Accuracy: 52506/60000 (87.51%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3106,                   Accuracy: 54321/60000 (90.54%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2464,                   Accuracy: 55719/60000 (92.86%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1885,                   Accuracy: 56740/60000 (94.57%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1514,                   Accuracy: 57326/60000 (95.54%)
{0: tensor(96.8967), 10: tensor(97.3333), 20: tensor(97.8867), 30: tensor(98.1400), 40: tensor(98.2967), 50: tensor(98.1933), 60: tensor(97.9233), 70: tensor(97.4300), 80: tensor(96.6633), 90: tensor(95.9417), 100: tensor(93.9517), 110: tensor(91.6167), 120: tensor(87.1550), 130: tensor(81.4917), 140: tensor(76.8600), 150: tensor(72.1067), 160: tensor(67.3467), 170: tensor(62.7233), 180: tensor(56.6900), 190: tensor(53.1733), 200: tensor(52.3767), 210: tensor(52.9000), 220: tensor(53.1817), 230: tensor(52.6883), 240: tensor(51.4650), 250: tensor(51.5900), 260: tensor(54.1167), 270: tensor(57.0667), 280: tensor(65.6750), 290: tensor(74.0750), 300: tensor(82.5317), 310: tensor(87.5100), 320: tensor(90.5350), 330: tensor(92.8650), 340: tensor(94.5667), 350: tensor(95.5433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=3, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.9471,                   Accuracy: 235/2000.0 (11.75%)



-= Testing valid =-
Test set: Average loss: 1.7416,                   Accuracy: 766/2000.0 (38.30%)



-= Testing valid =-
Test set: Average loss: 2.4825,                   Accuracy: 532/2000.0 (26.60%)



-= Testing valid =-
Test set: Average loss: 1.9232,                   Accuracy: 811/2000.0 (40.55%)



-= Testing valid =-
Test set: Average loss: 2.3732,                   Accuracy: 562/2000.0 (28.10%)



-= Testing valid =-
Test set: Average loss: 0.6626,                   Accuracy: 1526/2000.0 (76.30%)



-= Testing valid =-
Test set: Average loss: 1.0536,                   Accuracy: 1455/2000.0 (72.75%)



-= Testing valid =-
Test set: Average loss: 1.5663,                   Accuracy: 928/2000.0 (46.40%)



-= Testing valid =-
Test set: Average loss: 0.5794,                   Accuracy: 1619/2000.0 (80.95%)



-= Testing valid =-
Test set: Average loss: 0.5617,                   Accuracy: 1612/2000.0 (80.60%)



Epoch 10 train accuracy: 95.76%, valid accuracy 80.60%
-= Testing valid =-
Test set: Average loss: 1.0214,                   Accuracy: 1560/2000.0 (78.00%)



-= Testing valid =-
Test set: Average loss: 0.4188,                   Accuracy: 1711/2000.0 (85.55%)



-= Testing valid =-
Test set: Average loss: 0.4633,                   Accuracy: 1717/2000.0 (85.85%)



-= Testing valid =-
Test set: Average loss: 0.6581,                   Accuracy: 1660/2000.0 (83.00%)



-= Testing valid =-
Test set: Average loss: 0.4181,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.2496,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.1535,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.4489,                   Accuracy: 1687/2000.0 (84.35%)



-= Testing valid =-
Test set: Average loss: 0.3190,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.4548,                   Accuracy: 1695/2000.0 (84.75%)



Epoch 20 train accuracy: 97.80%, valid accuracy 84.75%
-= Testing valid =-
Test set: Average loss: 0.2159,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.1919,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2026,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.3397,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.2498,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.1627,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1654,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.2116,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.1681,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.2057,                   Accuracy: 1864/2000.0 (93.20%)



Epoch 30 train accuracy: 97.71%, valid accuracy 93.20%
-= Testing valid =-
Test set: Average loss: 0.2546,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.1596,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1701,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.2138,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2818,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2117,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.4985,                   Accuracy: 1716/2000.0 (85.80%)



-= Testing valid =-
Test set: Average loss: 0.1559,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1526,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.2472,                   Accuracy: 1845/2000.0 (92.25%)



Epoch 40 train accuracy: 98.44%, valid accuracy 92.25%
-= Testing valid =-
Test set: Average loss: 0.1420,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1842,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.2325,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.1544,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1643,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1217,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1919,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1418,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.3566,                   Accuracy: 1780/2000.0 (89.00%)



-= Testing valid =-
Test set: Average loss: 0.1913,                   Accuracy: 1879/2000.0 (93.95%)



Epoch 50 train accuracy: 98.57%, valid accuracy 93.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1408,                   Accuracy: 57485/60000 (95.81%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1094,                   Accuracy: 58061/60000 (96.77%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0782,                   Accuracy: 58635/60000 (97.72%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0704,                   Accuracy: 58807/60000 (98.01%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0677,                   Accuracy: 58848/60000 (98.08%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0717,                   Accuracy: 58759/60000 (97.93%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0823,                   Accuracy: 58591/60000 (97.65%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0969,                   Accuracy: 58310/60000 (97.18%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1275,                   Accuracy: 57791/60000 (96.32%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1466,                   Accuracy: 57459/60000 (95.76%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1845,                   Accuracy: 56661/60000 (94.43%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2263,                   Accuracy: 55694/60000 (92.82%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.2946,                   Accuracy: 54276/60000 (90.46%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4050,                   Accuracy: 52011/60000 (86.68%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.5665,                   Accuracy: 48824/60000 (81.37%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.7598,                   Accuracy: 45519/60000 (75.86%)
-= Testing Rotation 160 =-
Test set: Average loss: 1.0224,                   Accuracy: 42201/60000 (70.33%)
-= Testing Rotation 170 =-
Test set: Average loss: 1.3081,                   Accuracy: 39454/60000 (65.76%)
-= Testing Rotation 180 =-
Test set: Average loss: 1.6406,                   Accuracy: 36643/60000 (61.07%)
-= Testing Rotation 190 =-
Test set: Average loss: 1.9411,                   Accuracy: 35503/60000 (59.17%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.2390,                   Accuracy: 35000/60000 (58.33%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.4619,                   Accuracy: 34722/60000 (57.87%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.5812,                   Accuracy: 34766/60000 (57.94%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.6247,                   Accuracy: 34308/60000 (57.18%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.5541,                   Accuracy: 33319/60000 (55.53%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.3337,                   Accuracy: 33365/60000 (55.61%)
-= Testing Rotation 260 =-
Test set: Average loss: 1.9456,                   Accuracy: 34640/60000 (57.73%)
-= Testing Rotation 270 =-
Test set: Average loss: 1.6146,                   Accuracy: 36569/60000 (60.95%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.2823,                   Accuracy: 39571/60000 (65.95%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9434,                   Accuracy: 44006/60000 (73.34%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6803,                   Accuracy: 47900/60000 (79.83%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.4925,                   Accuracy: 50965/60000 (84.94%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3795,                   Accuracy: 53046/60000 (88.41%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3069,                   Accuracy: 54423/60000 (90.71%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2369,                   Accuracy: 55738/60000 (92.90%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2091,                   Accuracy: 56213/60000 (93.69%)
{0: tensor(95.8083), 10: tensor(96.7683), 20: tensor(97.7250), 30: tensor(98.0117), 40: tensor(98.0800), 50: tensor(97.9317), 60: tensor(97.6517), 70: tensor(97.1833), 80: tensor(96.3183), 90: tensor(95.7650), 100: tensor(94.4350), 110: tensor(92.8233), 120: tensor(90.4600), 130: tensor(86.6850), 140: tensor(81.3733), 150: tensor(75.8650), 160: tensor(70.3350), 170: tensor(65.7567), 180: tensor(61.0717), 190: tensor(59.1717), 200: tensor(58.3333), 210: tensor(57.8700), 220: tensor(57.9433), 230: tensor(57.1800), 240: tensor(55.5317), 250: tensor(55.6083), 260: tensor(57.7333), 270: tensor(60.9483), 280: tensor(65.9517), 290: tensor(73.3433), 300: tensor(79.8333), 310: tensor(84.9417), 320: tensor(88.4100), 330: tensor(90.7050), 340: tensor(92.8967), 350: tensor(93.6883)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=4, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.9223,                   Accuracy: 235/2000.0 (11.75%)



-= Testing valid =-
Test set: Average loss: 2.2205,                   Accuracy: 377/2000.0 (18.85%)



-= Testing valid =-
Test set: Average loss: 2.4510,                   Accuracy: 767/2000.0 (38.35%)



-= Testing valid =-
Test set: Average loss: 2.1097,                   Accuracy: 885/2000.0 (44.25%)



-= Testing valid =-
Test set: Average loss: 0.8624,                   Accuracy: 1427/2000.0 (71.35%)



-= Testing valid =-
Test set: Average loss: 0.5533,                   Accuracy: 1639/2000.0 (81.95%)



-= Testing valid =-
Test set: Average loss: 0.7657,                   Accuracy: 1506/2000.0 (75.30%)



-= Testing valid =-
Test set: Average loss: 0.5682,                   Accuracy: 1603/2000.0 (80.15%)



-= Testing valid =-
Test set: Average loss: 0.2901,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 1.0472,                   Accuracy: 1309/2000.0 (65.45%)



Epoch 10 train accuracy: 95.46%, valid accuracy 65.45%
-= Testing valid =-
Test set: Average loss: 0.2735,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2437,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2254,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.1608,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1409,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1739,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.2013,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1412,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1777,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1692,                   Accuracy: 1897/2000.0 (94.85%)



Epoch 20 train accuracy: 97.89%, valid accuracy 94.85%
-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1199,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1158,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1742,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1154,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1189,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1295,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1171,                   Accuracy: 1930/2000.0 (96.50%)



Epoch 30 train accuracy: 98.57%, valid accuracy 96.50%
-= Testing valid =-
Test set: Average loss: 0.1158,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1171,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1134,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1067,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1197,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1232,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1215,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 40 train accuracy: 98.60%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.1042,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1091,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1042,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1126,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0919,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 50 train accuracy: 98.46%, valid accuracy 96.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1034,                   Accuracy: 58115/60000 (96.86%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0883,                   Accuracy: 58387/60000 (97.31%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0724,                   Accuracy: 58665/60000 (97.78%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0701,                   Accuracy: 58742/60000 (97.90%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0637,                   Accuracy: 58861/60000 (98.10%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0635,                   Accuracy: 58798/60000 (98.00%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0715,                   Accuracy: 58715/60000 (97.86%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0809,                   Accuracy: 58565/60000 (97.61%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1054,                   Accuracy: 58147/60000 (96.91%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1295,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1650,                   Accuracy: 57182/60000 (95.30%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1981,                   Accuracy: 56545/60000 (94.24%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.2763,                   Accuracy: 55011/60000 (91.68%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3988,                   Accuracy: 52536/60000 (87.56%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.6095,                   Accuracy: 48637/60000 (81.06%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.9076,                   Accuracy: 44388/60000 (73.98%)
-= Testing Rotation 160 =-
Test set: Average loss: 1.3315,                   Accuracy: 40404/60000 (67.34%)
-= Testing Rotation 170 =-
Test set: Average loss: 1.8313,                   Accuracy: 37521/60000 (62.53%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.4183,                   Accuracy: 35213/60000 (58.69%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.8585,                   Accuracy: 33806/60000 (56.34%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.2069,                   Accuracy: 33050/60000 (55.08%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.4775,                   Accuracy: 32297/60000 (53.83%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.6163,                   Accuracy: 31944/60000 (53.24%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.7021,                   Accuracy: 31627/60000 (52.71%)
-= Testing Rotation 240 =-
Test set: Average loss: 3.6847,                   Accuracy: 31341/60000 (52.24%)
-= Testing Rotation 250 =-
Test set: Average loss: 3.4532,                   Accuracy: 31529/60000 (52.55%)
-= Testing Rotation 260 =-
Test set: Average loss: 3.1093,                   Accuracy: 31691/60000 (52.82%)
-= Testing Rotation 270 =-
Test set: Average loss: 2.7340,                   Accuracy: 32891/60000 (54.82%)
-= Testing Rotation 280 =-
Test set: Average loss: 2.1033,                   Accuracy: 35273/60000 (58.79%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.6030,                   Accuracy: 38588/60000 (64.31%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.1496,                   Accuracy: 42259/60000 (70.43%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.7026,                   Accuracy: 47286/60000 (78.81%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.4336,                   Accuracy: 51715/60000 (86.19%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3057,                   Accuracy: 54248/60000 (90.41%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1906,                   Accuracy: 56519/60000 (94.20%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1431,                   Accuracy: 57354/60000 (95.59%)
{0: tensor(96.8583), 10: tensor(97.3117), 20: tensor(97.7750), 30: tensor(97.9033), 40: tensor(98.1017), 50: tensor(97.9967), 60: tensor(97.8583), 70: tensor(97.6083), 80: tensor(96.9117), 90: tensor(96.3650), 100: tensor(95.3033), 110: tensor(94.2417), 120: tensor(91.6850), 130: tensor(87.5600), 140: tensor(81.0617), 150: tensor(73.9800), 160: tensor(67.3400), 170: tensor(62.5350), 180: tensor(58.6883), 190: tensor(56.3433), 200: tensor(55.0833), 210: tensor(53.8283), 220: tensor(53.2400), 230: tensor(52.7117), 240: tensor(52.2350), 250: tensor(52.5483), 260: tensor(52.8183), 270: tensor(54.8183), 280: tensor(58.7883), 290: tensor(64.3133), 300: tensor(70.4317), 310: tensor(78.8100), 320: tensor(86.1917), 330: tensor(90.4133), 340: tensor(94.1983), 350: tensor(95.5900)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=5, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.8483,                   Accuracy: 237/2000.0 (11.85%)



-= Testing valid =-
Test set: Average loss: 1.6578,                   Accuracy: 826/2000.0 (41.30%)



-= Testing valid =-
Test set: Average loss: 1.7601,                   Accuracy: 633/2000.0 (31.65%)



-= Testing valid =-
Test set: Average loss: 0.7406,                   Accuracy: 1576/2000.0 (78.80%)



-= Testing valid =-
Test set: Average loss: 1.6455,                   Accuracy: 968/2000.0 (48.40%)



-= Testing valid =-
Test set: Average loss: 2.0437,                   Accuracy: 1088/2000.0 (54.40%)



-= Testing valid =-
Test set: Average loss: 0.4021,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.2470,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.5333,                   Accuracy: 1667/2000.0 (83.35%)



-= Testing valid =-
Test set: Average loss: 0.1907,                   Accuracy: 1875/2000.0 (93.75%)



Epoch 10 train accuracy: 96.00%, valid accuracy 93.75%
-= Testing valid =-
Test set: Average loss: 0.2306,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.1918,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2680,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.1697,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.2163,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.1787,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.2188,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2485,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.1759,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1936,                   Accuracy: 1871/2000.0 (93.55%)



Epoch 20 train accuracy: 97.44%, valid accuracy 93.55%
-= Testing valid =-
Test set: Average loss: 0.1623,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1260,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1464,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1120,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1208,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1101,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1137,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1231,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1127,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 30 train accuracy: 98.24%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.1239,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1142,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1096,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1224,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1204,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1072,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1131,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1384,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1218,                   Accuracy: 1920/2000.0 (96.00%)



Epoch 40 train accuracy: 98.39%, valid accuracy 96.00%
-= Testing valid =-
Test set: Average loss: 0.1158,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1351,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1305,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1157,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1366,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1171,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1248,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1270,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1107,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1120,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 50 train accuracy: 98.74%, valid accuracy 96.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1164,                   Accuracy: 57914/60000 (96.52%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0944,                   Accuracy: 58342/60000 (97.24%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0724,                   Accuracy: 58670/60000 (97.78%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0649,                   Accuracy: 58837/60000 (98.06%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0604,                   Accuracy: 58917/60000 (98.19%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0644,                   Accuracy: 58848/60000 (98.08%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0735,                   Accuracy: 58684/60000 (97.81%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0882,                   Accuracy: 58416/60000 (97.36%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1160,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1329,                   Accuracy: 57684/60000 (96.14%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1627,                   Accuracy: 57157/60000 (95.26%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1836,                   Accuracy: 56821/60000 (94.70%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.2229,                   Accuracy: 56182/60000 (93.64%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.2751,                   Accuracy: 55116/60000 (91.86%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3718,                   Accuracy: 53176/60000 (88.63%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.5472,                   Accuracy: 50228/60000 (83.71%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.8285,                   Accuracy: 46271/60000 (77.12%)
-= Testing Rotation 170 =-
Test set: Average loss: 1.1622,                   Accuracy: 42900/60000 (71.50%)
-= Testing Rotation 180 =-
Test set: Average loss: 1.7227,                   Accuracy: 38041/60000 (63.40%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.2061,                   Accuracy: 35209/60000 (58.68%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.5556,                   Accuracy: 34266/60000 (57.11%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.8188,                   Accuracy: 33518/60000 (55.86%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.9472,                   Accuracy: 33147/60000 (55.24%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.9378,                   Accuracy: 32881/60000 (54.80%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.8396,                   Accuracy: 32370/60000 (53.95%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.6106,                   Accuracy: 32665/60000 (54.44%)
-= Testing Rotation 260 =-
Test set: Average loss: 2.2993,                   Accuracy: 33129/60000 (55.22%)
-= Testing Rotation 270 =-
Test set: Average loss: 2.0018,                   Accuracy: 33785/60000 (56.31%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.6028,                   Accuracy: 35850/60000 (59.75%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.1096,                   Accuracy: 40235/60000 (67.06%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.8028,                   Accuracy: 44292/60000 (73.82%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.5685,                   Accuracy: 48550/60000 (80.92%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.4031,                   Accuracy: 51994/60000 (86.66%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2903,                   Accuracy: 54450/60000 (90.75%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2080,                   Accuracy: 56230/60000 (93.72%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1633,                   Accuracy: 57109/60000 (95.18%)
{0: tensor(96.5233), 10: tensor(97.2367), 20: tensor(97.7833), 30: tensor(98.0617), 40: tensor(98.1950), 50: tensor(98.0800), 60: tensor(97.8067), 70: tensor(97.3600), 80: tensor(96.5833), 90: tensor(96.1400), 100: tensor(95.2617), 110: tensor(94.7017), 120: tensor(93.6367), 130: tensor(91.8600), 140: tensor(88.6267), 150: tensor(83.7133), 160: tensor(77.1183), 170: tensor(71.5000), 180: tensor(63.4017), 190: tensor(58.6817), 200: tensor(57.1100), 210: tensor(55.8633), 220: tensor(55.2450), 230: tensor(54.8017), 240: tensor(53.9500), 250: tensor(54.4417), 260: tensor(55.2150), 270: tensor(56.3083), 280: tensor(59.7500), 290: tensor(67.0583), 300: tensor(73.8200), 310: tensor(80.9167), 320: tensor(86.6567), 330: tensor(90.7500), 340: tensor(93.7167), 350: tensor(95.1817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=6, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.8233,                   Accuracy: 262/2000.0 (13.10%)



-= Testing valid =-
Test set: Average loss: 2.2849,                   Accuracy: 523/2000.0 (26.15%)



-= Testing valid =-
Test set: Average loss: 2.1210,                   Accuracy: 857/2000.0 (42.85%)



-= Testing valid =-
Test set: Average loss: 1.0019,                   Accuracy: 1309/2000.0 (65.45%)



-= Testing valid =-
Test set: Average loss: 0.7113,                   Accuracy: 1527/2000.0 (76.35%)



-= Testing valid =-
Test set: Average loss: 0.7913,                   Accuracy: 1478/2000.0 (73.90%)



-= Testing valid =-
Test set: Average loss: 0.4115,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.3881,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.4371,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.4801,                   Accuracy: 1699/2000.0 (84.95%)



Epoch 10 train accuracy: 95.66%, valid accuracy 84.95%
-= Testing valid =-
Test set: Average loss: 0.1739,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1658,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1868,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1551,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1823,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.2399,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.1310,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1356,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1825,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1202,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 20 train accuracy: 97.46%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.1489,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1374,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1399,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1598,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1703,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1362,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1391,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1401,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1476,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1422,                   Accuracy: 1921/2000.0 (96.05%)



Epoch 30 train accuracy: 98.57%, valid accuracy 96.05%
-= Testing valid =-
Test set: Average loss: 0.1133,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1351,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1197,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1237,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1580,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1091,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1225,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1306,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 40 train accuracy: 98.18%, valid accuracy 96.45%
-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1149,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1201,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1249,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1188,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1176,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1153,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1128,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1186,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 50 train accuracy: 98.51%, valid accuracy 96.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1163,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0887,                   Accuracy: 58395/60000 (97.32%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0700,                   Accuracy: 58741/60000 (97.90%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0654,                   Accuracy: 58788/60000 (97.98%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0621,                   Accuracy: 58878/60000 (98.13%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0653,                   Accuracy: 58805/60000 (98.01%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0755,                   Accuracy: 58649/60000 (97.75%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0896,                   Accuracy: 58399/60000 (97.33%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1197,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1625,                   Accuracy: 57198/60000 (95.33%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2109,                   Accuracy: 56354/60000 (93.92%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2958,                   Accuracy: 54588/60000 (90.98%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4483,                   Accuracy: 51149/60000 (85.25%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.6529,                   Accuracy: 46659/60000 (77.76%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.8933,                   Accuracy: 42753/60000 (71.25%)
-= Testing Rotation 150 =-
Test set: Average loss: 1.1616,                   Accuracy: 39338/60000 (65.56%)
-= Testing Rotation 160 =-
Test set: Average loss: 1.5262,                   Accuracy: 36254/60000 (60.42%)
-= Testing Rotation 170 =-
Test set: Average loss: 1.7919,                   Accuracy: 34067/60000 (56.78%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.2460,                   Accuracy: 31171/60000 (51.95%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.5301,                   Accuracy: 30831/60000 (51.38%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.8564,                   Accuracy: 30466/60000 (50.78%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.0877,                   Accuracy: 30126/60000 (50.21%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.2526,                   Accuracy: 30101/60000 (50.17%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.3554,                   Accuracy: 30007/60000 (50.01%)
-= Testing Rotation 240 =-
Test set: Average loss: 3.3856,                   Accuracy: 29561/60000 (49.27%)
-= Testing Rotation 250 =-
Test set: Average loss: 3.3087,                   Accuracy: 29861/60000 (49.77%)
-= Testing Rotation 260 =-
Test set: Average loss: 2.8041,                   Accuracy: 30603/60000 (51.01%)
-= Testing Rotation 270 =-
Test set: Average loss: 2.3490,                   Accuracy: 31338/60000 (52.23%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.7638,                   Accuracy: 35510/60000 (59.18%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.1964,                   Accuracy: 40505/60000 (67.51%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.7557,                   Accuracy: 45884/60000 (76.47%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.4878,                   Accuracy: 50384/60000 (83.97%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3492,                   Accuracy: 53012/60000 (88.35%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2678,                   Accuracy: 54910/60000 (91.52%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1983,                   Accuracy: 56380/60000 (93.97%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1530,                   Accuracy: 57271/60000 (95.45%)
{0: tensor(96.4900), 10: tensor(97.3250), 20: tensor(97.9017), 30: tensor(97.9800), 40: tensor(98.1300), 50: tensor(98.0083), 60: tensor(97.7483), 70: tensor(97.3317), 80: tensor(96.4467), 90: tensor(95.3300), 100: tensor(93.9233), 110: tensor(90.9800), 120: tensor(85.2483), 130: tensor(77.7650), 140: tensor(71.2550), 150: tensor(65.5633), 160: tensor(60.4233), 170: tensor(56.7783), 180: tensor(51.9517), 190: tensor(51.3850), 200: tensor(50.7767), 210: tensor(50.2100), 220: tensor(50.1683), 230: tensor(50.0117), 240: tensor(49.2683), 250: tensor(49.7683), 260: tensor(51.0050), 270: tensor(52.2300), 280: tensor(59.1833), 290: tensor(67.5083), 300: tensor(76.4733), 310: tensor(83.9733), 320: tensor(88.3533), 330: tensor(91.5167), 340: tensor(93.9667), 350: tensor(95.4517)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=7, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 11.8944,                   Accuracy: 190/2000.0 (9.50%)



-= Testing valid =-
Test set: Average loss: 1.2197,                   Accuracy: 1144/2000.0 (57.20%)



-= Testing valid =-
Test set: Average loss: 0.9443,                   Accuracy: 1358/2000.0 (67.90%)



-= Testing valid =-
Test set: Average loss: 1.6614,                   Accuracy: 799/2000.0 (39.95%)



-= Testing valid =-
Test set: Average loss: 0.4730,                   Accuracy: 1691/2000.0 (84.55%)



-= Testing valid =-
Test set: Average loss: 0.3656,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.5270,                   Accuracy: 1651/2000.0 (82.55%)



-= Testing valid =-
Test set: Average loss: 0.8449,                   Accuracy: 1343/2000.0 (67.15%)



-= Testing valid =-
Test set: Average loss: 1.5081,                   Accuracy: 1283/2000.0 (64.15%)



-= Testing valid =-
Test set: Average loss: 1.0897,                   Accuracy: 1357/2000.0 (67.85%)



Epoch 10 train accuracy: 95.86%, valid accuracy 67.85%
-= Testing valid =-
Test set: Average loss: 0.1897,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.3191,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.2366,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2992,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.1501,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.2219,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.1768,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.2091,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.3250,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.1769,                   Accuracy: 1877/2000.0 (93.85%)



Epoch 20 train accuracy: 97.74%, valid accuracy 93.85%
-= Testing valid =-
Test set: Average loss: 0.2033,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.1768,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1177,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1266,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1502,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1602,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1094,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1528,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1457,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 30 train accuracy: 97.81%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.1133,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1142,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1209,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1132,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1180,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 40 train accuracy: 98.35%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.1037,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1193,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1188,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 50 train accuracy: 98.50%, valid accuracy 97.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1105,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0960,                   Accuracy: 58315/60000 (97.19%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0788,                   Accuracy: 58583/60000 (97.64%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0682,                   Accuracy: 58757/60000 (97.93%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0659,                   Accuracy: 58781/60000 (97.97%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0692,                   Accuracy: 58743/60000 (97.90%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0756,                   Accuracy: 58609/60000 (97.68%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0968,                   Accuracy: 58213/60000 (97.02%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1289,                   Accuracy: 57696/60000 (96.16%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1341,                   Accuracy: 57664/60000 (96.11%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2058,                   Accuracy: 56346/60000 (93.91%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2596,                   Accuracy: 55379/60000 (92.30%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3448,                   Accuracy: 53617/60000 (89.36%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4829,                   Accuracy: 50355/60000 (83.93%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.6495,                   Accuracy: 46629/60000 (77.71%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.8359,                   Accuracy: 43339/60000 (72.23%)
-= Testing Rotation 160 =-
Test set: Average loss: 1.1083,                   Accuracy: 39855/60000 (66.43%)
-= Testing Rotation 170 =-
Test set: Average loss: 1.3020,                   Accuracy: 38313/60000 (63.85%)
-= Testing Rotation 180 =-
Test set: Average loss: 1.6492,                   Accuracy: 36309/60000 (60.51%)
-= Testing Rotation 190 =-
Test set: Average loss: 1.9868,                   Accuracy: 35140/60000 (58.57%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.2931,                   Accuracy: 34866/60000 (58.11%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.4624,                   Accuracy: 34988/60000 (58.31%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.6199,                   Accuracy: 34842/60000 (58.07%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.6689,                   Accuracy: 34547/60000 (57.58%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.6424,                   Accuracy: 33862/60000 (56.44%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.5171,                   Accuracy: 33539/60000 (55.90%)
-= Testing Rotation 260 =-
Test set: Average loss: 2.1446,                   Accuracy: 34004/60000 (56.67%)
-= Testing Rotation 270 =-
Test set: Average loss: 1.8277,                   Accuracy: 35614/60000 (59.36%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.3757,                   Accuracy: 38216/60000 (63.69%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9797,                   Accuracy: 42322/60000 (70.54%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.6691,                   Accuracy: 46570/60000 (77.62%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.5018,                   Accuracy: 49676/60000 (82.79%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3851,                   Accuracy: 52389/60000 (87.32%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2875,                   Accuracy: 54684/60000 (91.14%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2101,                   Accuracy: 56285/60000 (93.81%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1647,                   Accuracy: 57146/60000 (95.24%)
{0: tensor(96.7083), 10: tensor(97.1917), 20: tensor(97.6383), 30: tensor(97.9283), 40: tensor(97.9683), 50: tensor(97.9050), 60: tensor(97.6817), 70: tensor(97.0217), 80: tensor(96.1600), 90: tensor(96.1067), 100: tensor(93.9100), 110: tensor(92.2983), 120: tensor(89.3617), 130: tensor(83.9250), 140: tensor(77.7150), 150: tensor(72.2317), 160: tensor(66.4250), 170: tensor(63.8550), 180: tensor(60.5150), 190: tensor(58.5667), 200: tensor(58.1100), 210: tensor(58.3133), 220: tensor(58.0700), 230: tensor(57.5783), 240: tensor(56.4367), 250: tensor(55.8983), 260: tensor(56.6733), 270: tensor(59.3567), 280: tensor(63.6933), 290: tensor(70.5367), 300: tensor(77.6167), 310: tensor(82.7933), 320: tensor(87.3150), 330: tensor(91.1400), 340: tensor(93.8083), 350: tensor(95.2433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=8, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1356,                   Accuracy: 378/2000.0 (18.90%)



-= Testing valid =-
Test set: Average loss: 3.8806,                   Accuracy: 186/2000.0 (9.30%)



-= Testing valid =-
Test set: Average loss: 4.5638,                   Accuracy: 466/2000.0 (23.30%)



-= Testing valid =-
Test set: Average loss: 1.8254,                   Accuracy: 1049/2000.0 (52.45%)



-= Testing valid =-
Test set: Average loss: 0.4832,                   Accuracy: 1678/2000.0 (83.90%)



-= Testing valid =-
Test set: Average loss: 0.2089,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.4077,                   Accuracy: 1752/2000.0 (87.60%)



-= Testing valid =-
Test set: Average loss: 0.3458,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.2152,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.4347,                   Accuracy: 1742/2000.0 (87.10%)



Epoch 10 train accuracy: 96.12%, valid accuracy 87.10%
-= Testing valid =-
Test set: Average loss: 0.1784,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1673,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1115,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1227,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1410,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.2440,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.1262,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1290,                   Accuracy: 1917/2000.0 (95.85%)



Epoch 20 train accuracy: 97.39%, valid accuracy 95.85%
-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1017,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1231,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1301,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1325,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1064,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1050,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 30 train accuracy: 98.54%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1142,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0877,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 40 train accuracy: 98.16%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 50 train accuracy: 98.72%, valid accuracy 97.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1043,                   Accuracy: 58173/60000 (96.96%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0895,                   Accuracy: 58372/60000 (97.29%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0734,                   Accuracy: 58691/60000 (97.82%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0652,                   Accuracy: 58850/60000 (98.08%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0611,                   Accuracy: 58960/60000 (98.27%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0639,                   Accuracy: 58900/60000 (98.17%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0711,                   Accuracy: 58771/60000 (97.95%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0898,                   Accuracy: 58447/60000 (97.41%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1232,                   Accuracy: 57836/60000 (96.39%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1650,                   Accuracy: 57112/60000 (95.19%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2545,                   Accuracy: 55401/60000 (92.33%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3751,                   Accuracy: 53233/60000 (88.72%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5595,                   Accuracy: 50177/60000 (83.63%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.7906,                   Accuracy: 46334/60000 (77.22%)
-= Testing Rotation 140 =-
Test set: Average loss: 1.0298,                   Accuracy: 42831/60000 (71.39%)
-= Testing Rotation 150 =-
Test set: Average loss: 1.3150,                   Accuracy: 39589/60000 (65.98%)
-= Testing Rotation 160 =-
Test set: Average loss: 1.6179,                   Accuracy: 36795/60000 (61.33%)
-= Testing Rotation 170 =-
Test set: Average loss: 1.9399,                   Accuracy: 34156/60000 (56.93%)
-= Testing Rotation 180 =-
Test set: Average loss: 2.4503,                   Accuracy: 31462/60000 (52.44%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.8799,                   Accuracy: 29767/60000 (49.61%)
-= Testing Rotation 200 =-
Test set: Average loss: 3.1757,                   Accuracy: 29333/60000 (48.89%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.3428,                   Accuracy: 29296/60000 (48.83%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.3382,                   Accuracy: 29556/60000 (49.26%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.2090,                   Accuracy: 29764/60000 (49.61%)
-= Testing Rotation 240 =-
Test set: Average loss: 3.0125,                   Accuracy: 30126/60000 (50.21%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.6987,                   Accuracy: 30524/60000 (50.87%)
-= Testing Rotation 260 =-
Test set: Average loss: 2.3528,                   Accuracy: 31148/60000 (51.91%)
-= Testing Rotation 270 =-
Test set: Average loss: 1.9645,                   Accuracy: 33535/60000 (55.89%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.6183,                   Accuracy: 37024/60000 (61.71%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.1277,                   Accuracy: 41692/60000 (69.49%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.7407,                   Accuracy: 46232/60000 (77.05%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.4871,                   Accuracy: 50343/60000 (83.90%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3510,                   Accuracy: 53154/60000 (88.59%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2599,                   Accuracy: 55075/60000 (91.79%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1870,                   Accuracy: 56587/60000 (94.31%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1408,                   Accuracy: 57495/60000 (95.82%)
{0: tensor(96.9550), 10: tensor(97.2867), 20: tensor(97.8183), 30: tensor(98.0833), 40: tensor(98.2667), 50: tensor(98.1667), 60: tensor(97.9517), 70: tensor(97.4117), 80: tensor(96.3933), 90: tensor(95.1867), 100: tensor(92.3350), 110: tensor(88.7217), 120: tensor(83.6283), 130: tensor(77.2233), 140: tensor(71.3850), 150: tensor(65.9817), 160: tensor(61.3250), 170: tensor(56.9267), 180: tensor(52.4367), 190: tensor(49.6117), 200: tensor(48.8883), 210: tensor(48.8267), 220: tensor(49.2600), 230: tensor(49.6067), 240: tensor(50.2100), 250: tensor(50.8733), 260: tensor(51.9133), 270: tensor(55.8917), 280: tensor(61.7067), 290: tensor(69.4867), 300: tensor(77.0533), 310: tensor(83.9050), 320: tensor(88.5900), 330: tensor(91.7917), 340: tensor(94.3117), 350: tensor(95.8250)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=9, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.4788,                   Accuracy: 221/2000.0 (11.05%)



-= Testing valid =-
Test set: Average loss: 1.5009,                   Accuracy: 912/2000.0 (45.60%)



-= Testing valid =-
Test set: Average loss: 1.1107,                   Accuracy: 1277/2000.0 (63.85%)



-= Testing valid =-
Test set: Average loss: 1.4529,                   Accuracy: 1039/2000.0 (51.95%)



-= Testing valid =-
Test set: Average loss: 0.7700,                   Accuracy: 1529/2000.0 (76.45%)



-= Testing valid =-
Test set: Average loss: 0.5951,                   Accuracy: 1626/2000.0 (81.30%)



-= Testing valid =-
Test set: Average loss: 0.2140,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.2968,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2012,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.2457,                   Accuracy: 1862/2000.0 (93.10%)



Epoch 10 train accuracy: 96.55%, valid accuracy 93.10%
-= Testing valid =-
Test set: Average loss: 0.1906,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.2220,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.1319,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.2144,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1720,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1283,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1629,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1416,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1257,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1435,                   Accuracy: 1908/2000.0 (95.40%)



Epoch 20 train accuracy: 98.21%, valid accuracy 95.40%
-= Testing valid =-
Test set: Average loss: 0.1331,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1099,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1126,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1160,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1471,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1242,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1208,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1222,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1322,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1368,                   Accuracy: 1919/2000.0 (95.95%)



Epoch 30 train accuracy: 98.24%, valid accuracy 95.95%
-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1097,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1209,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 40 train accuracy: 98.47%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.1091,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1048,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1010,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 50 train accuracy: 98.90%, valid accuracy 96.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1004,                   Accuracy: 58213/60000 (97.02%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0872,                   Accuracy: 58431/60000 (97.39%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0673,                   Accuracy: 58741/60000 (97.90%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0581,                   Accuracy: 58932/60000 (98.22%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0556,                   Accuracy: 58990/60000 (98.32%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0590,                   Accuracy: 58932/60000 (98.22%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0691,                   Accuracy: 58752/60000 (97.92%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0864,                   Accuracy: 58462/60000 (97.44%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1100,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1279,                   Accuracy: 57813/60000 (96.36%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1761,                   Accuracy: 56975/60000 (94.96%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2364,                   Accuracy: 55706/60000 (92.84%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3576,                   Accuracy: 53255/60000 (88.76%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.5375,                   Accuracy: 49726/60000 (82.88%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.7838,                   Accuracy: 45274/60000 (75.46%)
-= Testing Rotation 150 =-
Test set: Average loss: 1.0288,                   Accuracy: 41491/60000 (69.15%)
-= Testing Rotation 160 =-
Test set: Average loss: 1.2607,                   Accuracy: 38938/60000 (64.90%)
-= Testing Rotation 170 =-
Test set: Average loss: 1.5189,                   Accuracy: 36811/60000 (61.35%)
-= Testing Rotation 180 =-
Test set: Average loss: 1.7493,                   Accuracy: 35646/60000 (59.41%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.1807,                   Accuracy: 33247/60000 (55.41%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.4284,                   Accuracy: 32370/60000 (53.95%)
-= Testing Rotation 210 =-
Test set: Average loss: 2.6647,                   Accuracy: 31756/60000 (52.93%)
-= Testing Rotation 220 =-
Test set: Average loss: 2.7911,                   Accuracy: 31416/60000 (52.36%)
-= Testing Rotation 230 =-
Test set: Average loss: 2.8399,                   Accuracy: 31344/60000 (52.24%)
-= Testing Rotation 240 =-
Test set: Average loss: 2.8322,                   Accuracy: 31254/60000 (52.09%)
-= Testing Rotation 250 =-
Test set: Average loss: 2.6497,                   Accuracy: 31746/60000 (52.91%)
-= Testing Rotation 260 =-
Test set: Average loss: 2.2771,                   Accuracy: 33311/60000 (55.52%)
-= Testing Rotation 270 =-
Test set: Average loss: 1.7936,                   Accuracy: 36081/60000 (60.13%)
-= Testing Rotation 280 =-
Test set: Average loss: 1.3744,                   Accuracy: 39278/60000 (65.46%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.9267,                   Accuracy: 44220/60000 (73.70%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5645,                   Accuracy: 49700/60000 (82.83%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3606,                   Accuracy: 53417/60000 (89.03%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2614,                   Accuracy: 55202/60000 (92.00%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2065,                   Accuracy: 56109/60000 (93.51%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1726,                   Accuracy: 56801/60000 (94.67%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1441,                   Accuracy: 57417/60000 (95.69%)
{0: tensor(97.0217), 10: tensor(97.3850), 20: tensor(97.9017), 30: tensor(98.2200), 40: tensor(98.3167), 50: tensor(98.2200), 60: tensor(97.9200), 70: tensor(97.4367), 80: tensor(96.7700), 90: tensor(96.3550), 100: tensor(94.9583), 110: tensor(92.8433), 120: tensor(88.7583), 130: tensor(82.8767), 140: tensor(75.4567), 150: tensor(69.1517), 160: tensor(64.8967), 170: tensor(61.3517), 180: tensor(59.4100), 190: tensor(55.4117), 200: tensor(53.9500), 210: tensor(52.9267), 220: tensor(52.3600), 230: tensor(52.2400), 240: tensor(52.0900), 250: tensor(52.9100), 260: tensor(55.5183), 270: tensor(60.1350), 280: tensor(65.4633), 290: tensor(73.7000), 300: tensor(82.8333), 310: tensor(89.0283), 320: tensor(92.0033), 330: tensor(93.5150), 340: tensor(94.6683), 350: tensor(95.6950)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=10, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.1607,                   Accuracy: 264/2000.0 (13.20%)



-= Testing valid =-
Test set: Average loss: 1.6973,                   Accuracy: 766/2000.0 (38.30%)



-= Testing valid =-
Test set: Average loss: 1.9687,                   Accuracy: 662/2000.0 (33.10%)



-= Testing valid =-
Test set: Average loss: 0.6288,                   Accuracy: 1617/2000.0 (80.85%)



-= Testing valid =-
Test set: Average loss: 0.7285,                   Accuracy: 1464/2000.0 (73.20%)



-= Testing valid =-
Test set: Average loss: 0.6388,                   Accuracy: 1572/2000.0 (78.60%)



-= Testing valid =-
Test set: Average loss: 0.4237,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.3496,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.5527,                   Accuracy: 1641/2000.0 (82.05%)



-= Testing valid =-
Test set: Average loss: 0.2387,                   Accuracy: 1864/2000.0 (93.20%)



Epoch 10 train accuracy: 95.76%, valid accuracy 93.20%
-= Testing valid =-
Test set: Average loss: 0.2805,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2935,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2030,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1343,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.2758,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.1277,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.2084,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.1525,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1066,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 20 train accuracy: 97.50%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.1246,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1701,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1457,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1214,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1324,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1324,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1102,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1273,                   Accuracy: 1920/2000.0 (96.00%)



Epoch 30 train accuracy: 97.80%, valid accuracy 96.00%
-= Testing valid =-
Test set: Average loss: 0.1492,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1233,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1147,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1080,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1107,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1386,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1401,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 40 train accuracy: 98.20%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.1207,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1086,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1108,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0978,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1170,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1020,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 50 train accuracy: 98.66%, valid accuracy 96.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1124,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0904,                   Accuracy: 58399/60000 (97.33%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0743,                   Accuracy: 58654/60000 (97.76%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0672,                   Accuracy: 58779/60000 (97.96%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0647,                   Accuracy: 58818/60000 (98.03%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0708,                   Accuracy: 58715/60000 (97.86%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0810,                   Accuracy: 58552/60000 (97.59%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1002,                   Accuracy: 58226/60000 (97.04%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1308,                   Accuracy: 57663/60000 (96.11%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1617,                   Accuracy: 57160/60000 (95.27%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2229,                   Accuracy: 55940/60000 (93.23%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2853,                   Accuracy: 54721/60000 (91.20%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3786,                   Accuracy: 52854/60000 (88.09%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.5127,                   Accuracy: 50418/60000 (84.03%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.6956,                   Accuracy: 47574/60000 (79.29%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.9366,                   Accuracy: 44102/60000 (73.50%)
-= Testing Rotation 160 =-
Test set: Average loss: 1.2049,                   Accuracy: 41016/60000 (68.36%)
-= Testing Rotation 170 =-
Test set: Average loss: 1.4779,                   Accuracy: 38304/60000 (63.84%)
-= Testing Rotation 180 =-
Test set: Average loss: 1.9974,                   Accuracy: 34056/60000 (56.76%)
-= Testing Rotation 190 =-
Test set: Average loss: 2.3167,                   Accuracy: 33577/60000 (55.96%)
-= Testing Rotation 200 =-
Test set: Average loss: 2.6687,                   Accuracy: 33223/60000 (55.37%)
-= Testing Rotation 210 =-
Test set: Average loss: 3.0612,                   Accuracy: 32360/60000 (53.93%)
-= Testing Rotation 220 =-
Test set: Average loss: 3.3106,                   Accuracy: 32306/60000 (53.84%)
-= Testing Rotation 230 =-
Test set: Average loss: 3.4535,                   Accuracy: 31725/60000 (52.88%)
-= Testing Rotation 240 =-
Test set: Average loss: 3.4826,                   Accuracy: 31414/60000 (52.36%)
-= Testing Rotation 250 =-
Test set: Average loss: 3.2349,                   Accuracy: 31793/60000 (52.99%)
-= Testing Rotation 260 =-
Test set: Average loss: 2.8768,                   Accuracy: 31855/60000 (53.09%)
-= Testing Rotation 270 =-
Test set: Average loss: 2.7506,                   Accuracy: 30739/60000 (51.23%)
-= Testing Rotation 280 =-
Test set: Average loss: 2.0707,                   Accuracy: 32962/60000 (54.94%)
-= Testing Rotation 290 =-
Test set: Average loss: 1.5903,                   Accuracy: 35831/60000 (59.72%)
-= Testing Rotation 300 =-
Test set: Average loss: 1.2537,                   Accuracy: 38763/60000 (64.61%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.8450,                   Accuracy: 44384/60000 (73.97%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.5808,                   Accuracy: 48807/60000 (81.35%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3666,                   Accuracy: 53075/60000 (88.46%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2216,                   Accuracy: 56038/60000 (93.40%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1572,                   Accuracy: 57233/60000 (95.39%)
{0: tensor(96.7117), 10: tensor(97.3317), 20: tensor(97.7567), 30: tensor(97.9650), 40: tensor(98.0300), 50: tensor(97.8583), 60: tensor(97.5867), 70: tensor(97.0433), 80: tensor(96.1050), 90: tensor(95.2667), 100: tensor(93.2333), 110: tensor(91.2017), 120: tensor(88.0900), 130: tensor(84.0300), 140: tensor(79.2900), 150: tensor(73.5033), 160: tensor(68.3600), 170: tensor(63.8400), 180: tensor(56.7600), 190: tensor(55.9617), 200: tensor(55.3717), 210: tensor(53.9333), 220: tensor(53.8433), 230: tensor(52.8750), 240: tensor(52.3567), 250: tensor(52.9883), 260: tensor(53.0917), 270: tensor(51.2317), 280: tensor(54.9367), 290: tensor(59.7183), 300: tensor(64.6050), 310: tensor(73.9733), 320: tensor(81.3450), 330: tensor(88.4583), 340: tensor(93.3967), 350: tensor(95.3883)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=1, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6361,                   Accuracy: 386/2000.0 (19.30%)



-= Testing valid =-
Test set: Average loss: 1.9167,                   Accuracy: 770/2000.0 (38.50%)



-= Testing valid =-
Test set: Average loss: 1.3140,                   Accuracy: 1132/2000.0 (56.60%)



-= Testing valid =-
Test set: Average loss: 0.9535,                   Accuracy: 1346/2000.0 (67.30%)



-= Testing valid =-
Test set: Average loss: 1.2063,                   Accuracy: 1227/2000.0 (61.35%)



-= Testing valid =-
Test set: Average loss: 0.4342,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.5891,                   Accuracy: 1635/2000.0 (81.75%)



-= Testing valid =-
Test set: Average loss: 0.7584,                   Accuracy: 1473/2000.0 (73.65%)



-= Testing valid =-
Test set: Average loss: 1.0043,                   Accuracy: 1385/2000.0 (69.25%)



-= Testing valid =-
Test set: Average loss: 0.5747,                   Accuracy: 1632/2000.0 (81.60%)



Epoch 10 train accuracy: 95.21%, valid accuracy 81.60%
-= Testing valid =-
Test set: Average loss: 0.3613,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.4467,                   Accuracy: 1705/2000.0 (85.25%)



-= Testing valid =-
Test set: Average loss: 0.4657,                   Accuracy: 1709/2000.0 (85.45%)



-= Testing valid =-
Test set: Average loss: 0.4694,                   Accuracy: 1704/2000.0 (85.20%)



-= Testing valid =-
Test set: Average loss: 0.5670,                   Accuracy: 1627/2000.0 (81.35%)



-= Testing valid =-
Test set: Average loss: 0.2660,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.3427,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.2038,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.3870,                   Accuracy: 1755/2000.0 (87.75%)



-= Testing valid =-
Test set: Average loss: 0.3394,                   Accuracy: 1784/2000.0 (89.20%)



Epoch 20 train accuracy: 97.40%, valid accuracy 89.20%
-= Testing valid =-
Test set: Average loss: 0.2373,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.1927,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.2661,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2254,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.3436,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.1902,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.2615,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.1808,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.2000,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1708,                   Accuracy: 1896/2000.0 (94.80%)



Epoch 30 train accuracy: 96.91%, valid accuracy 94.80%
-= Testing valid =-
Test set: Average loss: 0.1732,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.2132,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.1821,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1860,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.2112,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.2301,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.2532,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.1999,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1782,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.2236,                   Accuracy: 1869/2000.0 (93.45%)



Epoch 40 train accuracy: 97.62%, valid accuracy 93.45%
-= Testing valid =-
Test set: Average loss: 0.2127,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.2046,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2095,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.1866,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.2009,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1717,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1761,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1832,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1942,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1827,                   Accuracy: 1892/2000.0 (94.60%)



Epoch 50 train accuracy: 98.30%, valid accuracy 94.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1918,                   Accuracy: 56745/60000 (94.57%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1230,                   Accuracy: 57838/60000 (96.40%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0888,                   Accuracy: 58435/60000 (97.39%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0748,                   Accuracy: 58686/60000 (97.81%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0736,                   Accuracy: 58719/60000 (97.86%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0790,                   Accuracy: 58634/60000 (97.72%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0972,                   Accuracy: 58322/60000 (97.20%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1323,                   Accuracy: 57686/60000 (96.14%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1912,                   Accuracy: 56641/60000 (94.40%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3256,                   Accuracy: 54344/60000 (90.57%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.5904,                   Accuracy: 50007/60000 (83.35%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.0719,                   Accuracy: 43071/60000 (71.79%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.6680,                   Accuracy: 35791/60000 (59.65%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.4023,                   Accuracy: 28425/60000 (47.38%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.1299,                   Accuracy: 23622/60000 (39.37%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.6454,                   Accuracy: 22252/60000 (37.09%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.0485,                   Accuracy: 22844/60000 (38.07%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.3141,                   Accuracy: 24246/60000 (40.41%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.9144,                   Accuracy: 25703/60000 (42.84%)
-= Testing Rotation 190 =-
Test set: Average loss: 5.0356,                   Accuracy: 26698/60000 (44.50%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.3711,                   Accuracy: 26808/60000 (44.68%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.4759,                   Accuracy: 26949/60000 (44.92%)
-= Testing Rotation 220 =-
Test set: Average loss: 5.5183,                   Accuracy: 26708/60000 (44.51%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.5768,                   Accuracy: 26073/60000 (43.46%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.5648,                   Accuracy: 25577/60000 (42.63%)
-= Testing Rotation 250 =-
Test set: Average loss: 5.5896,                   Accuracy: 24881/60000 (41.47%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.4439,                   Accuracy: 24435/60000 (40.72%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.5836,                   Accuracy: 23158/60000 (38.60%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.2535,                   Accuracy: 22558/60000 (37.60%)
-= Testing Rotation 290 =-
Test set: Average loss: 4.9473,                   Accuracy: 21362/60000 (35.60%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.2776,                   Accuracy: 21895/60000 (36.49%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.4185,                   Accuracy: 24736/60000 (41.23%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.4671,                   Accuracy: 29772/60000 (49.62%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.5680,                   Accuracy: 37109/60000 (61.85%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.8034,                   Accuracy: 46326/60000 (77.21%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3634,                   Accuracy: 53689/60000 (89.48%)
{0: tensor(94.5750), 10: tensor(96.3967), 20: tensor(97.3917), 30: tensor(97.8100), 40: tensor(97.8650), 50: tensor(97.7233), 60: tensor(97.2033), 70: tensor(96.1433), 80: tensor(94.4017), 90: tensor(90.5733), 100: tensor(83.3450), 110: tensor(71.7850), 120: tensor(59.6517), 130: tensor(47.3750), 140: tensor(39.3700), 150: tensor(37.0867), 160: tensor(38.0733), 170: tensor(40.4100), 180: tensor(42.8383), 190: tensor(44.4967), 200: tensor(44.6800), 210: tensor(44.9150), 220: tensor(44.5133), 230: tensor(43.4550), 240: tensor(42.6283), 250: tensor(41.4683), 260: tensor(40.7250), 270: tensor(38.5967), 280: tensor(37.5967), 290: tensor(35.6033), 300: tensor(36.4917), 310: tensor(41.2267), 320: tensor(49.6200), 330: tensor(61.8483), 340: tensor(77.2100), 350: tensor(89.4817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=2, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1107,                   Accuracy: 443/2000.0 (22.15%)



-= Testing valid =-
Test set: Average loss: 1.3504,                   Accuracy: 1049/2000.0 (52.45%)



-= Testing valid =-
Test set: Average loss: 2.0901,                   Accuracy: 692/2000.0 (34.60%)



-= Testing valid =-
Test set: Average loss: 1.2941,                   Accuracy: 1128/2000.0 (56.40%)



-= Testing valid =-
Test set: Average loss: 1.5531,                   Accuracy: 1162/2000.0 (58.10%)



-= Testing valid =-
Test set: Average loss: 1.5543,                   Accuracy: 1155/2000.0 (57.75%)



-= Testing valid =-
Test set: Average loss: 1.1962,                   Accuracy: 1288/2000.0 (64.40%)



-= Testing valid =-
Test set: Average loss: 0.6606,                   Accuracy: 1573/2000.0 (78.65%)



-= Testing valid =-
Test set: Average loss: 0.5952,                   Accuracy: 1609/2000.0 (80.45%)



-= Testing valid =-
Test set: Average loss: 0.3404,                   Accuracy: 1782/2000.0 (89.10%)



Epoch 10 train accuracy: 94.88%, valid accuracy 89.10%
-= Testing valid =-
Test set: Average loss: 0.3504,                   Accuracy: 1780/2000.0 (89.00%)



-= Testing valid =-
Test set: Average loss: 0.3877,                   Accuracy: 1749/2000.0 (87.45%)



-= Testing valid =-
Test set: Average loss: 0.5151,                   Accuracy: 1679/2000.0 (83.95%)



-= Testing valid =-
Test set: Average loss: 0.1783,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.5421,                   Accuracy: 1645/2000.0 (82.25%)



-= Testing valid =-
Test set: Average loss: 0.1910,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.4548,                   Accuracy: 1723/2000.0 (86.15%)



-= Testing valid =-
Test set: Average loss: 0.2489,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2666,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2685,                   Accuracy: 1827/2000.0 (91.35%)



Epoch 20 train accuracy: 97.38%, valid accuracy 91.35%
-= Testing valid =-
Test set: Average loss: 0.3363,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.3121,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.3265,                   Accuracy: 1777/2000.0 (88.85%)



-= Testing valid =-
Test set: Average loss: 0.2661,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.2700,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.3351,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.1423,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1640,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.2147,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.3508,                   Accuracy: 1783/2000.0 (89.15%)



Epoch 30 train accuracy: 97.50%, valid accuracy 89.15%
-= Testing valid =-
Test set: Average loss: 0.1939,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.2532,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2131,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.2306,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.2340,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.1996,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.1914,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2650,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.3042,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.1685,                   Accuracy: 1892/2000.0 (94.60%)



Epoch 40 train accuracy: 98.10%, valid accuracy 94.60%
-= Testing valid =-
Test set: Average loss: 0.2246,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.1899,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1596,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1867,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.1849,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2170,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.1814,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1571,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.2001,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1998,                   Accuracy: 1875/2000.0 (93.75%)



Epoch 50 train accuracy: 97.39%, valid accuracy 93.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1914,                   Accuracy: 56538/60000 (94.23%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1355,                   Accuracy: 57548/60000 (95.91%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1006,                   Accuracy: 58178/60000 (96.96%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1001,                   Accuracy: 58236/60000 (97.06%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1036,                   Accuracy: 58202/60000 (97.00%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1279,                   Accuracy: 57761/60000 (96.27%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1744,                   Accuracy: 56967/60000 (94.94%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2446,                   Accuracy: 55699/60000 (92.83%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3639,                   Accuracy: 53489/60000 (89.15%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5735,                   Accuracy: 49908/60000 (83.18%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.9893,                   Accuracy: 43177/60000 (71.96%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.5689,                   Accuracy: 35457/60000 (59.10%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.2684,                   Accuracy: 28386/60000 (47.31%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.9876,                   Accuracy: 23644/60000 (39.41%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.5570,                   Accuracy: 21510/60000 (35.85%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.8852,                   Accuracy: 21374/60000 (35.62%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.1840,                   Accuracy: 23127/60000 (38.54%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.4437,                   Accuracy: 25068/60000 (41.78%)
-= Testing Rotation 180 =-
Test set: Average loss: 5.0240,                   Accuracy: 26204/60000 (43.67%)
-= Testing Rotation 190 =-
Test set: Average loss: 5.2467,                   Accuracy: 26835/60000 (44.72%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.6310,                   Accuracy: 26437/60000 (44.06%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.7742,                   Accuracy: 26021/60000 (43.37%)
-= Testing Rotation 220 =-
Test set: Average loss: 5.9233,                   Accuracy: 25503/60000 (42.51%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.9915,                   Accuracy: 24659/60000 (41.10%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.9103,                   Accuracy: 24070/60000 (40.12%)
-= Testing Rotation 250 =-
Test set: Average loss: 5.8386,                   Accuracy: 23731/60000 (39.55%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.4844,                   Accuracy: 23970/60000 (39.95%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.4374,                   Accuracy: 23225/60000 (38.71%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.0702,                   Accuracy: 22684/60000 (37.81%)
-= Testing Rotation 290 =-
Test set: Average loss: 4.7080,                   Accuracy: 22241/60000 (37.07%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.2664,                   Accuracy: 22603/60000 (37.67%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.5942,                   Accuracy: 24951/60000 (41.58%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.7138,                   Accuracy: 28689/60000 (47.81%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.7436,                   Accuracy: 35232/60000 (58.72%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.8819,                   Accuracy: 44894/60000 (74.82%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.4006,                   Accuracy: 52689/60000 (87.82%)
{0: tensor(94.2300), 10: tensor(95.9133), 20: tensor(96.9633), 30: tensor(97.0600), 40: tensor(97.0033), 50: tensor(96.2683), 60: tensor(94.9450), 70: tensor(92.8317), 80: tensor(89.1483), 90: tensor(83.1800), 100: tensor(71.9617), 110: tensor(59.0950), 120: tensor(47.3100), 130: tensor(39.4067), 140: tensor(35.8500), 150: tensor(35.6233), 160: tensor(38.5450), 170: tensor(41.7800), 180: tensor(43.6733), 190: tensor(44.7250), 200: tensor(44.0617), 210: tensor(43.3683), 220: tensor(42.5050), 230: tensor(41.0983), 240: tensor(40.1167), 250: tensor(39.5517), 260: tensor(39.9500), 270: tensor(38.7083), 280: tensor(37.8067), 290: tensor(37.0683), 300: tensor(37.6717), 310: tensor(41.5850), 320: tensor(47.8150), 330: tensor(58.7200), 340: tensor(74.8233), 350: tensor(87.8150)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=3, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.3721,                   Accuracy: 354/2000.0 (17.70%)



-= Testing valid =-
Test set: Average loss: 2.7492,                   Accuracy: 565/2000.0 (28.25%)



-= Testing valid =-
Test set: Average loss: 1.2530,                   Accuracy: 1133/2000.0 (56.65%)



-= Testing valid =-
Test set: Average loss: 1.0345,                   Accuracy: 1330/2000.0 (66.50%)



-= Testing valid =-
Test set: Average loss: 0.8363,                   Accuracy: 1461/2000.0 (73.05%)



-= Testing valid =-
Test set: Average loss: 1.1696,                   Accuracy: 1298/2000.0 (64.90%)



-= Testing valid =-
Test set: Average loss: 0.6897,                   Accuracy: 1579/2000.0 (78.95%)



-= Testing valid =-
Test set: Average loss: 0.8622,                   Accuracy: 1411/2000.0 (70.55%)



-= Testing valid =-
Test set: Average loss: 0.3563,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.5603,                   Accuracy: 1625/2000.0 (81.25%)



Epoch 10 train accuracy: 94.15%, valid accuracy 81.25%
-= Testing valid =-
Test set: Average loss: 0.4178,                   Accuracy: 1733/2000.0 (86.65%)



-= Testing valid =-
Test set: Average loss: 0.5016,                   Accuracy: 1686/2000.0 (84.30%)



-= Testing valid =-
Test set: Average loss: 0.3543,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.3697,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.4087,                   Accuracy: 1737/2000.0 (86.85%)



-= Testing valid =-
Test set: Average loss: 0.3706,                   Accuracy: 1756/2000.0 (87.80%)



-= Testing valid =-
Test set: Average loss: 0.2800,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.2351,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.5843,                   Accuracy: 1637/2000.0 (81.85%)



-= Testing valid =-
Test set: Average loss: 0.2970,                   Accuracy: 1815/2000.0 (90.75%)



Epoch 20 train accuracy: 96.26%, valid accuracy 90.75%
-= Testing valid =-
Test set: Average loss: 0.3361,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.2498,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.4324,                   Accuracy: 1711/2000.0 (85.55%)



-= Testing valid =-
Test set: Average loss: 0.3709,                   Accuracy: 1748/2000.0 (87.40%)



-= Testing valid =-
Test set: Average loss: 0.2819,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.4047,                   Accuracy: 1720/2000.0 (86.00%)



-= Testing valid =-
Test set: Average loss: 0.2859,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.1592,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.4049,                   Accuracy: 1745/2000.0 (87.25%)



-= Testing valid =-
Test set: Average loss: 0.3826,                   Accuracy: 1736/2000.0 (86.80%)



Epoch 30 train accuracy: 96.47%, valid accuracy 86.80%
-= Testing valid =-
Test set: Average loss: 0.2466,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2030,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.2238,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.1611,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1569,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.2016,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.2272,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.1702,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1840,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2167,                   Accuracy: 1858/2000.0 (92.90%)



Epoch 40 train accuracy: 97.88%, valid accuracy 92.90%
-= Testing valid =-
Test set: Average loss: 0.1799,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1830,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1633,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1782,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.2226,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2087,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.2191,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2027,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.2727,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.2165,                   Accuracy: 1855/2000.0 (92.75%)



Epoch 50 train accuracy: 98.01%, valid accuracy 92.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1971,                   Accuracy: 56451/60000 (94.08%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1249,                   Accuracy: 57798/60000 (96.33%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0857,                   Accuracy: 58473/60000 (97.46%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0730,                   Accuracy: 58712/60000 (97.85%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0736,                   Accuracy: 58710/60000 (97.85%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0845,                   Accuracy: 58505/60000 (97.51%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1032,                   Accuracy: 58189/60000 (96.98%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1376,                   Accuracy: 57633/60000 (96.06%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2023,                   Accuracy: 56491/60000 (94.15%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3195,                   Accuracy: 54436/60000 (90.73%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.5811,                   Accuracy: 49857/60000 (83.10%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.9615,                   Accuracy: 44097/60000 (73.50%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.4917,                   Accuracy: 37199/60000 (62.00%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.1283,                   Accuracy: 30680/60000 (51.13%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.8295,                   Accuracy: 25942/60000 (43.24%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4755,                   Accuracy: 23759/60000 (39.60%)
-= Testing Rotation 160 =-
Test set: Average loss: 4.1096,                   Accuracy: 23596/60000 (39.33%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.7025,                   Accuracy: 24756/60000 (41.26%)
-= Testing Rotation 180 =-
Test set: Average loss: 5.3468,                   Accuracy: 25689/60000 (42.81%)
-= Testing Rotation 190 =-
Test set: Average loss: 5.5614,                   Accuracy: 26551/60000 (44.25%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.9250,                   Accuracy: 26844/60000 (44.74%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.0467,                   Accuracy: 27573/60000 (45.96%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.0772,                   Accuracy: 27868/60000 (46.45%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.9786,                   Accuracy: 27564/60000 (45.94%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.7347,                   Accuracy: 27057/60000 (45.10%)
-= Testing Rotation 250 =-
Test set: Average loss: 5.4682,                   Accuracy: 26012/60000 (43.35%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.0108,                   Accuracy: 25418/60000 (42.36%)
-= Testing Rotation 270 =-
Test set: Average loss: 4.8287,                   Accuracy: 24231/60000 (40.38%)
-= Testing Rotation 280 =-
Test set: Average loss: 4.3383,                   Accuracy: 23683/60000 (39.47%)
-= Testing Rotation 290 =-
Test set: Average loss: 4.0537,                   Accuracy: 22917/60000 (38.19%)
-= Testing Rotation 300 =-
Test set: Average loss: 3.5442,                   Accuracy: 23462/60000 (39.10%)
-= Testing Rotation 310 =-
Test set: Average loss: 2.8418,                   Accuracy: 26162/60000 (43.60%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.0570,                   Accuracy: 30990/60000 (51.65%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.3248,                   Accuracy: 37751/60000 (62.92%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.7511,                   Accuracy: 46035/60000 (76.72%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3806,                   Accuracy: 53078/60000 (88.46%)
{0: tensor(94.0850), 10: tensor(96.3300), 20: tensor(97.4550), 30: tensor(97.8533), 40: tensor(97.8500), 50: tensor(97.5083), 60: tensor(96.9817), 70: tensor(96.0550), 80: tensor(94.1517), 90: tensor(90.7267), 100: tensor(83.0950), 110: tensor(73.4950), 120: tensor(61.9983), 130: tensor(51.1333), 140: tensor(43.2367), 150: tensor(39.5983), 160: tensor(39.3267), 170: tensor(41.2600), 180: tensor(42.8150), 190: tensor(44.2517), 200: tensor(44.7400), 210: tensor(45.9550), 220: tensor(46.4467), 230: tensor(45.9400), 240: tensor(45.0950), 250: tensor(43.3533), 260: tensor(42.3633), 270: tensor(40.3850), 280: tensor(39.4717), 290: tensor(38.1950), 300: tensor(39.1033), 310: tensor(43.6033), 320: tensor(51.6500), 330: tensor(62.9183), 340: tensor(76.7250), 350: tensor(88.4633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=4, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0059,                   Accuracy: 565/2000.0 (28.25%)



-= Testing valid =-
Test set: Average loss: 1.8300,                   Accuracy: 784/2000.0 (39.20%)



-= Testing valid =-
Test set: Average loss: 0.9802,                   Accuracy: 1394/2000.0 (69.70%)



-= Testing valid =-
Test set: Average loss: 2.0173,                   Accuracy: 849/2000.0 (42.45%)



-= Testing valid =-
Test set: Average loss: 0.9053,                   Accuracy: 1414/2000.0 (70.70%)



-= Testing valid =-
Test set: Average loss: 0.7938,                   Accuracy: 1533/2000.0 (76.65%)



-= Testing valid =-
Test set: Average loss: 0.9671,                   Accuracy: 1344/2000.0 (67.20%)



-= Testing valid =-
Test set: Average loss: 0.6715,                   Accuracy: 1569/2000.0 (78.45%)



-= Testing valid =-
Test set: Average loss: 0.8362,                   Accuracy: 1363/2000.0 (68.15%)



-= Testing valid =-
Test set: Average loss: 0.8812,                   Accuracy: 1336/2000.0 (66.80%)



Epoch 10 train accuracy: 91.90%, valid accuracy 66.80%
-= Testing valid =-
Test set: Average loss: 0.6100,                   Accuracy: 1617/2000.0 (80.85%)



-= Testing valid =-
Test set: Average loss: 0.3018,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.4004,                   Accuracy: 1751/2000.0 (87.55%)



-= Testing valid =-
Test set: Average loss: 0.3052,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2806,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.6138,                   Accuracy: 1571/2000.0 (78.55%)



-= Testing valid =-
Test set: Average loss: 0.3956,                   Accuracy: 1755/2000.0 (87.75%)



-= Testing valid =-
Test set: Average loss: 0.4028,                   Accuracy: 1739/2000.0 (86.95%)



-= Testing valid =-
Test set: Average loss: 0.3351,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.3305,                   Accuracy: 1783/2000.0 (89.15%)



Epoch 20 train accuracy: 97.06%, valid accuracy 89.15%
-= Testing valid =-
Test set: Average loss: 0.2674,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.3320,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.2916,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2913,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.2587,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2065,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.2908,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2419,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2165,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.3332,                   Accuracy: 1787/2000.0 (89.35%)



Epoch 30 train accuracy: 97.46%, valid accuracy 89.35%
-= Testing valid =-
Test set: Average loss: 0.2856,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2776,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.1558,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1952,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1674,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1953,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.2601,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.1890,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1879,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.2176,                   Accuracy: 1867/2000.0 (93.35%)



Epoch 40 train accuracy: 97.74%, valid accuracy 93.35%
-= Testing valid =-
Test set: Average loss: 0.1692,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1915,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1746,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.2318,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2073,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.1508,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1465,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1883,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1866,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1632,                   Accuracy: 1902/2000.0 (95.10%)



Epoch 50 train accuracy: 97.95%, valid accuracy 95.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1917,                   Accuracy: 56638/60000 (94.40%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1363,                   Accuracy: 57630/60000 (96.05%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1015,                   Accuracy: 58234/60000 (97.06%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0948,                   Accuracy: 58359/60000 (97.26%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0959,                   Accuracy: 58325/60000 (97.21%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1085,                   Accuracy: 58145/60000 (96.91%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1396,                   Accuracy: 57616/60000 (96.03%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1879,                   Accuracy: 56812/60000 (94.69%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2721,                   Accuracy: 55281/60000 (92.14%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5088,                   Accuracy: 51044/60000 (85.07%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.8758,                   Accuracy: 44897/60000 (74.83%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.4775,                   Accuracy: 36939/60000 (61.56%)
-= Testing Rotation 120 =-
Test set: Average loss: 2.1429,                   Accuracy: 30188/60000 (50.31%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.7445,                   Accuracy: 25292/60000 (42.15%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.2742,                   Accuracy: 22562/60000 (37.60%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.6561,                   Accuracy: 22170/60000 (36.95%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.9490,                   Accuracy: 23418/60000 (39.03%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.2744,                   Accuracy: 24757/60000 (41.26%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.8561,                   Accuracy: 25770/60000 (42.95%)
-= Testing Rotation 190 =-
Test set: Average loss: 5.2335,                   Accuracy: 26016/60000 (43.36%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.7637,                   Accuracy: 26501/60000 (44.17%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.1018,                   Accuracy: 26512/60000 (44.19%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.2498,                   Accuracy: 26208/60000 (43.68%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.2992,                   Accuracy: 25571/60000 (42.62%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.1996,                   Accuracy: 24527/60000 (40.88%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.1354,                   Accuracy: 23860/60000 (39.77%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.7761,                   Accuracy: 23715/60000 (39.53%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.6296,                   Accuracy: 21537/60000 (35.90%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.0874,                   Accuracy: 21353/60000 (35.59%)
-= Testing Rotation 290 =-
Test set: Average loss: 4.6150,                   Accuracy: 21099/60000 (35.17%)
-= Testing Rotation 300 =-
Test set: Average loss: 3.9110,                   Accuracy: 22455/60000 (37.42%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.0613,                   Accuracy: 25302/60000 (42.17%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1475,                   Accuracy: 30200/60000 (50.33%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.3323,                   Accuracy: 38288/60000 (63.81%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.7053,                   Accuracy: 47126/60000 (78.54%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3588,                   Accuracy: 53602/60000 (89.34%)
{0: tensor(94.3967), 10: tensor(96.0500), 20: tensor(97.0567), 30: tensor(97.2650), 40: tensor(97.2083), 50: tensor(96.9083), 60: tensor(96.0267), 70: tensor(94.6867), 80: tensor(92.1350), 90: tensor(85.0733), 100: tensor(74.8283), 110: tensor(61.5650), 120: tensor(50.3133), 130: tensor(42.1533), 140: tensor(37.6033), 150: tensor(36.9500), 160: tensor(39.0300), 170: tensor(41.2617), 180: tensor(42.9500), 190: tensor(43.3600), 200: tensor(44.1683), 210: tensor(44.1867), 220: tensor(43.6800), 230: tensor(42.6183), 240: tensor(40.8783), 250: tensor(39.7667), 260: tensor(39.5250), 270: tensor(35.8950), 280: tensor(35.5883), 290: tensor(35.1650), 300: tensor(37.4250), 310: tensor(42.1700), 320: tensor(50.3333), 330: tensor(63.8133), 340: tensor(78.5433), 350: tensor(89.3367)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=5, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.5111,                   Accuracy: 191/2000.0 (9.55%)



-= Testing valid =-
Test set: Average loss: 1.6747,                   Accuracy: 810/2000.0 (40.50%)



-= Testing valid =-
Test set: Average loss: 1.1459,                   Accuracy: 1231/2000.0 (61.55%)



-= Testing valid =-
Test set: Average loss: 1.1758,                   Accuracy: 1203/2000.0 (60.15%)



-= Testing valid =-
Test set: Average loss: 0.8808,                   Accuracy: 1393/2000.0 (69.65%)



-= Testing valid =-
Test set: Average loss: 0.9280,                   Accuracy: 1401/2000.0 (70.05%)



-= Testing valid =-
Test set: Average loss: 0.9653,                   Accuracy: 1409/2000.0 (70.45%)



-= Testing valid =-
Test set: Average loss: 0.6555,                   Accuracy: 1568/2000.0 (78.40%)



-= Testing valid =-
Test set: Average loss: 0.6623,                   Accuracy: 1568/2000.0 (78.40%)



-= Testing valid =-
Test set: Average loss: 0.4379,                   Accuracy: 1721/2000.0 (86.05%)



Epoch 10 train accuracy: 94.64%, valid accuracy 86.05%
-= Testing valid =-
Test set: Average loss: 0.8037,                   Accuracy: 1519/2000.0 (75.95%)



-= Testing valid =-
Test set: Average loss: 0.4213,                   Accuracy: 1726/2000.0 (86.30%)



-= Testing valid =-
Test set: Average loss: 0.5034,                   Accuracy: 1666/2000.0 (83.30%)



-= Testing valid =-
Test set: Average loss: 0.4000,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.3726,                   Accuracy: 1744/2000.0 (87.20%)



-= Testing valid =-
Test set: Average loss: 0.2421,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.3218,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.4290,                   Accuracy: 1733/2000.0 (86.65%)



-= Testing valid =-
Test set: Average loss: 0.2646,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.3088,                   Accuracy: 1805/2000.0 (90.25%)



Epoch 20 train accuracy: 95.34%, valid accuracy 90.25%
-= Testing valid =-
Test set: Average loss: 0.2623,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.1901,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2235,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.1918,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1986,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.1936,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2714,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.1793,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1882,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1852,                   Accuracy: 1879/2000.0 (93.95%)



Epoch 30 train accuracy: 96.85%, valid accuracy 93.95%
-= Testing valid =-
Test set: Average loss: 0.2077,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.2270,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2164,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.2310,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.2075,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1747,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.2298,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.1901,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1887,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1959,                   Accuracy: 1882/2000.0 (94.10%)



Epoch 40 train accuracy: 97.55%, valid accuracy 94.10%
-= Testing valid =-
Test set: Average loss: 0.2025,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.2002,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2414,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2093,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.2243,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2265,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.2249,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2191,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1936,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1986,                   Accuracy: 1873/2000.0 (93.65%)



Epoch 50 train accuracy: 98.19%, valid accuracy 93.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2106,                   Accuracy: 56182/60000 (93.64%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1336,                   Accuracy: 57521/60000 (95.87%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0918,                   Accuracy: 58336/60000 (97.23%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0777,                   Accuracy: 58579/60000 (97.63%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0779,                   Accuracy: 58615/60000 (97.69%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0876,                   Accuracy: 58452/60000 (97.42%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1097,                   Accuracy: 58080/60000 (96.80%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1455,                   Accuracy: 57424/60000 (95.71%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2015,                   Accuracy: 56411/60000 (94.02%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3300,                   Accuracy: 54133/60000 (90.22%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.5608,                   Accuracy: 49907/60000 (83.18%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.9385,                   Accuracy: 44075/60000 (73.46%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.4505,                   Accuracy: 37464/60000 (62.44%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.0442,                   Accuracy: 30971/60000 (51.62%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.6913,                   Accuracy: 25664/60000 (42.77%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.2859,                   Accuracy: 22905/60000 (38.17%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.8648,                   Accuracy: 22383/60000 (37.31%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.3769,                   Accuracy: 23414/60000 (39.02%)
-= Testing Rotation 180 =-
Test set: Average loss: 5.2094,                   Accuracy: 24529/60000 (40.88%)
-= Testing Rotation 190 =-
Test set: Average loss: 5.4609,                   Accuracy: 25552/60000 (42.59%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.8867,                   Accuracy: 26098/60000 (43.50%)
-= Testing Rotation 210 =-
Test set: Average loss: 6.0497,                   Accuracy: 26603/60000 (44.34%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.0942,                   Accuracy: 26678/60000 (44.46%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.0187,                   Accuracy: 26447/60000 (44.08%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.8677,                   Accuracy: 25748/60000 (42.91%)
-= Testing Rotation 250 =-
Test set: Average loss: 5.7424,                   Accuracy: 24538/60000 (40.90%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.4136,                   Accuracy: 23895/60000 (39.83%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.3263,                   Accuracy: 22104/60000 (36.84%)
-= Testing Rotation 280 =-
Test set: Average loss: 4.8485,                   Accuracy: 21686/60000 (36.14%)
-= Testing Rotation 290 =-
Test set: Average loss: 4.3143,                   Accuracy: 20724/60000 (34.54%)
-= Testing Rotation 300 =-
Test set: Average loss: 3.6650,                   Accuracy: 21517/60000 (35.86%)
-= Testing Rotation 310 =-
Test set: Average loss: 2.9884,                   Accuracy: 23356/60000 (38.93%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.2040,                   Accuracy: 27772/60000 (46.29%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.4893,                   Accuracy: 34919/60000 (58.20%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.8474,                   Accuracy: 44343/60000 (73.90%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.4169,                   Accuracy: 52290/60000 (87.15%)
{0: tensor(93.6367), 10: tensor(95.8683), 20: tensor(97.2267), 30: tensor(97.6317), 40: tensor(97.6917), 50: tensor(97.4200), 60: tensor(96.8000), 70: tensor(95.7067), 80: tensor(94.0183), 90: tensor(90.2217), 100: tensor(83.1783), 110: tensor(73.4583), 120: tensor(62.4400), 130: tensor(51.6183), 140: tensor(42.7733), 150: tensor(38.1750), 160: tensor(37.3050), 170: tensor(39.0233), 180: tensor(40.8817), 190: tensor(42.5867), 200: tensor(43.4967), 210: tensor(44.3383), 220: tensor(44.4633), 230: tensor(44.0783), 240: tensor(42.9133), 250: tensor(40.8967), 260: tensor(39.8250), 270: tensor(36.8400), 280: tensor(36.1433), 290: tensor(34.5400), 300: tensor(35.8617), 310: tensor(38.9267), 320: tensor(46.2867), 330: tensor(58.1983), 340: tensor(73.9050), 350: tensor(87.1500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=6, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3126,                   Accuracy: 527/2000.0 (26.35%)



-= Testing valid =-
Test set: Average loss: 2.3195,                   Accuracy: 492/2000.0 (24.60%)



-= Testing valid =-
Test set: Average loss: 1.3038,                   Accuracy: 1162/2000.0 (58.10%)



-= Testing valid =-
Test set: Average loss: 0.7314,                   Accuracy: 1507/2000.0 (75.35%)



-= Testing valid =-
Test set: Average loss: 0.6274,                   Accuracy: 1597/2000.0 (79.85%)



-= Testing valid =-
Test set: Average loss: 1.0632,                   Accuracy: 1285/2000.0 (64.25%)



-= Testing valid =-
Test set: Average loss: 1.1413,                   Accuracy: 1242/2000.0 (62.10%)



-= Testing valid =-
Test set: Average loss: 0.8710,                   Accuracy: 1390/2000.0 (69.50%)



-= Testing valid =-
Test set: Average loss: 0.4754,                   Accuracy: 1687/2000.0 (84.35%)



-= Testing valid =-
Test set: Average loss: 0.7811,                   Accuracy: 1483/2000.0 (74.15%)



Epoch 10 train accuracy: 93.51%, valid accuracy 74.15%
-= Testing valid =-
Test set: Average loss: 0.3439,                   Accuracy: 1768/2000.0 (88.40%)



-= Testing valid =-
Test set: Average loss: 0.3036,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.6954,                   Accuracy: 1578/2000.0 (78.90%)



-= Testing valid =-
Test set: Average loss: 0.2355,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.3481,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.4830,                   Accuracy: 1668/2000.0 (83.40%)



-= Testing valid =-
Test set: Average loss: 0.3613,                   Accuracy: 1751/2000.0 (87.55%)



-= Testing valid =-
Test set: Average loss: 0.3230,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.2530,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2327,                   Accuracy: 1860/2000.0 (93.00%)



Epoch 20 train accuracy: 95.66%, valid accuracy 93.00%
-= Testing valid =-
Test set: Average loss: 0.2280,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2316,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2886,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.3262,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.3340,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.2041,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.2619,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2541,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2495,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.3018,                   Accuracy: 1802/2000.0 (90.10%)



Epoch 30 train accuracy: 97.79%, valid accuracy 90.10%
-= Testing valid =-
Test set: Average loss: 0.2100,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2253,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2177,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2236,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2771,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.2089,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.1552,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.2065,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.1865,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1810,                   Accuracy: 1876/2000.0 (93.80%)



Epoch 40 train accuracy: 97.46%, valid accuracy 93.80%
-= Testing valid =-
Test set: Average loss: 0.2215,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.2105,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.2568,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2121,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.2441,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.1845,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.2165,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.1765,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1837,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1893,                   Accuracy: 1872/2000.0 (93.60%)



Epoch 50 train accuracy: 97.26%, valid accuracy 93.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2004,                   Accuracy: 56336/60000 (93.89%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1174,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0824,                   Accuracy: 58513/60000 (97.52%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0713,                   Accuracy: 58709/60000 (97.85%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0713,                   Accuracy: 58722/60000 (97.87%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0810,                   Accuracy: 58566/60000 (97.61%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1022,                   Accuracy: 58205/60000 (97.01%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1354,                   Accuracy: 57621/60000 (96.04%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1879,                   Accuracy: 56704/60000 (94.51%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3032,                   Accuracy: 54708/60000 (91.18%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.5346,                   Accuracy: 50512/60000 (84.19%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.8943,                   Accuracy: 44740/60000 (74.57%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.4327,                   Accuracy: 37382/60000 (62.30%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.0870,                   Accuracy: 30436/60000 (50.73%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.7559,                   Accuracy: 25249/60000 (42.08%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.3910,                   Accuracy: 22563/60000 (37.60%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.9838,                   Accuracy: 22356/60000 (37.26%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.4771,                   Accuracy: 23737/60000 (39.56%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.9852,                   Accuracy: 25122/60000 (41.87%)
-= Testing Rotation 190 =-
Test set: Average loss: 5.1325,                   Accuracy: 26149/60000 (43.58%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.4199,                   Accuracy: 26504/60000 (44.17%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.5766,                   Accuracy: 26972/60000 (44.95%)
-= Testing Rotation 220 =-
Test set: Average loss: 5.7329,                   Accuracy: 26887/60000 (44.81%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.7825,                   Accuracy: 26422/60000 (44.04%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.6445,                   Accuracy: 25735/60000 (42.89%)
-= Testing Rotation 250 =-
Test set: Average loss: 5.5037,                   Accuracy: 24820/60000 (41.37%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.1895,                   Accuracy: 24607/60000 (41.01%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.1151,                   Accuracy: 23403/60000 (39.01%)
-= Testing Rotation 280 =-
Test set: Average loss: 4.7414,                   Accuracy: 22703/60000 (37.84%)
-= Testing Rotation 290 =-
Test set: Average loss: 4.3787,                   Accuracy: 22263/60000 (37.10%)
-= Testing Rotation 300 =-
Test set: Average loss: 3.8472,                   Accuracy: 22924/60000 (38.21%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.1393,                   Accuracy: 25700/60000 (42.83%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.3211,                   Accuracy: 30585/60000 (50.97%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.5126,                   Accuracy: 37428/60000 (62.38%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.8311,                   Accuracy: 45694/60000 (76.16%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3967,                   Accuracy: 52756/60000 (87.93%)
{0: tensor(93.8933), 10: tensor(96.4100), 20: tensor(97.5217), 30: tensor(97.8483), 40: tensor(97.8700), 50: tensor(97.6100), 60: tensor(97.0083), 70: tensor(96.0350), 80: tensor(94.5067), 90: tensor(91.1800), 100: tensor(84.1867), 110: tensor(74.5667), 120: tensor(62.3033), 130: tensor(50.7267), 140: tensor(42.0817), 150: tensor(37.6050), 160: tensor(37.2600), 170: tensor(39.5617), 180: tensor(41.8700), 190: tensor(43.5817), 200: tensor(44.1733), 210: tensor(44.9533), 220: tensor(44.8117), 230: tensor(44.0367), 240: tensor(42.8917), 250: tensor(41.3667), 260: tensor(41.0117), 270: tensor(39.0050), 280: tensor(37.8383), 290: tensor(37.1050), 300: tensor(38.2067), 310: tensor(42.8333), 320: tensor(50.9750), 330: tensor(62.3800), 340: tensor(76.1567), 350: tensor(87.9267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=7, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5999,                   Accuracy: 442/2000.0 (22.10%)



-= Testing valid =-
Test set: Average loss: 3.0429,                   Accuracy: 480/2000.0 (24.00%)



-= Testing valid =-
Test set: Average loss: 1.1841,                   Accuracy: 1241/2000.0 (62.05%)



-= Testing valid =-
Test set: Average loss: 2.0011,                   Accuracy: 812/2000.0 (40.60%)



-= Testing valid =-
Test set: Average loss: 1.0833,                   Accuracy: 1275/2000.0 (63.75%)



-= Testing valid =-
Test set: Average loss: 1.1311,                   Accuracy: 1232/2000.0 (61.60%)



-= Testing valid =-
Test set: Average loss: 0.9576,                   Accuracy: 1386/2000.0 (69.30%)



-= Testing valid =-
Test set: Average loss: 0.5954,                   Accuracy: 1602/2000.0 (80.10%)



-= Testing valid =-
Test set: Average loss: 0.2365,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.6111,                   Accuracy: 1621/2000.0 (81.05%)



Epoch 10 train accuracy: 94.14%, valid accuracy 81.05%
-= Testing valid =-
Test set: Average loss: 0.3642,                   Accuracy: 1765/2000.0 (88.25%)



-= Testing valid =-
Test set: Average loss: 0.4645,                   Accuracy: 1695/2000.0 (84.75%)



-= Testing valid =-
Test set: Average loss: 0.4623,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.2807,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.3295,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.2049,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.4945,                   Accuracy: 1689/2000.0 (84.45%)



-= Testing valid =-
Test set: Average loss: 0.4227,                   Accuracy: 1732/2000.0 (86.60%)



-= Testing valid =-
Test set: Average loss: 0.3887,                   Accuracy: 1753/2000.0 (87.65%)



-= Testing valid =-
Test set: Average loss: 0.3823,                   Accuracy: 1754/2000.0 (87.70%)



Epoch 20 train accuracy: 96.68%, valid accuracy 87.70%
-= Testing valid =-
Test set: Average loss: 0.2963,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2776,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.2329,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.2781,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2876,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2352,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.2293,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.4250,                   Accuracy: 1718/2000.0 (85.90%)



-= Testing valid =-
Test set: Average loss: 0.2514,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.1947,                   Accuracy: 1870/2000.0 (93.50%)



Epoch 30 train accuracy: 97.29%, valid accuracy 93.50%
-= Testing valid =-
Test set: Average loss: 0.2284,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.1718,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.2534,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.1711,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.2833,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2665,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.1832,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1852,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1811,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1991,                   Accuracy: 1891/2000.0 (94.55%)



Epoch 40 train accuracy: 97.59%, valid accuracy 94.55%
-= Testing valid =-
Test set: Average loss: 0.1965,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1800,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1869,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.2217,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2092,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.2224,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.1750,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1590,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1741,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1753,                   Accuracy: 1900/2000.0 (95.00%)



Epoch 50 train accuracy: 98.01%, valid accuracy 95.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1885,                   Accuracy: 56677/60000 (94.46%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1074,                   Accuracy: 58080/60000 (96.80%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0683,                   Accuracy: 58764/60000 (97.94%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0579,                   Accuracy: 58946/60000 (98.24%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0597,                   Accuracy: 58916/60000 (98.19%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0692,                   Accuracy: 58734/60000 (97.89%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0939,                   Accuracy: 58329/60000 (97.21%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1368,                   Accuracy: 57595/60000 (95.99%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2101,                   Accuracy: 56231/60000 (93.72%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3465,                   Accuracy: 53715/60000 (89.53%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6089,                   Accuracy: 48892/60000 (81.49%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.0522,                   Accuracy: 41937/60000 (69.89%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.6535,                   Accuracy: 34336/60000 (57.23%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.3065,                   Accuracy: 28791/60000 (47.99%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.9266,                   Accuracy: 24268/60000 (40.45%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4173,                   Accuracy: 22524/60000 (37.54%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.8379,                   Accuracy: 23488/60000 (39.15%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.1685,                   Accuracy: 24669/60000 (41.12%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.7506,                   Accuracy: 25988/60000 (43.31%)
-= Testing Rotation 190 =-
Test set: Average loss: 5.0609,                   Accuracy: 26472/60000 (44.12%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.6631,                   Accuracy: 26551/60000 (44.25%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.9334,                   Accuracy: 26115/60000 (43.53%)
-= Testing Rotation 220 =-
Test set: Average loss: 6.1160,                   Accuracy: 25548/60000 (42.58%)
-= Testing Rotation 230 =-
Test set: Average loss: 6.2128,                   Accuracy: 25012/60000 (41.69%)
-= Testing Rotation 240 =-
Test set: Average loss: 6.1250,                   Accuracy: 24596/60000 (40.99%)
-= Testing Rotation 250 =-
Test set: Average loss: 6.0602,                   Accuracy: 24290/60000 (40.48%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.7343,                   Accuracy: 24359/60000 (40.60%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.7340,                   Accuracy: 23088/60000 (38.48%)
-= Testing Rotation 280 =-
Test set: Average loss: 5.3649,                   Accuracy: 22369/60000 (37.28%)
-= Testing Rotation 290 =-
Test set: Average loss: 4.9910,                   Accuracy: 21198/60000 (35.33%)
-= Testing Rotation 300 =-
Test set: Average loss: 4.3721,                   Accuracy: 21384/60000 (35.64%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.5691,                   Accuracy: 23189/60000 (38.65%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.5691,                   Accuracy: 27999/60000 (46.67%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.6290,                   Accuracy: 35930/60000 (59.88%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.8619,                   Accuracy: 45437/60000 (75.73%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3911,                   Accuracy: 53061/60000 (88.43%)
{0: tensor(94.4617), 10: tensor(96.8000), 20: tensor(97.9400), 30: tensor(98.2433), 40: tensor(98.1933), 50: tensor(97.8900), 60: tensor(97.2150), 70: tensor(95.9917), 80: tensor(93.7183), 90: tensor(89.5250), 100: tensor(81.4867), 110: tensor(69.8950), 120: tensor(57.2267), 130: tensor(47.9850), 140: tensor(40.4467), 150: tensor(37.5400), 160: tensor(39.1467), 170: tensor(41.1150), 180: tensor(43.3133), 190: tensor(44.1200), 200: tensor(44.2517), 210: tensor(43.5250), 220: tensor(42.5800), 230: tensor(41.6867), 240: tensor(40.9933), 250: tensor(40.4833), 260: tensor(40.5983), 270: tensor(38.4800), 280: tensor(37.2817), 290: tensor(35.3300), 300: tensor(35.6400), 310: tensor(38.6483), 320: tensor(46.6650), 330: tensor(59.8833), 340: tensor(75.7283), 350: tensor(88.4350)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=8, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8988,                   Accuracy: 568/2000.0 (28.40%)



-= Testing valid =-
Test set: Average loss: 3.9363,                   Accuracy: 319/2000.0 (15.95%)



-= Testing valid =-
Test set: Average loss: 1.5762,                   Accuracy: 971/2000.0 (48.55%)



-= Testing valid =-
Test set: Average loss: 1.5067,                   Accuracy: 1100/2000.0 (55.00%)



-= Testing valid =-
Test set: Average loss: 2.2653,                   Accuracy: 753/2000.0 (37.65%)



-= Testing valid =-
Test set: Average loss: 0.9127,                   Accuracy: 1383/2000.0 (69.15%)



-= Testing valid =-
Test set: Average loss: 0.6261,                   Accuracy: 1604/2000.0 (80.20%)



-= Testing valid =-
Test set: Average loss: 0.4735,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.8421,                   Accuracy: 1436/2000.0 (71.80%)



-= Testing valid =-
Test set: Average loss: 0.4591,                   Accuracy: 1711/2000.0 (85.55%)



Epoch 10 train accuracy: 93.59%, valid accuracy 85.55%
-= Testing valid =-
Test set: Average loss: 0.4920,                   Accuracy: 1649/2000.0 (82.45%)



-= Testing valid =-
Test set: Average loss: 0.3371,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.4307,                   Accuracy: 1709/2000.0 (85.45%)



-= Testing valid =-
Test set: Average loss: 0.3566,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.2557,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.3115,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.2430,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.2336,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.2556,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.3253,                   Accuracy: 1802/2000.0 (90.10%)



Epoch 20 train accuracy: 96.44%, valid accuracy 90.10%
-= Testing valid =-
Test set: Average loss: 0.2607,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.1752,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2006,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1755,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.2076,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.2804,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2564,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2205,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.1944,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2256,                   Accuracy: 1858/2000.0 (92.90%)



Epoch 30 train accuracy: 97.41%, valid accuracy 92.90%
-= Testing valid =-
Test set: Average loss: 0.2433,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2328,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2324,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2958,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2752,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2565,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2402,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.2307,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.2218,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1843,                   Accuracy: 1877/2000.0 (93.85%)



Epoch 40 train accuracy: 97.41%, valid accuracy 93.85%
-= Testing valid =-
Test set: Average loss: 0.2222,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2371,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.3076,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2519,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.1957,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1762,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.2054,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2142,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2034,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.2012,                   Accuracy: 1874/2000.0 (93.70%)



Epoch 50 train accuracy: 97.88%, valid accuracy 93.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2543,                   Accuracy: 55482/60000 (92.47%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1707,                   Accuracy: 56899/60000 (94.83%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1273,                   Accuracy: 57726/60000 (96.21%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1088,                   Accuracy: 58075/60000 (96.79%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1008,                   Accuracy: 58203/60000 (97.00%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1081,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1343,                   Accuracy: 57545/60000 (95.91%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1818,                   Accuracy: 56738/60000 (94.56%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2541,                   Accuracy: 55517/60000 (92.53%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4231,                   Accuracy: 52771/60000 (87.95%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7188,                   Accuracy: 47838/60000 (79.73%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.1728,                   Accuracy: 41236/60000 (68.73%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.8102,                   Accuracy: 33281/60000 (55.47%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.4702,                   Accuracy: 25876/60000 (43.13%)
-= Testing Rotation 140 =-
Test set: Average loss: 3.0860,                   Accuracy: 20896/60000 (34.83%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.5755,                   Accuracy: 19349/60000 (32.25%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.9132,                   Accuracy: 21184/60000 (35.31%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.1330,                   Accuracy: 24075/60000 (40.12%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.6441,                   Accuracy: 25624/60000 (42.71%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.7348,                   Accuracy: 26948/60000 (44.91%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.0796,                   Accuracy: 28058/60000 (46.76%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.2549,                   Accuracy: 28381/60000 (47.30%)
-= Testing Rotation 220 =-
Test set: Average loss: 5.4062,                   Accuracy: 28193/60000 (46.99%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.4612,                   Accuracy: 27789/60000 (46.31%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.4675,                   Accuracy: 27087/60000 (45.15%)
-= Testing Rotation 250 =-
Test set: Average loss: 5.4247,                   Accuracy: 26011/60000 (43.35%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.1514,                   Accuracy: 25186/60000 (41.98%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.1248,                   Accuracy: 23101/60000 (38.50%)
-= Testing Rotation 280 =-
Test set: Average loss: 4.6885,                   Accuracy: 22425/60000 (37.38%)
-= Testing Rotation 290 =-
Test set: Average loss: 4.4929,                   Accuracy: 21405/60000 (35.67%)
-= Testing Rotation 300 =-
Test set: Average loss: 3.9735,                   Accuracy: 22092/60000 (36.82%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.2924,                   Accuracy: 24873/60000 (41.46%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.4060,                   Accuracy: 30217/60000 (50.36%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.5597,                   Accuracy: 37428/60000 (62.38%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.8705,                   Accuracy: 46049/60000 (76.75%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.4403,                   Accuracy: 52418/60000 (87.36%)
{0: tensor(92.4700), 10: tensor(94.8317), 20: tensor(96.2100), 30: tensor(96.7917), 40: tensor(97.0050), 50: tensor(96.7317), 60: tensor(95.9083), 70: tensor(94.5633), 80: tensor(92.5283), 90: tensor(87.9517), 100: tensor(79.7300), 110: tensor(68.7267), 120: tensor(55.4683), 130: tensor(43.1267), 140: tensor(34.8267), 150: tensor(32.2483), 160: tensor(35.3067), 170: tensor(40.1250), 180: tensor(42.7067), 190: tensor(44.9133), 200: tensor(46.7633), 210: tensor(47.3017), 220: tensor(46.9883), 230: tensor(46.3150), 240: tensor(45.1450), 250: tensor(43.3517), 260: tensor(41.9767), 270: tensor(38.5017), 280: tensor(37.3750), 290: tensor(35.6750), 300: tensor(36.8200), 310: tensor(41.4550), 320: tensor(50.3617), 330: tensor(62.3800), 340: tensor(76.7483), 350: tensor(87.3633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=9, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.5918,                   Accuracy: 356/2000.0 (17.80%)



-= Testing valid =-
Test set: Average loss: 1.3268,                   Accuracy: 1029/2000.0 (51.45%)



-= Testing valid =-
Test set: Average loss: 1.0372,                   Accuracy: 1247/2000.0 (62.35%)



-= Testing valid =-
Test set: Average loss: 1.5908,                   Accuracy: 987/2000.0 (49.35%)



-= Testing valid =-
Test set: Average loss: 0.7045,                   Accuracy: 1553/2000.0 (77.65%)



-= Testing valid =-
Test set: Average loss: 0.6463,                   Accuracy: 1590/2000.0 (79.50%)



-= Testing valid =-
Test set: Average loss: 1.4850,                   Accuracy: 1114/2000.0 (55.70%)



-= Testing valid =-
Test set: Average loss: 0.7892,                   Accuracy: 1487/2000.0 (74.35%)



-= Testing valid =-
Test set: Average loss: 0.4887,                   Accuracy: 1688/2000.0 (84.40%)



-= Testing valid =-
Test set: Average loss: 0.3428,                   Accuracy: 1768/2000.0 (88.40%)



Epoch 10 train accuracy: 93.71%, valid accuracy 88.40%
-= Testing valid =-
Test set: Average loss: 0.4188,                   Accuracy: 1737/2000.0 (86.85%)



-= Testing valid =-
Test set: Average loss: 0.2782,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2737,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.4759,                   Accuracy: 1652/2000.0 (82.60%)



-= Testing valid =-
Test set: Average loss: 0.2802,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.4147,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.2753,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.2519,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.3142,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.2961,                   Accuracy: 1792/2000.0 (89.60%)



Epoch 20 train accuracy: 97.32%, valid accuracy 89.60%
-= Testing valid =-
Test set: Average loss: 0.2561,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2524,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2090,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2310,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.3589,                   Accuracy: 1738/2000.0 (86.90%)



-= Testing valid =-
Test set: Average loss: 0.3356,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.1993,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.2545,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.3351,                   Accuracy: 1765/2000.0 (88.25%)



-= Testing valid =-
Test set: Average loss: 0.2486,                   Accuracy: 1830/2000.0 (91.50%)



Epoch 30 train accuracy: 97.00%, valid accuracy 91.50%
-= Testing valid =-
Test set: Average loss: 0.2583,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.1831,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2377,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2134,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.1546,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1734,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1939,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1861,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.2035,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2374,                   Accuracy: 1834/2000.0 (91.70%)



Epoch 40 train accuracy: 97.12%, valid accuracy 91.70%
-= Testing valid =-
Test set: Average loss: 0.2225,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2163,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2433,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2049,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.1946,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.1677,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1866,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.1902,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.1978,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.1858,                   Accuracy: 1874/2000.0 (93.70%)



Epoch 50 train accuracy: 98.01%, valid accuracy 93.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1926,                   Accuracy: 56556/60000 (94.26%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1197,                   Accuracy: 57802/60000 (96.34%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0851,                   Accuracy: 58450/60000 (97.42%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0724,                   Accuracy: 58662/60000 (97.77%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0745,                   Accuracy: 58625/60000 (97.71%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0901,                   Accuracy: 58348/60000 (97.25%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1209,                   Accuracy: 57831/60000 (96.39%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1708,                   Accuracy: 56981/60000 (94.97%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2430,                   Accuracy: 55708/60000 (92.85%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3826,                   Accuracy: 53233/60000 (88.72%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.6296,                   Accuracy: 48889/60000 (81.48%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.0609,                   Accuracy: 42498/60000 (70.83%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.6275,                   Accuracy: 34975/60000 (58.29%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.2989,                   Accuracy: 28299/60000 (47.17%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.9795,                   Accuracy: 23642/60000 (39.40%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.5022,                   Accuracy: 22121/60000 (36.87%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.9485,                   Accuracy: 22486/60000 (37.48%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.3189,                   Accuracy: 23754/60000 (39.59%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.8186,                   Accuracy: 25347/60000 (42.24%)
-= Testing Rotation 190 =-
Test set: Average loss: 5.1286,                   Accuracy: 26358/60000 (43.93%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.4724,                   Accuracy: 26963/60000 (44.94%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.5762,                   Accuracy: 27560/60000 (45.93%)
-= Testing Rotation 220 =-
Test set: Average loss: 5.6622,                   Accuracy: 27367/60000 (45.61%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.6895,                   Accuracy: 26811/60000 (44.69%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.6050,                   Accuracy: 25824/60000 (43.04%)
-= Testing Rotation 250 =-
Test set: Average loss: 5.5285,                   Accuracy: 24619/60000 (41.03%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.2889,                   Accuracy: 23789/60000 (39.65%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.2262,                   Accuracy: 22508/60000 (37.51%)
-= Testing Rotation 280 =-
Test set: Average loss: 4.8402,                   Accuracy: 21939/60000 (36.56%)
-= Testing Rotation 290 =-
Test set: Average loss: 4.5524,                   Accuracy: 21233/60000 (35.39%)
-= Testing Rotation 300 =-
Test set: Average loss: 3.9895,                   Accuracy: 21985/60000 (36.64%)
-= Testing Rotation 310 =-
Test set: Average loss: 3.2920,                   Accuracy: 24081/60000 (40.13%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.4775,                   Accuracy: 27960/60000 (46.60%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.6239,                   Accuracy: 34978/60000 (58.30%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.8766,                   Accuracy: 44640/60000 (74.40%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3961,                   Accuracy: 52892/60000 (88.15%)
{0: tensor(94.2600), 10: tensor(96.3367), 20: tensor(97.4167), 30: tensor(97.7700), 40: tensor(97.7083), 50: tensor(97.2467), 60: tensor(96.3850), 70: tensor(94.9683), 80: tensor(92.8467), 90: tensor(88.7217), 100: tensor(81.4817), 110: tensor(70.8300), 120: tensor(58.2917), 130: tensor(47.1650), 140: tensor(39.4033), 150: tensor(36.8683), 160: tensor(37.4767), 170: tensor(39.5900), 180: tensor(42.2450), 190: tensor(43.9300), 200: tensor(44.9383), 210: tensor(45.9333), 220: tensor(45.6117), 230: tensor(44.6850), 240: tensor(43.0400), 250: tensor(41.0317), 260: tensor(39.6483), 270: tensor(37.5133), 280: tensor(36.5650), 290: tensor(35.3883), 300: tensor(36.6417), 310: tensor(40.1350), 320: tensor(46.6000), 330: tensor(58.2967), 340: tensor(74.4000), 350: tensor(88.1533)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=20.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=10, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=False, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0322,                   Accuracy: 547/2000.0 (27.35%)



-= Testing valid =-
Test set: Average loss: 2.1025,                   Accuracy: 640/2000.0 (32.00%)



-= Testing valid =-
Test set: Average loss: 1.8208,                   Accuracy: 860/2000.0 (43.00%)



-= Testing valid =-
Test set: Average loss: 0.7277,                   Accuracy: 1494/2000.0 (74.70%)



-= Testing valid =-
Test set: Average loss: 0.7828,                   Accuracy: 1491/2000.0 (74.55%)



-= Testing valid =-
Test set: Average loss: 0.6424,                   Accuracy: 1584/2000.0 (79.20%)



-= Testing valid =-
Test set: Average loss: 0.4879,                   Accuracy: 1680/2000.0 (84.00%)



-= Testing valid =-
Test set: Average loss: 0.6969,                   Accuracy: 1510/2000.0 (75.50%)



-= Testing valid =-
Test set: Average loss: 0.5859,                   Accuracy: 1617/2000.0 (80.85%)



-= Testing valid =-
Test set: Average loss: 0.3854,                   Accuracy: 1758/2000.0 (87.90%)



Epoch 10 train accuracy: 94.36%, valid accuracy 87.90%
-= Testing valid =-
Test set: Average loss: 0.2582,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.3663,                   Accuracy: 1764/2000.0 (88.20%)



-= Testing valid =-
Test set: Average loss: 0.2540,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2491,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.3134,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.2458,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.4173,                   Accuracy: 1728/2000.0 (86.40%)



-= Testing valid =-
Test set: Average loss: 0.2018,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.1909,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1960,                   Accuracy: 1874/2000.0 (93.70%)



Epoch 20 train accuracy: 96.60%, valid accuracy 93.70%
-= Testing valid =-
Test set: Average loss: 0.2080,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.2131,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.2677,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2557,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2051,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1916,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.2355,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.2283,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.1368,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.2561,                   Accuracy: 1845/2000.0 (92.25%)



Epoch 30 train accuracy: 97.31%, valid accuracy 92.25%
-= Testing valid =-
Test set: Average loss: 0.2345,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.2169,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.2314,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2035,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1796,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.2159,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.2025,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.2337,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2555,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2014,                   Accuracy: 1873/2000.0 (93.65%)



Epoch 40 train accuracy: 97.22%, valid accuracy 93.65%
-= Testing valid =-
Test set: Average loss: 0.2084,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.2018,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.2253,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.2030,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1774,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1693,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.2046,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1963,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1778,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1923,                   Accuracy: 1885/2000.0 (94.25%)



Epoch 50 train accuracy: 98.28%, valid accuracy 94.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1682,                   Accuracy: 56918/60000 (94.86%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1098,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0871,                   Accuracy: 58425/60000 (97.38%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0834,                   Accuracy: 58515/60000 (97.53%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0865,                   Accuracy: 58435/60000 (97.39%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1018,                   Accuracy: 58220/60000 (97.03%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1326,                   Accuracy: 57668/60000 (96.11%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1832,                   Accuracy: 56763/60000 (94.61%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2673,                   Accuracy: 55241/60000 (92.07%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4399,                   Accuracy: 52021/60000 (86.70%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.7848,                   Accuracy: 46202/60000 (77.00%)
-= Testing Rotation 110 =-
Test set: Average loss: 1.2344,                   Accuracy: 40111/60000 (66.85%)
-= Testing Rotation 120 =-
Test set: Average loss: 1.7626,                   Accuracy: 34057/60000 (56.76%)
-= Testing Rotation 130 =-
Test set: Average loss: 2.3572,                   Accuracy: 27986/60000 (46.64%)
-= Testing Rotation 140 =-
Test set: Average loss: 2.9544,                   Accuracy: 23678/60000 (39.46%)
-= Testing Rotation 150 =-
Test set: Average loss: 3.4397,                   Accuracy: 22065/60000 (36.78%)
-= Testing Rotation 160 =-
Test set: Average loss: 3.7990,                   Accuracy: 22604/60000 (37.67%)
-= Testing Rotation 170 =-
Test set: Average loss: 4.1585,                   Accuracy: 24223/60000 (40.37%)
-= Testing Rotation 180 =-
Test set: Average loss: 4.7365,                   Accuracy: 25416/60000 (42.36%)
-= Testing Rotation 190 =-
Test set: Average loss: 4.9833,                   Accuracy: 26793/60000 (44.65%)
-= Testing Rotation 200 =-
Test set: Average loss: 5.3985,                   Accuracy: 27120/60000 (45.20%)
-= Testing Rotation 210 =-
Test set: Average loss: 5.6323,                   Accuracy: 27230/60000 (45.38%)
-= Testing Rotation 220 =-
Test set: Average loss: 5.7221,                   Accuracy: 26901/60000 (44.83%)
-= Testing Rotation 230 =-
Test set: Average loss: 5.7548,                   Accuracy: 25985/60000 (43.31%)
-= Testing Rotation 240 =-
Test set: Average loss: 5.6827,                   Accuracy: 24953/60000 (41.59%)
-= Testing Rotation 250 =-
Test set: Average loss: 5.6105,                   Accuracy: 24095/60000 (40.16%)
-= Testing Rotation 260 =-
Test set: Average loss: 5.2340,                   Accuracy: 23808/60000 (39.68%)
-= Testing Rotation 270 =-
Test set: Average loss: 5.1485,                   Accuracy: 22724/60000 (37.87%)
-= Testing Rotation 280 =-
Test set: Average loss: 4.6329,                   Accuracy: 22290/60000 (37.15%)
-= Testing Rotation 290 =-
Test set: Average loss: 4.1697,                   Accuracy: 22495/60000 (37.49%)
-= Testing Rotation 300 =-
Test set: Average loss: 3.6040,                   Accuracy: 23917/60000 (39.86%)
-= Testing Rotation 310 =-
Test set: Average loss: 2.9209,                   Accuracy: 26439/60000 (44.06%)
-= Testing Rotation 320 =-
Test set: Average loss: 2.1005,                   Accuracy: 31525/60000 (52.54%)
-= Testing Rotation 330 =-
Test set: Average loss: 1.3139,                   Accuracy: 39152/60000 (65.25%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.6661,                   Accuracy: 48266/60000 (80.44%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3168,                   Accuracy: 54284/60000 (90.47%)
{0: tensor(94.8633), 10: tensor(96.6667), 20: tensor(97.3750), 30: tensor(97.5250), 40: tensor(97.3917), 50: tensor(97.0333), 60: tensor(96.1133), 70: tensor(94.6050), 80: tensor(92.0683), 90: tensor(86.7017), 100: tensor(77.0033), 110: tensor(66.8517), 120: tensor(56.7617), 130: tensor(46.6433), 140: tensor(39.4633), 150: tensor(36.7750), 160: tensor(37.6733), 170: tensor(40.3717), 180: tensor(42.3600), 190: tensor(44.6550), 200: tensor(45.2000), 210: tensor(45.3833), 220: tensor(44.8350), 230: tensor(43.3083), 240: tensor(41.5883), 250: tensor(40.1583), 260: tensor(39.6800), 270: tensor(37.8733), 280: tensor(37.1500), 290: tensor(37.4917), 300: tensor(39.8617), 310: tensor(44.0650), 320: tensor(52.5417), 330: tensor(65.2533), 340: tensor(80.4433), 350: tensor(90.4733)}
