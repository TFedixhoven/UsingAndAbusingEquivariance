Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=71, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8627,                   Accuracy: 641/2000.0 (32.05%)



-= Testing valid =-
Test set: Average loss: 1.4300,                   Accuracy: 1004/2000.0 (50.20%)



-= Testing valid =-
Test set: Average loss: 1.7339,                   Accuracy: 764/2000.0 (38.20%)



-= Testing valid =-
Test set: Average loss: 1.1580,                   Accuracy: 1263/2000.0 (63.15%)



-= Testing valid =-
Test set: Average loss: 0.8331,                   Accuracy: 1439/2000.0 (71.95%)



-= Testing valid =-
Test set: Average loss: 0.5208,                   Accuracy: 1633/2000.0 (81.65%)



-= Testing valid =-
Test set: Average loss: 0.6622,                   Accuracy: 1565/2000.0 (78.25%)



-= Testing valid =-
Test set: Average loss: 0.3099,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.2444,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2856,                   Accuracy: 1820/2000.0 (91.00%)



Epoch 10 train accuracy: 93.49%, valid accuracy 91.00%
-= Testing valid =-
Test set: Average loss: 0.1904,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2323,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.1629,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1993,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.2028,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.2014,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1405,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1680,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1601,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.2376,                   Accuracy: 1854/2000.0 (92.70%)



Epoch 20 train accuracy: 95.90%, valid accuracy 92.70%
-= Testing valid =-
Test set: Average loss: 0.1243,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1455,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1357,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1289,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1268,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1213,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1236,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1467,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1169,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1609,                   Accuracy: 1912/2000.0 (95.60%)



Epoch 30 train accuracy: 96.90%, valid accuracy 95.60%
-= Testing valid =-
Test set: Average loss: 0.1165,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1241,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1309,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1307,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1130,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1206,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1139,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 40 train accuracy: 97.21%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.0978,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1050,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1053,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1112,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1021,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1082,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 50 train accuracy: 97.35%, valid accuracy 96.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1182,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1212,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1175,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1177,                   Accuracy: 57954/60000 (96.59%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1154,                   Accuracy: 58029/60000 (96.71%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1154,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1169,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1175,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1184,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1182,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1212,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1175,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1177,                   Accuracy: 57954/60000 (96.59%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1154,                   Accuracy: 58029/60000 (96.71%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1154,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1169,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1175,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1184,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1182,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1212,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1175,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1177,                   Accuracy: 57954/60000 (96.59%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1154,                   Accuracy: 58029/60000 (96.71%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1154,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1169,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1175,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1184,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1182,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1212,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1175,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1177,                   Accuracy: 57954/60000 (96.59%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1154,                   Accuracy: 58029/60000 (96.71%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1154,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1169,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1175,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1184,                   Accuracy: 57937/60000 (96.56%)
{0: tensor(96.6817), 10: tensor(96.5067), 20: tensor(96.6117), 30: tensor(96.5900), 40: tensor(96.7150), 50: tensor(96.6217), 60: tensor(96.6183), 70: tensor(96.5450), 80: tensor(96.5617), 90: tensor(96.6817), 100: tensor(96.5067), 110: tensor(96.6117), 120: tensor(96.5900), 130: tensor(96.7150), 140: tensor(96.6217), 150: tensor(96.6183), 160: tensor(96.5450), 170: tensor(96.5617), 180: tensor(96.6817), 190: tensor(96.5067), 200: tensor(96.6117), 210: tensor(96.5900), 220: tensor(96.7150), 230: tensor(96.6217), 240: tensor(96.6183), 250: tensor(96.5450), 260: tensor(96.5617), 270: tensor(96.6817), 280: tensor(96.5067), 290: tensor(96.6117), 300: tensor(96.5900), 310: tensor(96.7150), 320: tensor(96.6217), 330: tensor(96.6183), 340: tensor(96.5450), 350: tensor(96.5617)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=72, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9696,                   Accuracy: 463/2000.0 (23.15%)



-= Testing valid =-
Test set: Average loss: 2.0463,                   Accuracy: 488/2000.0 (24.40%)



-= Testing valid =-
Test set: Average loss: 0.8872,                   Accuracy: 1300/2000.0 (65.00%)



-= Testing valid =-
Test set: Average loss: 0.6912,                   Accuracy: 1501/2000.0 (75.05%)



-= Testing valid =-
Test set: Average loss: 0.4090,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.3684,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.3241,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.2737,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2279,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.1763,                   Accuracy: 1892/2000.0 (94.60%)



Epoch 10 train accuracy: 93.18%, valid accuracy 94.60%
-= Testing valid =-
Test set: Average loss: 0.1395,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1414,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1528,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1264,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1227,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1345,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1476,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1561,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1301,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1347,                   Accuracy: 1914/2000.0 (95.70%)



Epoch 20 train accuracy: 95.29%, valid accuracy 95.70%
-= Testing valid =-
Test set: Average loss: 0.0947,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 30 train accuracy: 96.28%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0755,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 40 train accuracy: 96.96%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 50 train accuracy: 96.84%, valid accuracy 97.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1103,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1187,                   Accuracy: 57845/60000 (96.41%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1105,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1164,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1190,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1209,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1218,                   Accuracy: 57838/60000 (96.40%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1180,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1144,                   Accuracy: 57939/60000 (96.57%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1103,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1187,                   Accuracy: 57845/60000 (96.41%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1105,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1164,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1190,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1209,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1218,                   Accuracy: 57838/60000 (96.40%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1180,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1144,                   Accuracy: 57939/60000 (96.57%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1103,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1187,                   Accuracy: 57845/60000 (96.41%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1105,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1164,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1190,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1209,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1218,                   Accuracy: 57838/60000 (96.40%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1180,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1144,                   Accuracy: 57939/60000 (96.57%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1103,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1187,                   Accuracy: 57845/60000 (96.41%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1105,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1164,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1190,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1209,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1218,                   Accuracy: 57838/60000 (96.40%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1180,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1144,                   Accuracy: 57939/60000 (96.57%)
{0: tensor(96.7317), 10: tensor(96.4083), 20: tensor(96.7333), 30: tensor(96.5483), 40: tensor(96.4617), 50: tensor(96.4167), 60: tensor(96.3967), 70: tensor(96.5317), 80: tensor(96.5650), 90: tensor(96.7317), 100: tensor(96.4083), 110: tensor(96.7333), 120: tensor(96.5483), 130: tensor(96.4617), 140: tensor(96.4167), 150: tensor(96.3967), 160: tensor(96.5317), 170: tensor(96.5650), 180: tensor(96.7317), 190: tensor(96.4083), 200: tensor(96.7333), 210: tensor(96.5483), 220: tensor(96.4617), 230: tensor(96.4167), 240: tensor(96.3967), 250: tensor(96.5317), 260: tensor(96.5650), 270: tensor(96.7317), 280: tensor(96.4083), 290: tensor(96.7333), 300: tensor(96.5483), 310: tensor(96.4617), 320: tensor(96.4167), 330: tensor(96.3967), 340: tensor(96.5317), 350: tensor(96.5650)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=73, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7532,                   Accuracy: 714/2000.0 (35.70%)



-= Testing valid =-
Test set: Average loss: 1.4456,                   Accuracy: 918/2000.0 (45.90%)



-= Testing valid =-
Test set: Average loss: 0.9681,                   Accuracy: 1312/2000.0 (65.60%)



-= Testing valid =-
Test set: Average loss: 1.3784,                   Accuracy: 947/2000.0 (47.35%)



-= Testing valid =-
Test set: Average loss: 0.4155,                   Accuracy: 1728/2000.0 (86.40%)



-= Testing valid =-
Test set: Average loss: 0.3733,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.3195,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2972,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.1843,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1574,                   Accuracy: 1905/2000.0 (95.25%)



Epoch 10 train accuracy: 93.65%, valid accuracy 95.25%
-= Testing valid =-
Test set: Average loss: 0.1754,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1345,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1543,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1422,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1164,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 20 train accuracy: 95.89%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1166,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 30 train accuracy: 96.88%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0719,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0798,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 40 train accuracy: 96.85%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0746,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 50 train accuracy: 97.21%, valid accuracy 97.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1027,                   Accuracy: 58243/60000 (97.07%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1151,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1136,                   Accuracy: 58049/60000 (96.75%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1181,                   Accuracy: 57928/60000 (96.55%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1204,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1190,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1135,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1088,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1067,                   Accuracy: 58156/60000 (96.93%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1027,                   Accuracy: 58243/60000 (97.07%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1151,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1136,                   Accuracy: 58049/60000 (96.75%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1181,                   Accuracy: 57928/60000 (96.55%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1204,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1190,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1135,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1088,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1067,                   Accuracy: 58156/60000 (96.93%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1027,                   Accuracy: 58243/60000 (97.07%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1151,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1136,                   Accuracy: 58049/60000 (96.75%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1181,                   Accuracy: 57928/60000 (96.55%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1204,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1190,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1135,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1088,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1067,                   Accuracy: 58156/60000 (96.93%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1027,                   Accuracy: 58243/60000 (97.07%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1151,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1136,                   Accuracy: 58049/60000 (96.75%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1181,                   Accuracy: 57928/60000 (96.55%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1204,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1190,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1135,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1088,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1067,                   Accuracy: 58156/60000 (96.93%)
{0: tensor(97.0717), 10: tensor(96.6200), 20: tensor(96.7483), 30: tensor(96.5467), 40: tensor(96.4583), 50: tensor(96.5183), 60: tensor(96.6967), 70: tensor(96.8667), 80: tensor(96.9267), 90: tensor(97.0717), 100: tensor(96.6200), 110: tensor(96.7483), 120: tensor(96.5467), 130: tensor(96.4583), 140: tensor(96.5183), 150: tensor(96.6967), 160: tensor(96.8667), 170: tensor(96.9267), 180: tensor(97.0717), 190: tensor(96.6200), 200: tensor(96.7483), 210: tensor(96.5467), 220: tensor(96.4583), 230: tensor(96.5183), 240: tensor(96.6967), 250: tensor(96.8667), 260: tensor(96.9267), 270: tensor(97.0717), 280: tensor(96.6200), 290: tensor(96.7483), 300: tensor(96.5467), 310: tensor(96.4583), 320: tensor(96.5183), 330: tensor(96.6967), 340: tensor(96.8667), 350: tensor(96.9267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=74, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6404,                   Accuracy: 461/2000.0 (23.05%)



-= Testing valid =-
Test set: Average loss: 1.2570,                   Accuracy: 1104/2000.0 (55.20%)



-= Testing valid =-
Test set: Average loss: 1.1248,                   Accuracy: 1242/2000.0 (62.10%)



-= Testing valid =-
Test set: Average loss: 0.4919,                   Accuracy: 1671/2000.0 (83.55%)



-= Testing valid =-
Test set: Average loss: 0.3147,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.3190,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.2411,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2174,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2237,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.2586,                   Accuracy: 1838/2000.0 (91.90%)



Epoch 10 train accuracy: 93.59%, valid accuracy 91.90%
-= Testing valid =-
Test set: Average loss: 0.2040,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.1434,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1302,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1310,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1521,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1162,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1241,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1335,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1318,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1563,                   Accuracy: 1897/2000.0 (94.85%)



Epoch 20 train accuracy: 95.89%, valid accuracy 94.85%
-= Testing valid =-
Test set: Average loss: 0.1113,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1066,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1109,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 30 train accuracy: 96.64%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 40 train accuracy: 96.88%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 50 train accuracy: 96.80%, valid accuracy 97.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1069,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1222,                   Accuracy: 57769/60000 (96.28%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1110,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1101,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1103,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1111,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1101,                   Accuracy: 58076/60000 (96.79%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1132,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1159,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1069,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1222,                   Accuracy: 57769/60000 (96.28%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1110,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1101,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1103,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1111,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1101,                   Accuracy: 58076/60000 (96.79%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1132,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1159,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1069,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1222,                   Accuracy: 57769/60000 (96.28%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1110,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1101,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1103,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1111,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1101,                   Accuracy: 58076/60000 (96.79%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1132,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1159,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1069,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1222,                   Accuracy: 57769/60000 (96.28%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1110,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1101,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1103,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1111,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1101,                   Accuracy: 58076/60000 (96.79%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1132,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1159,                   Accuracy: 57885/60000 (96.47%)
{0: tensor(96.7800), 10: tensor(96.2817), 20: tensor(96.6933), 30: tensor(96.6800), 40: tensor(96.6683), 50: tensor(96.6750), 60: tensor(96.7933), 70: tensor(96.6200), 80: tensor(96.4750), 90: tensor(96.7800), 100: tensor(96.2817), 110: tensor(96.6933), 120: tensor(96.6800), 130: tensor(96.6683), 140: tensor(96.6750), 150: tensor(96.7933), 160: tensor(96.6200), 170: tensor(96.4750), 180: tensor(96.7800), 190: tensor(96.2817), 200: tensor(96.6933), 210: tensor(96.6800), 220: tensor(96.6683), 230: tensor(96.6750), 240: tensor(96.7933), 250: tensor(96.6200), 260: tensor(96.4750), 270: tensor(96.7800), 280: tensor(96.2817), 290: tensor(96.6933), 300: tensor(96.6800), 310: tensor(96.6683), 320: tensor(96.6750), 330: tensor(96.7933), 340: tensor(96.6200), 350: tensor(96.4750)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=75, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 8.0100,                   Accuracy: 215/2000.0 (10.75%)



-= Testing valid =-
Test set: Average loss: 4.2722,                   Accuracy: 293/2000.0 (14.65%)



-= Testing valid =-
Test set: Average loss: 2.0720,                   Accuracy: 699/2000.0 (34.95%)



-= Testing valid =-
Test set: Average loss: 3.1379,                   Accuracy: 657/2000.0 (32.85%)



-= Testing valid =-
Test set: Average loss: 0.6171,                   Accuracy: 1590/2000.0 (79.50%)



-= Testing valid =-
Test set: Average loss: 0.3019,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.3062,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.9123,                   Accuracy: 1319/2000.0 (65.95%)



-= Testing valid =-
Test set: Average loss: 0.1941,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.2175,                   Accuracy: 1871/2000.0 (93.55%)



Epoch 10 train accuracy: 93.40%, valid accuracy 93.55%
-= Testing valid =-
Test set: Average loss: 0.1129,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1479,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1551,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1365,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1170,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1683,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1061,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1020,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 20 train accuracy: 95.66%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.1097,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1046,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 30 train accuracy: 96.55%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0721,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0742,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 40 train accuracy: 97.00%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0686,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0678,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 50 train accuracy: 97.15%, valid accuracy 97.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0944,                   Accuracy: 58291/60000 (97.15%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0987,                   Accuracy: 58214/60000 (97.02%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0938,                   Accuracy: 58284/60000 (97.14%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0954,                   Accuracy: 58278/60000 (97.13%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1009,                   Accuracy: 58183/60000 (96.97%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1054,                   Accuracy: 58079/60000 (96.80%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1044,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1049,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1031,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0944,                   Accuracy: 58291/60000 (97.15%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.0987,                   Accuracy: 58214/60000 (97.02%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.0938,                   Accuracy: 58284/60000 (97.14%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.0954,                   Accuracy: 58278/60000 (97.13%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1009,                   Accuracy: 58183/60000 (96.97%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1054,                   Accuracy: 58079/60000 (96.80%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1044,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1049,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1031,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0944,                   Accuracy: 58291/60000 (97.15%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.0987,                   Accuracy: 58214/60000 (97.02%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.0938,                   Accuracy: 58284/60000 (97.14%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.0954,                   Accuracy: 58278/60000 (97.13%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1009,                   Accuracy: 58183/60000 (96.97%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1054,                   Accuracy: 58079/60000 (96.80%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1044,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1049,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1031,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0944,                   Accuracy: 58291/60000 (97.15%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.0987,                   Accuracy: 58214/60000 (97.02%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0938,                   Accuracy: 58284/60000 (97.14%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.0954,                   Accuracy: 58278/60000 (97.13%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1009,                   Accuracy: 58183/60000 (96.97%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1054,                   Accuracy: 58079/60000 (96.80%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1044,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1049,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1031,                   Accuracy: 58114/60000 (96.86%)
{0: tensor(97.1517), 10: tensor(97.0233), 20: tensor(97.1400), 30: tensor(97.1300), 40: tensor(96.9717), 50: tensor(96.7983), 60: tensor(96.8800), 70: tensor(96.8767), 80: tensor(96.8567), 90: tensor(97.1517), 100: tensor(97.0233), 110: tensor(97.1400), 120: tensor(97.1300), 130: tensor(96.9717), 140: tensor(96.7983), 150: tensor(96.8800), 160: tensor(96.8767), 170: tensor(96.8567), 180: tensor(97.1517), 190: tensor(97.0233), 200: tensor(97.1400), 210: tensor(97.1300), 220: tensor(96.9717), 230: tensor(96.7983), 240: tensor(96.8800), 250: tensor(96.8767), 260: tensor(96.8567), 270: tensor(97.1517), 280: tensor(97.0233), 290: tensor(97.1400), 300: tensor(97.1300), 310: tensor(96.9717), 320: tensor(96.7983), 330: tensor(96.8800), 340: tensor(96.8767), 350: tensor(96.8567)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=76, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0311,                   Accuracy: 481/2000.0 (24.05%)



-= Testing valid =-
Test set: Average loss: 1.9456,                   Accuracy: 627/2000.0 (31.35%)



-= Testing valid =-
Test set: Average loss: 2.3458,                   Accuracy: 529/2000.0 (26.45%)



-= Testing valid =-
Test set: Average loss: 4.5080,                   Accuracy: 272/2000.0 (13.60%)



-= Testing valid =-
Test set: Average loss: 0.4072,                   Accuracy: 1735/2000.0 (86.75%)



-= Testing valid =-
Test set: Average loss: 0.3146,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.2595,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2794,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2851,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.1820,                   Accuracy: 1870/2000.0 (93.50%)



Epoch 10 train accuracy: 93.41%, valid accuracy 93.50%
-= Testing valid =-
Test set: Average loss: 0.1547,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1337,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1377,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1354,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1363,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1518,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1220,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1509,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1098,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 20 train accuracy: 95.81%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 30 train accuracy: 96.78%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0790,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 40 train accuracy: 97.05%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 50 train accuracy: 97.29%, valid accuracy 97.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1026,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1076,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1007,                   Accuracy: 58219/60000 (97.03%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1014,                   Accuracy: 58220/60000 (97.03%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1031,                   Accuracy: 58163/60000 (96.94%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1065,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1079,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1039,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1043,                   Accuracy: 58106/60000 (96.84%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1026,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1076,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1007,                   Accuracy: 58219/60000 (97.03%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1014,                   Accuracy: 58220/60000 (97.03%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1031,                   Accuracy: 58163/60000 (96.94%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1065,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1079,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1039,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1043,                   Accuracy: 58106/60000 (96.84%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1026,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1076,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1007,                   Accuracy: 58219/60000 (97.03%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1014,                   Accuracy: 58220/60000 (97.03%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1031,                   Accuracy: 58163/60000 (96.94%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1065,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1079,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1039,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1043,                   Accuracy: 58106/60000 (96.84%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1026,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1076,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1007,                   Accuracy: 58219/60000 (97.03%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1014,                   Accuracy: 58220/60000 (97.03%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1031,                   Accuracy: 58163/60000 (96.94%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1065,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1079,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1039,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1043,                   Accuracy: 58106/60000 (96.84%)
{0: tensor(96.9217), 10: tensor(96.7433), 20: tensor(97.0317), 30: tensor(97.0333), 40: tensor(96.9383), 50: tensor(96.8717), 60: tensor(96.7750), 70: tensor(96.8133), 80: tensor(96.8433), 90: tensor(96.9217), 100: tensor(96.7433), 110: tensor(97.0317), 120: tensor(97.0333), 130: tensor(96.9383), 140: tensor(96.8717), 150: tensor(96.7750), 160: tensor(96.8133), 170: tensor(96.8433), 180: tensor(96.9217), 190: tensor(96.7433), 200: tensor(97.0317), 210: tensor(97.0333), 220: tensor(96.9383), 230: tensor(96.8717), 240: tensor(96.7750), 250: tensor(96.8133), 260: tensor(96.8433), 270: tensor(96.9217), 280: tensor(96.7433), 290: tensor(97.0317), 300: tensor(97.0333), 310: tensor(96.9383), 320: tensor(96.8717), 330: tensor(96.7750), 340: tensor(96.8133), 350: tensor(96.8433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=77, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1196,                   Accuracy: 565/2000.0 (28.25%)



-= Testing valid =-
Test set: Average loss: 1.9362,                   Accuracy: 722/2000.0 (36.10%)



-= Testing valid =-
Test set: Average loss: 0.9261,                   Accuracy: 1374/2000.0 (68.70%)



-= Testing valid =-
Test set: Average loss: 1.1205,                   Accuracy: 1332/2000.0 (66.60%)



-= Testing valid =-
Test set: Average loss: 0.4561,                   Accuracy: 1707/2000.0 (85.35%)



-= Testing valid =-
Test set: Average loss: 0.5996,                   Accuracy: 1527/2000.0 (76.35%)



-= Testing valid =-
Test set: Average loss: 0.3822,                   Accuracy: 1777/2000.0 (88.85%)



-= Testing valid =-
Test set: Average loss: 0.4592,                   Accuracy: 1714/2000.0 (85.70%)



-= Testing valid =-
Test set: Average loss: 0.3090,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2375,                   Accuracy: 1856/2000.0 (92.80%)



Epoch 10 train accuracy: 93.22%, valid accuracy 92.80%
-= Testing valid =-
Test set: Average loss: 0.1764,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.3138,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.1670,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1513,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1399,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1522,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1409,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1880,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1459,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1355,                   Accuracy: 1920/2000.0 (96.00%)



Epoch 20 train accuracy: 95.81%, valid accuracy 96.00%
-= Testing valid =-
Test set: Average loss: 0.1225,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1277,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1236,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1219,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1137,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1114,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1135,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1088,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1147,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 30 train accuracy: 96.76%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1086,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1012,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1082,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 40 train accuracy: 97.16%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 50 train accuracy: 97.25%, valid accuracy 97.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1182,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1258,                   Accuracy: 57751/60000 (96.25%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1204,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1255,                   Accuracy: 57739/60000 (96.23%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1233,                   Accuracy: 57812/60000 (96.35%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1237,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1233,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1210,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1186,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1182,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1258,                   Accuracy: 57751/60000 (96.25%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1204,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1255,                   Accuracy: 57739/60000 (96.23%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1233,                   Accuracy: 57812/60000 (96.35%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1237,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1233,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1210,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1186,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1182,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1258,                   Accuracy: 57751/60000 (96.25%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1204,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1255,                   Accuracy: 57739/60000 (96.23%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1233,                   Accuracy: 57812/60000 (96.35%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1237,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1233,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1210,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1186,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1182,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1258,                   Accuracy: 57751/60000 (96.25%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1204,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1255,                   Accuracy: 57739/60000 (96.23%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1233,                   Accuracy: 57812/60000 (96.35%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1237,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1233,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1210,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1186,                   Accuracy: 57951/60000 (96.58%)
{0: tensor(96.6450), 10: tensor(96.2517), 20: tensor(96.4583), 30: tensor(96.2317), 40: tensor(96.3533), 50: tensor(96.4533), 60: tensor(96.4617), 70: tensor(96.5533), 80: tensor(96.5850), 90: tensor(96.6450), 100: tensor(96.2517), 110: tensor(96.4583), 120: tensor(96.2317), 130: tensor(96.3533), 140: tensor(96.4533), 150: tensor(96.4617), 160: tensor(96.5533), 170: tensor(96.5850), 180: tensor(96.6450), 190: tensor(96.2517), 200: tensor(96.4583), 210: tensor(96.2317), 220: tensor(96.3533), 230: tensor(96.4533), 240: tensor(96.4617), 250: tensor(96.5533), 260: tensor(96.5850), 270: tensor(96.6450), 280: tensor(96.2517), 290: tensor(96.4583), 300: tensor(96.2317), 310: tensor(96.3533), 320: tensor(96.4533), 330: tensor(96.4617), 340: tensor(96.5533), 350: tensor(96.5850)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=78, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.8441,                   Accuracy: 225/2000.0 (11.25%)



-= Testing valid =-
Test set: Average loss: 1.7607,                   Accuracy: 694/2000.0 (34.70%)



-= Testing valid =-
Test set: Average loss: 1.3580,                   Accuracy: 1122/2000.0 (56.10%)



-= Testing valid =-
Test set: Average loss: 0.5627,                   Accuracy: 1678/2000.0 (83.90%)



-= Testing valid =-
Test set: Average loss: 0.4593,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.3515,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2162,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.4279,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.2350,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.2006,                   Accuracy: 1884/2000.0 (94.20%)



Epoch 10 train accuracy: 94.32%, valid accuracy 94.20%
-= Testing valid =-
Test set: Average loss: 0.1449,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1469,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1581,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1975,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1376,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1448,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1310,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1350,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1490,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 20 train accuracy: 96.32%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.1085,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1106,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1121,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1207,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1010,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1030,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1021,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 30 train accuracy: 97.06%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 40 train accuracy: 97.51%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0909,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0926,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 50 train accuracy: 97.59%, valid accuracy 97.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1007,                   Accuracy: 58281/60000 (97.14%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1047,                   Accuracy: 58187/60000 (96.98%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1063,                   Accuracy: 58098/60000 (96.83%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1089,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1107,                   Accuracy: 58066/60000 (96.78%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1137,                   Accuracy: 58029/60000 (96.71%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1122,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1093,                   Accuracy: 58149/60000 (96.92%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1004,                   Accuracy: 58273/60000 (97.12%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1007,                   Accuracy: 58281/60000 (97.14%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1047,                   Accuracy: 58187/60000 (96.98%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1063,                   Accuracy: 58098/60000 (96.83%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1089,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1107,                   Accuracy: 58066/60000 (96.78%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1137,                   Accuracy: 58029/60000 (96.71%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1122,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1093,                   Accuracy: 58149/60000 (96.92%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1004,                   Accuracy: 58273/60000 (97.12%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1007,                   Accuracy: 58281/60000 (97.14%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1047,                   Accuracy: 58187/60000 (96.98%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1063,                   Accuracy: 58098/60000 (96.83%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1089,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1107,                   Accuracy: 58066/60000 (96.78%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1137,                   Accuracy: 58029/60000 (96.71%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1122,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1093,                   Accuracy: 58149/60000 (96.92%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1004,                   Accuracy: 58273/60000 (97.12%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1007,                   Accuracy: 58281/60000 (97.14%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1047,                   Accuracy: 58187/60000 (96.98%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1063,                   Accuracy: 58098/60000 (96.83%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1089,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1107,                   Accuracy: 58066/60000 (96.78%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1137,                   Accuracy: 58029/60000 (96.71%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1122,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1093,                   Accuracy: 58149/60000 (96.92%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1004,                   Accuracy: 58273/60000 (97.12%)
{0: tensor(97.1350), 10: tensor(96.9783), 20: tensor(96.8300), 30: tensor(96.8167), 40: tensor(96.7767), 50: tensor(96.7150), 60: tensor(96.7633), 70: tensor(96.9150), 80: tensor(97.1217), 90: tensor(97.1350), 100: tensor(96.9783), 110: tensor(96.8300), 120: tensor(96.8167), 130: tensor(96.7767), 140: tensor(96.7150), 150: tensor(96.7633), 160: tensor(96.9150), 170: tensor(97.1217), 180: tensor(97.1350), 190: tensor(96.9783), 200: tensor(96.8300), 210: tensor(96.8167), 220: tensor(96.7767), 230: tensor(96.7150), 240: tensor(96.7633), 250: tensor(96.9150), 260: tensor(97.1217), 270: tensor(97.1350), 280: tensor(96.9783), 290: tensor(96.8300), 300: tensor(96.8167), 310: tensor(96.7767), 320: tensor(96.7150), 330: tensor(96.7633), 340: tensor(96.9150), 350: tensor(97.1217)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=79, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8588,                   Accuracy: 751/2000.0 (37.55%)



-= Testing valid =-
Test set: Average loss: 1.6827,                   Accuracy: 815/2000.0 (40.75%)



-= Testing valid =-
Test set: Average loss: 1.3016,                   Accuracy: 1008/2000.0 (50.40%)



-= Testing valid =-
Test set: Average loss: 0.9098,                   Accuracy: 1451/2000.0 (72.55%)



-= Testing valid =-
Test set: Average loss: 0.3266,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.3220,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.3708,                   Accuracy: 1753/2000.0 (87.65%)



-= Testing valid =-
Test set: Average loss: 0.1836,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1602,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.2540,                   Accuracy: 1845/2000.0 (92.25%)



Epoch 10 train accuracy: 93.59%, valid accuracy 92.25%
-= Testing valid =-
Test set: Average loss: 0.1923,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.1362,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1166,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1239,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1124,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1135,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1200,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1123,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 20 train accuracy: 96.00%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1020,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1011,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0986,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 30 train accuracy: 96.76%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 40 train accuracy: 96.86%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0743,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0721,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 50 train accuracy: 97.40%, valid accuracy 97.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0937,                   Accuracy: 58284/60000 (97.14%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1012,                   Accuracy: 58137/60000 (96.89%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0988,                   Accuracy: 58207/60000 (97.01%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1023,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1056,                   Accuracy: 58117/60000 (96.86%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1068,                   Accuracy: 58095/60000 (96.82%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1043,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0995,                   Accuracy: 58231/60000 (97.05%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.0957,                   Accuracy: 58256/60000 (97.09%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0937,                   Accuracy: 58284/60000 (97.14%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1012,                   Accuracy: 58137/60000 (96.89%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.0988,                   Accuracy: 58207/60000 (97.01%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1023,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1056,                   Accuracy: 58117/60000 (96.86%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1068,                   Accuracy: 58095/60000 (96.82%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1043,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.0995,                   Accuracy: 58231/60000 (97.05%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.0957,                   Accuracy: 58256/60000 (97.09%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0937,                   Accuracy: 58284/60000 (97.14%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1012,                   Accuracy: 58137/60000 (96.89%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.0988,                   Accuracy: 58207/60000 (97.01%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1023,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1056,                   Accuracy: 58117/60000 (96.86%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1068,                   Accuracy: 58095/60000 (96.82%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1043,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.0995,                   Accuracy: 58231/60000 (97.05%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.0957,                   Accuracy: 58256/60000 (97.09%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0937,                   Accuracy: 58284/60000 (97.14%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1012,                   Accuracy: 58137/60000 (96.89%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0988,                   Accuracy: 58207/60000 (97.01%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1023,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1056,                   Accuracy: 58117/60000 (96.86%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1068,                   Accuracy: 58095/60000 (96.82%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1043,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0995,                   Accuracy: 58231/60000 (97.05%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0957,                   Accuracy: 58256/60000 (97.09%)
{0: tensor(97.1400), 10: tensor(96.8950), 20: tensor(97.0117), 30: tensor(96.8683), 40: tensor(96.8617), 50: tensor(96.8250), 60: tensor(96.8533), 70: tensor(97.0517), 80: tensor(97.0933), 90: tensor(97.1400), 100: tensor(96.8950), 110: tensor(97.0117), 120: tensor(96.8683), 130: tensor(96.8617), 140: tensor(96.8250), 150: tensor(96.8533), 160: tensor(97.0517), 170: tensor(97.0933), 180: tensor(97.1400), 190: tensor(96.8950), 200: tensor(97.0117), 210: tensor(96.8683), 220: tensor(96.8617), 230: tensor(96.8250), 240: tensor(96.8533), 250: tensor(97.0517), 260: tensor(97.0933), 270: tensor(97.1400), 280: tensor(96.8950), 290: tensor(97.0117), 300: tensor(96.8683), 310: tensor(96.8617), 320: tensor(96.8250), 330: tensor(96.8533), 340: tensor(97.0517), 350: tensor(97.0933)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=80, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2076,                   Accuracy: 551/2000.0 (27.55%)



-= Testing valid =-
Test set: Average loss: 1.4894,                   Accuracy: 885/2000.0 (44.25%)



-= Testing valid =-
Test set: Average loss: 1.0274,                   Accuracy: 1251/2000.0 (62.55%)



-= Testing valid =-
Test set: Average loss: 0.3982,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.3380,                   Accuracy: 1777/2000.0 (88.85%)



-= Testing valid =-
Test set: Average loss: 0.2844,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.3164,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.8081,                   Accuracy: 1469/2000.0 (73.45%)



-= Testing valid =-
Test set: Average loss: 0.2613,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.1499,                   Accuracy: 1895/2000.0 (94.75%)



Epoch 10 train accuracy: 93.60%, valid accuracy 94.75%
-= Testing valid =-
Test set: Average loss: 0.2408,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.1479,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1575,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1848,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1451,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1829,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1052,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1269,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1544,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1197,                   Accuracy: 1922/2000.0 (96.10%)



Epoch 20 train accuracy: 95.95%, valid accuracy 96.10%
-= Testing valid =-
Test set: Average loss: 0.1241,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1173,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1398,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1178,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0976,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1178,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1172,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 30 train accuracy: 96.80%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0976,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1137,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 40 train accuracy: 97.12%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 50 train accuracy: 97.44%, valid accuracy 97.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1108,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1097,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1094,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1113,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1129,                   Accuracy: 58029/60000 (96.71%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1153,                   Accuracy: 57979/60000 (96.63%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1149,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1131,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1108,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1108,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1097,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1094,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1113,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1129,                   Accuracy: 58029/60000 (96.71%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1153,                   Accuracy: 57979/60000 (96.63%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1149,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1131,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1108,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1108,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1097,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1094,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1113,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1129,                   Accuracy: 58029/60000 (96.71%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1153,                   Accuracy: 57979/60000 (96.63%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1149,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1131,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1108,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1108,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1097,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1094,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1113,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1129,                   Accuracy: 58029/60000 (96.71%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1153,                   Accuracy: 57979/60000 (96.63%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1149,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1131,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1108,                   Accuracy: 58048/60000 (96.75%)
{0: tensor(96.7650), 10: tensor(96.6967), 20: tensor(96.6917), 30: tensor(96.6800), 40: tensor(96.7150), 50: tensor(96.6317), 60: tensor(96.7067), 70: tensor(96.7117), 80: tensor(96.7467), 90: tensor(96.7650), 100: tensor(96.6967), 110: tensor(96.6917), 120: tensor(96.6800), 130: tensor(96.7150), 140: tensor(96.6317), 150: tensor(96.7067), 160: tensor(96.7117), 170: tensor(96.7467), 180: tensor(96.7650), 190: tensor(96.6967), 200: tensor(96.6917), 210: tensor(96.6800), 220: tensor(96.7150), 230: tensor(96.6317), 240: tensor(96.7067), 250: tensor(96.7117), 260: tensor(96.7467), 270: tensor(96.7650), 280: tensor(96.6967), 290: tensor(96.6917), 300: tensor(96.6800), 310: tensor(96.7150), 320: tensor(96.6317), 330: tensor(96.7067), 340: tensor(96.7117), 350: tensor(96.7467)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=81, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.1506,                   Accuracy: 224/2000.0 (11.20%)



-= Testing valid =-
Test set: Average loss: 2.0851,                   Accuracy: 518/2000.0 (25.90%)



-= Testing valid =-
Test set: Average loss: 2.0223,                   Accuracy: 688/2000.0 (34.40%)



-= Testing valid =-
Test set: Average loss: 1.1872,                   Accuracy: 1186/2000.0 (59.30%)



-= Testing valid =-
Test set: Average loss: 0.6939,                   Accuracy: 1547/2000.0 (77.35%)



-= Testing valid =-
Test set: Average loss: 0.3024,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.9562,                   Accuracy: 1419/2000.0 (70.95%)



-= Testing valid =-
Test set: Average loss: 0.2771,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.2343,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.2419,                   Accuracy: 1841/2000.0 (92.05%)



Epoch 10 train accuracy: 94.04%, valid accuracy 92.05%
-= Testing valid =-
Test set: Average loss: 0.1657,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1414,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1529,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1424,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1103,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1657,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1193,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1154,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1275,                   Accuracy: 1919/2000.0 (95.95%)



Epoch 20 train accuracy: 95.96%, valid accuracy 95.95%
-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.1003,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 30 train accuracy: 96.80%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 40 train accuracy: 97.24%, valid accuracy 97.80%
-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0741,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0712,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 50 train accuracy: 97.32%, valid accuracy 98.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0923,                   Accuracy: 58318/60000 (97.20%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1014,                   Accuracy: 58174/60000 (96.96%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0982,                   Accuracy: 58201/60000 (97.00%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0992,                   Accuracy: 58140/60000 (96.90%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0995,                   Accuracy: 58240/60000 (97.07%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0983,                   Accuracy: 58248/60000 (97.08%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0964,                   Accuracy: 58286/60000 (97.14%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0959,                   Accuracy: 58244/60000 (97.07%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.0963,                   Accuracy: 58240/60000 (97.07%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0923,                   Accuracy: 58318/60000 (97.20%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1014,                   Accuracy: 58174/60000 (96.96%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.0982,                   Accuracy: 58201/60000 (97.00%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.0992,                   Accuracy: 58140/60000 (96.90%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.0995,                   Accuracy: 58240/60000 (97.07%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.0983,                   Accuracy: 58248/60000 (97.08%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.0964,                   Accuracy: 58286/60000 (97.14%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.0959,                   Accuracy: 58244/60000 (97.07%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.0963,                   Accuracy: 58240/60000 (97.07%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0923,                   Accuracy: 58318/60000 (97.20%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1014,                   Accuracy: 58174/60000 (96.96%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.0982,                   Accuracy: 58201/60000 (97.00%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.0992,                   Accuracy: 58140/60000 (96.90%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.0995,                   Accuracy: 58240/60000 (97.07%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.0983,                   Accuracy: 58248/60000 (97.08%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.0964,                   Accuracy: 58286/60000 (97.14%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.0959,                   Accuracy: 58244/60000 (97.07%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.0963,                   Accuracy: 58240/60000 (97.07%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0923,                   Accuracy: 58318/60000 (97.20%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1014,                   Accuracy: 58174/60000 (96.96%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0982,                   Accuracy: 58201/60000 (97.00%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.0992,                   Accuracy: 58140/60000 (96.90%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.0995,                   Accuracy: 58240/60000 (97.07%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.0983,                   Accuracy: 58248/60000 (97.08%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0964,                   Accuracy: 58286/60000 (97.14%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0959,                   Accuracy: 58244/60000 (97.07%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0963,                   Accuracy: 58240/60000 (97.07%)
{0: tensor(97.1967), 10: tensor(96.9567), 20: tensor(97.0017), 30: tensor(96.9000), 40: tensor(97.0667), 50: tensor(97.0800), 60: tensor(97.1433), 70: tensor(97.0733), 80: tensor(97.0667), 90: tensor(97.1967), 100: tensor(96.9567), 110: tensor(97.0017), 120: tensor(96.9000), 130: tensor(97.0667), 140: tensor(97.0800), 150: tensor(97.1433), 160: tensor(97.0733), 170: tensor(97.0667), 180: tensor(97.1967), 190: tensor(96.9567), 200: tensor(97.0017), 210: tensor(96.9000), 220: tensor(97.0667), 230: tensor(97.0800), 240: tensor(97.1433), 250: tensor(97.0733), 260: tensor(97.0667), 270: tensor(97.1967), 280: tensor(96.9567), 290: tensor(97.0017), 300: tensor(96.9000), 310: tensor(97.0667), 320: tensor(97.0800), 330: tensor(97.1433), 340: tensor(97.0733), 350: tensor(97.0667)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=82, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.7281,                   Accuracy: 385/2000.0 (19.25%)



-= Testing valid =-
Test set: Average loss: 1.3066,                   Accuracy: 1060/2000.0 (53.00%)



-= Testing valid =-
Test set: Average loss: 1.0673,                   Accuracy: 1295/2000.0 (64.75%)



-= Testing valid =-
Test set: Average loss: 0.3956,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.4472,                   Accuracy: 1729/2000.0 (86.45%)



-= Testing valid =-
Test set: Average loss: 0.5943,                   Accuracy: 1652/2000.0 (82.60%)



-= Testing valid =-
Test set: Average loss: 0.2076,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1666,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1786,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.1886,                   Accuracy: 1869/2000.0 (93.45%)



Epoch 10 train accuracy: 94.50%, valid accuracy 93.45%
-= Testing valid =-
Test set: Average loss: 0.1381,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1661,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1179,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1119,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1816,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1178,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1364,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1058,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1152,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1312,                   Accuracy: 1910/2000.0 (95.50%)



Epoch 20 train accuracy: 96.39%, valid accuracy 95.50%
-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1928/2000.0 (96.40%)



Epoch 30 train accuracy: 97.04%, valid accuracy 96.40%
-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0746,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0698,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0715,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0738,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0742,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 40 train accuracy: 97.44%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0670,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0664,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0683,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0710,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0704,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0684,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 50 train accuracy: 97.54%, valid accuracy 97.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0929,                   Accuracy: 58344/60000 (97.24%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1064,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1038,                   Accuracy: 58159/60000 (96.93%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1065,                   Accuracy: 58130/60000 (96.88%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1109,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1127,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1084,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1062,                   Accuracy: 58137/60000 (96.89%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1005,                   Accuracy: 58204/60000 (97.01%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0929,                   Accuracy: 58344/60000 (97.24%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1064,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1038,                   Accuracy: 58159/60000 (96.93%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1065,                   Accuracy: 58130/60000 (96.88%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1109,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1127,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1084,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1062,                   Accuracy: 58137/60000 (96.89%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1005,                   Accuracy: 58204/60000 (97.01%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0929,                   Accuracy: 58344/60000 (97.24%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1064,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1038,                   Accuracy: 58159/60000 (96.93%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1065,                   Accuracy: 58130/60000 (96.88%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1109,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1127,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1084,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1062,                   Accuracy: 58137/60000 (96.89%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1005,                   Accuracy: 58204/60000 (97.01%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0929,                   Accuracy: 58344/60000 (97.24%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1064,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1038,                   Accuracy: 58159/60000 (96.93%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1065,                   Accuracy: 58130/60000 (96.88%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1109,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1127,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1084,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1062,                   Accuracy: 58137/60000 (96.89%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1005,                   Accuracy: 58204/60000 (97.01%)
{0: tensor(97.2400), 10: tensor(96.8483), 20: tensor(96.9317), 30: tensor(96.8833), 40: tensor(96.7500), 50: tensor(96.7667), 60: tensor(96.8717), 70: tensor(96.8950), 80: tensor(97.0067), 90: tensor(97.2400), 100: tensor(96.8483), 110: tensor(96.9317), 120: tensor(96.8833), 130: tensor(96.7500), 140: tensor(96.7667), 150: tensor(96.8717), 160: tensor(96.8950), 170: tensor(97.0067), 180: tensor(97.2400), 190: tensor(96.8483), 200: tensor(96.9317), 210: tensor(96.8833), 220: tensor(96.7500), 230: tensor(96.7667), 240: tensor(96.8717), 250: tensor(96.8950), 260: tensor(97.0067), 270: tensor(97.2400), 280: tensor(96.8483), 290: tensor(96.9317), 300: tensor(96.8833), 310: tensor(96.7500), 320: tensor(96.7667), 330: tensor(96.8717), 340: tensor(96.8950), 350: tensor(97.0067)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=83, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6852,                   Accuracy: 270/2000.0 (13.50%)



-= Testing valid =-
Test set: Average loss: 1.4662,                   Accuracy: 989/2000.0 (49.45%)



-= Testing valid =-
Test set: Average loss: 1.2300,                   Accuracy: 1203/2000.0 (60.15%)



-= Testing valid =-
Test set: Average loss: 0.7640,                   Accuracy: 1554/2000.0 (77.70%)



-= Testing valid =-
Test set: Average loss: 0.3096,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.3748,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.2533,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.4306,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.3063,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.1889,                   Accuracy: 1878/2000.0 (93.90%)



Epoch 10 train accuracy: 93.21%, valid accuracy 93.90%
-= Testing valid =-
Test set: Average loss: 0.1692,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1442,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1432,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1425,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1613,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1352,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1329,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1180,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1332,                   Accuracy: 1911/2000.0 (95.55%)



Epoch 20 train accuracy: 95.70%, valid accuracy 95.55%
-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1071,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1208,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1082,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1076,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 30 train accuracy: 96.80%, valid accuracy 96.45%
-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1036,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 40 train accuracy: 97.16%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 50 train accuracy: 97.32%, valid accuracy 97.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1018,                   Accuracy: 58235/60000 (97.06%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1122,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1134,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1167,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1163,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1123,                   Accuracy: 58069/60000 (96.78%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1063,                   Accuracy: 58195/60000 (96.99%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1044,                   Accuracy: 58191/60000 (96.99%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1035,                   Accuracy: 58198/60000 (97.00%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1018,                   Accuracy: 58235/60000 (97.06%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1122,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1134,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1167,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1163,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1123,                   Accuracy: 58069/60000 (96.78%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1063,                   Accuracy: 58195/60000 (96.99%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1044,                   Accuracy: 58191/60000 (96.99%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1035,                   Accuracy: 58198/60000 (97.00%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1018,                   Accuracy: 58235/60000 (97.06%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1122,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1134,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1167,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1163,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1123,                   Accuracy: 58069/60000 (96.78%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1063,                   Accuracy: 58195/60000 (96.99%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1044,                   Accuracy: 58191/60000 (96.99%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1035,                   Accuracy: 58198/60000 (97.00%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1018,                   Accuracy: 58235/60000 (97.06%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1122,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1134,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1167,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1163,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1123,                   Accuracy: 58069/60000 (96.78%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1063,                   Accuracy: 58195/60000 (96.99%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1044,                   Accuracy: 58191/60000 (96.99%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1035,                   Accuracy: 58198/60000 (97.00%)
{0: tensor(97.0583), 10: tensor(96.6683), 20: tensor(96.7350), 30: tensor(96.6167), 40: tensor(96.6417), 50: tensor(96.7817), 60: tensor(96.9917), 70: tensor(96.9850), 80: tensor(96.9967), 90: tensor(97.0583), 100: tensor(96.6683), 110: tensor(96.7350), 120: tensor(96.6167), 130: tensor(96.6417), 140: tensor(96.7817), 150: tensor(96.9917), 160: tensor(96.9850), 170: tensor(96.9967), 180: tensor(97.0583), 190: tensor(96.6683), 200: tensor(96.7350), 210: tensor(96.6167), 220: tensor(96.6417), 230: tensor(96.7817), 240: tensor(96.9917), 250: tensor(96.9850), 260: tensor(96.9967), 270: tensor(97.0583), 280: tensor(96.6683), 290: tensor(96.7350), 300: tensor(96.6167), 310: tensor(96.6417), 320: tensor(96.7817), 330: tensor(96.9917), 340: tensor(96.9850), 350: tensor(96.9967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=84, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8249,                   Accuracy: 621/2000.0 (31.05%)



-= Testing valid =-
Test set: Average loss: 2.5117,                   Accuracy: 377/2000.0 (18.85%)



-= Testing valid =-
Test set: Average loss: 0.7418,                   Accuracy: 1579/2000.0 (78.95%)



-= Testing valid =-
Test set: Average loss: 0.5611,                   Accuracy: 1696/2000.0 (84.80%)



-= Testing valid =-
Test set: Average loss: 0.9904,                   Accuracy: 1312/2000.0 (65.60%)



-= Testing valid =-
Test set: Average loss: 0.4226,                   Accuracy: 1729/2000.0 (86.45%)



-= Testing valid =-
Test set: Average loss: 0.2398,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2871,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.1777,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1727,                   Accuracy: 1879/2000.0 (93.95%)



Epoch 10 train accuracy: 94.05%, valid accuracy 93.95%
-= Testing valid =-
Test set: Average loss: 0.1351,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1158,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1033,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1046,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1202,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1389,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1260,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1126,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 20 train accuracy: 96.04%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 30 train accuracy: 97.07%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0807,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 40 train accuracy: 97.31%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 50 train accuracy: 97.47%, valid accuracy 98.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0916,                   Accuracy: 58389/60000 (97.32%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0954,                   Accuracy: 58286/60000 (97.14%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0966,                   Accuracy: 58269/60000 (97.11%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1053,                   Accuracy: 58115/60000 (96.86%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1075,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1064,                   Accuracy: 58092/60000 (96.82%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1009,                   Accuracy: 58208/60000 (97.01%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0949,                   Accuracy: 58299/60000 (97.17%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.0897,                   Accuracy: 58343/60000 (97.24%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0916,                   Accuracy: 58389/60000 (97.32%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.0954,                   Accuracy: 58286/60000 (97.14%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.0966,                   Accuracy: 58269/60000 (97.11%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1053,                   Accuracy: 58115/60000 (96.86%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1075,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1064,                   Accuracy: 58092/60000 (96.82%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1009,                   Accuracy: 58208/60000 (97.01%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.0949,                   Accuracy: 58299/60000 (97.17%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.0897,                   Accuracy: 58343/60000 (97.24%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0916,                   Accuracy: 58389/60000 (97.32%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.0954,                   Accuracy: 58286/60000 (97.14%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.0966,                   Accuracy: 58269/60000 (97.11%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1053,                   Accuracy: 58115/60000 (96.86%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1075,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1064,                   Accuracy: 58092/60000 (96.82%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1009,                   Accuracy: 58208/60000 (97.01%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.0949,                   Accuracy: 58299/60000 (97.17%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.0897,                   Accuracy: 58343/60000 (97.24%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0916,                   Accuracy: 58389/60000 (97.32%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.0954,                   Accuracy: 58286/60000 (97.14%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0966,                   Accuracy: 58269/60000 (97.11%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1053,                   Accuracy: 58115/60000 (96.86%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1075,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1064,                   Accuracy: 58092/60000 (96.82%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1009,                   Accuracy: 58208/60000 (97.01%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0949,                   Accuracy: 58299/60000 (97.17%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0897,                   Accuracy: 58343/60000 (97.24%)
{0: tensor(97.3150), 10: tensor(97.1433), 20: tensor(97.1150), 30: tensor(96.8583), 40: tensor(96.7567), 50: tensor(96.8200), 60: tensor(97.0133), 70: tensor(97.1650), 80: tensor(97.2383), 90: tensor(97.3150), 100: tensor(97.1433), 110: tensor(97.1150), 120: tensor(96.8583), 130: tensor(96.7567), 140: tensor(96.8200), 150: tensor(97.0133), 160: tensor(97.1650), 170: tensor(97.2383), 180: tensor(97.3150), 190: tensor(97.1433), 200: tensor(97.1150), 210: tensor(96.8583), 220: tensor(96.7567), 230: tensor(96.8200), 240: tensor(97.0133), 250: tensor(97.1650), 260: tensor(97.2383), 270: tensor(97.3150), 280: tensor(97.1433), 290: tensor(97.1150), 300: tensor(96.8583), 310: tensor(96.7567), 320: tensor(96.8200), 330: tensor(97.0133), 340: tensor(97.1650), 350: tensor(97.2383)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=85, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.0677,                   Accuracy: 340/2000.0 (17.00%)



-= Testing valid =-
Test set: Average loss: 2.3707,                   Accuracy: 371/2000.0 (18.55%)



-= Testing valid =-
Test set: Average loss: 1.3693,                   Accuracy: 1023/2000.0 (51.15%)



-= Testing valid =-
Test set: Average loss: 0.5789,                   Accuracy: 1618/2000.0 (80.90%)



-= Testing valid =-
Test set: Average loss: 0.3382,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.3709,                   Accuracy: 1760/2000.0 (88.00%)



-= Testing valid =-
Test set: Average loss: 0.3444,                   Accuracy: 1777/2000.0 (88.85%)



-= Testing valid =-
Test set: Average loss: 0.2783,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2078,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.1713,                   Accuracy: 1891/2000.0 (94.55%)



Epoch 10 train accuracy: 93.70%, valid accuracy 94.55%
-= Testing valid =-
Test set: Average loss: 0.1662,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1441,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1702,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1258,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1222,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1614,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.2288,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.1114,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1198,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1618,                   Accuracy: 1903/2000.0 (95.15%)



Epoch 20 train accuracy: 95.93%, valid accuracy 95.15%
-= Testing valid =-
Test set: Average loss: 0.1052,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1197,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1195,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1240,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1143,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1145,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1255,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1058,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1045,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1114,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 30 train accuracy: 96.70%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1033,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1092,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1042,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 40 train accuracy: 97.34%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1003,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 50 train accuracy: 97.51%, valid accuracy 96.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1056,                   Accuracy: 58141/60000 (96.90%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1150,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1116,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1108,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1097,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1083,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1028,                   Accuracy: 58178/60000 (96.96%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1011,                   Accuracy: 58247/60000 (97.08%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1034,                   Accuracy: 58156/60000 (96.93%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1056,                   Accuracy: 58141/60000 (96.90%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1150,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1116,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1108,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1097,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1083,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1028,                   Accuracy: 58178/60000 (96.96%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1011,                   Accuracy: 58247/60000 (97.08%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1034,                   Accuracy: 58156/60000 (96.93%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1056,                   Accuracy: 58141/60000 (96.90%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1150,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1116,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1108,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1097,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1083,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1028,                   Accuracy: 58178/60000 (96.96%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1011,                   Accuracy: 58247/60000 (97.08%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1034,                   Accuracy: 58156/60000 (96.93%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1056,                   Accuracy: 58141/60000 (96.90%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1150,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1116,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1108,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1097,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1083,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1028,                   Accuracy: 58178/60000 (96.96%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1011,                   Accuracy: 58247/60000 (97.08%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1034,                   Accuracy: 58156/60000 (96.93%)
{0: tensor(96.9017), 10: tensor(96.5867), 20: tensor(96.6433), 30: tensor(96.6717), 40: tensor(96.7300), 50: tensor(96.7833), 60: tensor(96.9633), 70: tensor(97.0783), 80: tensor(96.9267), 90: tensor(96.9017), 100: tensor(96.5867), 110: tensor(96.6433), 120: tensor(96.6717), 130: tensor(96.7300), 140: tensor(96.7833), 150: tensor(96.9633), 160: tensor(97.0783), 170: tensor(96.9267), 180: tensor(96.9017), 190: tensor(96.5867), 200: tensor(96.6433), 210: tensor(96.6717), 220: tensor(96.7300), 230: tensor(96.7833), 240: tensor(96.9633), 250: tensor(97.0783), 260: tensor(96.9267), 270: tensor(96.9017), 280: tensor(96.5867), 290: tensor(96.6433), 300: tensor(96.6717), 310: tensor(96.7300), 320: tensor(96.7833), 330: tensor(96.9633), 340: tensor(97.0783), 350: tensor(96.9267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=86, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 6.3601,                   Accuracy: 245/2000.0 (12.25%)



-= Testing valid =-
Test set: Average loss: 2.9682,                   Accuracy: 425/2000.0 (21.25%)



-= Testing valid =-
Test set: Average loss: 1.2119,                   Accuracy: 1121/2000.0 (56.05%)



-= Testing valid =-
Test set: Average loss: 3.9804,                   Accuracy: 429/2000.0 (21.45%)



-= Testing valid =-
Test set: Average loss: 0.3570,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 5.1062,                   Accuracy: 485/2000.0 (24.25%)



-= Testing valid =-
Test set: Average loss: 0.5832,                   Accuracy: 1679/2000.0 (83.95%)



-= Testing valid =-
Test set: Average loss: 0.2829,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2068,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.6765,                   Accuracy: 1555/2000.0 (77.75%)



Epoch 10 train accuracy: 93.29%, valid accuracy 77.75%
-= Testing valid =-
Test set: Average loss: 0.1516,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1293,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1258,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1238,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1075,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1089,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1223,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1118,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1150,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 20 train accuracy: 95.81%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.1012,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 30 train accuracy: 96.57%, valid accuracy 98.10%
-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0688,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0638,                   Accuracy: 1969/2000.0 (98.45%)



Epoch 40 train accuracy: 96.99%, valid accuracy 98.45%
-= Testing valid =-
Test set: Average loss: 0.0659,                   Accuracy: 1968/2000.0 (98.40%)



-= Testing valid =-
Test set: Average loss: 0.0649,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0620,                   Accuracy: 1971/2000.0 (98.55%)



-= Testing valid =-
Test set: Average loss: 0.0629,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1967/2000.0 (98.35%)



-= Testing valid =-
Test set: Average loss: 0.0647,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1969/2000.0 (98.45%)



-= Testing valid =-
Test set: Average loss: 0.0659,                   Accuracy: 1967/2000.0 (98.35%)



Epoch 50 train accuracy: 97.35%, valid accuracy 98.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0967,                   Accuracy: 58324/60000 (97.21%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1078,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1020,                   Accuracy: 58235/60000 (97.06%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1076,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1119,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1109,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1077,                   Accuracy: 58150/60000 (96.92%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1035,                   Accuracy: 58148/60000 (96.91%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1027,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0967,                   Accuracy: 58324/60000 (97.21%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1078,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1020,                   Accuracy: 58235/60000 (97.06%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1076,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1119,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1109,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1077,                   Accuracy: 58150/60000 (96.92%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1035,                   Accuracy: 58148/60000 (96.91%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1027,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0967,                   Accuracy: 58324/60000 (97.21%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1078,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1020,                   Accuracy: 58235/60000 (97.06%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1076,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1119,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1109,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1077,                   Accuracy: 58150/60000 (96.92%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1035,                   Accuracy: 58148/60000 (96.91%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1027,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0967,                   Accuracy: 58324/60000 (97.21%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1078,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1020,                   Accuracy: 58235/60000 (97.06%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1076,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1119,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1109,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1077,                   Accuracy: 58150/60000 (96.92%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1035,                   Accuracy: 58148/60000 (96.91%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1027,                   Accuracy: 58170/60000 (96.95%)
{0: tensor(97.2067), 10: tensor(96.7867), 20: tensor(97.0583), 30: tensor(96.8717), 40: tensor(96.7600), 50: tensor(96.7500), 60: tensor(96.9167), 70: tensor(96.9133), 80: tensor(96.9500), 90: tensor(97.2067), 100: tensor(96.7867), 110: tensor(97.0583), 120: tensor(96.8717), 130: tensor(96.7600), 140: tensor(96.7500), 150: tensor(96.9167), 160: tensor(96.9133), 170: tensor(96.9500), 180: tensor(97.2067), 190: tensor(96.7867), 200: tensor(97.0583), 210: tensor(96.8717), 220: tensor(96.7600), 230: tensor(96.7500), 240: tensor(96.9167), 250: tensor(96.9133), 260: tensor(96.9500), 270: tensor(97.2067), 280: tensor(96.7867), 290: tensor(97.0583), 300: tensor(96.8717), 310: tensor(96.7600), 320: tensor(96.7500), 330: tensor(96.9167), 340: tensor(96.9133), 350: tensor(96.9500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=87, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9909,                   Accuracy: 431/2000.0 (21.55%)



-= Testing valid =-
Test set: Average loss: 1.6108,                   Accuracy: 753/2000.0 (37.65%)



-= Testing valid =-
Test set: Average loss: 2.8672,                   Accuracy: 582/2000.0 (29.10%)



-= Testing valid =-
Test set: Average loss: 1.3719,                   Accuracy: 1270/2000.0 (63.50%)



-= Testing valid =-
Test set: Average loss: 1.5221,                   Accuracy: 1210/2000.0 (60.50%)



-= Testing valid =-
Test set: Average loss: 0.2770,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.4423,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.2878,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.2158,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.1715,                   Accuracy: 1881/2000.0 (94.05%)



Epoch 10 train accuracy: 93.49%, valid accuracy 94.05%
-= Testing valid =-
Test set: Average loss: 0.2156,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.1578,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1282,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1838,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1433,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1335,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1605,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1192,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1508,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1163,                   Accuracy: 1920/2000.0 (96.00%)



Epoch 20 train accuracy: 95.82%, valid accuracy 96.00%
-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1147,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1106,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1173,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1075,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 30 train accuracy: 96.43%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 40 train accuracy: 96.99%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 50 train accuracy: 97.21%, valid accuracy 97.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1048,                   Accuracy: 58180/60000 (96.97%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1112,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1068,                   Accuracy: 58158/60000 (96.93%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1128,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1172,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1216,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1177,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1088,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1061,                   Accuracy: 58166/60000 (96.94%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1048,                   Accuracy: 58180/60000 (96.97%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1112,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1068,                   Accuracy: 58158/60000 (96.93%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1128,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1172,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1216,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1177,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1088,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1061,                   Accuracy: 58166/60000 (96.94%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1048,                   Accuracy: 58180/60000 (96.97%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1112,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1068,                   Accuracy: 58158/60000 (96.93%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1128,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1172,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1216,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1177,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1088,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1061,                   Accuracy: 58166/60000 (96.94%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1048,                   Accuracy: 58180/60000 (96.97%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1112,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1068,                   Accuracy: 58158/60000 (96.93%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1128,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1172,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1216,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1177,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1088,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1061,                   Accuracy: 58166/60000 (96.94%)
{0: tensor(96.9667), 10: tensor(96.7400), 20: tensor(96.9300), 30: tensor(96.7533), 40: tensor(96.6200), 50: tensor(96.4633), 60: tensor(96.5533), 70: tensor(96.8483), 80: tensor(96.9433), 90: tensor(96.9667), 100: tensor(96.7400), 110: tensor(96.9300), 120: tensor(96.7533), 130: tensor(96.6200), 140: tensor(96.4633), 150: tensor(96.5533), 160: tensor(96.8483), 170: tensor(96.9433), 180: tensor(96.9667), 190: tensor(96.7400), 200: tensor(96.9300), 210: tensor(96.7533), 220: tensor(96.6200), 230: tensor(96.4633), 240: tensor(96.5533), 250: tensor(96.8483), 260: tensor(96.9433), 270: tensor(96.9667), 280: tensor(96.7400), 290: tensor(96.9300), 300: tensor(96.7533), 310: tensor(96.6200), 320: tensor(96.4633), 330: tensor(96.5533), 340: tensor(96.8483), 350: tensor(96.9433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=88, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.1906,                   Accuracy: 382/2000.0 (19.10%)



-= Testing valid =-
Test set: Average loss: 2.2936,                   Accuracy: 383/2000.0 (19.15%)



-= Testing valid =-
Test set: Average loss: 1.7520,                   Accuracy: 773/2000.0 (38.65%)



-= Testing valid =-
Test set: Average loss: 2.0338,                   Accuracy: 719/2000.0 (35.95%)



-= Testing valid =-
Test set: Average loss: 0.8730,                   Accuracy: 1328/2000.0 (66.40%)



-= Testing valid =-
Test set: Average loss: 0.5836,                   Accuracy: 1601/2000.0 (80.05%)



-= Testing valid =-
Test set: Average loss: 0.4135,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.2627,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2210,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2228,                   Accuracy: 1858/2000.0 (92.90%)



Epoch 10 train accuracy: 93.20%, valid accuracy 92.90%
-= Testing valid =-
Test set: Average loss: 0.1702,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1595,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1595,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1998,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1413,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1437,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1282,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1283,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1428,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1424,                   Accuracy: 1915/2000.0 (95.75%)



Epoch 20 train accuracy: 95.96%, valid accuracy 95.75%
-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1050,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1076,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1131,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1154,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 30 train accuracy: 96.34%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0935,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 40 train accuracy: 97.03%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0882,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 50 train accuracy: 97.24%, valid accuracy 97.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0989,                   Accuracy: 58267/60000 (97.11%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1032,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0998,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1034,                   Accuracy: 58105/60000 (96.84%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1063,                   Accuracy: 58076/60000 (96.79%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1109,                   Accuracy: 58011/60000 (96.68%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1109,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1086,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1060,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0989,                   Accuracy: 58267/60000 (97.11%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1032,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.0998,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1034,                   Accuracy: 58105/60000 (96.84%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1063,                   Accuracy: 58076/60000 (96.79%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1109,                   Accuracy: 58011/60000 (96.68%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1109,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1086,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1060,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0989,                   Accuracy: 58267/60000 (97.11%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1032,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.0998,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1034,                   Accuracy: 58105/60000 (96.84%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1063,                   Accuracy: 58076/60000 (96.79%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1109,                   Accuracy: 58011/60000 (96.68%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1109,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1086,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1060,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0989,                   Accuracy: 58267/60000 (97.11%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1032,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0998,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1034,                   Accuracy: 58105/60000 (96.84%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1063,                   Accuracy: 58076/60000 (96.79%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1109,                   Accuracy: 58011/60000 (96.68%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1109,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1086,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1060,                   Accuracy: 58102/60000 (96.84%)
{0: tensor(97.1117), 10: tensor(96.8917), 20: tensor(96.9500), 30: tensor(96.8417), 40: tensor(96.7933), 50: tensor(96.6850), 60: tensor(96.6817), 70: tensor(96.8217), 80: tensor(96.8367), 90: tensor(97.1117), 100: tensor(96.8917), 110: tensor(96.9500), 120: tensor(96.8417), 130: tensor(96.7933), 140: tensor(96.6850), 150: tensor(96.6817), 160: tensor(96.8217), 170: tensor(96.8367), 180: tensor(97.1117), 190: tensor(96.8917), 200: tensor(96.9500), 210: tensor(96.8417), 220: tensor(96.7933), 230: tensor(96.6850), 240: tensor(96.6817), 250: tensor(96.8217), 260: tensor(96.8367), 270: tensor(97.1117), 280: tensor(96.8917), 290: tensor(96.9500), 300: tensor(96.8417), 310: tensor(96.7933), 320: tensor(96.6850), 330: tensor(96.6817), 340: tensor(96.8217), 350: tensor(96.8367)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=89, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8216,                   Accuracy: 657/2000.0 (32.85%)



-= Testing valid =-
Test set: Average loss: 1.9406,                   Accuracy: 676/2000.0 (33.80%)



-= Testing valid =-
Test set: Average loss: 1.6353,                   Accuracy: 932/2000.0 (46.60%)



-= Testing valid =-
Test set: Average loss: 2.5217,                   Accuracy: 458/2000.0 (22.90%)



-= Testing valid =-
Test set: Average loss: 0.8877,                   Accuracy: 1221/2000.0 (61.05%)



-= Testing valid =-
Test set: Average loss: 0.7544,                   Accuracy: 1533/2000.0 (76.65%)



-= Testing valid =-
Test set: Average loss: 0.2387,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.4856,                   Accuracy: 1671/2000.0 (83.55%)



-= Testing valid =-
Test set: Average loss: 0.3130,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.2078,                   Accuracy: 1859/2000.0 (92.95%)



Epoch 10 train accuracy: 92.78%, valid accuracy 92.95%
-= Testing valid =-
Test set: Average loss: 0.1753,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1515,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1337,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1504,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1317,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1213,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1329,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1370,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1593,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1326,                   Accuracy: 1917/2000.0 (95.85%)



Epoch 20 train accuracy: 95.64%, valid accuracy 95.85%
-= Testing valid =-
Test set: Average loss: 0.1113,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1010,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1021,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 30 train accuracy: 96.53%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0736,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 40 train accuracy: 96.80%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0668,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0718,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0738,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0687,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0738,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0674,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 50 train accuracy: 97.04%, valid accuracy 97.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1082,                   Accuracy: 58074/60000 (96.79%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1209,                   Accuracy: 57802/60000 (96.34%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1139,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1196,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1231,                   Accuracy: 57790/60000 (96.32%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1217,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1198,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1157,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1134,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1082,                   Accuracy: 58074/60000 (96.79%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1209,                   Accuracy: 57802/60000 (96.34%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1139,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1196,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1231,                   Accuracy: 57790/60000 (96.32%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1217,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1198,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1157,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1134,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1082,                   Accuracy: 58074/60000 (96.79%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1209,                   Accuracy: 57802/60000 (96.34%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1139,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1196,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1231,                   Accuracy: 57790/60000 (96.32%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1217,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1198,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1157,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1134,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1082,                   Accuracy: 58074/60000 (96.79%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1209,                   Accuracy: 57802/60000 (96.34%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1139,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1196,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1231,                   Accuracy: 57790/60000 (96.32%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1217,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1198,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1157,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1134,                   Accuracy: 57942/60000 (96.57%)
{0: tensor(96.7900), 10: tensor(96.3367), 20: tensor(96.5783), 30: tensor(96.3817), 40: tensor(96.3167), 50: tensor(96.3817), 60: tensor(96.4400), 70: tensor(96.5067), 80: tensor(96.5700), 90: tensor(96.7900), 100: tensor(96.3367), 110: tensor(96.5783), 120: tensor(96.3817), 130: tensor(96.3167), 140: tensor(96.3817), 150: tensor(96.4400), 160: tensor(96.5067), 170: tensor(96.5700), 180: tensor(96.7900), 190: tensor(96.3367), 200: tensor(96.5783), 210: tensor(96.3817), 220: tensor(96.3167), 230: tensor(96.3817), 240: tensor(96.4400), 250: tensor(96.5067), 260: tensor(96.5700), 270: tensor(96.7900), 280: tensor(96.3367), 290: tensor(96.5783), 300: tensor(96.3817), 310: tensor(96.3167), 320: tensor(96.3817), 330: tensor(96.4400), 340: tensor(96.5067), 350: tensor(96.5700)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=90, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.9570,                   Accuracy: 220/2000.0 (11.00%)



-= Testing valid =-
Test set: Average loss: 2.0282,                   Accuracy: 608/2000.0 (30.40%)



-= Testing valid =-
Test set: Average loss: 1.2964,                   Accuracy: 1076/2000.0 (53.80%)



-= Testing valid =-
Test set: Average loss: 0.6679,                   Accuracy: 1566/2000.0 (78.30%)



-= Testing valid =-
Test set: Average loss: 0.4432,                   Accuracy: 1708/2000.0 (85.40%)



-= Testing valid =-
Test set: Average loss: 0.5459,                   Accuracy: 1621/2000.0 (81.05%)



-= Testing valid =-
Test set: Average loss: 0.5531,                   Accuracy: 1587/2000.0 (79.35%)



-= Testing valid =-
Test set: Average loss: 0.1704,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1909,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1569,                   Accuracy: 1902/2000.0 (95.10%)



Epoch 10 train accuracy: 94.25%, valid accuracy 95.10%
-= Testing valid =-
Test set: Average loss: 0.1927,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1327,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1304,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1599,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1079,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1281,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1142,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1146,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1229,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 20 train accuracy: 96.14%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1122,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1123,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1169,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0752,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 30 train accuracy: 97.01%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 40 train accuracy: 97.25%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0718,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0723,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0701,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 50 train accuracy: 97.46%, valid accuracy 97.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1098,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1230,                   Accuracy: 57725/60000 (96.21%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1155,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1185,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1169,                   Accuracy: 57906/60000 (96.51%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1144,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1112,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1075,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1092,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1098,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1230,                   Accuracy: 57725/60000 (96.21%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1155,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1185,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1169,                   Accuracy: 57906/60000 (96.51%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1144,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1112,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1075,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1092,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1098,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1230,                   Accuracy: 57725/60000 (96.21%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1155,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1185,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1169,                   Accuracy: 57906/60000 (96.51%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1144,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1112,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1075,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1092,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1098,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1230,                   Accuracy: 57725/60000 (96.21%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1155,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1185,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1169,                   Accuracy: 57906/60000 (96.51%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1144,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1112,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1075,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1092,                   Accuracy: 58001/60000 (96.67%)
{0: tensor(96.6717), 10: tensor(96.2083), 20: tensor(96.4900), 30: tensor(96.4900), 40: tensor(96.5100), 50: tensor(96.6667), 60: tensor(96.7467), 70: tensor(96.8683), 80: tensor(96.6683), 90: tensor(96.6717), 100: tensor(96.2083), 110: tensor(96.4900), 120: tensor(96.4900), 130: tensor(96.5100), 140: tensor(96.6667), 150: tensor(96.7467), 160: tensor(96.8683), 170: tensor(96.6683), 180: tensor(96.6717), 190: tensor(96.2083), 200: tensor(96.4900), 210: tensor(96.4900), 220: tensor(96.5100), 230: tensor(96.6667), 240: tensor(96.7467), 250: tensor(96.8683), 260: tensor(96.6683), 270: tensor(96.6717), 280: tensor(96.2083), 290: tensor(96.4900), 300: tensor(96.4900), 310: tensor(96.5100), 320: tensor(96.6667), 330: tensor(96.7467), 340: tensor(96.8683), 350: tensor(96.6683)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=91, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9012,                   Accuracy: 611/2000.0 (30.55%)



-= Testing valid =-
Test set: Average loss: 2.2948,                   Accuracy: 445/2000.0 (22.25%)



-= Testing valid =-
Test set: Average loss: 1.7529,                   Accuracy: 640/2000.0 (32.00%)



-= Testing valid =-
Test set: Average loss: 1.4793,                   Accuracy: 1110/2000.0 (55.50%)



-= Testing valid =-
Test set: Average loss: 0.4641,                   Accuracy: 1685/2000.0 (84.25%)



-= Testing valid =-
Test set: Average loss: 0.5207,                   Accuracy: 1642/2000.0 (82.10%)



-= Testing valid =-
Test set: Average loss: 0.3849,                   Accuracy: 1728/2000.0 (86.40%)



-= Testing valid =-
Test set: Average loss: 0.2803,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.4374,                   Accuracy: 1690/2000.0 (84.50%)



-= Testing valid =-
Test set: Average loss: 0.3095,                   Accuracy: 1790/2000.0 (89.50%)



Epoch 10 train accuracy: 91.81%, valid accuracy 89.50%
-= Testing valid =-
Test set: Average loss: 0.1676,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1349,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1646,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1532,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1409,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1372,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1266,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1376,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1370,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1245,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 20 train accuracy: 95.45%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.1107,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1178,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1174,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1108,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1135,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1153,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1245,                   Accuracy: 1914/2000.0 (95.70%)



Epoch 30 train accuracy: 96.39%, valid accuracy 95.70%
-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1109,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 40 train accuracy: 96.93%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0976,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 50 train accuracy: 96.90%, valid accuracy 97.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1137,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1258,                   Accuracy: 57710/60000 (96.18%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1266,                   Accuracy: 57726/60000 (96.21%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1298,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1288,                   Accuracy: 57694/60000 (96.16%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1281,                   Accuracy: 57757/60000 (96.26%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1256,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1212,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1155,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1137,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1258,                   Accuracy: 57710/60000 (96.18%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1266,                   Accuracy: 57726/60000 (96.21%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1298,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1288,                   Accuracy: 57694/60000 (96.16%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1281,                   Accuracy: 57757/60000 (96.26%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1256,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1212,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1155,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1137,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1258,                   Accuracy: 57710/60000 (96.18%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1266,                   Accuracy: 57726/60000 (96.21%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1298,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1288,                   Accuracy: 57694/60000 (96.16%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1281,                   Accuracy: 57757/60000 (96.26%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1256,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1212,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1155,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1137,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1258,                   Accuracy: 57710/60000 (96.18%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1266,                   Accuracy: 57726/60000 (96.21%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1298,                   Accuracy: 57685/60000 (96.14%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1288,                   Accuracy: 57694/60000 (96.16%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1281,                   Accuracy: 57757/60000 (96.26%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1256,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1212,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1155,                   Accuracy: 57971/60000 (96.62%)
{0: tensor(96.6200), 10: tensor(96.1833), 20: tensor(96.2100), 30: tensor(96.1417), 40: tensor(96.1567), 50: tensor(96.2617), 60: tensor(96.3400), 70: tensor(96.4733), 80: tensor(96.6183), 90: tensor(96.6200), 100: tensor(96.1833), 110: tensor(96.2100), 120: tensor(96.1417), 130: tensor(96.1567), 140: tensor(96.2617), 150: tensor(96.3400), 160: tensor(96.4733), 170: tensor(96.6183), 180: tensor(96.6200), 190: tensor(96.1833), 200: tensor(96.2100), 210: tensor(96.1417), 220: tensor(96.1567), 230: tensor(96.2617), 240: tensor(96.3400), 250: tensor(96.4733), 260: tensor(96.6183), 270: tensor(96.6200), 280: tensor(96.1833), 290: tensor(96.2100), 300: tensor(96.1417), 310: tensor(96.1567), 320: tensor(96.2617), 330: tensor(96.3400), 340: tensor(96.4733), 350: tensor(96.6183)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=92, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1238,                   Accuracy: 437/2000.0 (21.85%)



-= Testing valid =-
Test set: Average loss: 2.0477,                   Accuracy: 598/2000.0 (29.90%)



-= Testing valid =-
Test set: Average loss: 0.8772,                   Accuracy: 1330/2000.0 (66.50%)



-= Testing valid =-
Test set: Average loss: 0.6713,                   Accuracy: 1537/2000.0 (76.85%)



-= Testing valid =-
Test set: Average loss: 0.6415,                   Accuracy: 1571/2000.0 (78.55%)



-= Testing valid =-
Test set: Average loss: 1.1034,                   Accuracy: 1278/2000.0 (63.90%)



-= Testing valid =-
Test set: Average loss: 0.2376,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2013,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 1.6597,                   Accuracy: 1376/2000.0 (68.80%)



-= Testing valid =-
Test set: Average loss: 0.1617,                   Accuracy: 1897/2000.0 (94.85%)



Epoch 10 train accuracy: 93.61%, valid accuracy 94.85%
-= Testing valid =-
Test set: Average loss: 0.1318,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1737,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.3400,                   Accuracy: 1702/2000.0 (85.10%)



-= Testing valid =-
Test set: Average loss: 0.1578,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1541,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1255,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1301,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1461,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 20 train accuracy: 95.94%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.1551,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1172,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1141,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1188,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 30 train accuracy: 96.60%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 40 train accuracy: 97.05%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 50 train accuracy: 97.43%, valid accuracy 97.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1097,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1139,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1089,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1144,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1192,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1247,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1244,                   Accuracy: 57832/60000 (96.39%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1221,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1168,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1097,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1139,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1089,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1144,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1192,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1247,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1244,                   Accuracy: 57832/60000 (96.39%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1221,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1168,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1097,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1139,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1089,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1144,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1192,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1247,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1244,                   Accuracy: 57832/60000 (96.39%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1221,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1168,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1097,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1139,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1089,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1144,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1192,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1247,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1244,                   Accuracy: 57832/60000 (96.39%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1221,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1168,                   Accuracy: 57962/60000 (96.60%)
{0: tensor(96.8667), 10: tensor(96.6000), 20: tensor(96.8467), 30: tensor(96.7067), 40: tensor(96.5450), 50: tensor(96.3767), 60: tensor(96.3867), 70: tensor(96.4533), 80: tensor(96.6033), 90: tensor(96.8667), 100: tensor(96.6000), 110: tensor(96.8467), 120: tensor(96.7067), 130: tensor(96.5450), 140: tensor(96.3767), 150: tensor(96.3867), 160: tensor(96.4533), 170: tensor(96.6033), 180: tensor(96.8667), 190: tensor(96.6000), 200: tensor(96.8467), 210: tensor(96.7067), 220: tensor(96.5450), 230: tensor(96.3767), 240: tensor(96.3867), 250: tensor(96.4533), 260: tensor(96.6033), 270: tensor(96.8667), 280: tensor(96.6000), 290: tensor(96.8467), 300: tensor(96.7067), 310: tensor(96.5450), 320: tensor(96.3767), 330: tensor(96.3867), 340: tensor(96.4533), 350: tensor(96.6033)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=93, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0361,                   Accuracy: 539/2000.0 (26.95%)



-= Testing valid =-
Test set: Average loss: 2.8449,                   Accuracy: 558/2000.0 (27.90%)



-= Testing valid =-
Test set: Average loss: 4.2647,                   Accuracy: 663/2000.0 (33.15%)



-= Testing valid =-
Test set: Average loss: 1.0424,                   Accuracy: 1308/2000.0 (65.40%)



-= Testing valid =-
Test set: Average loss: 0.4517,                   Accuracy: 1680/2000.0 (84.00%)



-= Testing valid =-
Test set: Average loss: 0.4721,                   Accuracy: 1684/2000.0 (84.20%)



-= Testing valid =-
Test set: Average loss: 0.4989,                   Accuracy: 1670/2000.0 (83.50%)



-= Testing valid =-
Test set: Average loss: 0.2587,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2062,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.2789,                   Accuracy: 1806/2000.0 (90.30%)



Epoch 10 train accuracy: 93.09%, valid accuracy 90.30%
-= Testing valid =-
Test set: Average loss: 0.1650,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1663,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1408,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.2098,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.1720,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1495,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1693,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1404,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1351,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1157,                   Accuracy: 1930/2000.0 (96.50%)



Epoch 20 train accuracy: 95.21%, valid accuracy 96.50%
-= Testing valid =-
Test set: Average loss: 0.1260,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1105,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1374,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1103,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 30 train accuracy: 96.44%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 40 train accuracy: 96.71%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 50 train accuracy: 97.11%, valid accuracy 96.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1151,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1247,                   Accuracy: 57731/60000 (96.22%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1199,                   Accuracy: 57835/60000 (96.39%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1256,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1303,                   Accuracy: 57740/60000 (96.23%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1327,                   Accuracy: 57739/60000 (96.23%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1259,                   Accuracy: 57838/60000 (96.40%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1225,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1168,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1151,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1247,                   Accuracy: 57731/60000 (96.22%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1199,                   Accuracy: 57835/60000 (96.39%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1256,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1303,                   Accuracy: 57740/60000 (96.23%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1327,                   Accuracy: 57739/60000 (96.23%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1259,                   Accuracy: 57838/60000 (96.40%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1225,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1168,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1151,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1247,                   Accuracy: 57731/60000 (96.22%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1199,                   Accuracy: 57835/60000 (96.39%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1256,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1303,                   Accuracy: 57740/60000 (96.23%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1327,                   Accuracy: 57739/60000 (96.23%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1259,                   Accuracy: 57838/60000 (96.40%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1225,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1168,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1151,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1247,                   Accuracy: 57731/60000 (96.22%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1199,                   Accuracy: 57835/60000 (96.39%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1256,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1303,                   Accuracy: 57740/60000 (96.23%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1327,                   Accuracy: 57739/60000 (96.23%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1259,                   Accuracy: 57838/60000 (96.40%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1225,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1168,                   Accuracy: 57895/60000 (96.49%)
{0: tensor(96.5583), 10: tensor(96.2183), 20: tensor(96.3917), 30: tensor(96.2600), 40: tensor(96.2333), 50: tensor(96.2317), 60: tensor(96.3967), 70: tensor(96.4300), 80: tensor(96.4917), 90: tensor(96.5583), 100: tensor(96.2183), 110: tensor(96.3917), 120: tensor(96.2600), 130: tensor(96.2333), 140: tensor(96.2317), 150: tensor(96.3967), 160: tensor(96.4300), 170: tensor(96.4917), 180: tensor(96.5583), 190: tensor(96.2183), 200: tensor(96.3917), 210: tensor(96.2600), 220: tensor(96.2333), 230: tensor(96.2317), 240: tensor(96.3967), 250: tensor(96.4300), 260: tensor(96.4917), 270: tensor(96.5583), 280: tensor(96.2183), 290: tensor(96.3917), 300: tensor(96.2600), 310: tensor(96.2333), 320: tensor(96.2317), 330: tensor(96.3967), 340: tensor(96.4300), 350: tensor(96.4917)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=94, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 7.6753,                   Accuracy: 193/2000.0 (9.65%)



-= Testing valid =-
Test set: Average loss: 1.6932,                   Accuracy: 709/2000.0 (35.45%)



-= Testing valid =-
Test set: Average loss: 0.5809,                   Accuracy: 1675/2000.0 (83.75%)



-= Testing valid =-
Test set: Average loss: 0.5463,                   Accuracy: 1598/2000.0 (79.90%)



-= Testing valid =-
Test set: Average loss: 0.4669,                   Accuracy: 1680/2000.0 (84.00%)



-= Testing valid =-
Test set: Average loss: 0.5077,                   Accuracy: 1633/2000.0 (81.65%)



-= Testing valid =-
Test set: Average loss: 0.2790,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.1833,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.2025,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1927,                   Accuracy: 1879/2000.0 (93.95%)



Epoch 10 train accuracy: 93.20%, valid accuracy 93.95%
-= Testing valid =-
Test set: Average loss: 0.1319,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1574,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.2001,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1114,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1475,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1326,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1084,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1231,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1061,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1079,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 20 train accuracy: 95.45%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 30 train accuracy: 96.47%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0926,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 40 train accuracy: 97.25%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0754,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0790,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 50 train accuracy: 97.09%, valid accuracy 97.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1111,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1268,                   Accuracy: 57697/60000 (96.16%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1272,                   Accuracy: 57787/60000 (96.31%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1338,                   Accuracy: 57703/60000 (96.17%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1319,                   Accuracy: 57747/60000 (96.25%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1301,                   Accuracy: 57740/60000 (96.23%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1259,                   Accuracy: 57761/60000 (96.27%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1189,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1126,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1111,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1268,                   Accuracy: 57697/60000 (96.16%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1272,                   Accuracy: 57787/60000 (96.31%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1338,                   Accuracy: 57703/60000 (96.17%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1319,                   Accuracy: 57747/60000 (96.25%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1301,                   Accuracy: 57740/60000 (96.23%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1259,                   Accuracy: 57761/60000 (96.27%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1189,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1126,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1111,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1268,                   Accuracy: 57697/60000 (96.16%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1272,                   Accuracy: 57787/60000 (96.31%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1338,                   Accuracy: 57703/60000 (96.17%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1319,                   Accuracy: 57747/60000 (96.25%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1301,                   Accuracy: 57740/60000 (96.23%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1259,                   Accuracy: 57761/60000 (96.27%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1189,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1126,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1111,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1268,                   Accuracy: 57697/60000 (96.16%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1272,                   Accuracy: 57787/60000 (96.31%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1338,                   Accuracy: 57703/60000 (96.17%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1319,                   Accuracy: 57747/60000 (96.25%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1301,                   Accuracy: 57740/60000 (96.23%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1259,                   Accuracy: 57761/60000 (96.27%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1189,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1126,                   Accuracy: 58008/60000 (96.68%)
{0: tensor(96.7867), 10: tensor(96.1617), 20: tensor(96.3117), 30: tensor(96.1717), 40: tensor(96.2450), 50: tensor(96.2333), 60: tensor(96.2683), 70: tensor(96.5117), 80: tensor(96.6800), 90: tensor(96.7867), 100: tensor(96.1617), 110: tensor(96.3117), 120: tensor(96.1717), 130: tensor(96.2450), 140: tensor(96.2333), 150: tensor(96.2683), 160: tensor(96.5117), 170: tensor(96.6800), 180: tensor(96.7867), 190: tensor(96.1617), 200: tensor(96.3117), 210: tensor(96.1717), 220: tensor(96.2450), 230: tensor(96.2333), 240: tensor(96.2683), 250: tensor(96.5117), 260: tensor(96.6800), 270: tensor(96.7867), 280: tensor(96.1617), 290: tensor(96.3117), 300: tensor(96.1717), 310: tensor(96.2450), 320: tensor(96.2333), 330: tensor(96.2683), 340: tensor(96.5117), 350: tensor(96.6800)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=95, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0779,                   Accuracy: 402/2000.0 (20.10%)



-= Testing valid =-
Test set: Average loss: 2.2174,                   Accuracy: 509/2000.0 (25.45%)



-= Testing valid =-
Test set: Average loss: 1.5243,                   Accuracy: 1195/2000.0 (59.75%)



-= Testing valid =-
Test set: Average loss: 0.8596,                   Accuracy: 1304/2000.0 (65.20%)



-= Testing valid =-
Test set: Average loss: 0.4561,                   Accuracy: 1742/2000.0 (87.10%)



-= Testing valid =-
Test set: Average loss: 0.2575,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2459,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2243,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.1879,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.2029,                   Accuracy: 1870/2000.0 (93.50%)



Epoch 10 train accuracy: 93.09%, valid accuracy 93.50%
-= Testing valid =-
Test set: Average loss: 0.1584,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1511,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1185,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1396,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1276,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1231,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1487,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1289,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1289,                   Accuracy: 1923/2000.0 (96.15%)



Epoch 20 train accuracy: 95.18%, valid accuracy 96.15%
-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1112,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1147,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 30 train accuracy: 96.05%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 40 train accuracy: 96.97%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0750,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0790,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 50 train accuracy: 97.10%, valid accuracy 97.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1146,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1207,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1156,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1176,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1176,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1188,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1178,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1157,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1146,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1146,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1207,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1156,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1176,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1176,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1188,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1178,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1157,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1146,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1146,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1207,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1156,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1176,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1176,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1188,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1178,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1157,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1146,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1146,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1207,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1156,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1176,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1176,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1188,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1178,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1157,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1146,                   Accuracy: 57936/60000 (96.56%)
{0: tensor(96.6417), 10: tensor(96.4400), 20: tensor(96.5717), 30: tensor(96.5450), 40: tensor(96.5617), 50: tensor(96.5950), 60: tensor(96.5683), 70: tensor(96.5283), 80: tensor(96.5600), 90: tensor(96.6417), 100: tensor(96.4400), 110: tensor(96.5717), 120: tensor(96.5450), 130: tensor(96.5617), 140: tensor(96.5950), 150: tensor(96.5683), 160: tensor(96.5283), 170: tensor(96.5600), 180: tensor(96.6417), 190: tensor(96.4400), 200: tensor(96.5717), 210: tensor(96.5450), 220: tensor(96.5617), 230: tensor(96.5950), 240: tensor(96.5683), 250: tensor(96.5283), 260: tensor(96.5600), 270: tensor(96.6417), 280: tensor(96.4400), 290: tensor(96.5717), 300: tensor(96.5450), 310: tensor(96.5617), 320: tensor(96.5950), 330: tensor(96.5683), 340: tensor(96.5283), 350: tensor(96.5600)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=96, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3593,                   Accuracy: 318/2000.0 (15.90%)



-= Testing valid =-
Test set: Average loss: 1.4045,                   Accuracy: 1048/2000.0 (52.40%)



-= Testing valid =-
Test set: Average loss: 0.8067,                   Accuracy: 1572/2000.0 (78.60%)



-= Testing valid =-
Test set: Average loss: 0.9742,                   Accuracy: 1296/2000.0 (64.80%)



-= Testing valid =-
Test set: Average loss: 0.7244,                   Accuracy: 1544/2000.0 (77.20%)



-= Testing valid =-
Test set: Average loss: 0.5460,                   Accuracy: 1682/2000.0 (84.10%)



-= Testing valid =-
Test set: Average loss: 0.3249,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.2745,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2004,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.2488,                   Accuracy: 1839/2000.0 (91.95%)



Epoch 10 train accuracy: 93.86%, valid accuracy 91.95%
-= Testing valid =-
Test set: Average loss: 0.1353,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1232,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1709,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1337,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1336,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1504,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1483,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1185,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1423,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1252,                   Accuracy: 1910/2000.0 (95.50%)



Epoch 20 train accuracy: 95.36%, valid accuracy 95.50%
-= Testing valid =-
Test set: Average loss: 0.1291,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1053,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1105,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1003,                   Accuracy: 1923/2000.0 (96.15%)



Epoch 30 train accuracy: 96.45%, valid accuracy 96.15%
-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0919,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 40 train accuracy: 97.06%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0802,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0738,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 50 train accuracy: 97.30%, valid accuracy 97.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1057,                   Accuracy: 58142/60000 (96.90%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1122,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1122,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1107,                   Accuracy: 57990/60000 (96.65%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1091,                   Accuracy: 58007/60000 (96.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1080,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1044,                   Accuracy: 58200/60000 (97.00%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1037,                   Accuracy: 58197/60000 (97.00%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1042,                   Accuracy: 58185/60000 (96.97%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1057,                   Accuracy: 58142/60000 (96.90%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1122,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1122,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1107,                   Accuracy: 57990/60000 (96.65%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1091,                   Accuracy: 58007/60000 (96.68%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1080,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1044,                   Accuracy: 58200/60000 (97.00%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1037,                   Accuracy: 58197/60000 (97.00%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1042,                   Accuracy: 58185/60000 (96.97%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1057,                   Accuracy: 58142/60000 (96.90%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1122,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1122,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1107,                   Accuracy: 57990/60000 (96.65%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1091,                   Accuracy: 58007/60000 (96.68%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1080,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1044,                   Accuracy: 58200/60000 (97.00%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1037,                   Accuracy: 58197/60000 (97.00%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1042,                   Accuracy: 58185/60000 (96.97%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1057,                   Accuracy: 58142/60000 (96.90%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1122,                   Accuracy: 57992/60000 (96.65%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1122,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1107,                   Accuracy: 57990/60000 (96.65%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1091,                   Accuracy: 58007/60000 (96.68%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1080,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1044,                   Accuracy: 58200/60000 (97.00%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1037,                   Accuracy: 58197/60000 (97.00%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1042,                   Accuracy: 58185/60000 (96.97%)
{0: tensor(96.9033), 10: tensor(96.6533), 20: tensor(96.6767), 30: tensor(96.6500), 40: tensor(96.6783), 50: tensor(96.8383), 60: tensor(97.), 70: tensor(96.9950), 80: tensor(96.9750), 90: tensor(96.9033), 100: tensor(96.6533), 110: tensor(96.6767), 120: tensor(96.6500), 130: tensor(96.6783), 140: tensor(96.8383), 150: tensor(97.), 160: tensor(96.9950), 170: tensor(96.9750), 180: tensor(96.9033), 190: tensor(96.6533), 200: tensor(96.6767), 210: tensor(96.6500), 220: tensor(96.6783), 230: tensor(96.8383), 240: tensor(97.), 250: tensor(96.9950), 260: tensor(96.9750), 270: tensor(96.9033), 280: tensor(96.6533), 290: tensor(96.6767), 300: tensor(96.6500), 310: tensor(96.6783), 320: tensor(96.8383), 330: tensor(97.), 340: tensor(96.9950), 350: tensor(96.9750)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=97, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0750,                   Accuracy: 488/2000.0 (24.40%)



-= Testing valid =-
Test set: Average loss: 1.8790,                   Accuracy: 737/2000.0 (36.85%)



-= Testing valid =-
Test set: Average loss: 0.6978,                   Accuracy: 1568/2000.0 (78.40%)



-= Testing valid =-
Test set: Average loss: 0.6425,                   Accuracy: 1551/2000.0 (77.55%)



-= Testing valid =-
Test set: Average loss: 0.2803,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2592,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.4074,                   Accuracy: 1749/2000.0 (87.45%)



-= Testing valid =-
Test set: Average loss: 0.3708,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.2085,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.1655,                   Accuracy: 1905/2000.0 (95.25%)



Epoch 10 train accuracy: 93.84%, valid accuracy 95.25%
-= Testing valid =-
Test set: Average loss: 0.1394,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1470,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1638,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1139,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1242,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1487,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1558,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1129,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1246,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1120,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 20 train accuracy: 95.93%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0956,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 30 train accuracy: 96.80%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0780,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 40 train accuracy: 96.94%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0807,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0798,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 50 train accuracy: 97.29%, valid accuracy 97.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0987,                   Accuracy: 58284/60000 (97.14%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1062,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1022,                   Accuracy: 58173/60000 (96.96%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1075,                   Accuracy: 58091/60000 (96.82%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1100,                   Accuracy: 58073/60000 (96.79%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1106,                   Accuracy: 58067/60000 (96.78%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1055,                   Accuracy: 58149/60000 (96.92%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1019,                   Accuracy: 58203/60000 (97.00%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1000,                   Accuracy: 58254/60000 (97.09%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0987,                   Accuracy: 58284/60000 (97.14%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1062,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1022,                   Accuracy: 58173/60000 (96.96%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1075,                   Accuracy: 58091/60000 (96.82%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1100,                   Accuracy: 58073/60000 (96.79%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1106,                   Accuracy: 58067/60000 (96.78%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1055,                   Accuracy: 58149/60000 (96.92%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1019,                   Accuracy: 58203/60000 (97.00%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1000,                   Accuracy: 58254/60000 (97.09%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0987,                   Accuracy: 58284/60000 (97.14%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1062,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1022,                   Accuracy: 58173/60000 (96.96%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1075,                   Accuracy: 58091/60000 (96.82%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1100,                   Accuracy: 58073/60000 (96.79%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1106,                   Accuracy: 58067/60000 (96.78%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1055,                   Accuracy: 58149/60000 (96.92%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1019,                   Accuracy: 58203/60000 (97.00%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1000,                   Accuracy: 58254/60000 (97.09%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0987,                   Accuracy: 58284/60000 (97.14%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1062,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1022,                   Accuracy: 58173/60000 (96.96%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1075,                   Accuracy: 58091/60000 (96.82%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1100,                   Accuracy: 58073/60000 (96.79%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1106,                   Accuracy: 58067/60000 (96.78%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1055,                   Accuracy: 58149/60000 (96.92%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1019,                   Accuracy: 58203/60000 (97.00%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1000,                   Accuracy: 58254/60000 (97.09%)
{0: tensor(97.1400), 10: tensor(96.8217), 20: tensor(96.9550), 30: tensor(96.8183), 40: tensor(96.7883), 50: tensor(96.7783), 60: tensor(96.9150), 70: tensor(97.0050), 80: tensor(97.0900), 90: tensor(97.1400), 100: tensor(96.8217), 110: tensor(96.9550), 120: tensor(96.8183), 130: tensor(96.7883), 140: tensor(96.7783), 150: tensor(96.9150), 160: tensor(97.0050), 170: tensor(97.0900), 180: tensor(97.1400), 190: tensor(96.8217), 200: tensor(96.9550), 210: tensor(96.8183), 220: tensor(96.7883), 230: tensor(96.7783), 240: tensor(96.9150), 250: tensor(97.0050), 260: tensor(97.0900), 270: tensor(97.1400), 280: tensor(96.8217), 290: tensor(96.9550), 300: tensor(96.8183), 310: tensor(96.7883), 320: tensor(96.7783), 330: tensor(96.9150), 340: tensor(97.0050), 350: tensor(97.0900)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=98, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 11.0640,                   Accuracy: 219/2000.0 (10.95%)



-= Testing valid =-
Test set: Average loss: 3.0983,                   Accuracy: 297/2000.0 (14.85%)



-= Testing valid =-
Test set: Average loss: 1.5710,                   Accuracy: 912/2000.0 (45.60%)



-= Testing valid =-
Test set: Average loss: 1.5767,                   Accuracy: 1050/2000.0 (52.50%)



-= Testing valid =-
Test set: Average loss: 0.6112,                   Accuracy: 1648/2000.0 (82.40%)



-= Testing valid =-
Test set: Average loss: 0.6789,                   Accuracy: 1547/2000.0 (77.35%)



-= Testing valid =-
Test set: Average loss: 0.5632,                   Accuracy: 1658/2000.0 (82.90%)



-= Testing valid =-
Test set: Average loss: 0.2676,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.4007,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.2106,                   Accuracy: 1865/2000.0 (93.25%)



Epoch 10 train accuracy: 92.85%, valid accuracy 93.25%
-= Testing valid =-
Test set: Average loss: 0.1916,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1631,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1512,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1618,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1633,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1785,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1621,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1335,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1371,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1950,                   Accuracy: 1887/2000.0 (94.35%)



Epoch 20 train accuracy: 95.46%, valid accuracy 94.35%
-= Testing valid =-
Test set: Average loss: 0.1268,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1322,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1292,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1353,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1300,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1338,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1233,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1213,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1053,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 30 train accuracy: 96.41%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.1057,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1128,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1242,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1104,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1094,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1128,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1135,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 40 train accuracy: 97.01%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1107,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 50 train accuracy: 97.12%, valid accuracy 97.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1230,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1319,                   Accuracy: 57740/60000 (96.23%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1307,                   Accuracy: 57789/60000 (96.32%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1316,                   Accuracy: 57721/60000 (96.20%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1293,                   Accuracy: 57735/60000 (96.22%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1245,                   Accuracy: 57833/60000 (96.39%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1194,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1211,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1239,                   Accuracy: 57815/60000 (96.36%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1230,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1319,                   Accuracy: 57740/60000 (96.23%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1307,                   Accuracy: 57789/60000 (96.32%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1316,                   Accuracy: 57721/60000 (96.20%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1293,                   Accuracy: 57735/60000 (96.22%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1245,                   Accuracy: 57833/60000 (96.39%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1194,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1211,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1239,                   Accuracy: 57815/60000 (96.36%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1230,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1319,                   Accuracy: 57740/60000 (96.23%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1307,                   Accuracy: 57789/60000 (96.32%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1316,                   Accuracy: 57721/60000 (96.20%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1293,                   Accuracy: 57735/60000 (96.22%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1245,                   Accuracy: 57833/60000 (96.39%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1194,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1211,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1239,                   Accuracy: 57815/60000 (96.36%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1230,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1319,                   Accuracy: 57740/60000 (96.23%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1307,                   Accuracy: 57789/60000 (96.32%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1316,                   Accuracy: 57721/60000 (96.20%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1293,                   Accuracy: 57735/60000 (96.22%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1245,                   Accuracy: 57833/60000 (96.39%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1194,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1211,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1239,                   Accuracy: 57815/60000 (96.36%)
{0: tensor(96.5250), 10: tensor(96.2333), 20: tensor(96.3150), 30: tensor(96.2017), 40: tensor(96.2250), 50: tensor(96.3883), 60: tensor(96.5933), 70: tensor(96.4817), 80: tensor(96.3583), 90: tensor(96.5250), 100: tensor(96.2333), 110: tensor(96.3150), 120: tensor(96.2017), 130: tensor(96.2250), 140: tensor(96.3883), 150: tensor(96.5933), 160: tensor(96.4817), 170: tensor(96.3583), 180: tensor(96.5250), 190: tensor(96.2333), 200: tensor(96.3150), 210: tensor(96.2017), 220: tensor(96.2250), 230: tensor(96.3883), 240: tensor(96.5933), 250: tensor(96.4817), 260: tensor(96.3583), 270: tensor(96.5250), 280: tensor(96.2333), 290: tensor(96.3150), 300: tensor(96.2017), 310: tensor(96.2250), 320: tensor(96.3883), 330: tensor(96.5933), 340: tensor(96.4817), 350: tensor(96.3583)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=99, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 11.7562,                   Accuracy: 196/2000.0 (9.80%)



-= Testing valid =-
Test set: Average loss: 1.5341,                   Accuracy: 845/2000.0 (42.25%)



-= Testing valid =-
Test set: Average loss: 1.5948,                   Accuracy: 959/2000.0 (47.95%)



-= Testing valid =-
Test set: Average loss: 0.7653,                   Accuracy: 1453/2000.0 (72.65%)



-= Testing valid =-
Test set: Average loss: 0.6554,                   Accuracy: 1590/2000.0 (79.50%)



-= Testing valid =-
Test set: Average loss: 0.3117,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.3597,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.4904,                   Accuracy: 1679/2000.0 (83.95%)



-= Testing valid =-
Test set: Average loss: 0.2731,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.1645,                   Accuracy: 1895/2000.0 (94.75%)



Epoch 10 train accuracy: 94.12%, valid accuracy 94.75%
-= Testing valid =-
Test set: Average loss: 0.1421,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1445,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1569,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1176,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1067,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1070,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1361,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1093,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1368,                   Accuracy: 1917/2000.0 (95.85%)



Epoch 20 train accuracy: 95.96%, valid accuracy 95.85%
-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1085,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1017,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 30 train accuracy: 96.62%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 40 train accuracy: 97.39%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0734,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0790,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 50 train accuracy: 97.29%, valid accuracy 97.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1048,                   Accuracy: 58181/60000 (96.97%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1089,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1044,                   Accuracy: 58213/60000 (97.02%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1044,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1057,                   Accuracy: 58157/60000 (96.93%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1069,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1050,                   Accuracy: 58154/60000 (96.92%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1057,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1040,                   Accuracy: 58166/60000 (96.94%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1048,                   Accuracy: 58181/60000 (96.97%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1089,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1044,                   Accuracy: 58213/60000 (97.02%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1044,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1057,                   Accuracy: 58157/60000 (96.93%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1069,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1050,                   Accuracy: 58154/60000 (96.92%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1057,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1040,                   Accuracy: 58166/60000 (96.94%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1048,                   Accuracy: 58181/60000 (96.97%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1089,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1044,                   Accuracy: 58213/60000 (97.02%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1044,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1057,                   Accuracy: 58157/60000 (96.93%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1069,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1050,                   Accuracy: 58154/60000 (96.92%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1057,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1040,                   Accuracy: 58166/60000 (96.94%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1048,                   Accuracy: 58181/60000 (96.97%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1089,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1044,                   Accuracy: 58213/60000 (97.02%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1044,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1057,                   Accuracy: 58157/60000 (96.93%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1069,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1050,                   Accuracy: 58154/60000 (96.92%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1057,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1040,                   Accuracy: 58166/60000 (96.94%)
{0: tensor(96.9683), 10: tensor(96.8167), 20: tensor(97.0217), 30: tensor(96.9417), 40: tensor(96.9283), 50: tensor(96.8533), 60: tensor(96.9233), 70: tensor(96.9100), 80: tensor(96.9433), 90: tensor(96.9683), 100: tensor(96.8167), 110: tensor(97.0217), 120: tensor(96.9417), 130: tensor(96.9283), 140: tensor(96.8533), 150: tensor(96.9233), 160: tensor(96.9100), 170: tensor(96.9433), 180: tensor(96.9683), 190: tensor(96.8167), 200: tensor(97.0217), 210: tensor(96.9417), 220: tensor(96.9283), 230: tensor(96.8533), 240: tensor(96.9233), 250: tensor(96.9100), 260: tensor(96.9433), 270: tensor(96.9683), 280: tensor(96.8167), 290: tensor(97.0217), 300: tensor(96.9417), 310: tensor(96.9283), 320: tensor(96.8533), 330: tensor(96.9233), 340: tensor(96.9100), 350: tensor(96.9433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=100, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 28, 28]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 28, 28]      20
├─Dropout: 1-3                           [256, 10, 4, 28, 28]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 28, 28]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 28, 28]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.82
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 405.20
Params size (MB): 0.10
Estimated Total Size (MB): 407.71
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0297,                   Accuracy: 440/2000.0 (22.00%)



-= Testing valid =-
Test set: Average loss: 2.1203,                   Accuracy: 525/2000.0 (26.25%)



-= Testing valid =-
Test set: Average loss: 1.9123,                   Accuracy: 813/2000.0 (40.65%)



-= Testing valid =-
Test set: Average loss: 0.6358,                   Accuracy: 1570/2000.0 (78.50%)



-= Testing valid =-
Test set: Average loss: 0.8327,                   Accuracy: 1371/2000.0 (68.55%)



-= Testing valid =-
Test set: Average loss: 0.2756,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.2346,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.4172,                   Accuracy: 1732/2000.0 (86.60%)



-= Testing valid =-
Test set: Average loss: 0.1669,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.2260,                   Accuracy: 1862/2000.0 (93.10%)



Epoch 10 train accuracy: 94.24%, valid accuracy 93.10%
-= Testing valid =-
Test set: Average loss: 0.1439,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1412,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1394,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1395,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1136,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1120,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1492,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1221,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 20 train accuracy: 96.06%, valid accuracy 96.45%
-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1068,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1069,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1172,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0947,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 30 train accuracy: 96.97%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 40 train accuracy: 97.11%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 50 train accuracy: 97.41%, valid accuracy 97.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1063,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1181,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1074,                   Accuracy: 58077/60000 (96.79%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1110,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1136,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1176,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1191,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1176,                   Accuracy: 57856/60000 (96.43%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1141,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1063,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1181,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1074,                   Accuracy: 58077/60000 (96.79%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1110,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1136,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1176,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1191,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1176,                   Accuracy: 57856/60000 (96.43%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1141,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1063,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1181,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1074,                   Accuracy: 58077/60000 (96.79%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1110,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1136,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1176,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1191,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1176,                   Accuracy: 57856/60000 (96.43%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1141,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1063,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1181,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1074,                   Accuracy: 58077/60000 (96.79%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1110,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1136,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1176,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1191,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1176,                   Accuracy: 57856/60000 (96.43%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1141,                   Accuracy: 57936/60000 (96.56%)
{0: tensor(96.8483), 10: tensor(96.4467), 20: tensor(96.7950), 30: tensor(96.5783), 40: tensor(96.5533), 50: tensor(96.4483), 60: tensor(96.3567), 70: tensor(96.4267), 80: tensor(96.5600), 90: tensor(96.8483), 100: tensor(96.4467), 110: tensor(96.7950), 120: tensor(96.5783), 130: tensor(96.5533), 140: tensor(96.4483), 150: tensor(96.3567), 160: tensor(96.4267), 170: tensor(96.5600), 180: tensor(96.8483), 190: tensor(96.4467), 200: tensor(96.7950), 210: tensor(96.5783), 220: tensor(96.5533), 230: tensor(96.4483), 240: tensor(96.3567), 250: tensor(96.4267), 260: tensor(96.5600), 270: tensor(96.8483), 280: tensor(96.4467), 290: tensor(96.7950), 300: tensor(96.5783), 310: tensor(96.5533), 320: tensor(96.4483), 330: tensor(96.3567), 340: tensor(96.4267), 350: tensor(96.5600)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=71, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0244,                   Accuracy: 298/2000.0 (14.90%)



-= Testing valid =-
Test set: Average loss: 1.4708,                   Accuracy: 957/2000.0 (47.85%)



-= Testing valid =-
Test set: Average loss: 1.6492,                   Accuracy: 991/2000.0 (49.55%)



-= Testing valid =-
Test set: Average loss: 0.8798,                   Accuracy: 1417/2000.0 (70.85%)



-= Testing valid =-
Test set: Average loss: 0.3876,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.3049,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2325,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.2783,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2328,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.1862,                   Accuracy: 1887/2000.0 (94.35%)



Epoch 10 train accuracy: 94.19%, valid accuracy 94.35%
-= Testing valid =-
Test set: Average loss: 0.1257,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1572,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1475,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1145,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1112,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1902,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1231,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1603,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1293,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1544,                   Accuracy: 1902/2000.0 (95.10%)



Epoch 20 train accuracy: 96.03%, valid accuracy 95.10%
-= Testing valid =-
Test set: Average loss: 0.1089,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1307,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1117,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1177,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0986,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1263,                   Accuracy: 1910/2000.0 (95.50%)



Epoch 30 train accuracy: 97.18%, valid accuracy 95.50%
-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1012,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1083,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 40 train accuracy: 97.10%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0919,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 50 train accuracy: 97.50%, valid accuracy 97.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1059,                   Accuracy: 58190/60000 (96.98%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1293,                   Accuracy: 57699/60000 (96.17%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1244,                   Accuracy: 57837/60000 (96.39%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1166,                   Accuracy: 57978/60000 (96.63%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1135,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1124,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1098,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1137,                   Accuracy: 58012/60000 (96.69%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1145,                   Accuracy: 58007/60000 (96.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1066,                   Accuracy: 58158/60000 (96.93%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1318,                   Accuracy: 57663/60000 (96.11%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1223,                   Accuracy: 57838/60000 (96.40%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1143,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1131,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1123,                   Accuracy: 58022/60000 (96.70%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1090,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1134,                   Accuracy: 58028/60000 (96.71%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1173,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1052,                   Accuracy: 58157/60000 (96.93%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1225,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1170,                   Accuracy: 57975/60000 (96.62%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1117,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1116,                   Accuracy: 58080/60000 (96.80%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1108,                   Accuracy: 58042/60000 (96.74%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1087,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1111,                   Accuracy: 58073/60000 (96.79%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1176,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1043,                   Accuracy: 58197/60000 (97.00%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1206,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1188,                   Accuracy: 57925/60000 (96.54%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1138,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1114,                   Accuracy: 58066/60000 (96.78%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1104,                   Accuracy: 58077/60000 (96.79%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1083,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1125,                   Accuracy: 58042/60000 (96.74%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1155,                   Accuracy: 58015/60000 (96.69%)
{0: tensor(96.9833), 10: tensor(96.1650), 20: tensor(96.3950), 30: tensor(96.6300), 40: tensor(96.6800), 50: tensor(96.7300), 60: tensor(96.7967), 70: tensor(96.6867), 80: tensor(96.6783), 90: tensor(96.9300), 100: tensor(96.1050), 110: tensor(96.3967), 120: tensor(96.7117), 130: tensor(96.7333), 140: tensor(96.7033), 150: tensor(96.8083), 160: tensor(96.7133), 170: tensor(96.6017), 180: tensor(96.9283), 190: tensor(96.4117), 200: tensor(96.6250), 210: tensor(96.7717), 220: tensor(96.8000), 230: tensor(96.7367), 240: tensor(96.8133), 250: tensor(96.7883), 260: tensor(96.5800), 270: tensor(96.9950), 280: tensor(96.5217), 290: tensor(96.5417), 300: tensor(96.6750), 310: tensor(96.7767), 320: tensor(96.7950), 330: tensor(96.8533), 340: tensor(96.7367), 350: tensor(96.6917)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=72, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9139,                   Accuracy: 495/2000.0 (24.75%)



-= Testing valid =-
Test set: Average loss: 4.1837,                   Accuracy: 464/2000.0 (23.20%)



-= Testing valid =-
Test set: Average loss: 0.7550,                   Accuracy: 1521/2000.0 (76.05%)



-= Testing valid =-
Test set: Average loss: 0.6802,                   Accuracy: 1534/2000.0 (76.70%)



-= Testing valid =-
Test set: Average loss: 1.1576,                   Accuracy: 1345/2000.0 (67.25%)



-= Testing valid =-
Test set: Average loss: 0.4006,                   Accuracy: 1742/2000.0 (87.10%)



-= Testing valid =-
Test set: Average loss: 0.2887,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.3198,                   Accuracy: 1777/2000.0 (88.85%)



-= Testing valid =-
Test set: Average loss: 0.4187,                   Accuracy: 1728/2000.0 (86.40%)



-= Testing valid =-
Test set: Average loss: 0.2828,                   Accuracy: 1820/2000.0 (91.00%)



Epoch 10 train accuracy: 92.86%, valid accuracy 91.00%
-= Testing valid =-
Test set: Average loss: 0.1604,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.2186,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.1571,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1222,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1305,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1757,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.2177,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1677,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1219,                   Accuracy: 1925/2000.0 (96.25%)



Epoch 20 train accuracy: 95.84%, valid accuracy 96.25%
-= Testing valid =-
Test set: Average loss: 0.1230,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1162,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1051,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1068,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1364,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 30 train accuracy: 96.55%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 40 train accuracy: 96.86%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 50 train accuracy: 97.09%, valid accuracy 97.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1083,                   Accuracy: 58069/60000 (96.78%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1215,                   Accuracy: 57817/60000 (96.36%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1194,                   Accuracy: 57857/60000 (96.43%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1192,                   Accuracy: 57914/60000 (96.52%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1142,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1089,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1067,                   Accuracy: 58117/60000 (96.86%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1090,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1161,                   Accuracy: 57881/60000 (96.47%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1102,                   Accuracy: 58029/60000 (96.71%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1227,                   Accuracy: 57746/60000 (96.24%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1214,                   Accuracy: 57803/60000 (96.34%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1224,                   Accuracy: 57818/60000 (96.36%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1184,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1145,                   Accuracy: 57940/60000 (96.57%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1131,                   Accuracy: 57918/60000 (96.53%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1141,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1259,                   Accuracy: 57593/60000 (95.99%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1139,                   Accuracy: 57888/60000 (96.48%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1289,                   Accuracy: 57567/60000 (95.94%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1234,                   Accuracy: 57728/60000 (96.21%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1218,                   Accuracy: 57810/60000 (96.35%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1161,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1143,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1111,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1118,                   Accuracy: 57916/60000 (96.53%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1185,                   Accuracy: 57781/60000 (96.30%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1110,                   Accuracy: 57982/60000 (96.64%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1266,                   Accuracy: 57662/60000 (96.10%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1189,                   Accuracy: 57853/60000 (96.42%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1183,                   Accuracy: 57898/60000 (96.50%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1120,                   Accuracy: 58031/60000 (96.72%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1080,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1051,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1078,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1104,                   Accuracy: 58030/60000 (96.72%)
{0: tensor(96.7817), 10: tensor(96.3617), 20: tensor(96.4283), 30: tensor(96.5233), 40: tensor(96.6233), 50: tensor(96.7400), 60: tensor(96.8617), 70: tensor(96.6833), 80: tensor(96.4683), 90: tensor(96.7150), 100: tensor(96.2433), 110: tensor(96.3383), 120: tensor(96.3633), 130: tensor(96.4600), 140: tensor(96.5667), 150: tensor(96.5300), 160: tensor(96.4750), 170: tensor(95.9883), 180: tensor(96.4800), 190: tensor(95.9450), 200: tensor(96.2133), 210: tensor(96.3500), 220: tensor(96.5783), 230: tensor(96.6167), 240: tensor(96.6333), 250: tensor(96.5267), 260: tensor(96.3017), 270: tensor(96.6367), 280: tensor(96.1033), 290: tensor(96.4217), 300: tensor(96.4967), 310: tensor(96.7183), 320: tensor(96.7667), 330: tensor(96.8683), 340: tensor(96.7300), 350: tensor(96.7167)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=73, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8660,                   Accuracy: 615/2000.0 (30.75%)



-= Testing valid =-
Test set: Average loss: 3.0825,                   Accuracy: 375/2000.0 (18.75%)



-= Testing valid =-
Test set: Average loss: 2.6672,                   Accuracy: 453/2000.0 (22.65%)



-= Testing valid =-
Test set: Average loss: 0.5535,                   Accuracy: 1638/2000.0 (81.90%)



-= Testing valid =-
Test set: Average loss: 0.3677,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.3087,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.1972,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.2256,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.1648,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.2268,                   Accuracy: 1855/2000.0 (92.75%)



Epoch 10 train accuracy: 93.68%, valid accuracy 92.75%
-= Testing valid =-
Test set: Average loss: 0.1601,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1327,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1207,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.2048,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1300,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1196,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1244,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1351,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1185,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 20 train accuracy: 95.57%, valid accuracy 96.45%
-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1079,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 30 train accuracy: 96.35%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 40 train accuracy: 97.09%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0719,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0807,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0672,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0698,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 50 train accuracy: 97.35%, valid accuracy 97.75%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0952,                   Accuracy: 58341/60000 (97.24%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1037,                   Accuracy: 58148/60000 (96.91%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0997,                   Accuracy: 58203/60000 (97.00%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1013,                   Accuracy: 58245/60000 (97.07%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1029,                   Accuracy: 58152/60000 (96.92%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1034,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1054,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1058,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1083,                   Accuracy: 58076/60000 (96.79%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0996,                   Accuracy: 58197/60000 (97.00%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1090,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1036,                   Accuracy: 58150/60000 (96.92%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1050,                   Accuracy: 58139/60000 (96.90%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1071,                   Accuracy: 58062/60000 (96.77%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1087,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1087,                   Accuracy: 57997/60000 (96.66%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1083,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1128,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1029,                   Accuracy: 58124/60000 (96.87%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1077,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1029,                   Accuracy: 58139/60000 (96.90%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1048,                   Accuracy: 58133/60000 (96.89%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1053,                   Accuracy: 58129/60000 (96.88%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1042,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1029,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1029,                   Accuracy: 58153/60000 (96.92%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1053,                   Accuracy: 58079/60000 (96.80%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0962,                   Accuracy: 58279/60000 (97.13%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1024,                   Accuracy: 58181/60000 (96.97%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0983,                   Accuracy: 58243/60000 (97.07%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1000,                   Accuracy: 58251/60000 (97.08%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1012,                   Accuracy: 58204/60000 (97.01%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.0999,                   Accuracy: 58229/60000 (97.05%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1006,                   Accuracy: 58189/60000 (96.98%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1010,                   Accuracy: 58204/60000 (97.01%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1033,                   Accuracy: 58160/60000 (96.93%)
{0: tensor(97.2350), 10: tensor(96.9133), 20: tensor(97.0050), 30: tensor(97.0750), 40: tensor(96.9200), 50: tensor(96.9500), 60: tensor(96.8450), 70: tensor(96.8800), 80: tensor(96.7933), 90: tensor(96.9950), 100: tensor(96.6267), 110: tensor(96.9167), 120: tensor(96.8983), 130: tensor(96.7700), 140: tensor(96.7550), 150: tensor(96.6617), 160: tensor(96.7500), 170: tensor(96.5250), 180: tensor(96.8733), 190: tensor(96.7117), 200: tensor(96.8983), 210: tensor(96.8883), 220: tensor(96.8817), 230: tensor(96.9100), 240: tensor(96.8800), 250: tensor(96.9217), 260: tensor(96.7983), 270: tensor(97.1317), 280: tensor(96.9683), 290: tensor(97.0717), 300: tensor(97.0850), 310: tensor(97.0067), 320: tensor(97.0483), 330: tensor(96.9817), 340: tensor(97.0067), 350: tensor(96.9333)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=74, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.3875,                   Accuracy: 193/2000.0 (9.65%)



-= Testing valid =-
Test set: Average loss: 1.3463,                   Accuracy: 1004/2000.0 (50.20%)



-= Testing valid =-
Test set: Average loss: 1.0509,                   Accuracy: 1274/2000.0 (63.70%)



-= Testing valid =-
Test set: Average loss: 0.6572,                   Accuracy: 1623/2000.0 (81.15%)



-= Testing valid =-
Test set: Average loss: 0.5863,                   Accuracy: 1553/2000.0 (77.65%)



-= Testing valid =-
Test set: Average loss: 0.2441,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2721,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.3732,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.1504,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.2192,                   Accuracy: 1864/2000.0 (93.20%)



Epoch 10 train accuracy: 93.79%, valid accuracy 93.20%
-= Testing valid =-
Test set: Average loss: 0.1622,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1151,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1668,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1610,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1249,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1657,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1305,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1433,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1179,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1442,                   Accuracy: 1896/2000.0 (94.80%)



Epoch 20 train accuracy: 96.15%, valid accuracy 94.80%
-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1174,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1169,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.0712,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 30 train accuracy: 96.62%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0659,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 40 train accuracy: 97.15%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0665,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0691,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0606,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0646,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0652,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 50 train accuracy: 97.46%, valid accuracy 97.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0963,                   Accuracy: 58259/60000 (97.10%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1073,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0970,                   Accuracy: 58193/60000 (96.99%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0933,                   Accuracy: 58292/60000 (97.15%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0911,                   Accuracy: 58338/60000 (97.23%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0912,                   Accuracy: 58344/60000 (97.24%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0930,                   Accuracy: 58314/60000 (97.19%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0947,                   Accuracy: 58265/60000 (97.11%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1009,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0937,                   Accuracy: 58312/60000 (97.19%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1049,                   Accuracy: 58057/60000 (96.76%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.0940,                   Accuracy: 58284/60000 (97.14%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.0909,                   Accuracy: 58301/60000 (97.17%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.0893,                   Accuracy: 58374/60000 (97.29%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.0892,                   Accuracy: 58350/60000 (97.25%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.0911,                   Accuracy: 58343/60000 (97.24%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.0919,                   Accuracy: 58305/60000 (97.18%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.0998,                   Accuracy: 58131/60000 (96.89%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0908,                   Accuracy: 58335/60000 (97.22%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1000,                   Accuracy: 58143/60000 (96.90%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.0933,                   Accuracy: 58280/60000 (97.13%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.0920,                   Accuracy: 58272/60000 (97.12%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.0895,                   Accuracy: 58363/60000 (97.27%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.0900,                   Accuracy: 58336/60000 (97.23%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.0923,                   Accuracy: 58303/60000 (97.17%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.0926,                   Accuracy: 58294/60000 (97.16%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1006,                   Accuracy: 58149/60000 (96.92%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0921,                   Accuracy: 58317/60000 (97.19%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1009,                   Accuracy: 58144/60000 (96.91%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0957,                   Accuracy: 58207/60000 (97.01%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.0939,                   Accuracy: 58232/60000 (97.05%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.0914,                   Accuracy: 58324/60000 (97.21%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.0925,                   Accuracy: 58287/60000 (97.14%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0960,                   Accuracy: 58240/60000 (97.07%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0977,                   Accuracy: 58210/60000 (97.02%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1036,                   Accuracy: 58094/60000 (96.82%)
{0: tensor(97.0983), 10: tensor(96.6733), 20: tensor(96.9883), 30: tensor(97.1533), 40: tensor(97.2300), 50: tensor(97.2400), 60: tensor(97.1900), 70: tensor(97.1083), 80: tensor(96.8717), 90: tensor(97.1867), 100: tensor(96.7617), 110: tensor(97.1400), 120: tensor(97.1683), 130: tensor(97.2900), 140: tensor(97.2500), 150: tensor(97.2383), 160: tensor(97.1750), 170: tensor(96.8850), 180: tensor(97.2250), 190: tensor(96.9050), 200: tensor(97.1333), 210: tensor(97.1200), 220: tensor(97.2717), 230: tensor(97.2267), 240: tensor(97.1717), 250: tensor(97.1567), 260: tensor(96.9150), 270: tensor(97.1950), 280: tensor(96.9067), 290: tensor(97.0117), 300: tensor(97.0533), 310: tensor(97.2067), 320: tensor(97.1450), 330: tensor(97.0667), 340: tensor(97.0167), 350: tensor(96.8233)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=75, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.0648,                   Accuracy: 216/2000.0 (10.80%)



-= Testing valid =-
Test set: Average loss: 4.0336,                   Accuracy: 375/2000.0 (18.75%)



-= Testing valid =-
Test set: Average loss: 1.7067,                   Accuracy: 764/2000.0 (38.20%)



-= Testing valid =-
Test set: Average loss: 1.1946,                   Accuracy: 1129/2000.0 (56.45%)



-= Testing valid =-
Test set: Average loss: 0.8810,                   Accuracy: 1412/2000.0 (70.60%)



-= Testing valid =-
Test set: Average loss: 1.0132,                   Accuracy: 1271/2000.0 (63.55%)



-= Testing valid =-
Test set: Average loss: 0.6727,                   Accuracy: 1553/2000.0 (77.65%)



-= Testing valid =-
Test set: Average loss: 0.3929,                   Accuracy: 1733/2000.0 (86.65%)



-= Testing valid =-
Test set: Average loss: 0.3926,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.5066,                   Accuracy: 1658/2000.0 (82.90%)



Epoch 10 train accuracy: 92.22%, valid accuracy 82.90%
-= Testing valid =-
Test set: Average loss: 0.2426,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2217,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.1797,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1565,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1803,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1565,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1665,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1459,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1873,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1410,                   Accuracy: 1916/2000.0 (95.80%)



Epoch 20 train accuracy: 95.32%, valid accuracy 95.80%
-= Testing valid =-
Test set: Average loss: 0.1724,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1182,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1251,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1423,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1141,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1215,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 30 train accuracy: 96.38%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.1046,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1100,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 40 train accuracy: 97.26%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0910,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0937,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 50 train accuracy: 96.97%, valid accuracy 97.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1086,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1171,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1123,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1149,                   Accuracy: 57928/60000 (96.55%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1140,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1135,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1137,                   Accuracy: 57954/60000 (96.59%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1052,                   Accuracy: 58111/60000 (96.85%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1083,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1097,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1177,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1127,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1164,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1135,                   Accuracy: 57959/60000 (96.60%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1139,                   Accuracy: 57974/60000 (96.62%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1141,                   Accuracy: 57955/60000 (96.59%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1053,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1102,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1086,                   Accuracy: 58034/60000 (96.72%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1137,                   Accuracy: 57952/60000 (96.59%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1105,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1144,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1106,                   Accuracy: 58034/60000 (96.72%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1089,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1107,                   Accuracy: 58033/60000 (96.72%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1021,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1066,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1075,                   Accuracy: 58061/60000 (96.77%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1129,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1106,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1140,                   Accuracy: 57975/60000 (96.62%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1118,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1109,                   Accuracy: 58066/60000 (96.78%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1110,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1033,                   Accuracy: 58162/60000 (96.94%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1066,                   Accuracy: 58094/60000 (96.82%)
{0: tensor(96.7533), 10: tensor(96.5217), 20: tensor(96.6233), 30: tensor(96.5467), 40: tensor(96.6483), 50: tensor(96.6483), 60: tensor(96.5900), 70: tensor(96.8517), 80: tensor(96.7600), 90: tensor(96.6900), 100: tensor(96.4767), 110: tensor(96.6050), 120: tensor(96.4783), 130: tensor(96.5983), 140: tensor(96.6233), 150: tensor(96.5917), 160: tensor(96.7533), 170: tensor(96.6467), 180: tensor(96.7233), 190: tensor(96.5867), 200: tensor(96.6717), 210: tensor(96.5883), 220: tensor(96.7233), 230: tensor(96.7850), 240: tensor(96.7217), 250: tensor(96.9417), 260: tensor(96.7583), 270: tensor(96.7683), 280: tensor(96.7067), 290: tensor(96.6900), 300: tensor(96.6250), 310: tensor(96.7650), 320: tensor(96.7767), 330: tensor(96.7167), 340: tensor(96.9367), 350: tensor(96.8233)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=76, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3985,                   Accuracy: 361/2000.0 (18.05%)



-= Testing valid =-
Test set: Average loss: 3.5239,                   Accuracy: 258/2000.0 (12.90%)



-= Testing valid =-
Test set: Average loss: 0.8786,                   Accuracy: 1468/2000.0 (73.40%)



-= Testing valid =-
Test set: Average loss: 1.1676,                   Accuracy: 1160/2000.0 (58.00%)



-= Testing valid =-
Test set: Average loss: 0.2620,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.4461,                   Accuracy: 1694/2000.0 (84.70%)



-= Testing valid =-
Test set: Average loss: 0.2540,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.3778,                   Accuracy: 1742/2000.0 (87.10%)



-= Testing valid =-
Test set: Average loss: 0.3073,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2533,                   Accuracy: 1858/2000.0 (92.90%)



Epoch 10 train accuracy: 93.51%, valid accuracy 92.90%
-= Testing valid =-
Test set: Average loss: 0.1097,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1199,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1463,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0947,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1074,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0882,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1406,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 20 train accuracy: 95.76%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 30 train accuracy: 96.46%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0759,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0775,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 40 train accuracy: 97.07%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0752,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0719,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0723,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0707,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0669,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1962/2000.0 (98.10%)



Epoch 50 train accuracy: 96.76%, valid accuracy 98.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0975,                   Accuracy: 58286/60000 (97.14%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1028,                   Accuracy: 58198/60000 (97.00%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1018,                   Accuracy: 58178/60000 (96.96%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1075,                   Accuracy: 58087/60000 (96.81%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1055,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1033,                   Accuracy: 58140/60000 (96.90%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1016,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0969,                   Accuracy: 58278/60000 (97.13%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1001,                   Accuracy: 58185/60000 (96.97%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1021,                   Accuracy: 58166/60000 (96.94%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1094,                   Accuracy: 58022/60000 (96.70%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1076,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1131,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1118,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1114,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1088,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1046,                   Accuracy: 58082/60000 (96.80%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1099,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1075,                   Accuracy: 58011/60000 (96.68%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1119,                   Accuracy: 57959/60000 (96.60%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1098,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1144,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1102,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1077,                   Accuracy: 58035/60000 (96.72%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1065,                   Accuracy: 58057/60000 (96.76%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.0992,                   Accuracy: 58195/60000 (96.99%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1020,                   Accuracy: 58161/60000 (96.93%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0997,                   Accuracy: 58213/60000 (97.02%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1033,                   Accuracy: 58176/60000 (96.96%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1024,                   Accuracy: 58145/60000 (96.91%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1074,                   Accuracy: 58077/60000 (96.79%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1049,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1014,                   Accuracy: 58179/60000 (96.96%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1008,                   Accuracy: 58215/60000 (97.03%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0938,                   Accuracy: 58331/60000 (97.22%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0956,                   Accuracy: 58290/60000 (97.15%)
{0: tensor(97.1433), 10: tensor(96.9967), 20: tensor(96.9633), 30: tensor(96.8117), 40: tensor(96.8667), 50: tensor(96.9000), 60: tensor(96.9500), 70: tensor(97.1300), 80: tensor(96.9750), 90: tensor(96.9433), 100: tensor(96.7033), 110: tensor(96.7850), 120: tensor(96.6000), 130: tensor(96.6400), 140: tensor(96.5950), 150: tensor(96.6467), 160: tensor(96.8033), 170: tensor(96.6067), 180: tensor(96.6850), 190: tensor(96.5983), 200: tensor(96.6217), 210: tensor(96.5250), 220: tensor(96.6333), 230: tensor(96.7250), 240: tensor(96.7617), 250: tensor(96.9917), 260: tensor(96.9350), 270: tensor(97.0217), 280: tensor(96.9600), 290: tensor(96.9083), 300: tensor(96.7950), 310: tensor(96.8800), 320: tensor(96.9650), 330: tensor(97.0250), 340: tensor(97.2183), 350: tensor(97.1500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=77, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 12.1941,                   Accuracy: 248/2000.0 (12.40%)



-= Testing valid =-
Test set: Average loss: 1.2859,                   Accuracy: 1065/2000.0 (53.25%)



-= Testing valid =-
Test set: Average loss: 1.9411,                   Accuracy: 677/2000.0 (33.85%)



-= Testing valid =-
Test set: Average loss: 1.2365,                   Accuracy: 1298/2000.0 (64.90%)



-= Testing valid =-
Test set: Average loss: 0.4753,                   Accuracy: 1691/2000.0 (84.55%)



-= Testing valid =-
Test set: Average loss: 0.3308,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3078,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.2055,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.2477,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.4372,                   Accuracy: 1707/2000.0 (85.35%)



Epoch 10 train accuracy: 93.34%, valid accuracy 85.35%
-= Testing valid =-
Test set: Average loss: 0.1409,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1553,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1630,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1398,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1158,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1159,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1597,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1118,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1133,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 20 train accuracy: 95.59%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.1129,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1238,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1104,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1086,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 30 train accuracy: 96.54%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0910,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0807,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0969,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 40 train accuracy: 96.65%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0802,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 50 train accuracy: 97.20%, valid accuracy 97.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1152,                   Accuracy: 58011/60000 (96.68%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1347,                   Accuracy: 57583/60000 (95.97%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1299,                   Accuracy: 57709/60000 (96.18%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1287,                   Accuracy: 57772/60000 (96.29%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1257,                   Accuracy: 57812/60000 (96.35%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1254,                   Accuracy: 57836/60000 (96.39%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1205,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1164,                   Accuracy: 57983/60000 (96.64%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1194,                   Accuracy: 57901/60000 (96.50%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1095,                   Accuracy: 58133/60000 (96.89%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1236,                   Accuracy: 57831/60000 (96.39%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1204,                   Accuracy: 57898/60000 (96.50%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1214,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1202,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1204,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1159,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1102,                   Accuracy: 58128/60000 (96.88%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1163,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1060,                   Accuracy: 58167/60000 (96.94%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1208,                   Accuracy: 57856/60000 (96.43%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1170,                   Accuracy: 57981/60000 (96.64%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1184,                   Accuracy: 57990/60000 (96.65%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1176,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1182,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1149,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1117,                   Accuracy: 58094/60000 (96.82%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1197,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1102,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1299,                   Accuracy: 57692/60000 (96.15%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1256,                   Accuracy: 57762/60000 (96.27%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1250,                   Accuracy: 57845/60000 (96.41%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1230,                   Accuracy: 57911/60000 (96.52%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1235,                   Accuracy: 57882/60000 (96.47%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1194,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1195,                   Accuracy: 57888/60000 (96.48%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1231,                   Accuracy: 57791/60000 (96.32%)
{0: tensor(96.6850), 10: tensor(95.9717), 20: tensor(96.1817), 30: tensor(96.2867), 40: tensor(96.3533), 50: tensor(96.3933), 60: tensor(96.5117), 70: tensor(96.6383), 80: tensor(96.5017), 90: tensor(96.8883), 100: tensor(96.3850), 110: tensor(96.4967), 120: tensor(96.5683), 130: tensor(96.6017), 140: tensor(96.5717), 150: tensor(96.7383), 160: tensor(96.8800), 170: tensor(96.6267), 180: tensor(96.9450), 190: tensor(96.4267), 200: tensor(96.6350), 210: tensor(96.6500), 220: tensor(96.6933), 230: tensor(96.6733), 240: tensor(96.7350), 250: tensor(96.8233), 260: tensor(96.5133), 270: tensor(96.8367), 280: tensor(96.1533), 290: tensor(96.2700), 300: tensor(96.4083), 310: tensor(96.5183), 320: tensor(96.4700), 330: tensor(96.5367), 340: tensor(96.4800), 350: tensor(96.3183)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=78, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.7944,                   Accuracy: 417/2000.0 (20.85%)



-= Testing valid =-
Test set: Average loss: 3.0627,                   Accuracy: 257/2000.0 (12.85%)



-= Testing valid =-
Test set: Average loss: 0.9900,                   Accuracy: 1212/2000.0 (60.60%)



-= Testing valid =-
Test set: Average loss: 0.3972,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.6468,                   Accuracy: 1587/2000.0 (79.35%)



-= Testing valid =-
Test set: Average loss: 0.7439,                   Accuracy: 1585/2000.0 (79.25%)



-= Testing valid =-
Test set: Average loss: 0.2553,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.3957,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.2919,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.1895,                   Accuracy: 1881/2000.0 (94.05%)



Epoch 10 train accuracy: 93.78%, valid accuracy 94.05%
-= Testing valid =-
Test set: Average loss: 0.1742,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1512,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1541,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1391,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1258,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1646,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1594,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1260,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1591,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1785,                   Accuracy: 1885/2000.0 (94.25%)



Epoch 20 train accuracy: 96.11%, valid accuracy 94.25%
-= Testing valid =-
Test set: Average loss: 0.1139,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1115,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1212,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1221,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1072,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1094,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1374,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1104,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1077,                   Accuracy: 1934/2000.0 (96.70%)



Epoch 30 train accuracy: 96.71%, valid accuracy 96.70%
-= Testing valid =-
Test set: Average loss: 0.1068,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1069,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1100,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1038,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 40 train accuracy: 97.14%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 50 train accuracy: 97.40%, valid accuracy 97.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0997,                   Accuracy: 58295/60000 (97.16%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1124,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1088,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1105,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1092,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1071,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1049,                   Accuracy: 58150/60000 (96.92%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1004,                   Accuracy: 58235/60000 (97.06%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1018,                   Accuracy: 58164/60000 (96.94%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1046,                   Accuracy: 58148/60000 (96.91%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1184,                   Accuracy: 57820/60000 (96.37%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1156,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1169,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1144,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1109,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1086,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1034,                   Accuracy: 58155/60000 (96.93%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1058,                   Accuracy: 58079/60000 (96.80%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1060,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1167,                   Accuracy: 57870/60000 (96.45%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1148,                   Accuracy: 57916/60000 (96.53%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1144,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1100,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1076,                   Accuracy: 58092/60000 (96.82%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1043,                   Accuracy: 58140/60000 (96.90%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.0999,                   Accuracy: 58214/60000 (97.02%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1019,                   Accuracy: 58164/60000 (96.94%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1008,                   Accuracy: 58259/60000 (97.10%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1102,                   Accuracy: 58032/60000 (96.72%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1078,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1085,                   Accuracy: 58057/60000 (96.76%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1059,                   Accuracy: 58155/60000 (96.93%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1056,                   Accuracy: 58137/60000 (96.89%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1014,                   Accuracy: 58247/60000 (97.08%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0981,                   Accuracy: 58301/60000 (97.17%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1006,                   Accuracy: 58228/60000 (97.05%)
{0: tensor(97.1583), 10: tensor(96.6133), 20: tensor(96.7350), 30: tensor(96.6433), 40: tensor(96.8083), 50: tensor(96.8167), 60: tensor(96.9167), 70: tensor(97.0583), 80: tensor(96.9400), 90: tensor(96.9133), 100: tensor(96.3667), 110: tensor(96.5117), 120: tensor(96.4400), 130: tensor(96.6183), 140: tensor(96.7083), 150: tensor(96.7400), 160: tensor(96.9250), 170: tensor(96.7983), 180: tensor(96.8533), 190: tensor(96.4500), 200: tensor(96.5267), 210: tensor(96.5583), 220: tensor(96.7017), 230: tensor(96.8200), 240: tensor(96.9000), 250: tensor(97.0233), 260: tensor(96.9400), 270: tensor(97.0983), 280: tensor(96.7200), 290: tensor(96.8367), 300: tensor(96.7617), 310: tensor(96.9250), 320: tensor(96.8950), 330: tensor(97.0783), 340: tensor(97.1683), 350: tensor(97.0467)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=79, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8100,                   Accuracy: 578/2000.0 (28.90%)



-= Testing valid =-
Test set: Average loss: 1.7563,                   Accuracy: 662/2000.0 (33.10%)



-= Testing valid =-
Test set: Average loss: 1.1038,                   Accuracy: 1170/2000.0 (58.50%)



-= Testing valid =-
Test set: Average loss: 0.7393,                   Accuracy: 1456/2000.0 (72.80%)



-= Testing valid =-
Test set: Average loss: 0.5752,                   Accuracy: 1599/2000.0 (79.95%)



-= Testing valid =-
Test set: Average loss: 0.3536,                   Accuracy: 1764/2000.0 (88.20%)



-= Testing valid =-
Test set: Average loss: 0.3267,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.3643,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.1571,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.2597,                   Accuracy: 1816/2000.0 (90.80%)



Epoch 10 train accuracy: 93.61%, valid accuracy 90.80%
-= Testing valid =-
Test set: Average loss: 0.1526,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1371,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1292,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.2147,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.1586,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1210,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1279,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 20 train accuracy: 95.66%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.1059,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1021,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1284,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1143,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 30 train accuracy: 96.80%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1156,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 40 train accuracy: 97.15%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 50 train accuracy: 97.41%, valid accuracy 97.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1136,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1250,                   Accuracy: 57797/60000 (96.33%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1220,                   Accuracy: 57873/60000 (96.46%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1232,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1273,                   Accuracy: 57776/60000 (96.29%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1281,                   Accuracy: 57752/60000 (96.25%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1292,                   Accuracy: 57704/60000 (96.17%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1284,                   Accuracy: 57673/60000 (96.12%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1325,                   Accuracy: 57662/60000 (96.10%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1218,                   Accuracy: 57825/60000 (96.38%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1337,                   Accuracy: 57607/60000 (96.01%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1335,                   Accuracy: 57604/60000 (96.01%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1341,                   Accuracy: 57598/60000 (96.00%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1385,                   Accuracy: 57495/60000 (95.82%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1434,                   Accuracy: 57372/60000 (95.62%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1417,                   Accuracy: 57377/60000 (95.63%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1421,                   Accuracy: 57360/60000 (95.60%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1416,                   Accuracy: 57421/60000 (95.70%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1283,                   Accuracy: 57633/60000 (96.06%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1398,                   Accuracy: 57412/60000 (95.69%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1352,                   Accuracy: 57515/60000 (95.86%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1328,                   Accuracy: 57614/60000 (96.02%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1347,                   Accuracy: 57548/60000 (95.91%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1362,                   Accuracy: 57518/60000 (95.86%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1330,                   Accuracy: 57543/60000 (95.90%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1305,                   Accuracy: 57577/60000 (95.96%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1273,                   Accuracy: 57691/60000 (96.15%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1164,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1279,                   Accuracy: 57703/60000 (96.17%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1211,                   Accuracy: 57852/60000 (96.42%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1203,                   Accuracy: 57916/60000 (96.53%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1236,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1237,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1237,                   Accuracy: 57815/60000 (96.36%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1202,                   Accuracy: 57844/60000 (96.41%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1216,                   Accuracy: 57860/60000 (96.43%)
{0: tensor(96.6750), 10: tensor(96.3283), 20: tensor(96.4550), 30: tensor(96.4583), 40: tensor(96.2933), 50: tensor(96.2533), 60: tensor(96.1733), 70: tensor(96.1217), 80: tensor(96.1033), 90: tensor(96.3750), 100: tensor(96.0117), 110: tensor(96.0067), 120: tensor(95.9967), 130: tensor(95.8250), 140: tensor(95.6200), 150: tensor(95.6283), 160: tensor(95.6000), 170: tensor(95.7017), 180: tensor(96.0550), 190: tensor(95.6867), 200: tensor(95.8583), 210: tensor(96.0233), 220: tensor(95.9133), 230: tensor(95.8633), 240: tensor(95.9050), 250: tensor(95.9617), 260: tensor(96.1517), 270: tensor(96.5133), 280: tensor(96.1717), 290: tensor(96.4200), 300: tensor(96.5267), 310: tensor(96.4167), 320: tensor(96.3600), 330: tensor(96.3583), 340: tensor(96.4067), 350: tensor(96.4333)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=80, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.4051,                   Accuracy: 214/2000.0 (10.70%)



-= Testing valid =-
Test set: Average loss: 1.5486,                   Accuracy: 956/2000.0 (47.80%)



-= Testing valid =-
Test set: Average loss: 7.7366,                   Accuracy: 331/2000.0 (16.55%)



-= Testing valid =-
Test set: Average loss: 1.5006,                   Accuracy: 1014/2000.0 (50.70%)



-= Testing valid =-
Test set: Average loss: 0.7764,                   Accuracy: 1437/2000.0 (71.85%)



-= Testing valid =-
Test set: Average loss: 0.4726,                   Accuracy: 1705/2000.0 (85.25%)



-= Testing valid =-
Test set: Average loss: 0.6933,                   Accuracy: 1515/2000.0 (75.75%)



-= Testing valid =-
Test set: Average loss: 0.2723,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.3006,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2222,                   Accuracy: 1849/2000.0 (92.45%)



Epoch 10 train accuracy: 92.99%, valid accuracy 92.45%
-= Testing valid =-
Test set: Average loss: 0.2069,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.1821,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1705,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1505,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1773,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2480,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.1524,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1491,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1466,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1924,                   Accuracy: 1877/2000.0 (93.85%)



Epoch 20 train accuracy: 95.20%, valid accuracy 93.85%
-= Testing valid =-
Test set: Average loss: 0.1227,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1257,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1378,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1459,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1347,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1186,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1320,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1244,                   Accuracy: 1916/2000.0 (95.80%)



Epoch 30 train accuracy: 96.65%, valid accuracy 95.80%
-= Testing valid =-
Test set: Average loss: 0.1245,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1120,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1224,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1313,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1205,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1185,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1082,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1014,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1037,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 40 train accuracy: 96.65%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.1061,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1192,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1202,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1052,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1082,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1048,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 50 train accuracy: 96.81%, valid accuracy 96.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1118,                   Accuracy: 58155/60000 (96.93%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1155,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1205,                   Accuracy: 57893/60000 (96.49%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1334,                   Accuracy: 57680/60000 (96.13%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1314,                   Accuracy: 57737/60000 (96.23%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1283,                   Accuracy: 57776/60000 (96.29%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1254,                   Accuracy: 57875/60000 (96.46%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1149,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1134,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1110,                   Accuracy: 58141/60000 (96.90%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1160,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1211,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1359,                   Accuracy: 57629/60000 (96.05%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1346,                   Accuracy: 57672/60000 (96.12%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1326,                   Accuracy: 57695/60000 (96.16%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1284,                   Accuracy: 57764/60000 (96.27%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1191,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1195,                   Accuracy: 57914/60000 (96.52%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1151,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1231,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1223,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1349,                   Accuracy: 57696/60000 (96.16%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1352,                   Accuracy: 57688/60000 (96.15%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1328,                   Accuracy: 57662/60000 (96.10%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1288,                   Accuracy: 57752/60000 (96.25%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1196,                   Accuracy: 57955/60000 (96.59%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1163,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1150,                   Accuracy: 58110/60000 (96.85%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1212,                   Accuracy: 57900/60000 (96.50%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1214,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1338,                   Accuracy: 57727/60000 (96.21%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1327,                   Accuracy: 57743/60000 (96.24%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1299,                   Accuracy: 57739/60000 (96.23%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1253,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1156,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1114,                   Accuracy: 58105/60000 (96.84%)
{0: tensor(96.9250), 10: tensor(96.6917), 20: tensor(96.4883), 30: tensor(96.1333), 40: tensor(96.2283), 50: tensor(96.2933), 60: tensor(96.4583), 70: tensor(96.7433), 80: tensor(96.7017), 90: tensor(96.9017), 100: tensor(96.6583), 110: tensor(96.4983), 120: tensor(96.0483), 130: tensor(96.1200), 140: tensor(96.1583), 150: tensor(96.2733), 160: tensor(96.5583), 170: tensor(96.5233), 180: tensor(96.7717), 190: tensor(96.4617), 200: tensor(96.4633), 210: tensor(96.1600), 220: tensor(96.1467), 230: tensor(96.1033), 240: tensor(96.2533), 250: tensor(96.5917), 260: tensor(96.6917), 270: tensor(96.8500), 280: tensor(96.5000), 290: tensor(96.5117), 300: tensor(96.2117), 310: tensor(96.2383), 320: tensor(96.2317), 330: tensor(96.4100), 340: tensor(96.6833), 350: tensor(96.8417)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=81, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6063,                   Accuracy: 278/2000.0 (13.90%)



-= Testing valid =-
Test set: Average loss: 1.8539,                   Accuracy: 799/2000.0 (39.95%)



-= Testing valid =-
Test set: Average loss: 1.2194,                   Accuracy: 1125/2000.0 (56.25%)



-= Testing valid =-
Test set: Average loss: 0.5081,                   Accuracy: 1730/2000.0 (86.50%)



-= Testing valid =-
Test set: Average loss: 0.5122,                   Accuracy: 1625/2000.0 (81.25%)



-= Testing valid =-
Test set: Average loss: 0.3166,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.4335,                   Accuracy: 1747/2000.0 (87.35%)



-= Testing valid =-
Test set: Average loss: 0.1983,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2797,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2220,                   Accuracy: 1862/2000.0 (93.10%)



Epoch 10 train accuracy: 93.16%, valid accuracy 93.10%
-= Testing valid =-
Test set: Average loss: 0.1361,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1468,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1434,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1823,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1170,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.2130,                   Accuracy: 1876/2000.0 (93.80%)



-= Testing valid =-
Test set: Average loss: 0.1598,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1119,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1423,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1587,                   Accuracy: 1897/2000.0 (94.85%)



Epoch 20 train accuracy: 95.25%, valid accuracy 94.85%
-= Testing valid =-
Test set: Average loss: 0.1190,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1211,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1059,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1064,                   Accuracy: 1928/2000.0 (96.40%)



Epoch 30 train accuracy: 96.15%, valid accuracy 96.40%
-= Testing valid =-
Test set: Average loss: 0.1074,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0882,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 40 train accuracy: 96.68%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 50 train accuracy: 96.91%, valid accuracy 97.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1034,                   Accuracy: 58234/60000 (97.06%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1121,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1101,                   Accuracy: 58083/60000 (96.81%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1164,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1166,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1169,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1161,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1113,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1122,                   Accuracy: 58007/60000 (96.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1065,                   Accuracy: 58154/60000 (96.92%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1169,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1126,                   Accuracy: 57997/60000 (96.66%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1154,                   Accuracy: 57973/60000 (96.62%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1162,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1166,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1164,                   Accuracy: 57955/60000 (96.59%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1136,                   Accuracy: 57965/60000 (96.61%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1152,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1091,                   Accuracy: 58077/60000 (96.79%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1189,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1134,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1138,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1133,                   Accuracy: 58017/60000 (96.69%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1127,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1125,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1088,                   Accuracy: 58105/60000 (96.84%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1090,                   Accuracy: 58106/60000 (96.84%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1048,                   Accuracy: 58200/60000 (97.00%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1129,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1101,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1142,                   Accuracy: 58022/60000 (96.70%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1126,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1122,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1118,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1070,                   Accuracy: 58091/60000 (96.82%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1076,                   Accuracy: 58150/60000 (96.92%)
{0: tensor(97.0567), 10: tensor(96.8083), 20: tensor(96.8050), 30: tensor(96.6217), 40: tensor(96.6217), 50: tensor(96.5800), 60: tensor(96.5717), 70: tensor(96.6817), 80: tensor(96.6783), 90: tensor(96.9233), 100: tensor(96.5800), 110: tensor(96.6617), 120: tensor(96.6217), 130: tensor(96.6117), 140: tensor(96.5833), 150: tensor(96.5917), 160: tensor(96.6083), 170: tensor(96.6167), 180: tensor(96.7950), 190: tensor(96.4400), 200: tensor(96.5633), 210: tensor(96.6883), 220: tensor(96.6950), 230: tensor(96.7600), 240: tensor(96.7550), 250: tensor(96.8417), 260: tensor(96.8433), 270: tensor(97.), 280: tensor(96.7017), 290: tensor(96.7667), 300: tensor(96.7033), 310: tensor(96.7167), 320: tensor(96.7667), 330: tensor(96.7600), 340: tensor(96.8183), 350: tensor(96.9167)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=82, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.5265,                   Accuracy: 228/2000.0 (11.40%)



-= Testing valid =-
Test set: Average loss: 1.6237,                   Accuracy: 790/2000.0 (39.50%)



-= Testing valid =-
Test set: Average loss: 0.9127,                   Accuracy: 1318/2000.0 (65.90%)



-= Testing valid =-
Test set: Average loss: 0.6179,                   Accuracy: 1622/2000.0 (81.10%)



-= Testing valid =-
Test set: Average loss: 0.8270,                   Accuracy: 1493/2000.0 (74.65%)



-= Testing valid =-
Test set: Average loss: 0.3998,                   Accuracy: 1735/2000.0 (86.75%)



-= Testing valid =-
Test set: Average loss: 0.2669,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2268,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.1742,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1742,                   Accuracy: 1888/2000.0 (94.40%)



Epoch 10 train accuracy: 93.00%, valid accuracy 94.40%
-= Testing valid =-
Test set: Average loss: 0.1365,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1143,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1672,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1532,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1616,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1204,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1394,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1263,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1017,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1227,                   Accuracy: 1916/2000.0 (95.80%)



Epoch 20 train accuracy: 95.35%, valid accuracy 95.80%
-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1127,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0723,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.1201,                   Accuracy: 1922/2000.0 (96.10%)



Epoch 30 train accuracy: 96.54%, valid accuracy 96.10%
-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0708,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1960/2000.0 (98.00%)



Epoch 40 train accuracy: 96.69%, valid accuracy 98.00%
-= Testing valid =-
Test set: Average loss: 0.0732,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0756,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0717,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0727,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 50 train accuracy: 96.94%, valid accuracy 97.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1030,                   Accuracy: 58185/60000 (96.97%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1137,                   Accuracy: 57966/60000 (96.61%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1102,                   Accuracy: 58061/60000 (96.77%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1162,                   Accuracy: 57977/60000 (96.63%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1200,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1220,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1200,                   Accuracy: 57857/60000 (96.43%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1114,                   Accuracy: 57981/60000 (96.64%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1078,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1036,                   Accuracy: 58173/60000 (96.96%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1152,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1105,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1156,                   Accuracy: 57983/60000 (96.64%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1189,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1212,                   Accuracy: 57827/60000 (96.38%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1194,                   Accuracy: 57831/60000 (96.39%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1111,                   Accuracy: 57955/60000 (96.59%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1107,                   Accuracy: 57958/60000 (96.60%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1048,                   Accuracy: 58132/60000 (96.89%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1159,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1100,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1122,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1150,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1169,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1146,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1081,                   Accuracy: 58026/60000 (96.71%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1070,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1021,                   Accuracy: 58199/60000 (97.00%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1122,                   Accuracy: 57983/60000 (96.64%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1092,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1138,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1171,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1192,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1161,                   Accuracy: 57940/60000 (96.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1098,                   Accuracy: 58028/60000 (96.71%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1061,                   Accuracy: 58080/60000 (96.80%)
{0: tensor(96.9750), 10: tensor(96.6100), 20: tensor(96.7683), 30: tensor(96.6283), 40: tensor(96.4917), 50: tensor(96.4750), 60: tensor(96.4283), 70: tensor(96.6350), 80: tensor(96.7050), 90: tensor(96.9550), 100: tensor(96.5717), 110: tensor(96.7533), 120: tensor(96.6383), 130: tensor(96.4917), 140: tensor(96.3783), 150: tensor(96.3850), 160: tensor(96.5917), 170: tensor(96.5967), 180: tensor(96.8867), 190: tensor(96.4917), 200: tensor(96.6900), 210: tensor(96.7633), 220: tensor(96.6050), 230: tensor(96.5283), 240: tensor(96.6017), 250: tensor(96.7100), 260: tensor(96.7833), 270: tensor(96.9983), 280: tensor(96.6383), 290: tensor(96.7517), 300: tensor(96.6900), 310: tensor(96.5383), 320: tensor(96.5217), 330: tensor(96.5667), 340: tensor(96.7133), 350: tensor(96.8000)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=83, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5954,                   Accuracy: 409/2000.0 (20.45%)



-= Testing valid =-
Test set: Average loss: 1.9251,                   Accuracy: 674/2000.0 (33.70%)



-= Testing valid =-
Test set: Average loss: 1.0006,                   Accuracy: 1374/2000.0 (68.70%)



-= Testing valid =-
Test set: Average loss: 0.9050,                   Accuracy: 1448/2000.0 (72.40%)



-= Testing valid =-
Test set: Average loss: 0.7495,                   Accuracy: 1526/2000.0 (76.30%)



-= Testing valid =-
Test set: Average loss: 0.3052,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.2515,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.2649,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.1506,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.2611,                   Accuracy: 1857/2000.0 (92.85%)



Epoch 10 train accuracy: 93.94%, valid accuracy 92.85%
-= Testing valid =-
Test set: Average loss: 0.2042,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.1282,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1148,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1199,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1272,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1315,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1096,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1153,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 20 train accuracy: 96.41%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1068,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1126,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1132,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1267,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 30 train accuracy: 96.68%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0756,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 40 train accuracy: 97.40%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 50 train accuracy: 97.43%, valid accuracy 97.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0994,                   Accuracy: 58293/60000 (97.15%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1160,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1107,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1105,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1132,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1113,                   Accuracy: 58057/60000 (96.76%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1068,                   Accuracy: 58127/60000 (96.88%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1066,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1105,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0990,                   Accuracy: 58286/60000 (97.14%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1142,                   Accuracy: 58032/60000 (96.72%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1094,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1124,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1142,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1118,                   Accuracy: 58077/60000 (96.79%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1109,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1045,                   Accuracy: 58118/60000 (96.86%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1118,                   Accuracy: 57998/60000 (96.66%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0997,                   Accuracy: 58256/60000 (97.09%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1128,                   Accuracy: 58034/60000 (96.72%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1100,                   Accuracy: 58033/60000 (96.72%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1133,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1145,                   Accuracy: 57982/60000 (96.64%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1132,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1115,                   Accuracy: 58011/60000 (96.68%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1055,                   Accuracy: 58099/60000 (96.83%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1103,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0992,                   Accuracy: 58277/60000 (97.13%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1141,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1106,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1112,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1135,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1124,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1077,                   Accuracy: 58140/60000 (96.90%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1080,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1097,                   Accuracy: 58116/60000 (96.86%)
{0: tensor(97.1550), 10: tensor(96.6650), 20: tensor(96.7750), 30: tensor(96.7450), 40: tensor(96.6450), 50: tensor(96.7617), 60: tensor(96.8783), 70: tensor(96.8083), 80: tensor(96.7967), 90: tensor(97.1433), 100: tensor(96.7200), 110: tensor(96.7433), 120: tensor(96.7000), 130: tensor(96.6033), 140: tensor(96.7950), 150: tensor(96.7500), 160: tensor(96.8633), 170: tensor(96.6633), 180: tensor(97.0933), 190: tensor(96.7233), 200: tensor(96.7217), 210: tensor(96.6200), 220: tensor(96.6367), 230: tensor(96.7267), 240: tensor(96.6850), 250: tensor(96.8317), 260: tensor(96.7567), 270: tensor(97.1283), 280: tensor(96.7083), 290: tensor(96.7567), 300: tensor(96.7500), 310: tensor(96.6600), 320: tensor(96.7467), 330: tensor(96.9000), 340: tensor(96.7667), 350: tensor(96.8600)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=84, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0528,                   Accuracy: 576/2000.0 (28.80%)



-= Testing valid =-
Test set: Average loss: 2.1582,                   Accuracy: 639/2000.0 (31.95%)



-= Testing valid =-
Test set: Average loss: 2.0795,                   Accuracy: 699/2000.0 (34.95%)



-= Testing valid =-
Test set: Average loss: 0.4399,                   Accuracy: 1714/2000.0 (85.70%)



-= Testing valid =-
Test set: Average loss: 0.4220,                   Accuracy: 1742/2000.0 (87.10%)



-= Testing valid =-
Test set: Average loss: 0.5372,                   Accuracy: 1672/2000.0 (83.60%)



-= Testing valid =-
Test set: Average loss: 0.1979,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1689,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1976,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1782,                   Accuracy: 1907/2000.0 (95.35%)



Epoch 10 train accuracy: 93.61%, valid accuracy 95.35%
-= Testing valid =-
Test set: Average loss: 0.1395,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1071,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1221,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1631,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1154,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1669,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1417,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1232,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 20 train accuracy: 95.93%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.1064,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1219,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.1101,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1165,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0882,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.1102,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 30 train accuracy: 96.62%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 40 train accuracy: 97.04%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 50 train accuracy: 97.32%, valid accuracy 98.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0921,                   Accuracy: 58399/60000 (97.33%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1045,                   Accuracy: 58185/60000 (96.97%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1016,                   Accuracy: 58196/60000 (96.99%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1031,                   Accuracy: 58169/60000 (96.95%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1048,                   Accuracy: 58174/60000 (96.96%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1052,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1008,                   Accuracy: 58231/60000 (97.05%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1004,                   Accuracy: 58201/60000 (97.00%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1054,                   Accuracy: 58098/60000 (96.83%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1029,                   Accuracy: 58168/60000 (96.95%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1201,                   Accuracy: 57808/60000 (96.35%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1159,                   Accuracy: 57873/60000 (96.46%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1187,                   Accuracy: 57781/60000 (96.30%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1219,                   Accuracy: 57784/60000 (96.31%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1247,                   Accuracy: 57692/60000 (96.15%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1204,                   Accuracy: 57718/60000 (96.20%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1198,                   Accuracy: 57745/60000 (96.24%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1309,                   Accuracy: 57469/60000 (95.78%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1186,                   Accuracy: 57786/60000 (96.31%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1316,                   Accuracy: 57537/60000 (95.89%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1203,                   Accuracy: 57732/60000 (96.22%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1169,                   Accuracy: 57854/60000 (96.42%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1135,                   Accuracy: 57900/60000 (96.50%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1113,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1033,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1015,                   Accuracy: 58161/60000 (96.93%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1069,                   Accuracy: 58019/60000 (96.70%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0988,                   Accuracy: 58268/60000 (97.11%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1104,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1029,                   Accuracy: 58145/60000 (96.91%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1009,                   Accuracy: 58237/60000 (97.06%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.0994,                   Accuracy: 58238/60000 (97.06%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.0976,                   Accuracy: 58267/60000 (97.11%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0918,                   Accuracy: 58385/60000 (97.31%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0912,                   Accuracy: 58400/60000 (97.33%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0944,                   Accuracy: 58309/60000 (97.18%)
{0: tensor(97.3317), 10: tensor(96.9750), 20: tensor(96.9933), 30: tensor(96.9483), 40: tensor(96.9567), 50: tensor(96.8750), 60: tensor(97.0517), 70: tensor(97.0017), 80: tensor(96.8300), 90: tensor(96.9467), 100: tensor(96.3467), 110: tensor(96.4550), 120: tensor(96.3017), 130: tensor(96.3067), 140: tensor(96.1533), 150: tensor(96.1967), 160: tensor(96.2417), 170: tensor(95.7817), 180: tensor(96.3100), 190: tensor(95.8950), 200: tensor(96.2200), 210: tensor(96.4233), 220: tensor(96.5000), 230: tensor(96.5583), 240: tensor(96.8450), 250: tensor(96.9350), 260: tensor(96.6983), 270: tensor(97.1133), 280: tensor(96.7350), 290: tensor(96.9083), 300: tensor(97.0617), 310: tensor(97.0633), 320: tensor(97.1117), 330: tensor(97.3083), 340: tensor(97.3333), 350: tensor(97.1817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=85, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 6.8904,                   Accuracy: 241/2000.0 (12.05%)



-= Testing valid =-
Test set: Average loss: 4.3630,                   Accuracy: 187/2000.0 (9.35%)



-= Testing valid =-
Test set: Average loss: 0.8777,                   Accuracy: 1416/2000.0 (70.80%)



-= Testing valid =-
Test set: Average loss: 0.6994,                   Accuracy: 1534/2000.0 (76.70%)



-= Testing valid =-
Test set: Average loss: 0.7424,                   Accuracy: 1467/2000.0 (73.35%)



-= Testing valid =-
Test set: Average loss: 0.3173,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2427,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.3000,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.3200,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.1602,                   Accuracy: 1899/2000.0 (94.95%)



Epoch 10 train accuracy: 93.85%, valid accuracy 94.95%
-= Testing valid =-
Test set: Average loss: 0.1259,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1657,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1680,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.2241,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.1694,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1088,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1470,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1553,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.2336,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.1283,                   Accuracy: 1903/2000.0 (95.15%)



Epoch 20 train accuracy: 95.61%, valid accuracy 95.15%
-= Testing valid =-
Test set: Average loss: 0.1242,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1208,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1093,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1186,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1075,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1314,                   Accuracy: 1913/2000.0 (95.65%)



Epoch 30 train accuracy: 96.71%, valid accuracy 95.65%
-= Testing valid =-
Test set: Average loss: 0.1274,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1192,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1101,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1147,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1140,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1042,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1149,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0978,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1068,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 40 train accuracy: 97.03%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1021,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1003,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1145,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 50 train accuracy: 97.25%, valid accuracy 96.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1050,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1264,                   Accuracy: 57598/60000 (96.00%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1166,                   Accuracy: 57766/60000 (96.28%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1137,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1155,                   Accuracy: 57803/60000 (96.34%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1112,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1043,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1004,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1052,                   Accuracy: 58026/60000 (96.71%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0963,                   Accuracy: 58233/60000 (97.06%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1133,                   Accuracy: 57845/60000 (96.41%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1075,                   Accuracy: 57959/60000 (96.60%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1055,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1050,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1042,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1018,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.0945,                   Accuracy: 58287/60000 (97.14%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1005,                   Accuracy: 58140/60000 (96.90%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0936,                   Accuracy: 58288/60000 (97.15%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1095,                   Accuracy: 57939/60000 (96.57%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1040,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1058,                   Accuracy: 58024/60000 (96.71%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1043,                   Accuracy: 58057/60000 (96.76%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1065,                   Accuracy: 58017/60000 (96.69%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1064,                   Accuracy: 58035/60000 (96.72%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1010,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1052,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1020,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1216,                   Accuracy: 57737/60000 (96.23%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1135,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1150,                   Accuracy: 57831/60000 (96.39%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1147,                   Accuracy: 57835/60000 (96.39%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1151,                   Accuracy: 57874/60000 (96.46%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1092,                   Accuracy: 57966/60000 (96.61%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1080,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1104,                   Accuracy: 57940/60000 (96.57%)
{0: tensor(96.7300), 10: tensor(95.9967), 20: tensor(96.2767), 30: tensor(96.4183), 40: tensor(96.3383), 50: tensor(96.5133), 60: tensor(96.7667), 70: tensor(96.8717), 80: tensor(96.7100), 90: tensor(97.0550), 100: tensor(96.4083), 110: tensor(96.5983), 120: tensor(96.7383), 130: tensor(96.7333), 140: tensor(96.7300), 150: tensor(96.8333), 160: tensor(97.1450), 170: tensor(96.9000), 180: tensor(97.1467), 190: tensor(96.5650), 200: tensor(96.7083), 210: tensor(96.7067), 220: tensor(96.7617), 230: tensor(96.6950), 240: tensor(96.7250), 250: tensor(96.9500), 260: tensor(96.7417), 270: tensor(96.8667), 280: tensor(96.2283), 290: tensor(96.4183), 300: tensor(96.3850), 310: tensor(96.3917), 320: tensor(96.4567), 330: tensor(96.6100), 340: tensor(96.6050), 350: tensor(96.5667)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=86, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6376,                   Accuracy: 360/2000.0 (18.00%)



-= Testing valid =-
Test set: Average loss: 2.0195,                   Accuracy: 574/2000.0 (28.70%)



-= Testing valid =-
Test set: Average loss: 0.8382,                   Accuracy: 1448/2000.0 (72.40%)



-= Testing valid =-
Test set: Average loss: 0.7523,                   Accuracy: 1442/2000.0 (72.10%)



-= Testing valid =-
Test set: Average loss: 0.3639,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.2334,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2281,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.1887,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.2371,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.1618,                   Accuracy: 1897/2000.0 (94.85%)



Epoch 10 train accuracy: 93.44%, valid accuracy 94.85%
-= Testing valid =-
Test set: Average loss: 0.1571,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1242,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1651,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1578,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1535,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1707,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1089,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1136,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1802,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1331,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 20 train accuracy: 95.11%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.1382,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1110,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1245,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0919,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1745,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1240,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 30 train accuracy: 96.50%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1374,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 40 train accuracy: 96.84%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0955,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 50 train accuracy: 96.90%, valid accuracy 97.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1154,                   Accuracy: 58048/60000 (96.75%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1224,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1234,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1308,                   Accuracy: 57738/60000 (96.23%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1296,                   Accuracy: 57741/60000 (96.24%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1304,                   Accuracy: 57734/60000 (96.22%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1243,                   Accuracy: 57812/60000 (96.35%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1198,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1213,                   Accuracy: 57863/60000 (96.44%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1201,                   Accuracy: 57910/60000 (96.52%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1299,                   Accuracy: 57720/60000 (96.20%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1278,                   Accuracy: 57769/60000 (96.28%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1365,                   Accuracy: 57612/60000 (96.02%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1341,                   Accuracy: 57639/60000 (96.07%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1375,                   Accuracy: 57530/60000 (95.88%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1333,                   Accuracy: 57613/60000 (96.02%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1252,                   Accuracy: 57794/60000 (96.32%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1299,                   Accuracy: 57676/60000 (96.13%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1271,                   Accuracy: 57748/60000 (96.25%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1382,                   Accuracy: 57543/60000 (95.90%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1313,                   Accuracy: 57671/60000 (96.12%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1378,                   Accuracy: 57586/60000 (95.98%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1333,                   Accuracy: 57643/60000 (96.07%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1364,                   Accuracy: 57579/60000 (95.96%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1306,                   Accuracy: 57717/60000 (96.19%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1215,                   Accuracy: 57859/60000 (96.43%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1205,                   Accuracy: 57896/60000 (96.49%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1198,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1284,                   Accuracy: 57748/60000 (96.25%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1244,                   Accuracy: 57798/60000 (96.33%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1315,                   Accuracy: 57738/60000 (96.23%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1294,                   Accuracy: 57761/60000 (96.27%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1291,                   Accuracy: 57784/60000 (96.31%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1233,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1176,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1151,                   Accuracy: 58011/60000 (96.68%)
{0: tensor(96.7467), 10: tensor(96.5117), 20: tensor(96.3567), 30: tensor(96.2300), 40: tensor(96.2350), 50: tensor(96.2233), 60: tensor(96.3533), 70: tensor(96.5550), 80: tensor(96.4383), 90: tensor(96.5167), 100: tensor(96.2000), 110: tensor(96.2817), 120: tensor(96.0200), 130: tensor(96.0650), 140: tensor(95.8833), 150: tensor(96.0217), 160: tensor(96.3233), 170: tensor(96.1267), 180: tensor(96.2467), 190: tensor(95.9050), 200: tensor(96.1183), 210: tensor(95.9767), 220: tensor(96.0717), 230: tensor(95.9650), 240: tensor(96.1950), 250: tensor(96.4317), 260: tensor(96.4933), 270: tensor(96.5700), 280: tensor(96.2467), 290: tensor(96.3300), 300: tensor(96.2300), 310: tensor(96.2683), 320: tensor(96.3067), 330: tensor(96.4400), 340: tensor(96.6667), 350: tensor(96.6850)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=87, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8251,                   Accuracy: 597/2000.0 (29.85%)



-= Testing valid =-
Test set: Average loss: 1.4947,                   Accuracy: 894/2000.0 (44.70%)



-= Testing valid =-
Test set: Average loss: 0.9101,                   Accuracy: 1376/2000.0 (68.80%)



-= Testing valid =-
Test set: Average loss: 0.3421,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.5027,                   Accuracy: 1684/2000.0 (84.20%)



-= Testing valid =-
Test set: Average loss: 0.4256,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.3016,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.3065,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.3874,                   Accuracy: 1753/2000.0 (87.65%)



-= Testing valid =-
Test set: Average loss: 0.3149,                   Accuracy: 1811/2000.0 (90.55%)



Epoch 10 train accuracy: 92.95%, valid accuracy 90.55%
-= Testing valid =-
Test set: Average loss: 0.1580,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1471,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1587,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1285,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1853,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1335,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1571,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1761,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1386,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1521,                   Accuracy: 1913/2000.0 (95.65%)



Epoch 20 train accuracy: 95.51%, valid accuracy 95.65%
-= Testing valid =-
Test set: Average loss: 0.1334,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1071,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1244,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1553,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1342,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1089,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1108,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1179,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1168,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1321,                   Accuracy: 1922/2000.0 (96.10%)



Epoch 30 train accuracy: 96.34%, valid accuracy 96.10%
-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1178,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1114,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1151,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1036,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1106,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1021,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 40 train accuracy: 96.70%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1084,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 50 train accuracy: 97.07%, valid accuracy 96.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1020,                   Accuracy: 58198/60000 (97.00%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1158,                   Accuracy: 57930/60000 (96.55%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1161,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1255,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1299,                   Accuracy: 57726/60000 (96.21%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1322,                   Accuracy: 57689/60000 (96.15%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1271,                   Accuracy: 57740/60000 (96.23%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1161,                   Accuracy: 57900/60000 (96.50%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1111,                   Accuracy: 57930/60000 (96.55%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1076,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1235,                   Accuracy: 57776/60000 (96.29%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1211,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1281,                   Accuracy: 57767/60000 (96.28%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1338,                   Accuracy: 57619/60000 (96.03%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1378,                   Accuracy: 57540/60000 (95.90%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1326,                   Accuracy: 57578/60000 (95.96%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1227,                   Accuracy: 57727/60000 (96.21%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1203,                   Accuracy: 57681/60000 (96.14%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1135,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1261,                   Accuracy: 57655/60000 (96.09%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1235,                   Accuracy: 57748/60000 (96.25%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1292,                   Accuracy: 57695/60000 (96.16%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1340,                   Accuracy: 57649/60000 (96.08%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1349,                   Accuracy: 57600/60000 (96.00%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1282,                   Accuracy: 57696/60000 (96.16%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1151,                   Accuracy: 57906/60000 (96.51%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1105,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1052,                   Accuracy: 58094/60000 (96.82%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1159,                   Accuracy: 57863/60000 (96.44%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1168,                   Accuracy: 57928/60000 (96.55%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1264,                   Accuracy: 57782/60000 (96.30%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1295,                   Accuracy: 57744/60000 (96.24%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1300,                   Accuracy: 57716/60000 (96.19%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1237,                   Accuracy: 57806/60000 (96.34%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1104,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1052,                   Accuracy: 58096/60000 (96.83%)
{0: tensor(96.9967), 10: tensor(96.5500), 20: tensor(96.6017), 30: tensor(96.3833), 40: tensor(96.2100), 50: tensor(96.1483), 60: tensor(96.2333), 70: tensor(96.5000), 80: tensor(96.5500), 90: tensor(96.8133), 100: tensor(96.2933), 110: tensor(96.3767), 120: tensor(96.2783), 130: tensor(96.0317), 140: tensor(95.9000), 150: tensor(95.9633), 160: tensor(96.2117), 170: tensor(96.1350), 180: tensor(96.5633), 190: tensor(96.0917), 200: tensor(96.2467), 210: tensor(96.1583), 220: tensor(96.0817), 230: tensor(96.), 240: tensor(96.1600), 250: tensor(96.5100), 260: tensor(96.5800), 270: tensor(96.8233), 280: tensor(96.4383), 290: tensor(96.5467), 300: tensor(96.3033), 310: tensor(96.2400), 320: tensor(96.1933), 330: tensor(96.3433), 340: tensor(96.6967), 350: tensor(96.8267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=88, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8355,                   Accuracy: 640/2000.0 (32.00%)



-= Testing valid =-
Test set: Average loss: 1.3424,                   Accuracy: 1197/2000.0 (59.85%)



-= Testing valid =-
Test set: Average loss: 0.9324,                   Accuracy: 1385/2000.0 (69.25%)



-= Testing valid =-
Test set: Average loss: 0.4563,                   Accuracy: 1726/2000.0 (86.30%)



-= Testing valid =-
Test set: Average loss: 0.5308,                   Accuracy: 1677/2000.0 (83.85%)



-= Testing valid =-
Test set: Average loss: 0.5403,                   Accuracy: 1631/2000.0 (81.55%)



-= Testing valid =-
Test set: Average loss: 0.3193,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.2601,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2983,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2184,                   Accuracy: 1862/2000.0 (93.10%)



Epoch 10 train accuracy: 93.74%, valid accuracy 93.10%
-= Testing valid =-
Test set: Average loss: 0.1547,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1446,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1606,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1538,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1596,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1304,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1092,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1571,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1245,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1100,                   Accuracy: 1928/2000.0 (96.40%)



Epoch 20 train accuracy: 95.75%, valid accuracy 96.40%
-= Testing valid =-
Test set: Average loss: 0.1127,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1070,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1048,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1129,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1053,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0996,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1003,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1067,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 30 train accuracy: 96.56%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 40 train accuracy: 97.04%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 50 train accuracy: 97.20%, valid accuracy 97.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0836,                   Accuracy: 58527/60000 (97.54%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0952,                   Accuracy: 58308/60000 (97.18%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0924,                   Accuracy: 58358/60000 (97.26%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0959,                   Accuracy: 58292/60000 (97.15%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.0975,                   Accuracy: 58229/60000 (97.05%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.0966,                   Accuracy: 58234/60000 (97.06%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.0957,                   Accuracy: 58293/60000 (97.15%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0924,                   Accuracy: 58342/60000 (97.24%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.0952,                   Accuracy: 58283/60000 (97.14%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0896,                   Accuracy: 58400/60000 (97.33%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1034,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1003,                   Accuracy: 58175/60000 (96.96%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1057,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1049,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1036,                   Accuracy: 58061/60000 (96.77%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1053,                   Accuracy: 58042/60000 (96.74%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1006,                   Accuracy: 58141/60000 (96.90%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1077,                   Accuracy: 57994/60000 (96.66%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0978,                   Accuracy: 58202/60000 (97.00%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1085,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1064,                   Accuracy: 58053/60000 (96.75%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1076,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1055,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1009,                   Accuracy: 58131/60000 (96.89%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.0992,                   Accuracy: 58185/60000 (96.97%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.0946,                   Accuracy: 58319/60000 (97.20%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1002,                   Accuracy: 58139/60000 (96.90%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0890,                   Accuracy: 58426/60000 (97.38%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.0984,                   Accuracy: 58245/60000 (97.07%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0966,                   Accuracy: 58283/60000 (97.14%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.0971,                   Accuracy: 58277/60000 (97.13%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.0977,                   Accuracy: 58220/60000 (97.03%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.0952,                   Accuracy: 58278/60000 (97.13%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0917,                   Accuracy: 58383/60000 (97.31%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0890,                   Accuracy: 58426/60000 (97.38%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0905,                   Accuracy: 58356/60000 (97.26%)
{0: tensor(97.5450), 10: tensor(97.1800), 20: tensor(97.2633), 30: tensor(97.1533), 40: tensor(97.0483), 50: tensor(97.0567), 60: tensor(97.1550), 70: tensor(97.2367), 80: tensor(97.1383), 90: tensor(97.3333), 100: tensor(96.8167), 110: tensor(96.9583), 120: tensor(96.7750), 130: tensor(96.7567), 140: tensor(96.7683), 150: tensor(96.7367), 160: tensor(96.9017), 170: tensor(96.6567), 180: tensor(97.0033), 190: tensor(96.6750), 200: tensor(96.7550), 210: tensor(96.7650), 220: tensor(96.7417), 230: tensor(96.8850), 240: tensor(96.9750), 250: tensor(97.1983), 260: tensor(96.8983), 270: tensor(97.3767), 280: tensor(97.0750), 290: tensor(97.1383), 300: tensor(97.1283), 310: tensor(97.0333), 320: tensor(97.1300), 330: tensor(97.3050), 340: tensor(97.3767), 350: tensor(97.2600)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=89, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.6618,                   Accuracy: 222/2000.0 (11.10%)



-= Testing valid =-
Test set: Average loss: 2.1263,                   Accuracy: 528/2000.0 (26.40%)



-= Testing valid =-
Test set: Average loss: 2.0877,                   Accuracy: 907/2000.0 (45.35%)



-= Testing valid =-
Test set: Average loss: 0.6535,                   Accuracy: 1538/2000.0 (76.90%)



-= Testing valid =-
Test set: Average loss: 0.3313,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.2370,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2933,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.6606,                   Accuracy: 1576/2000.0 (78.80%)



-= Testing valid =-
Test set: Average loss: 0.2752,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.3036,                   Accuracy: 1778/2000.0 (88.90%)



Epoch 10 train accuracy: 92.84%, valid accuracy 88.90%
-= Testing valid =-
Test set: Average loss: 0.1960,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1472,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1213,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1638,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1297,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1323,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 20 train accuracy: 95.24%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0682,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 30 train accuracy: 96.01%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0627,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0659,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0722,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0658,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0719,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0737,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 40 train accuracy: 96.75%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0721,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0613,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0736,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0668,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0611,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0675,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0619,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0661,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 50 train accuracy: 96.91%, valid accuracy 97.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1049,                   Accuracy: 58194/60000 (96.99%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1118,                   Accuracy: 58061/60000 (96.77%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1088,                   Accuracy: 58113/60000 (96.86%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1134,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1171,                   Accuracy: 57966/60000 (96.61%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1218,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1253,                   Accuracy: 57765/60000 (96.28%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1234,                   Accuracy: 57769/60000 (96.28%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1246,                   Accuracy: 57764/60000 (96.27%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1195,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1292,                   Accuracy: 57654/60000 (96.09%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1236,                   Accuracy: 57735/60000 (96.22%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1298,                   Accuracy: 57618/60000 (96.03%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1331,                   Accuracy: 57572/60000 (95.95%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1382,                   Accuracy: 57470/60000 (95.78%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1414,                   Accuracy: 57365/60000 (95.61%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1369,                   Accuracy: 57416/60000 (95.69%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1381,                   Accuracy: 57427/60000 (95.71%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1274,                   Accuracy: 57617/60000 (96.03%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1310,                   Accuracy: 57574/60000 (95.96%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1241,                   Accuracy: 57700/60000 (96.17%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1280,                   Accuracy: 57675/60000 (96.12%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1258,                   Accuracy: 57704/60000 (96.17%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1257,                   Accuracy: 57759/60000 (96.26%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1246,                   Accuracy: 57764/60000 (96.27%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1158,                   Accuracy: 57892/60000 (96.49%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1136,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1061,                   Accuracy: 58127/60000 (96.88%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1093,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1067,                   Accuracy: 58150/60000 (96.92%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1102,                   Accuracy: 58089/60000 (96.82%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1123,                   Accuracy: 58054/60000 (96.76%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1147,                   Accuracy: 58011/60000 (96.68%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1146,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1103,                   Accuracy: 58059/60000 (96.76%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1094,                   Accuracy: 58083/60000 (96.81%)
{0: tensor(96.9900), 10: tensor(96.7683), 20: tensor(96.8550), 30: tensor(96.7400), 40: tensor(96.6100), 50: tensor(96.4117), 60: tensor(96.2750), 70: tensor(96.2817), 80: tensor(96.2733), 90: tensor(96.4483), 100: tensor(96.0900), 110: tensor(96.2250), 120: tensor(96.0300), 130: tensor(95.9533), 140: tensor(95.7833), 150: tensor(95.6083), 160: tensor(95.6933), 170: tensor(95.7117), 180: tensor(96.0283), 190: tensor(95.9567), 200: tensor(96.1667), 210: tensor(96.1250), 220: tensor(96.1733), 230: tensor(96.2650), 240: tensor(96.2733), 250: tensor(96.4867), 260: tensor(96.5950), 270: tensor(96.8783), 280: tensor(96.8100), 290: tensor(96.9167), 300: tensor(96.8150), 310: tensor(96.7567), 320: tensor(96.6850), 330: tensor(96.6767), 340: tensor(96.7650), 350: tensor(96.8050)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=90, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1594,                   Accuracy: 501/2000.0 (25.05%)



-= Testing valid =-
Test set: Average loss: 1.1222,                   Accuracy: 1244/2000.0 (62.20%)



-= Testing valid =-
Test set: Average loss: 0.6575,                   Accuracy: 1615/2000.0 (80.75%)



-= Testing valid =-
Test set: Average loss: 0.8312,                   Accuracy: 1344/2000.0 (67.20%)



-= Testing valid =-
Test set: Average loss: 0.6361,                   Accuracy: 1554/2000.0 (77.70%)



-= Testing valid =-
Test set: Average loss: 0.4071,                   Accuracy: 1744/2000.0 (87.20%)



-= Testing valid =-
Test set: Average loss: 0.3944,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.2272,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.1816,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2412,                   Accuracy: 1853/2000.0 (92.65%)



Epoch 10 train accuracy: 93.71%, valid accuracy 92.65%
-= Testing valid =-
Test set: Average loss: 0.1460,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1156,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1327,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1141,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1568,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.0999,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1088,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1232,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1089,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0882,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 20 train accuracy: 95.29%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.1118,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1127,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1037,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1079,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0704,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 30 train accuracy: 96.66%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0739,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0704,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0742,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0766,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 40 train accuracy: 96.84%, valid accuracy 98.05%
-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 50 train accuracy: 97.16%, valid accuracy 97.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1004,                   Accuracy: 58234/60000 (97.06%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1106,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1142,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1193,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1118,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1066,                   Accuracy: 58091/60000 (96.82%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1030,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.0972,                   Accuracy: 58241/60000 (97.07%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1012,                   Accuracy: 58192/60000 (96.99%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1054,                   Accuracy: 58124/60000 (96.87%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1153,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1207,                   Accuracy: 57825/60000 (96.38%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1294,                   Accuracy: 57670/60000 (96.12%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1229,                   Accuracy: 57725/60000 (96.21%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1173,                   Accuracy: 57807/60000 (96.35%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1140,                   Accuracy: 57837/60000 (96.39%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1034,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1111,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1135,                   Accuracy: 57914/60000 (96.52%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1218,                   Accuracy: 57753/60000 (96.25%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1249,                   Accuracy: 57689/60000 (96.15%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1316,                   Accuracy: 57618/60000 (96.03%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1228,                   Accuracy: 57710/60000 (96.18%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1145,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1095,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.0983,                   Accuracy: 58178/60000 (96.96%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1029,                   Accuracy: 58127/60000 (96.88%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1043,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1140,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1144,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1202,                   Accuracy: 57853/60000 (96.42%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1115,                   Accuracy: 57983/60000 (96.64%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1046,                   Accuracy: 58100/60000 (96.83%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0998,                   Accuracy: 58203/60000 (97.00%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0943,                   Accuracy: 58305/60000 (97.18%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0966,                   Accuracy: 58293/60000 (97.15%)
{0: tensor(97.0567), 10: tensor(96.7450), 20: tensor(96.5883), 30: tensor(96.4117), 40: tensor(96.7017), 50: tensor(96.8183), 60: tensor(96.8717), 70: tensor(97.0683), 80: tensor(96.9867), 90: tensor(96.8733), 100: tensor(96.5633), 110: tensor(96.3750), 120: tensor(96.1167), 130: tensor(96.2083), 140: tensor(96.3450), 150: tensor(96.3950), 160: tensor(96.7867), 170: tensor(96.5750), 180: tensor(96.5233), 190: tensor(96.2550), 200: tensor(96.1483), 210: tensor(96.0300), 220: tensor(96.1833), 230: tensor(96.4533), 240: tensor(96.5617), 250: tensor(96.9633), 260: tensor(96.8783), 270: tensor(96.8717), 280: tensor(96.5933), 290: tensor(96.5283), 300: tensor(96.4217), 310: tensor(96.6383), 320: tensor(96.8333), 330: tensor(97.0050), 340: tensor(97.1750), 350: tensor(97.1550)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=91, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3130,                   Accuracy: 430/2000.0 (21.50%)



-= Testing valid =-
Test set: Average loss: 1.2734,                   Accuracy: 1175/2000.0 (58.75%)



-= Testing valid =-
Test set: Average loss: 1.3007,                   Accuracy: 995/2000.0 (49.75%)



-= Testing valid =-
Test set: Average loss: 0.5870,                   Accuracy: 1670/2000.0 (83.50%)



-= Testing valid =-
Test set: Average loss: 0.6156,                   Accuracy: 1643/2000.0 (82.15%)



-= Testing valid =-
Test set: Average loss: 0.3114,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.2850,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.3597,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.3101,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2111,                   Accuracy: 1844/2000.0 (92.20%)



Epoch 10 train accuracy: 92.34%, valid accuracy 92.20%
-= Testing valid =-
Test set: Average loss: 0.1941,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.2395,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.1768,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1800,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1776,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.2009,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1926,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.1849,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.1565,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1215,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 20 train accuracy: 95.51%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.1533,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1426,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1190,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1220,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1294,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1178,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1255,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1351,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1180,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 30 train accuracy: 95.61%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0975,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1058,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1190,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1052,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1111,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1934/2000.0 (96.70%)



Epoch 40 train accuracy: 96.31%, valid accuracy 96.70%
-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1123,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1066,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1083,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1012,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1121,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 50 train accuracy: 96.60%, valid accuracy 96.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1293,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1412,                   Accuracy: 57583/60000 (95.97%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1374,                   Accuracy: 57627/60000 (96.04%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1434,                   Accuracy: 57531/60000 (95.89%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1435,                   Accuracy: 57576/60000 (95.96%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1438,                   Accuracy: 57564/60000 (95.94%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1426,                   Accuracy: 57586/60000 (95.98%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1368,                   Accuracy: 57617/60000 (96.03%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1392,                   Accuracy: 57525/60000 (95.88%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1336,                   Accuracy: 57658/60000 (96.10%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1467,                   Accuracy: 57431/60000 (95.72%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1428,                   Accuracy: 57490/60000 (95.82%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1477,                   Accuracy: 57417/60000 (95.69%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1483,                   Accuracy: 57448/60000 (95.75%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1494,                   Accuracy: 57412/60000 (95.69%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1504,                   Accuracy: 57391/60000 (95.65%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1421,                   Accuracy: 57485/60000 (95.81%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1470,                   Accuracy: 57318/60000 (95.53%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1380,                   Accuracy: 57591/60000 (95.99%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1473,                   Accuracy: 57394/60000 (95.66%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1447,                   Accuracy: 57434/60000 (95.72%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1475,                   Accuracy: 57412/60000 (95.69%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1454,                   Accuracy: 57502/60000 (95.84%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1441,                   Accuracy: 57561/60000 (95.93%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1418,                   Accuracy: 57598/60000 (96.00%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1350,                   Accuracy: 57664/60000 (96.11%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1378,                   Accuracy: 57532/60000 (95.89%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1314,                   Accuracy: 57760/60000 (96.27%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1416,                   Accuracy: 57573/60000 (95.96%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1378,                   Accuracy: 57622/60000 (96.04%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1424,                   Accuracy: 57563/60000 (95.94%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1409,                   Accuracy: 57600/60000 (96.00%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1403,                   Accuracy: 57643/60000 (96.07%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1371,                   Accuracy: 57707/60000 (96.18%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1313,                   Accuracy: 57734/60000 (96.22%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1327,                   Accuracy: 57669/60000 (96.11%)
{0: tensor(96.3600), 10: tensor(95.9717), 20: tensor(96.0450), 30: tensor(95.8850), 40: tensor(95.9600), 50: tensor(95.9400), 60: tensor(95.9767), 70: tensor(96.0283), 80: tensor(95.8750), 90: tensor(96.0967), 100: tensor(95.7183), 110: tensor(95.8167), 120: tensor(95.6950), 130: tensor(95.7467), 140: tensor(95.6867), 150: tensor(95.6517), 160: tensor(95.8083), 170: tensor(95.5300), 180: tensor(95.9850), 190: tensor(95.6567), 200: tensor(95.7233), 210: tensor(95.6867), 220: tensor(95.8367), 230: tensor(95.9350), 240: tensor(95.9967), 250: tensor(96.1067), 260: tensor(95.8867), 270: tensor(96.2667), 280: tensor(95.9550), 290: tensor(96.0367), 300: tensor(95.9383), 310: tensor(96.), 320: tensor(96.0717), 330: tensor(96.1783), 340: tensor(96.2233), 350: tensor(96.1150)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=92, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3508,                   Accuracy: 368/2000.0 (18.40%)



-= Testing valid =-
Test set: Average loss: 2.1915,                   Accuracy: 591/2000.0 (29.55%)



-= Testing valid =-
Test set: Average loss: 1.5355,                   Accuracy: 980/2000.0 (49.00%)



-= Testing valid =-
Test set: Average loss: 1.2160,                   Accuracy: 1188/2000.0 (59.40%)



-= Testing valid =-
Test set: Average loss: 1.6593,                   Accuracy: 857/2000.0 (42.85%)



-= Testing valid =-
Test set: Average loss: 0.2814,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.4650,                   Accuracy: 1732/2000.0 (86.60%)



-= Testing valid =-
Test set: Average loss: 0.2377,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.1751,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.2042,                   Accuracy: 1867/2000.0 (93.35%)



Epoch 10 train accuracy: 93.72%, valid accuracy 93.35%
-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1202,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1379,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1266,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1495,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1227,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1314,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 20 train accuracy: 95.66%, valid accuracy 96.45%
-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0968,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1123,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 30 train accuracy: 96.49%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 40 train accuracy: 96.79%, valid accuracy 97.55%
-= Testing valid =-
Test set: Average loss: 0.0674,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0634,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0700,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0729,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0711,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 50 train accuracy: 97.24%, valid accuracy 97.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0863,                   Accuracy: 58496/60000 (97.49%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1017,                   Accuracy: 58189/60000 (96.98%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1001,                   Accuracy: 58232/60000 (97.05%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1015,                   Accuracy: 58232/60000 (97.05%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1046,                   Accuracy: 58177/60000 (96.96%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1038,                   Accuracy: 58190/60000 (96.98%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1011,                   Accuracy: 58236/60000 (97.06%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1011,                   Accuracy: 58195/60000 (96.99%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1035,                   Accuracy: 58166/60000 (96.94%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0954,                   Accuracy: 58316/60000 (97.19%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1175,                   Accuracy: 57836/60000 (96.39%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1091,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1129,                   Accuracy: 57988/60000 (96.65%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1159,                   Accuracy: 57903/60000 (96.50%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1164,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1146,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1130,                   Accuracy: 57928/60000 (96.55%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1228,                   Accuracy: 57661/60000 (96.10%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1049,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1189,                   Accuracy: 57774/60000 (96.29%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1110,                   Accuracy: 57944/60000 (96.57%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1147,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1133,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1104,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1052,                   Accuracy: 58160/60000 (96.93%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1012,                   Accuracy: 58173/60000 (96.96%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1045,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0910,                   Accuracy: 58389/60000 (97.32%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1010,                   Accuracy: 58155/60000 (96.93%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0986,                   Accuracy: 58240/60000 (97.07%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.0996,                   Accuracy: 58260/60000 (97.10%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1011,                   Accuracy: 58202/60000 (97.00%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.0995,                   Accuracy: 58306/60000 (97.18%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.0953,                   Accuracy: 58364/60000 (97.27%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0932,                   Accuracy: 58370/60000 (97.28%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0932,                   Accuracy: 58343/60000 (97.24%)
{0: tensor(97.4933), 10: tensor(96.9817), 20: tensor(97.0533), 30: tensor(97.0533), 40: tensor(96.9617), 50: tensor(96.9833), 60: tensor(97.0600), 70: tensor(96.9917), 80: tensor(96.9433), 90: tensor(97.1933), 100: tensor(96.3933), 110: tensor(96.7450), 120: tensor(96.6467), 130: tensor(96.5050), 140: tensor(96.5533), 150: tensor(96.5133), 160: tensor(96.5467), 170: tensor(96.1017), 180: tensor(96.7800), 190: tensor(96.2900), 200: tensor(96.5733), 210: tensor(96.5583), 220: tensor(96.5583), 230: tensor(96.6883), 240: tensor(96.9333), 250: tensor(96.9550), 260: tensor(96.8100), 270: tensor(97.3150), 280: tensor(96.9250), 290: tensor(97.0667), 300: tensor(97.1000), 310: tensor(97.0033), 320: tensor(97.1767), 330: tensor(97.2733), 340: tensor(97.2833), 350: tensor(97.2383)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=93, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0876,                   Accuracy: 455/2000.0 (22.75%)



-= Testing valid =-
Test set: Average loss: 2.9664,                   Accuracy: 380/2000.0 (19.00%)



-= Testing valid =-
Test set: Average loss: 1.8250,                   Accuracy: 761/2000.0 (38.05%)



-= Testing valid =-
Test set: Average loss: 1.3003,                   Accuracy: 1190/2000.0 (59.50%)



-= Testing valid =-
Test set: Average loss: 0.5751,                   Accuracy: 1592/2000.0 (79.60%)



-= Testing valid =-
Test set: Average loss: 0.4386,                   Accuracy: 1681/2000.0 (84.05%)



-= Testing valid =-
Test set: Average loss: 0.3856,                   Accuracy: 1725/2000.0 (86.25%)



-= Testing valid =-
Test set: Average loss: 0.2130,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2715,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2263,                   Accuracy: 1865/2000.0 (93.25%)



Epoch 10 train accuracy: 93.10%, valid accuracy 93.25%
-= Testing valid =-
Test set: Average loss: 0.2753,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.1412,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.2142,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.1479,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1887,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1313,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.2190,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.1289,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1646,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1648,                   Accuracy: 1896/2000.0 (94.80%)



Epoch 20 train accuracy: 95.22%, valid accuracy 94.80%
-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1082,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.0882,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 30 train accuracy: 96.01%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0935,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0738,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 40 train accuracy: 96.81%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0755,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0782,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 50 train accuracy: 96.96%, valid accuracy 97.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1135,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1435,                   Accuracy: 57396/60000 (95.66%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1387,                   Accuracy: 57492/60000 (95.82%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1319,                   Accuracy: 57663/60000 (96.11%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1382,                   Accuracy: 57557/60000 (95.93%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1390,                   Accuracy: 57543/60000 (95.90%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1351,                   Accuracy: 57614/60000 (96.02%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1377,                   Accuracy: 57539/60000 (95.90%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1437,                   Accuracy: 57335/60000 (95.56%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1160,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1466,                   Accuracy: 57293/60000 (95.49%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1407,                   Accuracy: 57410/60000 (95.68%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1376,                   Accuracy: 57518/60000 (95.86%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1412,                   Accuracy: 57454/60000 (95.76%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1452,                   Accuracy: 57377/60000 (95.63%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1433,                   Accuracy: 57399/60000 (95.67%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1451,                   Accuracy: 57348/60000 (95.58%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1517,                   Accuracy: 57153/60000 (95.25%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1247,                   Accuracy: 57673/60000 (96.12%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1525,                   Accuracy: 57103/60000 (95.17%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1410,                   Accuracy: 57373/60000 (95.62%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1371,                   Accuracy: 57506/60000 (95.84%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1377,                   Accuracy: 57513/60000 (95.86%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1422,                   Accuracy: 57438/60000 (95.73%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1389,                   Accuracy: 57479/60000 (95.80%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1411,                   Accuracy: 57379/60000 (95.63%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1451,                   Accuracy: 57299/60000 (95.50%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1187,                   Accuracy: 57828/60000 (96.38%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1456,                   Accuracy: 57308/60000 (95.51%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1368,                   Accuracy: 57473/60000 (95.79%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1293,                   Accuracy: 57691/60000 (96.15%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1340,                   Accuracy: 57606/60000 (96.01%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1355,                   Accuracy: 57596/60000 (95.99%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1316,                   Accuracy: 57669/60000 (96.11%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1359,                   Accuracy: 57540/60000 (95.90%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1387,                   Accuracy: 57459/60000 (95.76%)
{0: tensor(96.6033), 10: tensor(95.6600), 20: tensor(95.8200), 30: tensor(96.1050), 40: tensor(95.9283), 50: tensor(95.9050), 60: tensor(96.0233), 70: tensor(95.8983), 80: tensor(95.5583), 90: tensor(96.4167), 100: tensor(95.4883), 110: tensor(95.6833), 120: tensor(95.8633), 130: tensor(95.7567), 140: tensor(95.6283), 150: tensor(95.6650), 160: tensor(95.5800), 170: tensor(95.2550), 180: tensor(96.1217), 190: tensor(95.1717), 200: tensor(95.6217), 210: tensor(95.8433), 220: tensor(95.8550), 230: tensor(95.7300), 240: tensor(95.7983), 250: tensor(95.6317), 260: tensor(95.4983), 270: tensor(96.3800), 280: tensor(95.5133), 290: tensor(95.7883), 300: tensor(96.1517), 310: tensor(96.0100), 320: tensor(95.9933), 330: tensor(96.1150), 340: tensor(95.9000), 350: tensor(95.7650)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=94, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.6967,                   Accuracy: 193/2000.0 (9.65%)



-= Testing valid =-
Test set: Average loss: 1.2073,                   Accuracy: 1176/2000.0 (58.80%)



-= Testing valid =-
Test set: Average loss: 1.1500,                   Accuracy: 1288/2000.0 (64.40%)



-= Testing valid =-
Test set: Average loss: 0.6705,                   Accuracy: 1553/2000.0 (77.65%)



-= Testing valid =-
Test set: Average loss: 0.4790,                   Accuracy: 1709/2000.0 (85.45%)



-= Testing valid =-
Test set: Average loss: 0.3541,                   Accuracy: 1780/2000.0 (89.00%)



-= Testing valid =-
Test set: Average loss: 0.1858,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.2090,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1674,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.2726,                   Accuracy: 1834/2000.0 (91.70%)



Epoch 10 train accuracy: 93.66%, valid accuracy 91.70%
-= Testing valid =-
Test set: Average loss: 0.1209,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1398,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1069,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1208,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1380,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1162,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1211,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1161,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1762,                   Accuracy: 1897/2000.0 (94.85%)



Epoch 20 train accuracy: 95.81%, valid accuracy 94.85%
-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1059,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1244,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1168,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 30 train accuracy: 96.53%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0964,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0879,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 40 train accuracy: 96.97%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 50 train accuracy: 97.20%, valid accuracy 97.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1097,                   Accuracy: 58089/60000 (96.82%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1131,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1079,                   Accuracy: 58057/60000 (96.76%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1176,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1205,                   Accuracy: 57824/60000 (96.37%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1232,                   Accuracy: 57805/60000 (96.34%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1235,                   Accuracy: 57777/60000 (96.29%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1143,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1163,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1106,                   Accuracy: 58058/60000 (96.76%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1133,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1096,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1180,                   Accuracy: 57853/60000 (96.42%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1206,                   Accuracy: 57788/60000 (96.31%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1254,                   Accuracy: 57720/60000 (96.20%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1261,                   Accuracy: 57702/60000 (96.17%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1162,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1187,                   Accuracy: 57853/60000 (96.42%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1125,                   Accuracy: 58019/60000 (96.70%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1157,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1099,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1183,                   Accuracy: 57873/60000 (96.46%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1195,                   Accuracy: 57809/60000 (96.35%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1249,                   Accuracy: 57740/60000 (96.23%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1229,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1139,                   Accuracy: 57931/60000 (96.55%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1142,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1102,                   Accuracy: 58064/60000 (96.77%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1148,                   Accuracy: 57972/60000 (96.62%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1077,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1183,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1204,                   Accuracy: 57853/60000 (96.42%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1235,                   Accuracy: 57805/60000 (96.34%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1225,                   Accuracy: 57825/60000 (96.38%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1148,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1137,                   Accuracy: 57969/60000 (96.61%)
{0: tensor(96.8150), 10: tensor(96.6667), 20: tensor(96.7617), 30: tensor(96.4767), 40: tensor(96.3733), 50: tensor(96.3417), 60: tensor(96.2950), 70: tensor(96.5317), 80: tensor(96.4617), 90: tensor(96.7633), 100: tensor(96.6650), 110: tensor(96.6883), 120: tensor(96.4217), 130: tensor(96.3133), 140: tensor(96.2000), 150: tensor(96.1700), 160: tensor(96.4817), 170: tensor(96.4217), 180: tensor(96.6983), 190: tensor(96.6000), 200: tensor(96.6600), 210: tensor(96.4550), 220: tensor(96.3483), 230: tensor(96.2333), 240: tensor(96.3600), 250: tensor(96.5517), 260: tensor(96.5850), 270: tensor(96.7733), 280: tensor(96.6200), 290: tensor(96.7417), 300: tensor(96.4817), 310: tensor(96.4217), 320: tensor(96.3417), 330: tensor(96.3750), 340: tensor(96.5600), 350: tensor(96.6150)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=95, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1942,                   Accuracy: 358/2000.0 (17.90%)



-= Testing valid =-
Test set: Average loss: 1.9675,                   Accuracy: 574/2000.0 (28.70%)



-= Testing valid =-
Test set: Average loss: 2.0757,                   Accuracy: 551/2000.0 (27.55%)



-= Testing valid =-
Test set: Average loss: 1.3636,                   Accuracy: 1100/2000.0 (55.00%)



-= Testing valid =-
Test set: Average loss: 0.5398,                   Accuracy: 1656/2000.0 (82.80%)



-= Testing valid =-
Test set: Average loss: 0.5047,                   Accuracy: 1688/2000.0 (84.40%)



-= Testing valid =-
Test set: Average loss: 0.3675,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.2395,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.2075,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1940,                   Accuracy: 1872/2000.0 (93.60%)



Epoch 10 train accuracy: 93.21%, valid accuracy 93.60%
-= Testing valid =-
Test set: Average loss: 0.1876,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1283,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.2187,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.1270,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1395,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1651,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1290,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1298,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1273,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1310,                   Accuracy: 1917/2000.0 (95.85%)



Epoch 20 train accuracy: 95.21%, valid accuracy 95.85%
-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1069,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1194,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1420,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 30 train accuracy: 95.95%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0864,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0882,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0990,                   Accuracy: 1928/2000.0 (96.40%)



Epoch 40 train accuracy: 96.62%, valid accuracy 96.40%
-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0825,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0792,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0825,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 50 train accuracy: 97.05%, valid accuracy 96.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1251,                   Accuracy: 57824/60000 (96.37%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1340,                   Accuracy: 57650/60000 (96.08%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1299,                   Accuracy: 57754/60000 (96.26%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1327,                   Accuracy: 57650/60000 (96.08%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1282,                   Accuracy: 57778/60000 (96.30%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1254,                   Accuracy: 57809/60000 (96.35%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1292,                   Accuracy: 57705/60000 (96.18%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1287,                   Accuracy: 57728/60000 (96.21%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1312,                   Accuracy: 57669/60000 (96.11%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1364,                   Accuracy: 57598/60000 (96.00%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1500,                   Accuracy: 57269/60000 (95.45%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1440,                   Accuracy: 57381/60000 (95.64%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1441,                   Accuracy: 57399/60000 (95.67%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1398,                   Accuracy: 57457/60000 (95.76%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1357,                   Accuracy: 57516/60000 (95.86%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1359,                   Accuracy: 57523/60000 (95.87%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1362,                   Accuracy: 57508/60000 (95.85%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1402,                   Accuracy: 57385/60000 (95.64%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1385,                   Accuracy: 57498/60000 (95.83%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1471,                   Accuracy: 57304/60000 (95.51%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1413,                   Accuracy: 57393/60000 (95.65%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1384,                   Accuracy: 57513/60000 (95.86%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1320,                   Accuracy: 57618/60000 (96.03%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1257,                   Accuracy: 57712/60000 (96.19%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1241,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1225,                   Accuracy: 57799/60000 (96.33%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1253,                   Accuracy: 57750/60000 (96.25%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1239,                   Accuracy: 57783/60000 (96.31%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1306,                   Accuracy: 57672/60000 (96.12%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1258,                   Accuracy: 57798/60000 (96.33%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1270,                   Accuracy: 57771/60000 (96.29%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1221,                   Accuracy: 57898/60000 (96.50%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1186,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1212,                   Accuracy: 57870/60000 (96.45%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1192,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1222,                   Accuracy: 57849/60000 (96.42%)
{0: tensor(96.3733), 10: tensor(96.0833), 20: tensor(96.2567), 30: tensor(96.0833), 40: tensor(96.2967), 50: tensor(96.3483), 60: tensor(96.1750), 70: tensor(96.2133), 80: tensor(96.1150), 90: tensor(95.9967), 100: tensor(95.4483), 110: tensor(95.6350), 120: tensor(95.6650), 130: tensor(95.7617), 140: tensor(95.8600), 150: tensor(95.8717), 160: tensor(95.8467), 170: tensor(95.6417), 180: tensor(95.8300), 190: tensor(95.5067), 200: tensor(95.6550), 210: tensor(95.8550), 220: tensor(96.0300), 230: tensor(96.1867), 240: tensor(96.2600), 250: tensor(96.3317), 260: tensor(96.2500), 270: tensor(96.3050), 280: tensor(96.1200), 290: tensor(96.3300), 300: tensor(96.2850), 310: tensor(96.4967), 320: tensor(96.5700), 330: tensor(96.4500), 340: tensor(96.5067), 350: tensor(96.4150)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=96, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9135,                   Accuracy: 678/2000.0 (33.90%)



-= Testing valid =-
Test set: Average loss: 3.7351,                   Accuracy: 181/2000.0 (9.05%)



-= Testing valid =-
Test set: Average loss: 2.4332,                   Accuracy: 503/2000.0 (25.15%)



-= Testing valid =-
Test set: Average loss: 1.0712,                   Accuracy: 1266/2000.0 (63.30%)



-= Testing valid =-
Test set: Average loss: 1.0110,                   Accuracy: 1349/2000.0 (67.45%)



-= Testing valid =-
Test set: Average loss: 0.8864,                   Accuracy: 1371/2000.0 (68.55%)



-= Testing valid =-
Test set: Average loss: 0.3030,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2223,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.9238,                   Accuracy: 1442/2000.0 (72.10%)



-= Testing valid =-
Test set: Average loss: 0.3314,                   Accuracy: 1802/2000.0 (90.10%)



Epoch 10 train accuracy: 92.32%, valid accuracy 90.10%
-= Testing valid =-
Test set: Average loss: 0.1707,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.2211,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.1450,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1710,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1354,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1454,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1893,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1514,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1351,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1331,                   Accuracy: 1910/2000.0 (95.50%)



Epoch 20 train accuracy: 94.54%, valid accuracy 95.50%
-= Testing valid =-
Test set: Average loss: 0.1259,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1473,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1255,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1417,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1170,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1282,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1269,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1243,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1255,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1228,                   Accuracy: 1922/2000.0 (96.10%)



Epoch 30 train accuracy: 96.16%, valid accuracy 96.10%
-= Testing valid =-
Test set: Average loss: 0.1199,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1317,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1289,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1316,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1066,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1051,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1220,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1068,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1145,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 40 train accuracy: 96.55%, valid accuracy 96.45%
-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1058,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1118,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1139,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1117,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1163,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 50 train accuracy: 97.14%, valid accuracy 96.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1145,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1299,                   Accuracy: 57608/60000 (96.01%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1271,                   Accuracy: 57715/60000 (96.19%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1294,                   Accuracy: 57702/60000 (96.17%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1282,                   Accuracy: 57698/60000 (96.16%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1255,                   Accuracy: 57746/60000 (96.24%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1243,                   Accuracy: 57780/60000 (96.30%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1161,                   Accuracy: 57882/60000 (96.47%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1208,                   Accuracy: 57763/60000 (96.27%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1130,                   Accuracy: 57975/60000 (96.62%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1263,                   Accuracy: 57701/60000 (96.17%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1233,                   Accuracy: 57822/60000 (96.37%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1284,                   Accuracy: 57724/60000 (96.21%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1245,                   Accuracy: 57802/60000 (96.34%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1231,                   Accuracy: 57800/60000 (96.33%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1233,                   Accuracy: 57802/60000 (96.34%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1146,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1206,                   Accuracy: 57820/60000 (96.37%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1123,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1279,                   Accuracy: 57684/60000 (96.14%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1248,                   Accuracy: 57745/60000 (96.24%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1279,                   Accuracy: 57730/60000 (96.22%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1237,                   Accuracy: 57807/60000 (96.35%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1222,                   Accuracy: 57844/60000 (96.41%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1212,                   Accuracy: 57833/60000 (96.39%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1139,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1180,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1132,                   Accuracy: 57980/60000 (96.63%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1309,                   Accuracy: 57589/60000 (95.98%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1286,                   Accuracy: 57657/60000 (96.10%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1291,                   Accuracy: 57710/60000 (96.18%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1275,                   Accuracy: 57727/60000 (96.21%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1249,                   Accuracy: 57791/60000 (96.32%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1210,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1166,                   Accuracy: 57845/60000 (96.41%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1203,                   Accuracy: 57822/60000 (96.37%)
{0: tensor(96.5850), 10: tensor(96.0133), 20: tensor(96.1917), 30: tensor(96.1700), 40: tensor(96.1633), 50: tensor(96.2433), 60: tensor(96.3000), 70: tensor(96.4700), 80: tensor(96.2717), 90: tensor(96.6250), 100: tensor(96.1683), 110: tensor(96.3700), 120: tensor(96.2067), 130: tensor(96.3367), 140: tensor(96.3333), 150: tensor(96.3367), 160: tensor(96.5367), 170: tensor(96.3667), 180: tensor(96.6967), 190: tensor(96.1400), 200: tensor(96.2417), 210: tensor(96.2167), 220: tensor(96.3450), 230: tensor(96.4067), 240: tensor(96.3883), 250: tensor(96.5683), 260: tensor(96.4617), 270: tensor(96.6333), 280: tensor(95.9817), 290: tensor(96.0950), 300: tensor(96.1833), 310: tensor(96.2117), 320: tensor(96.3183), 330: tensor(96.4183), 340: tensor(96.4083), 350: tensor(96.3700)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=97, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.1930,                   Accuracy: 327/2000.0 (16.35%)



-= Testing valid =-
Test set: Average loss: 2.0579,                   Accuracy: 454/2000.0 (22.70%)



-= Testing valid =-
Test set: Average loss: 1.1508,                   Accuracy: 1167/2000.0 (58.35%)



-= Testing valid =-
Test set: Average loss: 1.9219,                   Accuracy: 738/2000.0 (36.90%)



-= Testing valid =-
Test set: Average loss: 0.5175,                   Accuracy: 1665/2000.0 (83.25%)



-= Testing valid =-
Test set: Average loss: 0.2872,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2962,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2384,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2506,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.1785,                   Accuracy: 1892/2000.0 (94.60%)



Epoch 10 train accuracy: 93.30%, valid accuracy 94.60%
-= Testing valid =-
Test set: Average loss: 0.1159,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1313,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1186,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1287,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1656,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1221,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1210,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1268,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1352,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1198,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 20 train accuracy: 96.04%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1188,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1213,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 30 train accuracy: 96.65%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 40 train accuracy: 96.95%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 50 train accuracy: 97.19%, valid accuracy 97.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1080,                   Accuracy: 58130/60000 (96.88%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1158,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1116,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1139,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1123,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1123,                   Accuracy: 58034/60000 (96.72%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1106,                   Accuracy: 58076/60000 (96.79%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1081,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1108,                   Accuracy: 58032/60000 (96.72%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1116,                   Accuracy: 58068/60000 (96.78%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1202,                   Accuracy: 57914/60000 (96.52%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1171,                   Accuracy: 57925/60000 (96.54%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1211,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1185,                   Accuracy: 57939/60000 (96.57%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1198,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1183,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1157,                   Accuracy: 57940/60000 (96.57%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1237,                   Accuracy: 57781/60000 (96.30%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1186,                   Accuracy: 57914/60000 (96.52%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1260,                   Accuracy: 57748/60000 (96.25%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1214,                   Accuracy: 57802/60000 (96.34%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1225,                   Accuracy: 57842/60000 (96.40%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1177,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1173,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1165,                   Accuracy: 57983/60000 (96.64%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1133,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1194,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1137,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1200,                   Accuracy: 57890/60000 (96.48%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1143,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1148,                   Accuracy: 58036/60000 (96.73%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1110,                   Accuracy: 58067/60000 (96.78%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1103,                   Accuracy: 58106/60000 (96.84%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1087,                   Accuracy: 58141/60000 (96.90%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1062,                   Accuracy: 58168/60000 (96.95%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1081,                   Accuracy: 58103/60000 (96.84%)
{0: tensor(96.8833), 10: tensor(96.6050), 20: tensor(96.7300), 30: tensor(96.7400), 40: tensor(96.7167), 50: tensor(96.7233), 60: tensor(96.7933), 70: tensor(96.8717), 80: tensor(96.7200), 90: tensor(96.7800), 100: tensor(96.5233), 110: tensor(96.5417), 120: tensor(96.4600), 130: tensor(96.5650), 140: tensor(96.5333), 150: tensor(96.5333), 160: tensor(96.5667), 170: tensor(96.3017), 180: tensor(96.5233), 190: tensor(96.2467), 200: tensor(96.3367), 210: tensor(96.4033), 220: tensor(96.5250), 230: tensor(96.5950), 240: tensor(96.6383), 250: tensor(96.6717), 260: tensor(96.4117), 270: tensor(96.6933), 280: tensor(96.4833), 290: tensor(96.6267), 300: tensor(96.7267), 310: tensor(96.7783), 320: tensor(96.8433), 330: tensor(96.9017), 340: tensor(96.9467), 350: tensor(96.8383)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=98, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.3437,                   Accuracy: 211/2000.0 (10.55%)



-= Testing valid =-
Test set: Average loss: 2.3417,                   Accuracy: 477/2000.0 (23.85%)



-= Testing valid =-
Test set: Average loss: 1.9270,                   Accuracy: 665/2000.0 (33.25%)



-= Testing valid =-
Test set: Average loss: 1.9143,                   Accuracy: 782/2000.0 (39.10%)



-= Testing valid =-
Test set: Average loss: 1.1644,                   Accuracy: 1230/2000.0 (61.50%)



-= Testing valid =-
Test set: Average loss: 0.5639,                   Accuracy: 1673/2000.0 (83.65%)



-= Testing valid =-
Test set: Average loss: 0.4538,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.3086,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.2507,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2496,                   Accuracy: 1840/2000.0 (92.00%)



Epoch 10 train accuracy: 92.16%, valid accuracy 92.00%
-= Testing valid =-
Test set: Average loss: 0.1897,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.2014,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1917,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.1438,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1711,                   Accuracy: 1890/2000.0 (94.50%)



-= Testing valid =-
Test set: Average loss: 0.1469,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.2492,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.1448,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.2011,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.1744,                   Accuracy: 1897/2000.0 (94.85%)



Epoch 20 train accuracy: 95.39%, valid accuracy 94.85%
-= Testing valid =-
Test set: Average loss: 0.1432,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1247,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1894,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1405,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1392,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1255,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1240,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0986,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 30 train accuracy: 96.29%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1253,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1055,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1082,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1124,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 40 train accuracy: 96.66%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1138,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0940,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 50 train accuracy: 97.12%, valid accuracy 96.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1252,                   Accuracy: 57855/60000 (96.43%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1425,                   Accuracy: 57450/60000 (95.75%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1353,                   Accuracy: 57593/60000 (95.99%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1390,                   Accuracy: 57536/60000 (95.89%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1407,                   Accuracy: 57538/60000 (95.90%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1420,                   Accuracy: 57540/60000 (95.90%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1409,                   Accuracy: 57575/60000 (95.96%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1384,                   Accuracy: 57534/60000 (95.89%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1422,                   Accuracy: 57386/60000 (95.64%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1382,                   Accuracy: 57501/60000 (95.83%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1581,                   Accuracy: 57073/60000 (95.12%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1492,                   Accuracy: 57244/60000 (95.41%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1524,                   Accuracy: 57206/60000 (95.34%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1545,                   Accuracy: 57201/60000 (95.33%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1551,                   Accuracy: 57183/60000 (95.31%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1546,                   Accuracy: 57197/60000 (95.33%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1465,                   Accuracy: 57314/60000 (95.52%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1535,                   Accuracy: 57101/60000 (95.17%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1411,                   Accuracy: 57415/60000 (95.69%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1562,                   Accuracy: 57095/60000 (95.16%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1474,                   Accuracy: 57258/60000 (95.43%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1488,                   Accuracy: 57281/60000 (95.47%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1483,                   Accuracy: 57316/60000 (95.53%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1472,                   Accuracy: 57359/60000 (95.60%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1428,                   Accuracy: 57447/60000 (95.75%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1340,                   Accuracy: 57603/60000 (96.00%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1371,                   Accuracy: 57489/60000 (95.82%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1259,                   Accuracy: 57793/60000 (96.32%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1386,                   Accuracy: 57467/60000 (95.78%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1327,                   Accuracy: 57595/60000 (95.99%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1346,                   Accuracy: 57593/60000 (95.99%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1354,                   Accuracy: 57642/60000 (96.07%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1350,                   Accuracy: 57684/60000 (96.14%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1312,                   Accuracy: 57779/60000 (96.30%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1287,                   Accuracy: 57753/60000 (96.25%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1304,                   Accuracy: 57665/60000 (96.11%)
{0: tensor(96.4250), 10: tensor(95.7500), 20: tensor(95.9883), 30: tensor(95.8933), 40: tensor(95.8967), 50: tensor(95.9000), 60: tensor(95.9583), 70: tensor(95.8900), 80: tensor(95.6433), 90: tensor(95.8350), 100: tensor(95.1217), 110: tensor(95.4067), 120: tensor(95.3433), 130: tensor(95.3350), 140: tensor(95.3050), 150: tensor(95.3283), 160: tensor(95.5233), 170: tensor(95.1683), 180: tensor(95.6917), 190: tensor(95.1583), 200: tensor(95.4300), 210: tensor(95.4683), 220: tensor(95.5267), 230: tensor(95.5983), 240: tensor(95.7450), 250: tensor(96.0050), 260: tensor(95.8150), 270: tensor(96.3217), 280: tensor(95.7783), 290: tensor(95.9917), 300: tensor(95.9883), 310: tensor(96.0700), 320: tensor(96.1400), 330: tensor(96.2983), 340: tensor(96.2550), 350: tensor(96.1083)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=99, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 6.4515,                   Accuracy: 196/2000.0 (9.80%)



-= Testing valid =-
Test set: Average loss: 1.9688,                   Accuracy: 634/2000.0 (31.70%)



-= Testing valid =-
Test set: Average loss: 1.7096,                   Accuracy: 1061/2000.0 (53.05%)



-= Testing valid =-
Test set: Average loss: 0.7273,                   Accuracy: 1550/2000.0 (77.50%)



-= Testing valid =-
Test set: Average loss: 0.4083,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.4898,                   Accuracy: 1715/2000.0 (85.75%)



-= Testing valid =-
Test set: Average loss: 0.2514,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2427,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2477,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2479,                   Accuracy: 1842/2000.0 (92.10%)



Epoch 10 train accuracy: 93.41%, valid accuracy 92.10%
-= Testing valid =-
Test set: Average loss: 0.1652,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1614,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1231,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1333,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1738,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1433,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1115,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1057,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 20 train accuracy: 95.41%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.1057,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0910,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0942,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1088,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0904,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0903,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 30 train accuracy: 96.53%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 40 train accuracy: 97.05%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0789,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0708,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0760,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0747,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0715,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 50 train accuracy: 97.32%, valid accuracy 97.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1034,                   Accuracy: 58239/60000 (97.07%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1120,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1118,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1151,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1121,                   Accuracy: 58077/60000 (96.79%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1094,                   Accuracy: 58108/60000 (96.85%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1053,                   Accuracy: 58127/60000 (96.88%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1004,                   Accuracy: 58180/60000 (96.97%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1017,                   Accuracy: 58197/60000 (97.00%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1062,                   Accuracy: 58159/60000 (96.93%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1154,                   Accuracy: 57939/60000 (96.57%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1149,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1184,                   Accuracy: 57926/60000 (96.54%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1140,                   Accuracy: 58028/60000 (96.71%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1107,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1085,                   Accuracy: 58084/60000 (96.81%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.0998,                   Accuracy: 58186/60000 (96.98%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1047,                   Accuracy: 58142/60000 (96.90%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1053,                   Accuracy: 58154/60000 (96.92%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1124,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1130,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1156,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1102,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1073,                   Accuracy: 58140/60000 (96.90%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1054,                   Accuracy: 58166/60000 (96.94%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.0975,                   Accuracy: 58265/60000 (97.11%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1006,                   Accuracy: 58241/60000 (97.07%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1015,                   Accuracy: 58293/60000 (97.15%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1080,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1099,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1127,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1097,                   Accuracy: 58142/60000 (96.90%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1072,                   Accuracy: 58154/60000 (96.92%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1036,                   Accuracy: 58215/60000 (97.03%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0989,                   Accuracy: 58229/60000 (97.05%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.0994,                   Accuracy: 58262/60000 (97.10%)
{0: tensor(97.0650), 10: tensor(96.7500), 20: tensor(96.7433), 30: tensor(96.7167), 40: tensor(96.7950), 50: tensor(96.8467), 60: tensor(96.8783), 70: tensor(96.9667), 80: tensor(96.9950), 90: tensor(96.9317), 100: tensor(96.5650), 110: tensor(96.5833), 120: tensor(96.5433), 130: tensor(96.7133), 140: tensor(96.8167), 150: tensor(96.8067), 160: tensor(96.9767), 170: tensor(96.9033), 180: tensor(96.9233), 190: tensor(96.6683), 200: tensor(96.6433), 210: tensor(96.6483), 220: tensor(96.8483), 230: tensor(96.9000), 240: tensor(96.9433), 250: tensor(97.1083), 260: tensor(97.0683), 270: tensor(97.1550), 280: tensor(96.8683), 290: tensor(96.7833), 300: tensor(96.8017), 310: tensor(96.9033), 320: tensor(96.9233), 330: tensor(97.0250), 340: tensor(97.0483), 350: tensor(97.1033)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=27, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=100, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 27, 27]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 27, 27]      20
├─Dropout: 1-3                           [256, 10, 4, 27, 27]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 27, 27]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 27, 27]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 13, 13]      20
├─Dropout: 1-9                           [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-12                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 13, 13]      20
├─Dropout: 1-15                          [256, 10, 4, 13, 13]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 13, 13]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 13, 13]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 10, 10]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 10, 10]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 6.06
==========================================================================================
Input size (MB): 2.24
Forward/backward pass size (MB): 366.04
Params size (MB): 0.10
Estimated Total Size (MB): 368.38
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1607,                   Accuracy: 463/2000.0 (23.15%)



-= Testing valid =-
Test set: Average loss: 1.6120,                   Accuracy: 727/2000.0 (36.35%)



-= Testing valid =-
Test set: Average loss: 0.8938,                   Accuracy: 1368/2000.0 (68.40%)



-= Testing valid =-
Test set: Average loss: 0.7895,                   Accuracy: 1474/2000.0 (73.70%)



-= Testing valid =-
Test set: Average loss: 0.3686,                   Accuracy: 1744/2000.0 (87.20%)



-= Testing valid =-
Test set: Average loss: 0.3032,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.2673,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.3808,                   Accuracy: 1756/2000.0 (87.80%)



-= Testing valid =-
Test set: Average loss: 0.1893,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.3037,                   Accuracy: 1800/2000.0 (90.00%)



Epoch 10 train accuracy: 93.69%, valid accuracy 90.00%
-= Testing valid =-
Test set: Average loss: 0.1698,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1610,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1836,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1215,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1645,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1511,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1257,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1518,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1010,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1064,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 20 train accuracy: 96.09%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.1225,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1207,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0972,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1285,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1170,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1934/2000.0 (96.70%)



Epoch 30 train accuracy: 96.47%, valid accuracy 96.70%
-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1002,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 40 train accuracy: 97.15%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0798,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0930,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 50 train accuracy: 97.32%, valid accuracy 97.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1076,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1178,                   Accuracy: 57931/60000 (96.55%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1152,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1215,                   Accuracy: 57903/60000 (96.50%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1262,                   Accuracy: 57799/60000 (96.33%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1288,                   Accuracy: 57755/60000 (96.26%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1290,                   Accuracy: 57758/60000 (96.26%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1191,                   Accuracy: 57940/60000 (96.57%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1157,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1114,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1222,                   Accuracy: 57833/60000 (96.39%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1211,                   Accuracy: 57828/60000 (96.38%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1288,                   Accuracy: 57727/60000 (96.21%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1335,                   Accuracy: 57621/60000 (96.04%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1373,                   Accuracy: 57541/60000 (95.90%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1379,                   Accuracy: 57531/60000 (95.89%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1239,                   Accuracy: 57783/60000 (96.31%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1213,                   Accuracy: 57834/60000 (96.39%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1142,                   Accuracy: 57944/60000 (96.57%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1246,                   Accuracy: 57712/60000 (96.19%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1213,                   Accuracy: 57795/60000 (96.32%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1276,                   Accuracy: 57707/60000 (96.18%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1321,                   Accuracy: 57624/60000 (96.04%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1341,                   Accuracy: 57574/60000 (95.96%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1334,                   Accuracy: 57605/60000 (96.01%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1203,                   Accuracy: 57845/60000 (96.41%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1163,                   Accuracy: 57901/60000 (96.50%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1101,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1197,                   Accuracy: 57838/60000 (96.40%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1152,                   Accuracy: 57936/60000 (96.56%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1210,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1247,                   Accuracy: 57813/60000 (96.36%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1279,                   Accuracy: 57729/60000 (96.21%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1262,                   Accuracy: 57757/60000 (96.26%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1170,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1125,                   Accuracy: 57994/60000 (96.66%)
{0: tensor(96.8917), 10: tensor(96.5517), 20: tensor(96.6117), 30: tensor(96.5050), 40: tensor(96.3317), 50: tensor(96.2583), 60: tensor(96.2633), 70: tensor(96.5667), 80: tensor(96.6150), 90: tensor(96.7500), 100: tensor(96.3883), 110: tensor(96.3800), 120: tensor(96.2117), 130: tensor(96.0350), 140: tensor(95.9017), 150: tensor(95.8850), 160: tensor(96.3050), 170: tensor(96.3900), 180: tensor(96.5733), 190: tensor(96.1867), 200: tensor(96.3250), 210: tensor(96.1783), 220: tensor(96.0400), 230: tensor(95.9567), 240: tensor(96.0083), 250: tensor(96.4083), 260: tensor(96.5017), 270: tensor(96.7750), 280: tensor(96.3967), 290: tensor(96.5600), 300: tensor(96.4733), 310: tensor(96.3550), 320: tensor(96.2150), 330: tensor(96.2617), 340: tensor(96.5617), 350: tensor(96.6567)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=71, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6018,                   Accuracy: 358/2000.0 (17.90%)



-= Testing valid =-
Test set: Average loss: 1.5933,                   Accuracy: 914/2000.0 (45.70%)



-= Testing valid =-
Test set: Average loss: 1.1122,                   Accuracy: 1180/2000.0 (59.00%)



-= Testing valid =-
Test set: Average loss: 0.5917,                   Accuracy: 1625/2000.0 (81.25%)



-= Testing valid =-
Test set: Average loss: 0.4159,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.3541,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.2948,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.2222,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.2257,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.2885,                   Accuracy: 1832/2000.0 (91.60%)



Epoch 10 train accuracy: 94.00%, valid accuracy 91.60%
-= Testing valid =-
Test set: Average loss: 0.1483,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1590,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1668,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1765,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1467,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1432,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1267,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1179,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1229,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1133,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 20 train accuracy: 96.20%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.1250,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1277,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1089,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1025,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1048,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1017,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 30 train accuracy: 96.97%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1057,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 40 train accuracy: 97.29%, valid accuracy 97.45%
-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0936,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 50 train accuracy: 97.81%, valid accuracy 97.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0993,                   Accuracy: 58237/60000 (97.06%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1083,                   Accuracy: 58084/60000 (96.81%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1055,                   Accuracy: 58122/60000 (96.87%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1089,                   Accuracy: 58089/60000 (96.82%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1071,                   Accuracy: 58145/60000 (96.91%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1048,                   Accuracy: 58173/60000 (96.96%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1032,                   Accuracy: 58194/60000 (96.99%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1002,                   Accuracy: 58242/60000 (97.07%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1039,                   Accuracy: 58189/60000 (96.98%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0997,                   Accuracy: 58229/60000 (97.05%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1084,                   Accuracy: 58096/60000 (96.83%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1070,                   Accuracy: 58064/60000 (96.77%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1119,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1108,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1105,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1109,                   Accuracy: 58031/60000 (96.72%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1058,                   Accuracy: 58126/60000 (96.88%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1096,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1042,                   Accuracy: 58150/60000 (96.92%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1126,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1081,                   Accuracy: 58052/60000 (96.75%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1099,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1083,                   Accuracy: 58079/60000 (96.80%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1082,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1079,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1050,                   Accuracy: 58145/60000 (96.91%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1079,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1026,                   Accuracy: 58195/60000 (96.99%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1113,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1063,                   Accuracy: 58143/60000 (96.90%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1075,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1050,                   Accuracy: 58174/60000 (96.96%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1041,                   Accuracy: 58190/60000 (96.98%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1017,                   Accuracy: 58235/60000 (97.06%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1002,                   Accuracy: 58264/60000 (97.11%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1032,                   Accuracy: 58203/60000 (97.00%)
{0: tensor(97.0617), 10: tensor(96.8067), 20: tensor(96.8700), 30: tensor(96.8150), 40: tensor(96.9083), 50: tensor(96.9550), 60: tensor(96.9900), 70: tensor(97.0700), 80: tensor(96.9817), 90: tensor(97.0483), 100: tensor(96.8267), 110: tensor(96.7733), 120: tensor(96.6483), 130: tensor(96.6800), 140: tensor(96.7383), 150: tensor(96.7183), 160: tensor(96.8767), 170: tensor(96.7717), 180: tensor(96.9167), 190: tensor(96.5883), 200: tensor(96.7533), 210: tensor(96.7300), 220: tensor(96.7983), 230: tensor(96.8133), 240: tensor(96.8450), 250: tensor(96.9083), 260: tensor(96.8217), 270: tensor(96.9917), 280: tensor(96.6883), 290: tensor(96.9050), 300: tensor(96.8567), 310: tensor(96.9567), 320: tensor(96.9833), 330: tensor(97.0583), 340: tensor(97.1067), 350: tensor(97.0050)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=72, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.5095,                   Accuracy: 346/2000.0 (17.30%)



-= Testing valid =-
Test set: Average loss: 1.3503,                   Accuracy: 1137/2000.0 (56.85%)



-= Testing valid =-
Test set: Average loss: 1.6008,                   Accuracy: 965/2000.0 (48.25%)



-= Testing valid =-
Test set: Average loss: 0.9554,                   Accuracy: 1322/2000.0 (66.10%)



-= Testing valid =-
Test set: Average loss: 1.2647,                   Accuracy: 1174/2000.0 (58.70%)



-= Testing valid =-
Test set: Average loss: 0.4131,                   Accuracy: 1744/2000.0 (87.20%)



-= Testing valid =-
Test set: Average loss: 0.4446,                   Accuracy: 1745/2000.0 (87.25%)



-= Testing valid =-
Test set: Average loss: 0.1938,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.2027,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.2673,                   Accuracy: 1830/2000.0 (91.50%)



Epoch 10 train accuracy: 93.65%, valid accuracy 91.50%
-= Testing valid =-
Test set: Average loss: 0.2529,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.1929,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.2016,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1681,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.3610,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.2001,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1354,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1578,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.2177,                   Accuracy: 1861/2000.0 (93.05%)



Epoch 20 train accuracy: 95.32%, valid accuracy 93.05%
-= Testing valid =-
Test set: Average loss: 0.1070,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1123,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1288,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1155,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1052,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1452,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1428,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1200,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 30 train accuracy: 96.38%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.1251,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1020,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 40 train accuracy: 96.96%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0841,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 50 train accuracy: 97.07%, valid accuracy 97.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1140,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1262,                   Accuracy: 57671/60000 (96.12%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1212,                   Accuracy: 57784/60000 (96.31%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1167,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1184,                   Accuracy: 57867/60000 (96.44%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1208,                   Accuracy: 57825/60000 (96.38%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1210,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1221,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1260,                   Accuracy: 57715/60000 (96.19%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1144,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1273,                   Accuracy: 57609/60000 (96.01%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1200,                   Accuracy: 57823/60000 (96.37%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1173,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1186,                   Accuracy: 57822/60000 (96.37%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1227,                   Accuracy: 57761/60000 (96.27%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1251,                   Accuracy: 57703/60000 (96.17%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1238,                   Accuracy: 57731/60000 (96.22%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1277,                   Accuracy: 57633/60000 (96.06%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1175,                   Accuracy: 57925/60000 (96.54%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1287,                   Accuracy: 57603/60000 (96.00%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1204,                   Accuracy: 57829/60000 (96.38%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1190,                   Accuracy: 57810/60000 (96.35%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1186,                   Accuracy: 57840/60000 (96.40%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1217,                   Accuracy: 57768/60000 (96.28%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1248,                   Accuracy: 57697/60000 (96.16%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1221,                   Accuracy: 57772/60000 (96.29%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1256,                   Accuracy: 57679/60000 (96.13%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1157,                   Accuracy: 57958/60000 (96.60%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1265,                   Accuracy: 57681/60000 (96.14%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1209,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1183,                   Accuracy: 57857/60000 (96.43%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1184,                   Accuracy: 57842/60000 (96.40%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1213,                   Accuracy: 57817/60000 (96.36%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1224,                   Accuracy: 57777/60000 (96.29%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1219,                   Accuracy: 57773/60000 (96.29%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1254,                   Accuracy: 57695/60000 (96.16%)
{0: tensor(96.6800), 10: tensor(96.1183), 20: tensor(96.3067), 30: tensor(96.4750), 40: tensor(96.4450), 50: tensor(96.3750), 60: tensor(96.3650), 70: tensor(96.2600), 80: tensor(96.1917), 90: tensor(96.6767), 100: tensor(96.0150), 110: tensor(96.3717), 120: tensor(96.4600), 130: tensor(96.3700), 140: tensor(96.2683), 150: tensor(96.1717), 160: tensor(96.2183), 170: tensor(96.0550), 180: tensor(96.5417), 190: tensor(96.0050), 200: tensor(96.3817), 210: tensor(96.3500), 220: tensor(96.4000), 230: tensor(96.2800), 240: tensor(96.1617), 250: tensor(96.2867), 260: tensor(96.1317), 270: tensor(96.5967), 280: tensor(96.1350), 290: tensor(96.3650), 300: tensor(96.4283), 310: tensor(96.4033), 320: tensor(96.3617), 330: tensor(96.2950), 340: tensor(96.2883), 350: tensor(96.1583)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=73, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.8158,                   Accuracy: 363/2000.0 (18.15%)



-= Testing valid =-
Test set: Average loss: 1.0010,                   Accuracy: 1361/2000.0 (68.05%)



-= Testing valid =-
Test set: Average loss: 1.1096,                   Accuracy: 1128/2000.0 (56.40%)



-= Testing valid =-
Test set: Average loss: 0.7384,                   Accuracy: 1518/2000.0 (75.90%)



-= Testing valid =-
Test set: Average loss: 0.6818,                   Accuracy: 1536/2000.0 (76.80%)



-= Testing valid =-
Test set: Average loss: 0.3223,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2737,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.1993,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.3280,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.3239,                   Accuracy: 1790/2000.0 (89.50%)



Epoch 10 train accuracy: 93.65%, valid accuracy 89.50%
-= Testing valid =-
Test set: Average loss: 0.1551,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.2576,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.1370,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1771,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1419,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1385,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1643,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1357,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1418,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1721,                   Accuracy: 1890/2000.0 (94.50%)



Epoch 20 train accuracy: 96.29%, valid accuracy 94.50%
-= Testing valid =-
Test set: Average loss: 0.1085,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1306,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1177,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1085,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1107,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1267,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1419,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 30 train accuracy: 96.80%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1050,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0987,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0978,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0909,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0994,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 40 train accuracy: 96.88%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0885,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 50 train accuracy: 97.18%, valid accuracy 97.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1111,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1163,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1167,                   Accuracy: 57978/60000 (96.63%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1219,                   Accuracy: 57925/60000 (96.54%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1246,                   Accuracy: 57905/60000 (96.51%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1272,                   Accuracy: 57823/60000 (96.37%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1254,                   Accuracy: 57810/60000 (96.35%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1205,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1180,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1165,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1212,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1205,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1268,                   Accuracy: 57813/60000 (96.36%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1283,                   Accuracy: 57769/60000 (96.28%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1311,                   Accuracy: 57701/60000 (96.17%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1326,                   Accuracy: 57635/60000 (96.06%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1243,                   Accuracy: 57779/60000 (96.30%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1204,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1186,                   Accuracy: 57912/60000 (96.52%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1214,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1188,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1248,                   Accuracy: 57854/60000 (96.42%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1248,                   Accuracy: 57867/60000 (96.44%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1249,                   Accuracy: 57823/60000 (96.37%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1255,                   Accuracy: 57793/60000 (96.32%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1193,                   Accuracy: 57912/60000 (96.52%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1152,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1123,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1159,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1151,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1199,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1222,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1235,                   Accuracy: 57897/60000 (96.50%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1207,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1168,                   Accuracy: 57949/60000 (96.58%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1136,                   Accuracy: 57983/60000 (96.64%)
{0: tensor(96.8367), 10: tensor(96.5783), 20: tensor(96.6300), 30: tensor(96.5417), 40: tensor(96.5083), 50: tensor(96.3717), 60: tensor(96.3500), 70: tensor(96.4533), 80: tensor(96.5117), 90: tensor(96.6167), 100: tensor(96.4350), 110: tensor(96.4917), 120: tensor(96.3550), 130: tensor(96.2817), 140: tensor(96.1683), 150: tensor(96.0583), 160: tensor(96.2983), 170: tensor(96.4100), 180: tensor(96.5200), 190: tensor(96.4300), 200: tensor(96.5067), 210: tensor(96.4233), 220: tensor(96.4450), 230: tensor(96.3717), 240: tensor(96.3217), 250: tensor(96.5200), 260: tensor(96.6067), 270: tensor(96.7350), 280: tensor(96.5833), 290: tensor(96.6600), 300: tensor(96.6483), 310: tensor(96.5850), 320: tensor(96.4950), 330: tensor(96.5217), 340: tensor(96.5817), 350: tensor(96.6383)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=74, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7538,                   Accuracy: 705/2000.0 (35.25%)



-= Testing valid =-
Test set: Average loss: 1.5517,                   Accuracy: 1017/2000.0 (50.85%)



-= Testing valid =-
Test set: Average loss: 0.9113,                   Accuracy: 1337/2000.0 (66.85%)



-= Testing valid =-
Test set: Average loss: 0.7296,                   Accuracy: 1586/2000.0 (79.30%)



-= Testing valid =-
Test set: Average loss: 0.3548,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.2785,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2057,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2160,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2105,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.1598,                   Accuracy: 1894/2000.0 (94.70%)



Epoch 10 train accuracy: 93.74%, valid accuracy 94.70%
-= Testing valid =-
Test set: Average loss: 0.1473,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1209,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1255,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1944,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1071,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1207,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.2385,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.1057,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1339,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.0978,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 20 train accuracy: 96.05%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1252,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1044,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 30 train accuracy: 96.69%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0909,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0832,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0882,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 40 train accuracy: 96.96%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0874,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0819,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0731,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 50 train accuracy: 97.46%, valid accuracy 97.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0936,                   Accuracy: 58346/60000 (97.24%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1053,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0998,                   Accuracy: 58198/60000 (97.00%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1047,                   Accuracy: 58148/60000 (96.91%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1049,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1060,                   Accuracy: 58099/60000 (96.83%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1053,                   Accuracy: 58096/60000 (96.83%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1022,                   Accuracy: 58111/60000 (96.85%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1031,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0972,                   Accuracy: 58259/60000 (97.10%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1108,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1034,                   Accuracy: 58142/60000 (96.90%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1092,                   Accuracy: 58019/60000 (96.70%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1096,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1119,                   Accuracy: 57982/60000 (96.64%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1114,                   Accuracy: 57924/60000 (96.54%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1052,                   Accuracy: 58055/60000 (96.76%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1069,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1012,                   Accuracy: 58183/60000 (96.97%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1131,                   Accuracy: 57900/60000 (96.50%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1056,                   Accuracy: 58094/60000 (96.82%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1096,                   Accuracy: 58035/60000 (96.72%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1090,                   Accuracy: 57994/60000 (96.66%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1098,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1084,                   Accuracy: 57975/60000 (96.62%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1000,                   Accuracy: 58129/60000 (96.88%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1025,                   Accuracy: 58118/60000 (96.86%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0961,                   Accuracy: 58285/60000 (97.14%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1058,                   Accuracy: 58075/60000 (96.79%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1018,                   Accuracy: 58201/60000 (97.00%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1050,                   Accuracy: 58166/60000 (96.94%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1046,                   Accuracy: 58132/60000 (96.89%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1050,                   Accuracy: 58116/60000 (96.86%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1032,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0987,                   Accuracy: 58211/60000 (97.02%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1002,                   Accuracy: 58214/60000 (97.02%)
{0: tensor(97.2433), 10: tensor(96.8217), 20: tensor(96.9967), 30: tensor(96.9133), 40: tensor(96.8667), 50: tensor(96.8317), 60: tensor(96.8267), 70: tensor(96.8517), 80: tensor(96.8717), 90: tensor(97.0983), 100: tensor(96.5633), 110: tensor(96.9033), 120: tensor(96.6983), 130: tensor(96.6750), 140: tensor(96.6367), 150: tensor(96.5400), 160: tensor(96.7583), 170: tensor(96.6967), 180: tensor(96.9717), 190: tensor(96.5000), 200: tensor(96.8233), 210: tensor(96.7250), 220: tensor(96.6567), 230: tensor(96.6583), 240: tensor(96.6250), 250: tensor(96.8817), 260: tensor(96.8633), 270: tensor(97.1417), 280: tensor(96.7917), 290: tensor(97.0017), 300: tensor(96.9433), 310: tensor(96.8867), 320: tensor(96.8600), 330: tensor(96.9500), 340: tensor(97.0183), 350: tensor(97.0233)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=75, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.6392,                   Accuracy: 219/2000.0 (10.95%)



-= Testing valid =-
Test set: Average loss: 2.2634,                   Accuracy: 529/2000.0 (26.45%)



-= Testing valid =-
Test set: Average loss: 1.2254,                   Accuracy: 1152/2000.0 (57.60%)



-= Testing valid =-
Test set: Average loss: 0.7904,                   Accuracy: 1424/2000.0 (71.20%)



-= Testing valid =-
Test set: Average loss: 0.9203,                   Accuracy: 1466/2000.0 (73.30%)



-= Testing valid =-
Test set: Average loss: 0.4211,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.2716,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.1864,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.2439,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.1904,                   Accuracy: 1874/2000.0 (93.70%)



Epoch 10 train accuracy: 93.46%, valid accuracy 93.70%
-= Testing valid =-
Test set: Average loss: 0.1533,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1694,                   Accuracy: 1886/2000.0 (94.30%)



-= Testing valid =-
Test set: Average loss: 0.1355,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1274,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1308,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1880,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1082,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1210,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1193,                   Accuracy: 1921/2000.0 (96.05%)



Epoch 20 train accuracy: 95.84%, valid accuracy 96.05%
-= Testing valid =-
Test set: Average loss: 0.1150,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0913,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 30 train accuracy: 96.90%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0718,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0719,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0710,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0687,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0751,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 40 train accuracy: 97.20%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0709,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0725,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0745,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0736,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0769,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0755,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 50 train accuracy: 97.44%, valid accuracy 97.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0968,                   Accuracy: 58334/60000 (97.22%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1014,                   Accuracy: 58215/60000 (97.03%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1001,                   Accuracy: 58221/60000 (97.04%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1090,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1127,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1153,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1151,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1060,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1021,                   Accuracy: 58221/60000 (97.04%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0981,                   Accuracy: 58307/60000 (97.18%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1022,                   Accuracy: 58198/60000 (97.00%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1007,                   Accuracy: 58202/60000 (97.00%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1094,                   Accuracy: 58051/60000 (96.75%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1118,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1150,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1152,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1081,                   Accuracy: 58137/60000 (96.89%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1033,                   Accuracy: 58167/60000 (96.94%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0987,                   Accuracy: 58267/60000 (97.11%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1006,                   Accuracy: 58234/60000 (97.06%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.0996,                   Accuracy: 58224/60000 (97.04%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1091,                   Accuracy: 58070/60000 (96.78%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1092,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1120,                   Accuracy: 58030/60000 (96.72%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1126,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1048,                   Accuracy: 58160/60000 (96.93%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1015,                   Accuracy: 58226/60000 (97.04%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0972,                   Accuracy: 58301/60000 (97.17%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.0989,                   Accuracy: 58263/60000 (97.11%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0994,                   Accuracy: 58247/60000 (97.08%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1086,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1101,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1116,                   Accuracy: 58033/60000 (96.72%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1123,                   Accuracy: 58088/60000 (96.81%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1034,                   Accuracy: 58205/60000 (97.01%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1004,                   Accuracy: 58249/60000 (97.08%)
{0: tensor(97.2233), 10: tensor(97.0250), 20: tensor(97.0350), 30: tensor(96.7967), 40: tensor(96.6417), 50: tensor(96.6583), 60: tensor(96.7050), 70: tensor(96.9417), 80: tensor(97.0350), 90: tensor(97.1783), 100: tensor(96.9967), 110: tensor(97.0033), 120: tensor(96.7517), 130: tensor(96.6517), 140: tensor(96.6167), 150: tensor(96.6417), 160: tensor(96.8950), 170: tensor(96.9450), 180: tensor(97.1117), 190: tensor(97.0567), 200: tensor(97.0400), 210: tensor(96.7833), 220: tensor(96.7383), 230: tensor(96.7167), 240: tensor(96.7717), 250: tensor(96.9333), 260: tensor(97.0433), 270: tensor(97.1683), 280: tensor(97.1050), 290: tensor(97.0783), 300: tensor(96.8283), 310: tensor(96.7017), 320: tensor(96.7217), 330: tensor(96.8133), 340: tensor(97.0083), 350: tensor(97.0817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=76, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2343,                   Accuracy: 398/2000.0 (19.90%)



-= Testing valid =-
Test set: Average loss: 2.6841,                   Accuracy: 451/2000.0 (22.55%)



-= Testing valid =-
Test set: Average loss: 1.3964,                   Accuracy: 972/2000.0 (48.60%)



-= Testing valid =-
Test set: Average loss: 2.2405,                   Accuracy: 695/2000.0 (34.75%)



-= Testing valid =-
Test set: Average loss: 0.4495,                   Accuracy: 1711/2000.0 (85.55%)



-= Testing valid =-
Test set: Average loss: 0.4059,                   Accuracy: 1728/2000.0 (86.40%)



-= Testing valid =-
Test set: Average loss: 0.4924,                   Accuracy: 1685/2000.0 (84.25%)



-= Testing valid =-
Test set: Average loss: 0.2572,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2531,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2977,                   Accuracy: 1798/2000.0 (89.90%)



Epoch 10 train accuracy: 92.26%, valid accuracy 89.90%
-= Testing valid =-
Test set: Average loss: 0.2471,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.1274,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1282,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1251,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1444,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1257,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1457,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1134,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1003,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 20 train accuracy: 94.70%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.1212,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 30 train accuracy: 95.97%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0738,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0703,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0762,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0877,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1955/2000.0 (97.75%)



Epoch 40 train accuracy: 96.79%, valid accuracy 97.75%
-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0779,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0723,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0748,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 50 train accuracy: 96.53%, valid accuracy 97.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1054,                   Accuracy: 58156/60000 (96.93%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1149,                   Accuracy: 57990/60000 (96.65%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1098,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1166,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1236,                   Accuracy: 57838/60000 (96.40%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1280,                   Accuracy: 57717/60000 (96.19%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1289,                   Accuracy: 57699/60000 (96.17%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1251,                   Accuracy: 57737/60000 (96.23%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1331,                   Accuracy: 57526/60000 (95.88%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1130,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1224,                   Accuracy: 57796/60000 (96.33%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1161,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1241,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1312,                   Accuracy: 57684/60000 (96.14%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1392,                   Accuracy: 57469/60000 (95.78%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1422,                   Accuracy: 57405/60000 (95.68%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1376,                   Accuracy: 57443/60000 (95.74%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1469,                   Accuracy: 57217/60000 (95.36%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1209,                   Accuracy: 57761/60000 (96.27%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1329,                   Accuracy: 57511/60000 (95.85%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1173,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1223,                   Accuracy: 57842/60000 (96.40%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1267,                   Accuracy: 57778/60000 (96.30%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1323,                   Accuracy: 57655/60000 (96.09%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1332,                   Accuracy: 57602/60000 (96.00%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1284,                   Accuracy: 57664/60000 (96.11%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1304,                   Accuracy: 57544/60000 (95.91%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1104,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1220,                   Accuracy: 57791/60000 (96.32%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1097,                   Accuracy: 58092/60000 (96.82%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1145,                   Accuracy: 58007/60000 (96.68%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1187,                   Accuracy: 57946/60000 (96.58%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1227,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1224,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1177,                   Accuracy: 57897/60000 (96.50%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1208,                   Accuracy: 57837/60000 (96.39%)
{0: tensor(96.9267), 10: tensor(96.6500), 20: tensor(96.8083), 30: tensor(96.6683), 40: tensor(96.3967), 50: tensor(96.1950), 60: tensor(96.1650), 70: tensor(96.2283), 80: tensor(95.8767), 90: tensor(96.6517), 100: tensor(96.3267), 110: tensor(96.5700), 120: tensor(96.3650), 130: tensor(96.1400), 140: tensor(95.7817), 150: tensor(95.6750), 160: tensor(95.7383), 170: tensor(95.3617), 180: tensor(96.2683), 190: tensor(95.8517), 200: tensor(96.4400), 210: tensor(96.4033), 220: tensor(96.2967), 230: tensor(96.0917), 240: tensor(96.0033), 250: tensor(96.1067), 260: tensor(95.9067), 270: tensor(96.7500), 280: tensor(96.3183), 290: tensor(96.8200), 300: tensor(96.6783), 310: tensor(96.5767), 320: tensor(96.4350), 330: tensor(96.3833), 340: tensor(96.4950), 350: tensor(96.3950)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=77, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9512,                   Accuracy: 571/2000.0 (28.55%)



-= Testing valid =-
Test set: Average loss: 2.0215,                   Accuracy: 570/2000.0 (28.50%)



-= Testing valid =-
Test set: Average loss: 1.4380,                   Accuracy: 908/2000.0 (45.40%)



-= Testing valid =-
Test set: Average loss: 0.6739,                   Accuracy: 1543/2000.0 (77.15%)



-= Testing valid =-
Test set: Average loss: 0.3341,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.2524,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2231,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2975,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.2784,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2719,                   Accuracy: 1838/2000.0 (91.90%)



Epoch 10 train accuracy: 93.28%, valid accuracy 91.90%
-= Testing valid =-
Test set: Average loss: 0.2394,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.1479,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1619,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1446,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1738,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.1851,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1441,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1999,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1600,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1341,                   Accuracy: 1916/2000.0 (95.80%)



Epoch 20 train accuracy: 95.30%, valid accuracy 95.80%
-= Testing valid =-
Test set: Average loss: 0.1177,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0997,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1035,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1313,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1435,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1124,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1227,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1058,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1021,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 30 train accuracy: 96.34%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0919,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1109,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 40 train accuracy: 96.75%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0836,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0923,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 50 train accuracy: 97.20%, valid accuracy 97.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1141,                   Accuracy: 58022/60000 (96.70%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1155,                   Accuracy: 57901/60000 (96.50%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1144,                   Accuracy: 58007/60000 (96.68%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1170,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1151,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1153,                   Accuracy: 57944/60000 (96.57%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1171,                   Accuracy: 57926/60000 (96.54%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1143,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1141,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1162,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1197,                   Accuracy: 57833/60000 (96.39%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1182,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1217,                   Accuracy: 57856/60000 (96.43%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1207,                   Accuracy: 57844/60000 (96.41%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1219,                   Accuracy: 57801/60000 (96.33%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1231,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1192,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1197,                   Accuracy: 57873/60000 (96.46%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1225,                   Accuracy: 57823/60000 (96.37%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1198,                   Accuracy: 57824/60000 (96.37%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1201,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1238,                   Accuracy: 57776/60000 (96.29%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1199,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1181,                   Accuracy: 57906/60000 (96.51%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1188,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1158,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1192,                   Accuracy: 57839/60000 (96.40%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1193,                   Accuracy: 57903/60000 (96.50%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1148,                   Accuracy: 57909/60000 (96.51%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1155,                   Accuracy: 57949/60000 (96.58%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1194,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1142,                   Accuracy: 57982/60000 (96.64%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1126,                   Accuracy: 57997/60000 (96.66%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1142,                   Accuracy: 57979/60000 (96.63%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1115,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1144,                   Accuracy: 57987/60000 (96.64%)
{0: tensor(96.7033), 10: tensor(96.5017), 20: tensor(96.6783), 30: tensor(96.5783), 40: tensor(96.6400), 50: tensor(96.5733), 60: tensor(96.5433), 70: tensor(96.6150), 80: tensor(96.6800), 90: tensor(96.6133), 100: tensor(96.3883), 110: tensor(96.6133), 120: tensor(96.4267), 130: tensor(96.4067), 140: tensor(96.3350), 150: tensor(96.3567), 160: tensor(96.4767), 170: tensor(96.4550), 180: tensor(96.3717), 190: tensor(96.3733), 200: tensor(96.4600), 210: tensor(96.2933), 220: tensor(96.4433), 230: tensor(96.5100), 240: tensor(96.4300), 250: tensor(96.5583), 260: tensor(96.3983), 270: tensor(96.5050), 280: tensor(96.5150), 290: tensor(96.5817), 300: tensor(96.4900), 310: tensor(96.6367), 320: tensor(96.6617), 330: tensor(96.6317), 340: tensor(96.7050), 350: tensor(96.6450)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=78, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.0335,                   Accuracy: 410/2000.0 (20.50%)



-= Testing valid =-
Test set: Average loss: 1.3129,                   Accuracy: 975/2000.0 (48.75%)



-= Testing valid =-
Test set: Average loss: 1.5417,                   Accuracy: 1100/2000.0 (55.00%)



-= Testing valid =-
Test set: Average loss: 1.3208,                   Accuracy: 1163/2000.0 (58.15%)



-= Testing valid =-
Test set: Average loss: 0.6225,                   Accuracy: 1598/2000.0 (79.90%)



-= Testing valid =-
Test set: Average loss: 0.8100,                   Accuracy: 1491/2000.0 (74.55%)



-= Testing valid =-
Test set: Average loss: 0.2252,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.4422,                   Accuracy: 1714/2000.0 (85.70%)



-= Testing valid =-
Test set: Average loss: 0.2121,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.1677,                   Accuracy: 1909/2000.0 (95.45%)



Epoch 10 train accuracy: 93.00%, valid accuracy 95.45%
-= Testing valid =-
Test set: Average loss: 0.1677,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1916,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1785,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1520,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1460,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1622,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1412,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1662,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1925,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.1570,                   Accuracy: 1906/2000.0 (95.30%)



Epoch 20 train accuracy: 95.86%, valid accuracy 95.30%
-= Testing valid =-
Test set: Average loss: 0.1296,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1246,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1170,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1214,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1298,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1207,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1320,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1260,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1201,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1125,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 30 train accuracy: 96.76%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.1090,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1088,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1258,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1148,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1191,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1322,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1265,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1077,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1132,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 40 train accuracy: 97.00%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1066,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1153,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1123,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1067,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1063,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1065,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1072,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 50 train accuracy: 97.35%, valid accuracy 96.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1123,                   Accuracy: 58119/60000 (96.86%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1241,                   Accuracy: 57782/60000 (96.30%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1209,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1176,                   Accuracy: 57967/60000 (96.61%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1179,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1184,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1162,                   Accuracy: 58026/60000 (96.71%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1175,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1194,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1122,                   Accuracy: 58109/60000 (96.85%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1252,                   Accuracy: 57770/60000 (96.28%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1223,                   Accuracy: 57811/60000 (96.35%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1193,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1184,                   Accuracy: 57930/60000 (96.55%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1202,                   Accuracy: 57925/60000 (96.54%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1208,                   Accuracy: 57912/60000 (96.52%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1191,                   Accuracy: 57923/60000 (96.54%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1203,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1149,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1260,                   Accuracy: 57756/60000 (96.26%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1198,                   Accuracy: 57845/60000 (96.41%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1176,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1154,                   Accuracy: 58003/60000 (96.67%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1175,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1190,                   Accuracy: 57940/60000 (96.57%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1178,                   Accuracy: 57954/60000 (96.59%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1216,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1140,                   Accuracy: 58064/60000 (96.77%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1249,                   Accuracy: 57768/60000 (96.28%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1193,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1169,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1154,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1175,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1161,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1174,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1205,                   Accuracy: 57942/60000 (96.57%)
{0: tensor(96.8650), 10: tensor(96.3033), 20: tensor(96.4767), 30: tensor(96.6117), 40: tensor(96.6767), 50: tensor(96.6433), 60: tensor(96.7100), 70: tensor(96.6733), 80: tensor(96.5833), 90: tensor(96.8483), 100: tensor(96.2833), 110: tensor(96.3517), 120: tensor(96.5217), 130: tensor(96.5500), 140: tensor(96.5417), 150: tensor(96.5200), 160: tensor(96.5383), 170: tensor(96.5683), 180: tensor(96.7717), 190: tensor(96.2600), 200: tensor(96.4083), 210: tensor(96.5950), 220: tensor(96.6717), 230: tensor(96.6900), 240: tensor(96.5667), 250: tensor(96.5900), 260: tensor(96.4983), 270: tensor(96.7733), 280: tensor(96.2800), 290: tensor(96.4783), 300: tensor(96.6067), 310: tensor(96.7433), 320: tensor(96.7317), 330: tensor(96.7083), 340: tensor(96.6750), 350: tensor(96.5700)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=79, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9693,                   Accuracy: 500/2000.0 (25.00%)



-= Testing valid =-
Test set: Average loss: 1.5292,                   Accuracy: 918/2000.0 (45.90%)



-= Testing valid =-
Test set: Average loss: 2.1935,                   Accuracy: 784/2000.0 (39.20%)



-= Testing valid =-
Test set: Average loss: 1.0245,                   Accuracy: 1281/2000.0 (64.05%)



-= Testing valid =-
Test set: Average loss: 0.4860,                   Accuracy: 1663/2000.0 (83.15%)



-= Testing valid =-
Test set: Average loss: 0.2773,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2591,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.1954,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.1980,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.1533,                   Accuracy: 1911/2000.0 (95.55%)



Epoch 10 train accuracy: 93.25%, valid accuracy 95.55%
-= Testing valid =-
Test set: Average loss: 0.1241,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1740,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1425,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1226,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1197,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1393,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1134,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 20 train accuracy: 95.22%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0861,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0764,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0765,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 30 train accuracy: 96.59%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0800,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0726,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0724,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0763,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0807,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0757,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0728,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0716,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0749,                   Accuracy: 1953/2000.0 (97.65%)



Epoch 40 train accuracy: 96.97%, valid accuracy 97.65%
-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0713,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0702,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0697,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0710,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0738,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0709,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 50 train accuracy: 97.06%, valid accuracy 97.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1005,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1082,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1085,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1114,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1144,                   Accuracy: 57940/60000 (96.57%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1148,                   Accuracy: 57954/60000 (96.59%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1127,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1056,                   Accuracy: 58104/60000 (96.84%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1069,                   Accuracy: 58022/60000 (96.70%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0973,                   Accuracy: 58206/60000 (97.01%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1062,                   Accuracy: 58026/60000 (96.71%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1040,                   Accuracy: 58101/60000 (96.83%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1071,                   Accuracy: 58074/60000 (96.79%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1095,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1116,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1101,                   Accuracy: 58084/60000 (96.81%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1043,                   Accuracy: 58150/60000 (96.92%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1035,                   Accuracy: 58110/60000 (96.85%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0952,                   Accuracy: 58264/60000 (97.11%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1057,                   Accuracy: 58073/60000 (96.79%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1038,                   Accuracy: 58067/60000 (96.78%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1074,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1097,                   Accuracy: 58047/60000 (96.75%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1121,                   Accuracy: 58028/60000 (96.71%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1114,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1053,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1036,                   Accuracy: 58089/60000 (96.82%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0974,                   Accuracy: 58228/60000 (97.05%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1074,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1083,                   Accuracy: 57994/60000 (96.66%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1121,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1153,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1157,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1151,                   Accuracy: 57990/60000 (96.65%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1079,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1077,                   Accuracy: 58044/60000 (96.74%)
{0: tensor(96.9417), 10: tensor(96.6483), 20: tensor(96.6800), 30: tensor(96.6733), 40: tensor(96.5667), 50: tensor(96.5900), 60: tensor(96.6450), 70: tensor(96.8400), 80: tensor(96.7033), 90: tensor(97.0100), 100: tensor(96.7100), 110: tensor(96.8350), 120: tensor(96.7900), 130: tensor(96.7433), 140: tensor(96.7433), 150: tensor(96.8067), 160: tensor(96.9167), 170: tensor(96.8500), 180: tensor(97.1067), 190: tensor(96.7883), 200: tensor(96.7783), 210: tensor(96.8100), 220: tensor(96.7450), 230: tensor(96.7133), 240: tensor(96.7283), 250: tensor(96.8917), 260: tensor(96.8150), 270: tensor(97.0467), 280: tensor(96.7300), 290: tensor(96.6567), 300: tensor(96.6683), 310: tensor(96.5633), 320: tensor(96.5533), 330: tensor(96.6500), 340: tensor(96.7717), 350: tensor(96.7400)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=80, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 7.1626,                   Accuracy: 214/2000.0 (10.70%)



-= Testing valid =-
Test set: Average loss: 4.1113,                   Accuracy: 237/2000.0 (11.85%)



-= Testing valid =-
Test set: Average loss: 1.1517,                   Accuracy: 1169/2000.0 (58.45%)



-= Testing valid =-
Test set: Average loss: 0.8400,                   Accuracy: 1414/2000.0 (70.70%)



-= Testing valid =-
Test set: Average loss: 0.3934,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.3270,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.4859,                   Accuracy: 1687/2000.0 (84.35%)



-= Testing valid =-
Test set: Average loss: 0.1795,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1940,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.3164,                   Accuracy: 1802/2000.0 (90.10%)



Epoch 10 train accuracy: 92.79%, valid accuracy 90.10%
-= Testing valid =-
Test set: Average loss: 0.1604,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1585,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1927,                   Accuracy: 1883/2000.0 (94.15%)



-= Testing valid =-
Test set: Average loss: 0.2215,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.1168,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1266,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.2047,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.1351,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1477,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1182,                   Accuracy: 1923/2000.0 (96.15%)



Epoch 20 train accuracy: 95.62%, valid accuracy 96.15%
-= Testing valid =-
Test set: Average loss: 0.1287,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1108,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1283,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1050,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1264,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1167,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1365,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 30 train accuracy: 96.70%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1030,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1054,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0978,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1076,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 40 train accuracy: 96.76%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0883,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0869,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1012,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0908,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 50 train accuracy: 97.25%, valid accuracy 97.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1110,                   Accuracy: 58105/60000 (96.84%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1137,                   Accuracy: 58020/60000 (96.70%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1098,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1154,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1133,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1141,                   Accuracy: 58026/60000 (96.71%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1158,                   Accuracy: 57984/60000 (96.64%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1118,                   Accuracy: 58049/60000 (96.75%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1128,                   Accuracy: 58027/60000 (96.71%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1121,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1154,                   Accuracy: 57939/60000 (96.57%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1118,                   Accuracy: 58021/60000 (96.70%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1163,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1149,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1150,                   Accuracy: 57981/60000 (96.64%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1178,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1135,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1156,                   Accuracy: 57946/60000 (96.58%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1145,                   Accuracy: 57990/60000 (96.65%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1137,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1132,                   Accuracy: 58013/60000 (96.69%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1187,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1141,                   Accuracy: 57982/60000 (96.64%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1144,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1158,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1121,                   Accuracy: 58017/60000 (96.69%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1162,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1117,                   Accuracy: 58084/60000 (96.81%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1101,                   Accuracy: 58064/60000 (96.77%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1102,                   Accuracy: 58102/60000 (96.84%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1176,                   Accuracy: 57955/60000 (96.59%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1127,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1136,                   Accuracy: 58028/60000 (96.71%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1144,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1115,                   Accuracy: 58039/60000 (96.73%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1140,                   Accuracy: 58007/60000 (96.68%)
{0: tensor(96.8417), 10: tensor(96.7000), 20: tensor(96.8217), 30: tensor(96.6183), 40: tensor(96.6833), 50: tensor(96.7100), 60: tensor(96.6400), 70: tensor(96.7483), 80: tensor(96.7117), 90: tensor(96.7717), 100: tensor(96.5650), 110: tensor(96.7017), 120: tensor(96.5750), 130: tensor(96.6067), 140: tensor(96.6350), 150: tensor(96.4750), 160: tensor(96.5883), 170: tensor(96.5767), 180: tensor(96.6500), 190: tensor(96.5617), 200: tensor(96.6883), 210: tensor(96.5550), 220: tensor(96.6367), 230: tensor(96.6800), 240: tensor(96.5850), 250: tensor(96.6950), 260: tensor(96.5483), 270: tensor(96.8067), 280: tensor(96.7733), 290: tensor(96.8367), 300: tensor(96.5917), 310: tensor(96.7300), 320: tensor(96.7133), 330: tensor(96.6967), 340: tensor(96.7317), 350: tensor(96.6783)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=81, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1941,                   Accuracy: 427/2000.0 (21.35%)



-= Testing valid =-
Test set: Average loss: 1.4258,                   Accuracy: 893/2000.0 (44.65%)



-= Testing valid =-
Test set: Average loss: 2.2589,                   Accuracy: 654/2000.0 (32.70%)



-= Testing valid =-
Test set: Average loss: 0.5183,                   Accuracy: 1620/2000.0 (81.00%)



-= Testing valid =-
Test set: Average loss: 0.4386,                   Accuracy: 1682/2000.0 (84.10%)



-= Testing valid =-
Test set: Average loss: 0.5427,                   Accuracy: 1666/2000.0 (83.30%)



-= Testing valid =-
Test set: Average loss: 0.3459,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.3856,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.3858,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.1548,                   Accuracy: 1904/2000.0 (95.20%)



Epoch 10 train accuracy: 93.21%, valid accuracy 95.20%
-= Testing valid =-
Test set: Average loss: 0.2063,                   Accuracy: 1874/2000.0 (93.70%)



-= Testing valid =-
Test set: Average loss: 0.1605,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.2048,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1701,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1114,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1210,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1661,                   Accuracy: 1903/2000.0 (95.15%)



-= Testing valid =-
Test set: Average loss: 0.1520,                   Accuracy: 1904/2000.0 (95.20%)



-= Testing valid =-
Test set: Average loss: 0.1212,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1075,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 20 train accuracy: 95.56%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1105,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1046,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1062,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1102,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0982,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1943/2000.0 (97.15%)



Epoch 30 train accuracy: 96.43%, valid accuracy 97.15%
-= Testing valid =-
Test set: Average loss: 0.0935,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1046,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0914,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 40 train accuracy: 97.24%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0893,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0881,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0847,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0894,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 50 train accuracy: 97.28%, valid accuracy 97.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1092,                   Accuracy: 58218/60000 (97.03%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1220,                   Accuracy: 57960/60000 (96.60%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1171,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1187,                   Accuracy: 57985/60000 (96.64%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1160,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1143,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1113,                   Accuracy: 58083/60000 (96.81%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1106,                   Accuracy: 58101/60000 (96.83%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1164,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1173,                   Accuracy: 58019/60000 (96.70%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1371,                   Accuracy: 57608/60000 (96.01%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1297,                   Accuracy: 57714/60000 (96.19%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1338,                   Accuracy: 57619/60000 (96.03%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1299,                   Accuracy: 57673/60000 (96.12%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1293,                   Accuracy: 57632/60000 (96.05%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1252,                   Accuracy: 57738/60000 (96.23%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1231,                   Accuracy: 57781/60000 (96.30%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1308,                   Accuracy: 57666/60000 (96.11%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1290,                   Accuracy: 57746/60000 (96.24%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1398,                   Accuracy: 57530/60000 (95.88%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1300,                   Accuracy: 57700/60000 (96.17%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1299,                   Accuracy: 57742/60000 (96.24%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1220,                   Accuracy: 57882/60000 (96.47%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1177,                   Accuracy: 57889/60000 (96.48%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1141,                   Accuracy: 57976/60000 (96.63%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1109,                   Accuracy: 58082/60000 (96.80%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1172,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1154,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1223,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1173,                   Accuracy: 58042/60000 (96.74%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1172,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1118,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1088,                   Accuracy: 58146/60000 (96.91%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1047,                   Accuracy: 58245/60000 (97.07%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1043,                   Accuracy: 58242/60000 (97.07%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1085,                   Accuracy: 58178/60000 (96.96%)
{0: tensor(97.0300), 10: tensor(96.6000), 20: tensor(96.7283), 30: tensor(96.6417), 40: tensor(96.6433), 50: tensor(96.7050), 60: tensor(96.8050), 70: tensor(96.8350), 80: tensor(96.6767), 90: tensor(96.6983), 100: tensor(96.0133), 110: tensor(96.1900), 120: tensor(96.0317), 130: tensor(96.1217), 140: tensor(96.0533), 150: tensor(96.2300), 160: tensor(96.3017), 170: tensor(96.1100), 180: tensor(96.2433), 190: tensor(95.8833), 200: tensor(96.1667), 210: tensor(96.2367), 220: tensor(96.4700), 230: tensor(96.4817), 240: tensor(96.6267), 250: tensor(96.8033), 260: tensor(96.6150), 270: tensor(96.7333), 280: tensor(96.5250), 290: tensor(96.7367), 300: tensor(96.7300), 310: tensor(96.8383), 320: tensor(96.9100), 330: tensor(97.0750), 340: tensor(97.0700), 350: tensor(96.9633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=82, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2277,                   Accuracy: 406/2000.0 (20.30%)



-= Testing valid =-
Test set: Average loss: 2.2484,                   Accuracy: 567/2000.0 (28.35%)



-= Testing valid =-
Test set: Average loss: 1.2139,                   Accuracy: 1142/2000.0 (57.10%)



-= Testing valid =-
Test set: Average loss: 0.3537,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.2983,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.2411,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2249,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2245,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2340,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.1674,                   Accuracy: 1897/2000.0 (94.85%)



Epoch 10 train accuracy: 94.32%, valid accuracy 94.85%
-= Testing valid =-
Test set: Average loss: 0.1570,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1251,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1282,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1221,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1185,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1182,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1036,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1092,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0909,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 20 train accuracy: 96.10%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1012,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0935,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0925,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 30 train accuracy: 97.15%, valid accuracy 97.20%
-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0795,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0807,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 40 train accuracy: 97.21%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0799,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 50 train accuracy: 97.50%, valid accuracy 97.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1154,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1183,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1146,                   Accuracy: 57932/60000 (96.55%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1189,                   Accuracy: 57873/60000 (96.46%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1230,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1264,                   Accuracy: 57716/60000 (96.19%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1313,                   Accuracy: 57615/60000 (96.03%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1294,                   Accuracy: 57643/60000 (96.07%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1246,                   Accuracy: 57769/60000 (96.28%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1189,                   Accuracy: 57837/60000 (96.39%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1222,                   Accuracy: 57753/60000 (96.25%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1172,                   Accuracy: 57850/60000 (96.42%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1201,                   Accuracy: 57823/60000 (96.37%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1231,                   Accuracy: 57777/60000 (96.29%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1237,                   Accuracy: 57740/60000 (96.23%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1301,                   Accuracy: 57614/60000 (96.02%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1262,                   Accuracy: 57695/60000 (96.16%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1250,                   Accuracy: 57701/60000 (96.17%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1192,                   Accuracy: 57848/60000 (96.41%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1215,                   Accuracy: 57743/60000 (96.24%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1142,                   Accuracy: 57912/60000 (96.52%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1171,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1179,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1182,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1230,                   Accuracy: 57771/60000 (96.29%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1197,                   Accuracy: 57838/60000 (96.40%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1170,                   Accuracy: 57874/60000 (96.46%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1136,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1157,                   Accuracy: 57898/60000 (96.50%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1103,                   Accuracy: 58015/60000 (96.69%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1147,                   Accuracy: 57931/60000 (96.55%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1179,                   Accuracy: 57927/60000 (96.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1211,                   Accuracy: 57818/60000 (96.36%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1252,                   Accuracy: 57734/60000 (96.22%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1237,                   Accuracy: 57775/60000 (96.29%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1190,                   Accuracy: 57890/60000 (96.48%)
{0: tensor(96.6067), 10: tensor(96.4350), 20: tensor(96.5533), 30: tensor(96.4550), 40: tensor(96.3400), 50: tensor(96.1933), 60: tensor(96.0250), 70: tensor(96.0717), 80: tensor(96.2817), 90: tensor(96.3950), 100: tensor(96.2550), 110: tensor(96.4167), 120: tensor(96.3717), 130: tensor(96.2950), 140: tensor(96.2333), 150: tensor(96.0233), 160: tensor(96.1583), 170: tensor(96.1683), 180: tensor(96.4133), 190: tensor(96.2383), 200: tensor(96.5200), 210: tensor(96.4750), 220: tensor(96.4733), 230: tensor(96.3833), 240: tensor(96.2850), 250: tensor(96.3967), 260: tensor(96.4567), 270: tensor(96.6800), 280: tensor(96.4967), 290: tensor(96.6917), 300: tensor(96.5517), 310: tensor(96.5450), 320: tensor(96.3633), 330: tensor(96.2233), 340: tensor(96.2917), 350: tensor(96.4833)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=83, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1612,                   Accuracy: 470/2000.0 (23.50%)



-= Testing valid =-
Test set: Average loss: 3.3771,                   Accuracy: 227/2000.0 (11.35%)



-= Testing valid =-
Test set: Average loss: 1.1724,                   Accuracy: 1222/2000.0 (61.10%)



-= Testing valid =-
Test set: Average loss: 1.4410,                   Accuracy: 1110/2000.0 (55.50%)



-= Testing valid =-
Test set: Average loss: 0.3419,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2898,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.2478,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.2574,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.4090,                   Accuracy: 1729/2000.0 (86.45%)



-= Testing valid =-
Test set: Average loss: 0.2365,                   Accuracy: 1850/2000.0 (92.50%)



Epoch 10 train accuracy: 93.20%, valid accuracy 92.50%
-= Testing valid =-
Test set: Average loss: 0.1648,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.2004,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1357,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1233,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1336,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1411,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1369,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1428,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1288,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1310,                   Accuracy: 1918/2000.0 (95.90%)



Epoch 20 train accuracy: 95.62%, valid accuracy 95.90%
-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1198,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1001,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1070,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1000,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 30 train accuracy: 96.89%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.1012,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0944,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 40 train accuracy: 97.05%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0862,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0843,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 50 train accuracy: 97.06%, valid accuracy 97.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0969,                   Accuracy: 58336/60000 (97.23%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1044,                   Accuracy: 58176/60000 (96.96%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1042,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1075,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1096,                   Accuracy: 58103/60000 (96.84%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1096,                   Accuracy: 58119/60000 (96.86%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1095,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1077,                   Accuracy: 58150/60000 (96.92%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1068,                   Accuracy: 58134/60000 (96.89%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1047,                   Accuracy: 58151/60000 (96.92%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1133,                   Accuracy: 57946/60000 (96.58%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1142,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1191,                   Accuracy: 57817/60000 (96.36%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1185,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1192,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1207,                   Accuracy: 57841/60000 (96.40%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1161,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1198,                   Accuracy: 57857/60000 (96.43%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1149,                   Accuracy: 57905/60000 (96.51%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1217,                   Accuracy: 57718/60000 (96.20%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1172,                   Accuracy: 57818/60000 (96.36%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1193,                   Accuracy: 57750/60000 (96.25%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1159,                   Accuracy: 57898/60000 (96.50%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1144,                   Accuracy: 57979/60000 (96.63%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1139,                   Accuracy: 57989/60000 (96.65%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1094,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1087,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1020,                   Accuracy: 58247/60000 (97.08%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1079,                   Accuracy: 58086/60000 (96.81%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1036,                   Accuracy: 58156/60000 (96.93%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1054,                   Accuracy: 58130/60000 (96.88%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1058,                   Accuracy: 58150/60000 (96.92%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1058,                   Accuracy: 58189/60000 (96.98%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1051,                   Accuracy: 58193/60000 (96.99%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1028,                   Accuracy: 58234/60000 (97.06%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1008,                   Accuracy: 58272/60000 (97.12%)
{0: tensor(97.2267), 10: tensor(96.9600), 20: tensor(96.9500), 30: tensor(96.8567), 40: tensor(96.8383), 50: tensor(96.8650), 60: tensor(96.8283), 70: tensor(96.9167), 80: tensor(96.8900), 90: tensor(96.9183), 100: tensor(96.5767), 110: tensor(96.5217), 120: tensor(96.3617), 130: tensor(96.4483), 140: tensor(96.4183), 150: tensor(96.4017), 160: tensor(96.5483), 170: tensor(96.4283), 180: tensor(96.5083), 190: tensor(96.1967), 200: tensor(96.3633), 210: tensor(96.2500), 220: tensor(96.4967), 230: tensor(96.6317), 240: tensor(96.6483), 250: tensor(96.7967), 260: tensor(96.8750), 270: tensor(97.0783), 280: tensor(96.8100), 290: tensor(96.9267), 300: tensor(96.8833), 310: tensor(96.9167), 320: tensor(96.9817), 330: tensor(96.9883), 340: tensor(97.0567), 350: tensor(97.1200)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=84, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8312,                   Accuracy: 637/2000.0 (31.85%)



-= Testing valid =-
Test set: Average loss: 1.5819,                   Accuracy: 757/2000.0 (37.85%)



-= Testing valid =-
Test set: Average loss: 1.6167,                   Accuracy: 903/2000.0 (45.15%)



-= Testing valid =-
Test set: Average loss: 0.5147,                   Accuracy: 1678/2000.0 (83.90%)



-= Testing valid =-
Test set: Average loss: 0.7400,                   Accuracy: 1532/2000.0 (76.60%)



-= Testing valid =-
Test set: Average loss: 0.2179,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.2239,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.3053,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2156,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.1766,                   Accuracy: 1901/2000.0 (95.05%)



Epoch 10 train accuracy: 94.14%, valid accuracy 95.05%
-= Testing valid =-
Test set: Average loss: 0.1350,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1819,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1525,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1184,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1340,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1111,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1102,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1121,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1175,                   Accuracy: 1930/2000.0 (96.50%)



Epoch 20 train accuracy: 96.04%, valid accuracy 96.50%
-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1080,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1083,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.1092,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0964,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0953,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1166,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0918,                   Accuracy: 1942/2000.0 (97.10%)



Epoch 30 train accuracy: 96.68%, valid accuracy 97.10%
-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0805,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0897,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0853,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0771,                   Accuracy: 1959/2000.0 (97.95%)



Epoch 40 train accuracy: 97.10%, valid accuracy 97.95%
-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0816,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0867,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1956/2000.0 (97.80%)



Epoch 50 train accuracy: 97.50%, valid accuracy 97.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1004,                   Accuracy: 58267/60000 (97.11%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1106,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1073,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1115,                   Accuracy: 58087/60000 (96.81%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1105,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1095,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1075,                   Accuracy: 58084/60000 (96.81%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1000,                   Accuracy: 58249/60000 (97.08%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1018,                   Accuracy: 58171/60000 (96.95%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1024,                   Accuracy: 58179/60000 (96.96%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1149,                   Accuracy: 57913/60000 (96.52%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1100,                   Accuracy: 58072/60000 (96.79%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1132,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1125,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1119,                   Accuracy: 58010/60000 (96.68%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1100,                   Accuracy: 58064/60000 (96.77%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1024,                   Accuracy: 58171/60000 (96.95%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1043,                   Accuracy: 58120/60000 (96.87%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1029,                   Accuracy: 58183/60000 (96.97%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1116,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1080,                   Accuracy: 58117/60000 (96.86%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1111,                   Accuracy: 58078/60000 (96.80%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1096,                   Accuracy: 58061/60000 (96.77%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1073,                   Accuracy: 58094/60000 (96.82%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1064,                   Accuracy: 58134/60000 (96.89%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.0989,                   Accuracy: 58266/60000 (97.11%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1025,                   Accuracy: 58183/60000 (96.97%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1005,                   Accuracy: 58260/60000 (97.10%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1072,                   Accuracy: 58095/60000 (96.82%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1056,                   Accuracy: 58161/60000 (96.93%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1100,                   Accuracy: 58106/60000 (96.84%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1081,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1058,                   Accuracy: 58133/60000 (96.89%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1038,                   Accuracy: 58178/60000 (96.96%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.0973,                   Accuracy: 58294/60000 (97.16%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1007,                   Accuracy: 58216/60000 (97.03%)
{0: tensor(97.1117), 10: tensor(96.7050), 20: tensor(96.8567), 30: tensor(96.8117), 40: tensor(96.7383), 50: tensor(96.8083), 60: tensor(96.8067), 70: tensor(97.0817), 80: tensor(96.9517), 90: tensor(96.9650), 100: tensor(96.5217), 110: tensor(96.7867), 120: tensor(96.6967), 130: tensor(96.6650), 140: tensor(96.6833), 150: tensor(96.7733), 160: tensor(96.9517), 170: tensor(96.8667), 180: tensor(96.9717), 190: tensor(96.6650), 200: tensor(96.8617), 210: tensor(96.7967), 220: tensor(96.7683), 230: tensor(96.8233), 240: tensor(96.8900), 250: tensor(97.1100), 260: tensor(96.9717), 270: tensor(97.1000), 280: tensor(96.8250), 290: tensor(96.9350), 300: tensor(96.8433), 310: tensor(96.7850), 320: tensor(96.8883), 330: tensor(96.9633), 340: tensor(97.1567), 350: tensor(97.0267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=85, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 7.1644,                   Accuracy: 241/2000.0 (12.05%)



-= Testing valid =-
Test set: Average loss: 1.4924,                   Accuracy: 919/2000.0 (45.95%)



-= Testing valid =-
Test set: Average loss: 1.0445,                   Accuracy: 1306/2000.0 (65.30%)



-= Testing valid =-
Test set: Average loss: 0.9372,                   Accuracy: 1334/2000.0 (66.70%)



-= Testing valid =-
Test set: Average loss: 0.3894,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.4898,                   Accuracy: 1692/2000.0 (84.60%)



-= Testing valid =-
Test set: Average loss: 0.2548,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.2435,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.2421,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2816,                   Accuracy: 1826/2000.0 (91.30%)



Epoch 10 train accuracy: 93.43%, valid accuracy 91.30%
-= Testing valid =-
Test set: Average loss: 0.2184,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.1640,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1764,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1449,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1413,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1418,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1391,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1474,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1279,                   Accuracy: 1915/2000.0 (95.75%)



Epoch 20 train accuracy: 96.05%, valid accuracy 95.75%
-= Testing valid =-
Test set: Average loss: 0.1043,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1269,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1135,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1290,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1139,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1081,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1283,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1190,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.0986,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1027,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 30 train accuracy: 96.97%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1102,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1204,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1012,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1072,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0981,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1056,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 40 train accuracy: 96.84%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1053,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0963,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0890,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0899,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 50 train accuracy: 97.30%, valid accuracy 97.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1121,                   Accuracy: 58081/60000 (96.80%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1287,                   Accuracy: 57786/60000 (96.31%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1218,                   Accuracy: 57857/60000 (96.43%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1186,                   Accuracy: 57918/60000 (96.53%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1157,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1166,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1161,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1196,                   Accuracy: 57877/60000 (96.46%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1286,                   Accuracy: 57707/60000 (96.18%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1129,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1301,                   Accuracy: 57690/60000 (96.15%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1223,                   Accuracy: 57852/60000 (96.42%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1180,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1177,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1190,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1195,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1240,                   Accuracy: 57763/60000 (96.27%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1312,                   Accuracy: 57621/60000 (96.04%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1149,                   Accuracy: 57975/60000 (96.62%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1333,                   Accuracy: 57633/60000 (96.06%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1216,                   Accuracy: 57842/60000 (96.40%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1179,                   Accuracy: 57931/60000 (96.55%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1163,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1189,                   Accuracy: 57853/60000 (96.42%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1190,                   Accuracy: 57847/60000 (96.41%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1233,                   Accuracy: 57825/60000 (96.38%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1307,                   Accuracy: 57648/60000 (96.08%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1136,                   Accuracy: 58028/60000 (96.71%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1309,                   Accuracy: 57725/60000 (96.21%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1205,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1180,                   Accuracy: 57945/60000 (96.57%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1141,                   Accuracy: 57981/60000 (96.64%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1161,                   Accuracy: 57941/60000 (96.57%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1161,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1200,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1292,                   Accuracy: 57703/60000 (96.17%)
{0: tensor(96.8017), 10: tensor(96.3100), 20: tensor(96.4283), 30: tensor(96.5300), 40: tensor(96.5483), 50: tensor(96.5700), 60: tensor(96.5550), 70: tensor(96.4617), 80: tensor(96.1783), 90: tensor(96.6933), 100: tensor(96.1500), 110: tensor(96.4200), 120: tensor(96.5583), 130: tensor(96.4850), 140: tensor(96.4100), 150: tensor(96.3767), 160: tensor(96.2717), 170: tensor(96.0350), 180: tensor(96.6250), 190: tensor(96.0550), 200: tensor(96.4033), 210: tensor(96.5517), 220: tensor(96.5250), 230: tensor(96.4217), 240: tensor(96.4117), 250: tensor(96.3750), 260: tensor(96.0800), 270: tensor(96.7133), 280: tensor(96.2083), 290: tensor(96.4733), 300: tensor(96.5750), 310: tensor(96.6350), 320: tensor(96.5683), 330: tensor(96.5617), 340: tensor(96.5133), 350: tensor(96.1717)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=86, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.1184,                   Accuracy: 397/2000.0 (19.85%)



-= Testing valid =-
Test set: Average loss: 1.5503,                   Accuracy: 889/2000.0 (44.45%)



-= Testing valid =-
Test set: Average loss: 1.8584,                   Accuracy: 805/2000.0 (40.25%)



-= Testing valid =-
Test set: Average loss: 0.6372,                   Accuracy: 1579/2000.0 (78.95%)



-= Testing valid =-
Test set: Average loss: 0.4261,                   Accuracy: 1753/2000.0 (87.65%)



-= Testing valid =-
Test set: Average loss: 0.5407,                   Accuracy: 1693/2000.0 (84.65%)



-= Testing valid =-
Test set: Average loss: 0.5648,                   Accuracy: 1637/2000.0 (81.85%)



-= Testing valid =-
Test set: Average loss: 0.1823,                   Accuracy: 1895/2000.0 (94.75%)



-= Testing valid =-
Test set: Average loss: 0.1942,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.3550,                   Accuracy: 1742/2000.0 (87.10%)



Epoch 10 train accuracy: 92.81%, valid accuracy 87.10%
-= Testing valid =-
Test set: Average loss: 0.2524,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.1292,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1277,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1104,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1963,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.1117,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1095,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1142,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1123,                   Accuracy: 1930/2000.0 (96.50%)



Epoch 20 train accuracy: 95.36%, valid accuracy 96.50%
-= Testing valid =-
Test set: Average loss: 0.0910,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0813,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 30 train accuracy: 96.47%, valid accuracy 97.50%
-= Testing valid =-
Test set: Average loss: 0.0705,                   Accuracy: 1963/2000.0 (98.15%)



-= Testing valid =-
Test set: Average loss: 0.0706,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0821,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0708,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0730,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0643,                   Accuracy: 1964/2000.0 (98.20%)



Epoch 40 train accuracy: 97.16%, valid accuracy 98.20%
-= Testing valid =-
Test set: Average loss: 0.0674,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0662,                   Accuracy: 1965/2000.0 (98.25%)



-= Testing valid =-
Test set: Average loss: 0.0667,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0631,                   Accuracy: 1966/2000.0 (98.30%)



-= Testing valid =-
Test set: Average loss: 0.0666,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0663,                   Accuracy: 1964/2000.0 (98.20%)



-= Testing valid =-
Test set: Average loss: 0.0673,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0645,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1961/2000.0 (98.05%)



Epoch 50 train accuracy: 97.20%, valid accuracy 98.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1015,                   Accuracy: 58271/60000 (97.12%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1135,                   Accuracy: 58033/60000 (96.72%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1150,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1196,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1186,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1191,                   Accuracy: 57956/60000 (96.59%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1159,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1139,                   Accuracy: 58008/60000 (96.68%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1160,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1152,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1290,                   Accuracy: 57677/60000 (96.13%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1306,                   Accuracy: 57660/60000 (96.10%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1408,                   Accuracy: 57490/60000 (95.82%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1392,                   Accuracy: 57524/60000 (95.87%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1400,                   Accuracy: 57506/60000 (95.84%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1390,                   Accuracy: 57513/60000 (95.86%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1287,                   Accuracy: 57688/60000 (96.15%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1343,                   Accuracy: 57576/60000 (95.96%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1279,                   Accuracy: 57671/60000 (96.12%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1405,                   Accuracy: 57408/60000 (95.68%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1337,                   Accuracy: 57567/60000 (95.94%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1386,                   Accuracy: 57478/60000 (95.80%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1327,                   Accuracy: 57642/60000 (96.07%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1276,                   Accuracy: 57734/60000 (96.22%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1224,                   Accuracy: 57824/60000 (96.37%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1122,                   Accuracy: 58000/60000 (96.67%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1132,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1069,                   Accuracy: 58147/60000 (96.91%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1170,                   Accuracy: 57905/60000 (96.51%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1142,                   Accuracy: 58004/60000 (96.67%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1157,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1135,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1111,                   Accuracy: 58105/60000 (96.84%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1055,                   Accuracy: 58221/60000 (97.04%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1028,                   Accuracy: 58212/60000 (97.02%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1036,                   Accuracy: 58198/60000 (97.00%)
{0: tensor(97.1183), 10: tensor(96.7217), 20: tensor(96.7433), 30: tensor(96.6017), 40: tensor(96.5950), 50: tensor(96.5933), 60: tensor(96.6450), 70: tensor(96.6800), 80: tensor(96.6067), 90: tensor(96.6733), 100: tensor(96.1283), 110: tensor(96.1000), 120: tensor(95.8167), 130: tensor(95.8733), 140: tensor(95.8433), 150: tensor(95.8550), 160: tensor(96.1467), 170: tensor(95.9600), 180: tensor(96.1183), 190: tensor(95.6800), 200: tensor(95.9450), 210: tensor(95.7967), 220: tensor(96.0700), 230: tensor(96.2233), 240: tensor(96.3733), 250: tensor(96.6667), 260: tensor(96.6683), 270: tensor(96.9117), 280: tensor(96.5083), 290: tensor(96.6733), 300: tensor(96.6900), 310: tensor(96.7667), 320: tensor(96.8417), 330: tensor(97.0350), 340: tensor(97.0200), 350: tensor(96.9967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=87, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5126,                   Accuracy: 482/2000.0 (24.10%)



-= Testing valid =-
Test set: Average loss: 1.3484,                   Accuracy: 941/2000.0 (47.05%)



-= Testing valid =-
Test set: Average loss: 1.0115,                   Accuracy: 1285/2000.0 (64.25%)



-= Testing valid =-
Test set: Average loss: 0.8576,                   Accuracy: 1424/2000.0 (71.20%)



-= Testing valid =-
Test set: Average loss: 0.3565,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.3881,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.2332,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.2519,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2737,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2497,                   Accuracy: 1853/2000.0 (92.65%)



Epoch 10 train accuracy: 93.91%, valid accuracy 92.65%
-= Testing valid =-
Test set: Average loss: 0.1649,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1568,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1292,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1741,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1325,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1693,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1537,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1285,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1339,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1163,                   Accuracy: 1929/2000.0 (96.45%)



Epoch 20 train accuracy: 96.09%, valid accuracy 96.45%
-= Testing valid =-
Test set: Average loss: 0.1180,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1163,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1335,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1161,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0828,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1140,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 30 train accuracy: 96.85%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.1034,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1022,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0837,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0924,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0808,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 40 train accuracy: 96.89%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.0860,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0880,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0876,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0798,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 50 train accuracy: 97.26%, valid accuracy 97.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1019,                   Accuracy: 58215/60000 (97.03%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1122,                   Accuracy: 58022/60000 (96.70%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1036,                   Accuracy: 58148/60000 (96.91%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1052,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1031,                   Accuracy: 58125/60000 (96.88%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1053,                   Accuracy: 58122/60000 (96.87%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1052,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1045,                   Accuracy: 58083/60000 (96.81%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1128,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1055,                   Accuracy: 58135/60000 (96.89%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1184,                   Accuracy: 57826/60000 (96.38%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1093,                   Accuracy: 58043/60000 (96.74%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1097,                   Accuracy: 58050/60000 (96.75%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1077,                   Accuracy: 58023/60000 (96.71%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1106,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1113,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1101,                   Accuracy: 57981/60000 (96.64%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1155,                   Accuracy: 57870/60000 (96.45%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1083,                   Accuracy: 58066/60000 (96.78%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1198,                   Accuracy: 57820/60000 (96.37%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1089,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1093,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1067,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1083,                   Accuracy: 58007/60000 (96.68%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1099,                   Accuracy: 57986/60000 (96.64%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1065,                   Accuracy: 58041/60000 (96.74%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1131,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1029,                   Accuracy: 58157/60000 (96.93%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1126,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1029,                   Accuracy: 58165/60000 (96.94%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1040,                   Accuracy: 58143/60000 (96.90%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1015,                   Accuracy: 58130/60000 (96.88%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1043,                   Accuracy: 58117/60000 (96.86%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1040,                   Accuracy: 58123/60000 (96.87%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1029,                   Accuracy: 58096/60000 (96.83%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1118,                   Accuracy: 57943/60000 (96.57%)
{0: tensor(97.0250), 10: tensor(96.7033), 20: tensor(96.9133), 30: tensor(96.8683), 40: tensor(96.8750), 50: tensor(96.8700), 60: tensor(96.8567), 70: tensor(96.8050), 80: tensor(96.5283), 90: tensor(96.8917), 100: tensor(96.3767), 110: tensor(96.7383), 120: tensor(96.7500), 130: tensor(96.7050), 140: tensor(96.6817), 150: tensor(96.6183), 160: tensor(96.6350), 170: tensor(96.4500), 180: tensor(96.7767), 190: tensor(96.3667), 200: tensor(96.7083), 210: tensor(96.6433), 220: tensor(96.6933), 230: tensor(96.6783), 240: tensor(96.6433), 250: tensor(96.7350), 260: tensor(96.5250), 270: tensor(96.9283), 280: tensor(96.6133), 290: tensor(96.9417), 300: tensor(96.9050), 310: tensor(96.8833), 320: tensor(96.8617), 330: tensor(96.8717), 340: tensor(96.8267), 350: tensor(96.5717)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=88, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.6345,                   Accuracy: 352/2000.0 (17.60%)



-= Testing valid =-
Test set: Average loss: 3.5007,                   Accuracy: 275/2000.0 (13.75%)



-= Testing valid =-
Test set: Average loss: 1.1992,                   Accuracy: 1188/2000.0 (59.40%)



-= Testing valid =-
Test set: Average loss: 1.3506,                   Accuracy: 1092/2000.0 (54.60%)



-= Testing valid =-
Test set: Average loss: 0.8593,                   Accuracy: 1359/2000.0 (67.95%)



-= Testing valid =-
Test set: Average loss: 0.5563,                   Accuracy: 1667/2000.0 (83.35%)



-= Testing valid =-
Test set: Average loss: 0.3766,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.2630,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2466,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.3210,                   Accuracy: 1829/2000.0 (91.45%)



Epoch 10 train accuracy: 92.82%, valid accuracy 91.45%
-= Testing valid =-
Test set: Average loss: 0.1242,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1873,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.1404,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1610,                   Accuracy: 1894/2000.0 (94.70%)



-= Testing valid =-
Test set: Average loss: 0.1351,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1209,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1673,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1378,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1350,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1238,                   Accuracy: 1923/2000.0 (96.15%)



Epoch 20 train accuracy: 95.43%, valid accuracy 96.15%
-= Testing valid =-
Test set: Average loss: 0.1077,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1059,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1239,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1313,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1080,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0965,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 30 train accuracy: 96.34%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0974,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0978,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0988,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1018,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1052,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0927,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1075,                   Accuracy: 1940/2000.0 (97.00%)



Epoch 40 train accuracy: 97.00%, valid accuracy 97.00%
-= Testing valid =-
Test set: Average loss: 0.0992,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1004,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1050,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0981,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0910,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0980,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1007,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 50 train accuracy: 97.54%, valid accuracy 96.80%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1127,                   Accuracy: 58012/60000 (96.69%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1203,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1159,                   Accuracy: 57939/60000 (96.57%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1189,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1187,                   Accuracy: 57872/60000 (96.45%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1190,                   Accuracy: 57837/60000 (96.39%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1169,                   Accuracy: 57849/60000 (96.42%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1148,                   Accuracy: 57930/60000 (96.55%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1174,                   Accuracy: 57922/60000 (96.54%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1105,                   Accuracy: 58090/60000 (96.82%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1188,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1146,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1169,                   Accuracy: 57921/60000 (96.54%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1195,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1204,                   Accuracy: 57789/60000 (96.32%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1198,                   Accuracy: 57769/60000 (96.28%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1187,                   Accuracy: 57795/60000 (96.32%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1191,                   Accuracy: 57828/60000 (96.38%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1150,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1255,                   Accuracy: 57701/60000 (96.17%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1175,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1205,                   Accuracy: 57881/60000 (96.47%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1213,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1211,                   Accuracy: 57805/60000 (96.34%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1221,                   Accuracy: 57713/60000 (96.19%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1186,                   Accuracy: 57808/60000 (96.35%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1187,                   Accuracy: 57811/60000 (96.35%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1158,                   Accuracy: 57912/60000 (96.52%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1259,                   Accuracy: 57722/60000 (96.20%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1186,                   Accuracy: 57854/60000 (96.42%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1232,                   Accuracy: 57804/60000 (96.34%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1212,                   Accuracy: 57819/60000 (96.36%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1205,                   Accuracy: 57830/60000 (96.38%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1208,                   Accuracy: 57781/60000 (96.30%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1164,                   Accuracy: 57892/60000 (96.49%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1186,                   Accuracy: 57898/60000 (96.50%)
{0: tensor(96.6867), 10: tensor(96.4350), 20: tensor(96.5650), 30: tensor(96.4717), 40: tensor(96.4533), 50: tensor(96.3950), 60: tensor(96.4150), 70: tensor(96.5500), 80: tensor(96.5367), 90: tensor(96.8167), 100: tensor(96.4733), 110: tensor(96.5833), 120: tensor(96.5350), 130: tensor(96.4300), 140: tensor(96.3150), 150: tensor(96.2817), 160: tensor(96.3250), 170: tensor(96.3800), 180: tensor(96.5783), 190: tensor(96.1683), 200: tensor(96.4983), 210: tensor(96.4683), 220: tensor(96.3400), 230: tensor(96.3417), 240: tensor(96.1883), 250: tensor(96.3467), 260: tensor(96.3517), 270: tensor(96.5200), 280: tensor(96.2033), 290: tensor(96.4233), 300: tensor(96.3400), 310: tensor(96.3650), 320: tensor(96.3833), 330: tensor(96.3017), 340: tensor(96.4867), 350: tensor(96.4967)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=89, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.8777,                   Accuracy: 227/2000.0 (11.35%)



-= Testing valid =-
Test set: Average loss: 1.5817,                   Accuracy: 817/2000.0 (40.85%)



-= Testing valid =-
Test set: Average loss: 0.9258,                   Accuracy: 1367/2000.0 (68.35%)



-= Testing valid =-
Test set: Average loss: 0.5416,                   Accuracy: 1663/2000.0 (83.15%)



-= Testing valid =-
Test set: Average loss: 0.3779,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.2806,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.4160,                   Accuracy: 1724/2000.0 (86.20%)



-= Testing valid =-
Test set: Average loss: 0.1894,                   Accuracy: 1880/2000.0 (94.00%)



-= Testing valid =-
Test set: Average loss: 0.1666,                   Accuracy: 1897/2000.0 (94.85%)



-= Testing valid =-
Test set: Average loss: 0.1986,                   Accuracy: 1877/2000.0 (93.85%)



Epoch 10 train accuracy: 92.95%, valid accuracy 93.85%
-= Testing valid =-
Test set: Average loss: 0.1173,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1155,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1390,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1010,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1123,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1943,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1116,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 20 train accuracy: 95.06%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1023,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0892,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1120,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.0818,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0801,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0838,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0753,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1947/2000.0 (97.35%)



Epoch 30 train accuracy: 95.91%, valid accuracy 97.35%
-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0783,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0681,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0829,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0696,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0686,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0659,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0671,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0778,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0711,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 40 train accuracy: 96.61%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0735,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0626,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0689,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0676,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0684,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0609,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0629,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0692,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0690,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 50 train accuracy: 96.76%, valid accuracy 97.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1168,                   Accuracy: 57888/60000 (96.48%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1312,                   Accuracy: 57622/60000 (96.04%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1254,                   Accuracy: 57781/60000 (96.30%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1257,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1281,                   Accuracy: 57753/60000 (96.25%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1284,                   Accuracy: 57741/60000 (96.24%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1259,                   Accuracy: 57768/60000 (96.28%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1230,                   Accuracy: 57795/60000 (96.32%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1249,                   Accuracy: 57704/60000 (96.17%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1187,                   Accuracy: 57811/60000 (96.35%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1316,                   Accuracy: 57589/60000 (95.98%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1255,                   Accuracy: 57721/60000 (96.20%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1249,                   Accuracy: 57820/60000 (96.37%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1272,                   Accuracy: 57754/60000 (96.26%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1286,                   Accuracy: 57702/60000 (96.17%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1263,                   Accuracy: 57736/60000 (96.23%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1215,                   Accuracy: 57801/60000 (96.33%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1224,                   Accuracy: 57809/60000 (96.35%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1154,                   Accuracy: 57916/60000 (96.53%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1298,                   Accuracy: 57600/60000 (96.00%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1189,                   Accuracy: 57880/60000 (96.47%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1209,                   Accuracy: 57871/60000 (96.45%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1222,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1231,                   Accuracy: 57812/60000 (96.35%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1221,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1159,                   Accuracy: 57937/60000 (96.56%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1176,                   Accuracy: 57881/60000 (96.47%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1132,                   Accuracy: 57993/60000 (96.65%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1294,                   Accuracy: 57615/60000 (96.03%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1185,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1218,                   Accuracy: 57882/60000 (96.47%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1228,                   Accuracy: 57876/60000 (96.46%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1231,                   Accuracy: 57854/60000 (96.42%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1214,                   Accuracy: 57879/60000 (96.46%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1182,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1209,                   Accuracy: 57824/60000 (96.37%)
{0: tensor(96.4800), 10: tensor(96.0367), 20: tensor(96.3017), 30: tensor(96.3567), 40: tensor(96.2550), 50: tensor(96.2350), 60: tensor(96.2800), 70: tensor(96.3250), 80: tensor(96.1733), 90: tensor(96.3517), 100: tensor(95.9817), 110: tensor(96.2017), 120: tensor(96.3667), 130: tensor(96.2567), 140: tensor(96.1700), 150: tensor(96.2267), 160: tensor(96.3350), 170: tensor(96.3483), 180: tensor(96.5267), 190: tensor(96.), 200: tensor(96.4667), 210: tensor(96.4517), 220: tensor(96.4767), 230: tensor(96.3533), 240: tensor(96.4100), 250: tensor(96.5617), 260: tensor(96.4683), 270: tensor(96.6550), 280: tensor(96.0250), 290: tensor(96.4750), 300: tensor(96.4700), 310: tensor(96.4600), 320: tensor(96.4233), 330: tensor(96.4650), 340: tensor(96.4983), 350: tensor(96.3733)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=90, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4028,                   Accuracy: 506/2000.0 (25.30%)



-= Testing valid =-
Test set: Average loss: 1.4958,                   Accuracy: 786/2000.0 (39.30%)



-= Testing valid =-
Test set: Average loss: 3.2038,                   Accuracy: 463/2000.0 (23.15%)



-= Testing valid =-
Test set: Average loss: 0.9200,                   Accuracy: 1345/2000.0 (67.25%)



-= Testing valid =-
Test set: Average loss: 0.3358,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.5089,                   Accuracy: 1693/2000.0 (84.65%)



-= Testing valid =-
Test set: Average loss: 0.3818,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.4027,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.2614,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2037,                   Accuracy: 1879/2000.0 (93.95%)



Epoch 10 train accuracy: 92.04%, valid accuracy 93.95%
-= Testing valid =-
Test set: Average loss: 0.1482,                   Accuracy: 1900/2000.0 (95.00%)



-= Testing valid =-
Test set: Average loss: 0.1794,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1482,                   Accuracy: 1887/2000.0 (94.35%)



-= Testing valid =-
Test set: Average loss: 0.1989,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.1345,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1655,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1565,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1434,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1339,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1143,                   Accuracy: 1922/2000.0 (96.10%)



Epoch 20 train accuracy: 95.30%, valid accuracy 96.10%
-= Testing valid =-
Test set: Average loss: 0.1206,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1162,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1148,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1305,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.1259,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1024,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1198,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1105,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1005,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 30 train accuracy: 96.45%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.1144,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1097,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.0909,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0896,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0845,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0946,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0846,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 40 train accuracy: 96.68%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0877,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0831,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0835,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0849,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0848,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 50 train accuracy: 97.30%, valid accuracy 97.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1195,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1236,                   Accuracy: 57825/60000 (96.38%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1176,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1164,                   Accuracy: 57969/60000 (96.61%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1141,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1150,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1197,                   Accuracy: 57908/60000 (96.51%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1206,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1280,                   Accuracy: 57719/60000 (96.20%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1228,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1271,                   Accuracy: 57706/60000 (96.18%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1214,                   Accuracy: 57842/60000 (96.40%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1205,                   Accuracy: 57881/60000 (96.47%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1155,                   Accuracy: 57950/60000 (96.58%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1166,                   Accuracy: 57963/60000 (96.61%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1214,                   Accuracy: 57833/60000 (96.39%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1222,                   Accuracy: 57801/60000 (96.33%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1274,                   Accuracy: 57715/60000 (96.19%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1236,                   Accuracy: 57787/60000 (96.31%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1280,                   Accuracy: 57719/60000 (96.20%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1217,                   Accuracy: 57820/60000 (96.37%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1203,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1148,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1163,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1194,                   Accuracy: 57865/60000 (96.44%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1207,                   Accuracy: 57846/60000 (96.41%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1274,                   Accuracy: 57737/60000 (96.23%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1202,                   Accuracy: 57900/60000 (96.50%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1242,                   Accuracy: 57838/60000 (96.40%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1184,                   Accuracy: 57933/60000 (96.56%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1169,                   Accuracy: 57961/60000 (96.60%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1139,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1153,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1183,                   Accuracy: 57948/60000 (96.58%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1190,                   Accuracy: 57925/60000 (96.54%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1269,                   Accuracy: 57770/60000 (96.28%)
{0: tensor(96.4900), 10: tensor(96.3750), 20: tensor(96.5633), 30: tensor(96.6150), 40: tensor(96.6517), 50: tensor(96.5950), 60: tensor(96.5133), 70: tensor(96.4917), 80: tensor(96.1983), 90: tensor(96.4467), 100: tensor(96.1767), 110: tensor(96.4033), 120: tensor(96.4683), 130: tensor(96.5833), 140: tensor(96.6050), 150: tensor(96.3883), 160: tensor(96.3350), 170: tensor(96.1917), 180: tensor(96.3117), 190: tensor(96.1983), 200: tensor(96.3667), 210: tensor(96.4467), 220: tensor(96.5850), 230: tensor(96.5800), 240: tensor(96.4417), 250: tensor(96.4100), 260: tensor(96.2283), 270: tensor(96.5000), 280: tensor(96.3967), 290: tensor(96.5550), 300: tensor(96.6017), 310: tensor(96.6900), 320: tensor(96.5850), 330: tensor(96.5800), 340: tensor(96.5417), 350: tensor(96.2833)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=91, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 10.6316,                   Accuracy: 294/2000.0 (14.70%)



-= Testing valid =-
Test set: Average loss: 2.0301,                   Accuracy: 544/2000.0 (27.20%)



-= Testing valid =-
Test set: Average loss: 1.4748,                   Accuracy: 822/2000.0 (41.10%)



-= Testing valid =-
Test set: Average loss: 3.0108,                   Accuracy: 623/2000.0 (31.15%)



-= Testing valid =-
Test set: Average loss: 0.7822,                   Accuracy: 1517/2000.0 (75.85%)



-= Testing valid =-
Test set: Average loss: 0.4207,                   Accuracy: 1728/2000.0 (86.40%)



-= Testing valid =-
Test set: Average loss: 0.5095,                   Accuracy: 1675/2000.0 (83.75%)



-= Testing valid =-
Test set: Average loss: 0.2794,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2588,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2202,                   Accuracy: 1857/2000.0 (92.85%)



Epoch 10 train accuracy: 92.99%, valid accuracy 92.85%
-= Testing valid =-
Test set: Average loss: 0.1468,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1290,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1107,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1377,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1662,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1616,                   Accuracy: 1898/2000.0 (94.90%)



-= Testing valid =-
Test set: Average loss: 0.1473,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1764,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1438,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1939/2000.0 (96.95%)



Epoch 20 train accuracy: 95.39%, valid accuracy 96.95%
-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1172,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1169,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1019,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1047,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1009,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.1073,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1058,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1946/2000.0 (97.30%)



Epoch 30 train accuracy: 96.61%, valid accuracy 97.30%
-= Testing valid =-
Test set: Average loss: 0.0877,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0935,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.1030,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1128,                   Accuracy: 1936/2000.0 (96.80%)



Epoch 40 train accuracy: 97.00%, valid accuracy 96.80%
-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0906,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0888,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0833,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 50 train accuracy: 97.19%, valid accuracy 97.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1121,                   Accuracy: 58142/60000 (96.90%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1136,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1160,                   Accuracy: 58046/60000 (96.74%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1234,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1272,                   Accuracy: 57759/60000 (96.26%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1292,                   Accuracy: 57716/60000 (96.19%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1318,                   Accuracy: 57713/60000 (96.19%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1222,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1224,                   Accuracy: 57873/60000 (96.46%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1205,                   Accuracy: 57953/60000 (96.59%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1229,                   Accuracy: 57894/60000 (96.49%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1267,                   Accuracy: 57778/60000 (96.30%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1371,                   Accuracy: 57571/60000 (95.95%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1415,                   Accuracy: 57425/60000 (95.71%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1462,                   Accuracy: 57321/60000 (95.54%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1503,                   Accuracy: 57264/60000 (95.44%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1382,                   Accuracy: 57491/60000 (95.82%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1362,                   Accuracy: 57574/60000 (95.96%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1327,                   Accuracy: 57671/60000 (96.12%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1299,                   Accuracy: 57712/60000 (96.19%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1279,                   Accuracy: 57713/60000 (96.19%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1355,                   Accuracy: 57583/60000 (95.97%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1340,                   Accuracy: 57594/60000 (95.99%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1340,                   Accuracy: 57583/60000 (95.97%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1360,                   Accuracy: 57548/60000 (95.91%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1238,                   Accuracy: 57818/60000 (96.36%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1179,                   Accuracy: 57962/60000 (96.60%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1175,                   Accuracy: 58017/60000 (96.69%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1156,                   Accuracy: 58040/60000 (96.73%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1143,                   Accuracy: 58056/60000 (96.76%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1207,                   Accuracy: 57931/60000 (96.55%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1211,                   Accuracy: 57855/60000 (96.43%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1211,                   Accuracy: 57878/60000 (96.46%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1233,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1141,                   Accuracy: 58060/60000 (96.77%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1115,                   Accuracy: 58094/60000 (96.82%)
{0: tensor(96.9033), 10: tensor(96.7433), 20: tensor(96.7433), 30: tensor(96.4433), 40: tensor(96.2650), 50: tensor(96.1933), 60: tensor(96.1883), 70: tensor(96.4983), 80: tensor(96.4550), 90: tensor(96.5883), 100: tensor(96.4900), 110: tensor(96.2967), 120: tensor(95.9517), 130: tensor(95.7083), 140: tensor(95.5350), 150: tensor(95.4400), 160: tensor(95.8183), 170: tensor(95.9567), 180: tensor(96.1183), 190: tensor(96.1867), 200: tensor(96.1883), 210: tensor(95.9717), 220: tensor(95.9900), 230: tensor(95.9717), 240: tensor(95.9133), 250: tensor(96.3633), 260: tensor(96.6033), 270: tensor(96.6950), 280: tensor(96.7333), 290: tensor(96.7600), 300: tensor(96.5517), 310: tensor(96.4250), 320: tensor(96.4633), 330: tensor(96.4717), 340: tensor(96.7667), 350: tensor(96.8233)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=92, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.1296,                   Accuracy: 237/2000.0 (11.85%)



-= Testing valid =-
Test set: Average loss: 3.4364,                   Accuracy: 400/2000.0 (20.00%)



-= Testing valid =-
Test set: Average loss: 2.2248,                   Accuracy: 629/2000.0 (31.45%)



-= Testing valid =-
Test set: Average loss: 0.7791,                   Accuracy: 1453/2000.0 (72.65%)



-= Testing valid =-
Test set: Average loss: 0.4798,                   Accuracy: 1711/2000.0 (85.55%)



-= Testing valid =-
Test set: Average loss: 0.5209,                   Accuracy: 1682/2000.0 (84.10%)



-= Testing valid =-
Test set: Average loss: 0.2433,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2010,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.3301,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.3287,                   Accuracy: 1779/2000.0 (88.95%)



Epoch 10 train accuracy: 93.03%, valid accuracy 88.95%
-= Testing valid =-
Test set: Average loss: 0.1801,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1530,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1336,                   Accuracy: 1912/2000.0 (95.60%)



-= Testing valid =-
Test set: Average loss: 0.1867,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1405,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1191,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1483,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1467,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1487,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1422,                   Accuracy: 1915/2000.0 (95.75%)



Epoch 20 train accuracy: 95.28%, valid accuracy 95.75%
-= Testing valid =-
Test set: Average loss: 0.1175,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1108,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1135,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1323,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1093,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1207,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1344,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 30 train accuracy: 96.10%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0976,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0954,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0934,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0891,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0932,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0855,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0859,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1954/2000.0 (97.70%)



Epoch 40 train accuracy: 96.51%, valid accuracy 97.70%
-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0875,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0929,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0857,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0926,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0902,                   Accuracy: 1950/2000.0 (97.50%)



Epoch 50 train accuracy: 97.04%, valid accuracy 97.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1063,                   Accuracy: 58173/60000 (96.96%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1131,                   Accuracy: 58045/60000 (96.74%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1157,                   Accuracy: 57983/60000 (96.64%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1228,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1293,                   Accuracy: 57797/60000 (96.33%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1294,                   Accuracy: 57799/60000 (96.33%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1261,                   Accuracy: 57879/60000 (96.46%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1200,                   Accuracy: 57966/60000 (96.61%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1213,                   Accuracy: 57906/60000 (96.51%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1126,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1212,                   Accuracy: 57857/60000 (96.43%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1237,                   Accuracy: 57831/60000 (96.39%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1337,                   Accuracy: 57618/60000 (96.03%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1401,                   Accuracy: 57552/60000 (95.92%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1404,                   Accuracy: 57531/60000 (95.89%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1373,                   Accuracy: 57584/60000 (95.97%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1284,                   Accuracy: 57730/60000 (96.22%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1311,                   Accuracy: 57653/60000 (96.09%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1204,                   Accuracy: 57856/60000 (96.43%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1313,                   Accuracy: 57601/60000 (96.00%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1249,                   Accuracy: 57780/60000 (96.30%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1329,                   Accuracy: 57667/60000 (96.11%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1359,                   Accuracy: 57639/60000 (96.07%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1353,                   Accuracy: 57636/60000 (96.06%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1298,                   Accuracy: 57739/60000 (96.23%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1204,                   Accuracy: 57931/60000 (96.55%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1205,                   Accuracy: 57881/60000 (96.47%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1104,                   Accuracy: 58074/60000 (96.79%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1183,                   Accuracy: 57919/60000 (96.53%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1154,                   Accuracy: 58009/60000 (96.68%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1217,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1268,                   Accuracy: 57853/60000 (96.42%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1270,                   Accuracy: 57843/60000 (96.40%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1223,                   Accuracy: 57943/60000 (96.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1148,                   Accuracy: 58077/60000 (96.79%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1143,                   Accuracy: 58014/60000 (96.69%)
{0: tensor(96.9550), 10: tensor(96.7417), 20: tensor(96.6383), 30: tensor(96.4733), 40: tensor(96.3283), 50: tensor(96.3317), 60: tensor(96.4650), 70: tensor(96.6100), 80: tensor(96.5100), 90: tensor(96.7717), 100: tensor(96.4283), 110: tensor(96.3850), 120: tensor(96.0300), 130: tensor(95.9200), 140: tensor(95.8850), 150: tensor(95.9733), 160: tensor(96.2167), 170: tensor(96.0883), 180: tensor(96.4267), 190: tensor(96.0017), 200: tensor(96.3000), 210: tensor(96.1117), 220: tensor(96.0650), 230: tensor(96.0600), 240: tensor(96.2317), 250: tensor(96.5517), 260: tensor(96.4683), 270: tensor(96.7900), 280: tensor(96.5317), 290: tensor(96.6817), 300: tensor(96.5250), 310: tensor(96.4217), 320: tensor(96.4050), 330: tensor(96.5717), 340: tensor(96.7950), 350: tensor(96.6900)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=93, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.8528,                   Accuracy: 627/2000.0 (31.35%)



-= Testing valid =-
Test set: Average loss: 3.6385,                   Accuracy: 427/2000.0 (21.35%)



-= Testing valid =-
Test set: Average loss: 0.8683,                   Accuracy: 1411/2000.0 (70.55%)



-= Testing valid =-
Test set: Average loss: 0.6895,                   Accuracy: 1524/2000.0 (76.20%)



-= Testing valid =-
Test set: Average loss: 0.5923,                   Accuracy: 1595/2000.0 (79.75%)



-= Testing valid =-
Test set: Average loss: 0.3102,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2203,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2371,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.2223,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.2485,                   Accuracy: 1848/2000.0 (92.40%)



Epoch 10 train accuracy: 93.29%, valid accuracy 92.40%
-= Testing valid =-
Test set: Average loss: 0.1325,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1365,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1426,                   Accuracy: 1908/2000.0 (95.40%)



-= Testing valid =-
Test set: Average loss: 0.1306,                   Accuracy: 1913/2000.0 (95.65%)



-= Testing valid =-
Test set: Average loss: 0.1546,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1156,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.0910,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1477,                   Accuracy: 1906/2000.0 (95.30%)



-= Testing valid =-
Test set: Average loss: 0.1193,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1098,                   Accuracy: 1926/2000.0 (96.30%)



Epoch 20 train accuracy: 95.43%, valid accuracy 96.30%
-= Testing valid =-
Test set: Average loss: 0.1028,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0977,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1048,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0931,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0915,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0798,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 30 train accuracy: 96.39%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0773,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0851,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0858,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0865,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0834,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0744,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0777,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0863,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0785,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 40 train accuracy: 96.97%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0803,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 50 train accuracy: 97.07%, valid accuracy 97.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1111,                   Accuracy: 58017/60000 (96.69%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1220,                   Accuracy: 57743/60000 (96.24%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1235,                   Accuracy: 57741/60000 (96.24%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1287,                   Accuracy: 57660/60000 (96.10%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1243,                   Accuracy: 57787/60000 (96.31%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1203,                   Accuracy: 57857/60000 (96.43%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1164,                   Accuracy: 57918/60000 (96.53%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1113,                   Accuracy: 57964/60000 (96.61%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1096,                   Accuracy: 58031/60000 (96.72%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1103,                   Accuracy: 58018/60000 (96.70%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1218,                   Accuracy: 57737/60000 (96.23%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1209,                   Accuracy: 57770/60000 (96.28%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1264,                   Accuracy: 57704/60000 (96.17%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1202,                   Accuracy: 57814/60000 (96.36%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1163,                   Accuracy: 57886/60000 (96.48%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1121,                   Accuracy: 57977/60000 (96.63%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1068,                   Accuracy: 58064/60000 (96.77%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1046,                   Accuracy: 58093/60000 (96.82%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1062,                   Accuracy: 58074/60000 (96.79%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1167,                   Accuracy: 57863/60000 (96.44%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1161,                   Accuracy: 57885/60000 (96.47%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1206,                   Accuracy: 57856/60000 (96.43%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1158,                   Accuracy: 57896/60000 (96.49%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1124,                   Accuracy: 57999/60000 (96.67%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1084,                   Accuracy: 58044/60000 (96.74%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1038,                   Accuracy: 58098/60000 (96.83%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1040,                   Accuracy: 58085/60000 (96.81%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1061,                   Accuracy: 58117/60000 (96.86%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1161,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1182,                   Accuracy: 57863/60000 (96.44%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1232,                   Accuracy: 57799/60000 (96.33%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1193,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1164,                   Accuracy: 57946/60000 (96.58%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1124,                   Accuracy: 58012/60000 (96.69%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1086,                   Accuracy: 58022/60000 (96.70%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1099,                   Accuracy: 58015/60000 (96.69%)
{0: tensor(96.6950), 10: tensor(96.2383), 20: tensor(96.2350), 30: tensor(96.1000), 40: tensor(96.3117), 50: tensor(96.4283), 60: tensor(96.5300), 70: tensor(96.6067), 80: tensor(96.7183), 90: tensor(96.6967), 100: tensor(96.2283), 110: tensor(96.2833), 120: tensor(96.1733), 130: tensor(96.3567), 140: tensor(96.4767), 150: tensor(96.6283), 160: tensor(96.7733), 170: tensor(96.8217), 180: tensor(96.7900), 190: tensor(96.4383), 200: tensor(96.4750), 210: tensor(96.4267), 220: tensor(96.4933), 230: tensor(96.6650), 240: tensor(96.7400), 250: tensor(96.8300), 260: tensor(96.8083), 270: tensor(96.8617), 280: tensor(96.5117), 290: tensor(96.4383), 300: tensor(96.3317), 310: tensor(96.4850), 320: tensor(96.5767), 330: tensor(96.6867), 340: tensor(96.7033), 350: tensor(96.6917)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=94, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0454,                   Accuracy: 585/2000.0 (29.25%)



-= Testing valid =-
Test set: Average loss: 2.0715,                   Accuracy: 753/2000.0 (37.65%)



-= Testing valid =-
Test set: Average loss: 1.5233,                   Accuracy: 1018/2000.0 (50.90%)



-= Testing valid =-
Test set: Average loss: 0.8395,                   Accuracy: 1400/2000.0 (70.00%)



-= Testing valid =-
Test set: Average loss: 1.5464,                   Accuracy: 1338/2000.0 (66.90%)



-= Testing valid =-
Test set: Average loss: 0.6242,                   Accuracy: 1540/2000.0 (77.00%)



-= Testing valid =-
Test set: Average loss: 0.2686,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.3468,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.2974,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.1825,                   Accuracy: 1893/2000.0 (94.65%)



Epoch 10 train accuracy: 92.69%, valid accuracy 94.65%
-= Testing valid =-
Test set: Average loss: 0.2512,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.2382,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.1249,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1278,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.2946,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.1156,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1190,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.1995,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.1183,                   Accuracy: 1937/2000.0 (96.85%)



Epoch 20 train accuracy: 95.53%, valid accuracy 96.85%
-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.1077,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0950,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1248,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1060,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0983,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1113,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0989,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.1070,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0886,                   Accuracy: 1948/2000.0 (97.40%)



Epoch 30 train accuracy: 96.65%, valid accuracy 97.40%
-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0907,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0781,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0941,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0784,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 40 train accuracy: 97.12%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0797,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0694,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0809,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0772,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0714,                   Accuracy: 1962/2000.0 (98.10%)



-= Testing valid =-
Test set: Average loss: 0.0755,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0786,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0770,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0794,                   Accuracy: 1956/2000.0 (97.80%)



-= Testing valid =-
Test set: Average loss: 0.0804,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 50 train accuracy: 97.26%, valid accuracy 97.90%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1064,                   Accuracy: 58197/60000 (97.00%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1120,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1114,                   Accuracy: 58049/60000 (96.75%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1204,                   Accuracy: 57887/60000 (96.48%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1202,                   Accuracy: 57883/60000 (96.47%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1183,                   Accuracy: 57902/60000 (96.50%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1155,                   Accuracy: 57966/60000 (96.61%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1068,                   Accuracy: 58157/60000 (96.93%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1036,                   Accuracy: 58224/60000 (97.04%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1045,                   Accuracy: 58222/60000 (97.04%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1113,                   Accuracy: 58005/60000 (96.68%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1097,                   Accuracy: 58038/60000 (96.73%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1176,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1176,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1182,                   Accuracy: 57907/60000 (96.51%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1163,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1110,                   Accuracy: 58049/60000 (96.75%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1084,                   Accuracy: 58104/60000 (96.84%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1100,                   Accuracy: 58087/60000 (96.81%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1162,                   Accuracy: 57905/60000 (96.51%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1155,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1237,                   Accuracy: 57801/60000 (96.33%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1214,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1195,                   Accuracy: 57871/60000 (96.45%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1178,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1109,                   Accuracy: 58016/60000 (96.69%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1112,                   Accuracy: 58069/60000 (96.78%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1116,                   Accuracy: 58065/60000 (96.78%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1155,                   Accuracy: 57934/60000 (96.56%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1172,                   Accuracy: 57947/60000 (96.58%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1266,                   Accuracy: 57770/60000 (96.28%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1244,                   Accuracy: 57797/60000 (96.33%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1205,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1175,                   Accuracy: 57915/60000 (96.53%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1077,                   Accuracy: 58133/60000 (96.89%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1067,                   Accuracy: 58166/60000 (96.94%)
{0: tensor(96.9950), 10: tensor(96.6683), 20: tensor(96.7483), 30: tensor(96.4783), 40: tensor(96.4717), 50: tensor(96.5033), 60: tensor(96.6100), 70: tensor(96.9283), 80: tensor(97.0400), 90: tensor(97.0367), 100: tensor(96.6750), 110: tensor(96.7300), 120: tensor(96.5283), 130: tensor(96.5483), 140: tensor(96.5117), 150: tensor(96.5483), 160: tensor(96.7483), 170: tensor(96.8400), 180: tensor(96.8117), 190: tensor(96.5083), 200: tensor(96.5583), 210: tensor(96.3350), 220: tensor(96.3600), 230: tensor(96.4517), 240: tensor(96.4983), 250: tensor(96.6933), 260: tensor(96.7817), 270: tensor(96.7750), 280: tensor(96.5567), 290: tensor(96.5783), 300: tensor(96.2833), 310: tensor(96.3283), 320: tensor(96.4350), 330: tensor(96.5250), 340: tensor(96.8883), 350: tensor(96.9433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=95, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0811,                   Accuracy: 444/2000.0 (22.20%)



-= Testing valid =-
Test set: Average loss: 1.5591,                   Accuracy: 948/2000.0 (47.40%)



-= Testing valid =-
Test set: Average loss: 1.1374,                   Accuracy: 1227/2000.0 (61.35%)



-= Testing valid =-
Test set: Average loss: 2.3730,                   Accuracy: 654/2000.0 (32.70%)



-= Testing valid =-
Test set: Average loss: 1.6486,                   Accuracy: 1001/2000.0 (50.05%)



-= Testing valid =-
Test set: Average loss: 0.3853,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.2607,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.3236,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2362,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2183,                   Accuracy: 1878/2000.0 (93.90%)



Epoch 10 train accuracy: 92.07%, valid accuracy 93.90%
-= Testing valid =-
Test set: Average loss: 0.1421,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1397,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1458,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1637,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.1204,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1185,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1194,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.1153,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1115,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1335,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 20 train accuracy: 95.22%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.1214,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1127,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1021,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1041,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0922,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0995,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1952/2000.0 (97.60%)



Epoch 30 train accuracy: 96.26%, valid accuracy 97.60%
-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0971,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0884,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0826,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0810,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0943,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0823,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0985,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0758,                   Accuracy: 1957/2000.0 (97.85%)



Epoch 40 train accuracy: 96.57%, valid accuracy 97.85%
-= Testing valid =-
Test set: Average loss: 0.0919,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0815,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0842,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0802,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0878,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0871,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0787,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0767,                   Accuracy: 1954/2000.0 (97.70%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1944/2000.0 (97.20%)



Epoch 50 train accuracy: 96.85%, valid accuracy 97.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1144,                   Accuracy: 58037/60000 (96.73%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1227,                   Accuracy: 57842/60000 (96.40%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1271,                   Accuracy: 57779/60000 (96.30%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1352,                   Accuracy: 57687/60000 (96.14%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1365,                   Accuracy: 57664/60000 (96.11%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1343,                   Accuracy: 57682/60000 (96.14%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1295,                   Accuracy: 57734/60000 (96.22%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1243,                   Accuracy: 57866/60000 (96.44%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1223,                   Accuracy: 57857/60000 (96.43%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1207,                   Accuracy: 57917/60000 (96.53%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1302,                   Accuracy: 57700/60000 (96.17%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1353,                   Accuracy: 57630/60000 (96.05%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1455,                   Accuracy: 57454/60000 (95.76%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1487,                   Accuracy: 57408/60000 (95.68%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1462,                   Accuracy: 57436/60000 (95.73%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1419,                   Accuracy: 57494/60000 (95.82%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1321,                   Accuracy: 57673/60000 (96.12%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1282,                   Accuracy: 57721/60000 (96.20%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1246,                   Accuracy: 57823/60000 (96.37%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1353,                   Accuracy: 57573/60000 (95.96%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1340,                   Accuracy: 57664/60000 (96.11%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1417,                   Accuracy: 57506/60000 (95.84%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1442,                   Accuracy: 57483/60000 (95.81%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1397,                   Accuracy: 57570/60000 (95.95%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1329,                   Accuracy: 57683/60000 (96.14%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1234,                   Accuracy: 57832/60000 (96.39%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1184,                   Accuracy: 57918/60000 (96.53%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1166,                   Accuracy: 58001/60000 (96.67%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1255,                   Accuracy: 57791/60000 (96.32%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1260,                   Accuracy: 57781/60000 (96.30%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1327,                   Accuracy: 57722/60000 (96.20%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1346,                   Accuracy: 57695/60000 (96.16%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1308,                   Accuracy: 57763/60000 (96.27%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1248,                   Accuracy: 57835/60000 (96.39%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1185,                   Accuracy: 57977/60000 (96.63%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1162,                   Accuracy: 57985/60000 (96.64%)
{0: tensor(96.7283), 10: tensor(96.4033), 20: tensor(96.2983), 30: tensor(96.1450), 40: tensor(96.1067), 50: tensor(96.1367), 60: tensor(96.2233), 70: tensor(96.4433), 80: tensor(96.4283), 90: tensor(96.5283), 100: tensor(96.1667), 110: tensor(96.0500), 120: tensor(95.7567), 130: tensor(95.6800), 140: tensor(95.7267), 150: tensor(95.8233), 160: tensor(96.1217), 170: tensor(96.2017), 180: tensor(96.3717), 190: tensor(95.9550), 200: tensor(96.1067), 210: tensor(95.8433), 220: tensor(95.8050), 230: tensor(95.9500), 240: tensor(96.1383), 250: tensor(96.3867), 260: tensor(96.5300), 270: tensor(96.6683), 280: tensor(96.3183), 290: tensor(96.3017), 300: tensor(96.2033), 310: tensor(96.1583), 320: tensor(96.2717), 330: tensor(96.3917), 340: tensor(96.6283), 350: tensor(96.6417)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=96, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.9444,                   Accuracy: 255/2000.0 (12.75%)



-= Testing valid =-
Test set: Average loss: 1.3632,                   Accuracy: 1041/2000.0 (52.05%)



-= Testing valid =-
Test set: Average loss: 1.2812,                   Accuracy: 1206/2000.0 (60.30%)



-= Testing valid =-
Test set: Average loss: 0.6124,                   Accuracy: 1582/2000.0 (79.10%)



-= Testing valid =-
Test set: Average loss: 0.4801,                   Accuracy: 1709/2000.0 (85.45%)



-= Testing valid =-
Test set: Average loss: 0.3570,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3195,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2717,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.6762,                   Accuracy: 1638/2000.0 (81.90%)



-= Testing valid =-
Test set: Average loss: 0.1992,                   Accuracy: 1870/2000.0 (93.50%)



Epoch 10 train accuracy: 93.41%, valid accuracy 93.50%
-= Testing valid =-
Test set: Average loss: 0.2019,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.1703,                   Accuracy: 1889/2000.0 (94.45%)



-= Testing valid =-
Test set: Average loss: 0.1302,                   Accuracy: 1911/2000.0 (95.55%)



-= Testing valid =-
Test set: Average loss: 0.1440,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.2181,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.3410,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.2115,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.1350,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.2306,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1303,                   Accuracy: 1914/2000.0 (95.70%)



Epoch 20 train accuracy: 95.80%, valid accuracy 95.70%
-= Testing valid =-
Test set: Average loss: 0.1120,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1039,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1202,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1112,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1091,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1015,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1068,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0978,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.1291,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0998,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 30 train accuracy: 97.05%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0967,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0984,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0852,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0959,                   Accuracy: 1937/2000.0 (96.85%)



-= Testing valid =-
Test set: Average loss: 0.0870,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0898,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0928,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0868,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0911,                   Accuracy: 1938/2000.0 (96.90%)



Epoch 40 train accuracy: 97.29%, valid accuracy 96.90%
-= Testing valid =-
Test set: Average loss: 0.0887,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0822,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0807,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0820,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0910,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0827,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0916,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1949/2000.0 (97.45%)



Epoch 50 train accuracy: 97.61%, valid accuracy 97.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1106,                   Accuracy: 58082/60000 (96.80%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1214,                   Accuracy: 57904/60000 (96.51%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1198,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1186,                   Accuracy: 57892/60000 (96.49%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1169,                   Accuracy: 57939/60000 (96.57%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1157,                   Accuracy: 57951/60000 (96.58%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1137,                   Accuracy: 57987/60000 (96.64%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1131,                   Accuracy: 57995/60000 (96.66%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1158,                   Accuracy: 57944/60000 (96.57%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1138,                   Accuracy: 57971/60000 (96.62%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1234,                   Accuracy: 57822/60000 (96.37%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1218,                   Accuracy: 57835/60000 (96.39%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1221,                   Accuracy: 57791/60000 (96.32%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1182,                   Accuracy: 57869/60000 (96.45%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1185,                   Accuracy: 57858/60000 (96.43%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1190,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1174,                   Accuracy: 57863/60000 (96.44%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1201,                   Accuracy: 57834/60000 (96.39%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1170,                   Accuracy: 57929/60000 (96.55%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1235,                   Accuracy: 57816/60000 (96.36%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1207,                   Accuracy: 57867/60000 (96.44%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1228,                   Accuracy: 57805/60000 (96.34%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1165,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1155,                   Accuracy: 57942/60000 (96.57%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1161,                   Accuracy: 57918/60000 (96.53%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1123,                   Accuracy: 57991/60000 (96.65%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1141,                   Accuracy: 57968/60000 (96.61%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1118,                   Accuracy: 58025/60000 (96.71%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1207,                   Accuracy: 57896/60000 (96.49%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1183,                   Accuracy: 57920/60000 (96.53%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1186,                   Accuracy: 57914/60000 (96.52%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1149,                   Accuracy: 57970/60000 (96.62%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1132,                   Accuracy: 57996/60000 (96.66%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1110,                   Accuracy: 58042/60000 (96.74%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1095,                   Accuracy: 58063/60000 (96.77%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1117,                   Accuracy: 58039/60000 (96.73%)
{0: tensor(96.8033), 10: tensor(96.5067), 20: tensor(96.4983), 30: tensor(96.4867), 40: tensor(96.5650), 50: tensor(96.5850), 60: tensor(96.6450), 70: tensor(96.6583), 80: tensor(96.5733), 90: tensor(96.6183), 100: tensor(96.3700), 110: tensor(96.3917), 120: tensor(96.3183), 130: tensor(96.4483), 140: tensor(96.4300), 150: tensor(96.4183), 160: tensor(96.4383), 170: tensor(96.3900), 180: tensor(96.5483), 190: tensor(96.3600), 200: tensor(96.4450), 210: tensor(96.3417), 220: tensor(96.5333), 230: tensor(96.5700), 240: tensor(96.5300), 250: tensor(96.6517), 260: tensor(96.6133), 270: tensor(96.7083), 280: tensor(96.4933), 290: tensor(96.5333), 300: tensor(96.5233), 310: tensor(96.6167), 320: tensor(96.6600), 330: tensor(96.7367), 340: tensor(96.7717), 350: tensor(96.7317)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=97, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.7754,                   Accuracy: 685/2000.0 (34.25%)



-= Testing valid =-
Test set: Average loss: 1.8267,                   Accuracy: 548/2000.0 (27.40%)



-= Testing valid =-
Test set: Average loss: 0.8768,                   Accuracy: 1480/2000.0 (74.00%)



-= Testing valid =-
Test set: Average loss: 0.6569,                   Accuracy: 1672/2000.0 (83.60%)



-= Testing valid =-
Test set: Average loss: 0.4261,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.2435,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.5477,                   Accuracy: 1676/2000.0 (83.80%)



-= Testing valid =-
Test set: Average loss: 0.3000,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.1728,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.3567,                   Accuracy: 1780/2000.0 (89.00%)



Epoch 10 train accuracy: 93.50%, valid accuracy 89.00%
-= Testing valid =-
Test set: Average loss: 0.1490,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1879,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1496,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1100,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1304,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1645,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1456,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.1713,                   Accuracy: 1899/2000.0 (94.95%)



-= Testing valid =-
Test set: Average loss: 0.1403,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.1560,                   Accuracy: 1893/2000.0 (94.65%)



Epoch 20 train accuracy: 95.66%, valid accuracy 94.65%
-= Testing valid =-
Test set: Average loss: 0.1176,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.1173,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.1176,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1452,                   Accuracy: 1907/2000.0 (95.35%)



-= Testing valid =-
Test set: Average loss: 0.1288,                   Accuracy: 1918/2000.0 (95.90%)



-= Testing valid =-
Test set: Average loss: 0.1346,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1433,                   Accuracy: 1909/2000.0 (95.45%)



-= Testing valid =-
Test set: Average loss: 0.1087,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1145,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1163,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 30 train accuracy: 96.46%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.1051,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1143,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1153,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1101,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.1151,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1159,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.1103,                   Accuracy: 1931/2000.0 (96.55%)



-= Testing valid =-
Test set: Average loss: 0.1026,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1191,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1032,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 40 train accuracy: 96.96%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.1029,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1008,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0957,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0993,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0948,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1016,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1040,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.1059,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0960,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 50 train accuracy: 97.25%, valid accuracy 97.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1271,                   Accuracy: 57789/60000 (96.32%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1224,                   Accuracy: 57853/60000 (96.42%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1190,                   Accuracy: 57871/60000 (96.45%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1216,                   Accuracy: 57835/60000 (96.39%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1265,                   Accuracy: 57733/60000 (96.22%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1332,                   Accuracy: 57634/60000 (96.06%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1392,                   Accuracy: 57561/60000 (95.93%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1431,                   Accuracy: 57501/60000 (95.83%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1405,                   Accuracy: 57504/60000 (95.84%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1332,                   Accuracy: 57625/60000 (96.04%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1309,                   Accuracy: 57649/60000 (96.08%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1257,                   Accuracy: 57690/60000 (96.15%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1291,                   Accuracy: 57677/60000 (96.13%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1340,                   Accuracy: 57547/60000 (95.91%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1430,                   Accuracy: 57406/60000 (95.68%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1508,                   Accuracy: 57269/60000 (95.45%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1518,                   Accuracy: 57281/60000 (95.47%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1527,                   Accuracy: 57266/60000 (95.44%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1431,                   Accuracy: 57431/60000 (95.72%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1395,                   Accuracy: 57450/60000 (95.75%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1324,                   Accuracy: 57574/60000 (95.96%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1354,                   Accuracy: 57526/60000 (95.88%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1370,                   Accuracy: 57469/60000 (95.78%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1424,                   Accuracy: 57399/60000 (95.67%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1494,                   Accuracy: 57293/60000 (95.49%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1459,                   Accuracy: 57382/60000 (95.64%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1454,                   Accuracy: 57390/60000 (95.65%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1338,                   Accuracy: 57634/60000 (96.06%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1287,                   Accuracy: 57714/60000 (96.19%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1228,                   Accuracy: 57762/60000 (96.27%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1250,                   Accuracy: 57733/60000 (96.22%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1273,                   Accuracy: 57703/60000 (96.17%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1318,                   Accuracy: 57674/60000 (96.12%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1374,                   Accuracy: 57609/60000 (96.01%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1383,                   Accuracy: 57573/60000 (95.96%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1348,                   Accuracy: 57600/60000 (96.00%)
{0: tensor(96.3150), 10: tensor(96.4217), 20: tensor(96.4517), 30: tensor(96.3917), 40: tensor(96.2217), 50: tensor(96.0567), 60: tensor(95.9350), 70: tensor(95.8350), 80: tensor(95.8400), 90: tensor(96.0417), 100: tensor(96.0817), 110: tensor(96.1500), 120: tensor(96.1283), 130: tensor(95.9117), 140: tensor(95.6767), 150: tensor(95.4483), 160: tensor(95.4683), 170: tensor(95.4433), 180: tensor(95.7183), 190: tensor(95.7500), 200: tensor(95.9567), 210: tensor(95.8767), 220: tensor(95.7817), 230: tensor(95.6650), 240: tensor(95.4883), 250: tensor(95.6367), 260: tensor(95.6500), 270: tensor(96.0567), 280: tensor(96.1900), 290: tensor(96.2700), 300: tensor(96.2217), 310: tensor(96.1717), 320: tensor(96.1233), 330: tensor(96.0150), 340: tensor(95.9550), 350: tensor(96.)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=98, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 6.8715,                   Accuracy: 219/2000.0 (10.95%)



-= Testing valid =-
Test set: Average loss: 2.4287,                   Accuracy: 464/2000.0 (23.20%)



-= Testing valid =-
Test set: Average loss: 2.0352,                   Accuracy: 479/2000.0 (23.95%)



-= Testing valid =-
Test set: Average loss: 3.4604,                   Accuracy: 426/2000.0 (21.30%)



-= Testing valid =-
Test set: Average loss: 2.0901,                   Accuracy: 783/2000.0 (39.15%)



-= Testing valid =-
Test set: Average loss: 0.4501,                   Accuracy: 1735/2000.0 (86.75%)



-= Testing valid =-
Test set: Average loss: 0.5370,                   Accuracy: 1640/2000.0 (82.00%)



-= Testing valid =-
Test set: Average loss: 0.4730,                   Accuracy: 1718/2000.0 (85.90%)



-= Testing valid =-
Test set: Average loss: 0.2394,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.3025,                   Accuracy: 1811/2000.0 (90.55%)



Epoch 10 train accuracy: 91.78%, valid accuracy 90.55%
-= Testing valid =-
Test set: Average loss: 0.2141,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.2210,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1657,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1743,                   Accuracy: 1893/2000.0 (94.65%)



-= Testing valid =-
Test set: Average loss: 0.1715,                   Accuracy: 1891/2000.0 (94.55%)



-= Testing valid =-
Test set: Average loss: 0.1836,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.1625,                   Accuracy: 1901/2000.0 (95.05%)



-= Testing valid =-
Test set: Average loss: 0.1522,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.1634,                   Accuracy: 1896/2000.0 (94.80%)



-= Testing valid =-
Test set: Average loss: 0.1241,                   Accuracy: 1924/2000.0 (96.20%)



Epoch 20 train accuracy: 95.47%, valid accuracy 96.20%
-= Testing valid =-
Test set: Average loss: 0.1243,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1113,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.1157,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.1267,                   Accuracy: 1917/2000.0 (95.85%)



-= Testing valid =-
Test set: Average loss: 0.1265,                   Accuracy: 1926/2000.0 (96.30%)



-= Testing valid =-
Test set: Average loss: 0.1119,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1203,                   Accuracy: 1922/2000.0 (96.10%)



-= Testing valid =-
Test set: Average loss: 0.1176,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0917,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.1049,                   Accuracy: 1935/2000.0 (96.75%)



Epoch 30 train accuracy: 96.31%, valid accuracy 96.75%
-= Testing valid =-
Test set: Average loss: 0.0970,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0966,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.1150,                   Accuracy: 1925/2000.0 (96.25%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0919,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0921,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0949,                   Accuracy: 1940/2000.0 (97.00%)



-= Testing valid =-
Test set: Average loss: 0.0991,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0962,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.1099,                   Accuracy: 1933/2000.0 (96.65%)



Epoch 40 train accuracy: 96.82%, valid accuracy 96.65%
-= Testing valid =-
Test set: Average loss: 0.0933,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0958,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0912,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0895,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0920,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0952,                   Accuracy: 1941/2000.0 (97.05%)



-= Testing valid =-
Test set: Average loss: 0.0938,                   Accuracy: 1934/2000.0 (96.70%)



-= Testing valid =-
Test set: Average loss: 0.0937,                   Accuracy: 1939/2000.0 (96.95%)



-= Testing valid =-
Test set: Average loss: 0.0905,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 50 train accuracy: 96.96%, valid accuracy 97.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1098,                   Accuracy: 58097/60000 (96.83%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1163,                   Accuracy: 57935/60000 (96.56%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1209,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1268,                   Accuracy: 57782/60000 (96.30%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1292,                   Accuracy: 57728/60000 (96.21%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1284,                   Accuracy: 57705/60000 (96.18%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1251,                   Accuracy: 57792/60000 (96.32%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1215,                   Accuracy: 57835/60000 (96.39%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1189,                   Accuracy: 57851/60000 (96.42%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1130,                   Accuracy: 57997/60000 (96.66%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1185,                   Accuracy: 57879/60000 (96.46%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1227,                   Accuracy: 57813/60000 (96.36%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1301,                   Accuracy: 57679/60000 (96.13%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1320,                   Accuracy: 57644/60000 (96.07%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1334,                   Accuracy: 57567/60000 (95.94%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1312,                   Accuracy: 57641/60000 (96.07%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1255,                   Accuracy: 57726/60000 (96.21%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1262,                   Accuracy: 57707/60000 (96.18%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1190,                   Accuracy: 57845/60000 (96.41%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1231,                   Accuracy: 57730/60000 (96.22%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1249,                   Accuracy: 57749/60000 (96.25%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1316,                   Accuracy: 57636/60000 (96.06%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1319,                   Accuracy: 57645/60000 (96.07%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1292,                   Accuracy: 57650/60000 (96.08%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1255,                   Accuracy: 57766/60000 (96.28%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1190,                   Accuracy: 57902/60000 (96.50%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1194,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1132,                   Accuracy: 58006/60000 (96.68%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1186,                   Accuracy: 57860/60000 (96.43%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1210,                   Accuracy: 57861/60000 (96.43%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1272,                   Accuracy: 57782/60000 (96.30%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1287,                   Accuracy: 57710/60000 (96.18%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1256,                   Accuracy: 57783/60000 (96.31%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1209,                   Accuracy: 57884/60000 (96.47%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1162,                   Accuracy: 57957/60000 (96.60%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1143,                   Accuracy: 57964/60000 (96.61%)
{0: tensor(96.8283), 10: tensor(96.5583), 20: tensor(96.4350), 30: tensor(96.3033), 40: tensor(96.2133), 50: tensor(96.1750), 60: tensor(96.3200), 70: tensor(96.3917), 80: tensor(96.4183), 90: tensor(96.6617), 100: tensor(96.4650), 110: tensor(96.3550), 120: tensor(96.1317), 130: tensor(96.0733), 140: tensor(95.9450), 150: tensor(96.0683), 160: tensor(96.2100), 170: tensor(96.1783), 180: tensor(96.4083), 190: tensor(96.2167), 200: tensor(96.2483), 210: tensor(96.0600), 220: tensor(96.0750), 230: tensor(96.0833), 240: tensor(96.2767), 250: tensor(96.5033), 260: tensor(96.4400), 270: tensor(96.6767), 280: tensor(96.4333), 290: tensor(96.4350), 300: tensor(96.3033), 310: tensor(96.1833), 320: tensor(96.3050), 330: tensor(96.4733), 340: tensor(96.5950), 350: tensor(96.6067)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=99, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.6949,                   Accuracy: 196/2000.0 (9.80%)



-= Testing valid =-
Test set: Average loss: 1.9238,                   Accuracy: 611/2000.0 (30.55%)



-= Testing valid =-
Test set: Average loss: 0.7170,                   Accuracy: 1585/2000.0 (79.25%)



-= Testing valid =-
Test set: Average loss: 0.4125,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.2638,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.5250,                   Accuracy: 1699/2000.0 (84.95%)



-= Testing valid =-
Test set: Average loss: 0.2076,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.1389,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.2215,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.2746,                   Accuracy: 1839/2000.0 (91.95%)



Epoch 10 train accuracy: 94.51%, valid accuracy 91.95%
-= Testing valid =-
Test set: Average loss: 0.1111,                   Accuracy: 1928/2000.0 (96.40%)



-= Testing valid =-
Test set: Average loss: 0.1450,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.1074,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.1265,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.0791,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.4017,                   Accuracy: 1713/2000.0 (85.65%)



-= Testing valid =-
Test set: Average loss: 0.1031,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.1328,                   Accuracy: 1910/2000.0 (95.50%)



-= Testing valid =-
Test set: Average loss: 0.0951,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.1078,                   Accuracy: 1932/2000.0 (96.60%)



Epoch 20 train accuracy: 95.90%, valid accuracy 96.60%
-= Testing valid =-
Test set: Average loss: 0.1006,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0775,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0900,                   Accuracy: 1943/2000.0 (97.15%)



-= Testing valid =-
Test set: Average loss: 0.0854,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0839,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.1126,                   Accuracy: 1920/2000.0 (96.00%)



-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.0776,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.1175,                   Accuracy: 1914/2000.0 (95.70%)



-= Testing valid =-
Test set: Average loss: 0.0830,                   Accuracy: 1945/2000.0 (97.25%)



Epoch 30 train accuracy: 96.96%, valid accuracy 97.25%
-= Testing valid =-
Test set: Average loss: 0.0733,                   Accuracy: 1952/2000.0 (97.60%)



-= Testing valid =-
Test set: Average loss: 0.0699,                   Accuracy: 1960/2000.0 (98.00%)



-= Testing valid =-
Test set: Average loss: 0.0774,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0707,                   Accuracy: 1955/2000.0 (97.75%)



-= Testing valid =-
Test set: Average loss: 0.0708,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0679,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0625,                   Accuracy: 1959/2000.0 (97.95%)



-= Testing valid =-
Test set: Average loss: 0.0656,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0756,                   Accuracy: 1949/2000.0 (97.45%)



-= Testing valid =-
Test set: Average loss: 0.0651,                   Accuracy: 1958/2000.0 (97.90%)



Epoch 40 train accuracy: 97.11%, valid accuracy 97.90%
-= Testing valid =-
Test set: Average loss: 0.0658,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0693,                   Accuracy: 1957/2000.0 (97.85%)



-= Testing valid =-
Test set: Average loss: 0.0740,                   Accuracy: 1953/2000.0 (97.65%)



-= Testing valid =-
Test set: Average loss: 0.0793,                   Accuracy: 1950/2000.0 (97.50%)



-= Testing valid =-
Test set: Average loss: 0.0812,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0736,                   Accuracy: 1951/2000.0 (97.55%)



-= Testing valid =-
Test set: Average loss: 0.0630,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0653,                   Accuracy: 1958/2000.0 (97.90%)



-= Testing valid =-
Test set: Average loss: 0.0635,                   Accuracy: 1961/2000.0 (98.05%)



-= Testing valid =-
Test set: Average loss: 0.0712,                   Accuracy: 1951/2000.0 (97.55%)



Epoch 50 train accuracy: 97.53%, valid accuracy 97.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.0923,                   Accuracy: 58355/60000 (97.26%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.0952,                   Accuracy: 58290/60000 (97.15%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.0932,                   Accuracy: 58297/60000 (97.16%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.0990,                   Accuracy: 58230/60000 (97.05%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1024,                   Accuracy: 58170/60000 (96.95%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1074,                   Accuracy: 58099/60000 (96.83%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1062,                   Accuracy: 58142/60000 (96.90%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1027,                   Accuracy: 58182/60000 (96.97%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.0984,                   Accuracy: 58249/60000 (97.08%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.0918,                   Accuracy: 58326/60000 (97.21%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.0949,                   Accuracy: 58290/60000 (97.15%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.0914,                   Accuracy: 58327/60000 (97.21%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.0957,                   Accuracy: 58278/60000 (97.13%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.0999,                   Accuracy: 58203/60000 (97.00%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1059,                   Accuracy: 58106/60000 (96.84%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1071,                   Accuracy: 58121/60000 (96.87%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1048,                   Accuracy: 58087/60000 (96.81%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.0999,                   Accuracy: 58216/60000 (97.03%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.0947,                   Accuracy: 58306/60000 (97.18%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.0976,                   Accuracy: 58247/60000 (97.08%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.0935,                   Accuracy: 58307/60000 (97.18%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.0977,                   Accuracy: 58228/60000 (97.05%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1009,                   Accuracy: 58197/60000 (97.00%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1061,                   Accuracy: 58114/60000 (96.86%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1080,                   Accuracy: 58107/60000 (96.85%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1044,                   Accuracy: 58112/60000 (96.85%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1025,                   Accuracy: 58162/60000 (96.94%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.0955,                   Accuracy: 58294/60000 (97.16%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.0966,                   Accuracy: 58251/60000 (97.08%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.0955,                   Accuracy: 58290/60000 (97.15%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1014,                   Accuracy: 58183/60000 (96.97%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1035,                   Accuracy: 58127/60000 (96.88%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1074,                   Accuracy: 58106/60000 (96.84%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1073,                   Accuracy: 58101/60000 (96.83%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1026,                   Accuracy: 58181/60000 (96.97%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1009,                   Accuracy: 58216/60000 (97.03%)
{0: tensor(97.2583), 10: tensor(97.1500), 20: tensor(97.1617), 30: tensor(97.0500), 40: tensor(96.9500), 50: tensor(96.8317), 60: tensor(96.9033), 70: tensor(96.9700), 80: tensor(97.0817), 90: tensor(97.2100), 100: tensor(97.1500), 110: tensor(97.2117), 120: tensor(97.1300), 130: tensor(97.0050), 140: tensor(96.8433), 150: tensor(96.8683), 160: tensor(96.8117), 170: tensor(97.0267), 180: tensor(97.1767), 190: tensor(97.0783), 200: tensor(97.1783), 210: tensor(97.0467), 220: tensor(96.9950), 230: tensor(96.8567), 240: tensor(96.8450), 250: tensor(96.8533), 260: tensor(96.9367), 270: tensor(97.1567), 280: tensor(97.0850), 290: tensor(97.1500), 300: tensor(96.9717), 310: tensor(96.8783), 320: tensor(96.8433), 330: tensor(96.8350), 340: tensor(96.9683), 350: tensor(97.0267)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='P4', input_size=29, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=10, rotated=False, samples=None, savestr='', seed=100, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─P4ConvZ2: 1-1                          [256, 10, 4, 29, 29]      280
├─BatchNorm3d: 1-2                       [256, 10, 4, 29, 29]      20
├─Dropout: 1-3                           [256, 10, 4, 29, 29]      --
├─P4ConvP4: 1-4                          [256, 10, 4, 29, 29]      3,610
├─BatchNorm3d: 1-5                       [256, 10, 4, 29, 29]      20
├─GroupMaxPool2d: 1-6                    [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-7                          [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-8                       [256, 10, 4, 14, 14]      20
├─Dropout: 1-9                           [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-10                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-11                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-12                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-13                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-14                      [256, 10, 4, 14, 14]      20
├─Dropout: 1-15                          [256, 10, 4, 14, 14]      --
├─P4ConvP4: 1-16                         [256, 10, 4, 14, 14]      3,610
├─BatchNorm3d: 1-17                      [256, 10, 4, 14, 14]      20
├─P4ConvP4: 1-18                         [256, 10, 4, 11, 11]      6,410
├─BatchNorm3d: 1-19                      [256, 10, 4, 11, 11]      20
├─AdaptiveAvgPool2d: 1-20                [256, 40, 1, 1]           --
├─GroupCosetMaxPool: 1-21                [256, 10, 1, 1]           --
├─Linear: 1-22                           [256, 10]                 110
==========================================================================================
Total params: 24,990
Trainable params: 24,990
Non-trainable params: 0
Total mult-adds (G): 7.04
==========================================================================================
Input size (MB): 2.58
Forward/backward pass size (MB): 423.87
Params size (MB): 0.10
Estimated Total Size (MB): 426.56
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9010,                   Accuracy: 637/2000.0 (31.85%)



-= Testing valid =-
Test set: Average loss: 2.4597,                   Accuracy: 390/2000.0 (19.50%)



-= Testing valid =-
Test set: Average loss: 0.7444,                   Accuracy: 1529/2000.0 (76.45%)



-= Testing valid =-
Test set: Average loss: 0.8211,                   Accuracy: 1415/2000.0 (70.75%)



-= Testing valid =-
Test set: Average loss: 0.3535,                   Accuracy: 1752/2000.0 (87.60%)



-= Testing valid =-
Test set: Average loss: 0.5337,                   Accuracy: 1600/2000.0 (80.00%)



-= Testing valid =-
Test set: Average loss: 0.2417,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2580,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2049,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.1619,                   Accuracy: 1903/2000.0 (95.15%)



Epoch 10 train accuracy: 93.44%, valid accuracy 95.15%
-= Testing valid =-
Test set: Average loss: 0.1253,                   Accuracy: 1915/2000.0 (95.75%)



-= Testing valid =-
Test set: Average loss: 0.1180,                   Accuracy: 1916/2000.0 (95.80%)



-= Testing valid =-
Test set: Average loss: 0.1108,                   Accuracy: 1927/2000.0 (96.35%)



-= Testing valid =-
Test set: Average loss: 0.1392,                   Accuracy: 1902/2000.0 (95.10%)



-= Testing valid =-
Test set: Average loss: 0.1318,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1166,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1199,                   Accuracy: 1919/2000.0 (95.95%)



-= Testing valid =-
Test set: Average loss: 0.1626,                   Accuracy: 1888/2000.0 (94.40%)



-= Testing valid =-
Test set: Average loss: 0.1201,                   Accuracy: 1921/2000.0 (96.05%)



-= Testing valid =-
Test set: Average loss: 0.1297,                   Accuracy: 1927/2000.0 (96.35%)



Epoch 20 train accuracy: 95.80%, valid accuracy 96.35%
-= Testing valid =-
Test set: Average loss: 0.0889,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0945,                   Accuracy: 1924/2000.0 (96.20%)



-= Testing valid =-
Test set: Average loss: 0.1013,                   Accuracy: 1929/2000.0 (96.45%)



-= Testing valid =-
Test set: Average loss: 0.0973,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0790,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1088,                   Accuracy: 1923/2000.0 (96.15%)



-= Testing valid =-
Test set: Average loss: 0.0872,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0811,                   Accuracy: 1948/2000.0 (97.40%)



-= Testing valid =-
Test set: Average loss: 0.1330,                   Accuracy: 1905/2000.0 (95.25%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1931/2000.0 (96.55%)



Epoch 30 train accuracy: 96.60%, valid accuracy 96.55%
-= Testing valid =-
Test set: Average loss: 0.1003,                   Accuracy: 1933/2000.0 (96.65%)



-= Testing valid =-
Test set: Average loss: 0.0840,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0901,                   Accuracy: 1936/2000.0 (96.80%)



-= Testing valid =-
Test set: Average loss: 0.0866,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0961,                   Accuracy: 1930/2000.0 (96.50%)



-= Testing valid =-
Test set: Average loss: 0.0979,                   Accuracy: 1932/2000.0 (96.60%)



-= Testing valid =-
Test set: Average loss: 0.0939,                   Accuracy: 1935/2000.0 (96.75%)



-= Testing valid =-
Test set: Average loss: 0.0844,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0856,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0873,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 40 train accuracy: 97.35%, valid accuracy 97.05%
-= Testing valid =-
Test set: Average loss: 0.0768,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0806,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0817,                   Accuracy: 1938/2000.0 (96.90%)



-= Testing valid =-
Test set: Average loss: 0.0825,                   Accuracy: 1944/2000.0 (97.20%)



-= Testing valid =-
Test set: Average loss: 0.0788,                   Accuracy: 1945/2000.0 (97.25%)



-= Testing valid =-
Test set: Average loss: 0.0761,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0814,                   Accuracy: 1947/2000.0 (97.35%)



-= Testing valid =-
Test set: Average loss: 0.0796,                   Accuracy: 1946/2000.0 (97.30%)



-= Testing valid =-
Test set: Average loss: 0.0850,                   Accuracy: 1942/2000.0 (97.10%)



-= Testing valid =-
Test set: Average loss: 0.0824,                   Accuracy: 1941/2000.0 (97.05%)



Epoch 50 train accuracy: 97.36%, valid accuracy 97.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.1010,                   Accuracy: 58217/60000 (97.03%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.1122,                   Accuracy: 58014/60000 (96.69%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.1159,                   Accuracy: 57938/60000 (96.56%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.1196,                   Accuracy: 57899/60000 (96.50%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.1259,                   Accuracy: 57771/60000 (96.29%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.1305,                   Accuracy: 57695/60000 (96.16%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.1268,                   Accuracy: 57727/60000 (96.21%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.1240,                   Accuracy: 57799/60000 (96.33%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.1243,                   Accuracy: 57778/60000 (96.30%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.1171,                   Accuracy: 57890/60000 (96.48%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.1334,                   Accuracy: 57553/60000 (95.92%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.1367,                   Accuracy: 57470/60000 (95.78%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.1450,                   Accuracy: 57310/60000 (95.52%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.1514,                   Accuracy: 57201/60000 (95.33%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.1566,                   Accuracy: 57084/60000 (95.14%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.1573,                   Accuracy: 57067/60000 (95.11%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.1527,                   Accuracy: 57148/60000 (95.25%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.1477,                   Accuracy: 57212/60000 (95.35%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.1373,                   Accuracy: 57392/60000 (95.65%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.1501,                   Accuracy: 57130/60000 (95.22%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.1447,                   Accuracy: 57277/60000 (95.46%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.1475,                   Accuracy: 57232/60000 (95.39%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.1449,                   Accuracy: 57310/60000 (95.52%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.1414,                   Accuracy: 57390/60000 (95.65%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.1383,                   Accuracy: 57453/60000 (95.75%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.1267,                   Accuracy: 57691/60000 (96.15%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.1212,                   Accuracy: 57791/60000 (96.32%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.1093,                   Accuracy: 58026/60000 (96.71%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.1184,                   Accuracy: 57868/60000 (96.45%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.1168,                   Accuracy: 57895/60000 (96.49%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.1186,                   Accuracy: 57891/60000 (96.49%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.1197,                   Accuracy: 57836/60000 (96.39%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.1196,                   Accuracy: 57864/60000 (96.44%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.1150,                   Accuracy: 57959/60000 (96.60%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.1099,                   Accuracy: 58071/60000 (96.79%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.1089,                   Accuracy: 58076/60000 (96.79%)
{0: tensor(97.0283), 10: tensor(96.6900), 20: tensor(96.5633), 30: tensor(96.4983), 40: tensor(96.2850), 50: tensor(96.1583), 60: tensor(96.2117), 70: tensor(96.3317), 80: tensor(96.2967), 90: tensor(96.4833), 100: tensor(95.9217), 110: tensor(95.7833), 120: tensor(95.5167), 130: tensor(95.3350), 140: tensor(95.1400), 150: tensor(95.1117), 160: tensor(95.2467), 170: tensor(95.3533), 180: tensor(95.6533), 190: tensor(95.2167), 200: tensor(95.4617), 210: tensor(95.3867), 220: tensor(95.5167), 230: tensor(95.6500), 240: tensor(95.7550), 250: tensor(96.1517), 260: tensor(96.3183), 270: tensor(96.7100), 280: tensor(96.4467), 290: tensor(96.4917), 300: tensor(96.4850), 310: tensor(96.3933), 320: tensor(96.4400), 330: tensor(96.5983), 340: tensor(96.7850), 350: tensor(96.7933)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=71, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9100,                   Accuracy: 638/2000.0 (31.90%)



-= Testing valid =-
Test set: Average loss: 2.2791,                   Accuracy: 487/2000.0 (24.35%)



-= Testing valid =-
Test set: Average loss: 1.5403,                   Accuracy: 843/2000.0 (42.15%)



-= Testing valid =-
Test set: Average loss: 1.8162,                   Accuracy: 832/2000.0 (41.60%)



-= Testing valid =-
Test set: Average loss: 1.3185,                   Accuracy: 1160/2000.0 (58.00%)



-= Testing valid =-
Test set: Average loss: 1.8420,                   Accuracy: 878/2000.0 (43.90%)



-= Testing valid =-
Test set: Average loss: 1.1792,                   Accuracy: 1163/2000.0 (58.15%)



-= Testing valid =-
Test set: Average loss: 1.0431,                   Accuracy: 1337/2000.0 (66.85%)



-= Testing valid =-
Test set: Average loss: 1.1105,                   Accuracy: 1190/2000.0 (59.50%)



-= Testing valid =-
Test set: Average loss: 1.8781,                   Accuracy: 882/2000.0 (44.10%)



Epoch 10 train accuracy: 74.25%, valid accuracy 44.10%
-= Testing valid =-
Test set: Average loss: 1.3328,                   Accuracy: 1123/2000.0 (56.15%)



-= Testing valid =-
Test set: Average loss: 1.0462,                   Accuracy: 1177/2000.0 (58.85%)



-= Testing valid =-
Test set: Average loss: 0.5805,                   Accuracy: 1643/2000.0 (82.15%)



-= Testing valid =-
Test set: Average loss: 0.7103,                   Accuracy: 1519/2000.0 (75.95%)



-= Testing valid =-
Test set: Average loss: 0.5174,                   Accuracy: 1691/2000.0 (84.55%)



-= Testing valid =-
Test set: Average loss: 0.4183,                   Accuracy: 1747/2000.0 (87.35%)



-= Testing valid =-
Test set: Average loss: 0.5095,                   Accuracy: 1700/2000.0 (85.00%)



-= Testing valid =-
Test set: Average loss: 0.5199,                   Accuracy: 1672/2000.0 (83.60%)



-= Testing valid =-
Test set: Average loss: 0.4068,                   Accuracy: 1745/2000.0 (87.25%)



-= Testing valid =-
Test set: Average loss: 0.4558,                   Accuracy: 1708/2000.0 (85.40%)



Epoch 20 train accuracy: 86.91%, valid accuracy 85.40%
-= Testing valid =-
Test set: Average loss: 0.3432,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.3458,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 0.3638,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.3664,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.3420,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.3781,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.3735,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.3395,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.3006,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3745,                   Accuracy: 1766/2000.0 (88.30%)



Epoch 30 train accuracy: 89.28%, valid accuracy 88.30%
-= Testing valid =-
Test set: Average loss: 0.2986,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2995,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.3100,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.3539,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.3225,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.2913,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.3328,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.3006,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2740,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2746,                   Accuracy: 1828/2000.0 (91.40%)



Epoch 40 train accuracy: 90.53%, valid accuracy 91.40%
-= Testing valid =-
Test set: Average loss: 0.2524,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2458,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.2948,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2597,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2693,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2343,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.2551,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2621,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2709,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2726,                   Accuracy: 1831/2000.0 (91.55%)



Epoch 50 train accuracy: 90.85%, valid accuracy 91.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2469,                   Accuracy: 55705/60000 (92.84%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2454,                   Accuracy: 55687/60000 (92.81%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2542,                   Accuracy: 55642/60000 (92.74%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2672,                   Accuracy: 55418/60000 (92.36%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2768,                   Accuracy: 55195/60000 (91.99%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2927,                   Accuracy: 54841/60000 (91.40%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3046,                   Accuracy: 54535/60000 (90.89%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3141,                   Accuracy: 54248/60000 (90.41%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3207,                   Accuracy: 53931/60000 (89.89%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3408,                   Accuracy: 53472/60000 (89.12%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3547,                   Accuracy: 53177/60000 (88.63%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3784,                   Accuracy: 52744/60000 (87.91%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3866,                   Accuracy: 52500/60000 (87.50%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3891,                   Accuracy: 52480/60000 (87.47%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3835,                   Accuracy: 52616/60000 (87.69%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3696,                   Accuracy: 52805/60000 (88.01%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3561,                   Accuracy: 53074/60000 (88.46%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3334,                   Accuracy: 53343/60000 (88.90%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3287,                   Accuracy: 53521/60000 (89.20%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3152,                   Accuracy: 53971/60000 (89.95%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3368,                   Accuracy: 53464/60000 (89.11%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3341,                   Accuracy: 53570/60000 (89.28%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3293,                   Accuracy: 53834/60000 (89.72%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3190,                   Accuracy: 54190/60000 (90.32%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3100,                   Accuracy: 54410/60000 (90.68%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3085,                   Accuracy: 54462/60000 (90.77%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2861,                   Accuracy: 54913/60000 (91.52%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2819,                   Accuracy: 55068/60000 (91.78%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2764,                   Accuracy: 55139/60000 (91.90%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2869,                   Accuracy: 55031/60000 (91.72%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2906,                   Accuracy: 55032/60000 (91.72%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2971,                   Accuracy: 54811/60000 (91.35%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2942,                   Accuracy: 54890/60000 (91.48%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2801,                   Accuracy: 55102/60000 (91.84%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2691,                   Accuracy: 55280/60000 (92.13%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2515,                   Accuracy: 55505/60000 (92.51%)
{0: tensor(92.8417), 10: tensor(92.8117), 20: tensor(92.7367), 30: tensor(92.3633), 40: tensor(91.9917), 50: tensor(91.4017), 60: tensor(90.8917), 70: tensor(90.4133), 80: tensor(89.8850), 90: tensor(89.1200), 100: tensor(88.6283), 110: tensor(87.9067), 120: tensor(87.5000), 130: tensor(87.4667), 140: tensor(87.6933), 150: tensor(88.0083), 160: tensor(88.4567), 170: tensor(88.9050), 180: tensor(89.2017), 190: tensor(89.9517), 200: tensor(89.1067), 210: tensor(89.2833), 220: tensor(89.7233), 230: tensor(90.3167), 240: tensor(90.6833), 250: tensor(90.7700), 260: tensor(91.5217), 270: tensor(91.7800), 280: tensor(91.8983), 290: tensor(91.7183), 300: tensor(91.7200), 310: tensor(91.3517), 320: tensor(91.4833), 330: tensor(91.8367), 340: tensor(92.1333), 350: tensor(92.5083)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=72, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 11.8740,                   Accuracy: 260/2000.0 (13.00%)



-= Testing valid =-
Test set: Average loss: 2.2437,                   Accuracy: 431/2000.0 (21.55%)



-= Testing valid =-
Test set: Average loss: 2.6849,                   Accuracy: 507/2000.0 (25.35%)



-= Testing valid =-
Test set: Average loss: 1.8934,                   Accuracy: 855/2000.0 (42.75%)



-= Testing valid =-
Test set: Average loss: 1.2230,                   Accuracy: 1101/2000.0 (55.05%)



-= Testing valid =-
Test set: Average loss: 1.6369,                   Accuracy: 789/2000.0 (39.45%)



-= Testing valid =-
Test set: Average loss: 1.1336,                   Accuracy: 1146/2000.0 (57.30%)



-= Testing valid =-
Test set: Average loss: 1.5989,                   Accuracy: 901/2000.0 (45.05%)



-= Testing valid =-
Test set: Average loss: 0.9257,                   Accuracy: 1358/2000.0 (67.90%)



-= Testing valid =-
Test set: Average loss: 1.1826,                   Accuracy: 1084/2000.0 (54.20%)



Epoch 10 train accuracy: 70.07%, valid accuracy 54.20%
-= Testing valid =-
Test set: Average loss: 0.7239,                   Accuracy: 1523/2000.0 (76.15%)



-= Testing valid =-
Test set: Average loss: 0.7686,                   Accuracy: 1469/2000.0 (73.45%)



-= Testing valid =-
Test set: Average loss: 0.6477,                   Accuracy: 1575/2000.0 (78.75%)



-= Testing valid =-
Test set: Average loss: 0.5627,                   Accuracy: 1624/2000.0 (81.20%)



-= Testing valid =-
Test set: Average loss: 0.5789,                   Accuracy: 1622/2000.0 (81.10%)



-= Testing valid =-
Test set: Average loss: 0.5777,                   Accuracy: 1615/2000.0 (80.75%)



-= Testing valid =-
Test set: Average loss: 0.4545,                   Accuracy: 1685/2000.0 (84.25%)



-= Testing valid =-
Test set: Average loss: 0.3444,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.4745,                   Accuracy: 1710/2000.0 (85.50%)



-= Testing valid =-
Test set: Average loss: 0.5858,                   Accuracy: 1570/2000.0 (78.50%)



Epoch 20 train accuracy: 85.54%, valid accuracy 78.50%
-= Testing valid =-
Test set: Average loss: 0.3345,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.3696,                   Accuracy: 1739/2000.0 (86.95%)



-= Testing valid =-
Test set: Average loss: 0.3527,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.3019,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.2570,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2788,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.2935,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2693,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2438,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2796,                   Accuracy: 1820/2000.0 (91.00%)



Epoch 30 train accuracy: 88.10%, valid accuracy 91.00%
-= Testing valid =-
Test set: Average loss: 0.2778,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.3206,                   Accuracy: 1780/2000.0 (89.00%)



-= Testing valid =-
Test set: Average loss: 0.3053,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.3159,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.3431,                   Accuracy: 1768/2000.0 (88.40%)



-= Testing valid =-
Test set: Average loss: 0.2693,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.2312,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2308,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.2281,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.2369,                   Accuracy: 1846/2000.0 (92.30%)



Epoch 40 train accuracy: 89.39%, valid accuracy 92.30%
-= Testing valid =-
Test set: Average loss: 0.2574,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2309,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2506,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2295,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2149,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2375,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2422,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2307,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2386,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2223,                   Accuracy: 1859/2000.0 (92.95%)



Epoch 50 train accuracy: 89.90%, valid accuracy 92.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2610,                   Accuracy: 55198/60000 (92.00%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2754,                   Accuracy: 54806/60000 (91.34%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2977,                   Accuracy: 54387/60000 (90.64%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3111,                   Accuracy: 54057/60000 (90.10%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3289,                   Accuracy: 53666/60000 (89.44%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3411,                   Accuracy: 53282/60000 (88.80%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3420,                   Accuracy: 53265/60000 (88.78%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3374,                   Accuracy: 53333/60000 (88.89%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3252,                   Accuracy: 53479/60000 (89.13%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3187,                   Accuracy: 53727/60000 (89.54%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3229,                   Accuracy: 53596/60000 (89.33%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3156,                   Accuracy: 53792/60000 (89.65%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3077,                   Accuracy: 53936/60000 (89.89%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3073,                   Accuracy: 53902/60000 (89.84%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3070,                   Accuracy: 54013/60000 (90.02%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3112,                   Accuracy: 53870/60000 (89.78%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3037,                   Accuracy: 54046/60000 (90.08%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.2967,                   Accuracy: 54169/60000 (90.28%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.2917,                   Accuracy: 54453/60000 (90.75%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3082,                   Accuracy: 54124/60000 (90.21%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3090,                   Accuracy: 54220/60000 (90.37%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3030,                   Accuracy: 54384/60000 (90.64%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3092,                   Accuracy: 54315/60000 (90.53%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3095,                   Accuracy: 54395/60000 (90.66%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3086,                   Accuracy: 54372/60000 (90.62%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3082,                   Accuracy: 54378/60000 (90.63%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2917,                   Accuracy: 54652/60000 (91.09%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2929,                   Accuracy: 54614/60000 (91.02%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2966,                   Accuracy: 54360/60000 (90.60%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2925,                   Accuracy: 54533/60000 (90.89%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2813,                   Accuracy: 54789/60000 (91.32%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2779,                   Accuracy: 54862/60000 (91.44%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2765,                   Accuracy: 54968/60000 (91.61%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2713,                   Accuracy: 55082/60000 (91.80%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2712,                   Accuracy: 55066/60000 (91.78%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2634,                   Accuracy: 55145/60000 (91.91%)
{0: tensor(91.9967), 10: tensor(91.3433), 20: tensor(90.6450), 30: tensor(90.0950), 40: tensor(89.4433), 50: tensor(88.8033), 60: tensor(88.7750), 70: tensor(88.8883), 80: tensor(89.1317), 90: tensor(89.5450), 100: tensor(89.3267), 110: tensor(89.6533), 120: tensor(89.8933), 130: tensor(89.8367), 140: tensor(90.0217), 150: tensor(89.7833), 160: tensor(90.0767), 170: tensor(90.2817), 180: tensor(90.7550), 190: tensor(90.2067), 200: tensor(90.3667), 210: tensor(90.6400), 220: tensor(90.5250), 230: tensor(90.6583), 240: tensor(90.6200), 250: tensor(90.6300), 260: tensor(91.0867), 270: tensor(91.0233), 280: tensor(90.6000), 290: tensor(90.8883), 300: tensor(91.3150), 310: tensor(91.4367), 320: tensor(91.6133), 330: tensor(91.8033), 340: tensor(91.7767), 350: tensor(91.9083)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=73, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1287,                   Accuracy: 609/2000.0 (30.45%)



-= Testing valid =-
Test set: Average loss: 4.6922,                   Accuracy: 243/2000.0 (12.15%)



-= Testing valid =-
Test set: Average loss: 1.5350,                   Accuracy: 910/2000.0 (45.50%)



-= Testing valid =-
Test set: Average loss: 1.7235,                   Accuracy: 808/2000.0 (40.40%)



-= Testing valid =-
Test set: Average loss: 1.7154,                   Accuracy: 881/2000.0 (44.05%)



-= Testing valid =-
Test set: Average loss: 1.3116,                   Accuracy: 1101/2000.0 (55.05%)



-= Testing valid =-
Test set: Average loss: 1.7103,                   Accuracy: 707/2000.0 (35.35%)



-= Testing valid =-
Test set: Average loss: 0.9342,                   Accuracy: 1322/2000.0 (66.10%)



-= Testing valid =-
Test set: Average loss: 1.0742,                   Accuracy: 1176/2000.0 (58.80%)



-= Testing valid =-
Test set: Average loss: 1.1301,                   Accuracy: 1118/2000.0 (55.90%)



Epoch 10 train accuracy: 71.97%, valid accuracy 55.90%
-= Testing valid =-
Test set: Average loss: 0.7585,                   Accuracy: 1479/2000.0 (73.95%)



-= Testing valid =-
Test set: Average loss: 0.6579,                   Accuracy: 1587/2000.0 (79.35%)



-= Testing valid =-
Test set: Average loss: 0.5936,                   Accuracy: 1607/2000.0 (80.35%)



-= Testing valid =-
Test set: Average loss: 0.6431,                   Accuracy: 1537/2000.0 (76.85%)



-= Testing valid =-
Test set: Average loss: 0.5113,                   Accuracy: 1661/2000.0 (83.05%)



-= Testing valid =-
Test set: Average loss: 0.5088,                   Accuracy: 1650/2000.0 (82.50%)



-= Testing valid =-
Test set: Average loss: 0.4571,                   Accuracy: 1688/2000.0 (84.40%)



-= Testing valid =-
Test set: Average loss: 0.5701,                   Accuracy: 1608/2000.0 (80.40%)



-= Testing valid =-
Test set: Average loss: 0.6907,                   Accuracy: 1519/2000.0 (75.95%)



-= Testing valid =-
Test set: Average loss: 0.9105,                   Accuracy: 1316/2000.0 (65.80%)



Epoch 20 train accuracy: 84.45%, valid accuracy 65.80%
-= Testing valid =-
Test set: Average loss: 0.3820,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.2891,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.3806,                   Accuracy: 1729/2000.0 (86.45%)



-= Testing valid =-
Test set: Average loss: 0.3663,                   Accuracy: 1759/2000.0 (87.95%)



-= Testing valid =-
Test set: Average loss: 0.3745,                   Accuracy: 1752/2000.0 (87.60%)



-= Testing valid =-
Test set: Average loss: 0.3311,                   Accuracy: 1780/2000.0 (89.00%)



-= Testing valid =-
Test set: Average loss: 0.3393,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3246,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.3292,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.3795,                   Accuracy: 1745/2000.0 (87.25%)



Epoch 30 train accuracy: 87.86%, valid accuracy 87.25%
-= Testing valid =-
Test set: Average loss: 0.3703,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.2874,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.3021,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.2794,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.3086,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.2630,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2378,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2647,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2715,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.3402,                   Accuracy: 1765/2000.0 (88.25%)



Epoch 40 train accuracy: 89.41%, valid accuracy 88.25%
-= Testing valid =-
Test set: Average loss: 0.3201,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.2922,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.2996,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.3224,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.2469,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2561,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2880,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.3137,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.2621,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2749,                   Accuracy: 1813/2000.0 (90.65%)



Epoch 50 train accuracy: 90.94%, valid accuracy 90.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2765,                   Accuracy: 55053/60000 (91.75%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2782,                   Accuracy: 54955/60000 (91.59%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2924,                   Accuracy: 54793/60000 (91.32%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2990,                   Accuracy: 54660/60000 (91.10%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3026,                   Accuracy: 54549/60000 (90.92%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3045,                   Accuracy: 54590/60000 (90.98%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3097,                   Accuracy: 54485/60000 (90.81%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3115,                   Accuracy: 54330/60000 (90.55%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3059,                   Accuracy: 54396/60000 (90.66%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3039,                   Accuracy: 54493/60000 (90.82%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3139,                   Accuracy: 54189/60000 (90.32%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3374,                   Accuracy: 53857/60000 (89.76%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3419,                   Accuracy: 53666/60000 (89.44%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3511,                   Accuracy: 53411/60000 (89.02%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3499,                   Accuracy: 53354/60000 (88.92%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3437,                   Accuracy: 53384/60000 (88.97%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3388,                   Accuracy: 53517/60000 (89.19%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3231,                   Accuracy: 53763/60000 (89.61%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3211,                   Accuracy: 53703/60000 (89.50%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3399,                   Accuracy: 53239/60000 (88.73%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3575,                   Accuracy: 52995/60000 (88.32%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3800,                   Accuracy: 52375/60000 (87.29%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3815,                   Accuracy: 52329/60000 (87.21%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3870,                   Accuracy: 52316/60000 (87.19%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3899,                   Accuracy: 52107/60000 (86.85%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3726,                   Accuracy: 52560/60000 (87.60%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3570,                   Accuracy: 52899/60000 (88.17%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3508,                   Accuracy: 53119/60000 (88.53%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3432,                   Accuracy: 53421/60000 (89.04%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3391,                   Accuracy: 53634/60000 (89.39%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3379,                   Accuracy: 53717/60000 (89.53%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3345,                   Accuracy: 53774/60000 (89.62%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3301,                   Accuracy: 53910/60000 (89.85%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3216,                   Accuracy: 54090/60000 (90.15%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3104,                   Accuracy: 54360/60000 (90.60%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2856,                   Accuracy: 54875/60000 (91.46%)
{0: tensor(91.7550), 10: tensor(91.5917), 20: tensor(91.3217), 30: tensor(91.1000), 40: tensor(90.9150), 50: tensor(90.9833), 60: tensor(90.8083), 70: tensor(90.5500), 80: tensor(90.6600), 90: tensor(90.8217), 100: tensor(90.3150), 110: tensor(89.7617), 120: tensor(89.4433), 130: tensor(89.0183), 140: tensor(88.9233), 150: tensor(88.9733), 160: tensor(89.1950), 170: tensor(89.6050), 180: tensor(89.5050), 190: tensor(88.7317), 200: tensor(88.3250), 210: tensor(87.2917), 220: tensor(87.2150), 230: tensor(87.1933), 240: tensor(86.8450), 250: tensor(87.6000), 260: tensor(88.1650), 270: tensor(88.5317), 280: tensor(89.0350), 290: tensor(89.3900), 300: tensor(89.5283), 310: tensor(89.6233), 320: tensor(89.8500), 330: tensor(90.1500), 340: tensor(90.6000), 350: tensor(91.4583)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=74, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.4947,                   Accuracy: 236/2000.0 (11.80%)



-= Testing valid =-
Test set: Average loss: 12.4590,                   Accuracy: 190/2000.0 (9.50%)



-= Testing valid =-
Test set: Average loss: 1.6020,                   Accuracy: 815/2000.0 (40.75%)



-= Testing valid =-
Test set: Average loss: 1.1118,                   Accuracy: 1250/2000.0 (62.50%)



-= Testing valid =-
Test set: Average loss: 1.5020,                   Accuracy: 1020/2000.0 (51.00%)



-= Testing valid =-
Test set: Average loss: 1.2264,                   Accuracy: 1154/2000.0 (57.70%)



-= Testing valid =-
Test set: Average loss: 1.3341,                   Accuracy: 1217/2000.0 (60.85%)



-= Testing valid =-
Test set: Average loss: 1.0798,                   Accuracy: 1268/2000.0 (63.40%)



-= Testing valid =-
Test set: Average loss: 0.8757,                   Accuracy: 1426/2000.0 (71.30%)



-= Testing valid =-
Test set: Average loss: 0.9208,                   Accuracy: 1344/2000.0 (67.20%)



Epoch 10 train accuracy: 74.90%, valid accuracy 67.20%
-= Testing valid =-
Test set: Average loss: 0.5612,                   Accuracy: 1678/2000.0 (83.90%)



-= Testing valid =-
Test set: Average loss: 0.4551,                   Accuracy: 1735/2000.0 (86.75%)



-= Testing valid =-
Test set: Average loss: 0.4777,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.4648,                   Accuracy: 1687/2000.0 (84.35%)



-= Testing valid =-
Test set: Average loss: 0.3719,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.3776,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.5554,                   Accuracy: 1646/2000.0 (82.30%)



-= Testing valid =-
Test set: Average loss: 0.4423,                   Accuracy: 1694/2000.0 (84.70%)



-= Testing valid =-
Test set: Average loss: 0.3376,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.4527,                   Accuracy: 1729/2000.0 (86.45%)



Epoch 20 train accuracy: 86.66%, valid accuracy 86.45%
-= Testing valid =-
Test set: Average loss: 0.3458,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.2532,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2294,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.2098,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2150,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.2259,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2106,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.2664,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.1837,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.2811,                   Accuracy: 1811/2000.0 (90.55%)



Epoch 30 train accuracy: 89.32%, valid accuracy 90.55%
-= Testing valid =-
Test set: Average loss: 0.2324,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2055,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.1686,                   Accuracy: 1885/2000.0 (94.25%)



-= Testing valid =-
Test set: Average loss: 0.2125,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2533,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2025,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.1854,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.3221,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.2413,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2499,                   Accuracy: 1836/2000.0 (91.80%)



Epoch 40 train accuracy: 90.32%, valid accuracy 91.80%
-= Testing valid =-
Test set: Average loss: 0.2227,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2487,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2440,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2362,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2425,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2026,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.1954,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.2455,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.2062,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.2359,                   Accuracy: 1830/2000.0 (91.50%)



Epoch 50 train accuracy: 91.00%, valid accuracy 91.50%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2088,                   Accuracy: 56288/60000 (93.81%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2310,                   Accuracy: 55823/60000 (93.04%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2320,                   Accuracy: 55846/60000 (93.08%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2441,                   Accuracy: 55561/60000 (92.60%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2557,                   Accuracy: 55289/60000 (92.15%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2749,                   Accuracy: 54907/60000 (91.51%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2912,                   Accuracy: 54476/60000 (90.79%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3056,                   Accuracy: 54170/60000 (90.28%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3272,                   Accuracy: 53713/60000 (89.52%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3393,                   Accuracy: 53393/60000 (88.99%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3870,                   Accuracy: 52520/60000 (87.53%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3888,                   Accuracy: 52271/60000 (87.12%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3962,                   Accuracy: 52107/60000 (86.85%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4095,                   Accuracy: 51726/60000 (86.21%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.4168,                   Accuracy: 51580/60000 (85.97%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4108,                   Accuracy: 51610/60000 (86.02%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4035,                   Accuracy: 51747/60000 (86.25%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.4014,                   Accuracy: 51999/60000 (86.67%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3689,                   Accuracy: 52620/60000 (87.70%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3811,                   Accuracy: 52669/60000 (87.78%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3478,                   Accuracy: 53285/60000 (88.81%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3263,                   Accuracy: 53785/60000 (89.64%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3203,                   Accuracy: 53958/60000 (89.93%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3160,                   Accuracy: 54162/60000 (90.27%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3029,                   Accuracy: 54467/60000 (90.78%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2924,                   Accuracy: 54658/60000 (91.10%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2863,                   Accuracy: 54859/60000 (91.43%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2750,                   Accuracy: 55120/60000 (91.87%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2824,                   Accuracy: 55066/60000 (91.78%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2730,                   Accuracy: 55275/60000 (92.12%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2595,                   Accuracy: 55487/60000 (92.48%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2500,                   Accuracy: 55693/60000 (92.82%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2415,                   Accuracy: 55846/60000 (93.08%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2306,                   Accuracy: 55951/60000 (93.25%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2250,                   Accuracy: 56066/60000 (93.44%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2209,                   Accuracy: 56066/60000 (93.44%)
{0: tensor(93.8133), 10: tensor(93.0383), 20: tensor(93.0767), 30: tensor(92.6017), 40: tensor(92.1483), 50: tensor(91.5117), 60: tensor(90.7933), 70: tensor(90.2833), 80: tensor(89.5217), 90: tensor(88.9883), 100: tensor(87.5333), 110: tensor(87.1183), 120: tensor(86.8450), 130: tensor(86.2100), 140: tensor(85.9667), 150: tensor(86.0167), 160: tensor(86.2450), 170: tensor(86.6650), 180: tensor(87.7000), 190: tensor(87.7817), 200: tensor(88.8083), 210: tensor(89.6417), 220: tensor(89.9300), 230: tensor(90.2700), 240: tensor(90.7783), 250: tensor(91.0967), 260: tensor(91.4317), 270: tensor(91.8667), 280: tensor(91.7767), 290: tensor(92.1250), 300: tensor(92.4783), 310: tensor(92.8217), 320: tensor(93.0767), 330: tensor(93.2517), 340: tensor(93.4433), 350: tensor(93.4433)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=75, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.7830,                   Accuracy: 219/2000.0 (10.95%)



-= Testing valid =-
Test set: Average loss: 2.6394,                   Accuracy: 440/2000.0 (22.00%)



-= Testing valid =-
Test set: Average loss: 2.3635,                   Accuracy: 530/2000.0 (26.50%)



-= Testing valid =-
Test set: Average loss: 1.7247,                   Accuracy: 782/2000.0 (39.10%)



-= Testing valid =-
Test set: Average loss: 1.3493,                   Accuracy: 1029/2000.0 (51.45%)



-= Testing valid =-
Test set: Average loss: 1.6593,                   Accuracy: 863/2000.0 (43.15%)



-= Testing valid =-
Test set: Average loss: 1.6528,                   Accuracy: 885/2000.0 (44.25%)



-= Testing valid =-
Test set: Average loss: 1.0782,                   Accuracy: 1344/2000.0 (67.20%)



-= Testing valid =-
Test set: Average loss: 0.6669,                   Accuracy: 1565/2000.0 (78.25%)



-= Testing valid =-
Test set: Average loss: 1.3581,                   Accuracy: 1070/2000.0 (53.50%)



Epoch 10 train accuracy: 76.46%, valid accuracy 53.50%
-= Testing valid =-
Test set: Average loss: 0.8137,                   Accuracy: 1362/2000.0 (68.10%)



-= Testing valid =-
Test set: Average loss: 0.4735,                   Accuracy: 1686/2000.0 (84.30%)



-= Testing valid =-
Test set: Average loss: 0.4033,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.5576,                   Accuracy: 1580/2000.0 (79.00%)



-= Testing valid =-
Test set: Average loss: 0.5873,                   Accuracy: 1559/2000.0 (77.95%)



-= Testing valid =-
Test set: Average loss: 0.4106,                   Accuracy: 1728/2000.0 (86.40%)



-= Testing valid =-
Test set: Average loss: 0.3737,                   Accuracy: 1765/2000.0 (88.25%)



-= Testing valid =-
Test set: Average loss: 0.4234,                   Accuracy: 1731/2000.0 (86.55%)



-= Testing valid =-
Test set: Average loss: 0.3715,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.4847,                   Accuracy: 1652/2000.0 (82.60%)



Epoch 20 train accuracy: 86.64%, valid accuracy 82.60%
-= Testing valid =-
Test set: Average loss: 0.4088,                   Accuracy: 1723/2000.0 (86.15%)



-= Testing valid =-
Test set: Average loss: 0.3329,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.2920,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.3134,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.2603,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.3367,                   Accuracy: 1768/2000.0 (88.40%)



-= Testing valid =-
Test set: Average loss: 0.3558,                   Accuracy: 1753/2000.0 (87.65%)



-= Testing valid =-
Test set: Average loss: 0.3829,                   Accuracy: 1716/2000.0 (85.80%)



-= Testing valid =-
Test set: Average loss: 0.3367,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3427,                   Accuracy: 1777/2000.0 (88.85%)



Epoch 30 train accuracy: 89.75%, valid accuracy 88.85%
-= Testing valid =-
Test set: Average loss: 0.3319,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.3274,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.3534,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.2750,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2435,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2914,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.2549,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2701,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2600,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.3333,                   Accuracy: 1764/2000.0 (88.20%)



Epoch 40 train accuracy: 90.85%, valid accuracy 88.20%
-= Testing valid =-
Test set: Average loss: 0.2792,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.2511,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2426,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.2891,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2554,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2630,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2900,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2603,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2263,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.2527,                   Accuracy: 1841/2000.0 (92.05%)



Epoch 50 train accuracy: 90.60%, valid accuracy 92.05%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2766,                   Accuracy: 55171/60000 (91.95%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2686,                   Accuracy: 55353/60000 (92.25%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2832,                   Accuracy: 55087/60000 (91.81%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2817,                   Accuracy: 55139/60000 (91.90%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2825,                   Accuracy: 55011/60000 (91.68%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2747,                   Accuracy: 55203/60000 (92.00%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2683,                   Accuracy: 55282/60000 (92.14%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2708,                   Accuracy: 55220/60000 (92.03%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2637,                   Accuracy: 55246/60000 (92.08%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2744,                   Accuracy: 55125/60000 (91.88%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2769,                   Accuracy: 55018/60000 (91.70%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3011,                   Accuracy: 54544/60000 (90.91%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3152,                   Accuracy: 54303/60000 (90.50%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3286,                   Accuracy: 53970/60000 (89.95%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3337,                   Accuracy: 53870/60000 (89.78%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3326,                   Accuracy: 53875/60000 (89.79%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3356,                   Accuracy: 53831/60000 (89.72%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3162,                   Accuracy: 54140/60000 (90.23%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3319,                   Accuracy: 53896/60000 (89.83%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3346,                   Accuracy: 53764/60000 (89.61%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3670,                   Accuracy: 52972/60000 (88.29%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3872,                   Accuracy: 52498/60000 (87.50%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3932,                   Accuracy: 52401/60000 (87.33%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3841,                   Accuracy: 52623/60000 (87.71%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3743,                   Accuracy: 52759/60000 (87.93%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3575,                   Accuracy: 53194/60000 (88.66%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3298,                   Accuracy: 53665/60000 (89.44%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3348,                   Accuracy: 53653/60000 (89.42%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3157,                   Accuracy: 54103/60000 (90.17%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3208,                   Accuracy: 54078/60000 (90.13%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3325,                   Accuracy: 53904/60000 (89.84%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3274,                   Accuracy: 53939/60000 (89.90%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3133,                   Accuracy: 54347/60000 (90.58%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3020,                   Accuracy: 54523/60000 (90.87%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2897,                   Accuracy: 54857/60000 (91.43%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2668,                   Accuracy: 55177/60000 (91.96%)
{0: tensor(91.9517), 10: tensor(92.2550), 20: tensor(91.8117), 30: tensor(91.8983), 40: tensor(91.6850), 50: tensor(92.0050), 60: tensor(92.1367), 70: tensor(92.0333), 80: tensor(92.0767), 90: tensor(91.8750), 100: tensor(91.6967), 110: tensor(90.9067), 120: tensor(90.5050), 130: tensor(89.9500), 140: tensor(89.7833), 150: tensor(89.7917), 160: tensor(89.7183), 170: tensor(90.2333), 180: tensor(89.8267), 190: tensor(89.6067), 200: tensor(88.2867), 210: tensor(87.4967), 220: tensor(87.3350), 230: tensor(87.7050), 240: tensor(87.9317), 250: tensor(88.6567), 260: tensor(89.4417), 270: tensor(89.4217), 280: tensor(90.1717), 290: tensor(90.1300), 300: tensor(89.8400), 310: tensor(89.8983), 320: tensor(90.5783), 330: tensor(90.8717), 340: tensor(91.4283), 350: tensor(91.9617)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=76, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.0716,                   Accuracy: 282/2000.0 (14.10%)



-= Testing valid =-
Test set: Average loss: 2.2140,                   Accuracy: 401/2000.0 (20.05%)



-= Testing valid =-
Test set: Average loss: 1.7898,                   Accuracy: 643/2000.0 (32.15%)



-= Testing valid =-
Test set: Average loss: 1.3090,                   Accuracy: 1051/2000.0 (52.55%)



-= Testing valid =-
Test set: Average loss: 2.1646,                   Accuracy: 692/2000.0 (34.60%)



-= Testing valid =-
Test set: Average loss: 1.4544,                   Accuracy: 1052/2000.0 (52.60%)



-= Testing valid =-
Test set: Average loss: 1.4006,                   Accuracy: 1140/2000.0 (57.00%)



-= Testing valid =-
Test set: Average loss: 2.0052,                   Accuracy: 869/2000.0 (43.45%)



-= Testing valid =-
Test set: Average loss: 0.8550,                   Accuracy: 1409/2000.0 (70.45%)



-= Testing valid =-
Test set: Average loss: 0.8614,                   Accuracy: 1470/2000.0 (73.50%)



Epoch 10 train accuracy: 75.90%, valid accuracy 73.50%
-= Testing valid =-
Test set: Average loss: 0.7572,                   Accuracy: 1456/2000.0 (72.80%)



-= Testing valid =-
Test set: Average loss: 0.6935,                   Accuracy: 1564/2000.0 (78.20%)



-= Testing valid =-
Test set: Average loss: 0.4730,                   Accuracy: 1708/2000.0 (85.40%)



-= Testing valid =-
Test set: Average loss: 0.5683,                   Accuracy: 1650/2000.0 (82.50%)



-= Testing valid =-
Test set: Average loss: 0.4307,                   Accuracy: 1755/2000.0 (87.75%)



-= Testing valid =-
Test set: Average loss: 0.4357,                   Accuracy: 1753/2000.0 (87.65%)



-= Testing valid =-
Test set: Average loss: 0.5988,                   Accuracy: 1583/2000.0 (79.15%)



-= Testing valid =-
Test set: Average loss: 0.4421,                   Accuracy: 1724/2000.0 (86.20%)



-= Testing valid =-
Test set: Average loss: 0.5787,                   Accuracy: 1611/2000.0 (80.55%)



-= Testing valid =-
Test set: Average loss: 0.6373,                   Accuracy: 1609/2000.0 (80.45%)



Epoch 20 train accuracy: 86.45%, valid accuracy 80.45%
-= Testing valid =-
Test set: Average loss: 0.3801,                   Accuracy: 1764/2000.0 (88.20%)



-= Testing valid =-
Test set: Average loss: 0.3449,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.3754,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.4164,                   Accuracy: 1752/2000.0 (87.60%)



-= Testing valid =-
Test set: Average loss: 0.2992,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.3569,                   Accuracy: 1760/2000.0 (88.00%)



-= Testing valid =-
Test set: Average loss: 0.3999,                   Accuracy: 1753/2000.0 (87.65%)



-= Testing valid =-
Test set: Average loss: 0.4022,                   Accuracy: 1737/2000.0 (86.85%)



-= Testing valid =-
Test set: Average loss: 0.4730,                   Accuracy: 1677/2000.0 (83.85%)



-= Testing valid =-
Test set: Average loss: 0.3575,                   Accuracy: 1783/2000.0 (89.15%)



Epoch 30 train accuracy: 89.35%, valid accuracy 89.15%
-= Testing valid =-
Test set: Average loss: 0.3470,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.4241,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.3974,                   Accuracy: 1738/2000.0 (86.90%)



-= Testing valid =-
Test set: Average loss: 0.2861,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2515,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.4207,                   Accuracy: 1731/2000.0 (86.55%)



-= Testing valid =-
Test set: Average loss: 0.3123,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.3468,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.2774,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2842,                   Accuracy: 1830/2000.0 (91.50%)



Epoch 40 train accuracy: 91.25%, valid accuracy 91.50%
-= Testing valid =-
Test set: Average loss: 0.3167,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2744,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.3271,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.2961,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2760,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2656,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.2586,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2552,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2595,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2661,                   Accuracy: 1845/2000.0 (92.25%)



Epoch 50 train accuracy: 91.05%, valid accuracy 92.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2633,                   Accuracy: 55445/60000 (92.41%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2661,                   Accuracy: 55288/60000 (92.15%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2927,                   Accuracy: 54916/60000 (91.53%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3093,                   Accuracy: 54666/60000 (91.11%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3123,                   Accuracy: 54518/60000 (90.86%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3165,                   Accuracy: 54459/60000 (90.76%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3259,                   Accuracy: 54179/60000 (90.30%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3303,                   Accuracy: 54027/60000 (90.04%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3232,                   Accuracy: 53991/60000 (89.99%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3433,                   Accuracy: 53562/60000 (89.27%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3555,                   Accuracy: 53203/60000 (88.67%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3796,                   Accuracy: 52651/60000 (87.75%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3901,                   Accuracy: 52325/60000 (87.21%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3959,                   Accuracy: 52073/60000 (86.79%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3931,                   Accuracy: 52153/60000 (86.92%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3879,                   Accuracy: 52080/60000 (86.80%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3783,                   Accuracy: 52250/60000 (87.08%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3555,                   Accuracy: 52741/60000 (87.90%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3604,                   Accuracy: 52733/60000 (87.89%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3503,                   Accuracy: 52943/60000 (88.24%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3501,                   Accuracy: 53103/60000 (88.50%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3532,                   Accuracy: 53103/60000 (88.50%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3537,                   Accuracy: 53075/60000 (88.46%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3537,                   Accuracy: 53017/60000 (88.36%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3451,                   Accuracy: 53174/60000 (88.62%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3280,                   Accuracy: 53667/60000 (89.44%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3164,                   Accuracy: 53977/60000 (89.96%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3155,                   Accuracy: 54211/60000 (90.35%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3107,                   Accuracy: 54384/60000 (90.64%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3098,                   Accuracy: 54599/60000 (91.00%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3069,                   Accuracy: 54578/60000 (90.96%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3009,                   Accuracy: 54799/60000 (91.33%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2919,                   Accuracy: 54928/60000 (91.55%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2811,                   Accuracy: 55077/60000 (91.79%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2748,                   Accuracy: 55225/60000 (92.04%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2543,                   Accuracy: 55568/60000 (92.61%)
{0: tensor(92.4083), 10: tensor(92.1467), 20: tensor(91.5267), 30: tensor(91.1100), 40: tensor(90.8633), 50: tensor(90.7650), 60: tensor(90.2983), 70: tensor(90.0450), 80: tensor(89.9850), 90: tensor(89.2700), 100: tensor(88.6717), 110: tensor(87.7517), 120: tensor(87.2083), 130: tensor(86.7883), 140: tensor(86.9217), 150: tensor(86.8000), 160: tensor(87.0833), 170: tensor(87.9017), 180: tensor(87.8883), 190: tensor(88.2383), 200: tensor(88.5050), 210: tensor(88.5050), 220: tensor(88.4583), 230: tensor(88.3617), 240: tensor(88.6233), 250: tensor(89.4450), 260: tensor(89.9617), 270: tensor(90.3517), 280: tensor(90.6400), 290: tensor(90.9983), 300: tensor(90.9633), 310: tensor(91.3317), 320: tensor(91.5467), 330: tensor(91.7950), 340: tensor(92.0417), 350: tensor(92.6133)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=77, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 7.9754,                   Accuracy: 253/2000.0 (12.65%)



-= Testing valid =-
Test set: Average loss: 5.0820,                   Accuracy: 256/2000.0 (12.80%)



-= Testing valid =-
Test set: Average loss: 1.4422,                   Accuracy: 926/2000.0 (46.30%)



-= Testing valid =-
Test set: Average loss: 1.8441,                   Accuracy: 689/2000.0 (34.45%)



-= Testing valid =-
Test set: Average loss: 1.4012,                   Accuracy: 959/2000.0 (47.95%)



-= Testing valid =-
Test set: Average loss: 1.6113,                   Accuracy: 863/2000.0 (43.15%)



-= Testing valid =-
Test set: Average loss: 1.2672,                   Accuracy: 1123/2000.0 (56.15%)



-= Testing valid =-
Test set: Average loss: 1.2933,                   Accuracy: 1055/2000.0 (52.75%)



-= Testing valid =-
Test set: Average loss: 1.8407,                   Accuracy: 624/2000.0 (31.20%)



-= Testing valid =-
Test set: Average loss: 1.4952,                   Accuracy: 960/2000.0 (48.00%)



Epoch 10 train accuracy: 71.66%, valid accuracy 48.00%
-= Testing valid =-
Test set: Average loss: 0.7237,                   Accuracy: 1546/2000.0 (77.30%)



-= Testing valid =-
Test set: Average loss: 1.0502,                   Accuracy: 1236/2000.0 (61.80%)



-= Testing valid =-
Test set: Average loss: 0.7548,                   Accuracy: 1484/2000.0 (74.20%)



-= Testing valid =-
Test set: Average loss: 0.6906,                   Accuracy: 1560/2000.0 (78.00%)



-= Testing valid =-
Test set: Average loss: 0.3989,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.5199,                   Accuracy: 1662/2000.0 (83.10%)



-= Testing valid =-
Test set: Average loss: 0.6520,                   Accuracy: 1557/2000.0 (77.85%)



-= Testing valid =-
Test set: Average loss: 0.6788,                   Accuracy: 1557/2000.0 (77.85%)



-= Testing valid =-
Test set: Average loss: 0.4739,                   Accuracy: 1712/2000.0 (85.60%)



-= Testing valid =-
Test set: Average loss: 0.3124,                   Accuracy: 1811/2000.0 (90.55%)



Epoch 20 train accuracy: 86.40%, valid accuracy 90.55%
-= Testing valid =-
Test set: Average loss: 0.3456,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.3864,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3275,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.3394,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.4417,                   Accuracy: 1722/2000.0 (86.10%)



-= Testing valid =-
Test set: Average loss: 0.3600,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.4549,                   Accuracy: 1720/2000.0 (86.00%)



-= Testing valid =-
Test set: Average loss: 0.4088,                   Accuracy: 1751/2000.0 (87.55%)



-= Testing valid =-
Test set: Average loss: 0.2599,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2895,                   Accuracy: 1835/2000.0 (91.75%)



Epoch 30 train accuracy: 88.05%, valid accuracy 91.75%
-= Testing valid =-
Test set: Average loss: 0.3049,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2752,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2759,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.3428,                   Accuracy: 1783/2000.0 (89.15%)



-= Testing valid =-
Test set: Average loss: 0.3748,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.2902,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2843,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2571,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2930,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2239,                   Accuracy: 1872/2000.0 (93.60%)



Epoch 40 train accuracy: 89.97%, valid accuracy 93.60%
-= Testing valid =-
Test set: Average loss: 0.2764,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2299,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.2212,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2755,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2483,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2993,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2759,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2529,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2497,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2369,                   Accuracy: 1860/2000.0 (93.00%)



Epoch 50 train accuracy: 90.68%, valid accuracy 93.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2710,                   Accuracy: 55315/60000 (92.19%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2708,                   Accuracy: 55184/60000 (91.97%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2791,                   Accuracy: 55037/60000 (91.73%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2996,                   Accuracy: 54577/60000 (90.96%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3028,                   Accuracy: 54484/60000 (90.81%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3167,                   Accuracy: 54290/60000 (90.48%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3377,                   Accuracy: 53840/60000 (89.73%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3341,                   Accuracy: 53928/60000 (89.88%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3424,                   Accuracy: 53588/60000 (89.31%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3696,                   Accuracy: 52995/60000 (88.32%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3891,                   Accuracy: 52456/60000 (87.43%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.4151,                   Accuracy: 51946/60000 (86.58%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4555,                   Accuracy: 50984/60000 (84.97%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4733,                   Accuracy: 50382/60000 (83.97%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.4794,                   Accuracy: 50122/60000 (83.54%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4779,                   Accuracy: 50091/60000 (83.49%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4704,                   Accuracy: 50215/60000 (83.69%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.4467,                   Accuracy: 50754/60000 (84.59%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.4446,                   Accuracy: 50906/60000 (84.84%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.4420,                   Accuracy: 51195/60000 (85.32%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.4425,                   Accuracy: 51050/60000 (85.08%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4360,                   Accuracy: 51319/60000 (85.53%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4173,                   Accuracy: 51747/60000 (86.25%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4023,                   Accuracy: 51988/60000 (86.65%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3911,                   Accuracy: 52157/60000 (86.93%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3693,                   Accuracy: 52705/60000 (87.84%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3383,                   Accuracy: 53427/60000 (89.04%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3340,                   Accuracy: 53724/60000 (89.54%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3278,                   Accuracy: 53893/60000 (89.82%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3126,                   Accuracy: 54416/60000 (90.69%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3169,                   Accuracy: 54369/60000 (90.61%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3012,                   Accuracy: 54758/60000 (91.26%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2917,                   Accuracy: 55032/60000 (91.72%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2898,                   Accuracy: 55047/60000 (91.75%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2782,                   Accuracy: 55266/60000 (92.11%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2703,                   Accuracy: 55350/60000 (92.25%)
{0: tensor(92.1917), 10: tensor(91.9733), 20: tensor(91.7283), 30: tensor(90.9617), 40: tensor(90.8067), 50: tensor(90.4833), 60: tensor(89.7333), 70: tensor(89.8800), 80: tensor(89.3133), 90: tensor(88.3250), 100: tensor(87.4267), 110: tensor(86.5767), 120: tensor(84.9733), 130: tensor(83.9700), 140: tensor(83.5367), 150: tensor(83.4850), 160: tensor(83.6917), 170: tensor(84.5900), 180: tensor(84.8433), 190: tensor(85.3250), 200: tensor(85.0833), 210: tensor(85.5317), 220: tensor(86.2450), 230: tensor(86.6467), 240: tensor(86.9283), 250: tensor(87.8417), 260: tensor(89.0450), 270: tensor(89.5400), 280: tensor(89.8217), 290: tensor(90.6933), 300: tensor(90.6150), 310: tensor(91.2633), 320: tensor(91.7200), 330: tensor(91.7450), 340: tensor(92.1100), 350: tensor(92.2500)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=78, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.6364,                   Accuracy: 266/2000.0 (13.30%)



-= Testing valid =-
Test set: Average loss: 1.7045,                   Accuracy: 856/2000.0 (42.80%)



-= Testing valid =-
Test set: Average loss: 1.3700,                   Accuracy: 1023/2000.0 (51.15%)



-= Testing valid =-
Test set: Average loss: 1.3119,                   Accuracy: 1136/2000.0 (56.80%)



-= Testing valid =-
Test set: Average loss: 1.1530,                   Accuracy: 1212/2000.0 (60.60%)



-= Testing valid =-
Test set: Average loss: 1.3252,                   Accuracy: 1128/2000.0 (56.40%)



-= Testing valid =-
Test set: Average loss: 1.3099,                   Accuracy: 1020/2000.0 (51.00%)



-= Testing valid =-
Test set: Average loss: 0.8300,                   Accuracy: 1407/2000.0 (70.35%)



-= Testing valid =-
Test set: Average loss: 0.8971,                   Accuracy: 1369/2000.0 (68.45%)



-= Testing valid =-
Test set: Average loss: 1.2542,                   Accuracy: 1202/2000.0 (60.10%)



Epoch 10 train accuracy: 78.29%, valid accuracy 60.10%
-= Testing valid =-
Test set: Average loss: 0.4876,                   Accuracy: 1724/2000.0 (86.20%)



-= Testing valid =-
Test set: Average loss: 0.6598,                   Accuracy: 1521/2000.0 (76.05%)



-= Testing valid =-
Test set: Average loss: 0.3782,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.4632,                   Accuracy: 1691/2000.0 (84.55%)



-= Testing valid =-
Test set: Average loss: 0.4275,                   Accuracy: 1729/2000.0 (86.45%)



-= Testing valid =-
Test set: Average loss: 0.3587,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.3332,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.4828,                   Accuracy: 1690/2000.0 (84.50%)



-= Testing valid =-
Test set: Average loss: 0.3614,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.3288,                   Accuracy: 1791/2000.0 (89.55%)



Epoch 20 train accuracy: 86.59%, valid accuracy 89.55%
-= Testing valid =-
Test set: Average loss: 0.3575,                   Accuracy: 1748/2000.0 (87.40%)



-= Testing valid =-
Test set: Average loss: 0.2877,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.3147,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.2665,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.2694,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2870,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2720,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.3118,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.2216,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.2166,                   Accuracy: 1893/2000.0 (94.65%)



Epoch 30 train accuracy: 88.75%, valid accuracy 94.65%
-= Testing valid =-
Test set: Average loss: 0.2512,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2480,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.2416,                   Accuracy: 1861/2000.0 (93.05%)



-= Testing valid =-
Test set: Average loss: 0.2707,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2716,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2332,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.2653,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2803,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2456,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2195,                   Accuracy: 1875/2000.0 (93.75%)



Epoch 40 train accuracy: 90.46%, valid accuracy 93.75%
-= Testing valid =-
Test set: Average loss: 0.2319,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.2472,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2405,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2270,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.2284,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2496,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.2285,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.2671,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2458,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.2463,                   Accuracy: 1854/2000.0 (92.70%)



Epoch 50 train accuracy: 91.07%, valid accuracy 92.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2492,                   Accuracy: 55719/60000 (92.86%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2472,                   Accuracy: 55799/60000 (93.00%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2606,                   Accuracy: 55623/60000 (92.71%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2670,                   Accuracy: 55451/60000 (92.42%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2734,                   Accuracy: 55292/60000 (92.15%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2794,                   Accuracy: 55190/60000 (91.98%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2791,                   Accuracy: 55106/60000 (91.84%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2786,                   Accuracy: 55048/60000 (91.75%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2629,                   Accuracy: 55293/60000 (92.15%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2663,                   Accuracy: 55203/60000 (92.00%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2671,                   Accuracy: 55107/60000 (91.85%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2874,                   Accuracy: 54697/60000 (91.16%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3006,                   Accuracy: 54356/60000 (90.59%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3259,                   Accuracy: 53703/60000 (89.50%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3534,                   Accuracy: 52957/60000 (88.26%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3872,                   Accuracy: 51928/60000 (86.55%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4178,                   Accuracy: 51150/60000 (85.25%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.4186,                   Accuracy: 51074/60000 (85.12%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.4422,                   Accuracy: 50462/60000 (84.10%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.4404,                   Accuracy: 50730/60000 (84.55%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.4658,                   Accuracy: 50125/60000 (83.54%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4663,                   Accuracy: 50207/60000 (83.68%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4598,                   Accuracy: 50525/60000 (84.21%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4431,                   Accuracy: 50879/60000 (84.80%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4178,                   Accuracy: 51363/60000 (85.61%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3929,                   Accuracy: 51968/60000 (86.61%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3540,                   Accuracy: 52910/60000 (88.18%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3360,                   Accuracy: 53266/60000 (88.78%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3050,                   Accuracy: 54110/60000 (90.18%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2931,                   Accuracy: 54447/60000 (90.75%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2899,                   Accuracy: 54528/60000 (90.88%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2906,                   Accuracy: 54615/60000 (91.03%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2885,                   Accuracy: 54724/60000 (91.21%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2774,                   Accuracy: 55056/60000 (91.76%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2686,                   Accuracy: 55307/60000 (92.18%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2475,                   Accuracy: 55661/60000 (92.77%)
{0: tensor(92.8650), 10: tensor(92.9983), 20: tensor(92.7050), 30: tensor(92.4183), 40: tensor(92.1533), 50: tensor(91.9833), 60: tensor(91.8433), 70: tensor(91.7467), 80: tensor(92.1550), 90: tensor(92.0050), 100: tensor(91.8450), 110: tensor(91.1617), 120: tensor(90.5933), 130: tensor(89.5050), 140: tensor(88.2617), 150: tensor(86.5467), 160: tensor(85.2500), 170: tensor(85.1233), 180: tensor(84.1033), 190: tensor(84.5500), 200: tensor(83.5417), 210: tensor(83.6783), 220: tensor(84.2083), 230: tensor(84.7983), 240: tensor(85.6050), 250: tensor(86.6133), 260: tensor(88.1833), 270: tensor(88.7767), 280: tensor(90.1833), 290: tensor(90.7450), 300: tensor(90.8800), 310: tensor(91.0250), 320: tensor(91.2067), 330: tensor(91.7600), 340: tensor(92.1783), 350: tensor(92.7683)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=79, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 1.9984,                   Accuracy: 598/2000.0 (29.90%)



-= Testing valid =-
Test set: Average loss: 2.7545,                   Accuracy: 479/2000.0 (23.95%)



-= Testing valid =-
Test set: Average loss: 1.7388,                   Accuracy: 768/2000.0 (38.40%)



-= Testing valid =-
Test set: Average loss: 1.5610,                   Accuracy: 967/2000.0 (48.35%)



-= Testing valid =-
Test set: Average loss: 1.5791,                   Accuracy: 904/2000.0 (45.20%)



-= Testing valid =-
Test set: Average loss: 1.5071,                   Accuracy: 947/2000.0 (47.35%)



-= Testing valid =-
Test set: Average loss: 0.9583,                   Accuracy: 1406/2000.0 (70.30%)



-= Testing valid =-
Test set: Average loss: 0.8308,                   Accuracy: 1473/2000.0 (73.65%)



-= Testing valid =-
Test set: Average loss: 0.8576,                   Accuracy: 1423/2000.0 (71.15%)



-= Testing valid =-
Test set: Average loss: 0.9547,                   Accuracy: 1294/2000.0 (64.70%)



Epoch 10 train accuracy: 74.64%, valid accuracy 64.70%
-= Testing valid =-
Test set: Average loss: 1.0158,                   Accuracy: 1281/2000.0 (64.05%)



-= Testing valid =-
Test set: Average loss: 0.5935,                   Accuracy: 1591/2000.0 (79.55%)



-= Testing valid =-
Test set: Average loss: 0.4850,                   Accuracy: 1687/2000.0 (84.35%)



-= Testing valid =-
Test set: Average loss: 0.5136,                   Accuracy: 1668/2000.0 (83.40%)



-= Testing valid =-
Test set: Average loss: 0.4126,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.4439,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.6086,                   Accuracy: 1600/2000.0 (80.00%)



-= Testing valid =-
Test set: Average loss: 0.5582,                   Accuracy: 1643/2000.0 (82.15%)



-= Testing valid =-
Test set: Average loss: 0.3763,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 0.3325,                   Accuracy: 1798/2000.0 (89.90%)



Epoch 20 train accuracy: 86.93%, valid accuracy 89.90%
-= Testing valid =-
Test set: Average loss: 0.3415,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2989,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2856,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.3253,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.2997,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.3406,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.3153,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.3722,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.3023,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3677,                   Accuracy: 1776/2000.0 (88.80%)



Epoch 30 train accuracy: 90.09%, valid accuracy 88.80%
-= Testing valid =-
Test set: Average loss: 0.3217,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.3052,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.3302,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.3096,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.3140,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2930,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.3059,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2938,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.3246,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.2739,                   Accuracy: 1846/2000.0 (92.30%)



Epoch 40 train accuracy: 90.90%, valid accuracy 92.30%
-= Testing valid =-
Test set: Average loss: 0.2765,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.3428,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.2816,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.3555,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3385,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.2892,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.3276,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.3264,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.2893,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.3172,                   Accuracy: 1820/2000.0 (91.00%)



Epoch 50 train accuracy: 90.74%, valid accuracy 91.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3174,                   Accuracy: 54159/60000 (90.26%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3155,                   Accuracy: 54230/60000 (90.38%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3235,                   Accuracy: 54120/60000 (90.20%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3231,                   Accuracy: 54101/60000 (90.17%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3128,                   Accuracy: 54247/60000 (90.41%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2995,                   Accuracy: 54580/60000 (90.97%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2906,                   Accuracy: 54729/60000 (91.21%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2805,                   Accuracy: 54985/60000 (91.64%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2626,                   Accuracy: 55291/60000 (92.15%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2737,                   Accuracy: 55131/60000 (91.89%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2858,                   Accuracy: 54825/60000 (91.38%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3007,                   Accuracy: 54662/60000 (91.10%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3114,                   Accuracy: 54467/60000 (90.78%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3215,                   Accuracy: 54301/60000 (90.50%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3295,                   Accuracy: 54049/60000 (90.08%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3404,                   Accuracy: 53709/60000 (89.51%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3445,                   Accuracy: 53566/60000 (89.28%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3321,                   Accuracy: 53623/60000 (89.37%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3443,                   Accuracy: 53494/60000 (89.16%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3651,                   Accuracy: 53031/60000 (88.39%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3826,                   Accuracy: 52690/60000 (87.82%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3894,                   Accuracy: 52438/60000 (87.40%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3974,                   Accuracy: 52176/60000 (86.96%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3920,                   Accuracy: 52288/60000 (87.15%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3905,                   Accuracy: 52271/60000 (87.12%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3947,                   Accuracy: 52187/60000 (86.98%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3758,                   Accuracy: 52567/60000 (87.61%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3804,                   Accuracy: 52420/60000 (87.37%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3835,                   Accuracy: 52456/60000 (87.43%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3975,                   Accuracy: 52233/60000 (87.06%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3897,                   Accuracy: 52425/60000 (87.38%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3775,                   Accuracy: 52729/60000 (87.88%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3568,                   Accuracy: 53310/60000 (88.85%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3397,                   Accuracy: 53745/60000 (89.57%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3294,                   Accuracy: 54002/60000 (90.00%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3039,                   Accuracy: 54432/60000 (90.72%)
{0: tensor(90.2650), 10: tensor(90.3833), 20: tensor(90.2000), 30: tensor(90.1683), 40: tensor(90.4117), 50: tensor(90.9667), 60: tensor(91.2150), 70: tensor(91.6417), 80: tensor(92.1517), 90: tensor(91.8850), 100: tensor(91.3750), 110: tensor(91.1033), 120: tensor(90.7783), 130: tensor(90.5017), 140: tensor(90.0817), 150: tensor(89.5150), 160: tensor(89.2767), 170: tensor(89.3717), 180: tensor(89.1567), 190: tensor(88.3850), 200: tensor(87.8167), 210: tensor(87.3967), 220: tensor(86.9600), 230: tensor(87.1467), 240: tensor(87.1183), 250: tensor(86.9783), 260: tensor(87.6117), 270: tensor(87.3667), 280: tensor(87.4267), 290: tensor(87.0550), 300: tensor(87.3750), 310: tensor(87.8817), 320: tensor(88.8500), 330: tensor(89.5750), 340: tensor(90.0033), 350: tensor(90.7200)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=80, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.5829,                   Accuracy: 465/2000.0 (23.25%)



-= Testing valid =-
Test set: Average loss: 2.8737,                   Accuracy: 308/2000.0 (15.40%)



-= Testing valid =-
Test set: Average loss: 2.4372,                   Accuracy: 541/2000.0 (27.05%)



-= Testing valid =-
Test set: Average loss: 2.0288,                   Accuracy: 596/2000.0 (29.80%)



-= Testing valid =-
Test set: Average loss: 2.7571,                   Accuracy: 501/2000.0 (25.05%)



-= Testing valid =-
Test set: Average loss: 1.8903,                   Accuracy: 799/2000.0 (39.95%)



-= Testing valid =-
Test set: Average loss: 1.1714,                   Accuracy: 1252/2000.0 (62.60%)



-= Testing valid =-
Test set: Average loss: 2.3964,                   Accuracy: 601/2000.0 (30.05%)



-= Testing valid =-
Test set: Average loss: 1.3123,                   Accuracy: 1137/2000.0 (56.85%)



-= Testing valid =-
Test set: Average loss: 0.7439,                   Accuracy: 1456/2000.0 (72.80%)



Epoch 10 train accuracy: 73.69%, valid accuracy 72.80%
-= Testing valid =-
Test set: Average loss: 0.6706,                   Accuracy: 1522/2000.0 (76.10%)



-= Testing valid =-
Test set: Average loss: 0.7207,                   Accuracy: 1514/2000.0 (75.70%)



-= Testing valid =-
Test set: Average loss: 0.6515,                   Accuracy: 1571/2000.0 (78.55%)



-= Testing valid =-
Test set: Average loss: 0.6957,                   Accuracy: 1491/2000.0 (74.55%)



-= Testing valid =-
Test set: Average loss: 0.4830,                   Accuracy: 1705/2000.0 (85.25%)



-= Testing valid =-
Test set: Average loss: 0.3973,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.6847,                   Accuracy: 1521/2000.0 (76.05%)



-= Testing valid =-
Test set: Average loss: 0.3665,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.4238,                   Accuracy: 1718/2000.0 (85.90%)



-= Testing valid =-
Test set: Average loss: 0.3993,                   Accuracy: 1746/2000.0 (87.30%)



Epoch 20 train accuracy: 85.56%, valid accuracy 87.30%
-= Testing valid =-
Test set: Average loss: 0.4812,                   Accuracy: 1690/2000.0 (84.50%)



-= Testing valid =-
Test set: Average loss: 0.3279,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.3998,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.3942,                   Accuracy: 1754/2000.0 (87.70%)



-= Testing valid =-
Test set: Average loss: 0.3455,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.3362,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.3043,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.2725,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2837,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.3325,                   Accuracy: 1786/2000.0 (89.30%)



Epoch 30 train accuracy: 88.61%, valid accuracy 89.30%
-= Testing valid =-
Test set: Average loss: 0.2810,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2551,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.3134,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.2638,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2950,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.3661,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.2883,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.3061,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2924,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.2698,                   Accuracy: 1834/2000.0 (91.70%)



Epoch 40 train accuracy: 90.09%, valid accuracy 91.70%
-= Testing valid =-
Test set: Average loss: 0.2898,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2814,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.2692,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2872,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2970,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.3190,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.2829,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2880,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.2819,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.2461,                   Accuracy: 1860/2000.0 (93.00%)



Epoch 50 train accuracy: 90.97%, valid accuracy 93.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2850,                   Accuracy: 54774/60000 (91.29%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2713,                   Accuracy: 55147/60000 (91.91%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2685,                   Accuracy: 55280/60000 (92.13%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2748,                   Accuracy: 55185/60000 (91.97%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2830,                   Accuracy: 55067/60000 (91.78%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2854,                   Accuracy: 55038/60000 (91.73%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2936,                   Accuracy: 54877/60000 (91.46%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2964,                   Accuracy: 54823/60000 (91.37%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2831,                   Accuracy: 54991/60000 (91.65%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3007,                   Accuracy: 54710/60000 (91.18%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3042,                   Accuracy: 54547/60000 (90.91%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3208,                   Accuracy: 54255/60000 (90.43%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3332,                   Accuracy: 53937/60000 (89.89%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3529,                   Accuracy: 53355/60000 (88.93%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3671,                   Accuracy: 52996/60000 (88.33%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3766,                   Accuracy: 52660/60000 (87.77%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3716,                   Accuracy: 52758/60000 (87.93%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3641,                   Accuracy: 52908/60000 (88.18%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3768,                   Accuracy: 52626/60000 (87.71%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3741,                   Accuracy: 52583/60000 (87.64%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3840,                   Accuracy: 52191/60000 (86.99%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4025,                   Accuracy: 51787/60000 (86.31%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4106,                   Accuracy: 51447/60000 (85.75%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4123,                   Accuracy: 51283/60000 (85.47%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4139,                   Accuracy: 51376/60000 (85.63%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.4001,                   Accuracy: 51751/60000 (86.25%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3809,                   Accuracy: 52245/60000 (87.07%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3874,                   Accuracy: 52256/60000 (87.09%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3636,                   Accuracy: 53056/60000 (88.43%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3731,                   Accuracy: 52757/60000 (87.93%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3810,                   Accuracy: 52589/60000 (87.65%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3704,                   Accuracy: 52815/60000 (88.03%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3506,                   Accuracy: 53308/60000 (88.85%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3374,                   Accuracy: 53598/60000 (89.33%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3084,                   Accuracy: 54303/60000 (90.50%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2754,                   Accuracy: 54989/60000 (91.65%)
{0: tensor(91.2900), 10: tensor(91.9117), 20: tensor(92.1333), 30: tensor(91.9750), 40: tensor(91.7783), 50: tensor(91.7300), 60: tensor(91.4617), 70: tensor(91.3717), 80: tensor(91.6517), 90: tensor(91.1833), 100: tensor(90.9117), 110: tensor(90.4250), 120: tensor(89.8950), 130: tensor(88.9250), 140: tensor(88.3267), 150: tensor(87.7667), 160: tensor(87.9300), 170: tensor(88.1800), 180: tensor(87.7100), 190: tensor(87.6383), 200: tensor(86.9850), 210: tensor(86.3117), 220: tensor(85.7450), 230: tensor(85.4717), 240: tensor(85.6267), 250: tensor(86.2517), 260: tensor(87.0750), 270: tensor(87.0933), 280: tensor(88.4267), 290: tensor(87.9283), 300: tensor(87.6483), 310: tensor(88.0250), 320: tensor(88.8467), 330: tensor(89.3300), 340: tensor(90.5050), 350: tensor(91.6483)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=81, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 8.5101,                   Accuracy: 220/2000.0 (11.00%)



-= Testing valid =-
Test set: Average loss: 2.2982,                   Accuracy: 493/2000.0 (24.65%)



-= Testing valid =-
Test set: Average loss: 1.8769,                   Accuracy: 725/2000.0 (36.25%)



-= Testing valid =-
Test set: Average loss: 2.1897,                   Accuracy: 525/2000.0 (26.25%)



-= Testing valid =-
Test set: Average loss: 1.1054,                   Accuracy: 1228/2000.0 (61.40%)



-= Testing valid =-
Test set: Average loss: 1.6518,                   Accuracy: 1031/2000.0 (51.55%)



-= Testing valid =-
Test set: Average loss: 0.8608,                   Accuracy: 1418/2000.0 (70.90%)



-= Testing valid =-
Test set: Average loss: 0.9660,                   Accuracy: 1349/2000.0 (67.45%)



-= Testing valid =-
Test set: Average loss: 1.0302,                   Accuracy: 1331/2000.0 (66.55%)



-= Testing valid =-
Test set: Average loss: 1.1353,                   Accuracy: 1212/2000.0 (60.60%)



Epoch 10 train accuracy: 74.04%, valid accuracy 60.60%
-= Testing valid =-
Test set: Average loss: 0.8286,                   Accuracy: 1479/2000.0 (73.95%)



-= Testing valid =-
Test set: Average loss: 0.6304,                   Accuracy: 1607/2000.0 (80.35%)



-= Testing valid =-
Test set: Average loss: 0.8607,                   Accuracy: 1288/2000.0 (64.40%)



-= Testing valid =-
Test set: Average loss: 0.5717,                   Accuracy: 1610/2000.0 (80.50%)



-= Testing valid =-
Test set: Average loss: 0.5265,                   Accuracy: 1610/2000.0 (80.50%)



-= Testing valid =-
Test set: Average loss: 0.7387,                   Accuracy: 1452/2000.0 (72.60%)



-= Testing valid =-
Test set: Average loss: 0.5112,                   Accuracy: 1661/2000.0 (83.05%)



-= Testing valid =-
Test set: Average loss: 0.5147,                   Accuracy: 1637/2000.0 (81.85%)



-= Testing valid =-
Test set: Average loss: 0.4243,                   Accuracy: 1736/2000.0 (86.80%)



-= Testing valid =-
Test set: Average loss: 0.4482,                   Accuracy: 1699/2000.0 (84.95%)



Epoch 20 train accuracy: 85.36%, valid accuracy 84.95%
-= Testing valid =-
Test set: Average loss: 0.3716,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.3832,                   Accuracy: 1748/2000.0 (87.40%)



-= Testing valid =-
Test set: Average loss: 0.4706,                   Accuracy: 1639/2000.0 (81.95%)



-= Testing valid =-
Test set: Average loss: 0.3450,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.3713,                   Accuracy: 1760/2000.0 (88.00%)



-= Testing valid =-
Test set: Average loss: 0.3864,                   Accuracy: 1764/2000.0 (88.20%)



-= Testing valid =-
Test set: Average loss: 0.3604,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.4679,                   Accuracy: 1657/2000.0 (82.85%)



-= Testing valid =-
Test set: Average loss: 0.3498,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.3686,                   Accuracy: 1758/2000.0 (87.90%)



Epoch 30 train accuracy: 88.61%, valid accuracy 87.90%
-= Testing valid =-
Test set: Average loss: 0.3256,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.3271,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.3197,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.3602,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.3014,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.3325,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.3017,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2869,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.2931,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.3959,                   Accuracy: 1704/2000.0 (85.20%)



Epoch 40 train accuracy: 89.68%, valid accuracy 85.20%
-= Testing valid =-
Test set: Average loss: 0.4122,                   Accuracy: 1690/2000.0 (84.50%)



-= Testing valid =-
Test set: Average loss: 0.4081,                   Accuracy: 1706/2000.0 (85.30%)



-= Testing valid =-
Test set: Average loss: 0.3485,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.3023,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.3299,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.3007,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.3418,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.2998,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.3089,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.3215,                   Accuracy: 1794/2000.0 (89.70%)



Epoch 50 train accuracy: 90.30%, valid accuracy 89.70%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3462,                   Accuracy: 53741/60000 (89.57%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3336,                   Accuracy: 53997/60000 (90.00%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3357,                   Accuracy: 54046/60000 (90.08%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3361,                   Accuracy: 54096/60000 (90.16%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3260,                   Accuracy: 54274/60000 (90.46%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3206,                   Accuracy: 54460/60000 (90.77%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3129,                   Accuracy: 54629/60000 (91.05%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3032,                   Accuracy: 54746/60000 (91.24%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2934,                   Accuracy: 54805/60000 (91.34%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3006,                   Accuracy: 54645/60000 (91.07%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3079,                   Accuracy: 54304/60000 (90.51%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3251,                   Accuracy: 54039/60000 (90.07%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3504,                   Accuracy: 53497/60000 (89.16%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3633,                   Accuracy: 53201/60000 (88.67%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3761,                   Accuracy: 52804/60000 (88.01%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3877,                   Accuracy: 52465/60000 (87.44%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3824,                   Accuracy: 52533/60000 (87.56%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3597,                   Accuracy: 53027/60000 (88.38%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3681,                   Accuracy: 52952/60000 (88.25%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3584,                   Accuracy: 53149/60000 (88.58%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3736,                   Accuracy: 52874/60000 (88.12%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3936,                   Accuracy: 52358/60000 (87.26%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4007,                   Accuracy: 52071/60000 (86.79%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3989,                   Accuracy: 52258/60000 (87.10%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3916,                   Accuracy: 52591/60000 (87.65%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3770,                   Accuracy: 52834/60000 (88.06%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3480,                   Accuracy: 53406/60000 (89.01%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3546,                   Accuracy: 53336/60000 (88.89%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3514,                   Accuracy: 53418/60000 (89.03%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3568,                   Accuracy: 53336/60000 (88.89%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3707,                   Accuracy: 53151/60000 (88.58%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3694,                   Accuracy: 53202/60000 (88.67%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3660,                   Accuracy: 53339/60000 (88.90%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3683,                   Accuracy: 53292/60000 (88.82%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3537,                   Accuracy: 53626/60000 (89.38%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3307,                   Accuracy: 54045/60000 (90.07%)
{0: tensor(89.5683), 10: tensor(89.9950), 20: tensor(90.0767), 30: tensor(90.1600), 40: tensor(90.4567), 50: tensor(90.7667), 60: tensor(91.0483), 70: tensor(91.2433), 80: tensor(91.3417), 90: tensor(91.0750), 100: tensor(90.5067), 110: tensor(90.0650), 120: tensor(89.1617), 130: tensor(88.6683), 140: tensor(88.0067), 150: tensor(87.4417), 160: tensor(87.5550), 170: tensor(88.3783), 180: tensor(88.2533), 190: tensor(88.5817), 200: tensor(88.1233), 210: tensor(87.2633), 220: tensor(86.7850), 230: tensor(87.0967), 240: tensor(87.6517), 250: tensor(88.0567), 260: tensor(89.0100), 270: tensor(88.8933), 280: tensor(89.0300), 290: tensor(88.8933), 300: tensor(88.5850), 310: tensor(88.6700), 320: tensor(88.8983), 330: tensor(88.8200), 340: tensor(89.3767), 350: tensor(90.0750)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=82, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 8.2225,                   Accuracy: 225/2000.0 (11.25%)



-= Testing valid =-
Test set: Average loss: 6.2814,                   Accuracy: 226/2000.0 (11.30%)



-= Testing valid =-
Test set: Average loss: 2.3264,                   Accuracy: 434/2000.0 (21.70%)



-= Testing valid =-
Test set: Average loss: 1.4566,                   Accuracy: 921/2000.0 (46.05%)



-= Testing valid =-
Test set: Average loss: 1.7461,                   Accuracy: 856/2000.0 (42.80%)



-= Testing valid =-
Test set: Average loss: 0.8932,                   Accuracy: 1322/2000.0 (66.10%)



-= Testing valid =-
Test set: Average loss: 1.2983,                   Accuracy: 1128/2000.0 (56.40%)



-= Testing valid =-
Test set: Average loss: 1.0279,                   Accuracy: 1275/2000.0 (63.75%)



-= Testing valid =-
Test set: Average loss: 0.9207,                   Accuracy: 1377/2000.0 (68.85%)



-= Testing valid =-
Test set: Average loss: 0.6621,                   Accuracy: 1575/2000.0 (78.75%)



Epoch 10 train accuracy: 72.14%, valid accuracy 78.75%
-= Testing valid =-
Test set: Average loss: 0.5917,                   Accuracy: 1647/2000.0 (82.35%)



-= Testing valid =-
Test set: Average loss: 0.6951,                   Accuracy: 1526/2000.0 (76.30%)



-= Testing valid =-
Test set: Average loss: 0.6452,                   Accuracy: 1485/2000.0 (74.25%)



-= Testing valid =-
Test set: Average loss: 0.4540,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.5684,                   Accuracy: 1659/2000.0 (82.95%)



-= Testing valid =-
Test set: Average loss: 0.4570,                   Accuracy: 1714/2000.0 (85.70%)



-= Testing valid =-
Test set: Average loss: 0.5907,                   Accuracy: 1593/2000.0 (79.65%)



-= Testing valid =-
Test set: Average loss: 0.4537,                   Accuracy: 1712/2000.0 (85.60%)



-= Testing valid =-
Test set: Average loss: 0.3879,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.3572,                   Accuracy: 1776/2000.0 (88.80%)



Epoch 20 train accuracy: 84.19%, valid accuracy 88.80%
-= Testing valid =-
Test set: Average loss: 0.2767,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.3013,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.3450,                   Accuracy: 1768/2000.0 (88.40%)



-= Testing valid =-
Test set: Average loss: 0.2362,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.3113,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.2720,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2526,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2802,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.2784,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2502,                   Accuracy: 1837/2000.0 (91.85%)



Epoch 30 train accuracy: 87.46%, valid accuracy 91.85%
-= Testing valid =-
Test set: Average loss: 0.2997,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.2418,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.2585,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2373,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.2373,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2626,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2319,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.2184,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2431,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2711,                   Accuracy: 1806/2000.0 (90.30%)



Epoch 40 train accuracy: 89.60%, valid accuracy 90.30%
-= Testing valid =-
Test set: Average loss: 0.2575,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2619,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2414,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2525,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2523,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2141,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2333,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2623,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2303,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2295,                   Accuracy: 1846/2000.0 (92.30%)



Epoch 50 train accuracy: 90.06%, valid accuracy 92.30%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2678,                   Accuracy: 54896/60000 (91.49%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2865,                   Accuracy: 54523/60000 (90.87%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2792,                   Accuracy: 54747/60000 (91.25%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2857,                   Accuracy: 54602/60000 (91.00%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2929,                   Accuracy: 54461/60000 (90.77%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2993,                   Accuracy: 54270/60000 (90.45%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2967,                   Accuracy: 54242/60000 (90.40%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3008,                   Accuracy: 54091/60000 (90.15%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2988,                   Accuracy: 54061/60000 (90.10%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2950,                   Accuracy: 54228/60000 (90.38%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3139,                   Accuracy: 53868/60000 (89.78%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3200,                   Accuracy: 53723/60000 (89.54%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3324,                   Accuracy: 53603/60000 (89.34%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3222,                   Accuracy: 53826/60000 (89.71%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3137,                   Accuracy: 54049/60000 (90.08%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3028,                   Accuracy: 54252/60000 (90.42%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.2941,                   Accuracy: 54449/60000 (90.75%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.2914,                   Accuracy: 54364/60000 (90.61%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.2826,                   Accuracy: 54611/60000 (91.02%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.2873,                   Accuracy: 54518/60000 (90.86%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.2730,                   Accuracy: 54934/60000 (91.56%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.2772,                   Accuracy: 54871/60000 (91.45%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.2726,                   Accuracy: 54960/60000 (91.60%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.2682,                   Accuracy: 55038/60000 (91.73%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.2652,                   Accuracy: 55021/60000 (91.70%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2537,                   Accuracy: 55258/60000 (92.10%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2504,                   Accuracy: 55215/60000 (92.03%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2421,                   Accuracy: 55459/60000 (92.43%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2562,                   Accuracy: 55188/60000 (91.98%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2569,                   Accuracy: 55251/60000 (92.08%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2681,                   Accuracy: 55048/60000 (91.75%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2738,                   Accuracy: 54953/60000 (91.59%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2792,                   Accuracy: 54826/60000 (91.38%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2789,                   Accuracy: 54778/60000 (91.30%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2731,                   Accuracy: 54896/60000 (91.49%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2752,                   Accuracy: 54724/60000 (91.21%)
{0: tensor(91.4933), 10: tensor(90.8717), 20: tensor(91.2450), 30: tensor(91.0033), 40: tensor(90.7683), 50: tensor(90.4500), 60: tensor(90.4033), 70: tensor(90.1517), 80: tensor(90.1017), 90: tensor(90.3800), 100: tensor(89.7800), 110: tensor(89.5383), 120: tensor(89.3383), 130: tensor(89.7100), 140: tensor(90.0817), 150: tensor(90.4200), 160: tensor(90.7483), 170: tensor(90.6067), 180: tensor(91.0183), 190: tensor(90.8633), 200: tensor(91.5567), 210: tensor(91.4517), 220: tensor(91.6000), 230: tensor(91.7300), 240: tensor(91.7017), 250: tensor(92.0967), 260: tensor(92.0250), 270: tensor(92.4317), 280: tensor(91.9800), 290: tensor(92.0850), 300: tensor(91.7467), 310: tensor(91.5883), 320: tensor(91.3767), 330: tensor(91.2967), 340: tensor(91.4933), 350: tensor(91.2067)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=83, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.2281,                   Accuracy: 223/2000.0 (11.15%)



-= Testing valid =-
Test set: Average loss: 2.6902,                   Accuracy: 344/2000.0 (17.20%)



-= Testing valid =-
Test set: Average loss: 2.1552,                   Accuracy: 541/2000.0 (27.05%)



-= Testing valid =-
Test set: Average loss: 1.4004,                   Accuracy: 992/2000.0 (49.60%)



-= Testing valid =-
Test set: Average loss: 3.0375,                   Accuracy: 608/2000.0 (30.40%)



-= Testing valid =-
Test set: Average loss: 2.6179,                   Accuracy: 560/2000.0 (28.00%)



-= Testing valid =-
Test set: Average loss: 1.7394,                   Accuracy: 692/2000.0 (34.60%)



-= Testing valid =-
Test set: Average loss: 1.1276,                   Accuracy: 1173/2000.0 (58.65%)



-= Testing valid =-
Test set: Average loss: 1.7400,                   Accuracy: 897/2000.0 (44.85%)



-= Testing valid =-
Test set: Average loss: 1.0748,                   Accuracy: 1235/2000.0 (61.75%)



Epoch 10 train accuracy: 71.78%, valid accuracy 61.75%
-= Testing valid =-
Test set: Average loss: 0.9002,                   Accuracy: 1427/2000.0 (71.35%)



-= Testing valid =-
Test set: Average loss: 1.1211,                   Accuracy: 1248/2000.0 (62.40%)



-= Testing valid =-
Test set: Average loss: 0.7461,                   Accuracy: 1488/2000.0 (74.40%)



-= Testing valid =-
Test set: Average loss: 0.8629,                   Accuracy: 1392/2000.0 (69.60%)



-= Testing valid =-
Test set: Average loss: 0.7219,                   Accuracy: 1524/2000.0 (76.20%)



-= Testing valid =-
Test set: Average loss: 0.5694,                   Accuracy: 1629/2000.0 (81.45%)



-= Testing valid =-
Test set: Average loss: 0.6472,                   Accuracy: 1530/2000.0 (76.50%)



-= Testing valid =-
Test set: Average loss: 0.3930,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.3761,                   Accuracy: 1755/2000.0 (87.75%)



-= Testing valid =-
Test set: Average loss: 0.3522,                   Accuracy: 1771/2000.0 (88.55%)



Epoch 20 train accuracy: 85.96%, valid accuracy 88.55%
-= Testing valid =-
Test set: Average loss: 0.3608,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.3649,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3321,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3634,                   Accuracy: 1751/2000.0 (87.55%)



-= Testing valid =-
Test set: Average loss: 0.2979,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.3331,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.3311,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.3669,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.3969,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.3363,                   Accuracy: 1775/2000.0 (88.75%)



Epoch 30 train accuracy: 89.15%, valid accuracy 88.75%
-= Testing valid =-
Test set: Average loss: 0.3637,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.3173,                   Accuracy: 1800/2000.0 (90.00%)



-= Testing valid =-
Test set: Average loss: 0.3375,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.3442,                   Accuracy: 1768/2000.0 (88.40%)



-= Testing valid =-
Test set: Average loss: 0.3520,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.3579,                   Accuracy: 1759/2000.0 (87.95%)



-= Testing valid =-
Test set: Average loss: 0.3087,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2785,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.2800,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.3202,                   Accuracy: 1790/2000.0 (89.50%)



Epoch 40 train accuracy: 90.00%, valid accuracy 89.50%
-= Testing valid =-
Test set: Average loss: 0.3296,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3230,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.3186,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.2996,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.3111,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2878,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.2886,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2779,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2857,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2690,                   Accuracy: 1827/2000.0 (91.35%)



Epoch 50 train accuracy: 90.31%, valid accuracy 91.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3084,                   Accuracy: 54519/60000 (90.86%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2966,                   Accuracy: 54799/60000 (91.33%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2905,                   Accuracy: 55023/60000 (91.71%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2919,                   Accuracy: 55032/60000 (91.72%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2923,                   Accuracy: 55021/60000 (91.70%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2903,                   Accuracy: 55097/60000 (91.83%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2880,                   Accuracy: 55089/60000 (91.82%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2885,                   Accuracy: 55027/60000 (91.71%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2760,                   Accuracy: 55105/60000 (91.84%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2922,                   Accuracy: 54849/60000 (91.42%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3076,                   Accuracy: 54422/60000 (90.70%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3234,                   Accuracy: 54096/60000 (90.16%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3505,                   Accuracy: 53545/60000 (89.24%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3687,                   Accuracy: 53211/60000 (88.68%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3823,                   Accuracy: 52865/60000 (88.11%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3908,                   Accuracy: 52598/60000 (87.66%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4005,                   Accuracy: 52371/60000 (87.29%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3930,                   Accuracy: 52325/60000 (87.21%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.4145,                   Accuracy: 52041/60000 (86.74%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.4269,                   Accuracy: 51740/60000 (86.23%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.4358,                   Accuracy: 51515/60000 (85.86%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4406,                   Accuracy: 51338/60000 (85.56%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4377,                   Accuracy: 51469/60000 (85.78%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4277,                   Accuracy: 51733/60000 (86.22%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4126,                   Accuracy: 52085/60000 (86.81%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3955,                   Accuracy: 52511/60000 (87.52%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3617,                   Accuracy: 53143/60000 (88.57%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3612,                   Accuracy: 53313/60000 (88.86%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3485,                   Accuracy: 53662/60000 (89.44%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3484,                   Accuracy: 53697/60000 (89.50%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3542,                   Accuracy: 53652/60000 (89.42%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3537,                   Accuracy: 53685/60000 (89.47%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3433,                   Accuracy: 53909/60000 (89.85%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3309,                   Accuracy: 54195/60000 (90.32%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3208,                   Accuracy: 54356/60000 (90.59%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2997,                   Accuracy: 54668/60000 (91.11%)
{0: tensor(90.8650), 10: tensor(91.3317), 20: tensor(91.7050), 30: tensor(91.7200), 40: tensor(91.7017), 50: tensor(91.8283), 60: tensor(91.8150), 70: tensor(91.7117), 80: tensor(91.8417), 90: tensor(91.4150), 100: tensor(90.7033), 110: tensor(90.1600), 120: tensor(89.2417), 130: tensor(88.6850), 140: tensor(88.1083), 150: tensor(87.6633), 160: tensor(87.2850), 170: tensor(87.2083), 180: tensor(86.7350), 190: tensor(86.2333), 200: tensor(85.8583), 210: tensor(85.5633), 220: tensor(85.7817), 230: tensor(86.2217), 240: tensor(86.8083), 250: tensor(87.5183), 260: tensor(88.5717), 270: tensor(88.8550), 280: tensor(89.4367), 290: tensor(89.4950), 300: tensor(89.4200), 310: tensor(89.4750), 320: tensor(89.8483), 330: tensor(90.3250), 340: tensor(90.5933), 350: tensor(91.1133)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=84, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.5276,                   Accuracy: 231/2000.0 (11.55%)



-= Testing valid =-
Test set: Average loss: 5.0543,                   Accuracy: 258/2000.0 (12.90%)



-= Testing valid =-
Test set: Average loss: 2.1733,                   Accuracy: 553/2000.0 (27.65%)



-= Testing valid =-
Test set: Average loss: 1.3905,                   Accuracy: 1047/2000.0 (52.35%)



-= Testing valid =-
Test set: Average loss: 1.6874,                   Accuracy: 812/2000.0 (40.60%)



-= Testing valid =-
Test set: Average loss: 1.0440,                   Accuracy: 1284/2000.0 (64.20%)



-= Testing valid =-
Test set: Average loss: 1.0657,                   Accuracy: 1258/2000.0 (62.90%)



-= Testing valid =-
Test set: Average loss: 1.4106,                   Accuracy: 905/2000.0 (45.25%)



-= Testing valid =-
Test set: Average loss: 0.8044,                   Accuracy: 1436/2000.0 (71.80%)



-= Testing valid =-
Test set: Average loss: 0.7725,                   Accuracy: 1477/2000.0 (73.85%)



Epoch 10 train accuracy: 75.38%, valid accuracy 73.85%
-= Testing valid =-
Test set: Average loss: 0.6277,                   Accuracy: 1556/2000.0 (77.80%)



-= Testing valid =-
Test set: Average loss: 0.7189,                   Accuracy: 1472/2000.0 (73.60%)



-= Testing valid =-
Test set: Average loss: 0.5699,                   Accuracy: 1615/2000.0 (80.75%)



-= Testing valid =-
Test set: Average loss: 0.7839,                   Accuracy: 1424/2000.0 (71.20%)



-= Testing valid =-
Test set: Average loss: 0.4175,                   Accuracy: 1729/2000.0 (86.45%)



-= Testing valid =-
Test set: Average loss: 0.3880,                   Accuracy: 1759/2000.0 (87.95%)



-= Testing valid =-
Test set: Average loss: 0.5725,                   Accuracy: 1581/2000.0 (79.05%)



-= Testing valid =-
Test set: Average loss: 0.5087,                   Accuracy: 1675/2000.0 (83.75%)



-= Testing valid =-
Test set: Average loss: 0.3134,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.7780,                   Accuracy: 1405/2000.0 (70.25%)



Epoch 20 train accuracy: 86.55%, valid accuracy 70.25%
-= Testing valid =-
Test set: Average loss: 0.4809,                   Accuracy: 1692/2000.0 (84.60%)



-= Testing valid =-
Test set: Average loss: 0.4704,                   Accuracy: 1669/2000.0 (83.45%)



-= Testing valid =-
Test set: Average loss: 0.5297,                   Accuracy: 1667/2000.0 (83.35%)



-= Testing valid =-
Test set: Average loss: 0.5208,                   Accuracy: 1642/2000.0 (82.10%)



-= Testing valid =-
Test set: Average loss: 0.4540,                   Accuracy: 1713/2000.0 (85.65%)



-= Testing valid =-
Test set: Average loss: 0.3420,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.4544,                   Accuracy: 1721/2000.0 (86.05%)



-= Testing valid =-
Test set: Average loss: 0.3531,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.4255,                   Accuracy: 1727/2000.0 (86.35%)



-= Testing valid =-
Test set: Average loss: 0.4647,                   Accuracy: 1704/2000.0 (85.20%)



Epoch 30 train accuracy: 90.01%, valid accuracy 85.20%
-= Testing valid =-
Test set: Average loss: 0.5226,                   Accuracy: 1647/2000.0 (82.35%)



-= Testing valid =-
Test set: Average loss: 0.3205,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.2682,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.3925,                   Accuracy: 1745/2000.0 (87.25%)



-= Testing valid =-
Test set: Average loss: 0.2964,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2946,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.3786,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.4023,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.3139,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.4109,                   Accuracy: 1731/2000.0 (86.55%)



Epoch 40 train accuracy: 90.26%, valid accuracy 86.55%
-= Testing valid =-
Test set: Average loss: 0.3430,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.3235,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.3228,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.3147,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.3185,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2934,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2838,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2873,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2882,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.3297,                   Accuracy: 1799/2000.0 (89.95%)



Epoch 50 train accuracy: 91.46%, valid accuracy 89.95%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2997,                   Accuracy: 54525/60000 (90.88%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3113,                   Accuracy: 54233/60000 (90.39%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3258,                   Accuracy: 53899/60000 (89.83%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3490,                   Accuracy: 53467/60000 (89.11%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3615,                   Accuracy: 53187/60000 (88.64%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3794,                   Accuracy: 52860/60000 (88.10%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3959,                   Accuracy: 52616/60000 (87.69%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3974,                   Accuracy: 52512/60000 (87.52%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3852,                   Accuracy: 52728/60000 (87.88%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3808,                   Accuracy: 52952/60000 (88.25%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3987,                   Accuracy: 52412/60000 (87.35%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.4028,                   Accuracy: 52582/60000 (87.64%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4050,                   Accuracy: 52500/60000 (87.50%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3939,                   Accuracy: 52700/60000 (87.83%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3849,                   Accuracy: 52871/60000 (88.12%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3750,                   Accuracy: 52959/60000 (88.26%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3682,                   Accuracy: 53013/60000 (88.36%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3574,                   Accuracy: 53253/60000 (88.75%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3561,                   Accuracy: 53240/60000 (88.73%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3823,                   Accuracy: 52704/60000 (87.84%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3968,                   Accuracy: 52541/60000 (87.57%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4185,                   Accuracy: 52195/60000 (86.99%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4296,                   Accuracy: 51978/60000 (86.63%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4321,                   Accuracy: 51962/60000 (86.60%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4300,                   Accuracy: 52109/60000 (86.85%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.4122,                   Accuracy: 52505/60000 (87.51%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3793,                   Accuracy: 53099/60000 (88.50%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3556,                   Accuracy: 53566/60000 (89.28%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3654,                   Accuracy: 53420/60000 (89.03%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3657,                   Accuracy: 53404/60000 (89.01%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3668,                   Accuracy: 53351/60000 (88.92%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3571,                   Accuracy: 53513/60000 (89.19%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3417,                   Accuracy: 53806/60000 (89.68%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3248,                   Accuracy: 54119/60000 (90.20%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3131,                   Accuracy: 54341/60000 (90.57%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3060,                   Accuracy: 54402/60000 (90.67%)
{0: tensor(90.8750), 10: tensor(90.3883), 20: tensor(89.8317), 30: tensor(89.1117), 40: tensor(88.6450), 50: tensor(88.1000), 60: tensor(87.6933), 70: tensor(87.5200), 80: tensor(87.8800), 90: tensor(88.2533), 100: tensor(87.3533), 110: tensor(87.6367), 120: tensor(87.5000), 130: tensor(87.8333), 140: tensor(88.1183), 150: tensor(88.2650), 160: tensor(88.3550), 170: tensor(88.7550), 180: tensor(88.7333), 190: tensor(87.8400), 200: tensor(87.5683), 210: tensor(86.9917), 220: tensor(86.6300), 230: tensor(86.6033), 240: tensor(86.8483), 250: tensor(87.5083), 260: tensor(88.4983), 270: tensor(89.2767), 280: tensor(89.0333), 290: tensor(89.0067), 300: tensor(88.9183), 310: tensor(89.1883), 320: tensor(89.6767), 330: tensor(90.1983), 340: tensor(90.5683), 350: tensor(90.6700)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=85, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.2213,                   Accuracy: 229/2000.0 (11.45%)



-= Testing valid =-
Test set: Average loss: 1.5934,                   Accuracy: 781/2000.0 (39.05%)



-= Testing valid =-
Test set: Average loss: 2.4932,                   Accuracy: 570/2000.0 (28.50%)



-= Testing valid =-
Test set: Average loss: 1.3409,                   Accuracy: 1120/2000.0 (56.00%)



-= Testing valid =-
Test set: Average loss: 1.3629,                   Accuracy: 1086/2000.0 (54.30%)



-= Testing valid =-
Test set: Average loss: 1.8278,                   Accuracy: 781/2000.0 (39.05%)



-= Testing valid =-
Test set: Average loss: 1.8752,                   Accuracy: 780/2000.0 (39.00%)



-= Testing valid =-
Test set: Average loss: 1.9153,                   Accuracy: 742/2000.0 (37.10%)



-= Testing valid =-
Test set: Average loss: 0.9264,                   Accuracy: 1312/2000.0 (65.60%)



-= Testing valid =-
Test set: Average loss: 1.7368,                   Accuracy: 991/2000.0 (49.55%)



Epoch 10 train accuracy: 71.84%, valid accuracy 49.55%
-= Testing valid =-
Test set: Average loss: 0.9870,                   Accuracy: 1321/2000.0 (66.05%)



-= Testing valid =-
Test set: Average loss: 0.6394,                   Accuracy: 1541/2000.0 (77.05%)



-= Testing valid =-
Test set: Average loss: 0.7089,                   Accuracy: 1508/2000.0 (75.40%)



-= Testing valid =-
Test set: Average loss: 0.6418,                   Accuracy: 1564/2000.0 (78.20%)



-= Testing valid =-
Test set: Average loss: 0.6069,                   Accuracy: 1602/2000.0 (80.10%)



-= Testing valid =-
Test set: Average loss: 0.6691,                   Accuracy: 1520/2000.0 (76.00%)



-= Testing valid =-
Test set: Average loss: 0.4635,                   Accuracy: 1718/2000.0 (85.90%)



-= Testing valid =-
Test set: Average loss: 0.5562,                   Accuracy: 1648/2000.0 (82.40%)



-= Testing valid =-
Test set: Average loss: 0.7123,                   Accuracy: 1475/2000.0 (73.75%)



-= Testing valid =-
Test set: Average loss: 0.6273,                   Accuracy: 1536/2000.0 (76.80%)



Epoch 20 train accuracy: 85.60%, valid accuracy 76.80%
-= Testing valid =-
Test set: Average loss: 0.3997,                   Accuracy: 1732/2000.0 (86.60%)



-= Testing valid =-
Test set: Average loss: 0.3719,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.3786,                   Accuracy: 1764/2000.0 (88.20%)



-= Testing valid =-
Test set: Average loss: 0.4545,                   Accuracy: 1654/2000.0 (82.70%)



-= Testing valid =-
Test set: Average loss: 0.3763,                   Accuracy: 1748/2000.0 (87.40%)



-= Testing valid =-
Test set: Average loss: 0.3819,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.3545,                   Accuracy: 1780/2000.0 (89.00%)



-= Testing valid =-
Test set: Average loss: 0.3433,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.4078,                   Accuracy: 1723/2000.0 (86.15%)



-= Testing valid =-
Test set: Average loss: 0.3981,                   Accuracy: 1708/2000.0 (85.40%)



Epoch 30 train accuracy: 88.72%, valid accuracy 85.40%
-= Testing valid =-
Test set: Average loss: 0.3735,                   Accuracy: 1752/2000.0 (87.60%)



-= Testing valid =-
Test set: Average loss: 0.3332,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.3482,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.2956,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.3431,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.3073,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.3822,                   Accuracy: 1747/2000.0 (87.35%)



-= Testing valid =-
Test set: Average loss: 0.2891,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.3140,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.3285,                   Accuracy: 1768/2000.0 (88.40%)



Epoch 40 train accuracy: 89.74%, valid accuracy 88.40%
-= Testing valid =-
Test set: Average loss: 0.2803,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2750,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.3088,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.2957,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.3196,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.2819,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2843,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.2734,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2986,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2687,                   Accuracy: 1833/2000.0 (91.65%)



Epoch 50 train accuracy: 90.71%, valid accuracy 91.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2933,                   Accuracy: 54746/60000 (91.24%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2897,                   Accuracy: 54818/60000 (91.36%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3088,                   Accuracy: 54490/60000 (90.82%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3135,                   Accuracy: 54468/60000 (90.78%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3158,                   Accuracy: 54328/60000 (90.55%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3178,                   Accuracy: 54250/60000 (90.42%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3177,                   Accuracy: 54112/60000 (90.19%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3205,                   Accuracy: 53969/60000 (89.95%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3033,                   Accuracy: 54175/60000 (90.29%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3176,                   Accuracy: 53937/60000 (89.89%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3239,                   Accuracy: 53876/60000 (89.79%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3532,                   Accuracy: 53211/60000 (88.68%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3801,                   Accuracy: 52636/60000 (87.73%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3912,                   Accuracy: 52354/60000 (87.26%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3948,                   Accuracy: 52276/60000 (87.13%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3841,                   Accuracy: 52516/60000 (87.53%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3713,                   Accuracy: 52864/60000 (88.11%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3306,                   Accuracy: 53713/60000 (89.52%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3285,                   Accuracy: 53813/60000 (89.69%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3247,                   Accuracy: 53841/60000 (89.74%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3305,                   Accuracy: 53931/60000 (89.89%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3320,                   Accuracy: 53980/60000 (89.97%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3356,                   Accuracy: 53942/60000 (89.90%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3346,                   Accuracy: 53913/60000 (89.86%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3224,                   Accuracy: 54174/60000 (90.29%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3141,                   Accuracy: 54287/60000 (90.48%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2808,                   Accuracy: 54859/60000 (91.43%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2870,                   Accuracy: 54753/60000 (91.25%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2912,                   Accuracy: 54700/60000 (91.17%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3047,                   Accuracy: 54459/60000 (90.76%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3144,                   Accuracy: 54305/60000 (90.51%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3186,                   Accuracy: 54323/60000 (90.54%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3207,                   Accuracy: 54321/60000 (90.54%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3180,                   Accuracy: 54355/60000 (90.59%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3158,                   Accuracy: 54388/60000 (90.65%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2959,                   Accuracy: 54651/60000 (91.08%)
{0: tensor(91.2433), 10: tensor(91.3633), 20: tensor(90.8167), 30: tensor(90.7800), 40: tensor(90.5467), 50: tensor(90.4167), 60: tensor(90.1867), 70: tensor(89.9483), 80: tensor(90.2917), 90: tensor(89.8950), 100: tensor(89.7933), 110: tensor(88.6850), 120: tensor(87.7267), 130: tensor(87.2567), 140: tensor(87.1267), 150: tensor(87.5267), 160: tensor(88.1067), 170: tensor(89.5217), 180: tensor(89.6883), 190: tensor(89.7350), 200: tensor(89.8850), 210: tensor(89.9667), 220: tensor(89.9033), 230: tensor(89.8550), 240: tensor(90.2900), 250: tensor(90.4783), 260: tensor(91.4317), 270: tensor(91.2550), 280: tensor(91.1667), 290: tensor(90.7650), 300: tensor(90.5083), 310: tensor(90.5383), 320: tensor(90.5350), 330: tensor(90.5917), 340: tensor(90.6467), 350: tensor(91.0850)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=86, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.0749,                   Accuracy: 456/2000.0 (22.80%)



-= Testing valid =-
Test set: Average loss: 2.4788,                   Accuracy: 403/2000.0 (20.15%)



-= Testing valid =-
Test set: Average loss: 2.3933,                   Accuracy: 586/2000.0 (29.30%)



-= Testing valid =-
Test set: Average loss: 1.4288,                   Accuracy: 975/2000.0 (48.75%)



-= Testing valid =-
Test set: Average loss: 1.3742,                   Accuracy: 1075/2000.0 (53.75%)



-= Testing valid =-
Test set: Average loss: 1.2045,                   Accuracy: 1113/2000.0 (55.65%)



-= Testing valid =-
Test set: Average loss: 0.9530,                   Accuracy: 1372/2000.0 (68.60%)



-= Testing valid =-
Test set: Average loss: 0.8218,                   Accuracy: 1431/2000.0 (71.55%)



-= Testing valid =-
Test set: Average loss: 0.7446,                   Accuracy: 1418/2000.0 (70.90%)



-= Testing valid =-
Test set: Average loss: 0.7224,                   Accuracy: 1507/2000.0 (75.35%)



Epoch 10 train accuracy: 74.80%, valid accuracy 75.35%
-= Testing valid =-
Test set: Average loss: 0.5332,                   Accuracy: 1650/2000.0 (82.50%)



-= Testing valid =-
Test set: Average loss: 0.5060,                   Accuracy: 1694/2000.0 (84.70%)



-= Testing valid =-
Test set: Average loss: 0.4139,                   Accuracy: 1721/2000.0 (86.05%)



-= Testing valid =-
Test set: Average loss: 0.6492,                   Accuracy: 1543/2000.0 (77.15%)



-= Testing valid =-
Test set: Average loss: 0.5182,                   Accuracy: 1651/2000.0 (82.55%)



-= Testing valid =-
Test set: Average loss: 0.3910,                   Accuracy: 1759/2000.0 (87.95%)



-= Testing valid =-
Test set: Average loss: 0.3449,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.4662,                   Accuracy: 1673/2000.0 (83.65%)



-= Testing valid =-
Test set: Average loss: 0.3128,                   Accuracy: 1793/2000.0 (89.65%)



-= Testing valid =-
Test set: Average loss: 0.2880,                   Accuracy: 1824/2000.0 (91.20%)



Epoch 20 train accuracy: 86.64%, valid accuracy 91.20%
-= Testing valid =-
Test set: Average loss: 0.2740,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2844,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.3180,                   Accuracy: 1805/2000.0 (90.25%)



-= Testing valid =-
Test set: Average loss: 0.2776,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2511,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.3384,                   Accuracy: 1759/2000.0 (87.95%)



-= Testing valid =-
Test set: Average loss: 0.3521,                   Accuracy: 1760/2000.0 (88.00%)



-= Testing valid =-
Test set: Average loss: 0.2748,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.2810,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2461,                   Accuracy: 1841/2000.0 (92.05%)



Epoch 30 train accuracy: 89.40%, valid accuracy 92.05%
-= Testing valid =-
Test set: Average loss: 0.2429,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2330,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2068,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.2268,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.2293,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.1898,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2070,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2450,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.1857,                   Accuracy: 1884/2000.0 (94.20%)



-= Testing valid =-
Test set: Average loss: 0.1872,                   Accuracy: 1893/2000.0 (94.65%)



Epoch 40 train accuracy: 91.18%, valid accuracy 94.65%
-= Testing valid =-
Test set: Average loss: 0.2137,                   Accuracy: 1872/2000.0 (93.60%)



-= Testing valid =-
Test set: Average loss: 0.2078,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2167,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.1950,                   Accuracy: 1881/2000.0 (94.05%)



-= Testing valid =-
Test set: Average loss: 0.1925,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.2104,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2164,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2052,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.2074,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.2250,                   Accuracy: 1860/2000.0 (93.00%)



Epoch 50 train accuracy: 91.16%, valid accuracy 93.00%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2223,                   Accuracy: 56213/60000 (93.69%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2304,                   Accuracy: 56110/60000 (93.52%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2332,                   Accuracy: 55993/60000 (93.32%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2476,                   Accuracy: 55825/60000 (93.04%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2607,                   Accuracy: 55648/60000 (92.75%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2750,                   Accuracy: 55349/60000 (92.25%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2902,                   Accuracy: 55018/60000 (91.70%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2956,                   Accuracy: 54839/60000 (91.40%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2865,                   Accuracy: 54884/60000 (91.47%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2902,                   Accuracy: 54743/60000 (91.24%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2892,                   Accuracy: 54775/60000 (91.29%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3066,                   Accuracy: 54290/60000 (90.48%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3177,                   Accuracy: 54008/60000 (90.01%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3326,                   Accuracy: 53660/60000 (89.43%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3479,                   Accuracy: 53334/60000 (88.89%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3637,                   Accuracy: 52932/60000 (88.22%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3644,                   Accuracy: 52783/60000 (87.97%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3580,                   Accuracy: 52789/60000 (87.98%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3637,                   Accuracy: 52486/60000 (87.48%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3845,                   Accuracy: 52085/60000 (86.81%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3913,                   Accuracy: 51944/60000 (86.57%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4029,                   Accuracy: 51798/60000 (86.33%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3978,                   Accuracy: 52035/60000 (86.72%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3842,                   Accuracy: 52475/60000 (87.46%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3619,                   Accuracy: 53067/60000 (88.44%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3412,                   Accuracy: 53487/60000 (89.14%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3131,                   Accuracy: 54229/60000 (90.38%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2991,                   Accuracy: 54430/60000 (90.72%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2972,                   Accuracy: 54481/60000 (90.80%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3003,                   Accuracy: 54476/60000 (90.79%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3002,                   Accuracy: 54496/60000 (90.83%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3020,                   Accuracy: 54547/60000 (90.91%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2897,                   Accuracy: 54816/60000 (91.36%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2779,                   Accuracy: 55129/60000 (91.88%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2587,                   Accuracy: 55422/60000 (92.37%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2394,                   Accuracy: 55841/60000 (93.07%)
{0: tensor(93.6883), 10: tensor(93.5167), 20: tensor(93.3217), 30: tensor(93.0417), 40: tensor(92.7467), 50: tensor(92.2483), 60: tensor(91.6967), 70: tensor(91.3983), 80: tensor(91.4733), 90: tensor(91.2383), 100: tensor(91.2917), 110: tensor(90.4833), 120: tensor(90.0133), 130: tensor(89.4333), 140: tensor(88.8900), 150: tensor(88.2200), 160: tensor(87.9717), 170: tensor(87.9817), 180: tensor(87.4767), 190: tensor(86.8083), 200: tensor(86.5733), 210: tensor(86.3300), 220: tensor(86.7250), 230: tensor(87.4583), 240: tensor(88.4450), 250: tensor(89.1450), 260: tensor(90.3817), 270: tensor(90.7167), 280: tensor(90.8017), 290: tensor(90.7933), 300: tensor(90.8267), 310: tensor(90.9117), 320: tensor(91.3600), 330: tensor(91.8817), 340: tensor(92.3700), 350: tensor(93.0683)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=87, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 6.4514,                   Accuracy: 244/2000.0 (12.20%)



-= Testing valid =-
Test set: Average loss: 2.1219,                   Accuracy: 533/2000.0 (26.65%)



-= Testing valid =-
Test set: Average loss: 2.5755,                   Accuracy: 473/2000.0 (23.65%)



-= Testing valid =-
Test set: Average loss: 1.9357,                   Accuracy: 557/2000.0 (27.85%)



-= Testing valid =-
Test set: Average loss: 1.1407,                   Accuracy: 1192/2000.0 (59.60%)



-= Testing valid =-
Test set: Average loss: 1.1074,                   Accuracy: 1230/2000.0 (61.50%)



-= Testing valid =-
Test set: Average loss: 1.5905,                   Accuracy: 940/2000.0 (47.00%)



-= Testing valid =-
Test set: Average loss: 0.9338,                   Accuracy: 1316/2000.0 (65.80%)



-= Testing valid =-
Test set: Average loss: 0.8193,                   Accuracy: 1467/2000.0 (73.35%)



-= Testing valid =-
Test set: Average loss: 0.9224,                   Accuracy: 1347/2000.0 (67.35%)



Epoch 10 train accuracy: 74.99%, valid accuracy 67.35%
-= Testing valid =-
Test set: Average loss: 0.6481,                   Accuracy: 1571/2000.0 (78.55%)



-= Testing valid =-
Test set: Average loss: 0.5148,                   Accuracy: 1695/2000.0 (84.75%)



-= Testing valid =-
Test set: Average loss: 0.5795,                   Accuracy: 1624/2000.0 (81.20%)



-= Testing valid =-
Test set: Average loss: 0.4670,                   Accuracy: 1703/2000.0 (85.15%)



-= Testing valid =-
Test set: Average loss: 0.3199,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.3603,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.3706,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.4790,                   Accuracy: 1656/2000.0 (82.80%)



-= Testing valid =-
Test set: Average loss: 0.2640,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.4960,                   Accuracy: 1672/2000.0 (83.60%)



Epoch 20 train accuracy: 86.44%, valid accuracy 83.60%
-= Testing valid =-
Test set: Average loss: 0.3330,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.3274,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.2881,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2828,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.3217,                   Accuracy: 1791/2000.0 (89.55%)



-= Testing valid =-
Test set: Average loss: 0.3790,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.3469,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.3758,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.2593,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2714,                   Accuracy: 1832/2000.0 (91.60%)



Epoch 30 train accuracy: 89.45%, valid accuracy 91.60%
-= Testing valid =-
Test set: Average loss: 0.2911,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2589,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2561,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2360,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.2145,                   Accuracy: 1878/2000.0 (93.90%)



-= Testing valid =-
Test set: Average loss: 0.2403,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.2444,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.2331,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.2270,                   Accuracy: 1871/2000.0 (93.55%)



-= Testing valid =-
Test set: Average loss: 0.2522,                   Accuracy: 1852/2000.0 (92.60%)



Epoch 40 train accuracy: 90.32%, valid accuracy 92.60%
-= Testing valid =-
Test set: Average loss: 0.2501,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2557,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2624,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2426,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2545,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.2557,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2265,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2293,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.2365,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2279,                   Accuracy: 1871/2000.0 (93.55%)



Epoch 50 train accuracy: 91.20%, valid accuracy 93.55%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2436,                   Accuracy: 55748/60000 (92.91%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2364,                   Accuracy: 55878/60000 (93.13%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2518,                   Accuracy: 55632/60000 (92.72%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2639,                   Accuracy: 55365/60000 (92.28%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2728,                   Accuracy: 55206/60000 (92.01%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2789,                   Accuracy: 55057/60000 (91.76%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2845,                   Accuracy: 54950/60000 (91.58%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2808,                   Accuracy: 54970/60000 (91.62%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2671,                   Accuracy: 55165/60000 (91.94%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2847,                   Accuracy: 54777/60000 (91.29%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2793,                   Accuracy: 54927/60000 (91.54%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2918,                   Accuracy: 54697/60000 (91.16%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3105,                   Accuracy: 54261/60000 (90.43%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3182,                   Accuracy: 53969/60000 (89.95%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3228,                   Accuracy: 53772/60000 (89.62%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3262,                   Accuracy: 53643/60000 (89.40%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3230,                   Accuracy: 53594/60000 (89.32%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3132,                   Accuracy: 53771/60000 (89.62%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3289,                   Accuracy: 53406/60000 (89.01%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3399,                   Accuracy: 53265/60000 (88.78%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3497,                   Accuracy: 53079/60000 (88.46%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3703,                   Accuracy: 52570/60000 (87.62%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3732,                   Accuracy: 52745/60000 (87.91%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3777,                   Accuracy: 52739/60000 (87.90%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3760,                   Accuracy: 52759/60000 (87.93%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3660,                   Accuracy: 53020/60000 (88.37%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3474,                   Accuracy: 53432/60000 (89.05%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3481,                   Accuracy: 53449/60000 (89.08%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3372,                   Accuracy: 53564/60000 (89.27%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3411,                   Accuracy: 53447/60000 (89.08%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3372,                   Accuracy: 53507/60000 (89.18%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3182,                   Accuracy: 53964/60000 (89.94%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3024,                   Accuracy: 54382/60000 (90.64%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2797,                   Accuracy: 54970/60000 (91.62%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2593,                   Accuracy: 55355/60000 (92.26%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2400,                   Accuracy: 55747/60000 (92.91%)
{0: tensor(92.9133), 10: tensor(93.1300), 20: tensor(92.7200), 30: tensor(92.2750), 40: tensor(92.0100), 50: tensor(91.7617), 60: tensor(91.5833), 70: tensor(91.6167), 80: tensor(91.9417), 90: tensor(91.2950), 100: tensor(91.5450), 110: tensor(91.1617), 120: tensor(90.4350), 130: tensor(89.9483), 140: tensor(89.6200), 150: tensor(89.4050), 160: tensor(89.3233), 170: tensor(89.6183), 180: tensor(89.0100), 190: tensor(88.7750), 200: tensor(88.4650), 210: tensor(87.6167), 220: tensor(87.9083), 230: tensor(87.8983), 240: tensor(87.9317), 250: tensor(88.3667), 260: tensor(89.0533), 270: tensor(89.0817), 280: tensor(89.2733), 290: tensor(89.0783), 300: tensor(89.1783), 310: tensor(89.9400), 320: tensor(90.6367), 330: tensor(91.6167), 340: tensor(92.2583), 350: tensor(92.9117)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=88, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1589,                   Accuracy: 430/2000.0 (21.50%)



-= Testing valid =-
Test set: Average loss: 4.6730,                   Accuracy: 276/2000.0 (13.80%)



-= Testing valid =-
Test set: Average loss: 1.9048,                   Accuracy: 687/2000.0 (34.35%)



-= Testing valid =-
Test set: Average loss: 2.1997,                   Accuracy: 663/2000.0 (33.15%)



-= Testing valid =-
Test set: Average loss: 1.5633,                   Accuracy: 859/2000.0 (42.95%)



-= Testing valid =-
Test set: Average loss: 1.2182,                   Accuracy: 1143/2000.0 (57.15%)



-= Testing valid =-
Test set: Average loss: 1.5349,                   Accuracy: 969/2000.0 (48.45%)



-= Testing valid =-
Test set: Average loss: 1.2116,                   Accuracy: 1213/2000.0 (60.65%)



-= Testing valid =-
Test set: Average loss: 1.0880,                   Accuracy: 1316/2000.0 (65.80%)



-= Testing valid =-
Test set: Average loss: 0.9439,                   Accuracy: 1333/2000.0 (66.65%)



Epoch 10 train accuracy: 71.85%, valid accuracy 66.65%
-= Testing valid =-
Test set: Average loss: 0.6815,                   Accuracy: 1590/2000.0 (79.50%)



-= Testing valid =-
Test set: Average loss: 0.5457,                   Accuracy: 1667/2000.0 (83.35%)



-= Testing valid =-
Test set: Average loss: 0.5678,                   Accuracy: 1651/2000.0 (82.55%)



-= Testing valid =-
Test set: Average loss: 0.6740,                   Accuracy: 1557/2000.0 (77.85%)



-= Testing valid =-
Test set: Average loss: 0.6967,                   Accuracy: 1537/2000.0 (76.85%)



-= Testing valid =-
Test set: Average loss: 0.5606,                   Accuracy: 1661/2000.0 (83.05%)



-= Testing valid =-
Test set: Average loss: 0.5241,                   Accuracy: 1689/2000.0 (84.45%)



-= Testing valid =-
Test set: Average loss: 0.3840,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.4592,                   Accuracy: 1691/2000.0 (84.55%)



-= Testing valid =-
Test set: Average loss: 0.6286,                   Accuracy: 1592/2000.0 (79.60%)



Epoch 20 train accuracy: 86.38%, valid accuracy 79.60%
-= Testing valid =-
Test set: Average loss: 0.3997,                   Accuracy: 1742/2000.0 (87.10%)



-= Testing valid =-
Test set: Average loss: 0.3519,                   Accuracy: 1753/2000.0 (87.65%)



-= Testing valid =-
Test set: Average loss: 0.4580,                   Accuracy: 1681/2000.0 (84.05%)



-= Testing valid =-
Test set: Average loss: 0.3429,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.3433,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.3426,                   Accuracy: 1769/2000.0 (88.45%)



-= Testing valid =-
Test set: Average loss: 0.3343,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.3314,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.4379,                   Accuracy: 1684/2000.0 (84.20%)



-= Testing valid =-
Test set: Average loss: 0.3073,                   Accuracy: 1791/2000.0 (89.55%)



Epoch 30 train accuracy: 88.20%, valid accuracy 89.55%
-= Testing valid =-
Test set: Average loss: 0.3081,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.3098,                   Accuracy: 1789/2000.0 (89.45%)



-= Testing valid =-
Test set: Average loss: 0.3405,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.3432,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.2772,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.3038,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2713,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.3336,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.3276,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.3054,                   Accuracy: 1797/2000.0 (89.85%)



Epoch 40 train accuracy: 89.93%, valid accuracy 89.85%
-= Testing valid =-
Test set: Average loss: 0.2932,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2476,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2860,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.2607,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2758,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2533,                   Accuracy: 1833/2000.0 (91.65%)



-= Testing valid =-
Test set: Average loss: 0.2789,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.2943,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.3047,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.3069,                   Accuracy: 1787/2000.0 (89.35%)



Epoch 50 train accuracy: 90.31%, valid accuracy 89.35%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2658,                   Accuracy: 55148/60000 (91.91%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2777,                   Accuracy: 54820/60000 (91.37%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2909,                   Accuracy: 54546/60000 (90.91%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2982,                   Accuracy: 54386/60000 (90.64%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3046,                   Accuracy: 54242/60000 (90.40%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3127,                   Accuracy: 54123/60000 (90.21%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3167,                   Accuracy: 54038/60000 (90.06%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3226,                   Accuracy: 53921/60000 (89.87%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3206,                   Accuracy: 53906/60000 (89.84%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3449,                   Accuracy: 53384/60000 (88.97%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3580,                   Accuracy: 53102/60000 (88.50%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3694,                   Accuracy: 52787/60000 (87.98%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3690,                   Accuracy: 52656/60000 (87.76%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3708,                   Accuracy: 52515/60000 (87.53%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3782,                   Accuracy: 52204/60000 (87.01%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3789,                   Accuracy: 52174/60000 (86.96%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3780,                   Accuracy: 52238/60000 (87.06%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3652,                   Accuracy: 52461/60000 (87.43%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3471,                   Accuracy: 53033/60000 (88.39%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3505,                   Accuracy: 53069/60000 (88.45%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3473,                   Accuracy: 53229/60000 (88.71%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3403,                   Accuracy: 53341/60000 (88.90%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3329,                   Accuracy: 53505/60000 (89.18%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3322,                   Accuracy: 53581/60000 (89.30%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3288,                   Accuracy: 53651/60000 (89.42%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3236,                   Accuracy: 53865/60000 (89.78%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3098,                   Accuracy: 54058/60000 (90.10%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3033,                   Accuracy: 54319/60000 (90.53%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3071,                   Accuracy: 54169/60000 (90.28%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2975,                   Accuracy: 54560/60000 (90.93%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2923,                   Accuracy: 54689/60000 (91.15%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2834,                   Accuracy: 54882/60000 (91.47%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2765,                   Accuracy: 55046/60000 (91.74%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2691,                   Accuracy: 55173/60000 (91.96%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2663,                   Accuracy: 55195/60000 (91.99%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2518,                   Accuracy: 55451/60000 (92.42%)
{0: tensor(91.9133), 10: tensor(91.3667), 20: tensor(90.9100), 30: tensor(90.6433), 40: tensor(90.4033), 50: tensor(90.2050), 60: tensor(90.0633), 70: tensor(89.8683), 80: tensor(89.8433), 90: tensor(88.9733), 100: tensor(88.5033), 110: tensor(87.9783), 120: tensor(87.7600), 130: tensor(87.5250), 140: tensor(87.0067), 150: tensor(86.9567), 160: tensor(87.0633), 170: tensor(87.4350), 180: tensor(88.3883), 190: tensor(88.4483), 200: tensor(88.7150), 210: tensor(88.9017), 220: tensor(89.1750), 230: tensor(89.3017), 240: tensor(89.4183), 250: tensor(89.7750), 260: tensor(90.0967), 270: tensor(90.5317), 280: tensor(90.2817), 290: tensor(90.9333), 300: tensor(91.1483), 310: tensor(91.4700), 320: tensor(91.7433), 330: tensor(91.9550), 340: tensor(91.9917), 350: tensor(92.4183)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=89, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.2306,                   Accuracy: 227/2000.0 (11.35%)



-= Testing valid =-
Test set: Average loss: 3.2048,                   Accuracy: 391/2000.0 (19.55%)



-= Testing valid =-
Test set: Average loss: 3.5805,                   Accuracy: 284/2000.0 (14.20%)



-= Testing valid =-
Test set: Average loss: 1.4676,                   Accuracy: 891/2000.0 (44.55%)



-= Testing valid =-
Test set: Average loss: 1.7167,                   Accuracy: 842/2000.0 (42.10%)



-= Testing valid =-
Test set: Average loss: 3.8001,                   Accuracy: 377/2000.0 (18.85%)



-= Testing valid =-
Test set: Average loss: 1.2491,                   Accuracy: 1075/2000.0 (53.75%)



-= Testing valid =-
Test set: Average loss: 1.2079,                   Accuracy: 1046/2000.0 (52.30%)



-= Testing valid =-
Test set: Average loss: 0.8313,                   Accuracy: 1370/2000.0 (68.50%)



-= Testing valid =-
Test set: Average loss: 0.7967,                   Accuracy: 1448/2000.0 (72.40%)



Epoch 10 train accuracy: 68.25%, valid accuracy 72.40%
-= Testing valid =-
Test set: Average loss: 1.1940,                   Accuracy: 1032/2000.0 (51.60%)



-= Testing valid =-
Test set: Average loss: 1.0489,                   Accuracy: 1214/2000.0 (60.70%)



-= Testing valid =-
Test set: Average loss: 0.7509,                   Accuracy: 1489/2000.0 (74.45%)



-= Testing valid =-
Test set: Average loss: 1.2883,                   Accuracy: 1026/2000.0 (51.30%)



-= Testing valid =-
Test set: Average loss: 0.5248,                   Accuracy: 1643/2000.0 (82.15%)



-= Testing valid =-
Test set: Average loss: 0.6448,                   Accuracy: 1555/2000.0 (77.75%)



-= Testing valid =-
Test set: Average loss: 0.3531,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.5606,                   Accuracy: 1598/2000.0 (79.90%)



-= Testing valid =-
Test set: Average loss: 0.4055,                   Accuracy: 1720/2000.0 (86.00%)



-= Testing valid =-
Test set: Average loss: 0.5044,                   Accuracy: 1673/2000.0 (83.65%)



Epoch 20 train accuracy: 84.82%, valid accuracy 83.65%
-= Testing valid =-
Test set: Average loss: 0.3907,                   Accuracy: 1743/2000.0 (87.15%)



-= Testing valid =-
Test set: Average loss: 0.3316,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.3531,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.3200,                   Accuracy: 1777/2000.0 (88.85%)



-= Testing valid =-
Test set: Average loss: 0.3662,                   Accuracy: 1747/2000.0 (87.35%)



-= Testing valid =-
Test set: Average loss: 0.3650,                   Accuracy: 1749/2000.0 (87.45%)



-= Testing valid =-
Test set: Average loss: 0.3044,                   Accuracy: 1792/2000.0 (89.60%)



-= Testing valid =-
Test set: Average loss: 0.2995,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.3400,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.3252,                   Accuracy: 1761/2000.0 (88.05%)



Epoch 30 train accuracy: 88.07%, valid accuracy 88.05%
-= Testing valid =-
Test set: Average loss: 0.3215,                   Accuracy: 1767/2000.0 (88.35%)



-= Testing valid =-
Test set: Average loss: 0.2274,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2852,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.2753,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2532,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.2347,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2197,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2963,                   Accuracy: 1782/2000.0 (89.10%)



-= Testing valid =-
Test set: Average loss: 0.2596,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2904,                   Accuracy: 1787/2000.0 (89.35%)



Epoch 40 train accuracy: 89.82%, valid accuracy 89.35%
-= Testing valid =-
Test set: Average loss: 0.2569,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2565,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.3059,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3066,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.2475,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2656,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.2766,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2511,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2634,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2388,                   Accuracy: 1833/2000.0 (91.65%)



Epoch 50 train accuracy: 90.85%, valid accuracy 91.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2750,                   Accuracy: 55016/60000 (91.69%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2793,                   Accuracy: 54950/60000 (91.58%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3035,                   Accuracy: 54486/60000 (90.81%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3330,                   Accuracy: 54074/60000 (90.12%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3400,                   Accuracy: 53943/60000 (89.90%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3461,                   Accuracy: 53893/60000 (89.82%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3477,                   Accuracy: 53782/60000 (89.64%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3434,                   Accuracy: 53763/60000 (89.61%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3226,                   Accuracy: 54046/60000 (90.08%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3328,                   Accuracy: 53823/60000 (89.71%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3331,                   Accuracy: 53762/60000 (89.60%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3583,                   Accuracy: 53144/60000 (88.57%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3747,                   Accuracy: 52921/60000 (88.20%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3666,                   Accuracy: 53105/60000 (88.51%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3561,                   Accuracy: 53400/60000 (89.00%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3508,                   Accuracy: 53441/60000 (89.07%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3428,                   Accuracy: 53506/60000 (89.18%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3172,                   Accuracy: 53886/60000 (89.81%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3299,                   Accuracy: 53694/60000 (89.49%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3115,                   Accuracy: 54084/60000 (90.14%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3149,                   Accuracy: 54209/60000 (90.35%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3247,                   Accuracy: 54080/60000 (90.13%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3166,                   Accuracy: 54323/60000 (90.54%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3082,                   Accuracy: 54609/60000 (91.01%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3041,                   Accuracy: 54669/60000 (91.11%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3118,                   Accuracy: 54464/60000 (90.77%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2981,                   Accuracy: 54676/60000 (91.13%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3106,                   Accuracy: 54391/60000 (90.65%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3123,                   Accuracy: 54275/60000 (90.46%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3168,                   Accuracy: 54262/60000 (90.44%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3271,                   Accuracy: 54161/60000 (90.27%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3046,                   Accuracy: 54605/60000 (91.01%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2849,                   Accuracy: 54984/60000 (91.64%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2779,                   Accuracy: 55109/60000 (91.85%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2658,                   Accuracy: 55352/60000 (92.25%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2566,                   Accuracy: 55329/60000 (92.21%)
{0: tensor(91.6933), 10: tensor(91.5833), 20: tensor(90.8100), 30: tensor(90.1233), 40: tensor(89.9050), 50: tensor(89.8217), 60: tensor(89.6367), 70: tensor(89.6050), 80: tensor(90.0767), 90: tensor(89.7050), 100: tensor(89.6033), 110: tensor(88.5733), 120: tensor(88.2017), 130: tensor(88.5083), 140: tensor(89.), 150: tensor(89.0683), 160: tensor(89.1767), 170: tensor(89.8100), 180: tensor(89.4900), 190: tensor(90.1400), 200: tensor(90.3483), 210: tensor(90.1333), 220: tensor(90.5383), 230: tensor(91.0150), 240: tensor(91.1150), 250: tensor(90.7733), 260: tensor(91.1267), 270: tensor(90.6517), 280: tensor(90.4583), 290: tensor(90.4367), 300: tensor(90.2683), 310: tensor(91.0083), 320: tensor(91.6400), 330: tensor(91.8483), 340: tensor(92.2533), 350: tensor(92.2150)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=90, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.8215,                   Accuracy: 232/2000.0 (11.60%)



-= Testing valid =-
Test set: Average loss: 1.8755,                   Accuracy: 575/2000.0 (28.75%)



-= Testing valid =-
Test set: Average loss: 3.1593,                   Accuracy: 412/2000.0 (20.60%)



-= Testing valid =-
Test set: Average loss: 2.4127,                   Accuracy: 659/2000.0 (32.95%)



-= Testing valid =-
Test set: Average loss: 2.4009,                   Accuracy: 550/2000.0 (27.50%)



-= Testing valid =-
Test set: Average loss: 1.3345,                   Accuracy: 910/2000.0 (45.50%)



-= Testing valid =-
Test set: Average loss: 1.5403,                   Accuracy: 996/2000.0 (49.80%)



-= Testing valid =-
Test set: Average loss: 2.2273,                   Accuracy: 667/2000.0 (33.35%)



-= Testing valid =-
Test set: Average loss: 2.0982,                   Accuracy: 834/2000.0 (41.70%)



-= Testing valid =-
Test set: Average loss: 1.0312,                   Accuracy: 1256/2000.0 (62.80%)



Epoch 10 train accuracy: 73.11%, valid accuracy 62.80%
-= Testing valid =-
Test set: Average loss: 0.7102,                   Accuracy: 1568/2000.0 (78.40%)



-= Testing valid =-
Test set: Average loss: 0.7083,                   Accuracy: 1611/2000.0 (80.55%)



-= Testing valid =-
Test set: Average loss: 0.8927,                   Accuracy: 1339/2000.0 (66.95%)



-= Testing valid =-
Test set: Average loss: 0.8757,                   Accuracy: 1399/2000.0 (69.95%)



-= Testing valid =-
Test set: Average loss: 0.5509,                   Accuracy: 1631/2000.0 (81.55%)



-= Testing valid =-
Test set: Average loss: 0.4057,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.4975,                   Accuracy: 1700/2000.0 (85.00%)



-= Testing valid =-
Test set: Average loss: 0.3934,                   Accuracy: 1752/2000.0 (87.60%)



-= Testing valid =-
Test set: Average loss: 0.4412,                   Accuracy: 1710/2000.0 (85.50%)



-= Testing valid =-
Test set: Average loss: 0.4115,                   Accuracy: 1739/2000.0 (86.95%)



Epoch 20 train accuracy: 85.84%, valid accuracy 86.95%
-= Testing valid =-
Test set: Average loss: 0.4810,                   Accuracy: 1694/2000.0 (84.70%)



-= Testing valid =-
Test set: Average loss: 0.3678,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.3907,                   Accuracy: 1742/2000.0 (87.10%)



-= Testing valid =-
Test set: Average loss: 0.3592,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.3891,                   Accuracy: 1755/2000.0 (87.75%)



-= Testing valid =-
Test set: Average loss: 0.3948,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.3763,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.3274,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.3866,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.3485,                   Accuracy: 1780/2000.0 (89.00%)



Epoch 30 train accuracy: 88.84%, valid accuracy 89.00%
-= Testing valid =-
Test set: Average loss: 0.2843,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2776,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.3133,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.2944,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.2679,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2402,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.3595,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.2932,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2896,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.2739,                   Accuracy: 1833/2000.0 (91.65%)



Epoch 40 train accuracy: 90.47%, valid accuracy 91.65%
-= Testing valid =-
Test set: Average loss: 0.2355,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2353,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.2515,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.2541,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.2465,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2366,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.2383,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2452,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2941,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2858,                   Accuracy: 1817/2000.0 (90.85%)



Epoch 50 train accuracy: 90.46%, valid accuracy 90.85%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2865,                   Accuracy: 55030/60000 (91.72%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2781,                   Accuracy: 55128/60000 (91.88%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2818,                   Accuracy: 55114/60000 (91.86%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2879,                   Accuracy: 55027/60000 (91.71%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2880,                   Accuracy: 55025/60000 (91.71%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2912,                   Accuracy: 54976/60000 (91.63%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2947,                   Accuracy: 54936/60000 (91.56%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3014,                   Accuracy: 54691/60000 (91.15%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2962,                   Accuracy: 54749/60000 (91.25%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3119,                   Accuracy: 54465/60000 (90.78%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3171,                   Accuracy: 54241/60000 (90.40%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3386,                   Accuracy: 53890/60000 (89.82%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3591,                   Accuracy: 53443/60000 (89.07%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3603,                   Accuracy: 53428/60000 (89.05%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3586,                   Accuracy: 53391/60000 (88.99%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3500,                   Accuracy: 53523/60000 (89.21%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3476,                   Accuracy: 53351/60000 (88.92%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3388,                   Accuracy: 53398/60000 (89.00%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3537,                   Accuracy: 53023/60000 (88.37%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3548,                   Accuracy: 53078/60000 (88.46%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3707,                   Accuracy: 52746/60000 (87.91%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3785,                   Accuracy: 52495/60000 (87.49%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3734,                   Accuracy: 52645/60000 (87.74%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3696,                   Accuracy: 52824/60000 (88.04%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3648,                   Accuracy: 52969/60000 (88.28%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3629,                   Accuracy: 53136/60000 (88.56%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3501,                   Accuracy: 53315/60000 (88.86%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3618,                   Accuracy: 53127/60000 (88.54%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3551,                   Accuracy: 53201/60000 (88.67%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3654,                   Accuracy: 53079/60000 (88.46%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3665,                   Accuracy: 53077/60000 (88.46%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3563,                   Accuracy: 53332/60000 (88.89%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3425,                   Accuracy: 53786/60000 (89.64%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3284,                   Accuracy: 54095/60000 (90.16%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3139,                   Accuracy: 54460/60000 (90.77%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2913,                   Accuracy: 54820/60000 (91.37%)
{0: tensor(91.7167), 10: tensor(91.8800), 20: tensor(91.8567), 30: tensor(91.7117), 40: tensor(91.7083), 50: tensor(91.6267), 60: tensor(91.5600), 70: tensor(91.1517), 80: tensor(91.2483), 90: tensor(90.7750), 100: tensor(90.4017), 110: tensor(89.8167), 120: tensor(89.0717), 130: tensor(89.0467), 140: tensor(88.9850), 150: tensor(89.2050), 160: tensor(88.9183), 170: tensor(88.9967), 180: tensor(88.3717), 190: tensor(88.4633), 200: tensor(87.9100), 210: tensor(87.4917), 220: tensor(87.7417), 230: tensor(88.0400), 240: tensor(88.2817), 250: tensor(88.5600), 260: tensor(88.8583), 270: tensor(88.5450), 280: tensor(88.6683), 290: tensor(88.4650), 300: tensor(88.4617), 310: tensor(88.8867), 320: tensor(89.6433), 330: tensor(90.1583), 340: tensor(90.7667), 350: tensor(91.3667)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=91, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.1006,                   Accuracy: 439/2000.0 (21.95%)



-= Testing valid =-
Test set: Average loss: 1.7590,                   Accuracy: 754/2000.0 (37.70%)



-= Testing valid =-
Test set: Average loss: 4.4723,                   Accuracy: 301/2000.0 (15.05%)



-= Testing valid =-
Test set: Average loss: 2.8433,                   Accuracy: 407/2000.0 (20.35%)



-= Testing valid =-
Test set: Average loss: 2.1836,                   Accuracy: 580/2000.0 (29.00%)



-= Testing valid =-
Test set: Average loss: 1.2691,                   Accuracy: 1143/2000.0 (57.15%)



-= Testing valid =-
Test set: Average loss: 1.6734,                   Accuracy: 791/2000.0 (39.55%)



-= Testing valid =-
Test set: Average loss: 1.6918,                   Accuracy: 983/2000.0 (49.15%)



-= Testing valid =-
Test set: Average loss: 2.6977,                   Accuracy: 551/2000.0 (27.55%)



-= Testing valid =-
Test set: Average loss: 1.3116,                   Accuracy: 1192/2000.0 (59.60%)



Epoch 10 train accuracy: 70.74%, valid accuracy 59.60%
-= Testing valid =-
Test set: Average loss: 1.2264,                   Accuracy: 1107/2000.0 (55.35%)



-= Testing valid =-
Test set: Average loss: 0.9248,                   Accuracy: 1364/2000.0 (68.20%)



-= Testing valid =-
Test set: Average loss: 0.8092,                   Accuracy: 1482/2000.0 (74.10%)



-= Testing valid =-
Test set: Average loss: 0.8596,                   Accuracy: 1400/2000.0 (70.00%)



-= Testing valid =-
Test set: Average loss: 0.5988,                   Accuracy: 1591/2000.0 (79.55%)



-= Testing valid =-
Test set: Average loss: 0.6429,                   Accuracy: 1573/2000.0 (78.65%)



-= Testing valid =-
Test set: Average loss: 0.9528,                   Accuracy: 1330/2000.0 (66.50%)



-= Testing valid =-
Test set: Average loss: 0.6376,                   Accuracy: 1512/2000.0 (75.60%)



-= Testing valid =-
Test set: Average loss: 0.5052,                   Accuracy: 1687/2000.0 (84.35%)



-= Testing valid =-
Test set: Average loss: 0.4622,                   Accuracy: 1692/2000.0 (84.60%)



Epoch 20 train accuracy: 85.59%, valid accuracy 84.60%
-= Testing valid =-
Test set: Average loss: 0.5499,                   Accuracy: 1632/2000.0 (81.60%)



-= Testing valid =-
Test set: Average loss: 0.3749,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.3584,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.4463,                   Accuracy: 1716/2000.0 (85.80%)



-= Testing valid =-
Test set: Average loss: 0.2424,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.3119,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.4619,                   Accuracy: 1697/2000.0 (84.85%)



-= Testing valid =-
Test set: Average loss: 0.3501,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.3067,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.3372,                   Accuracy: 1787/2000.0 (89.35%)



Epoch 30 train accuracy: 89.35%, valid accuracy 89.35%
-= Testing valid =-
Test set: Average loss: 0.2866,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.2648,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.3180,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.2645,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.2836,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.3075,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.3588,                   Accuracy: 1759/2000.0 (87.95%)



-= Testing valid =-
Test set: Average loss: 0.2740,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.3529,                   Accuracy: 1770/2000.0 (88.50%)



-= Testing valid =-
Test set: Average loss: 0.3733,                   Accuracy: 1764/2000.0 (88.20%)



Epoch 40 train accuracy: 90.16%, valid accuracy 88.20%
-= Testing valid =-
Test set: Average loss: 0.3665,                   Accuracy: 1768/2000.0 (88.40%)



-= Testing valid =-
Test set: Average loss: 0.3217,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.3323,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.2904,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2999,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.3172,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.3128,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3768,                   Accuracy: 1766/2000.0 (88.30%)



-= Testing valid =-
Test set: Average loss: 0.3075,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2848,                   Accuracy: 1824/2000.0 (91.20%)



Epoch 50 train accuracy: 91.04%, valid accuracy 91.20%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2775,                   Accuracy: 55172/60000 (91.95%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2842,                   Accuracy: 54959/60000 (91.60%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3013,                   Accuracy: 54660/60000 (91.10%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3262,                   Accuracy: 54160/60000 (90.27%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3359,                   Accuracy: 53937/60000 (89.89%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3453,                   Accuracy: 53837/60000 (89.73%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3469,                   Accuracy: 53816/60000 (89.69%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3520,                   Accuracy: 53682/60000 (89.47%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3465,                   Accuracy: 53750/60000 (89.58%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3462,                   Accuracy: 53803/60000 (89.67%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3638,                   Accuracy: 53312/60000 (88.85%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3641,                   Accuracy: 53414/60000 (89.02%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3805,                   Accuracy: 52982/60000 (88.30%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3843,                   Accuracy: 52829/60000 (88.05%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3922,                   Accuracy: 52640/60000 (87.73%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4015,                   Accuracy: 52313/60000 (87.19%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4071,                   Accuracy: 52175/60000 (86.96%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.4035,                   Accuracy: 52222/60000 (87.04%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.4250,                   Accuracy: 51486/60000 (85.81%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.4383,                   Accuracy: 51126/60000 (85.21%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.4297,                   Accuracy: 51482/60000 (85.80%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4335,                   Accuracy: 51381/60000 (85.64%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4128,                   Accuracy: 51904/60000 (86.51%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3921,                   Accuracy: 52411/60000 (87.35%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3793,                   Accuracy: 52726/60000 (87.88%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3694,                   Accuracy: 53000/60000 (88.33%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3546,                   Accuracy: 53335/60000 (88.89%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3394,                   Accuracy: 53718/60000 (89.53%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3344,                   Accuracy: 53891/60000 (89.82%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3396,                   Accuracy: 53917/60000 (89.86%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3427,                   Accuracy: 53765/60000 (89.61%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3406,                   Accuracy: 53876/60000 (89.79%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3278,                   Accuracy: 54168/60000 (90.28%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3111,                   Accuracy: 54551/60000 (90.92%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2964,                   Accuracy: 54856/60000 (91.43%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2840,                   Accuracy: 55024/60000 (91.71%)
{0: tensor(91.9533), 10: tensor(91.5983), 20: tensor(91.1000), 30: tensor(90.2667), 40: tensor(89.8950), 50: tensor(89.7283), 60: tensor(89.6933), 70: tensor(89.4700), 80: tensor(89.5833), 90: tensor(89.6717), 100: tensor(88.8533), 110: tensor(89.0233), 120: tensor(88.3033), 130: tensor(88.0483), 140: tensor(87.7333), 150: tensor(87.1883), 160: tensor(86.9583), 170: tensor(87.0367), 180: tensor(85.8100), 190: tensor(85.2100), 200: tensor(85.8033), 210: tensor(85.6350), 220: tensor(86.5067), 230: tensor(87.3517), 240: tensor(87.8767), 250: tensor(88.3333), 260: tensor(88.8917), 270: tensor(89.5300), 280: tensor(89.8183), 290: tensor(89.8617), 300: tensor(89.6083), 310: tensor(89.7933), 320: tensor(90.2800), 330: tensor(90.9183), 340: tensor(91.4267), 350: tensor(91.7067)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=92, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.5904,                   Accuracy: 241/2000.0 (12.05%)



-= Testing valid =-
Test set: Average loss: 4.4808,                   Accuracy: 260/2000.0 (13.00%)



-= Testing valid =-
Test set: Average loss: 2.7699,                   Accuracy: 373/2000.0 (18.65%)



-= Testing valid =-
Test set: Average loss: 3.3932,                   Accuracy: 527/2000.0 (26.35%)



-= Testing valid =-
Test set: Average loss: 1.1399,                   Accuracy: 1172/2000.0 (58.60%)



-= Testing valid =-
Test set: Average loss: 2.5493,                   Accuracy: 672/2000.0 (33.60%)



-= Testing valid =-
Test set: Average loss: 1.6496,                   Accuracy: 858/2000.0 (42.90%)



-= Testing valid =-
Test set: Average loss: 1.8113,                   Accuracy: 705/2000.0 (35.25%)



-= Testing valid =-
Test set: Average loss: 1.4471,                   Accuracy: 947/2000.0 (47.35%)



-= Testing valid =-
Test set: Average loss: 0.9152,                   Accuracy: 1401/2000.0 (70.05%)



Epoch 10 train accuracy: 73.34%, valid accuracy 70.05%
-= Testing valid =-
Test set: Average loss: 0.5056,                   Accuracy: 1710/2000.0 (85.50%)



-= Testing valid =-
Test set: Average loss: 0.5906,                   Accuracy: 1643/2000.0 (82.15%)



-= Testing valid =-
Test set: Average loss: 0.7164,                   Accuracy: 1391/2000.0 (69.55%)



-= Testing valid =-
Test set: Average loss: 0.6488,                   Accuracy: 1545/2000.0 (77.25%)



-= Testing valid =-
Test set: Average loss: 0.4172,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.4076,                   Accuracy: 1756/2000.0 (87.80%)



-= Testing valid =-
Test set: Average loss: 0.5065,                   Accuracy: 1670/2000.0 (83.50%)



-= Testing valid =-
Test set: Average loss: 0.3335,                   Accuracy: 1803/2000.0 (90.15%)



-= Testing valid =-
Test set: Average loss: 0.3551,                   Accuracy: 1777/2000.0 (88.85%)



-= Testing valid =-
Test set: Average loss: 0.3927,                   Accuracy: 1752/2000.0 (87.60%)



Epoch 20 train accuracy: 86.68%, valid accuracy 87.60%
-= Testing valid =-
Test set: Average loss: 0.2978,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2870,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.3046,                   Accuracy: 1823/2000.0 (91.15%)



-= Testing valid =-
Test set: Average loss: 0.3633,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.2715,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.2909,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.3167,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.3440,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.3724,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.3457,                   Accuracy: 1789/2000.0 (89.45%)



Epoch 30 train accuracy: 89.47%, valid accuracy 89.45%
-= Testing valid =-
Test set: Average loss: 0.3267,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.3063,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2549,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2834,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.2798,                   Accuracy: 1834/2000.0 (91.70%)



-= Testing valid =-
Test set: Average loss: 0.3729,                   Accuracy: 1762/2000.0 (88.10%)



-= Testing valid =-
Test set: Average loss: 0.2340,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2769,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2777,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.3287,                   Accuracy: 1794/2000.0 (89.70%)



Epoch 40 train accuracy: 90.55%, valid accuracy 89.70%
-= Testing valid =-
Test set: Average loss: 0.3032,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2902,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2569,                   Accuracy: 1844/2000.0 (92.20%)



-= Testing valid =-
Test set: Average loss: 0.2752,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2872,                   Accuracy: 1830/2000.0 (91.50%)



-= Testing valid =-
Test set: Average loss: 0.3128,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.2751,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2561,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2370,                   Accuracy: 1860/2000.0 (93.00%)



-= Testing valid =-
Test set: Average loss: 0.2697,                   Accuracy: 1832/2000.0 (91.60%)



Epoch 50 train accuracy: 90.85%, valid accuracy 91.60%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2708,                   Accuracy: 55124/60000 (91.87%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2733,                   Accuracy: 55056/60000 (91.76%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2908,                   Accuracy: 54807/60000 (91.35%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3106,                   Accuracy: 54463/60000 (90.77%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3221,                   Accuracy: 54223/60000 (90.37%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3419,                   Accuracy: 53845/60000 (89.74%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3585,                   Accuracy: 53477/60000 (89.13%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3677,                   Accuracy: 53274/60000 (88.79%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3561,                   Accuracy: 53306/60000 (88.84%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3794,                   Accuracy: 53047/60000 (88.41%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3816,                   Accuracy: 52864/60000 (88.11%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.4025,                   Accuracy: 52712/60000 (87.85%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4127,                   Accuracy: 52471/60000 (87.45%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4088,                   Accuracy: 52463/60000 (87.44%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.4077,                   Accuracy: 52453/60000 (87.42%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3998,                   Accuracy: 52519/60000 (87.53%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3835,                   Accuracy: 52737/60000 (87.89%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3532,                   Accuracy: 53242/60000 (88.74%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3456,                   Accuracy: 53398/60000 (89.00%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3424,                   Accuracy: 53464/60000 (89.11%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3517,                   Accuracy: 53356/60000 (88.93%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3593,                   Accuracy: 53244/60000 (88.74%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3565,                   Accuracy: 53333/60000 (88.89%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3561,                   Accuracy: 53426/60000 (89.04%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3531,                   Accuracy: 53515/60000 (89.19%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3506,                   Accuracy: 53525/60000 (89.21%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3420,                   Accuracy: 53635/60000 (89.39%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3312,                   Accuracy: 54051/60000 (90.08%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3285,                   Accuracy: 53980/60000 (89.97%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3277,                   Accuracy: 54200/60000 (90.33%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3244,                   Accuracy: 54227/60000 (90.38%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3179,                   Accuracy: 54351/60000 (90.58%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3109,                   Accuracy: 54556/60000 (90.93%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3044,                   Accuracy: 54586/60000 (90.98%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2904,                   Accuracy: 54855/60000 (91.43%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2686,                   Accuracy: 55249/60000 (92.08%)
{0: tensor(91.8733), 10: tensor(91.7600), 20: tensor(91.3450), 30: tensor(90.7717), 40: tensor(90.3717), 50: tensor(89.7417), 60: tensor(89.1283), 70: tensor(88.7900), 80: tensor(88.8433), 90: tensor(88.4117), 100: tensor(88.1067), 110: tensor(87.8533), 120: tensor(87.4517), 130: tensor(87.4383), 140: tensor(87.4217), 150: tensor(87.5317), 160: tensor(87.8950), 170: tensor(88.7367), 180: tensor(88.9967), 190: tensor(89.1067), 200: tensor(88.9267), 210: tensor(88.7400), 220: tensor(88.8883), 230: tensor(89.0433), 240: tensor(89.1917), 250: tensor(89.2083), 260: tensor(89.3917), 270: tensor(90.0850), 280: tensor(89.9667), 290: tensor(90.3333), 300: tensor(90.3783), 310: tensor(90.5850), 320: tensor(90.9267), 330: tensor(90.9767), 340: tensor(91.4250), 350: tensor(92.0817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=93, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 4.8996,                   Accuracy: 235/2000.0 (11.75%)



-= Testing valid =-
Test set: Average loss: 3.0945,                   Accuracy: 297/2000.0 (14.85%)



-= Testing valid =-
Test set: Average loss: 1.7303,                   Accuracy: 794/2000.0 (39.70%)



-= Testing valid =-
Test set: Average loss: 1.5509,                   Accuracy: 827/2000.0 (41.35%)



-= Testing valid =-
Test set: Average loss: 1.8960,                   Accuracy: 695/2000.0 (34.75%)



-= Testing valid =-
Test set: Average loss: 1.2750,                   Accuracy: 980/2000.0 (49.00%)



-= Testing valid =-
Test set: Average loss: 1.7095,                   Accuracy: 935/2000.0 (46.75%)



-= Testing valid =-
Test set: Average loss: 2.2391,                   Accuracy: 876/2000.0 (43.80%)



-= Testing valid =-
Test set: Average loss: 1.4012,                   Accuracy: 1152/2000.0 (57.60%)



-= Testing valid =-
Test set: Average loss: 0.9454,                   Accuracy: 1257/2000.0 (62.85%)



Epoch 10 train accuracy: 75.29%, valid accuracy 62.85%
-= Testing valid =-
Test set: Average loss: 1.2623,                   Accuracy: 1184/2000.0 (59.20%)



-= Testing valid =-
Test set: Average loss: 0.7664,                   Accuracy: 1438/2000.0 (71.90%)



-= Testing valid =-
Test set: Average loss: 0.6950,                   Accuracy: 1488/2000.0 (74.40%)



-= Testing valid =-
Test set: Average loss: 0.8257,                   Accuracy: 1419/2000.0 (70.95%)



-= Testing valid =-
Test set: Average loss: 0.4121,                   Accuracy: 1726/2000.0 (86.30%)



-= Testing valid =-
Test set: Average loss: 0.9873,                   Accuracy: 1265/2000.0 (63.25%)



-= Testing valid =-
Test set: Average loss: 0.5178,                   Accuracy: 1611/2000.0 (80.55%)



-= Testing valid =-
Test set: Average loss: 0.4311,                   Accuracy: 1740/2000.0 (87.00%)



-= Testing valid =-
Test set: Average loss: 0.4012,                   Accuracy: 1736/2000.0 (86.80%)



-= Testing valid =-
Test set: Average loss: 0.4016,                   Accuracy: 1764/2000.0 (88.20%)



Epoch 20 train accuracy: 86.46%, valid accuracy 88.20%
-= Testing valid =-
Test set: Average loss: 0.3465,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.2610,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.4108,                   Accuracy: 1713/2000.0 (85.65%)



-= Testing valid =-
Test set: Average loss: 0.4123,                   Accuracy: 1705/2000.0 (85.25%)



-= Testing valid =-
Test set: Average loss: 0.2954,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.3150,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.3446,                   Accuracy: 1771/2000.0 (88.55%)



-= Testing valid =-
Test set: Average loss: 0.2450,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.3710,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.3558,                   Accuracy: 1787/2000.0 (89.35%)



Epoch 30 train accuracy: 89.18%, valid accuracy 89.35%
-= Testing valid =-
Test set: Average loss: 0.2562,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.3299,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.3140,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.3196,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.3127,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.2640,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2555,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2877,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2616,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2399,                   Accuracy: 1849/2000.0 (92.45%)



Epoch 40 train accuracy: 90.65%, valid accuracy 92.45%
-= Testing valid =-
Test set: Average loss: 0.2877,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2966,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2501,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.3175,                   Accuracy: 1790/2000.0 (89.50%)



-= Testing valid =-
Test set: Average loss: 0.2741,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2988,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2487,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2624,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.2232,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.2804,                   Accuracy: 1822/2000.0 (91.10%)



Epoch 50 train accuracy: 90.40%, valid accuracy 91.10%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2653,                   Accuracy: 55144/60000 (91.91%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2660,                   Accuracy: 55187/60000 (91.98%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2909,                   Accuracy: 54685/60000 (91.14%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3066,                   Accuracy: 54391/60000 (90.65%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3160,                   Accuracy: 54280/60000 (90.47%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3299,                   Accuracy: 53992/60000 (89.99%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.3366,                   Accuracy: 53745/60000 (89.57%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3339,                   Accuracy: 53764/60000 (89.61%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3160,                   Accuracy: 53940/60000 (89.90%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3398,                   Accuracy: 53489/60000 (89.15%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3295,                   Accuracy: 53664/60000 (89.44%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3526,                   Accuracy: 53231/60000 (88.72%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3685,                   Accuracy: 52953/60000 (88.25%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3762,                   Accuracy: 52799/60000 (88.00%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3829,                   Accuracy: 52777/60000 (87.96%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3803,                   Accuracy: 52723/60000 (87.87%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3720,                   Accuracy: 52804/60000 (88.01%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3439,                   Accuracy: 53335/60000 (88.89%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3573,                   Accuracy: 53030/60000 (88.38%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3345,                   Accuracy: 53682/60000 (89.47%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3453,                   Accuracy: 53583/60000 (89.31%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3539,                   Accuracy: 53397/60000 (89.00%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3376,                   Accuracy: 53777/60000 (89.63%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3375,                   Accuracy: 53768/60000 (89.61%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3188,                   Accuracy: 54052/60000 (90.09%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3036,                   Accuracy: 54340/60000 (90.57%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2757,                   Accuracy: 54807/60000 (91.35%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2783,                   Accuracy: 54927/60000 (91.54%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2812,                   Accuracy: 54924/60000 (91.54%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2978,                   Accuracy: 54675/60000 (91.12%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3088,                   Accuracy: 54522/60000 (90.87%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3040,                   Accuracy: 54556/60000 (90.93%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3052,                   Accuracy: 54507/60000 (90.85%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2982,                   Accuracy: 54613/60000 (91.02%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2864,                   Accuracy: 54785/60000 (91.31%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2635,                   Accuracy: 55125/60000 (91.88%)
{0: tensor(91.9067), 10: tensor(91.9783), 20: tensor(91.1417), 30: tensor(90.6517), 40: tensor(90.4667), 50: tensor(89.9867), 60: tensor(89.5750), 70: tensor(89.6067), 80: tensor(89.9000), 90: tensor(89.1483), 100: tensor(89.4400), 110: tensor(88.7183), 120: tensor(88.2550), 130: tensor(87.9983), 140: tensor(87.9617), 150: tensor(87.8717), 160: tensor(88.0067), 170: tensor(88.8917), 180: tensor(88.3833), 190: tensor(89.4700), 200: tensor(89.3050), 210: tensor(88.9950), 220: tensor(89.6283), 230: tensor(89.6133), 240: tensor(90.0867), 250: tensor(90.5667), 260: tensor(91.3450), 270: tensor(91.5450), 280: tensor(91.5400), 290: tensor(91.1250), 300: tensor(90.8700), 310: tensor(90.9267), 320: tensor(90.8450), 330: tensor(91.0217), 340: tensor(91.3083), 350: tensor(91.8750)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=94, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 3.2880,                   Accuracy: 313/2000.0 (15.65%)



-= Testing valid =-
Test set: Average loss: 2.4563,                   Accuracy: 321/2000.0 (16.05%)



-= Testing valid =-
Test set: Average loss: 2.6992,                   Accuracy: 329/2000.0 (16.45%)



-= Testing valid =-
Test set: Average loss: 1.2921,                   Accuracy: 1064/2000.0 (53.20%)



-= Testing valid =-
Test set: Average loss: 2.1989,                   Accuracy: 581/2000.0 (29.05%)



-= Testing valid =-
Test set: Average loss: 1.2022,                   Accuracy: 1095/2000.0 (54.75%)



-= Testing valid =-
Test set: Average loss: 1.1985,                   Accuracy: 1247/2000.0 (62.35%)



-= Testing valid =-
Test set: Average loss: 1.6389,                   Accuracy: 853/2000.0 (42.65%)



-= Testing valid =-
Test set: Average loss: 1.6131,                   Accuracy: 930/2000.0 (46.50%)



-= Testing valid =-
Test set: Average loss: 3.2381,                   Accuracy: 435/2000.0 (21.75%)



Epoch 10 train accuracy: 73.74%, valid accuracy 21.75%
-= Testing valid =-
Test set: Average loss: 0.6312,                   Accuracy: 1606/2000.0 (80.30%)



-= Testing valid =-
Test set: Average loss: 0.6641,                   Accuracy: 1559/2000.0 (77.95%)



-= Testing valid =-
Test set: Average loss: 0.5399,                   Accuracy: 1640/2000.0 (82.00%)



-= Testing valid =-
Test set: Average loss: 0.4376,                   Accuracy: 1737/2000.0 (86.85%)



-= Testing valid =-
Test set: Average loss: 0.3644,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.6299,                   Accuracy: 1603/2000.0 (80.15%)



-= Testing valid =-
Test set: Average loss: 0.4512,                   Accuracy: 1711/2000.0 (85.55%)



-= Testing valid =-
Test set: Average loss: 0.3433,                   Accuracy: 1761/2000.0 (88.05%)



-= Testing valid =-
Test set: Average loss: 0.4992,                   Accuracy: 1690/2000.0 (84.50%)



-= Testing valid =-
Test set: Average loss: 0.3663,                   Accuracy: 1791/2000.0 (89.55%)



Epoch 20 train accuracy: 86.21%, valid accuracy 89.55%
-= Testing valid =-
Test set: Average loss: 0.2941,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.3597,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.3977,                   Accuracy: 1751/2000.0 (87.55%)



-= Testing valid =-
Test set: Average loss: 0.2954,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.3057,                   Accuracy: 1809/2000.0 (90.45%)



-= Testing valid =-
Test set: Average loss: 0.2422,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.3022,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2333,                   Accuracy: 1859/2000.0 (92.95%)



-= Testing valid =-
Test set: Average loss: 0.2648,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2878,                   Accuracy: 1811/2000.0 (90.55%)



Epoch 30 train accuracy: 89.41%, valid accuracy 90.55%
-= Testing valid =-
Test set: Average loss: 0.2490,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.2416,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.2723,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.3086,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2393,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.2402,                   Accuracy: 1850/2000.0 (92.50%)



-= Testing valid =-
Test set: Average loss: 0.2671,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2416,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.2445,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2282,                   Accuracy: 1853/2000.0 (92.65%)



Epoch 40 train accuracy: 89.96%, valid accuracy 92.65%
-= Testing valid =-
Test set: Average loss: 0.2141,                   Accuracy: 1865/2000.0 (93.25%)



-= Testing valid =-
Test set: Average loss: 0.2473,                   Accuracy: 1837/2000.0 (91.85%)



-= Testing valid =-
Test set: Average loss: 0.2426,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2704,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2376,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2205,                   Accuracy: 1867/2000.0 (93.35%)



-= Testing valid =-
Test set: Average loss: 0.2217,                   Accuracy: 1854/2000.0 (92.70%)



-= Testing valid =-
Test set: Average loss: 0.2515,                   Accuracy: 1835/2000.0 (91.75%)



-= Testing valid =-
Test set: Average loss: 0.2606,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2330,                   Accuracy: 1849/2000.0 (92.45%)



Epoch 50 train accuracy: 90.90%, valid accuracy 92.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2616,                   Accuracy: 55297/60000 (92.16%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2726,                   Accuracy: 55118/60000 (91.86%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2778,                   Accuracy: 55009/60000 (91.68%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2812,                   Accuracy: 54953/60000 (91.59%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2820,                   Accuracy: 54915/60000 (91.53%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2857,                   Accuracy: 54857/60000 (91.43%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2848,                   Accuracy: 54811/60000 (91.35%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2966,                   Accuracy: 54567/60000 (90.94%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2885,                   Accuracy: 54655/60000 (91.09%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2955,                   Accuracy: 54679/60000 (91.13%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3157,                   Accuracy: 54181/60000 (90.30%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3281,                   Accuracy: 54023/60000 (90.04%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3437,                   Accuracy: 53591/60000 (89.32%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3520,                   Accuracy: 53326/60000 (88.88%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3580,                   Accuracy: 53103/60000 (88.50%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3584,                   Accuracy: 53096/60000 (88.49%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3559,                   Accuracy: 53157/60000 (88.60%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3335,                   Accuracy: 53663/60000 (89.44%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3479,                   Accuracy: 53267/60000 (88.78%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3547,                   Accuracy: 53234/60000 (88.72%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3555,                   Accuracy: 53233/60000 (88.72%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3549,                   Accuracy: 53251/60000 (88.75%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3435,                   Accuracy: 53403/60000 (89.00%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3415,                   Accuracy: 53479/60000 (89.13%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3385,                   Accuracy: 53533/60000 (89.22%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3466,                   Accuracy: 53308/60000 (88.85%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3219,                   Accuracy: 53912/60000 (89.85%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3247,                   Accuracy: 53896/60000 (89.83%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3301,                   Accuracy: 53819/60000 (89.70%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3308,                   Accuracy: 53976/60000 (89.96%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3272,                   Accuracy: 53999/60000 (90.00%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3232,                   Accuracy: 53997/60000 (90.00%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3118,                   Accuracy: 54136/60000 (90.23%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2974,                   Accuracy: 54418/60000 (90.70%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2903,                   Accuracy: 54649/60000 (91.08%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2692,                   Accuracy: 54961/60000 (91.60%)
{0: tensor(92.1617), 10: tensor(91.8633), 20: tensor(91.6817), 30: tensor(91.5883), 40: tensor(91.5250), 50: tensor(91.4283), 60: tensor(91.3517), 70: tensor(90.9450), 80: tensor(91.0917), 90: tensor(91.1317), 100: tensor(90.3017), 110: tensor(90.0383), 120: tensor(89.3183), 130: tensor(88.8767), 140: tensor(88.5050), 150: tensor(88.4933), 160: tensor(88.5950), 170: tensor(89.4383), 180: tensor(88.7783), 190: tensor(88.7233), 200: tensor(88.7217), 210: tensor(88.7517), 220: tensor(89.0050), 230: tensor(89.1317), 240: tensor(89.2217), 250: tensor(88.8467), 260: tensor(89.8533), 270: tensor(89.8267), 280: tensor(89.6983), 290: tensor(89.9600), 300: tensor(89.9983), 310: tensor(89.9950), 320: tensor(90.2267), 330: tensor(90.6967), 340: tensor(91.0817), 350: tensor(91.6017)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=95, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.6036,                   Accuracy: 233/2000.0 (11.65%)



-= Testing valid =-
Test set: Average loss: 4.8980,                   Accuracy: 344/2000.0 (17.20%)



-= Testing valid =-
Test set: Average loss: 1.3961,                   Accuracy: 978/2000.0 (48.90%)



-= Testing valid =-
Test set: Average loss: 2.2518,                   Accuracy: 569/2000.0 (28.45%)



-= Testing valid =-
Test set: Average loss: 2.0487,                   Accuracy: 578/2000.0 (28.90%)



-= Testing valid =-
Test set: Average loss: 1.7599,                   Accuracy: 820/2000.0 (41.00%)



-= Testing valid =-
Test set: Average loss: 2.5828,                   Accuracy: 672/2000.0 (33.60%)



-= Testing valid =-
Test set: Average loss: 0.9785,                   Accuracy: 1332/2000.0 (66.60%)



-= Testing valid =-
Test set: Average loss: 1.9758,                   Accuracy: 840/2000.0 (42.00%)



-= Testing valid =-
Test set: Average loss: 1.1492,                   Accuracy: 1202/2000.0 (60.10%)



Epoch 10 train accuracy: 72.95%, valid accuracy 60.10%
-= Testing valid =-
Test set: Average loss: 0.5446,                   Accuracy: 1682/2000.0 (84.10%)



-= Testing valid =-
Test set: Average loss: 1.0316,                   Accuracy: 1331/2000.0 (66.55%)



-= Testing valid =-
Test set: Average loss: 0.6809,                   Accuracy: 1541/2000.0 (77.05%)



-= Testing valid =-
Test set: Average loss: 0.7511,                   Accuracy: 1501/2000.0 (75.05%)



-= Testing valid =-
Test set: Average loss: 0.6146,                   Accuracy: 1590/2000.0 (79.50%)



-= Testing valid =-
Test set: Average loss: 0.4709,                   Accuracy: 1688/2000.0 (84.40%)



-= Testing valid =-
Test set: Average loss: 0.5416,                   Accuracy: 1659/2000.0 (82.95%)



-= Testing valid =-
Test set: Average loss: 0.4681,                   Accuracy: 1723/2000.0 (86.15%)



-= Testing valid =-
Test set: Average loss: 0.7832,                   Accuracy: 1424/2000.0 (71.20%)



-= Testing valid =-
Test set: Average loss: 0.5634,                   Accuracy: 1569/2000.0 (78.45%)



Epoch 20 train accuracy: 85.22%, valid accuracy 78.45%
-= Testing valid =-
Test set: Average loss: 0.5339,                   Accuracy: 1639/2000.0 (81.95%)



-= Testing valid =-
Test set: Average loss: 0.5769,                   Accuracy: 1609/2000.0 (80.45%)



-= Testing valid =-
Test set: Average loss: 0.5954,                   Accuracy: 1593/2000.0 (79.65%)



-= Testing valid =-
Test set: Average loss: 0.5835,                   Accuracy: 1549/2000.0 (77.45%)



-= Testing valid =-
Test set: Average loss: 0.5733,                   Accuracy: 1598/2000.0 (79.90%)



-= Testing valid =-
Test set: Average loss: 0.5966,                   Accuracy: 1528/2000.0 (76.40%)



-= Testing valid =-
Test set: Average loss: 0.4935,                   Accuracy: 1667/2000.0 (83.35%)



-= Testing valid =-
Test set: Average loss: 0.3933,                   Accuracy: 1748/2000.0 (87.40%)



-= Testing valid =-
Test set: Average loss: 0.5012,                   Accuracy: 1641/2000.0 (82.05%)



-= Testing valid =-
Test set: Average loss: 0.4495,                   Accuracy: 1710/2000.0 (85.50%)



Epoch 30 train accuracy: 88.34%, valid accuracy 85.50%
-= Testing valid =-
Test set: Average loss: 0.4284,                   Accuracy: 1708/2000.0 (85.40%)



-= Testing valid =-
Test set: Average loss: 0.4278,                   Accuracy: 1721/2000.0 (86.05%)



-= Testing valid =-
Test set: Average loss: 0.4603,                   Accuracy: 1685/2000.0 (84.25%)



-= Testing valid =-
Test set: Average loss: 0.5201,                   Accuracy: 1610/2000.0 (80.50%)



-= Testing valid =-
Test set: Average loss: 0.3951,                   Accuracy: 1758/2000.0 (87.90%)



-= Testing valid =-
Test set: Average loss: 0.4006,                   Accuracy: 1748/2000.0 (87.40%)



-= Testing valid =-
Test set: Average loss: 0.4448,                   Accuracy: 1698/2000.0 (84.90%)



-= Testing valid =-
Test set: Average loss: 0.3596,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.4293,                   Accuracy: 1699/2000.0 (84.95%)



-= Testing valid =-
Test set: Average loss: 0.4616,                   Accuracy: 1684/2000.0 (84.20%)



Epoch 40 train accuracy: 89.78%, valid accuracy 84.20%
-= Testing valid =-
Test set: Average loss: 0.3841,                   Accuracy: 1744/2000.0 (87.20%)



-= Testing valid =-
Test set: Average loss: 0.3660,                   Accuracy: 1765/2000.0 (88.25%)



-= Testing valid =-
Test set: Average loss: 0.3819,                   Accuracy: 1757/2000.0 (87.85%)



-= Testing valid =-
Test set: Average loss: 0.3706,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.4310,                   Accuracy: 1713/2000.0 (85.65%)



-= Testing valid =-
Test set: Average loss: 0.3712,                   Accuracy: 1756/2000.0 (87.80%)



-= Testing valid =-
Test set: Average loss: 0.4026,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.4498,                   Accuracy: 1691/2000.0 (84.55%)



-= Testing valid =-
Test set: Average loss: 0.3869,                   Accuracy: 1741/2000.0 (87.05%)



-= Testing valid =-
Test set: Average loss: 0.4416,                   Accuracy: 1708/2000.0 (85.40%)



Epoch 50 train accuracy: 90.38%, valid accuracy 85.40%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3996,                   Accuracy: 52873/60000 (88.12%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3909,                   Accuracy: 53021/60000 (88.37%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.4344,                   Accuracy: 52517/60000 (87.53%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4828,                   Accuracy: 51434/60000 (85.72%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.5112,                   Accuracy: 50599/60000 (84.33%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.5437,                   Accuracy: 49465/60000 (82.44%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.5733,                   Accuracy: 48148/60000 (80.25%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.5844,                   Accuracy: 46853/60000 (78.09%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.5884,                   Accuracy: 46489/60000 (77.48%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.6007,                   Accuracy: 46319/60000 (77.20%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.5981,                   Accuracy: 46731/60000 (77.89%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.6157,                   Accuracy: 47235/60000 (78.72%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.6232,                   Accuracy: 47122/60000 (78.54%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.5768,                   Accuracy: 48198/60000 (80.33%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.5377,                   Accuracy: 49173/60000 (81.96%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4939,                   Accuracy: 50392/60000 (83.99%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4604,                   Accuracy: 51130/60000 (85.22%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.4206,                   Accuracy: 52008/60000 (86.68%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.4322,                   Accuracy: 52113/60000 (86.86%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.4501,                   Accuracy: 51583/60000 (85.97%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.4943,                   Accuracy: 50892/60000 (84.82%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5314,                   Accuracy: 50104/60000 (83.51%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.5639,                   Accuracy: 49100/60000 (81.83%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.6003,                   Accuracy: 47656/60000 (79.43%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.6142,                   Accuracy: 46744/60000 (77.91%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.6135,                   Accuracy: 45671/60000 (76.12%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.6241,                   Accuracy: 45686/60000 (76.14%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.6096,                   Accuracy: 46016/60000 (76.69%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.5842,                   Accuracy: 47181/60000 (78.64%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.5813,                   Accuracy: 48028/60000 (80.05%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.5809,                   Accuracy: 48005/60000 (80.01%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.5472,                   Accuracy: 48957/60000 (81.60%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.5103,                   Accuracy: 49810/60000 (83.02%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4723,                   Accuracy: 50909/60000 (84.85%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.4396,                   Accuracy: 51758/60000 (86.26%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3859,                   Accuracy: 52958/60000 (88.26%)
{0: tensor(88.1217), 10: tensor(88.3683), 20: tensor(87.5283), 30: tensor(85.7233), 40: tensor(84.3317), 50: tensor(82.4417), 60: tensor(80.2467), 70: tensor(78.0883), 80: tensor(77.4817), 90: tensor(77.1983), 100: tensor(77.8850), 110: tensor(78.7250), 120: tensor(78.5367), 130: tensor(80.3300), 140: tensor(81.9550), 150: tensor(83.9867), 160: tensor(85.2167), 170: tensor(86.6800), 180: tensor(86.8550), 190: tensor(85.9717), 200: tensor(84.8200), 210: tensor(83.5067), 220: tensor(81.8333), 230: tensor(79.4267), 240: tensor(77.9067), 250: tensor(76.1183), 260: tensor(76.1433), 270: tensor(76.6933), 280: tensor(78.6350), 290: tensor(80.0467), 300: tensor(80.0083), 310: tensor(81.5950), 320: tensor(83.0167), 330: tensor(84.8483), 340: tensor(86.2633), 350: tensor(88.2633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=96, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.2069,                   Accuracy: 440/2000.0 (22.00%)



-= Testing valid =-
Test set: Average loss: 4.7901,                   Accuracy: 263/2000.0 (13.15%)



-= Testing valid =-
Test set: Average loss: 1.3653,                   Accuracy: 983/2000.0 (49.15%)



-= Testing valid =-
Test set: Average loss: 1.9354,                   Accuracy: 570/2000.0 (28.50%)



-= Testing valid =-
Test set: Average loss: 1.5435,                   Accuracy: 880/2000.0 (44.00%)



-= Testing valid =-
Test set: Average loss: 1.3227,                   Accuracy: 967/2000.0 (48.35%)



-= Testing valid =-
Test set: Average loss: 2.0994,                   Accuracy: 785/2000.0 (39.25%)



-= Testing valid =-
Test set: Average loss: 1.1037,                   Accuracy: 1296/2000.0 (64.80%)



-= Testing valid =-
Test set: Average loss: 1.5537,                   Accuracy: 965/2000.0 (48.25%)



-= Testing valid =-
Test set: Average loss: 0.9529,                   Accuracy: 1328/2000.0 (66.40%)



Epoch 10 train accuracy: 71.31%, valid accuracy 66.40%
-= Testing valid =-
Test set: Average loss: 1.0346,                   Accuracy: 1326/2000.0 (66.30%)



-= Testing valid =-
Test set: Average loss: 0.7888,                   Accuracy: 1443/2000.0 (72.15%)



-= Testing valid =-
Test set: Average loss: 0.7957,                   Accuracy: 1444/2000.0 (72.20%)



-= Testing valid =-
Test set: Average loss: 1.1413,                   Accuracy: 1108/2000.0 (55.40%)



-= Testing valid =-
Test set: Average loss: 0.8717,                   Accuracy: 1359/2000.0 (67.95%)



-= Testing valid =-
Test set: Average loss: 0.8019,                   Accuracy: 1424/2000.0 (71.20%)



-= Testing valid =-
Test set: Average loss: 0.6732,                   Accuracy: 1528/2000.0 (76.40%)



-= Testing valid =-
Test set: Average loss: 0.3994,                   Accuracy: 1744/2000.0 (87.20%)



-= Testing valid =-
Test set: Average loss: 0.3498,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.3125,                   Accuracy: 1810/2000.0 (90.50%)



Epoch 20 train accuracy: 85.34%, valid accuracy 90.50%
-= Testing valid =-
Test set: Average loss: 0.3266,                   Accuracy: 1778/2000.0 (88.90%)



-= Testing valid =-
Test set: Average loss: 0.3007,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.3319,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.2504,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.3916,                   Accuracy: 1729/2000.0 (86.45%)



-= Testing valid =-
Test set: Average loss: 0.3244,                   Accuracy: 1804/2000.0 (90.20%)



-= Testing valid =-
Test set: Average loss: 0.4587,                   Accuracy: 1702/2000.0 (85.10%)



-= Testing valid =-
Test set: Average loss: 0.3253,                   Accuracy: 1775/2000.0 (88.75%)



-= Testing valid =-
Test set: Average loss: 0.3839,                   Accuracy: 1763/2000.0 (88.15%)



-= Testing valid =-
Test set: Average loss: 0.3773,                   Accuracy: 1749/2000.0 (87.45%)



Epoch 30 train accuracy: 89.26%, valid accuracy 87.45%
-= Testing valid =-
Test set: Average loss: 0.3024,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.3276,                   Accuracy: 1781/2000.0 (89.05%)



-= Testing valid =-
Test set: Average loss: 0.2670,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.3128,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.2767,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.3073,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.2595,                   Accuracy: 1838/2000.0 (91.90%)



-= Testing valid =-
Test set: Average loss: 0.3330,                   Accuracy: 1774/2000.0 (88.70%)



-= Testing valid =-
Test set: Average loss: 0.3024,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.2942,                   Accuracy: 1807/2000.0 (90.35%)



Epoch 40 train accuracy: 90.31%, valid accuracy 90.35%
-= Testing valid =-
Test set: Average loss: 0.2944,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.2406,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2276,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2733,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2798,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2815,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.2774,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2717,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2633,                   Accuracy: 1831/2000.0 (91.55%)



-= Testing valid =-
Test set: Average loss: 0.3051,                   Accuracy: 1789/2000.0 (89.45%)



Epoch 50 train accuracy: 90.19%, valid accuracy 89.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2576,                   Accuracy: 55452/60000 (92.42%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2640,                   Accuracy: 55086/60000 (91.81%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2570,                   Accuracy: 55278/60000 (92.13%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2653,                   Accuracy: 55109/60000 (91.85%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2728,                   Accuracy: 54857/60000 (91.43%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2833,                   Accuracy: 54644/60000 (91.07%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2925,                   Accuracy: 54510/60000 (90.85%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.3027,                   Accuracy: 54230/60000 (90.38%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3108,                   Accuracy: 53976/60000 (89.96%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3081,                   Accuracy: 54030/60000 (90.05%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3266,                   Accuracy: 53598/60000 (89.33%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3416,                   Accuracy: 53403/60000 (89.00%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3465,                   Accuracy: 53372/60000 (88.95%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3511,                   Accuracy: 53154/60000 (88.59%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3502,                   Accuracy: 53145/60000 (88.57%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3444,                   Accuracy: 53204/60000 (88.67%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3484,                   Accuracy: 53211/60000 (88.68%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3331,                   Accuracy: 53442/60000 (89.07%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3173,                   Accuracy: 53804/60000 (89.67%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3215,                   Accuracy: 53641/60000 (89.40%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3124,                   Accuracy: 53863/60000 (89.77%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.2968,                   Accuracy: 54247/60000 (90.41%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.2974,                   Accuracy: 54236/60000 (90.39%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.2974,                   Accuracy: 54299/60000 (90.50%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3014,                   Accuracy: 54226/60000 (90.38%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3099,                   Accuracy: 54038/60000 (90.06%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2968,                   Accuracy: 54393/60000 (90.65%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3038,                   Accuracy: 54136/60000 (90.23%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2990,                   Accuracy: 54056/60000 (90.09%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.3031,                   Accuracy: 54098/60000 (90.16%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.3008,                   Accuracy: 54354/60000 (90.59%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2969,                   Accuracy: 54453/60000 (90.75%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2942,                   Accuracy: 54531/60000 (90.89%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2863,                   Accuracy: 54795/60000 (91.32%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2852,                   Accuracy: 54697/60000 (91.16%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2655,                   Accuracy: 55244/60000 (92.07%)
{0: tensor(92.4200), 10: tensor(91.8100), 20: tensor(92.1300), 30: tensor(91.8483), 40: tensor(91.4283), 50: tensor(91.0733), 60: tensor(90.8500), 70: tensor(90.3833), 80: tensor(89.9600), 90: tensor(90.0500), 100: tensor(89.3300), 110: tensor(89.0050), 120: tensor(88.9533), 130: tensor(88.5900), 140: tensor(88.5750), 150: tensor(88.6733), 160: tensor(88.6850), 170: tensor(89.0700), 180: tensor(89.6733), 190: tensor(89.4017), 200: tensor(89.7717), 210: tensor(90.4117), 220: tensor(90.3933), 230: tensor(90.4983), 240: tensor(90.3767), 250: tensor(90.0633), 260: tensor(90.6550), 270: tensor(90.2267), 280: tensor(90.0933), 290: tensor(90.1633), 300: tensor(90.5900), 310: tensor(90.7550), 320: tensor(90.8850), 330: tensor(91.3250), 340: tensor(91.1617), 350: tensor(92.0733)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=97, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 9.4832,                   Accuracy: 211/2000.0 (10.55%)



-= Testing valid =-
Test set: Average loss: 3.0730,                   Accuracy: 310/2000.0 (15.50%)



-= Testing valid =-
Test set: Average loss: 4.9472,                   Accuracy: 222/2000.0 (11.10%)



-= Testing valid =-
Test set: Average loss: 4.2154,                   Accuracy: 387/2000.0 (19.35%)



-= Testing valid =-
Test set: Average loss: 1.7370,                   Accuracy: 782/2000.0 (39.10%)



-= Testing valid =-
Test set: Average loss: 1.8135,                   Accuracy: 820/2000.0 (41.00%)



-= Testing valid =-
Test set: Average loss: 1.6889,                   Accuracy: 870/2000.0 (43.50%)



-= Testing valid =-
Test set: Average loss: 1.2673,                   Accuracy: 1011/2000.0 (50.55%)



-= Testing valid =-
Test set: Average loss: 1.2173,                   Accuracy: 1251/2000.0 (62.55%)



-= Testing valid =-
Test set: Average loss: 1.2239,                   Accuracy: 1131/2000.0 (56.55%)



Epoch 10 train accuracy: 68.74%, valid accuracy 56.55%
-= Testing valid =-
Test set: Average loss: 1.1809,                   Accuracy: 1169/2000.0 (58.45%)



-= Testing valid =-
Test set: Average loss: 0.9518,                   Accuracy: 1306/2000.0 (65.30%)



-= Testing valid =-
Test set: Average loss: 0.9162,                   Accuracy: 1312/2000.0 (65.60%)



-= Testing valid =-
Test set: Average loss: 0.8106,                   Accuracy: 1445/2000.0 (72.25%)



-= Testing valid =-
Test set: Average loss: 0.5788,                   Accuracy: 1656/2000.0 (82.80%)



-= Testing valid =-
Test set: Average loss: 0.5525,                   Accuracy: 1670/2000.0 (83.50%)



-= Testing valid =-
Test set: Average loss: 0.6053,                   Accuracy: 1618/2000.0 (80.90%)



-= Testing valid =-
Test set: Average loss: 0.5101,                   Accuracy: 1683/2000.0 (84.15%)



-= Testing valid =-
Test set: Average loss: 0.5758,                   Accuracy: 1609/2000.0 (80.45%)



-= Testing valid =-
Test set: Average loss: 0.5012,                   Accuracy: 1673/2000.0 (83.65%)



Epoch 20 train accuracy: 82.12%, valid accuracy 83.65%
-= Testing valid =-
Test set: Average loss: 0.5774,                   Accuracy: 1642/2000.0 (82.10%)



-= Testing valid =-
Test set: Average loss: 0.5817,                   Accuracy: 1630/2000.0 (81.50%)



-= Testing valid =-
Test set: Average loss: 0.5034,                   Accuracy: 1690/2000.0 (84.50%)



-= Testing valid =-
Test set: Average loss: 0.4381,                   Accuracy: 1746/2000.0 (87.30%)



-= Testing valid =-
Test set: Average loss: 0.4811,                   Accuracy: 1704/2000.0 (85.20%)



-= Testing valid =-
Test set: Average loss: 0.5264,                   Accuracy: 1665/2000.0 (83.25%)



-= Testing valid =-
Test set: Average loss: 0.4888,                   Accuracy: 1685/2000.0 (84.25%)



-= Testing valid =-
Test set: Average loss: 0.3658,                   Accuracy: 1779/2000.0 (88.95%)



-= Testing valid =-
Test set: Average loss: 0.3891,                   Accuracy: 1765/2000.0 (88.25%)



-= Testing valid =-
Test set: Average loss: 0.3895,                   Accuracy: 1756/2000.0 (87.80%)



Epoch 30 train accuracy: 86.79%, valid accuracy 87.80%
-= Testing valid =-
Test set: Average loss: 0.3807,                   Accuracy: 1776/2000.0 (88.80%)



-= Testing valid =-
Test set: Average loss: 0.4148,                   Accuracy: 1749/2000.0 (87.45%)



-= Testing valid =-
Test set: Average loss: 0.3501,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.4158,                   Accuracy: 1750/2000.0 (87.50%)



-= Testing valid =-
Test set: Average loss: 0.4065,                   Accuracy: 1738/2000.0 (86.90%)



-= Testing valid =-
Test set: Average loss: 0.3999,                   Accuracy: 1764/2000.0 (88.20%)



-= Testing valid =-
Test set: Average loss: 0.3538,                   Accuracy: 1802/2000.0 (90.10%)



-= Testing valid =-
Test set: Average loss: 0.3441,                   Accuracy: 1811/2000.0 (90.55%)



-= Testing valid =-
Test set: Average loss: 0.3390,                   Accuracy: 1810/2000.0 (90.50%)



-= Testing valid =-
Test set: Average loss: 0.3633,                   Accuracy: 1782/2000.0 (89.10%)



Epoch 40 train accuracy: 88.19%, valid accuracy 89.10%
-= Testing valid =-
Test set: Average loss: 0.3614,                   Accuracy: 1784/2000.0 (89.20%)



-= Testing valid =-
Test set: Average loss: 0.3151,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.3632,                   Accuracy: 1785/2000.0 (89.25%)



-= Testing valid =-
Test set: Average loss: 0.3497,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.3216,                   Accuracy: 1825/2000.0 (91.25%)



-= Testing valid =-
Test set: Average loss: 0.3387,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.3346,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.3160,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.3183,                   Accuracy: 1827/2000.0 (91.35%)



-= Testing valid =-
Test set: Average loss: 0.3448,                   Accuracy: 1809/2000.0 (90.45%)



Epoch 50 train accuracy: 89.19%, valid accuracy 90.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.3573,                   Accuracy: 54078/60000 (90.13%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.3576,                   Accuracy: 54092/60000 (90.15%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3688,                   Accuracy: 53874/60000 (89.79%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.4222,                   Accuracy: 52620/60000 (87.70%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.4276,                   Accuracy: 52601/60000 (87.67%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.4555,                   Accuracy: 51811/60000 (86.35%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.4874,                   Accuracy: 50886/60000 (84.81%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.4789,                   Accuracy: 51414/60000 (85.69%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4823,                   Accuracy: 50630/60000 (84.38%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.5046,                   Accuracy: 50201/60000 (83.67%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.4942,                   Accuracy: 50736/60000 (84.56%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.4773,                   Accuracy: 51119/60000 (85.20%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.5030,                   Accuracy: 50756/60000 (84.59%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4765,                   Accuracy: 51353/60000 (85.59%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.4747,                   Accuracy: 51435/60000 (85.72%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4632,                   Accuracy: 51808/60000 (86.35%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4387,                   Accuracy: 52029/60000 (86.71%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.4232,                   Accuracy: 52164/60000 (86.94%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.4187,                   Accuracy: 52486/60000 (87.48%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.4138,                   Accuracy: 52599/60000 (87.67%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.4443,                   Accuracy: 51883/60000 (86.47%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.5193,                   Accuracy: 49887/60000 (83.14%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.5244,                   Accuracy: 49832/60000 (83.05%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.5313,                   Accuracy: 49574/60000 (82.62%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.5394,                   Accuracy: 48996/60000 (81.66%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.5102,                   Accuracy: 49950/60000 (83.25%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.5044,                   Accuracy: 49391/60000 (82.32%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4899,                   Accuracy: 50025/60000 (83.38%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4541,                   Accuracy: 51296/60000 (85.49%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.4428,                   Accuracy: 51679/60000 (86.13%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.4713,                   Accuracy: 51092/60000 (85.15%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.4384,                   Accuracy: 52085/60000 (86.81%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.4293,                   Accuracy: 52259/60000 (87.10%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.4199,                   Accuracy: 52548/60000 (87.58%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.3926,                   Accuracy: 53114/60000 (88.52%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.3673,                   Accuracy: 53749/60000 (89.58%)
{0: tensor(90.1300), 10: tensor(90.1533), 20: tensor(89.7900), 30: tensor(87.7000), 40: tensor(87.6683), 50: tensor(86.3517), 60: tensor(84.8100), 70: tensor(85.6900), 80: tensor(84.3833), 90: tensor(83.6683), 100: tensor(84.5600), 110: tensor(85.1983), 120: tensor(84.5933), 130: tensor(85.5883), 140: tensor(85.7250), 150: tensor(86.3467), 160: tensor(86.7150), 170: tensor(86.9400), 180: tensor(87.4767), 190: tensor(87.6650), 200: tensor(86.4717), 210: tensor(83.1450), 220: tensor(83.0533), 230: tensor(82.6233), 240: tensor(81.6600), 250: tensor(83.2500), 260: tensor(82.3183), 270: tensor(83.3750), 280: tensor(85.4933), 290: tensor(86.1317), 300: tensor(85.1533), 310: tensor(86.8083), 320: tensor(87.0983), 330: tensor(87.5800), 340: tensor(88.5233), 350: tensor(89.5817)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=98, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.5817,                   Accuracy: 242/2000.0 (12.10%)



-= Testing valid =-
Test set: Average loss: 1.8375,                   Accuracy: 709/2000.0 (35.45%)



-= Testing valid =-
Test set: Average loss: 1.5887,                   Accuracy: 944/2000.0 (47.20%)



-= Testing valid =-
Test set: Average loss: 1.5505,                   Accuracy: 907/2000.0 (45.35%)



-= Testing valid =-
Test set: Average loss: 1.8835,                   Accuracy: 844/2000.0 (42.20%)



-= Testing valid =-
Test set: Average loss: 1.2056,                   Accuracy: 1073/2000.0 (53.65%)



-= Testing valid =-
Test set: Average loss: 0.9006,                   Accuracy: 1419/2000.0 (70.95%)



-= Testing valid =-
Test set: Average loss: 0.7904,                   Accuracy: 1481/2000.0 (74.05%)



-= Testing valid =-
Test set: Average loss: 0.7934,                   Accuracy: 1468/2000.0 (73.40%)



-= Testing valid =-
Test set: Average loss: 0.6824,                   Accuracy: 1613/2000.0 (80.65%)



Epoch 10 train accuracy: 74.71%, valid accuracy 80.65%
-= Testing valid =-
Test set: Average loss: 0.9200,                   Accuracy: 1298/2000.0 (64.90%)



-= Testing valid =-
Test set: Average loss: 0.5853,                   Accuracy: 1631/2000.0 (81.55%)



-= Testing valid =-
Test set: Average loss: 0.5625,                   Accuracy: 1635/2000.0 (81.75%)



-= Testing valid =-
Test set: Average loss: 0.6344,                   Accuracy: 1560/2000.0 (78.00%)



-= Testing valid =-
Test set: Average loss: 0.3527,                   Accuracy: 1796/2000.0 (89.80%)



-= Testing valid =-
Test set: Average loss: 0.8342,                   Accuracy: 1372/2000.0 (68.60%)



-= Testing valid =-
Test set: Average loss: 0.4530,                   Accuracy: 1710/2000.0 (85.50%)



-= Testing valid =-
Test set: Average loss: 0.6041,                   Accuracy: 1574/2000.0 (78.70%)



-= Testing valid =-
Test set: Average loss: 0.3324,                   Accuracy: 1808/2000.0 (90.40%)



-= Testing valid =-
Test set: Average loss: 0.4898,                   Accuracy: 1662/2000.0 (83.10%)



Epoch 20 train accuracy: 86.43%, valid accuracy 83.10%
-= Testing valid =-
Test set: Average loss: 0.3306,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.3036,                   Accuracy: 1798/2000.0 (89.90%)



-= Testing valid =-
Test set: Average loss: 0.4154,                   Accuracy: 1724/2000.0 (86.20%)



-= Testing valid =-
Test set: Average loss: 0.2526,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.4225,                   Accuracy: 1730/2000.0 (86.50%)



-= Testing valid =-
Test set: Average loss: 0.2784,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2768,                   Accuracy: 1818/2000.0 (90.90%)



-= Testing valid =-
Test set: Average loss: 0.2675,                   Accuracy: 1826/2000.0 (91.30%)



-= Testing valid =-
Test set: Average loss: 0.2954,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2664,                   Accuracy: 1829/2000.0 (91.45%)



Epoch 30 train accuracy: 90.09%, valid accuracy 91.45%
-= Testing valid =-
Test set: Average loss: 0.2867,                   Accuracy: 1816/2000.0 (90.80%)



-= Testing valid =-
Test set: Average loss: 0.3115,                   Accuracy: 1799/2000.0 (89.95%)



-= Testing valid =-
Test set: Average loss: 0.2970,                   Accuracy: 1806/2000.0 (90.30%)



-= Testing valid =-
Test set: Average loss: 0.3338,                   Accuracy: 1773/2000.0 (88.65%)



-= Testing valid =-
Test set: Average loss: 0.2438,                   Accuracy: 1848/2000.0 (92.40%)



-= Testing valid =-
Test set: Average loss: 0.2799,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2357,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2582,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2603,                   Accuracy: 1828/2000.0 (91.40%)



-= Testing valid =-
Test set: Average loss: 0.2533,                   Accuracy: 1826/2000.0 (91.30%)



Epoch 40 train accuracy: 90.74%, valid accuracy 91.30%
-= Testing valid =-
Test set: Average loss: 0.2630,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2857,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.2506,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2790,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2833,                   Accuracy: 1807/2000.0 (90.35%)



-= Testing valid =-
Test set: Average loss: 0.2316,                   Accuracy: 1847/2000.0 (92.35%)



-= Testing valid =-
Test set: Average loss: 0.2450,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2740,                   Accuracy: 1813/2000.0 (90.65%)



-= Testing valid =-
Test set: Average loss: 0.2826,                   Accuracy: 1812/2000.0 (90.60%)



-= Testing valid =-
Test set: Average loss: 0.2548,                   Accuracy: 1833/2000.0 (91.65%)



Epoch 50 train accuracy: 91.15%, valid accuracy 91.65%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2697,                   Accuracy: 55044/60000 (91.74%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2878,                   Accuracy: 54680/60000 (91.13%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2980,                   Accuracy: 54568/60000 (90.95%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3015,                   Accuracy: 54550/60000 (90.92%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3047,                   Accuracy: 54401/60000 (90.67%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2958,                   Accuracy: 54576/60000 (90.96%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2909,                   Accuracy: 54631/60000 (91.05%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2896,                   Accuracy: 54587/60000 (90.98%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.2796,                   Accuracy: 54741/60000 (91.24%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.2693,                   Accuracy: 54962/60000 (91.60%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.2843,                   Accuracy: 54562/60000 (90.94%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.2840,                   Accuracy: 54634/60000 (91.06%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.2881,                   Accuracy: 54581/60000 (90.97%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3021,                   Accuracy: 54288/60000 (90.48%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3128,                   Accuracy: 54011/60000 (90.02%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3175,                   Accuracy: 53902/60000 (89.84%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3220,                   Accuracy: 53757/60000 (89.60%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3107,                   Accuracy: 53942/60000 (89.90%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3069,                   Accuracy: 54098/60000 (90.16%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3102,                   Accuracy: 54059/60000 (90.10%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3159,                   Accuracy: 54036/60000 (90.06%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3229,                   Accuracy: 53882/60000 (89.80%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3161,                   Accuracy: 53997/60000 (90.00%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3081,                   Accuracy: 54194/60000 (90.32%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.2953,                   Accuracy: 54439/60000 (90.73%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.2953,                   Accuracy: 54431/60000 (90.72%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.2869,                   Accuracy: 54501/60000 (90.83%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.2845,                   Accuracy: 54540/60000 (90.90%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.2910,                   Accuracy: 54446/60000 (90.74%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2945,                   Accuracy: 54398/60000 (90.66%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2898,                   Accuracy: 54539/60000 (90.90%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2853,                   Accuracy: 54736/60000 (91.23%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2756,                   Accuracy: 54989/60000 (91.65%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2689,                   Accuracy: 55149/60000 (91.92%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2700,                   Accuracy: 55135/60000 (91.89%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2713,                   Accuracy: 54999/60000 (91.67%)
{0: tensor(91.7400), 10: tensor(91.1333), 20: tensor(90.9467), 30: tensor(90.9167), 40: tensor(90.6683), 50: tensor(90.9600), 60: tensor(91.0517), 70: tensor(90.9783), 80: tensor(91.2350), 90: tensor(91.6033), 100: tensor(90.9367), 110: tensor(91.0567), 120: tensor(90.9683), 130: tensor(90.4800), 140: tensor(90.0183), 150: tensor(89.8367), 160: tensor(89.5950), 170: tensor(89.9033), 180: tensor(90.1633), 190: tensor(90.0983), 200: tensor(90.0600), 210: tensor(89.8033), 220: tensor(89.9950), 230: tensor(90.3233), 240: tensor(90.7317), 250: tensor(90.7183), 260: tensor(90.8350), 270: tensor(90.9000), 280: tensor(90.7433), 290: tensor(90.6633), 300: tensor(90.8983), 310: tensor(91.2267), 320: tensor(91.6483), 330: tensor(91.9150), 340: tensor(91.8917), 350: tensor(91.6650)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=99, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 5.7930,                   Accuracy: 225/2000.0 (11.25%)



-= Testing valid =-
Test set: Average loss: 2.9428,                   Accuracy: 297/2000.0 (14.85%)



-= Testing valid =-
Test set: Average loss: 3.6107,                   Accuracy: 287/2000.0 (14.35%)



-= Testing valid =-
Test set: Average loss: 1.5455,                   Accuracy: 884/2000.0 (44.20%)



-= Testing valid =-
Test set: Average loss: 1.5541,                   Accuracy: 807/2000.0 (40.35%)



-= Testing valid =-
Test set: Average loss: 1.3449,                   Accuracy: 964/2000.0 (48.20%)



-= Testing valid =-
Test set: Average loss: 1.3588,                   Accuracy: 1079/2000.0 (53.95%)



-= Testing valid =-
Test set: Average loss: 2.5987,                   Accuracy: 672/2000.0 (33.60%)



-= Testing valid =-
Test set: Average loss: 1.0178,                   Accuracy: 1399/2000.0 (69.95%)



-= Testing valid =-
Test set: Average loss: 0.6187,                   Accuracy: 1621/2000.0 (81.05%)



Epoch 10 train accuracy: 74.65%, valid accuracy 81.05%
-= Testing valid =-
Test set: Average loss: 0.8940,                   Accuracy: 1363/2000.0 (68.15%)



-= Testing valid =-
Test set: Average loss: 0.5911,                   Accuracy: 1546/2000.0 (77.30%)



-= Testing valid =-
Test set: Average loss: 0.6974,                   Accuracy: 1495/2000.0 (74.75%)



-= Testing valid =-
Test set: Average loss: 0.5475,                   Accuracy: 1648/2000.0 (82.40%)



-= Testing valid =-
Test set: Average loss: 0.6182,                   Accuracy: 1586/2000.0 (79.30%)



-= Testing valid =-
Test set: Average loss: 0.5064,                   Accuracy: 1658/2000.0 (82.90%)



-= Testing valid =-
Test set: Average loss: 0.3471,                   Accuracy: 1787/2000.0 (89.35%)



-= Testing valid =-
Test set: Average loss: 0.5787,                   Accuracy: 1565/2000.0 (78.25%)



-= Testing valid =-
Test set: Average loss: 0.4881,                   Accuracy: 1633/2000.0 (81.65%)



-= Testing valid =-
Test set: Average loss: 0.5799,                   Accuracy: 1602/2000.0 (80.10%)



Epoch 20 train accuracy: 86.56%, valid accuracy 80.10%
-= Testing valid =-
Test set: Average loss: 0.2171,                   Accuracy: 1877/2000.0 (93.85%)



-= Testing valid =-
Test set: Average loss: 0.2874,                   Accuracy: 1821/2000.0 (91.05%)



-= Testing valid =-
Test set: Average loss: 0.2734,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.2986,                   Accuracy: 1815/2000.0 (90.75%)



-= Testing valid =-
Test set: Average loss: 0.2738,                   Accuracy: 1829/2000.0 (91.45%)



-= Testing valid =-
Test set: Average loss: 0.3368,                   Accuracy: 1788/2000.0 (89.40%)



-= Testing valid =-
Test set: Average loss: 0.2936,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.3185,                   Accuracy: 1795/2000.0 (89.75%)



-= Testing valid =-
Test set: Average loss: 0.2289,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2679,                   Accuracy: 1835/2000.0 (91.75%)



Epoch 30 train accuracy: 89.31%, valid accuracy 91.75%
-= Testing valid =-
Test set: Average loss: 0.2345,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.2572,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2426,                   Accuracy: 1858/2000.0 (92.90%)



-= Testing valid =-
Test set: Average loss: 0.2500,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2515,                   Accuracy: 1846/2000.0 (92.30%)



-= Testing valid =-
Test set: Average loss: 0.2391,                   Accuracy: 1855/2000.0 (92.75%)



-= Testing valid =-
Test set: Average loss: 0.2734,                   Accuracy: 1824/2000.0 (91.20%)



-= Testing valid =-
Test set: Average loss: 0.2886,                   Accuracy: 1817/2000.0 (90.85%)



-= Testing valid =-
Test set: Average loss: 0.2131,                   Accuracy: 1868/2000.0 (93.40%)



-= Testing valid =-
Test set: Average loss: 0.2460,                   Accuracy: 1851/2000.0 (92.55%)



Epoch 40 train accuracy: 90.80%, valid accuracy 92.55%
-= Testing valid =-
Test set: Average loss: 0.2504,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2388,                   Accuracy: 1856/2000.0 (92.80%)



-= Testing valid =-
Test set: Average loss: 0.2512,                   Accuracy: 1849/2000.0 (92.45%)



-= Testing valid =-
Test set: Average loss: 0.2833,                   Accuracy: 1822/2000.0 (91.10%)



-= Testing valid =-
Test set: Average loss: 0.2575,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2641,                   Accuracy: 1843/2000.0 (92.15%)



-= Testing valid =-
Test set: Average loss: 0.2352,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2286,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.2540,                   Accuracy: 1842/2000.0 (92.10%)



-= Testing valid =-
Test set: Average loss: 0.2578,                   Accuracy: 1849/2000.0 (92.45%)



Epoch 50 train accuracy: 91.22%, valid accuracy 92.45%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2709,                   Accuracy: 55103/60000 (91.84%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2991,                   Accuracy: 54416/60000 (90.69%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.3043,                   Accuracy: 54451/60000 (90.75%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.3306,                   Accuracy: 54047/60000 (90.08%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.3545,                   Accuracy: 53664/60000 (89.44%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.3809,                   Accuracy: 53192/60000 (88.65%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.4055,                   Accuracy: 52746/60000 (87.91%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.4291,                   Accuracy: 52229/60000 (87.05%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.4434,                   Accuracy: 52058/60000 (86.76%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.4428,                   Accuracy: 52037/60000 (86.73%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.5032,                   Accuracy: 50700/60000 (84.50%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.5065,                   Accuracy: 50660/60000 (84.43%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.4962,                   Accuracy: 50994/60000 (84.99%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.4780,                   Accuracy: 51291/60000 (85.49%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.4485,                   Accuracy: 51793/60000 (86.32%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.4146,                   Accuracy: 52412/60000 (87.35%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.3910,                   Accuracy: 52778/60000 (87.96%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.3790,                   Accuracy: 52929/60000 (88.21%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.3629,                   Accuracy: 53304/60000 (88.84%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.3752,                   Accuracy: 53118/60000 (88.53%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.3696,                   Accuracy: 53145/60000 (88.57%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.3861,                   Accuracy: 53011/60000 (88.35%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.3914,                   Accuracy: 52947/60000 (88.25%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.4023,                   Accuracy: 52879/60000 (88.13%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.4171,                   Accuracy: 52615/60000 (87.69%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.4240,                   Accuracy: 52414/60000 (87.36%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.4341,                   Accuracy: 52040/60000 (86.73%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.4213,                   Accuracy: 52243/60000 (87.07%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.4375,                   Accuracy: 51954/60000 (86.59%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.4172,                   Accuracy: 52477/60000 (87.46%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.4045,                   Accuracy: 52727/60000 (87.88%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.3709,                   Accuracy: 53463/60000 (89.11%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.3334,                   Accuracy: 54150/60000 (90.25%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.3076,                   Accuracy: 54595/60000 (90.99%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2841,                   Accuracy: 54925/60000 (91.54%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2770,                   Accuracy: 54938/60000 (91.56%)
{0: tensor(91.8383), 10: tensor(90.6933), 20: tensor(90.7517), 30: tensor(90.0783), 40: tensor(89.4400), 50: tensor(88.6533), 60: tensor(87.9100), 70: tensor(87.0483), 80: tensor(86.7633), 90: tensor(86.7283), 100: tensor(84.5000), 110: tensor(84.4333), 120: tensor(84.9900), 130: tensor(85.4850), 140: tensor(86.3217), 150: tensor(87.3533), 160: tensor(87.9633), 170: tensor(88.2150), 180: tensor(88.8400), 190: tensor(88.5300), 200: tensor(88.5750), 210: tensor(88.3517), 220: tensor(88.2450), 230: tensor(88.1317), 240: tensor(87.6917), 250: tensor(87.3567), 260: tensor(86.7333), 270: tensor(87.0717), 280: tensor(86.5900), 290: tensor(87.4617), 300: tensor(87.8783), 310: tensor(89.1050), 320: tensor(90.2500), 330: tensor(90.9917), 340: tensor(91.5417), 350: tensor(91.5633)}
Namespace(batch_size=256, biased_mean=45.0, biased_std=5.0, biased_training=True, cuda=True, dataset_path='./', epochs=50, equivariance='Z2', input_size=28, log_interval=10, lr=0.01, no_cuda=False, nopool=False, pad=1, planes=20, rotated=False, samples=None, savestr='', seed=100, sharedCNN=False, sharedPool=False, shift_augment=False, step=10, test_batch_size=256, train_fraction=1.0, uniform=True, wd=1e-05)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
Net                                      --                        --
├─Conv2d: 1-1                            [256, 20, 28, 28]         560
├─BatchNorm2d: 1-2                       [256, 20, 28, 28]         40
├─Dropout: 1-3                           [256, 20, 28, 28]         --
├─Conv2d: 1-4                            [256, 20, 28, 28]         3,620
├─BatchNorm2d: 1-5                       [256, 20, 28, 28]         40
├─MaxPool2d: 1-6                         [256, 20, 14, 14]         --
├─Conv2d: 1-7                            [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-8                       [256, 20, 14, 14]         40
├─Dropout: 1-9                           [256, 20, 14, 14]         --
├─Conv2d: 1-10                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-11                      [256, 20, 14, 14]         40
├─Dropout: 1-12                          [256, 20, 14, 14]         --
├─Conv2d: 1-13                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-14                      [256, 20, 14, 14]         40
├─Dropout: 1-15                          [256, 20, 14, 14]         --
├─Conv2d: 1-16                           [256, 20, 14, 14]         3,620
├─BatchNorm2d: 1-17                      [256, 20, 14, 14]         40
├─Conv2d: 1-18                           [256, 20, 11, 11]         6,420
├─BatchNorm2d: 1-19                      [256, 20, 11, 11]         40
├─AdaptiveAvgPool2d: 1-20                [256, 20, 1, 1]           --
├─Linear: 1-21                           [256, 10]                 210
==========================================================================================
Total params: 25,570
Trainable params: 25,570
Non-trainable params: 0
Total mult-adds (G): 1.76
==========================================================================================
Input size (MB): 2.41
Forward/backward pass size (MB): 202.61
Params size (MB): 0.10
Estimated Total Size (MB): 205.12
==========================================================================================
TexNIST loading ./data/RotMNIST_nonrot_validation/ into memory...
TexNIST loaded 10000 samples from 10000 into memory.
TexNIST loading ./data/RotMNIST_scaled/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
TexNIST loading ./data/RotMNIST_nonrot/ into memory...
TexNIST loaded 60000 samples from 60000 into memory.
-= Testing valid =-
Test set: Average loss: 2.4902,                   Accuracy: 495/2000.0 (24.75%)



-= Testing valid =-
Test set: Average loss: 1.6999,                   Accuracy: 742/2000.0 (37.10%)



-= Testing valid =-
Test set: Average loss: 1.9215,                   Accuracy: 615/2000.0 (30.75%)



-= Testing valid =-
Test set: Average loss: 1.2471,                   Accuracy: 1069/2000.0 (53.45%)



-= Testing valid =-
Test set: Average loss: 1.7373,                   Accuracy: 780/2000.0 (39.00%)



-= Testing valid =-
Test set: Average loss: 1.0512,                   Accuracy: 1245/2000.0 (62.25%)



-= Testing valid =-
Test set: Average loss: 1.1593,                   Accuracy: 1288/2000.0 (64.40%)



-= Testing valid =-
Test set: Average loss: 0.6194,                   Accuracy: 1618/2000.0 (80.90%)



-= Testing valid =-
Test set: Average loss: 0.9803,                   Accuracy: 1197/2000.0 (59.85%)



-= Testing valid =-
Test set: Average loss: 0.7826,                   Accuracy: 1520/2000.0 (76.00%)



Epoch 10 train accuracy: 77.81%, valid accuracy 76.00%
-= Testing valid =-
Test set: Average loss: 0.3931,                   Accuracy: 1764/2000.0 (88.20%)



-= Testing valid =-
Test set: Average loss: 0.5902,                   Accuracy: 1609/2000.0 (80.45%)



-= Testing valid =-
Test set: Average loss: 0.5124,                   Accuracy: 1680/2000.0 (84.00%)



-= Testing valid =-
Test set: Average loss: 0.4064,                   Accuracy: 1734/2000.0 (86.70%)



-= Testing valid =-
Test set: Average loss: 0.2929,                   Accuracy: 1820/2000.0 (91.00%)



-= Testing valid =-
Test set: Average loss: 0.3609,                   Accuracy: 1797/2000.0 (89.85%)



-= Testing valid =-
Test set: Average loss: 0.4676,                   Accuracy: 1691/2000.0 (84.55%)



-= Testing valid =-
Test set: Average loss: 0.3749,                   Accuracy: 1786/2000.0 (89.30%)



-= Testing valid =-
Test set: Average loss: 0.3467,                   Accuracy: 1772/2000.0 (88.60%)



-= Testing valid =-
Test set: Average loss: 0.3311,                   Accuracy: 1773/2000.0 (88.65%)



Epoch 20 train accuracy: 87.71%, valid accuracy 88.65%
-= Testing valid =-
Test set: Average loss: 0.2428,                   Accuracy: 1864/2000.0 (93.20%)



-= Testing valid =-
Test set: Average loss: 0.3127,                   Accuracy: 1794/2000.0 (89.70%)



-= Testing valid =-
Test set: Average loss: 0.2606,                   Accuracy: 1840/2000.0 (92.00%)



-= Testing valid =-
Test set: Average loss: 0.3067,                   Accuracy: 1801/2000.0 (90.05%)



-= Testing valid =-
Test set: Average loss: 0.2231,                   Accuracy: 1866/2000.0 (93.30%)



-= Testing valid =-
Test set: Average loss: 0.2713,                   Accuracy: 1832/2000.0 (91.60%)



-= Testing valid =-
Test set: Average loss: 0.2366,                   Accuracy: 1857/2000.0 (92.85%)



-= Testing valid =-
Test set: Average loss: 0.1684,                   Accuracy: 1892/2000.0 (94.60%)



-= Testing valid =-
Test set: Average loss: 0.2434,                   Accuracy: 1845/2000.0 (92.25%)



-= Testing valid =-
Test set: Average loss: 0.2716,                   Accuracy: 1823/2000.0 (91.15%)



Epoch 30 train accuracy: 90.41%, valid accuracy 91.15%
-= Testing valid =-
Test set: Average loss: 0.2082,                   Accuracy: 1862/2000.0 (93.10%)



-= Testing valid =-
Test set: Average loss: 0.2097,                   Accuracy: 1875/2000.0 (93.75%)



-= Testing valid =-
Test set: Average loss: 0.2063,                   Accuracy: 1870/2000.0 (93.50%)



-= Testing valid =-
Test set: Average loss: 0.1947,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.2202,                   Accuracy: 1853/2000.0 (92.65%)



-= Testing valid =-
Test set: Average loss: 0.2666,                   Accuracy: 1814/2000.0 (90.70%)



-= Testing valid =-
Test set: Average loss: 0.2274,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.2028,                   Accuracy: 1869/2000.0 (93.45%)



-= Testing valid =-
Test set: Average loss: 0.2712,                   Accuracy: 1819/2000.0 (90.95%)



-= Testing valid =-
Test set: Average loss: 0.2451,                   Accuracy: 1847/2000.0 (92.35%)



Epoch 40 train accuracy: 91.41%, valid accuracy 92.35%
-= Testing valid =-
Test set: Average loss: 0.2429,                   Accuracy: 1839/2000.0 (91.95%)



-= Testing valid =-
Test set: Average loss: 0.2439,                   Accuracy: 1836/2000.0 (91.80%)



-= Testing valid =-
Test set: Average loss: 0.2193,                   Accuracy: 1863/2000.0 (93.15%)



-= Testing valid =-
Test set: Average loss: 0.1980,                   Accuracy: 1873/2000.0 (93.65%)



-= Testing valid =-
Test set: Average loss: 0.2023,                   Accuracy: 1879/2000.0 (93.95%)



-= Testing valid =-
Test set: Average loss: 0.2218,                   Accuracy: 1852/2000.0 (92.60%)



-= Testing valid =-
Test set: Average loss: 0.2390,                   Accuracy: 1841/2000.0 (92.05%)



-= Testing valid =-
Test set: Average loss: 0.2200,                   Accuracy: 1851/2000.0 (92.55%)



-= Testing valid =-
Test set: Average loss: 0.1982,                   Accuracy: 1882/2000.0 (94.10%)



-= Testing valid =-
Test set: Average loss: 0.2301,                   Accuracy: 1865/2000.0 (93.25%)



Epoch 50 train accuracy: 91.59%, valid accuracy 93.25%
Accuracies:
[]
-= Testing Rotation 0 =-
Test set: Average loss: 0.2016,                   Accuracy: 56441/60000 (94.07%)
-= Testing Rotation 10 =-
Test set: Average loss: 0.2130,                   Accuracy: 56226/60000 (93.71%)
-= Testing Rotation 20 =-
Test set: Average loss: 0.2158,                   Accuracy: 56217/60000 (93.69%)
-= Testing Rotation 30 =-
Test set: Average loss: 0.2259,                   Accuracy: 56004/60000 (93.34%)
-= Testing Rotation 40 =-
Test set: Average loss: 0.2349,                   Accuracy: 55847/60000 (93.08%)
-= Testing Rotation 50 =-
Test set: Average loss: 0.2493,                   Accuracy: 55532/60000 (92.55%)
-= Testing Rotation 60 =-
Test set: Average loss: 0.2673,                   Accuracy: 55160/60000 (91.93%)
-= Testing Rotation 70 =-
Test set: Average loss: 0.2880,                   Accuracy: 54718/60000 (91.20%)
-= Testing Rotation 80 =-
Test set: Average loss: 0.3064,                   Accuracy: 54230/60000 (90.38%)
-= Testing Rotation 90 =-
Test set: Average loss: 0.3101,                   Accuracy: 54037/60000 (90.06%)
-= Testing Rotation 100 =-
Test set: Average loss: 0.3259,                   Accuracy: 53852/60000 (89.75%)
-= Testing Rotation 110 =-
Test set: Average loss: 0.3296,                   Accuracy: 53518/60000 (89.20%)
-= Testing Rotation 120 =-
Test set: Average loss: 0.3348,                   Accuracy: 53210/60000 (88.68%)
-= Testing Rotation 130 =-
Test set: Average loss: 0.3424,                   Accuracy: 52999/60000 (88.33%)
-= Testing Rotation 140 =-
Test set: Average loss: 0.3582,                   Accuracy: 52578/60000 (87.63%)
-= Testing Rotation 150 =-
Test set: Average loss: 0.3710,                   Accuracy: 52207/60000 (87.01%)
-= Testing Rotation 160 =-
Test set: Average loss: 0.4050,                   Accuracy: 51420/60000 (85.70%)
-= Testing Rotation 170 =-
Test set: Average loss: 0.4245,                   Accuracy: 51149/60000 (85.25%)
-= Testing Rotation 180 =-
Test set: Average loss: 0.4284,                   Accuracy: 50809/60000 (84.68%)
-= Testing Rotation 190 =-
Test set: Average loss: 0.4574,                   Accuracy: 50311/60000 (83.85%)
-= Testing Rotation 200 =-
Test set: Average loss: 0.4442,                   Accuracy: 50649/60000 (84.42%)
-= Testing Rotation 210 =-
Test set: Average loss: 0.4317,                   Accuracy: 50836/60000 (84.73%)
-= Testing Rotation 220 =-
Test set: Average loss: 0.4108,                   Accuracy: 51462/60000 (85.77%)
-= Testing Rotation 230 =-
Test set: Average loss: 0.3934,                   Accuracy: 51889/60000 (86.48%)
-= Testing Rotation 240 =-
Test set: Average loss: 0.3734,                   Accuracy: 52417/60000 (87.36%)
-= Testing Rotation 250 =-
Test set: Average loss: 0.3590,                   Accuracy: 52792/60000 (87.99%)
-= Testing Rotation 260 =-
Test set: Average loss: 0.3461,                   Accuracy: 53273/60000 (88.79%)
-= Testing Rotation 270 =-
Test set: Average loss: 0.3159,                   Accuracy: 53867/60000 (89.78%)
-= Testing Rotation 280 =-
Test set: Average loss: 0.3053,                   Accuracy: 54371/60000 (90.62%)
-= Testing Rotation 290 =-
Test set: Average loss: 0.2982,                   Accuracy: 54425/60000 (90.71%)
-= Testing Rotation 300 =-
Test set: Average loss: 0.2832,                   Accuracy: 54662/60000 (91.10%)
-= Testing Rotation 310 =-
Test set: Average loss: 0.2693,                   Accuracy: 54972/60000 (91.62%)
-= Testing Rotation 320 =-
Test set: Average loss: 0.2524,                   Accuracy: 55410/60000 (92.35%)
-= Testing Rotation 330 =-
Test set: Average loss: 0.2340,                   Accuracy: 55761/60000 (92.93%)
-= Testing Rotation 340 =-
Test set: Average loss: 0.2230,                   Accuracy: 56038/60000 (93.40%)
-= Testing Rotation 350 =-
Test set: Average loss: 0.2167,                   Accuracy: 56153/60000 (93.59%)
{0: tensor(94.0683), 10: tensor(93.7100), 20: tensor(93.6950), 30: tensor(93.3400), 40: tensor(93.0783), 50: tensor(92.5533), 60: tensor(91.9333), 70: tensor(91.1967), 80: tensor(90.3833), 90: tensor(90.0617), 100: tensor(89.7533), 110: tensor(89.1967), 120: tensor(88.6833), 130: tensor(88.3317), 140: tensor(87.6300), 150: tensor(87.0117), 160: tensor(85.7000), 170: tensor(85.2483), 180: tensor(84.6817), 190: tensor(83.8517), 200: tensor(84.4150), 210: tensor(84.7267), 220: tensor(85.7700), 230: tensor(86.4817), 240: tensor(87.3617), 250: tensor(87.9867), 260: tensor(88.7883), 270: tensor(89.7783), 280: tensor(90.6183), 290: tensor(90.7083), 300: tensor(91.1033), 310: tensor(91.6200), 320: tensor(92.3500), 330: tensor(92.9350), 340: tensor(93.3967), 350: tensor(93.5883)}
